2023-08-21 14:27:35 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18390
2023-08-21 14:27:35 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18390
2023-08-21 14:27:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-21 14:27:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-21 14:27:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-08-21 14:27:35 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-21 14:27:35 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-08-21 14:27:35 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-21 14:27:37 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'checkpoints/mustc/enes-baseline', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18390', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 28, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints/mustc/enes-baseline', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 10, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_mustc_en_de', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9, 0.997)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_mustc_en_de', attention_dropout=0.1, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/mustc-enes-silent', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=28, max_tokens=4096, max_tokens_valid=4096, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_src_tgt_embed=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=2, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/mustc/enes-baseline', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang='en', stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang='es', task='translation', tensorboard_logdir='checkpoints/mustc/enes-baseline', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_config=None, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/mustc-enes-silent', 'source_lang': 'en', 'target_lang': 'es', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.997)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.001]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-08-21 14:27:37 | INFO | fairseq.tasks.translation | [en] dictionary: 9999 types
2023-08-21 14:27:37 | INFO | fairseq.tasks.translation | [es] dictionary: 9999 types
2023-08-21 14:27:38 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9999, bias=False)
  )
)
2023-08-21 14:27:38 | INFO | fairseq_cli.train | task: TranslationTask
2023-08-21 14:27:38 | INFO | fairseq_cli.train | model: TransformerModel
2023-08-21 14:27:38 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2023-08-21 14:27:38 | INFO | fairseq_cli.train | num. shared model params: 36,664,832 (num. trained: 36,664,832)
2023-08-21 14:27:38 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-21 14:27:38 | INFO | fairseq.data.data_utils | loaded 1,316 examples from: data-bin/mustc-enes-silent/valid.en-es.en
2023-08-21 14:27:38 | INFO | fairseq.data.data_utils | loaded 1,316 examples from: data-bin/mustc-enes-silent/valid.en-es.es
2023-08-21 14:27:38 | INFO | fairseq.tasks.translation | data-bin/mustc-enes-silent valid en-es 1316 examples
2023-08-21 14:27:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-21 14:27:38 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
2023-08-21 14:27:38 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-08-21 14:27:38 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-08-21 14:27:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2023-08-21 14:27:38 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 14:27:38 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 14:27:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2023-08-21 14:27:38 | INFO | fairseq_cli.train | training on 2 devices (GPUs/TPUs)
2023-08-21 14:27:38 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None
2023-08-21 14:27:38 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/mustc/enes-baseline/checkpoint_last.pt
2023-08-21 14:27:38 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/mustc/enes-baseline/checkpoint_last.pt
2023-08-21 14:27:38 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-21 14:27:38 | INFO | fairseq.data.data_utils | loaded 317,472 examples from: data-bin/mustc-enes-silent/train.en-es.en
2023-08-21 14:27:38 | INFO | fairseq.data.data_utils | loaded 317,472 examples from: data-bin/mustc-enes-silent/train.en-es.es
2023-08-21 14:27:38 | INFO | fairseq.tasks.translation | data-bin/mustc-enes-silent train en-es 317472 examples
2023-08-21 14:27:38 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-21 14:27:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:27:38 | INFO | fairseq.trainer | begin training epoch 1
2023-08-21 14:27:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:27:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-21 14:27:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-21 14:27:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-21 14:27:50 | INFO | train_inner | epoch 001:    103 / 1265 loss=13, nll_loss=12.843, ppl=7345.92, wps=80934.2, ups=11.83, wpb=6815.4, bsz=235.7, num_updates=100, lr=2.50975e-05, gnorm=3.416, loss_scale=16, train_wall=9, gb_free=21.7, wall=12
2023-08-21 14:27:58 | INFO | train_inner | epoch 001:    203 / 1265 loss=10.671, nll_loss=10.27, ppl=1234.36, wps=85083.4, ups=12.32, wpb=6906, bsz=241.6, num_updates=200, lr=5.0095e-05, gnorm=0.724, loss_scale=16, train_wall=8, gb_free=21.9, wall=20
2023-08-21 14:28:06 | INFO | train_inner | epoch 001:    303 / 1265 loss=10.063, nll_loss=9.534, ppl=741.39, wps=84406.9, ups=12.29, wpb=6865.7, bsz=232.6, num_updates=300, lr=7.50925e-05, gnorm=0.545, loss_scale=16, train_wall=8, gb_free=21.7, wall=28
2023-08-21 14:28:14 | INFO | train_inner | epoch 001:    403 / 1265 loss=9.798, nll_loss=9.212, ppl=593.09, wps=85948.1, ups=12.41, wpb=6927.1, bsz=251.5, num_updates=400, lr=0.00010009, gnorm=0.72, loss_scale=16, train_wall=8, gb_free=21.8, wall=36
2023-08-21 14:28:22 | INFO | train_inner | epoch 001:    503 / 1265 loss=9.432, nll_loss=8.791, ppl=442.92, wps=85057.7, ups=12.44, wpb=6837.2, bsz=270.8, num_updates=500, lr=0.000125087, gnorm=0.852, loss_scale=16, train_wall=8, gb_free=21.8, wall=44
2023-08-21 14:28:31 | INFO | train_inner | epoch 001:    603 / 1265 loss=9.148, nll_loss=8.46, ppl=352.14, wps=83895.3, ups=12.31, wpb=6817.6, bsz=246.3, num_updates=600, lr=0.000150085, gnorm=0.794, loss_scale=16, train_wall=8, gb_free=21.7, wall=52
2023-08-21 14:28:39 | INFO | train_inner | epoch 001:    703 / 1265 loss=8.74, nll_loss=7.988, ppl=253.92, wps=86592.6, ups=12.52, wpb=6918, bsz=262.6, num_updates=700, lr=0.000175082, gnorm=0.945, loss_scale=16, train_wall=8, gb_free=22, wall=60
2023-08-21 14:28:47 | INFO | train_inner | epoch 001:    803 / 1265 loss=8.353, nll_loss=7.541, ppl=186.22, wps=87076.2, ups=12.56, wpb=6933.7, bsz=246.2, num_updates=800, lr=0.00020008, gnorm=0.915, loss_scale=16, train_wall=8, gb_free=21.8, wall=68
2023-08-21 14:28:55 | INFO | train_inner | epoch 001:    903 / 1265 loss=7.999, nll_loss=7.131, ppl=140.21, wps=85139.1, ups=12.34, wpb=6898.7, bsz=247, num_updates=900, lr=0.000225077, gnorm=0.938, loss_scale=16, train_wall=8, gb_free=21.7, wall=76
2023-08-21 14:29:03 | INFO | train_inner | epoch 001:   1003 / 1265 loss=7.677, nll_loss=6.759, ppl=108.32, wps=86132.4, ups=12.46, wpb=6915, bsz=239.1, num_updates=1000, lr=0.000250075, gnorm=0.836, loss_scale=16, train_wall=8, gb_free=21.8, wall=84
2023-08-21 14:29:11 | INFO | train_inner | epoch 001:   1103 / 1265 loss=7.293, nll_loss=6.314, ppl=79.54, wps=87793.6, ups=12.62, wpb=6957.8, bsz=279.9, num_updates=1100, lr=0.000275072, gnorm=0.914, loss_scale=16, train_wall=8, gb_free=21.9, wall=92
2023-08-21 14:29:19 | INFO | train_inner | epoch 001:   1203 / 1265 loss=7.101, nll_loss=6.09, ppl=68.14, wps=85087.8, ups=12.42, wpb=6852, bsz=243.9, num_updates=1200, lr=0.00030007, gnorm=0.897, loss_scale=16, train_wall=8, gb_free=21.8, wall=100
2023-08-21 14:29:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-21 14:29:26 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.708 | nll_loss 5.597 | ppl 48.4 | wps 143605 | wpb 3858.1 | bsz 131.6 | num_updates 1262
2023-08-21 14:29:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1262 updates
2023-08-21 14:29:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint1.pt
2023-08-21 14:29:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint1.pt
2023-08-21 14:29:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint1.pt (epoch 1 @ 1262 updates, score 6.708) (writing took 1.292573729006108 seconds)
2023-08-21 14:29:27 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-21 14:29:27 | INFO | train | epoch 001 | loss 8.993 | nll_loss 8.28 | ppl 310.92 | wps 82289.3 | ups 11.96 | wpb 6879.6 | bsz 249.9 | num_updates 1262 | lr 0.000315568 | gnorm 1.033 | loss_scale 16 | train_wall 100 | gb_free 21.9 | wall 109
2023-08-21 14:29:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:29:27 | INFO | fairseq.trainer | begin training epoch 2
2023-08-21 14:29:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:29:32 | INFO | train_inner | epoch 002:     38 / 1265 loss=6.785, nll_loss=5.724, ppl=52.87, wps=49569.5, ups=7.35, wpb=6744.6, bsz=255.5, num_updates=1300, lr=0.000325067, gnorm=0.865, loss_scale=16, train_wall=8, gb_free=21.7, wall=114
2023-08-21 14:29:40 | INFO | train_inner | epoch 002:    138 / 1265 loss=6.61, nll_loss=5.516, ppl=45.75, wps=89598, ups=12.91, wpb=6941.5, bsz=244.6, num_updates=1400, lr=0.000350065, gnorm=0.929, loss_scale=16, train_wall=7, gb_free=21.8, wall=122
2023-08-21 14:29:48 | INFO | train_inner | epoch 002:    238 / 1265 loss=6.337, nll_loss=5.197, ppl=36.68, wps=89874.2, ups=12.93, wpb=6951.8, bsz=266.2, num_updates=1500, lr=0.000375062, gnorm=0.87, loss_scale=16, train_wall=8, gb_free=21.7, wall=130
2023-08-21 14:29:56 | INFO | train_inner | epoch 002:    338 / 1265 loss=6.163, nll_loss=4.993, ppl=31.84, wps=87512.9, ups=12.71, wpb=6884.1, bsz=257.4, num_updates=1600, lr=0.00040006, gnorm=0.833, loss_scale=16, train_wall=8, gb_free=22, wall=137
2023-08-21 14:30:03 | INFO | train_inner | epoch 002:    438 / 1265 loss=5.964, nll_loss=4.758, ppl=27.05, wps=88228.6, ups=12.77, wpb=6910.4, bsz=260.1, num_updates=1700, lr=0.000425057, gnorm=0.852, loss_scale=16, train_wall=8, gb_free=21.8, wall=145
2023-08-21 14:30:11 | INFO | train_inner | epoch 002:    538 / 1265 loss=5.912, nll_loss=4.694, ppl=25.88, wps=86334.1, ups=12.54, wpb=6885.9, bsz=236, num_updates=1800, lr=0.000450055, gnorm=0.801, loss_scale=16, train_wall=8, gb_free=21.7, wall=153
2023-08-21 14:30:19 | INFO | train_inner | epoch 002:    638 / 1265 loss=5.644, nll_loss=4.384, ppl=20.87, wps=87983.9, ups=12.53, wpb=7024, bsz=258.4, num_updates=1900, lr=0.000475052, gnorm=0.792, loss_scale=16, train_wall=8, gb_free=21.7, wall=161
2023-08-21 14:30:27 | INFO | train_inner | epoch 002:    738 / 1265 loss=5.511, nll_loss=4.226, ppl=18.72, wps=85173.8, ups=12.41, wpb=6863.5, bsz=247.6, num_updates=2000, lr=0.00050005, gnorm=0.784, loss_scale=16, train_wall=8, gb_free=21.7, wall=169
2023-08-21 14:30:35 | INFO | train_inner | epoch 002:    838 / 1265 loss=5.414, nll_loss=4.112, ppl=17.29, wps=85914.8, ups=12.55, wpb=6843.4, bsz=253.4, num_updates=2100, lr=0.000525047, gnorm=0.819, loss_scale=16, train_wall=8, gb_free=21.7, wall=177
2023-08-21 14:30:44 | INFO | train_inner | epoch 002:    938 / 1265 loss=5.355, nll_loss=4.042, ppl=16.47, wps=84238.2, ups=12.4, wpb=6794.9, bsz=245.4, num_updates=2200, lr=0.000550045, gnorm=0.795, loss_scale=16, train_wall=8, gb_free=21.7, wall=185
2023-08-21 14:30:51 | INFO | train_inner | epoch 002:   1038 / 1265 loss=5.204, nll_loss=3.867, ppl=14.59, wps=87489.3, ups=12.64, wpb=6921.5, bsz=233.4, num_updates=2300, lr=0.000575042, gnorm=0.712, loss_scale=16, train_wall=8, gb_free=21.6, wall=193
2023-08-21 14:30:59 | INFO | train_inner | epoch 002:   1138 / 1265 loss=5.071, nll_loss=3.716, ppl=13.14, wps=86863.9, ups=12.79, wpb=6789.8, bsz=263.4, num_updates=2400, lr=0.00060004, gnorm=0.714, loss_scale=16, train_wall=8, gb_free=21.8, wall=201
2023-08-21 14:31:07 | INFO | train_inner | epoch 002:   1238 / 1265 loss=4.977, nll_loss=3.608, ppl=12.2, wps=86290.3, ups=12.57, wpb=6866.9, bsz=256.6, num_updates=2500, lr=0.000625037, gnorm=0.69, loss_scale=16, train_wall=8, gb_free=21.7, wall=209
2023-08-21 14:31:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:31:12 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.819 | nll_loss 3.393 | ppl 10.51 | wps 153695 | wpb 3858.1 | bsz 131.6 | num_updates 2527 | best_loss 4.819
2023-08-21 14:31:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2527 updates
2023-08-21 14:31:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint2.pt
2023-08-21 14:31:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint2.pt
2023-08-21 14:31:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint2.pt (epoch 2 @ 2527 updates, score 4.819) (writing took 3.345613491954282 seconds)
2023-08-21 14:31:15 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-21 14:31:15 | INFO | train | epoch 002 | loss 5.699 | nll_loss 4.448 | ppl 21.83 | wps 80846 | ups 11.75 | wpb 6881.3 | bsz 251 | num_updates 2527 | lr 0.000631787 | gnorm 0.799 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 217
2023-08-21 14:31:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:31:15 | INFO | fairseq.trainer | begin training epoch 3
2023-08-21 14:31:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:31:23 | INFO | train_inner | epoch 003:     73 / 1265 loss=4.865, nll_loss=3.479, ppl=11.15, wps=44461.6, ups=6.45, wpb=6898, bsz=259.5, num_updates=2600, lr=0.000650035, gnorm=0.66, loss_scale=16, train_wall=8, gb_free=21.8, wall=225
2023-08-21 14:31:31 | INFO | train_inner | epoch 003:    173 / 1265 loss=4.877, nll_loss=3.492, ppl=11.25, wps=87824.7, ups=12.81, wpb=6855.6, bsz=235.7, num_updates=2700, lr=0.000675032, gnorm=0.667, loss_scale=16, train_wall=8, gb_free=21.8, wall=232
2023-08-21 14:31:38 | INFO | train_inner | epoch 003:    273 / 1265 loss=4.774, nll_loss=3.374, ppl=10.37, wps=91386.3, ups=13.24, wpb=6904.2, bsz=246.4, num_updates=2800, lr=0.00070003, gnorm=0.657, loss_scale=16, train_wall=7, gb_free=21.8, wall=240
2023-08-21 14:31:46 | INFO | train_inner | epoch 003:    373 / 1265 loss=4.781, nll_loss=3.381, ppl=10.42, wps=88645.7, ups=13.13, wpb=6749.4, bsz=237.1, num_updates=2900, lr=0.000725027, gnorm=0.663, loss_scale=16, train_wall=7, gb_free=21.8, wall=248
2023-08-21 14:31:53 | INFO | train_inner | epoch 003:    473 / 1265 loss=4.705, nll_loss=3.295, ppl=9.81, wps=88530.6, ups=12.91, wpb=6858.6, bsz=256, num_updates=3000, lr=0.000750025, gnorm=0.638, loss_scale=16, train_wall=8, gb_free=21.7, wall=255
2023-08-21 14:32:01 | INFO | train_inner | epoch 003:    573 / 1265 loss=4.694, nll_loss=3.283, ppl=9.74, wps=88239.6, ups=12.78, wpb=6903.5, bsz=239.9, num_updates=3100, lr=0.000775022, gnorm=0.643, loss_scale=16, train_wall=8, gb_free=21.7, wall=263
2023-08-21 14:32:09 | INFO | train_inner | epoch 003:    673 / 1265 loss=4.664, nll_loss=3.248, ppl=9.5, wps=86878.5, ups=12.71, wpb=6835.9, bsz=245.7, num_updates=3200, lr=0.00080002, gnorm=0.64, loss_scale=16, train_wall=8, gb_free=22, wall=271
2023-08-21 14:32:17 | INFO | train_inner | epoch 003:    773 / 1265 loss=4.55, nll_loss=3.12, ppl=8.69, wps=88036, ups=12.58, wpb=6995.4, bsz=265.6, num_updates=3300, lr=0.000825017, gnorm=0.572, loss_scale=16, train_wall=8, gb_free=21.8, wall=279
2023-08-21 14:32:25 | INFO | train_inner | epoch 003:    873 / 1265 loss=4.635, nll_loss=3.217, ppl=9.3, wps=85366.4, ups=12.58, wpb=6785.5, bsz=255.3, num_updates=3400, lr=0.000850015, gnorm=0.658, loss_scale=16, train_wall=8, gb_free=22, wall=287
2023-08-21 14:32:33 | INFO | train_inner | epoch 003:    973 / 1265 loss=4.634, nll_loss=3.217, ppl=9.3, wps=88361.7, ups=12.94, wpb=6829.5, bsz=225.6, num_updates=3500, lr=0.000875012, gnorm=0.592, loss_scale=16, train_wall=8, gb_free=21.8, wall=295
2023-08-21 14:32:40 | INFO | train_inner | epoch 003:   1073 / 1265 loss=4.549, nll_loss=3.121, ppl=8.7, wps=90881.8, ups=13.03, wpb=6972.9, bsz=262.4, num_updates=3600, lr=0.00090001, gnorm=0.559, loss_scale=16, train_wall=7, gb_free=21.7, wall=302
2023-08-21 14:32:48 | INFO | train_inner | epoch 003:   1173 / 1265 loss=4.513, nll_loss=3.078, ppl=8.44, wps=88195.9, ups=12.84, wpb=6867.9, bsz=270.2, num_updates=3700, lr=0.000925007, gnorm=0.624, loss_scale=16, train_wall=8, gb_free=21.7, wall=310
2023-08-21 14:32:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:32:57 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.407 | nll_loss 2.895 | ppl 7.44 | wps 134646 | wpb 3858.1 | bsz 131.6 | num_updates 3792 | best_loss 4.407
2023-08-21 14:32:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3792 updates
2023-08-21 14:32:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint3.pt
2023-08-21 14:32:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint3.pt
2023-08-21 14:33:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint3.pt (epoch 3 @ 3792 updates, score 4.407) (writing took 3.08569522597827 seconds)
2023-08-21 14:33:00 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-21 14:33:00 | INFO | train | epoch 003 | loss 4.663 | nll_loss 3.249 | ppl 9.51 | wps 82447.4 | ups 11.98 | wpb 6881.3 | bsz 251 | num_updates 3792 | lr 0.000948005 | gnorm 0.623 | loss_scale 16 | train_wall 95 | gb_free 21.7 | wall 322
2023-08-21 14:33:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:33:00 | INFO | fairseq.trainer | begin training epoch 4
2023-08-21 14:33:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:33:03 | INFO | train_inner | epoch 004:      8 / 1265 loss=4.458, nll_loss=3.019, ppl=8.11, wps=46530.2, ups=6.68, wpb=6961.6, bsz=246.6, num_updates=3800, lr=0.000950005, gnorm=0.542, loss_scale=16, train_wall=7, gb_free=21.7, wall=325
2023-08-21 14:33:11 | INFO | train_inner | epoch 004:    108 / 1265 loss=4.309, nll_loss=2.849, ppl=7.21, wps=87671.5, ups=12.63, wpb=6943.6, bsz=253, num_updates=3900, lr=0.000975002, gnorm=0.533, loss_scale=16, train_wall=8, gb_free=21.7, wall=333
2023-08-21 14:33:19 | INFO | train_inner | epoch 004:    208 / 1265 loss=4.365, nll_loss=2.912, ppl=7.53, wps=93482.4, ups=13.43, wpb=6960.7, bsz=247.7, num_updates=4000, lr=0.001, gnorm=0.523, loss_scale=16, train_wall=7, gb_free=21.8, wall=340
2023-08-21 14:33:26 | INFO | train_inner | epoch 004:    308 / 1265 loss=4.358, nll_loss=2.908, ppl=7.51, wps=91102.9, ups=13.3, wpb=6847.5, bsz=265.7, num_updates=4100, lr=0.00098773, gnorm=0.525, loss_scale=16, train_wall=7, gb_free=21.9, wall=348
2023-08-21 14:33:34 | INFO | train_inner | epoch 004:    408 / 1265 loss=4.344, nll_loss=2.891, ppl=7.42, wps=90670.4, ups=13.28, wpb=6825.2, bsz=254.4, num_updates=4200, lr=0.0009759, gnorm=0.514, loss_scale=16, train_wall=7, gb_free=21.8, wall=355
2023-08-21 14:33:41 | INFO | train_inner | epoch 004:    508 / 1265 loss=4.361, nll_loss=2.912, ppl=7.53, wps=86471.7, ups=12.81, wpb=6748.2, bsz=248.6, num_updates=4300, lr=0.000964486, gnorm=0.524, loss_scale=16, train_wall=8, gb_free=21.9, wall=363
2023-08-21 14:33:49 | INFO | train_inner | epoch 004:    608 / 1265 loss=4.333, nll_loss=2.88, ppl=7.36, wps=90521.1, ups=13.09, wpb=6914.5, bsz=238.7, num_updates=4400, lr=0.000953463, gnorm=0.488, loss_scale=16, train_wall=7, gb_free=21.7, wall=371
2023-08-21 14:33:57 | INFO | train_inner | epoch 004:    708 / 1265 loss=4.295, nll_loss=2.84, ppl=7.16, wps=90336.6, ups=13.24, wpb=6824.4, bsz=274, num_updates=4500, lr=0.000942809, gnorm=0.507, loss_scale=16, train_wall=7, gb_free=21.9, wall=378
2023-08-21 14:34:04 | INFO | train_inner | epoch 004:    808 / 1265 loss=4.271, nll_loss=2.813, ppl=7.03, wps=88090.2, ups=12.86, wpb=6848.5, bsz=244.5, num_updates=4600, lr=0.000932505, gnorm=0.463, loss_scale=16, train_wall=8, gb_free=22, wall=386
2023-08-21 14:34:12 | INFO | train_inner | epoch 004:    908 / 1265 loss=4.235, nll_loss=2.774, ppl=6.84, wps=89206.1, ups=13.14, wpb=6790, bsz=232.5, num_updates=4700, lr=0.000922531, gnorm=0.468, loss_scale=16, train_wall=7, gb_free=21.8, wall=394
2023-08-21 14:34:19 | INFO | train_inner | epoch 004:   1008 / 1265 loss=4.151, nll_loss=2.679, ppl=6.4, wps=95664.3, ups=13.63, wpb=7019.9, bsz=249.8, num_updates=4800, lr=0.000912871, gnorm=0.434, loss_scale=16, train_wall=7, gb_free=21.8, wall=401
2023-08-21 14:34:27 | INFO | train_inner | epoch 004:   1108 / 1265 loss=4.189, nll_loss=2.722, ppl=6.6, wps=90931, ups=12.99, wpb=6997.9, bsz=232.6, num_updates=4900, lr=0.000903508, gnorm=0.439, loss_scale=16, train_wall=7, gb_free=21.9, wall=409
2023-08-21 14:34:34 | INFO | train_inner | epoch 004:   1208 / 1265 loss=4.136, nll_loss=2.665, ppl=6.34, wps=92784.7, ups=13.57, wpb=6836.5, bsz=260.4, num_updates=5000, lr=0.000894427, gnorm=0.437, loss_scale=16, train_wall=7, gb_free=21.6, wall=416
2023-08-21 14:34:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:34:41 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.099 | nll_loss 2.567 | ppl 5.93 | wps 202702 | wpb 3858.1 | bsz 131.6 | num_updates 5057 | best_loss 4.099
2023-08-21 14:34:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5057 updates
2023-08-21 14:34:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint4.pt
2023-08-21 14:34:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint4.pt
2023-08-21 14:34:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint4.pt (epoch 4 @ 5057 updates, score 4.099) (writing took 2.604520950000733 seconds)
2023-08-21 14:34:44 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-21 14:34:44 | INFO | train | epoch 004 | loss 4.271 | nll_loss 2.812 | ppl 7.02 | wps 84436.2 | ups 12.27 | wpb 6881.3 | bsz 251 | num_updates 5057 | lr 0.000889372 | gnorm 0.485 | loss_scale 16 | train_wall 93 | gb_free 21.8 | wall 425
2023-08-21 14:34:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:34:44 | INFO | fairseq.trainer | begin training epoch 5
2023-08-21 14:34:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:34:49 | INFO | train_inner | epoch 005:     43 / 1265 loss=4.069, nll_loss=2.588, ppl=6.01, wps=47037.6, ups=6.86, wpb=6855.9, bsz=259.3, num_updates=5100, lr=0.000885615, gnorm=0.42, loss_scale=16, train_wall=7, gb_free=21.8, wall=431
2023-08-21 14:34:57 | INFO | train_inner | epoch 005:    143 / 1265 loss=4.023, nll_loss=2.534, ppl=5.79, wps=90137.2, ups=13.12, wpb=6868.8, bsz=247.5, num_updates=5200, lr=0.000877058, gnorm=0.422, loss_scale=16, train_wall=7, gb_free=21.8, wall=438
2023-08-21 14:35:04 | INFO | train_inner | epoch 005:    243 / 1265 loss=4.028, nll_loss=2.538, ppl=5.81, wps=93582.8, ups=13.55, wpb=6908.2, bsz=231.6, num_updates=5300, lr=0.000868744, gnorm=0.418, loss_scale=16, train_wall=7, gb_free=21.8, wall=446
2023-08-21 14:35:11 | INFO | train_inner | epoch 005:    343 / 1265 loss=3.977, nll_loss=2.483, ppl=5.59, wps=97650.2, ups=13.94, wpb=7004.5, bsz=257.6, num_updates=5400, lr=0.000860663, gnorm=0.397, loss_scale=16, train_wall=7, gb_free=22, wall=453
2023-08-21 14:35:19 | INFO | train_inner | epoch 005:    443 / 1265 loss=4.012, nll_loss=2.524, ppl=5.75, wps=93245.8, ups=13.53, wpb=6889.6, bsz=249.5, num_updates=5500, lr=0.000852803, gnorm=0.403, loss_scale=16, train_wall=7, gb_free=22.1, wall=460
2023-08-21 14:35:26 | INFO | train_inner | epoch 005:    543 / 1265 loss=4.008, nll_loss=2.52, ppl=5.73, wps=93431.3, ups=13.69, wpb=6822.9, bsz=240.7, num_updates=5600, lr=0.000845154, gnorm=0.41, loss_scale=16, train_wall=7, gb_free=21.8, wall=468
2023-08-21 14:35:33 | INFO | train_inner | epoch 005:    643 / 1265 loss=3.982, nll_loss=2.493, ppl=5.63, wps=89757.8, ups=13.25, wpb=6773.3, bsz=272.6, num_updates=5700, lr=0.000837708, gnorm=0.397, loss_scale=16, train_wall=7, gb_free=21.8, wall=475
2023-08-21 14:35:41 | INFO | train_inner | epoch 005:    743 / 1265 loss=3.984, nll_loss=2.493, ppl=5.63, wps=88629.1, ups=12.96, wpb=6836.9, bsz=240.9, num_updates=5800, lr=0.000830455, gnorm=0.399, loss_scale=16, train_wall=7, gb_free=21.7, wall=483
2023-08-21 14:35:50 | INFO | train_inner | epoch 005:    843 / 1265 loss=3.924, nll_loss=2.427, ppl=5.38, wps=80476.9, ups=11.65, wpb=6909.8, bsz=271.8, num_updates=5900, lr=0.000823387, gnorm=0.382, loss_scale=16, train_wall=8, gb_free=21.9, wall=492
2023-08-21 14:35:58 | INFO | train_inner | epoch 005:    943 / 1265 loss=3.989, nll_loss=2.501, ppl=5.66, wps=84888.6, ups=12.5, wpb=6790.2, bsz=235.5, num_updates=6000, lr=0.000816497, gnorm=0.395, loss_scale=16, train_wall=8, gb_free=21.8, wall=500
2023-08-21 14:36:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-21 14:36:06 | INFO | train_inner | epoch 005:   1044 / 1265 loss=3.981, nll_loss=2.492, ppl=5.62, wps=86738.8, ups=12.63, wpb=6868.1, bsz=241.8, num_updates=6100, lr=0.000809776, gnorm=0.392, loss_scale=8, train_wall=8, gb_free=21.8, wall=507
2023-08-21 14:36:13 | INFO | train_inner | epoch 005:   1144 / 1265 loss=3.923, nll_loss=2.427, ppl=5.38, wps=91703.3, ups=13.1, wpb=7002.6, bsz=273.8, num_updates=6200, lr=0.000803219, gnorm=0.394, loss_scale=8, train_wall=7, gb_free=21.8, wall=515
2023-08-21 14:36:21 | INFO | train_inner | epoch 005:   1244 / 1265 loss=3.954, nll_loss=2.464, ppl=5.52, wps=88145.5, ups=12.68, wpb=6949.3, bsz=247.8, num_updates=6300, lr=0.000796819, gnorm=0.383, loss_scale=8, train_wall=8, gb_free=22, wall=523
2023-08-21 14:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:36:25 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.961 | nll_loss 2.423 | ppl 5.36 | wps 192122 | wpb 3858.1 | bsz 131.6 | num_updates 6321 | best_loss 3.961
2023-08-21 14:36:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6321 updates
2023-08-21 14:36:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint5.pt
2023-08-21 14:36:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint5.pt
2023-08-21 14:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint5.pt (epoch 5 @ 6321 updates, score 3.961) (writing took 3.391190477006603 seconds)
2023-08-21 14:36:29 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-21 14:36:29 | INFO | train | epoch 005 | loss 3.982 | nll_loss 2.491 | ppl 5.62 | wps 82383.1 | ups 11.97 | wpb 6880.6 | bsz 250.3 | num_updates 6321 | lr 0.000795494 | gnorm 0.4 | loss_scale 8 | train_wall 94 | gb_free 21.9 | wall 531
2023-08-21 14:36:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:36:29 | INFO | fairseq.trainer | begin training epoch 6
2023-08-21 14:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:36:38 | INFO | train_inner | epoch 006:     79 / 1265 loss=3.842, nll_loss=2.332, ppl=5.03, wps=40621.8, ups=6.06, wpb=6697.8, bsz=225.6, num_updates=6400, lr=0.000790569, gnorm=0.372, loss_scale=8, train_wall=8, gb_free=21.7, wall=539
2023-08-21 14:36:45 | INFO | train_inner | epoch 006:    179 / 1265 loss=3.774, nll_loss=2.256, ppl=4.78, wps=90807.4, ups=12.91, wpb=7036.5, bsz=276.2, num_updates=6500, lr=0.000784465, gnorm=0.363, loss_scale=8, train_wall=7, gb_free=21.8, wall=547
2023-08-21 14:36:53 | INFO | train_inner | epoch 006:    279 / 1265 loss=3.803, nll_loss=2.288, ppl=4.89, wps=87678.4, ups=12.64, wpb=6938, bsz=259.2, num_updates=6600, lr=0.000778499, gnorm=0.367, loss_scale=8, train_wall=8, gb_free=21.8, wall=555
2023-08-21 14:37:01 | INFO | train_inner | epoch 006:    379 / 1265 loss=3.807, nll_loss=2.294, ppl=4.9, wps=86645.4, ups=12.47, wpb=6950, bsz=230.1, num_updates=6700, lr=0.000772667, gnorm=0.362, loss_scale=8, train_wall=8, gb_free=21.8, wall=563
2023-08-21 14:37:09 | INFO | train_inner | epoch 006:    479 / 1265 loss=3.798, nll_loss=2.285, ppl=4.87, wps=88146.6, ups=12.74, wpb=6920.2, bsz=244, num_updates=6800, lr=0.000766965, gnorm=0.36, loss_scale=8, train_wall=8, gb_free=22, wall=571
2023-08-21 14:37:17 | INFO | train_inner | epoch 006:    579 / 1265 loss=3.757, nll_loss=2.239, ppl=4.72, wps=89904.5, ups=12.94, wpb=6947.6, bsz=272.7, num_updates=6900, lr=0.000761387, gnorm=0.352, loss_scale=8, train_wall=7, gb_free=21.8, wall=579
2023-08-21 14:37:25 | INFO | train_inner | epoch 006:    679 / 1265 loss=3.837, nll_loss=2.33, ppl=5.03, wps=87075.8, ups=12.68, wpb=6865.9, bsz=238.5, num_updates=7000, lr=0.000755929, gnorm=0.363, loss_scale=8, train_wall=8, gb_free=21.7, wall=587
2023-08-21 14:37:32 | INFO | train_inner | epoch 006:    779 / 1265 loss=3.837, nll_loss=2.332, ppl=5.03, wps=88567, ups=13.06, wpb=6781.6, bsz=256.6, num_updates=7100, lr=0.000750587, gnorm=0.358, loss_scale=8, train_wall=7, gb_free=21.9, wall=594
2023-08-21 14:37:40 | INFO | train_inner | epoch 006:    879 / 1265 loss=3.83, nll_loss=2.325, ppl=5.01, wps=89418.8, ups=12.85, wpb=6961.1, bsz=248.4, num_updates=7200, lr=0.000745356, gnorm=0.355, loss_scale=8, train_wall=8, gb_free=21.7, wall=602
2023-08-21 14:37:48 | INFO | train_inner | epoch 006:    979 / 1265 loss=3.75, nll_loss=2.234, ppl=4.7, wps=92958.7, ups=13.3, wpb=6987.3, bsz=262.2, num_updates=7300, lr=0.000740233, gnorm=0.336, loss_scale=8, train_wall=7, gb_free=21.8, wall=610
2023-08-21 14:37:55 | INFO | train_inner | epoch 006:   1079 / 1265 loss=3.789, nll_loss=2.277, ppl=4.85, wps=89500.3, ups=13.21, wpb=6773.4, bsz=240.9, num_updates=7400, lr=0.000735215, gnorm=0.356, loss_scale=8, train_wall=7, gb_free=21.7, wall=617
2023-08-21 14:38:03 | INFO | train_inner | epoch 006:   1179 / 1265 loss=3.814, nll_loss=2.307, ppl=4.95, wps=87397.9, ups=12.71, wpb=6877.1, bsz=242.4, num_updates=7500, lr=0.000730297, gnorm=0.351, loss_scale=8, train_wall=8, gb_free=21.8, wall=625
2023-08-21 14:38:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:38:12 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.883 | nll_loss 2.34 | ppl 5.06 | wps 131160 | wpb 3858.1 | bsz 131.6 | num_updates 7586 | best_loss 3.883
2023-08-21 14:38:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 7586 updates
2023-08-21 14:38:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint6.pt
2023-08-21 14:38:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint6.pt
2023-08-21 14:38:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint6.pt (epoch 6 @ 7586 updates, score 3.883) (writing took 4.131155151990242 seconds)
2023-08-21 14:38:16 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-21 14:38:16 | INFO | train | epoch 006 | loss 3.798 | nll_loss 2.286 | ppl 4.88 | wps 81137.6 | ups 11.79 | wpb 6881.3 | bsz 251 | num_updates 7586 | lr 0.000726145 | gnorm 0.357 | loss_scale 8 | train_wall 95 | gb_free 21.7 | wall 638
2023-08-21 14:38:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:38:16 | INFO | fairseq.trainer | begin training epoch 7
2023-08-21 14:38:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:38:20 | INFO | train_inner | epoch 007:     14 / 1265 loss=3.744, nll_loss=2.228, ppl=4.68, wps=40769.4, ups=6.07, wpb=6712.3, bsz=258.5, num_updates=7600, lr=0.000725476, gnorm=0.347, loss_scale=8, train_wall=7, gb_free=21.7, wall=642
2023-08-21 14:38:28 | INFO | train_inner | epoch 007:    114 / 1265 loss=3.627, nll_loss=2.09, ppl=4.26, wps=88285.8, ups=12.59, wpb=7013.6, bsz=245.8, num_updates=7700, lr=0.00072075, gnorm=0.327, loss_scale=8, train_wall=8, gb_free=21.8, wall=650
2023-08-21 14:38:36 | INFO | train_inner | epoch 007:    214 / 1265 loss=3.633, nll_loss=2.098, ppl=4.28, wps=89601.2, ups=13.14, wpb=6819.1, bsz=256.6, num_updates=7800, lr=0.000716115, gnorm=0.335, loss_scale=8, train_wall=7, gb_free=21.8, wall=658
2023-08-21 14:38:43 | INFO | train_inner | epoch 007:    314 / 1265 loss=3.687, nll_loss=2.159, ppl=4.47, wps=90921.8, ups=13.38, wpb=6794.5, bsz=245.7, num_updates=7900, lr=0.000711568, gnorm=0.343, loss_scale=8, train_wall=7, gb_free=21.7, wall=665
2023-08-21 14:38:51 | INFO | train_inner | epoch 007:    414 / 1265 loss=3.687, nll_loss=2.16, ppl=4.47, wps=90928.6, ups=13.29, wpb=6840.2, bsz=248.1, num_updates=8000, lr=0.000707107, gnorm=0.335, loss_scale=8, train_wall=7, gb_free=21.6, wall=673
2023-08-21 14:38:58 | INFO | train_inner | epoch 007:    514 / 1265 loss=3.674, nll_loss=2.146, ppl=4.42, wps=91811.3, ups=13.21, wpb=6951.8, bsz=252.6, num_updates=8100, lr=0.000702728, gnorm=0.338, loss_scale=8, train_wall=7, gb_free=21.9, wall=680
2023-08-21 14:39:06 | INFO | train_inner | epoch 007:    614 / 1265 loss=3.696, nll_loss=2.171, ppl=4.5, wps=87478.7, ups=12.86, wpb=6801.9, bsz=252.5, num_updates=8200, lr=0.00069843, gnorm=0.344, loss_scale=8, train_wall=8, gb_free=21.8, wall=688
2023-08-21 14:39:14 | INFO | train_inner | epoch 007:    714 / 1265 loss=3.674, nll_loss=2.145, ppl=4.42, wps=89039.9, ups=12.97, wpb=6864.6, bsz=228, num_updates=8300, lr=0.00069421, gnorm=0.339, loss_scale=8, train_wall=7, gb_free=21.7, wall=696
2023-08-21 14:39:21 | INFO | train_inner | epoch 007:    814 / 1265 loss=3.688, nll_loss=2.164, ppl=4.48, wps=91868.8, ups=13.23, wpb=6945.4, bsz=268.6, num_updates=8400, lr=0.000690066, gnorm=0.328, loss_scale=8, train_wall=7, gb_free=21.9, wall=703
2023-08-21 14:39:29 | INFO | train_inner | epoch 007:    914 / 1265 loss=3.671, nll_loss=2.143, ppl=4.42, wps=88243.3, ups=12.73, wpb=6930.6, bsz=245.4, num_updates=8500, lr=0.000685994, gnorm=0.335, loss_scale=8, train_wall=8, gb_free=21.7, wall=711
2023-08-21 14:39:37 | INFO | train_inner | epoch 007:   1014 / 1265 loss=3.702, nll_loss=2.182, ppl=4.54, wps=89275.8, ups=13.18, wpb=6773.8, bsz=266.6, num_updates=8600, lr=0.000681994, gnorm=0.335, loss_scale=8, train_wall=7, gb_free=21.7, wall=719
2023-08-21 14:39:44 | INFO | train_inner | epoch 007:   1114 / 1265 loss=3.623, nll_loss=2.089, ppl=4.26, wps=93925.8, ups=13.62, wpb=6898.2, bsz=267.4, num_updates=8700, lr=0.000678064, gnorm=0.327, loss_scale=8, train_wall=7, gb_free=21.7, wall=726
2023-08-21 14:39:52 | INFO | train_inner | epoch 007:   1214 / 1265 loss=3.665, nll_loss=2.139, ppl=4.41, wps=93136.4, ups=13.4, wpb=6950.6, bsz=241.1, num_updates=8800, lr=0.0006742, gnorm=0.323, loss_scale=8, train_wall=7, gb_free=21.7, wall=733
2023-08-21 14:39:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:39:58 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 3.812 | nll_loss 2.251 | ppl 4.76 | wps 139741 | wpb 3858.1 | bsz 131.6 | num_updates 8851 | best_loss 3.812
2023-08-21 14:39:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8851 updates
2023-08-21 14:39:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint7.pt
2023-08-21 14:39:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint7.pt
2023-08-21 14:40:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint7.pt (epoch 7 @ 8851 updates, score 3.812) (writing took 3.673182860016823 seconds)
2023-08-21 14:40:02 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-21 14:40:02 | INFO | train | epoch 007 | loss 3.667 | nll_loss 2.138 | ppl 4.4 | wps 82697.8 | ups 12.02 | wpb 6881.3 | bsz 251 | num_updates 8851 | lr 0.000672255 | gnorm 0.334 | loss_scale 8 | train_wall 94 | gb_free 21.7 | wall 743
2023-08-21 14:40:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:40:02 | INFO | fairseq.trainer | begin training epoch 8
2023-08-21 14:40:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:40:08 | INFO | train_inner | epoch 008:     49 / 1265 loss=3.559, nll_loss=2.018, ppl=4.05, wps=43018.2, ups=6.23, wpb=6903.1, bsz=271.6, num_updates=8900, lr=0.000670402, gnorm=0.311, loss_scale=8, train_wall=8, gb_free=21.8, wall=750
2023-08-21 14:40:15 | INFO | train_inner | epoch 008:    149 / 1265 loss=3.531, nll_loss=1.983, ppl=3.95, wps=89156.5, ups=13.05, wpb=6832.5, bsz=257.8, num_updates=9000, lr=0.000666667, gnorm=0.319, loss_scale=8, train_wall=7, gb_free=21.7, wall=757
2023-08-21 14:40:23 | INFO | train_inner | epoch 008:    249 / 1265 loss=3.563, nll_loss=2.019, ppl=4.05, wps=87932.7, ups=12.79, wpb=6873.1, bsz=239.8, num_updates=9100, lr=0.000662994, gnorm=0.324, loss_scale=8, train_wall=8, gb_free=21.8, wall=765
2023-08-21 14:40:31 | INFO | train_inner | epoch 008:    349 / 1265 loss=3.594, nll_loss=2.054, ppl=4.15, wps=88915.4, ups=13.13, wpb=6770.2, bsz=235, num_updates=9200, lr=0.00065938, gnorm=0.33, loss_scale=8, train_wall=7, gb_free=21.8, wall=773
2023-08-21 14:40:38 | INFO | train_inner | epoch 008:    449 / 1265 loss=3.554, nll_loss=2.011, ppl=4.03, wps=94432.6, ups=13.65, wpb=6919.7, bsz=271.9, num_updates=9300, lr=0.000655826, gnorm=0.315, loss_scale=8, train_wall=7, gb_free=21.7, wall=780
2023-08-21 14:40:46 | INFO | train_inner | epoch 008:    549 / 1265 loss=3.569, nll_loss=2.026, ppl=4.07, wps=91707.5, ups=13.48, wpb=6805.5, bsz=240.2, num_updates=9400, lr=0.000652328, gnorm=0.326, loss_scale=8, train_wall=7, gb_free=21.7, wall=787
2023-08-21 14:40:53 | INFO | train_inner | epoch 008:    649 / 1265 loss=3.57, nll_loss=2.029, ppl=4.08, wps=89540.3, ups=12.93, wpb=6925.4, bsz=255, num_updates=9500, lr=0.000648886, gnorm=0.318, loss_scale=8, train_wall=7, gb_free=21.8, wall=795
2023-08-21 14:41:01 | INFO | train_inner | epoch 008:    749 / 1265 loss=3.598, nll_loss=2.061, ppl=4.17, wps=87407.9, ups=12.77, wpb=6846.4, bsz=239, num_updates=9600, lr=0.000645497, gnorm=0.325, loss_scale=8, train_wall=8, gb_free=21.6, wall=803
2023-08-21 14:41:09 | INFO | train_inner | epoch 008:    849 / 1265 loss=3.606, nll_loss=2.07, ppl=4.2, wps=89809.5, ups=12.93, wpb=6948.4, bsz=230, num_updates=9700, lr=0.000642161, gnorm=0.324, loss_scale=8, train_wall=8, gb_free=21.8, wall=811
2023-08-21 14:41:16 | INFO | train_inner | epoch 008:    949 / 1265 loss=3.571, nll_loss=2.032, ppl=4.09, wps=95875.9, ups=13.78, wpb=6956.7, bsz=259.8, num_updates=9800, lr=0.000638877, gnorm=0.327, loss_scale=8, train_wall=7, gb_free=21.7, wall=818
2023-08-21 14:41:24 | INFO | train_inner | epoch 008:   1049 / 1265 loss=3.557, nll_loss=2.016, ppl=4.04, wps=93242.4, ups=13.35, wpb=6984.2, bsz=269.5, num_updates=9900, lr=0.000635642, gnorm=0.311, loss_scale=8, train_wall=7, gb_free=21.7, wall=825
2023-08-21 14:41:31 | INFO | train_inner | epoch 008:   1149 / 1265 loss=3.59, nll_loss=2.054, ppl=4.15, wps=93926.3, ups=13.75, wpb=6828.7, bsz=237.9, num_updates=10000, lr=0.000632456, gnorm=0.32, loss_scale=8, train_wall=7, gb_free=21.7, wall=833
2023-08-21 14:41:39 | INFO | train_inner | epoch 008:   1249 / 1265 loss=3.565, nll_loss=2.025, ppl=4.07, wps=87603.3, ups=12.74, wpb=6877.7, bsz=257.7, num_updates=10100, lr=0.000629317, gnorm=0.323, loss_scale=8, train_wall=8, gb_free=21.8, wall=841
2023-08-21 14:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:41:42 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 3.776 | nll_loss 2.225 | ppl 4.68 | wps 160814 | wpb 3858.1 | bsz 131.6 | num_updates 10116 | best_loss 3.776
2023-08-21 14:41:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 10116 updates
2023-08-21 14:41:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint8.pt
2023-08-21 14:41:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint8.pt
2023-08-21 14:41:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint8.pt (epoch 8 @ 10116 updates, score 3.776) (writing took 3.348303336999379 seconds)
2023-08-21 14:41:46 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-21 14:41:46 | INFO | train | epoch 008 | loss 3.568 | nll_loss 2.027 | ppl 4.08 | wps 83733.2 | ups 12.17 | wpb 6881.3 | bsz 251 | num_updates 10116 | lr 0.000628819 | gnorm 0.321 | loss_scale 8 | train_wall 93 | gb_free 21.8 | wall 847
2023-08-21 14:41:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:41:46 | INFO | fairseq.trainer | begin training epoch 9
2023-08-21 14:41:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:41:55 | INFO | train_inner | epoch 009:     84 / 1265 loss=3.474, nll_loss=1.918, ppl=3.78, wps=43732, ups=6.33, wpb=6903.5, bsz=254.2, num_updates=10200, lr=0.000626224, gnorm=0.309, loss_scale=8, train_wall=8, gb_free=21.8, wall=856
2023-08-21 14:42:02 | INFO | train_inner | epoch 009:    184 / 1265 loss=3.448, nll_loss=1.887, ppl=3.7, wps=87167.4, ups=12.73, wpb=6848.7, bsz=236.9, num_updates=10300, lr=0.000623177, gnorm=0.311, loss_scale=8, train_wall=8, gb_free=21.8, wall=864
2023-08-21 14:42:10 | INFO | train_inner | epoch 009:    284 / 1265 loss=3.436, nll_loss=1.877, ppl=3.67, wps=90905.1, ups=13.05, wpb=6964.2, bsz=285.3, num_updates=10400, lr=0.000620174, gnorm=0.305, loss_scale=8, train_wall=7, gb_free=21.7, wall=872
2023-08-21 14:42:18 | INFO | train_inner | epoch 009:    384 / 1265 loss=3.47, nll_loss=1.914, ppl=3.77, wps=90246.4, ups=12.86, wpb=7015.2, bsz=249.4, num_updates=10500, lr=0.000617213, gnorm=0.309, loss_scale=8, train_wall=8, gb_free=21.8, wall=880
2023-08-21 14:42:25 | INFO | train_inner | epoch 009:    484 / 1265 loss=3.472, nll_loss=1.916, ppl=3.77, wps=94289.4, ups=13.48, wpb=6992.2, bsz=253.6, num_updates=10600, lr=0.000614295, gnorm=0.309, loss_scale=8, train_wall=7, gb_free=21.6, wall=887
2023-08-21 14:42:33 | INFO | train_inner | epoch 009:    584 / 1265 loss=3.525, nll_loss=1.977, ppl=3.94, wps=89963.1, ups=13.13, wpb=6852.9, bsz=235, num_updates=10700, lr=0.000611418, gnorm=0.32, loss_scale=8, train_wall=7, gb_free=21.7, wall=895
2023-08-21 14:42:41 | INFO | train_inner | epoch 009:    684 / 1265 loss=3.493, nll_loss=1.941, ppl=3.84, wps=89469.6, ups=13.02, wpb=6873.4, bsz=238.9, num_updates=10800, lr=0.000608581, gnorm=0.312, loss_scale=8, train_wall=7, gb_free=21.7, wall=902
2023-08-21 14:42:48 | INFO | train_inner | epoch 009:    784 / 1265 loss=3.487, nll_loss=1.936, ppl=3.83, wps=87031.3, ups=12.83, wpb=6784.4, bsz=259.4, num_updates=10900, lr=0.000605783, gnorm=0.315, loss_scale=8, train_wall=8, gb_free=21.7, wall=910
2023-08-21 14:42:56 | INFO | train_inner | epoch 009:    884 / 1265 loss=3.518, nll_loss=1.97, ppl=3.92, wps=86731, ups=12.56, wpb=6905, bsz=239, num_updates=11000, lr=0.000603023, gnorm=0.311, loss_scale=8, train_wall=8, gb_free=21.7, wall=918
2023-08-21 14:43:04 | INFO | train_inner | epoch 009:    984 / 1265 loss=3.49, nll_loss=1.94, ppl=3.84, wps=86293.5, ups=12.68, wpb=6804.3, bsz=275, num_updates=11100, lr=0.0006003, gnorm=0.311, loss_scale=8, train_wall=8, gb_free=21.7, wall=926
2023-08-21 14:43:12 | INFO | train_inner | epoch 009:   1084 / 1265 loss=3.532, nll_loss=1.987, ppl=3.96, wps=87472.8, ups=12.92, wpb=6772.1, bsz=217.4, num_updates=11200, lr=0.000597614, gnorm=0.317, loss_scale=8, train_wall=8, gb_free=21.8, wall=934
2023-08-21 14:43:20 | INFO | train_inner | epoch 009:   1184 / 1265 loss=3.478, nll_loss=1.927, ppl=3.8, wps=93285.5, ups=13.33, wpb=6998.5, bsz=270.5, num_updates=11300, lr=0.000594964, gnorm=0.3, loss_scale=8, train_wall=7, gb_free=21.9, wall=941
2023-08-21 14:43:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:43:28 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 3.755 | nll_loss 2.187 | ppl 4.55 | wps 179153 | wpb 3858.1 | bsz 131.6 | num_updates 11381 | best_loss 3.755
2023-08-21 14:43:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 11381 updates
2023-08-21 14:43:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint9.pt
2023-08-21 14:43:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint9.pt
2023-08-21 14:43:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint9.pt (epoch 9 @ 11381 updates, score 3.755) (writing took 3.6890370520413853 seconds)
2023-08-21 14:43:32 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-21 14:43:32 | INFO | train | epoch 009 | loss 3.487 | nll_loss 1.935 | ppl 3.82 | wps 82095.7 | ups 11.93 | wpb 6881.3 | bsz 251 | num_updates 11381 | lr 0.000592843 | gnorm 0.311 | loss_scale 8 | train_wall 95 | gb_free 21.9 | wall 953
2023-08-21 14:43:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:43:32 | INFO | fairseq.trainer | begin training epoch 10
2023-08-21 14:43:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:43:35 | INFO | train_inner | epoch 010:     19 / 1265 loss=3.516, nll_loss=1.969, ppl=3.92, wps=42478.7, ups=6.37, wpb=6664.5, bsz=237.8, num_updates=11400, lr=0.000592349, gnorm=0.316, loss_scale=8, train_wall=7, gb_free=22, wall=957
2023-08-21 14:43:43 | INFO | train_inner | epoch 010:    119 / 1265 loss=3.331, nll_loss=1.756, ppl=3.38, wps=93574.5, ups=13.27, wpb=7051.9, bsz=277.5, num_updates=11500, lr=0.000589768, gnorm=0.286, loss_scale=8, train_wall=7, gb_free=21.7, wall=965
2023-08-21 14:43:50 | INFO | train_inner | epoch 010:    219 / 1265 loss=3.375, nll_loss=1.804, ppl=3.49, wps=90062.9, ups=13.16, wpb=6843.4, bsz=240.1, num_updates=11600, lr=0.00058722, gnorm=0.301, loss_scale=8, train_wall=7, gb_free=21.8, wall=972
2023-08-21 14:43:58 | INFO | train_inner | epoch 010:    319 / 1265 loss=3.368, nll_loss=1.799, ppl=3.48, wps=88722.5, ups=12.94, wpb=6857.5, bsz=278.8, num_updates=11700, lr=0.000584705, gnorm=0.299, loss_scale=8, train_wall=7, gb_free=21.8, wall=980
2023-08-21 14:44:06 | INFO | train_inner | epoch 010:    419 / 1265 loss=3.451, nll_loss=1.891, ppl=3.71, wps=93131.2, ups=13.41, wpb=6946.6, bsz=225.4, num_updates=11800, lr=0.000582223, gnorm=0.313, loss_scale=8, train_wall=7, gb_free=22, wall=987
2023-08-21 14:44:13 | INFO | train_inner | epoch 010:    519 / 1265 loss=3.464, nll_loss=1.908, ppl=3.75, wps=91288.3, ups=13.49, wpb=6766.2, bsz=243.6, num_updates=11900, lr=0.000579771, gnorm=0.313, loss_scale=8, train_wall=7, gb_free=21.8, wall=995
2023-08-21 14:44:21 | INFO | train_inner | epoch 010:    619 / 1265 loss=3.437, nll_loss=1.876, ppl=3.67, wps=92030.7, ups=13.26, wpb=6942.5, bsz=248.6, num_updates=12000, lr=0.00057735, gnorm=0.305, loss_scale=8, train_wall=7, gb_free=21.7, wall=1002
2023-08-21 14:44:28 | INFO | train_inner | epoch 010:    719 / 1265 loss=3.436, nll_loss=1.876, ppl=3.67, wps=91919, ups=13.31, wpb=6904, bsz=235.9, num_updates=12100, lr=0.00057496, gnorm=0.311, loss_scale=8, train_wall=7, gb_free=21.9, wall=1010
2023-08-21 14:44:36 | INFO | train_inner | epoch 010:    819 / 1265 loss=3.408, nll_loss=1.845, ppl=3.59, wps=90525.7, ups=12.83, wpb=7058.4, bsz=256.4, num_updates=12200, lr=0.000572598, gnorm=0.301, loss_scale=8, train_wall=8, gb_free=21.7, wall=1018
2023-08-21 14:44:44 | INFO | train_inner | epoch 010:    919 / 1265 loss=3.446, nll_loss=1.889, ppl=3.7, wps=84507.2, ups=12.68, wpb=6662.3, bsz=257.8, num_updates=12300, lr=0.000570266, gnorm=0.317, loss_scale=8, train_wall=8, gb_free=21.8, wall=1026
2023-08-21 14:44:52 | INFO | train_inner | epoch 010:   1019 / 1265 loss=3.428, nll_loss=1.868, ppl=3.65, wps=87079, ups=12.65, wpb=6883, bsz=239.4, num_updates=12400, lr=0.000567962, gnorm=0.312, loss_scale=8, train_wall=8, gb_free=21.7, wall=1033
2023-08-21 14:44:59 | INFO | train_inner | epoch 010:   1119 / 1265 loss=3.45, nll_loss=1.895, ppl=3.72, wps=89035.4, ups=12.97, wpb=6866.5, bsz=259.6, num_updates=12500, lr=0.000565685, gnorm=0.313, loss_scale=8, train_wall=7, gb_free=21.7, wall=1041
2023-08-21 14:45:07 | INFO | train_inner | epoch 010:   1219 / 1265 loss=3.472, nll_loss=1.92, ppl=3.78, wps=88670.9, ups=12.9, wpb=6872.2, bsz=243.6, num_updates=12600, lr=0.000563436, gnorm=0.31, loss_scale=8, train_wall=8, gb_free=21.8, wall=1049
2023-08-21 14:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:45:13 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 3.724 | nll_loss 2.155 | ppl 4.45 | wps 146461 | wpb 3858.1 | bsz 131.6 | num_updates 12646 | best_loss 3.724
2023-08-21 14:45:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 12646 updates
2023-08-21 14:45:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint10.pt
2023-08-21 14:45:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint10.pt
2023-08-21 14:45:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint10.pt (epoch 10 @ 12646 updates, score 3.724) (writing took 2.2534464320051484 seconds)
2023-08-21 14:45:15 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-21 14:45:15 | INFO | train | epoch 010 | loss 3.421 | nll_loss 1.86 | ppl 3.63 | wps 84309.2 | ups 12.25 | wpb 6881.3 | bsz 251 | num_updates 12646 | lr 0.00056241 | gnorm 0.307 | loss_scale 8 | train_wall 94 | gb_free 21.8 | wall 1057
2023-08-21 14:45:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:45:15 | INFO | fairseq.trainer | begin training epoch 11
2023-08-21 14:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:45:21 | INFO | train_inner | epoch 011:     54 / 1265 loss=3.378, nll_loss=1.81, ppl=3.51, wps=48624.4, ups=7.19, wpb=6760.5, bsz=239.6, num_updates=12700, lr=0.000561214, gnorm=0.306, loss_scale=8, train_wall=7, gb_free=21.8, wall=1063
2023-08-21 14:45:29 | INFO | train_inner | epoch 011:    154 / 1265 loss=3.349, nll_loss=1.773, ppl=3.42, wps=89698.3, ups=13.04, wpb=6876.9, bsz=228.9, num_updates=12800, lr=0.000559017, gnorm=0.304, loss_scale=8, train_wall=7, gb_free=21.8, wall=1070
2023-08-21 14:45:36 | INFO | train_inner | epoch 011:    254 / 1265 loss=3.317, nll_loss=1.739, ppl=3.34, wps=96149.8, ups=13.93, wpb=6901.8, bsz=260.4, num_updates=12900, lr=0.000556846, gnorm=0.298, loss_scale=8, train_wall=7, gb_free=21.8, wall=1078
2023-08-21 14:45:43 | INFO | train_inner | epoch 011:    354 / 1265 loss=3.314, nll_loss=1.736, ppl=3.33, wps=92036.5, ups=13.26, wpb=6938.4, bsz=274, num_updates=13000, lr=0.0005547, gnorm=0.3, loss_scale=8, train_wall=7, gb_free=21.8, wall=1085
2023-08-21 14:45:51 | INFO | train_inner | epoch 011:    454 / 1265 loss=3.321, nll_loss=1.744, ppl=3.35, wps=89895.1, ups=13.11, wpb=6858.1, bsz=269.8, num_updates=13100, lr=0.000552579, gnorm=0.301, loss_scale=8, train_wall=7, gb_free=21.9, wall=1093
2023-08-21 14:45:59 | INFO | train_inner | epoch 011:    554 / 1265 loss=3.377, nll_loss=1.81, ppl=3.51, wps=91121, ups=13.2, wpb=6905.4, bsz=263, num_updates=13200, lr=0.000550482, gnorm=0.302, loss_scale=8, train_wall=7, gb_free=21.7, wall=1100
2023-08-21 14:46:06 | INFO | train_inner | epoch 011:    654 / 1265 loss=3.403, nll_loss=1.839, ppl=3.58, wps=85961, ups=12.76, wpb=6738, bsz=250.6, num_updates=13300, lr=0.000548408, gnorm=0.313, loss_scale=8, train_wall=8, gb_free=21.6, wall=1108
2023-08-21 14:46:14 | INFO | train_inner | epoch 011:    754 / 1265 loss=3.384, nll_loss=1.817, ppl=3.52, wps=87225.5, ups=12.55, wpb=6948.4, bsz=248.6, num_updates=13400, lr=0.000546358, gnorm=0.298, loss_scale=8, train_wall=8, gb_free=22, wall=1116
2023-08-21 14:46:22 | INFO | train_inner | epoch 011:    854 / 1265 loss=3.38, nll_loss=1.813, ppl=3.51, wps=89235.7, ups=13.14, wpb=6790, bsz=244.9, num_updates=13500, lr=0.000544331, gnorm=0.305, loss_scale=8, train_wall=7, gb_free=21.7, wall=1124
2023-08-21 14:46:29 | INFO | train_inner | epoch 011:    954 / 1265 loss=3.408, nll_loss=1.845, ppl=3.59, wps=91953.3, ups=13.41, wpb=6859.4, bsz=240.2, num_updates=13600, lr=0.000542326, gnorm=0.306, loss_scale=8, train_wall=7, gb_free=21.7, wall=1131
2023-08-21 14:46:37 | INFO | train_inner | epoch 011:   1054 / 1265 loss=3.419, nll_loss=1.857, ppl=3.62, wps=90450.8, ups=13.26, wpb=6818.9, bsz=227, num_updates=13700, lr=0.000540343, gnorm=0.314, loss_scale=8, train_wall=7, gb_free=22.1, wall=1139
2023-08-21 14:46:45 | INFO | train_inner | epoch 011:   1154 / 1265 loss=3.349, nll_loss=1.779, ppl=3.43, wps=89513.3, ups=12.76, wpb=7013.4, bsz=264.6, num_updates=13800, lr=0.000538382, gnorm=0.293, loss_scale=8, train_wall=8, gb_free=21.9, wall=1147
2023-08-21 14:46:52 | INFO | train_inner | epoch 011:   1254 / 1265 loss=3.351, nll_loss=1.781, ppl=3.44, wps=98137.6, ups=13.92, wpb=7049.6, bsz=256.3, num_updates=13900, lr=0.000536442, gnorm=0.292, loss_scale=8, train_wall=7, gb_free=22, wall=1154
2023-08-21 14:46:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:46:55 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 3.711 | nll_loss 2.138 | ppl 4.4 | wps 155378 | wpb 3858.1 | bsz 131.6 | num_updates 13911 | best_loss 3.711
2023-08-21 14:46:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 13911 updates
2023-08-21 14:46:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint11.pt
2023-08-21 14:46:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint11.pt
2023-08-21 14:46:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint11.pt (epoch 11 @ 13911 updates, score 3.711) (writing took 3.347502605000045 seconds)
2023-08-21 14:46:59 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-21 14:46:59 | INFO | train | epoch 011 | loss 3.363 | nll_loss 1.793 | ppl 3.47 | wps 83977.7 | ups 12.2 | wpb 6881.3 | bsz 251 | num_updates 13911 | lr 0.00053623 | gnorm 0.302 | loss_scale 8 | train_wall 93 | gb_free 21.7 | wall 1160
2023-08-21 14:46:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:46:59 | INFO | fairseq.trainer | begin training epoch 12
2023-08-21 14:46:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:47:07 | INFO | train_inner | epoch 012:     89 / 1265 loss=3.251, nll_loss=1.662, ppl=3.17, wps=44562, ups=6.51, wpb=6850, bsz=243.2, num_updates=14000, lr=0.000534522, gnorm=0.29, loss_scale=8, train_wall=7, gb_free=21.9, wall=1169
2023-08-21 14:47:15 | INFO | train_inner | epoch 012:    189 / 1265 loss=3.264, nll_loss=1.679, ppl=3.2, wps=91080.3, ups=13.21, wpb=6893.9, bsz=269.9, num_updates=14100, lr=0.000532624, gnorm=0.29, loss_scale=8, train_wall=7, gb_free=21.8, wall=1177
2023-08-21 14:47:23 | INFO | train_inner | epoch 012:    289 / 1265 loss=3.284, nll_loss=1.702, ppl=3.25, wps=92037.8, ups=13.29, wpb=6926.5, bsz=258.6, num_updates=14200, lr=0.000530745, gnorm=0.294, loss_scale=8, train_wall=7, gb_free=21.8, wall=1184
2023-08-21 14:47:30 | INFO | train_inner | epoch 012:    389 / 1265 loss=3.279, nll_loss=1.695, ppl=3.24, wps=88627.5, ups=12.85, wpb=6895.3, bsz=251.8, num_updates=14300, lr=0.000528886, gnorm=0.298, loss_scale=16, train_wall=8, gb_free=21.7, wall=1192
2023-08-21 14:47:38 | INFO | train_inner | epoch 012:    489 / 1265 loss=3.326, nll_loss=1.75, ppl=3.36, wps=93977.7, ups=13.63, wpb=6895.5, bsz=250.9, num_updates=14400, lr=0.000527046, gnorm=0.303, loss_scale=16, train_wall=7, gb_free=21.8, wall=1199
2023-08-21 14:47:45 | INFO | train_inner | epoch 012:    589 / 1265 loss=3.324, nll_loss=1.746, ppl=3.35, wps=90136.1, ups=12.94, wpb=6965.1, bsz=226.6, num_updates=14500, lr=0.000525226, gnorm=0.302, loss_scale=16, train_wall=7, gb_free=21.7, wall=1207
2023-08-21 14:47:54 | INFO | train_inner | epoch 012:    689 / 1265 loss=3.327, nll_loss=1.751, ppl=3.37, wps=84062.3, ups=12.14, wpb=6922.9, bsz=246.3, num_updates=14600, lr=0.000523424, gnorm=0.305, loss_scale=16, train_wall=8, gb_free=21.8, wall=1215
2023-08-21 14:48:01 | INFO | train_inner | epoch 012:    789 / 1265 loss=3.342, nll_loss=1.768, ppl=3.41, wps=88427.7, ups=12.95, wpb=6828, bsz=249.5, num_updates=14700, lr=0.000521641, gnorm=0.307, loss_scale=16, train_wall=7, gb_free=21.7, wall=1223
2023-08-21 14:48:09 | INFO | train_inner | epoch 012:    889 / 1265 loss=3.342, nll_loss=1.769, ppl=3.41, wps=90080.3, ups=13.07, wpb=6894.3, bsz=255.8, num_updates=14800, lr=0.000519875, gnorm=0.305, loss_scale=16, train_wall=7, gb_free=21.7, wall=1231
2023-08-21 14:48:17 | INFO | train_inner | epoch 012:    989 / 1265 loss=3.375, nll_loss=1.807, ppl=3.5, wps=88908, ups=13.22, wpb=6723.7, bsz=258.3, num_updates=14900, lr=0.000518128, gnorm=0.31, loss_scale=16, train_wall=7, gb_free=21.8, wall=1238
2023-08-21 14:48:24 | INFO | train_inner | epoch 012:   1089 / 1265 loss=3.328, nll_loss=1.754, ppl=3.37, wps=89732.6, ups=13.07, wpb=6865.3, bsz=249.7, num_updates=15000, lr=0.000516398, gnorm=0.302, loss_scale=16, train_wall=7, gb_free=21.7, wall=1246
2023-08-21 14:48:32 | INFO | train_inner | epoch 012:   1189 / 1265 loss=3.324, nll_loss=1.75, ppl=3.36, wps=90286.3, ups=12.97, wpb=6961.9, bsz=263.2, num_updates=15100, lr=0.000514685, gnorm=0.294, loss_scale=16, train_wall=7, gb_free=21.8, wall=1254
2023-08-21 14:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:48:40 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 3.715 | nll_loss 2.14 | ppl 4.41 | wps 161214 | wpb 3858.1 | bsz 131.6 | num_updates 15176 | best_loss 3.711
2023-08-21 14:48:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 15176 updates
2023-08-21 14:48:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint12.pt
2023-08-21 14:48:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint12.pt
2023-08-21 14:48:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint12.pt (epoch 12 @ 15176 updates, score 3.715) (writing took 1.8249458100181073 seconds)
2023-08-21 14:48:42 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-21 14:48:42 | INFO | train | epoch 012 | loss 3.315 | nll_loss 1.737 | ppl 3.33 | wps 84238 | ups 12.24 | wpb 6881.3 | bsz 251 | num_updates 15176 | lr 0.000513395 | gnorm 0.3 | loss_scale 16 | train_wall 94 | gb_free 21.9 | wall 1264
2023-08-21 14:48:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:48:42 | INFO | fairseq.trainer | begin training epoch 13
2023-08-21 14:48:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:48:46 | INFO | train_inner | epoch 013:     24 / 1265 loss=3.314, nll_loss=1.737, ppl=3.33, wps=48817, ups=7.2, wpb=6782.7, bsz=247.4, num_updates=15200, lr=0.000512989, gnorm=0.3, loss_scale=16, train_wall=7, gb_free=21.8, wall=1268
2023-08-21 14:48:53 | INFO | train_inner | epoch 013:    124 / 1265 loss=3.226, nll_loss=1.635, ppl=3.1, wps=91376.4, ups=13.16, wpb=6944.5, bsz=263.8, num_updates=15300, lr=0.00051131, gnorm=0.289, loss_scale=16, train_wall=7, gb_free=21.7, wall=1275
2023-08-21 14:49:01 | INFO | train_inner | epoch 013:    224 / 1265 loss=3.216, nll_loss=1.623, ppl=3.08, wps=91266.6, ups=13.22, wpb=6903.7, bsz=266.7, num_updates=15400, lr=0.000509647, gnorm=0.289, loss_scale=16, train_wall=7, gb_free=21.8, wall=1283
2023-08-21 14:49:09 | INFO | train_inner | epoch 013:    324 / 1265 loss=3.242, nll_loss=1.652, ppl=3.14, wps=91013.4, ups=13.17, wpb=6908.5, bsz=259.9, num_updates=15500, lr=0.000508001, gnorm=0.3, loss_scale=16, train_wall=7, gb_free=21.7, wall=1290
2023-08-21 14:49:16 | INFO | train_inner | epoch 013:    424 / 1265 loss=3.257, nll_loss=1.669, ppl=3.18, wps=92210.8, ups=13.41, wpb=6875.6, bsz=242.2, num_updates=15600, lr=0.00050637, gnorm=0.301, loss_scale=16, train_wall=7, gb_free=21.8, wall=1298
2023-08-21 14:49:24 | INFO | train_inner | epoch 013:    524 / 1265 loss=3.281, nll_loss=1.696, ppl=3.24, wps=89369.3, ups=12.97, wpb=6892.1, bsz=230.2, num_updates=15700, lr=0.000504754, gnorm=0.305, loss_scale=16, train_wall=7, gb_free=21.8, wall=1306
2023-08-21 14:49:31 | INFO | train_inner | epoch 013:    624 / 1265 loss=3.266, nll_loss=1.68, ppl=3.21, wps=94197, ups=13.31, wpb=7079, bsz=245.4, num_updates=15800, lr=0.000503155, gnorm=0.295, loss_scale=16, train_wall=7, gb_free=21.9, wall=1313
2023-08-21 14:49:39 | INFO | train_inner | epoch 013:    724 / 1265 loss=3.277, nll_loss=1.692, ppl=3.23, wps=89492.6, ups=13.05, wpb=6860.1, bsz=230.3, num_updates=15900, lr=0.00050157, gnorm=0.306, loss_scale=16, train_wall=7, gb_free=21.8, wall=1321
2023-08-21 14:49:47 | INFO | train_inner | epoch 013:    824 / 1265 loss=3.288, nll_loss=1.706, ppl=3.26, wps=85854.4, ups=12.48, wpb=6879, bsz=259.3, num_updates=16000, lr=0.0005, gnorm=0.304, loss_scale=16, train_wall=8, gb_free=21.7, wall=1329
2023-08-21 14:49:55 | INFO | train_inner | epoch 013:    924 / 1265 loss=3.29, nll_loss=1.71, ppl=3.27, wps=85623.8, ups=12.68, wpb=6753.5, bsz=266.5, num_updates=16100, lr=0.000498445, gnorm=0.304, loss_scale=16, train_wall=8, gb_free=22.1, wall=1337
2023-08-21 14:50:03 | INFO | train_inner | epoch 013:   1024 / 1265 loss=3.281, nll_loss=1.7, ppl=3.25, wps=87366.2, ups=12.86, wpb=6791.2, bsz=260.1, num_updates=16200, lr=0.000496904, gnorm=0.302, loss_scale=16, train_wall=8, gb_free=21.7, wall=1344
2023-08-21 14:50:10 | INFO | train_inner | epoch 013:   1124 / 1265 loss=3.31, nll_loss=1.733, ppl=3.32, wps=87164, ups=12.87, wpb=6774.1, bsz=251.4, num_updates=16300, lr=0.000495377, gnorm=0.306, loss_scale=16, train_wall=8, gb_free=21.7, wall=1352
2023-08-21 14:50:18 | INFO | train_inner | epoch 013:   1224 / 1265 loss=3.304, nll_loss=1.725, ppl=3.31, wps=88991.9, ups=12.78, wpb=6961.4, bsz=239.1, num_updates=16400, lr=0.000493865, gnorm=0.301, loss_scale=16, train_wall=8, gb_free=21.6, wall=1360
2023-08-21 14:50:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:50:24 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 3.708 | nll_loss 2.136 | ppl 4.4 | wps 194260 | wpb 3858.1 | bsz 131.6 | num_updates 16441 | best_loss 3.708
2023-08-21 14:50:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 16441 updates
2023-08-21 14:50:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint13.pt
2023-08-21 14:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint13.pt
2023-08-21 14:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint13.pt (epoch 13 @ 16441 updates, score 3.708) (writing took 3.7641995710437186 seconds)
2023-08-21 14:50:28 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-21 14:50:28 | INFO | train | epoch 013 | loss 3.271 | nll_loss 1.686 | ppl 3.22 | wps 82393.6 | ups 11.97 | wpb 6881.3 | bsz 251 | num_updates 16441 | lr 0.000493249 | gnorm 0.3 | loss_scale 16 | train_wall 94 | gb_free 21.7 | wall 1369
2023-08-21 14:50:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:50:28 | INFO | fairseq.trainer | begin training epoch 14
2023-08-21 14:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:50:34 | INFO | train_inner | epoch 014:     59 / 1265 loss=3.228, nll_loss=1.636, ppl=3.11, wps=43092.7, ups=6.36, wpb=6777.9, bsz=236.8, num_updates=16500, lr=0.000492366, gnorm=0.298, loss_scale=16, train_wall=7, gb_free=21.8, wall=1376
2023-08-21 14:50:42 | INFO | train_inner | epoch 014:    159 / 1265 loss=3.202, nll_loss=1.605, ppl=3.04, wps=89477.3, ups=13.21, wpb=6771.4, bsz=256.5, num_updates=16600, lr=0.000490881, gnorm=0.295, loss_scale=16, train_wall=7, gb_free=21.9, wall=1383
2023-08-21 14:50:49 | INFO | train_inner | epoch 014:    259 / 1265 loss=3.226, nll_loss=1.632, ppl=3.1, wps=92990.4, ups=13.52, wpb=6878.4, bsz=242.2, num_updates=16700, lr=0.000489409, gnorm=0.301, loss_scale=16, train_wall=7, gb_free=22, wall=1391
2023-08-21 14:50:57 | INFO | train_inner | epoch 014:    359 / 1265 loss=3.208, nll_loss=1.612, ppl=3.06, wps=89324.6, ups=13, wpb=6871.8, bsz=246.2, num_updates=16800, lr=0.00048795, gnorm=0.294, loss_scale=16, train_wall=7, gb_free=21.8, wall=1398
2023-08-21 14:51:04 | INFO | train_inner | epoch 014:    459 / 1265 loss=3.218, nll_loss=1.625, ppl=3.08, wps=90007.2, ups=13.04, wpb=6900.9, bsz=264, num_updates=16900, lr=0.000486504, gnorm=0.295, loss_scale=16, train_wall=7, gb_free=21.7, wall=1406
2023-08-21 14:51:12 | INFO | train_inner | epoch 014:    559 / 1265 loss=3.224, nll_loss=1.631, ppl=3.1, wps=90085.6, ups=13.07, wpb=6893.2, bsz=247.2, num_updates=17000, lr=0.000485071, gnorm=0.297, loss_scale=16, train_wall=7, gb_free=21.7, wall=1414
2023-08-21 14:51:20 | INFO | train_inner | epoch 014:    659 / 1265 loss=3.216, nll_loss=1.623, ppl=3.08, wps=90153.1, ups=12.96, wpb=6953.9, bsz=261.8, num_updates=17100, lr=0.000483651, gnorm=0.296, loss_scale=16, train_wall=7, gb_free=21.7, wall=1421
2023-08-21 14:51:28 | INFO | train_inner | epoch 014:    759 / 1265 loss=3.273, nll_loss=1.688, ppl=3.22, wps=87565.5, ups=12.62, wpb=6936.4, bsz=248.5, num_updates=17200, lr=0.000482243, gnorm=0.304, loss_scale=16, train_wall=8, gb_free=21.7, wall=1429
2023-08-21 14:51:35 | INFO | train_inner | epoch 014:    859 / 1265 loss=3.26, nll_loss=1.674, ppl=3.19, wps=89776.5, ups=13.16, wpb=6823.2, bsz=245.4, num_updates=17300, lr=0.000480847, gnorm=0.304, loss_scale=16, train_wall=7, gb_free=21.8, wall=1437
2023-08-21 14:51:43 | INFO | train_inner | epoch 014:    959 / 1265 loss=3.233, nll_loss=1.644, ppl=3.13, wps=90975.6, ups=13.27, wpb=6855.5, bsz=255.5, num_updates=17400, lr=0.000479463, gnorm=0.303, loss_scale=16, train_wall=7, gb_free=21.7, wall=1445
2023-08-21 14:51:50 | INFO | train_inner | epoch 014:   1059 / 1265 loss=3.25, nll_loss=1.663, ppl=3.17, wps=94824.5, ups=13.73, wpb=6904.6, bsz=246.9, num_updates=17500, lr=0.000478091, gnorm=0.303, loss_scale=16, train_wall=7, gb_free=21.8, wall=1452
2023-08-21 14:51:57 | INFO | train_inner | epoch 014:   1159 / 1265 loss=3.274, nll_loss=1.69, ppl=3.23, wps=93712, ups=13.56, wpb=6908.7, bsz=237, num_updates=17600, lr=0.000476731, gnorm=0.303, loss_scale=16, train_wall=7, gb_free=21.6, wall=1459
2023-08-21 14:52:05 | INFO | train_inner | epoch 014:   1259 / 1265 loss=3.223, nll_loss=1.635, ppl=3.11, wps=91149.5, ups=13.06, wpb=6981.4, bsz=270.2, num_updates=17700, lr=0.000475383, gnorm=0.292, loss_scale=16, train_wall=7, gb_free=21.7, wall=1467
2023-08-21 14:52:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:52:08 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 3.701 | nll_loss 2.121 | ppl 4.35 | wps 210503 | wpb 3858.1 | bsz 131.6 | num_updates 17706 | best_loss 3.701
2023-08-21 14:52:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 17706 updates
2023-08-21 14:52:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint14.pt
2023-08-21 14:52:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint14.pt
2023-08-21 14:52:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint14.pt (epoch 14 @ 17706 updates, score 3.701) (writing took 3.3215263899764977 seconds)
2023-08-21 14:52:11 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-21 14:52:11 | INFO | train | epoch 014 | loss 3.232 | nll_loss 1.641 | ppl 3.12 | wps 84040.6 | ups 12.21 | wpb 6881.3 | bsz 251 | num_updates 17706 | lr 0.000475302 | gnorm 0.299 | loss_scale 16 | train_wall 93 | gb_free 21.7 | wall 1473
2023-08-21 14:52:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:52:11 | INFO | fairseq.trainer | begin training epoch 15
2023-08-21 14:52:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:52:21 | INFO | train_inner | epoch 015:     94 / 1265 loss=3.156, nll_loss=1.552, ppl=2.93, wps=44200.8, ups=6.47, wpb=6836.8, bsz=245.8, num_updates=17800, lr=0.000474045, gnorm=0.294, loss_scale=16, train_wall=7, gb_free=21.9, wall=1482
2023-08-21 14:52:28 | INFO | train_inner | epoch 015:    194 / 1265 loss=3.168, nll_loss=1.566, ppl=2.96, wps=91363.2, ups=13.23, wpb=6906.7, bsz=251.6, num_updates=17900, lr=0.000472719, gnorm=0.293, loss_scale=16, train_wall=7, gb_free=21.7, wall=1490
2023-08-21 14:52:35 | INFO | train_inner | epoch 015:    294 / 1265 loss=3.186, nll_loss=1.586, ppl=3, wps=94912.3, ups=13.7, wpb=6928.8, bsz=242.8, num_updates=18000, lr=0.000471405, gnorm=0.298, loss_scale=16, train_wall=7, gb_free=21.7, wall=1497
2023-08-21 14:52:43 | INFO | train_inner | epoch 015:    394 / 1265 loss=3.181, nll_loss=1.581, ppl=2.99, wps=96466.3, ups=13.85, wpb=6967.2, bsz=260.3, num_updates=18100, lr=0.0004701, gnorm=0.295, loss_scale=16, train_wall=7, gb_free=21.8, wall=1504
2023-08-21 14:52:50 | INFO | train_inner | epoch 015:    494 / 1265 loss=3.188, nll_loss=1.59, ppl=3.01, wps=87230.3, ups=12.79, wpb=6819, bsz=263.5, num_updates=18200, lr=0.000468807, gnorm=0.297, loss_scale=16, train_wall=8, gb_free=21.8, wall=1512
2023-08-21 14:52:58 | INFO | train_inner | epoch 015:    594 / 1265 loss=3.214, nll_loss=1.618, ppl=3.07, wps=90729.1, ups=13.05, wpb=6951.1, bsz=235.4, num_updates=18300, lr=0.000467525, gnorm=0.301, loss_scale=16, train_wall=7, gb_free=21.7, wall=1520
2023-08-21 14:53:06 | INFO | train_inner | epoch 015:    694 / 1265 loss=3.207, nll_loss=1.613, ppl=3.06, wps=86776.8, ups=12.67, wpb=6846.5, bsz=256.7, num_updates=18400, lr=0.000466252, gnorm=0.302, loss_scale=16, train_wall=8, gb_free=21.9, wall=1528
2023-08-21 14:53:14 | INFO | train_inner | epoch 015:    794 / 1265 loss=3.213, nll_loss=1.619, ppl=3.07, wps=90599.2, ups=13.1, wpb=6916.1, bsz=246.6, num_updates=18500, lr=0.000464991, gnorm=0.298, loss_scale=16, train_wall=7, gb_free=21.7, wall=1535
2023-08-21 14:53:21 | INFO | train_inner | epoch 015:    894 / 1265 loss=3.202, nll_loss=1.606, ppl=3.04, wps=87661.7, ups=12.87, wpb=6812.5, bsz=250.3, num_updates=18600, lr=0.000463739, gnorm=0.304, loss_scale=16, train_wall=8, gb_free=21.7, wall=1543
2023-08-21 14:53:29 | INFO | train_inner | epoch 015:    994 / 1265 loss=3.224, nll_loss=1.633, ppl=3.1, wps=90623.2, ups=13.15, wpb=6892.3, bsz=242, num_updates=18700, lr=0.000462497, gnorm=0.301, loss_scale=16, train_wall=7, gb_free=21.8, wall=1551
2023-08-21 14:53:37 | INFO | train_inner | epoch 015:   1094 / 1265 loss=3.185, nll_loss=1.589, ppl=3.01, wps=89005.2, ups=12.85, wpb=6927.5, bsz=258.1, num_updates=18800, lr=0.000461266, gnorm=0.296, loss_scale=16, train_wall=8, gb_free=21.8, wall=1559
2023-08-21 14:53:45 | INFO | train_inner | epoch 015:   1194 / 1265 loss=3.211, nll_loss=1.618, ppl=3.07, wps=87602.5, ups=12.88, wpb=6800.4, bsz=260, num_updates=18900, lr=0.000460044, gnorm=0.305, loss_scale=16, train_wall=8, gb_free=21.8, wall=1566
2023-08-21 14:53:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:53:52 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 3.709 | nll_loss 2.132 | ppl 4.38 | wps 196523 | wpb 3858.1 | bsz 131.6 | num_updates 18971 | best_loss 3.701
2023-08-21 14:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 18971 updates
2023-08-21 14:53:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint15.pt
2023-08-21 14:53:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint15.pt
2023-08-21 14:53:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint15.pt (epoch 15 @ 18971 updates, score 3.709) (writing took 1.6445307829999365 seconds)
2023-08-21 14:53:54 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-21 14:53:54 | INFO | train | epoch 015 | loss 3.196 | nll_loss 1.6 | ppl 3.03 | wps 84878.7 | ups 12.33 | wpb 6881.3 | bsz 251 | num_updates 18971 | lr 0.000459182 | gnorm 0.299 | loss_scale 16 | train_wall 93 | gb_free 21.7 | wall 1576
2023-08-21 14:53:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:53:54 | INFO | fairseq.trainer | begin training epoch 16
2023-08-21 14:53:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:53:58 | INFO | train_inner | epoch 016:     29 / 1265 loss=3.22, nll_loss=1.627, ppl=3.09, wps=50570.1, ups=7.41, wpb=6826.4, bsz=246.2, num_updates=19000, lr=0.000458831, gnorm=0.3, loss_scale=16, train_wall=7, gb_free=21.8, wall=1580
2023-08-21 14:54:05 | INFO | train_inner | epoch 016:    129 / 1265 loss=3.104, nll_loss=1.491, ppl=2.81, wps=92720.6, ups=13.52, wpb=6856.4, bsz=245.4, num_updates=19100, lr=0.000457629, gnorm=0.289, loss_scale=16, train_wall=7, gb_free=21.7, wall=1587
2023-08-21 14:54:13 | INFO | train_inner | epoch 016:    229 / 1265 loss=3.168, nll_loss=1.564, ppl=2.96, wps=87467.4, ups=12.8, wpb=6835.4, bsz=248.8, num_updates=19200, lr=0.000456435, gnorm=0.299, loss_scale=16, train_wall=8, gb_free=21.8, wall=1595
2023-08-21 14:54:21 | INFO | train_inner | epoch 016:    329 / 1265 loss=3.143, nll_loss=1.536, ppl=2.9, wps=88988.2, ups=12.97, wpb=6859, bsz=246.4, num_updates=19300, lr=0.000455251, gnorm=0.299, loss_scale=16, train_wall=7, gb_free=21.7, wall=1603
2023-08-21 14:54:29 | INFO | train_inner | epoch 016:    429 / 1265 loss=3.145, nll_loss=1.538, ppl=2.9, wps=86449.7, ups=12.56, wpb=6883.2, bsz=247.9, num_updates=19400, lr=0.000454077, gnorm=0.298, loss_scale=16, train_wall=8, gb_free=21.9, wall=1611
2023-08-21 14:54:37 | INFO | train_inner | epoch 016:    529 / 1265 loss=3.155, nll_loss=1.552, ppl=2.93, wps=89966.1, ups=12.96, wpb=6941.8, bsz=258.6, num_updates=19500, lr=0.000452911, gnorm=0.297, loss_scale=16, train_wall=8, gb_free=21.7, wall=1618
2023-08-21 14:54:45 | INFO | train_inner | epoch 016:    629 / 1265 loss=3.138, nll_loss=1.533, ppl=2.89, wps=88385.2, ups=12.7, wpb=6961.6, bsz=246.7, num_updates=19600, lr=0.000451754, gnorm=0.296, loss_scale=16, train_wall=8, gb_free=21.8, wall=1626
2023-08-21 14:54:52 | INFO | train_inner | epoch 016:    729 / 1265 loss=3.181, nll_loss=1.583, ppl=3, wps=87944, ups=12.81, wpb=6865.5, bsz=271.6, num_updates=19700, lr=0.000450606, gnorm=0.301, loss_scale=16, train_wall=8, gb_free=21.7, wall=1634
2023-08-21 14:55:00 | INFO | train_inner | epoch 016:    829 / 1265 loss=3.194, nll_loss=1.596, ppl=3.02, wps=85640.6, ups=12.64, wpb=6778, bsz=237.5, num_updates=19800, lr=0.000449467, gnorm=0.309, loss_scale=16, train_wall=8, gb_free=21.7, wall=1642
2023-08-21 14:55:08 | INFO | train_inner | epoch 016:    929 / 1265 loss=3.196, nll_loss=1.599, ppl=3.03, wps=87915.8, ups=12.77, wpb=6885.7, bsz=248.6, num_updates=19900, lr=0.000448336, gnorm=0.304, loss_scale=16, train_wall=8, gb_free=22, wall=1650
2023-08-21 14:55:16 | INFO | train_inner | epoch 016:   1029 / 1265 loss=3.178, nll_loss=1.579, ppl=2.99, wps=90350.1, ups=13.14, wpb=6876.6, bsz=257.6, num_updates=20000, lr=0.000447214, gnorm=0.302, loss_scale=16, train_wall=7, gb_free=21.8, wall=1658
2023-08-21 14:55:23 | INFO | train_inner | epoch 016:   1129 / 1265 loss=3.18, nll_loss=1.582, ppl=2.99, wps=91796.5, ups=13.1, wpb=7008.2, bsz=245.4, num_updates=20100, lr=0.0004461, gnorm=0.297, loss_scale=16, train_wall=7, gb_free=21.9, wall=1665
2023-08-21 14:55:31 | INFO | train_inner | epoch 016:   1229 / 1265 loss=3.185, nll_loss=1.588, ppl=3.01, wps=88358.7, ups=12.8, wpb=6900.7, bsz=257.9, num_updates=20200, lr=0.000444994, gnorm=0.297, loss_scale=16, train_wall=8, gb_free=21.8, wall=1673
2023-08-21 14:55:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:55:36 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 3.707 | nll_loss 2.129 | ppl 4.38 | wps 196750 | wpb 3858.1 | bsz 131.6 | num_updates 20236 | best_loss 3.701
2023-08-21 14:55:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 20236 updates
2023-08-21 14:55:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint16.pt
2023-08-21 14:55:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint16.pt
2023-08-21 14:55:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint16.pt (epoch 16 @ 20236 updates, score 3.707) (writing took 4.167995631985832 seconds)
2023-08-21 14:55:41 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-21 14:55:41 | INFO | train | epoch 016 | loss 3.165 | nll_loss 1.563 | ppl 2.95 | wps 81021.5 | ups 11.77 | wpb 6881.3 | bsz 251 | num_updates 20236 | lr 0.000444598 | gnorm 0.3 | loss_scale 16 | train_wall 95 | gb_free 21.9 | wall 1683
2023-08-21 14:55:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:55:41 | INFO | fairseq.trainer | begin training epoch 17
2023-08-21 14:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:55:48 | INFO | train_inner | epoch 017:     64 / 1265 loss=3.118, nll_loss=1.509, ppl=2.85, wps=41061.9, ups=6, wpb=6848.7, bsz=248.7, num_updates=20300, lr=0.000443897, gnorm=0.302, loss_scale=16, train_wall=7, gb_free=21.8, wall=1690
2023-08-21 14:55:55 | INFO | train_inner | epoch 017:    164 / 1265 loss=3.126, nll_loss=1.515, ppl=2.86, wps=90822.5, ups=13.29, wpb=6832, bsz=231.2, num_updates=20400, lr=0.000442807, gnorm=0.299, loss_scale=16, train_wall=7, gb_free=21.8, wall=1697
2023-08-21 14:56:03 | INFO | train_inner | epoch 017:    264 / 1265 loss=3.107, nll_loss=1.495, ppl=2.82, wps=86908.9, ups=12.89, wpb=6743.5, bsz=253.3, num_updates=20500, lr=0.000441726, gnorm=0.303, loss_scale=16, train_wall=8, gb_free=21.8, wall=1705
2023-08-21 14:56:10 | INFO | train_inner | epoch 017:    364 / 1265 loss=3.121, nll_loss=1.512, ppl=2.85, wps=95599.7, ups=13.68, wpb=6990.3, bsz=257.8, num_updates=20600, lr=0.000440653, gnorm=0.297, loss_scale=16, train_wall=7, gb_free=21.8, wall=1712
2023-08-21 14:56:19 | INFO | train_inner | epoch 017:    464 / 1265 loss=3.131, nll_loss=1.522, ppl=2.87, wps=83833.4, ups=12.29, wpb=6822.1, bsz=244.9, num_updates=20700, lr=0.000439587, gnorm=0.3, loss_scale=16, train_wall=8, gb_free=21.8, wall=1720
2023-08-21 14:56:26 | INFO | train_inner | epoch 017:    564 / 1265 loss=3.12, nll_loss=1.511, ppl=2.85, wps=93884.4, ups=13.42, wpb=6995, bsz=259.9, num_updates=20800, lr=0.000438529, gnorm=0.293, loss_scale=16, train_wall=7, gb_free=21.8, wall=1728
2023-08-21 14:56:33 | INFO | train_inner | epoch 017:    664 / 1265 loss=3.158, nll_loss=1.555, ppl=2.94, wps=95056.1, ups=13.57, wpb=7003.1, bsz=261.3, num_updates=20900, lr=0.000437479, gnorm=0.296, loss_scale=16, train_wall=7, gb_free=21.9, wall=1735
2023-08-21 14:56:41 | INFO | train_inner | epoch 017:    764 / 1265 loss=3.117, nll_loss=1.51, ppl=2.85, wps=91971.3, ups=13.55, wpb=6789.9, bsz=263.8, num_updates=21000, lr=0.000436436, gnorm=0.301, loss_scale=16, train_wall=7, gb_free=22.1, wall=1743
2023-08-21 14:56:48 | INFO | train_inner | epoch 017:    864 / 1265 loss=3.161, nll_loss=1.558, ppl=2.94, wps=93986.9, ups=13.68, wpb=6869.5, bsz=245.5, num_updates=21100, lr=0.0004354, gnorm=0.305, loss_scale=16, train_wall=7, gb_free=21.8, wall=1750
2023-08-21 14:56:56 | INFO | train_inner | epoch 017:    964 / 1265 loss=3.144, nll_loss=1.539, ppl=2.91, wps=91450.8, ups=13.43, wpb=6808.3, bsz=264.7, num_updates=21200, lr=0.000434372, gnorm=0.299, loss_scale=16, train_wall=7, gb_free=21.9, wall=1757
2023-08-21 14:57:03 | INFO | train_inner | epoch 017:   1064 / 1265 loss=3.152, nll_loss=1.547, ppl=2.92, wps=91104.1, ups=13.18, wpb=6914, bsz=233.4, num_updates=21300, lr=0.000433351, gnorm=0.3, loss_scale=16, train_wall=7, gb_free=22, wall=1765
2023-08-21 14:57:11 | INFO | train_inner | epoch 017:   1164 / 1265 loss=3.187, nll_loss=1.588, ppl=3.01, wps=89256.6, ups=13.2, wpb=6762.8, bsz=241.3, num_updates=21400, lr=0.000432338, gnorm=0.309, loss_scale=16, train_wall=7, gb_free=21.7, wall=1773
2023-08-21 14:57:18 | INFO | train_inner | epoch 017:   1264 / 1265 loss=3.145, nll_loss=1.542, ppl=2.91, wps=91551.7, ups=13.06, wpb=7012.7, bsz=254.4, num_updates=21500, lr=0.000431331, gnorm=0.294, loss_scale=16, train_wall=7, gb_free=21.7, wall=1780
2023-08-21 14:57:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:57:21 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.698 | nll_loss 2.121 | ppl 4.35 | wps 135428 | wpb 3858.1 | bsz 131.6 | num_updates 21501 | best_loss 3.698
2023-08-21 14:57:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 21501 updates
2023-08-21 14:57:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint17.pt
2023-08-21 14:57:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint17.pt
2023-08-21 14:57:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint17.pt (epoch 17 @ 21501 updates, score 3.698) (writing took 8.189412344014272 seconds)
2023-08-21 14:57:31 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-21 14:57:31 | INFO | train | epoch 017 | loss 3.136 | nll_loss 1.529 | ppl 2.89 | wps 79401.8 | ups 11.54 | wpb 6881.3 | bsz 251 | num_updates 21501 | lr 0.000431321 | gnorm 0.299 | loss_scale 16 | train_wall 93 | gb_free 21.8 | wall 1793
2023-08-21 14:57:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:57:31 | INFO | fairseq.trainer | begin training epoch 18
2023-08-21 14:57:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:57:40 | INFO | train_inner | epoch 018:     99 / 1265 loss=3.057, nll_loss=1.438, ppl=2.71, wps=31276.1, ups=4.54, wpb=6883.4, bsz=248.1, num_updates=21600, lr=0.000430331, gnorm=0.29, loss_scale=16, train_wall=7, gb_free=21.8, wall=1802
2023-08-21 14:57:48 | INFO | train_inner | epoch 018:    199 / 1265 loss=3.066, nll_loss=1.447, ppl=2.73, wps=91671, ups=13.34, wpb=6872.8, bsz=248.3, num_updates=21700, lr=0.000429339, gnorm=0.295, loss_scale=16, train_wall=7, gb_free=22, wall=1810
2023-08-21 14:57:55 | INFO | train_inner | epoch 018:    299 / 1265 loss=3.086, nll_loss=1.471, ppl=2.77, wps=94770.6, ups=13.57, wpb=6984.9, bsz=265.4, num_updates=21800, lr=0.000428353, gnorm=0.294, loss_scale=16, train_wall=7, gb_free=21.8, wall=1817
2023-08-21 14:58:03 | INFO | train_inner | epoch 018:    399 / 1265 loss=3.127, nll_loss=1.517, ppl=2.86, wps=90984.8, ups=13.26, wpb=6859.2, bsz=242.3, num_updates=21900, lr=0.000427374, gnorm=0.307, loss_scale=16, train_wall=7, gb_free=21.8, wall=1825
2023-08-21 14:58:11 | INFO | train_inner | epoch 018:    499 / 1265 loss=3.112, nll_loss=1.5, ppl=2.83, wps=86863, ups=12.54, wpb=6924.8, bsz=238.8, num_updates=22000, lr=0.000426401, gnorm=0.298, loss_scale=16, train_wall=8, gb_free=21.8, wall=1833
2023-08-21 14:58:19 | INFO | train_inner | epoch 018:    599 / 1265 loss=3.095, nll_loss=1.48, ppl=2.79, wps=83449.9, ups=12.33, wpb=6765.3, bsz=257.3, num_updates=22100, lr=0.000425436, gnorm=0.302, loss_scale=16, train_wall=8, gb_free=21.8, wall=1841
2023-08-21 14:58:27 | INFO | train_inner | epoch 018:    699 / 1265 loss=3.114, nll_loss=1.503, ppl=2.84, wps=86025.2, ups=12.6, wpb=6826.2, bsz=242, num_updates=22200, lr=0.000424476, gnorm=0.304, loss_scale=16, train_wall=8, gb_free=21.8, wall=1849
2023-08-21 14:58:35 | INFO | train_inner | epoch 018:    799 / 1265 loss=3.123, nll_loss=1.513, ppl=2.85, wps=85064.7, ups=12.53, wpb=6790.5, bsz=230.1, num_updates=22300, lr=0.000423524, gnorm=0.307, loss_scale=16, train_wall=8, gb_free=21.8, wall=1857
2023-08-21 14:58:43 | INFO | train_inner | epoch 018:    899 / 1265 loss=3.12, nll_loss=1.511, ppl=2.85, wps=85158.9, ups=12.43, wpb=6849.1, bsz=264.5, num_updates=22400, lr=0.000422577, gnorm=0.299, loss_scale=16, train_wall=8, gb_free=21.7, wall=1865
2023-08-21 14:58:51 | INFO | train_inner | epoch 018:    999 / 1265 loss=3.108, nll_loss=1.498, ppl=2.83, wps=85718.1, ups=12.23, wpb=7010.2, bsz=255.1, num_updates=22500, lr=0.000421637, gnorm=0.298, loss_scale=32, train_wall=8, gb_free=21.8, wall=1873
2023-08-21 14:58:59 | INFO | train_inner | epoch 018:   1099 / 1265 loss=3.142, nll_loss=1.537, ppl=2.9, wps=83968.1, ups=12.27, wpb=6845.9, bsz=251.8, num_updates=22600, lr=0.000420703, gnorm=0.302, loss_scale=32, train_wall=8, gb_free=21.8, wall=1881
2023-08-21 14:59:07 | INFO | train_inner | epoch 018:   1199 / 1265 loss=3.136, nll_loss=1.529, ppl=2.89, wps=82747.6, ups=12.18, wpb=6795.5, bsz=264.6, num_updates=22700, lr=0.000419775, gnorm=0.308, loss_scale=32, train_wall=8, gb_free=21.8, wall=1889
2023-08-21 14:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 14:59:15 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.711 | nll_loss 2.125 | ppl 4.36 | wps 196926 | wpb 3858.1 | bsz 131.6 | num_updates 22766 | best_loss 3.698
2023-08-21 14:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 22766 updates
2023-08-21 14:59:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint18.pt
2023-08-21 14:59:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint18.pt
2023-08-21 14:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint18.pt (epoch 18 @ 22766 updates, score 3.711) (writing took 2.0929433880373836 seconds)
2023-08-21 14:59:17 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-21 14:59:17 | INFO | train | epoch 018 | loss 3.109 | nll_loss 1.498 | ppl 2.82 | wps 81846.9 | ups 11.89 | wpb 6881.3 | bsz 251 | num_updates 22766 | lr 0.000419167 | gnorm 0.3 | loss_scale 32 | train_wall 97 | gb_free 21.7 | wall 1899
2023-08-21 14:59:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 14:59:17 | INFO | fairseq.trainer | begin training epoch 19
2023-08-21 14:59:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 14:59:22 | INFO | train_inner | epoch 019:     34 / 1265 loss=3.105, nll_loss=1.493, ppl=2.81, wps=48094.2, ups=6.73, wpb=7146.9, bsz=255, num_updates=22800, lr=0.000418854, gnorm=0.289, loss_scale=32, train_wall=8, gb_free=21.8, wall=1904
2023-08-21 14:59:30 | INFO | train_inner | epoch 019:    134 / 1265 loss=3.031, nll_loss=1.405, ppl=2.65, wps=87007.9, ups=12.68, wpb=6859.9, bsz=261.4, num_updates=22900, lr=0.000417938, gnorm=0.29, loss_scale=32, train_wall=8, gb_free=21.8, wall=1912
2023-08-21 14:59:38 | INFO | train_inner | epoch 019:    234 / 1265 loss=3.055, nll_loss=1.433, ppl=2.7, wps=84352.3, ups=12.27, wpb=6874.3, bsz=242.4, num_updates=23000, lr=0.000417029, gnorm=0.299, loss_scale=32, train_wall=8, gb_free=21.8, wall=1920
2023-08-21 14:59:47 | INFO | train_inner | epoch 019:    334 / 1265 loss=3.041, nll_loss=1.419, ppl=2.67, wps=83377.1, ups=12.07, wpb=6905.9, bsz=259, num_updates=23100, lr=0.000416125, gnorm=0.295, loss_scale=32, train_wall=8, gb_free=21.7, wall=1928
2023-08-21 14:59:55 | INFO | train_inner | epoch 019:    434 / 1265 loss=3.065, nll_loss=1.447, ppl=2.73, wps=87273, ups=12.58, wpb=6936.3, bsz=252.4, num_updates=23200, lr=0.000415227, gnorm=0.293, loss_scale=32, train_wall=8, gb_free=21.7, wall=1936
2023-08-21 15:00:03 | INFO | train_inner | epoch 019:    534 / 1265 loss=3.083, nll_loss=1.466, ppl=2.76, wps=84501, ups=12.35, wpb=6843.8, bsz=247.8, num_updates=23300, lr=0.000414335, gnorm=0.303, loss_scale=32, train_wall=8, gb_free=21.7, wall=1944
2023-08-21 15:00:11 | INFO | train_inner | epoch 019:    634 / 1265 loss=3.113, nll_loss=1.501, ppl=2.83, wps=88503.4, ups=12.53, wpb=7062.2, bsz=248.8, num_updates=23400, lr=0.000413449, gnorm=0.3, loss_scale=32, train_wall=8, gb_free=21.7, wall=1952
2023-08-21 15:00:19 | INFO | train_inner | epoch 019:    734 / 1265 loss=3.098, nll_loss=1.485, ppl=2.8, wps=84964.4, ups=12.2, wpb=6961.8, bsz=256.9, num_updates=23500, lr=0.000412568, gnorm=0.298, loss_scale=32, train_wall=8, gb_free=21.7, wall=1961
2023-08-21 15:00:27 | INFO | train_inner | epoch 019:    834 / 1265 loss=3.103, nll_loss=1.491, ppl=2.81, wps=84432.9, ups=12.2, wpb=6922.2, bsz=261.4, num_updates=23600, lr=0.000411693, gnorm=0.301, loss_scale=32, train_wall=8, gb_free=21.8, wall=1969
2023-08-21 15:00:35 | INFO | train_inner | epoch 019:    934 / 1265 loss=3.106, nll_loss=1.493, ppl=2.81, wps=79993.3, ups=12.02, wpb=6657.2, bsz=229, num_updates=23700, lr=0.000410824, gnorm=0.313, loss_scale=32, train_wall=8, gb_free=21.9, wall=1977
2023-08-21 15:00:43 | INFO | train_inner | epoch 019:   1034 / 1265 loss=3.13, nll_loss=1.522, ppl=2.87, wps=85406.6, ups=12.49, wpb=6837.8, bsz=249.9, num_updates=23800, lr=0.00040996, gnorm=0.309, loss_scale=32, train_wall=8, gb_free=21.7, wall=1985
2023-08-21 15:00:51 | INFO | train_inner | epoch 019:   1134 / 1265 loss=3.116, nll_loss=1.506, ppl=2.84, wps=85870.8, ups=12.43, wpb=6906.4, bsz=245.7, num_updates=23900, lr=0.000409101, gnorm=0.303, loss_scale=32, train_wall=8, gb_free=21.7, wall=1993
2023-08-21 15:01:00 | INFO | train_inner | epoch 019:   1234 / 1265 loss=3.093, nll_loss=1.48, ppl=2.79, wps=83828.2, ups=12.29, wpb=6822.7, bsz=260.8, num_updates=24000, lr=0.000408248, gnorm=0.304, loss_scale=32, train_wall=8, gb_free=21.8, wall=2001
2023-08-21 15:01:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 15:01:04 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.711 | nll_loss 2.13 | ppl 4.38 | wps 189026 | wpb 3858.1 | bsz 131.6 | num_updates 24031 | best_loss 3.698
2023-08-21 15:01:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 24031 updates
2023-08-21 15:01:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint19.pt
2023-08-21 15:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint19.pt
2023-08-21 15:01:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint19.pt (epoch 19 @ 24031 updates, score 3.711) (writing took 1.6204861599835567 seconds)
2023-08-21 15:01:06 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-21 15:01:06 | INFO | train | epoch 019 | loss 3.085 | nll_loss 1.469 | ppl 2.77 | wps 79957.2 | ups 11.62 | wpb 6881.3 | bsz 251 | num_updates 24031 | lr 0.000407985 | gnorm 0.301 | loss_scale 32 | train_wall 99 | gb_free 21.6 | wall 2008
2023-08-21 15:01:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 15:01:06 | INFO | fairseq.trainer | begin training epoch 20
2023-08-21 15:01:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 15:01:14 | INFO | train_inner | epoch 020:     69 / 1265 loss=3.03, nll_loss=1.405, ppl=2.65, wps=48119.9, ups=7.16, wpb=6722.6, bsz=245.7, num_updates=24100, lr=0.0004074, gnorm=0.302, loss_scale=32, train_wall=8, gb_free=21.8, wall=2015
2023-08-21 15:01:22 | INFO | train_inner | epoch 020:    169 / 1265 loss=3.012, nll_loss=1.384, ppl=2.61, wps=85596.1, ups=12.42, wpb=6893, bsz=256, num_updates=24200, lr=0.000406558, gnorm=0.294, loss_scale=32, train_wall=8, gb_free=21.8, wall=2023
2023-08-21 15:01:30 | INFO | train_inner | epoch 020:    269 / 1265 loss=3.034, nll_loss=1.408, ppl=2.65, wps=85106.3, ups=12.4, wpb=6862.7, bsz=237.1, num_updates=24300, lr=0.00040572, gnorm=0.3, loss_scale=32, train_wall=8, gb_free=21.8, wall=2031
2023-08-21 15:01:38 | INFO | train_inner | epoch 020:    369 / 1265 loss=3.062, nll_loss=1.44, ppl=2.71, wps=82633.8, ups=12.45, wpb=6638.2, bsz=234, num_updates=24400, lr=0.000404888, gnorm=0.313, loss_scale=32, train_wall=8, gb_free=21.8, wall=2040
2023-08-21 15:01:46 | INFO | train_inner | epoch 020:    469 / 1265 loss=3.062, nll_loss=1.441, ppl=2.71, wps=86774, ups=12.4, wpb=6997.8, bsz=233.8, num_updates=24500, lr=0.000404061, gnorm=0.298, loss_scale=32, train_wall=8, gb_free=21.7, wall=2048
2023-08-21 15:01:54 | INFO | train_inner | epoch 020:    569 / 1265 loss=3.073, nll_loss=1.455, ppl=2.74, wps=86511.9, ups=12.38, wpb=6985.5, bsz=258.2, num_updates=24600, lr=0.000403239, gnorm=0.296, loss_scale=32, train_wall=8, gb_free=21.7, wall=2056
2023-08-21 15:02:02 | INFO | train_inner | epoch 020:    669 / 1265 loss=3.057, nll_loss=1.438, ppl=2.71, wps=84888.5, ups=12.25, wpb=6927.6, bsz=275, num_updates=24700, lr=0.000402422, gnorm=0.297, loss_scale=32, train_wall=8, gb_free=21.7, wall=2064
2023-08-21 15:02:10 | INFO | train_inner | epoch 020:    769 / 1265 loss=3.071, nll_loss=1.453, ppl=2.74, wps=88516.8, ups=12.79, wpb=6918.8, bsz=252.5, num_updates=24800, lr=0.00040161, gnorm=0.301, loss_scale=32, train_wall=8, gb_free=21.6, wall=2072
2023-08-21 15:02:18 | INFO | train_inner | epoch 020:    869 / 1265 loss=3.081, nll_loss=1.463, ppl=2.76, wps=85484.5, ups=12.28, wpb=6963.5, bsz=233.6, num_updates=24900, lr=0.000400802, gnorm=0.3, loss_scale=32, train_wall=8, gb_free=21.8, wall=2080
2023-08-21 15:02:26 | INFO | train_inner | epoch 020:    969 / 1265 loss=3.073, nll_loss=1.457, ppl=2.74, wps=84520.7, ups=12.22, wpb=6914.9, bsz=260.9, num_updates=25000, lr=0.0004, gnorm=0.299, loss_scale=32, train_wall=8, gb_free=21.8, wall=2088
2023-08-21 15:02:34 | INFO | train_inner | epoch 020:   1069 / 1265 loss=3.076, nll_loss=1.46, ppl=2.75, wps=86034, ups=12.57, wpb=6846, bsz=263, num_updates=25100, lr=0.000399202, gnorm=0.305, loss_scale=32, train_wall=8, gb_free=21.7, wall=2096
2023-08-21 15:02:42 | INFO | train_inner | epoch 020:   1169 / 1265 loss=3.095, nll_loss=1.482, ppl=2.79, wps=85224, ups=12.39, wpb=6881.1, bsz=263, num_updates=25200, lr=0.00039841, gnorm=0.3, loss_scale=32, train_wall=8, gb_free=21.7, wall=2104
2023-08-21 15:02:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 15:02:52 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.704 | nll_loss 2.124 | ppl 4.36 | wps 166213 | wpb 3858.1 | bsz 131.6 | num_updates 25296 | best_loss 3.698
2023-08-21 15:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 25296 updates
2023-08-21 15:02:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint20.pt
2023-08-21 15:02:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint20.pt
2023-08-21 15:02:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint20.pt (epoch 20 @ 25296 updates, score 3.704) (writing took 1.7724151349975727 seconds)
2023-08-21 15:02:54 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-21 15:02:54 | INFO | train | epoch 020 | loss 3.061 | nll_loss 1.442 | ppl 2.72 | wps 80694.4 | ups 11.73 | wpb 6881.3 | bsz 251 | num_updates 25296 | lr 0.000397653 | gnorm 0.301 | loss_scale 32 | train_wall 98 | gb_free 21.7 | wall 2116
2023-08-21 15:02:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 15:02:54 | INFO | fairseq.trainer | begin training epoch 21
2023-08-21 15:02:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 15:02:56 | INFO | train_inner | epoch 021:      4 / 1265 loss=3.079, nll_loss=1.463, ppl=2.76, wps=47975.6, ups=7.08, wpb=6776.4, bsz=252.7, num_updates=25300, lr=0.000397621, gnorm=0.311, loss_scale=32, train_wall=8, gb_free=21.8, wall=2118
2023-08-21 15:03:04 | INFO | train_inner | epoch 021:    104 / 1265 loss=2.993, nll_loss=1.361, ppl=2.57, wps=84402.9, ups=12.39, wpb=6812.7, bsz=263.9, num_updates=25400, lr=0.000396838, gnorm=0.296, loss_scale=32, train_wall=8, gb_free=21.8, wall=2126
2023-08-21 15:03:12 | INFO | train_inner | epoch 021:    204 / 1265 loss=3, nll_loss=1.369, ppl=2.58, wps=85055.7, ups=12.52, wpb=6794, bsz=244.1, num_updates=25500, lr=0.000396059, gnorm=0.301, loss_scale=32, train_wall=8, gb_free=21.8, wall=2134
2023-08-21 15:03:21 | INFO | train_inner | epoch 021:    304 / 1265 loss=3.011, nll_loss=1.382, ppl=2.61, wps=84683, ups=12.28, wpb=6896.9, bsz=245, num_updates=25600, lr=0.000395285, gnorm=0.299, loss_scale=32, train_wall=8, gb_free=21.8, wall=2142
2023-08-21 15:03:29 | INFO | train_inner | epoch 021:    404 / 1265 loss=3.033, nll_loss=1.409, ppl=2.66, wps=87029.5, ups=12.49, wpb=6967.2, bsz=267.4, num_updates=25700, lr=0.000394515, gnorm=0.295, loss_scale=32, train_wall=8, gb_free=21.7, wall=2150
2023-08-21 15:03:36 | INFO | train_inner | epoch 021:    504 / 1265 loss=3.024, nll_loss=1.399, ppl=2.64, wps=89696.7, ups=12.9, wpb=6951.6, bsz=265, num_updates=25800, lr=0.00039375, gnorm=0.296, loss_scale=32, train_wall=8, gb_free=21.8, wall=2158
2023-08-21 15:03:44 | INFO | train_inner | epoch 021:    604 / 1265 loss=3.026, nll_loss=1.4, ppl=2.64, wps=87044.2, ups=12.74, wpb=6834.5, bsz=251.9, num_updates=25900, lr=0.000392989, gnorm=0.304, loss_scale=32, train_wall=8, gb_free=21.8, wall=2166
2023-08-21 15:03:52 | INFO | train_inner | epoch 021:    704 / 1265 loss=3.05, nll_loss=1.428, ppl=2.69, wps=86590.4, ups=12.71, wpb=6813.4, bsz=239.4, num_updates=26000, lr=0.000392232, gnorm=0.306, loss_scale=32, train_wall=8, gb_free=21.8, wall=2174
2023-08-21 15:04:00 | INFO | train_inner | epoch 021:    804 / 1265 loss=3.054, nll_loss=1.432, ppl=2.7, wps=86085.4, ups=12.32, wpb=6985.4, bsz=244.2, num_updates=26100, lr=0.00039148, gnorm=0.302, loss_scale=32, train_wall=8, gb_free=21.9, wall=2182
2023-08-21 15:04:08 | INFO | train_inner | epoch 021:    904 / 1265 loss=3.07, nll_loss=1.451, ppl=2.73, wps=87236.8, ups=12.54, wpb=6959.3, bsz=246.5, num_updates=26200, lr=0.000390732, gnorm=0.302, loss_scale=32, train_wall=8, gb_free=21.7, wall=2190
2023-08-21 15:04:16 | INFO | train_inner | epoch 021:   1004 / 1265 loss=3.06, nll_loss=1.439, ppl=2.71, wps=83151.6, ups=12.35, wpb=6735.7, bsz=231, num_updates=26300, lr=0.000389989, gnorm=0.312, loss_scale=32, train_wall=8, gb_free=21.8, wall=2198
2023-08-21 15:04:24 | INFO | train_inner | epoch 021:   1104 / 1265 loss=3.071, nll_loss=1.453, ppl=2.74, wps=86896.1, ups=12.63, wpb=6882.8, bsz=253, num_updates=26400, lr=0.000389249, gnorm=0.308, loss_scale=32, train_wall=8, gb_free=21.7, wall=2206
2023-08-21 15:04:32 | INFO | train_inner | epoch 021:   1204 / 1265 loss=3.065, nll_loss=1.448, ppl=2.73, wps=88550.7, ups=12.75, wpb=6946.1, bsz=267.2, num_updates=26500, lr=0.000388514, gnorm=0.298, loss_scale=32, train_wall=8, gb_free=21.7, wall=2214
2023-08-21 15:04:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 15:04:39 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.719 | nll_loss 2.135 | ppl 4.39 | wps 190789 | wpb 3858.1 | bsz 131.6 | num_updates 26561 | best_loss 3.698
2023-08-21 15:04:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 26561 updates
2023-08-21 15:04:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint21.pt
2023-08-21 15:04:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint21.pt
2023-08-21 15:04:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint21.pt (epoch 21 @ 26561 updates, score 3.719) (writing took 1.8069440000108443 seconds)
2023-08-21 15:04:41 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-21 15:04:41 | INFO | train | epoch 021 | loss 3.041 | nll_loss 1.417 | ppl 2.67 | wps 81151.3 | ups 11.79 | wpb 6881.3 | bsz 251 | num_updates 26561 | lr 0.000388068 | gnorm 0.302 | loss_scale 32 | train_wall 98 | gb_free 21.8 | wall 2223
2023-08-21 15:04:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 15:04:41 | INFO | fairseq.trainer | begin training epoch 22
2023-08-21 15:04:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 15:04:46 | INFO | train_inner | epoch 022:     39 / 1265 loss=3.052, nll_loss=1.43, ppl=2.69, wps=47538.6, ups=6.95, wpb=6836.8, bsz=239.4, num_updates=26600, lr=0.000387783, gnorm=0.308, loss_scale=32, train_wall=8, gb_free=22, wall=2228
2023-08-21 15:04:54 | INFO | train_inner | epoch 022:    139 / 1265 loss=2.955, nll_loss=1.318, ppl=2.49, wps=88132.1, ups=12.69, wpb=6946.5, bsz=267.5, num_updates=26700, lr=0.000387056, gnorm=0.289, loss_scale=32, train_wall=8, gb_free=21.8, wall=2236
2023-08-21 15:05:02 | INFO | train_inner | epoch 022:    239 / 1265 loss=3.002, nll_loss=1.37, ppl=2.58, wps=88032.9, ups=12.85, wpb=6848.8, bsz=231.4, num_updates=26800, lr=0.000386334, gnorm=0.306, loss_scale=32, train_wall=8, gb_free=21.7, wall=2244
2023-08-21 15:05:10 | INFO | train_inner | epoch 022:    339 / 1265 loss=2.985, nll_loss=1.352, ppl=2.55, wps=86863.8, ups=12.6, wpb=6894.9, bsz=233.2, num_updates=26900, lr=0.000385615, gnorm=0.297, loss_scale=32, train_wall=8, gb_free=21.8, wall=2252
2023-08-21 15:05:18 | INFO | train_inner | epoch 022:    439 / 1265 loss=3.018, nll_loss=1.39, ppl=2.62, wps=84061.7, ups=12.33, wpb=6817.6, bsz=258.8, num_updates=27000, lr=0.0003849, gnorm=0.305, loss_scale=32, train_wall=8, gb_free=21.9, wall=2260
2023-08-21 15:05:26 | INFO | train_inner | epoch 022:    539 / 1265 loss=3.037, nll_loss=1.412, ppl=2.66, wps=85444.4, ups=12.55, wpb=6809.2, bsz=253, num_updates=27100, lr=0.000384189, gnorm=0.307, loss_scale=32, train_wall=8, gb_free=21.9, wall=2268
2023-08-21 15:05:34 | INFO | train_inner | epoch 022:    639 / 1265 loss=3.039, nll_loss=1.414, ppl=2.66, wps=87691.7, ups=12.71, wpb=6899, bsz=252.2, num_updates=27200, lr=0.000383482, gnorm=0.306, loss_scale=32, train_wall=8, gb_free=21.7, wall=2276
2023-08-21 15:05:42 | INFO | train_inner | epoch 022:    739 / 1265 loss=3.011, nll_loss=1.384, ppl=2.61, wps=88590.6, ups=12.74, wpb=6952, bsz=253.6, num_updates=27300, lr=0.00038278, gnorm=0.3, loss_scale=32, train_wall=8, gb_free=21.6, wall=2284
2023-08-21 15:05:50 | INFO | train_inner | epoch 022:    839 / 1265 loss=3.005, nll_loss=1.377, ppl=2.6, wps=85112.9, ups=12.23, wpb=6959.2, bsz=256.8, num_updates=27400, lr=0.00038208, gnorm=0.301, loss_scale=32, train_wall=8, gb_free=21.8, wall=2292
2023-08-21 15:05:58 | INFO | train_inner | epoch 022:    939 / 1265 loss=3.04, nll_loss=1.418, ppl=2.67, wps=87424.8, ups=12.49, wpb=7001.4, bsz=260.4, num_updates=27500, lr=0.000381385, gnorm=0.3, loss_scale=32, train_wall=8, gb_free=21.8, wall=2300
2023-08-21 15:06:06 | INFO | train_inner | epoch 022:   1039 / 1265 loss=3.028, nll_loss=1.402, ppl=2.64, wps=87877.9, ups=12.95, wpb=6787.9, bsz=245.8, num_updates=27600, lr=0.000380693, gnorm=0.307, loss_scale=32, train_wall=8, gb_free=21.7, wall=2308
2023-08-21 15:06:13 | INFO | train_inner | epoch 022:   1139 / 1265 loss=3.073, nll_loss=1.455, ppl=2.74, wps=89071.5, ups=13.02, wpb=6840.4, bsz=246, num_updates=27700, lr=0.000380006, gnorm=0.308, loss_scale=32, train_wall=7, gb_free=21.8, wall=2315
2023-08-21 15:06:21 | INFO | train_inner | epoch 022:   1239 / 1265 loss=3.067, nll_loss=1.448, ppl=2.73, wps=85579.8, ups=12.4, wpb=6902.5, bsz=256.1, num_updates=27800, lr=0.000379322, gnorm=0.314, loss_scale=32, train_wall=8, gb_free=21.7, wall=2323
2023-08-21 15:06:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 15:06:26 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.718 | nll_loss 2.132 | ppl 4.38 | wps 175029 | wpb 3858.1 | bsz 131.6 | num_updates 27826 | best_loss 3.698
2023-08-21 15:06:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 27826 updates
2023-08-21 15:06:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint22.pt
2023-08-21 15:06:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint22.pt
2023-08-21 15:06:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint22.pt (epoch 22 @ 27826 updates, score 3.718) (writing took 1.717236372991465 seconds)
2023-08-21 15:06:28 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-21 15:06:28 | INFO | train | epoch 022 | loss 3.021 | nll_loss 1.394 | ppl 2.63 | wps 81795.4 | ups 11.89 | wpb 6881.3 | bsz 251 | num_updates 27826 | lr 0.000379144 | gnorm 0.303 | loss_scale 32 | train_wall 97 | gb_free 21.7 | wall 2329
2023-08-21 15:06:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 15:06:28 | INFO | fairseq.trainer | begin training epoch 23
2023-08-21 15:06:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 15:06:35 | INFO | train_inner | epoch 023:     74 / 1265 loss=2.975, nll_loss=1.34, ppl=2.53, wps=48807, ups=7.12, wpb=6851, bsz=251.4, num_updates=27900, lr=0.000378641, gnorm=0.293, loss_scale=32, train_wall=8, gb_free=21.9, wall=2337
2023-08-21 15:06:44 | INFO | train_inner | epoch 023:    174 / 1265 loss=2.967, nll_loss=1.331, ppl=2.52, wps=86593.1, ups=12.42, wpb=6970.6, bsz=266.2, num_updates=28000, lr=0.000377964, gnorm=0.295, loss_scale=32, train_wall=8, gb_free=21.7, wall=2345
2023-08-21 15:06:52 | INFO | train_inner | epoch 023:    274 / 1265 loss=2.97, nll_loss=1.334, ppl=2.52, wps=85438.7, ups=12.39, wpb=6893.9, bsz=229, num_updates=28100, lr=0.000377291, gnorm=0.301, loss_scale=32, train_wall=8, gb_free=21.9, wall=2353
2023-08-21 15:06:59 | INFO | train_inner | epoch 023:    374 / 1265 loss=2.985, nll_loss=1.352, ppl=2.55, wps=88831.5, ups=13.02, wpb=6824.5, bsz=258.1, num_updates=28200, lr=0.000376622, gnorm=0.304, loss_scale=32, train_wall=7, gb_free=21.6, wall=2361
2023-08-21 15:07:07 | INFO | train_inner | epoch 023:    474 / 1265 loss=3.014, nll_loss=1.384, ppl=2.61, wps=86616.4, ups=12.85, wpb=6739.7, bsz=237.5, num_updates=28300, lr=0.000375956, gnorm=0.31, loss_scale=32, train_wall=8, gb_free=21.9, wall=2369
2023-08-21 15:07:15 | INFO | train_inner | epoch 023:    574 / 1265 loss=2.994, nll_loss=1.362, ppl=2.57, wps=88040.5, ups=12.72, wpb=6919.8, bsz=243.2, num_updates=28400, lr=0.000375293, gnorm=0.303, loss_scale=32, train_wall=8, gb_free=21.6, wall=2377
2023-08-21 15:07:23 | INFO | train_inner | epoch 023:    674 / 1265 loss=3.005, nll_loss=1.375, ppl=2.59, wps=90820, ups=12.94, wpb=7016.1, bsz=251.4, num_updates=28500, lr=0.000374634, gnorm=0.301, loss_scale=32, train_wall=8, gb_free=21.9, wall=2384
2023-08-21 15:07:30 | INFO | train_inner | epoch 023:    774 / 1265 loss=3.009, nll_loss=1.38, ppl=2.6, wps=90296.5, ups=12.94, wpb=6980.1, bsz=248.4, num_updates=28600, lr=0.000373979, gnorm=0.302, loss_scale=32, train_wall=8, gb_free=21.6, wall=2392
2023-08-21 15:07:38 | INFO | train_inner | epoch 023:    874 / 1265 loss=3.02, nll_loss=1.392, ppl=2.62, wps=88632.3, ups=12.91, wpb=6865.7, bsz=237.4, num_updates=28700, lr=0.000373327, gnorm=0.308, loss_scale=32, train_wall=8, gb_free=21.8, wall=2400
2023-08-21 15:07:46 | INFO | train_inner | epoch 023:    974 / 1265 loss=3.01, nll_loss=1.382, ppl=2.61, wps=88301.6, ups=12.83, wpb=6880.3, bsz=267.7, num_updates=28800, lr=0.000372678, gnorm=0.302, loss_scale=32, train_wall=8, gb_free=21.9, wall=2408
2023-08-21 15:07:54 | INFO | train_inner | epoch 023:   1074 / 1265 loss=3.02, nll_loss=1.393, ppl=2.63, wps=85010, ups=12.59, wpb=6754.5, bsz=235.4, num_updates=28900, lr=0.000372033, gnorm=0.312, loss_scale=32, train_wall=8, gb_free=21.7, wall=2416
2023-08-21 15:08:02 | INFO | train_inner | epoch 023:   1174 / 1265 loss=3.03, nll_loss=1.406, ppl=2.65, wps=88897, ups=12.9, wpb=6889.1, bsz=264.5, num_updates=29000, lr=0.000371391, gnorm=0.308, loss_scale=32, train_wall=8, gb_free=21.8, wall=2423
2023-08-21 15:08:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 15:08:11 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.708 | nll_loss 2.125 | ppl 4.36 | wps 183034 | wpb 3858.1 | bsz 131.6 | num_updates 29091 | best_loss 3.698
2023-08-21 15:08:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 29091 updates
2023-08-21 15:08:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint23.pt
2023-08-21 15:08:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint23.pt
2023-08-21 15:08:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint23.pt (epoch 23 @ 29091 updates, score 3.708) (writing took 1.7957031279802322 seconds)
2023-08-21 15:08:13 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-21 15:08:13 | INFO | train | epoch 023 | loss 3.002 | nll_loss 1.371 | ppl 2.59 | wps 82697 | ups 12.02 | wpb 6881.3 | bsz 251 | num_updates 29091 | lr 0.000370809 | gnorm 0.303 | loss_scale 32 | train_wall 96 | gb_free 21.7 | wall 2435
2023-08-21 15:08:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 15:08:13 | INFO | fairseq.trainer | begin training epoch 24
2023-08-21 15:08:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 15:08:16 | INFO | train_inner | epoch 024:      9 / 1265 loss=3.039, nll_loss=1.416, ppl=2.67, wps=48777.4, ups=7.15, wpb=6818.1, bsz=264, num_updates=29100, lr=0.000370752, gnorm=0.307, loss_scale=32, train_wall=7, gb_free=21.8, wall=2437
2023-08-21 15:08:23 | INFO | train_inner | epoch 024:    109 / 1265 loss=2.967, nll_loss=1.329, ppl=2.51, wps=90259.2, ups=12.98, wpb=6954.5, bsz=240.5, num_updates=29200, lr=0.000370117, gnorm=0.3, loss_scale=32, train_wall=7, gb_free=21.8, wall=2445
2023-08-21 15:08:31 | INFO | train_inner | epoch 024:    209 / 1265 loss=2.956, nll_loss=1.318, ppl=2.49, wps=90346.9, ups=13.32, wpb=6784.5, bsz=263.8, num_updates=29300, lr=0.000369484, gnorm=0.305, loss_scale=32, train_wall=7, gb_free=21.9, wall=2453
2023-08-21 15:08:38 | INFO | train_inner | epoch 024:    309 / 1265 loss=2.954, nll_loss=1.316, ppl=2.49, wps=89910.1, ups=13.16, wpb=6830.7, bsz=267.1, num_updates=29400, lr=0.000368856, gnorm=0.301, loss_scale=32, train_wall=7, gb_free=21.7, wall=2460
2023-08-21 15:08:46 | INFO | train_inner | epoch 024:    409 / 1265 loss=2.975, nll_loss=1.339, ppl=2.53, wps=90697.3, ups=13.13, wpb=6906.7, bsz=237.5, num_updates=29500, lr=0.00036823, gnorm=0.306, loss_scale=32, train_wall=7, gb_free=22, wall=2468
2023-08-21 15:08:54 | INFO | train_inner | epoch 024:    509 / 1265 loss=2.967, nll_loss=1.331, ppl=2.52, wps=90784.8, ups=13.12, wpb=6917.8, bsz=258.3, num_updates=29600, lr=0.000367607, gnorm=0.303, loss_scale=32, train_wall=7, gb_free=21.8, wall=2476
2023-08-21 15:09:01 | INFO | train_inner | epoch 024:    609 / 1265 loss=2.983, nll_loss=1.348, ppl=2.55, wps=92673.3, ups=13.42, wpb=6904.2, bsz=237.7, num_updates=29700, lr=0.000366988, gnorm=0.306, loss_scale=32, train_wall=7, gb_free=21.7, wall=2483
2023-08-21 15:09:09 | INFO | train_inner | epoch 024:    709 / 1265 loss=2.981, nll_loss=1.347, ppl=2.54, wps=90708.7, ups=13.17, wpb=6889.2, bsz=231.4, num_updates=29800, lr=0.000366372, gnorm=0.305, loss_scale=32, train_wall=7, gb_free=21.8, wall=2491
2023-08-21 15:09:17 | INFO | train_inner | epoch 024:    809 / 1265 loss=2.98, nll_loss=1.347, ppl=2.54, wps=86598.3, ups=12.59, wpb=6878.2, bsz=251.3, num_updates=29900, lr=0.000365758, gnorm=0.305, loss_scale=32, train_wall=8, gb_free=21.7, wall=2498
2023-08-21 15:09:24 | INFO | train_inner | epoch 024:    909 / 1265 loss=2.975, nll_loss=1.342, ppl=2.54, wps=90048.8, ups=13.11, wpb=6870.6, bsz=258.7, num_updates=30000, lr=0.000365148, gnorm=0.304, loss_scale=32, train_wall=7, gb_free=21.8, wall=2506
2023-08-21 15:09:32 | INFO | train_inner | epoch 024:   1009 / 1265 loss=3.013, nll_loss=1.384, ppl=2.61, wps=89640.6, ups=13, wpb=6894.1, bsz=245.9, num_updates=30100, lr=0.000364541, gnorm=0.306, loss_scale=32, train_wall=7, gb_free=21.9, wall=2514
2023-08-21 15:09:39 | INFO | train_inner | epoch 024:   1109 / 1265 loss=3.021, nll_loss=1.394, ppl=2.63, wps=93364.3, ups=13.44, wpb=6944.7, bsz=242.6, num_updates=30200, lr=0.000363937, gnorm=0.304, loss_scale=32, train_wall=7, gb_free=21.7, wall=2521
2023-08-21 15:09:47 | INFO | train_inner | epoch 024:   1209 / 1265 loss=3.01, nll_loss=1.383, ppl=2.61, wps=92576, ups=13.43, wpb=6895.5, bsz=267.4, num_updates=30300, lr=0.000363336, gnorm=0.306, loss_scale=32, train_wall=7, gb_free=21.8, wall=2529
2023-08-21 15:09:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 15:09:53 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.717 | nll_loss 2.133 | ppl 4.39 | wps 197001 | wpb 3858.1 | bsz 131.6 | num_updates 30356 | best_loss 3.698
2023-08-21 15:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 30356 updates
2023-08-21 15:09:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint24.pt
2023-08-21 15:09:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint24.pt
2023-08-21 15:09:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint24.pt (epoch 24 @ 30356 updates, score 3.717) (writing took 1.6767796920030378 seconds)
2023-08-21 15:09:55 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-21 15:09:55 | INFO | train | epoch 024 | loss 2.983 | nll_loss 1.35 | ppl 2.55 | wps 85201.6 | ups 12.38 | wpb 6881.3 | bsz 251 | num_updates 30356 | lr 0.000363001 | gnorm 0.304 | loss_scale 32 | train_wall 93 | gb_free 22 | wall 2537
2023-08-21 15:09:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 15:09:55 | INFO | fairseq.trainer | begin training epoch 25
2023-08-21 15:09:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 15:10:00 | INFO | train_inner | epoch 025:     44 / 1265 loss=2.959, nll_loss=1.324, ppl=2.5, wps=50329.9, ups=7.41, wpb=6790.1, bsz=276.6, num_updates=30400, lr=0.000362738, gnorm=0.3, loss_scale=32, train_wall=7, gb_free=21.7, wall=2542
2023-08-21 15:10:08 | INFO | train_inner | epoch 025:    144 / 1265 loss=2.916, nll_loss=1.27, ppl=2.41, wps=93469.8, ups=13.6, wpb=6872.6, bsz=250.6, num_updates=30500, lr=0.000362143, gnorm=0.301, loss_scale=32, train_wall=7, gb_free=21.7, wall=2550
2023-08-21 15:10:16 | INFO | train_inner | epoch 025:    244 / 1265 loss=2.948, nll_loss=1.308, ppl=2.48, wps=87775.2, ups=12.85, wpb=6830.2, bsz=248.7, num_updates=30600, lr=0.000361551, gnorm=0.304, loss_scale=32, train_wall=8, gb_free=21.8, wall=2557
2023-08-21 15:10:23 | INFO | train_inner | epoch 025:    344 / 1265 loss=2.963, nll_loss=1.325, ppl=2.51, wps=86761, ups=12.83, wpb=6763.7, bsz=238.1, num_updates=30700, lr=0.000360961, gnorm=0.312, loss_scale=64, train_wall=8, gb_free=21.7, wall=2565
2023-08-21 15:10:31 | INFO | train_inner | epoch 025:    444 / 1265 loss=2.956, nll_loss=1.317, ppl=2.49, wps=89319.3, ups=12.92, wpb=6911.4, bsz=231.3, num_updates=30800, lr=0.000360375, gnorm=0.306, loss_scale=64, train_wall=7, gb_free=21.7, wall=2573
2023-08-21 15:10:39 | INFO | train_inner | epoch 025:    544 / 1265 loss=2.942, nll_loss=1.304, ppl=2.47, wps=90644.9, ups=13.17, wpb=6884.9, bsz=271.8, num_updates=30900, lr=0.000359791, gnorm=0.3, loss_scale=64, train_wall=7, gb_free=21.8, wall=2580
2023-08-21 15:10:46 | INFO | train_inner | epoch 025:    644 / 1265 loss=2.936, nll_loss=1.296, ppl=2.46, wps=89050.6, ups=12.79, wpb=6964.6, bsz=251, num_updates=31000, lr=0.000359211, gnorm=0.3, loss_scale=64, train_wall=8, gb_free=21.8, wall=2588
2023-08-21 15:10:54 | INFO | train_inner | epoch 025:    744 / 1265 loss=2.983, nll_loss=1.349, ppl=2.55, wps=91931.9, ups=13.31, wpb=6908.8, bsz=243.4, num_updates=31100, lr=0.000358633, gnorm=0.309, loss_scale=64, train_wall=7, gb_free=21.8, wall=2596
2023-08-21 15:11:02 | INFO | train_inner | epoch 025:    844 / 1265 loss=3.009, nll_loss=1.378, ppl=2.6, wps=88403.7, ups=12.92, wpb=6840.3, bsz=226.6, num_updates=31200, lr=0.000358057, gnorm=0.313, loss_scale=64, train_wall=8, gb_free=21.7, wall=2604
2023-08-21 15:11:10 | INFO | train_inner | epoch 025:    944 / 1265 loss=2.967, nll_loss=1.332, ppl=2.52, wps=87681.2, ups=12.61, wpb=6956, bsz=257.2, num_updates=31300, lr=0.000357485, gnorm=0.304, loss_scale=64, train_wall=8, gb_free=21.7, wall=2611
2023-08-21 15:11:17 | INFO | train_inner | epoch 025:   1044 / 1265 loss=2.98, nll_loss=1.347, ppl=2.54, wps=90738.3, ups=13.17, wpb=6891, bsz=266.2, num_updates=31400, lr=0.000356915, gnorm=0.304, loss_scale=64, train_wall=7, gb_free=21.9, wall=2619
2023-08-21 15:11:25 | INFO | train_inner | epoch 025:   1144 / 1265 loss=3.012, nll_loss=1.384, ppl=2.61, wps=87003.9, ups=12.78, wpb=6809.5, bsz=260, num_updates=31500, lr=0.000356348, gnorm=0.313, loss_scale=64, train_wall=8, gb_free=21.7, wall=2627
2023-08-21 15:11:33 | INFO | train_inner | epoch 025:   1244 / 1265 loss=3.025, nll_loss=1.4, ppl=2.64, wps=92752.6, ups=13.26, wpb=6993.5, bsz=266.1, num_updates=31600, lr=0.000355784, gnorm=0.309, loss_scale=64, train_wall=7, gb_free=21.8, wall=2634
2023-08-21 15:11:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 15:11:37 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.725 | nll_loss 2.141 | ppl 4.41 | wps 191378 | wpb 3858.1 | bsz 131.6 | num_updates 31621 | best_loss 3.698
2023-08-21 15:11:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 31621 updates
2023-08-21 15:11:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint25.pt
2023-08-21 15:11:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint25.pt
2023-08-21 15:11:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint25.pt (epoch 25 @ 31621 updates, score 3.725) (writing took 1.8296869209734723 seconds)
2023-08-21 15:11:38 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-21 15:11:38 | INFO | train | epoch 025 | loss 2.968 | nll_loss 1.332 | ppl 2.52 | wps 84146.3 | ups 12.23 | wpb 6881.3 | bsz 251 | num_updates 31621 | lr 0.000355666 | gnorm 0.306 | loss_scale 64 | train_wall 94 | gb_free 21.9 | wall 2640
2023-08-21 15:11:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 15:11:38 | INFO | fairseq.trainer | begin training epoch 26
2023-08-21 15:11:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 15:11:47 | INFO | train_inner | epoch 026:     79 / 1265 loss=2.933, nll_loss=1.289, ppl=2.44, wps=49179.5, ups=7.13, wpb=6893.6, bsz=221.6, num_updates=31700, lr=0.000355222, gnorm=0.303, loss_scale=64, train_wall=7, gb_free=21.7, wall=2648
2023-08-21 15:11:54 | INFO | train_inner | epoch 026:    179 / 1265 loss=2.905, nll_loss=1.258, ppl=2.39, wps=88984.5, ups=12.89, wpb=6905.6, bsz=258.5, num_updates=31800, lr=0.000354663, gnorm=0.301, loss_scale=64, train_wall=8, gb_free=22.1, wall=2656
2023-08-21 15:12:02 | INFO | train_inner | epoch 026:    279 / 1265 loss=2.943, nll_loss=1.303, ppl=2.47, wps=88650.9, ups=12.79, wpb=6930.5, bsz=284.2, num_updates=31900, lr=0.000354107, gnorm=0.3, loss_scale=64, train_wall=8, gb_free=21.9, wall=2664
2023-08-21 15:12:10 | INFO | train_inner | epoch 026:    379 / 1265 loss=2.929, nll_loss=1.288, ppl=2.44, wps=86751.7, ups=12.57, wpb=6899, bsz=263.2, num_updates=32000, lr=0.000353553, gnorm=0.302, loss_scale=64, train_wall=8, gb_free=22, wall=2672
2023-08-21 15:12:18 | INFO | train_inner | epoch 026:    479 / 1265 loss=2.946, nll_loss=1.306, ppl=2.47, wps=90256.9, ups=13.1, wpb=6890.9, bsz=257.4, num_updates=32100, lr=0.000353002, gnorm=0.306, loss_scale=64, train_wall=7, gb_free=21.7, wall=2680
2023-08-21 15:12:26 | INFO | train_inner | epoch 026:    579 / 1265 loss=2.946, nll_loss=1.306, ppl=2.47, wps=89132.6, ups=12.93, wpb=6895.9, bsz=240.2, num_updates=32200, lr=0.000352454, gnorm=0.305, loss_scale=64, train_wall=7, gb_free=21.7, wall=2687
2023-08-21 15:12:33 | INFO | train_inner | epoch 026:    679 / 1265 loss=2.974, nll_loss=1.337, ppl=2.53, wps=87896.3, ups=12.93, wpb=6798.3, bsz=226.1, num_updates=32300, lr=0.000351908, gnorm=0.315, loss_scale=64, train_wall=7, gb_free=21.8, wall=2695
2023-08-21 15:12:41 | INFO | train_inner | epoch 026:    779 / 1265 loss=2.959, nll_loss=1.322, ppl=2.5, wps=89010.1, ups=12.95, wpb=6872.4, bsz=260.8, num_updates=32400, lr=0.000351364, gnorm=0.315, loss_scale=64, train_wall=7, gb_free=21.7, wall=2703
2023-08-21 15:12:49 | INFO | train_inner | epoch 026:    879 / 1265 loss=2.976, nll_loss=1.34, ppl=2.53, wps=91199.1, ups=13.33, wpb=6840.8, bsz=242.9, num_updates=32500, lr=0.000350823, gnorm=0.311, loss_scale=64, train_wall=7, gb_free=22, wall=2710
2023-08-21 15:12:56 | INFO | train_inner | epoch 026:    979 / 1265 loss=2.973, nll_loss=1.338, ppl=2.53, wps=89530.1, ups=13.03, wpb=6871.7, bsz=240.8, num_updates=32600, lr=0.000350285, gnorm=0.309, loss_scale=64, train_wall=7, gb_free=21.8, wall=2718
2023-08-21 15:13:04 | INFO | train_inner | epoch 026:   1079 / 1265 loss=2.967, nll_loss=1.331, ppl=2.52, wps=86637.9, ups=12.83, wpb=6755, bsz=238.6, num_updates=32700, lr=0.000349749, gnorm=0.314, loss_scale=64, train_wall=8, gb_free=21.9, wall=2726
2023-08-21 15:13:12 | INFO | train_inner | epoch 026:   1179 / 1265 loss=2.964, nll_loss=1.329, ppl=2.51, wps=90174.5, ups=12.94, wpb=6967.1, bsz=265.5, num_updates=32800, lr=0.000349215, gnorm=0.304, loss_scale=64, train_wall=7, gb_free=21.7, wall=2734
2023-08-21 15:13:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 15:13:21 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.726 | nll_loss 2.141 | ppl 4.41 | wps 198128 | wpb 3858.1 | bsz 131.6 | num_updates 32886 | best_loss 3.698
2023-08-21 15:13:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 32886 updates
2023-08-21 15:13:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint26.pt
2023-08-21 15:13:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint26.pt
2023-08-21 15:13:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint26.pt (epoch 26 @ 32886 updates, score 3.726) (writing took 2.4361970490426756 seconds)
2023-08-21 15:13:23 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-21 15:13:23 | INFO | train | epoch 026 | loss 2.951 | nll_loss 1.313 | ppl 2.48 | wps 82919.1 | ups 12.05 | wpb 6881.3 | bsz 251 | num_updates 32886 | lr 0.000348758 | gnorm 0.307 | loss_scale 64 | train_wall 95 | gb_free 21.7 | wall 2745
2023-08-21 15:13:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 15:13:23 | INFO | fairseq.trainer | begin training epoch 27
2023-08-21 15:13:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 15:13:27 | INFO | train_inner | epoch 027:     14 / 1265 loss=2.954, nll_loss=1.318, ppl=2.49, wps=45904.2, ups=6.7, wpb=6854.7, bsz=247.8, num_updates=32900, lr=0.000348684, gnorm=0.308, loss_scale=64, train_wall=8, gb_free=21.8, wall=2749
2023-08-21 15:13:34 | INFO | train_inner | epoch 027:    114 / 1265 loss=2.905, nll_loss=1.256, ppl=2.39, wps=88805.3, ups=13.06, wpb=6800.3, bsz=243.9, num_updates=33000, lr=0.000348155, gnorm=0.304, loss_scale=64, train_wall=7, gb_free=21.7, wall=2756
2023-08-21 15:13:42 | INFO | train_inner | epoch 027:    214 / 1265 loss=2.922, nll_loss=1.276, ppl=2.42, wps=86446, ups=12.6, wpb=6858.7, bsz=249.1, num_updates=33100, lr=0.000347629, gnorm=0.301, loss_scale=64, train_wall=8, gb_free=21.7, wall=2764
2023-08-21 15:13:50 | INFO | train_inner | epoch 027:    314 / 1265 loss=2.919, nll_loss=1.273, ppl=2.42, wps=87198.9, ups=12.72, wpb=6854.3, bsz=240.3, num_updates=33200, lr=0.000347105, gnorm=0.307, loss_scale=64, train_wall=8, gb_free=21.7, wall=2772
2023-08-21 15:13:58 | INFO | train_inner | epoch 027:    414 / 1265 loss=2.917, nll_loss=1.273, ppl=2.42, wps=88515.9, ups=12.78, wpb=6927.2, bsz=258.9, num_updates=33300, lr=0.000346583, gnorm=0.302, loss_scale=64, train_wall=8, gb_free=21.8, wall=2780
2023-08-21 15:14:06 | INFO | train_inner | epoch 027:    514 / 1265 loss=2.941, nll_loss=1.302, ppl=2.47, wps=90128.1, ups=12.96, wpb=6951.8, bsz=283.3, num_updates=33400, lr=0.000346064, gnorm=0.306, loss_scale=64, train_wall=7, gb_free=21.8, wall=2788
2023-08-21 15:14:13 | INFO | train_inner | epoch 027:    614 / 1265 loss=2.94, nll_loss=1.298, ppl=2.46, wps=88799.7, ups=13.01, wpb=6823.9, bsz=246, num_updates=33500, lr=0.000345547, gnorm=0.308, loss_scale=64, train_wall=7, gb_free=21.8, wall=2795
2023-08-21 15:14:21 | INFO | train_inner | epoch 027:    714 / 1265 loss=2.912, nll_loss=1.268, ppl=2.41, wps=92662.6, ups=13.26, wpb=6990.2, bsz=263.6, num_updates=33600, lr=0.000345033, gnorm=0.299, loss_scale=64, train_wall=7, gb_free=22.1, wall=2803
2023-08-21 15:14:29 | INFO | train_inner | epoch 027:    814 / 1265 loss=2.924, nll_loss=1.283, ppl=2.43, wps=90383.8, ups=12.94, wpb=6986.3, bsz=266.8, num_updates=33700, lr=0.00034452, gnorm=0.299, loss_scale=64, train_wall=7, gb_free=21.7, wall=2810
2023-08-21 15:14:36 | INFO | train_inner | epoch 027:    914 / 1265 loss=2.942, nll_loss=1.302, ppl=2.47, wps=91913.1, ups=13.32, wpb=6899, bsz=236.2, num_updates=33800, lr=0.00034401, gnorm=0.307, loss_scale=64, train_wall=7, gb_free=21.6, wall=2818
2023-08-21 15:14:44 | INFO | train_inner | epoch 027:   1014 / 1265 loss=2.97, nll_loss=1.334, ppl=2.52, wps=88641.9, ups=13, wpb=6820.9, bsz=251.5, num_updates=33900, lr=0.000343503, gnorm=0.315, loss_scale=64, train_wall=7, gb_free=22.1, wall=2826
2023-08-21 15:14:52 | INFO | train_inner | epoch 027:   1114 / 1265 loss=2.955, nll_loss=1.317, ppl=2.49, wps=86379.6, ups=12.48, wpb=6919.8, bsz=246.7, num_updates=34000, lr=0.000342997, gnorm=0.308, loss_scale=64, train_wall=8, gb_free=21.8, wall=2834
2023-08-21 15:15:00 | INFO | train_inner | epoch 027:   1214 / 1265 loss=2.985, nll_loss=1.35, ppl=2.55, wps=86836.1, ups=12.67, wpb=6853.6, bsz=228.3, num_updates=34100, lr=0.000342494, gnorm=0.315, loss_scale=64, train_wall=8, gb_free=21.9, wall=2842
2023-08-21 15:15:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 15:15:06 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.732 | nll_loss 2.145 | ppl 4.42 | wps 168236 | wpb 3858.1 | bsz 131.6 | num_updates 34151 | best_loss 3.698
2023-08-21 15:15:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 34151 updates
2023-08-21 15:15:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint27.pt
2023-08-21 15:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint27.pt
2023-08-21 15:15:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint27.pt (epoch 27 @ 34151 updates, score 3.732) (writing took 1.7101668859831989 seconds)
2023-08-21 15:15:08 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-21 15:15:08 | INFO | train | epoch 027 | loss 2.937 | nll_loss 1.295 | ppl 2.45 | wps 83178.9 | ups 12.09 | wpb 6881.3 | bsz 251 | num_updates 34151 | lr 0.000342238 | gnorm 0.306 | loss_scale 64 | train_wall 95 | gb_free 21.8 | wall 2850
2023-08-21 15:15:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1265
2023-08-21 15:15:08 | INFO | fairseq.trainer | begin training epoch 28
2023-08-21 15:15:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 15:15:14 | INFO | train_inner | epoch 028:     49 / 1265 loss=2.922, nll_loss=1.278, ppl=2.43, wps=47573.4, ups=7, wpb=6800.7, bsz=258.2, num_updates=34200, lr=0.000341993, gnorm=0.305, loss_scale=64, train_wall=8, gb_free=21.7, wall=2856
2023-08-21 15:15:22 | INFO | train_inner | epoch 028:    149 / 1265 loss=2.877, nll_loss=1.226, ppl=2.34, wps=85783.3, ups=12.27, wpb=6988.5, bsz=250.2, num_updates=34300, lr=0.000341494, gnorm=0.299, loss_scale=64, train_wall=8, gb_free=22, wall=2864
2023-08-21 15:15:30 | INFO | train_inner | epoch 028:    249 / 1265 loss=2.908, nll_loss=1.261, ppl=2.4, wps=87540.9, ups=12.66, wpb=6914.1, bsz=262.1, num_updates=34400, lr=0.000340997, gnorm=0.303, loss_scale=64, train_wall=8, gb_free=21.7, wall=2872
2023-08-21 15:15:38 | INFO | train_inner | epoch 028:    349 / 1265 loss=2.894, nll_loss=1.245, ppl=2.37, wps=85866.2, ups=12.63, wpb=6797.9, bsz=258.2, num_updates=34500, lr=0.000340503, gnorm=0.307, loss_scale=64, train_wall=8, gb_free=21.8, wall=2880
2023-08-21 15:15:46 | INFO | train_inner | epoch 028:    449 / 1265 loss=2.908, nll_loss=1.262, ppl=2.4, wps=91220.9, ups=13.2, wpb=6913.1, bsz=252.9, num_updates=34600, lr=0.00034001, gnorm=0.306, loss_scale=64, train_wall=7, gb_free=21.7, wall=2887
2023-08-21 15:15:53 | INFO | train_inner | epoch 028:    549 / 1265 loss=2.916, nll_loss=1.27, ppl=2.41, wps=92026.2, ups=13.36, wpb=6889.4, bsz=235.7, num_updates=34700, lr=0.00033952, gnorm=0.308, loss_scale=64, train_wall=7, gb_free=21.8, wall=2895
2023-08-21 15:16:01 | INFO | train_inner | epoch 028:    649 / 1265 loss=2.914, nll_loss=1.269, ppl=2.41, wps=88674.3, ups=12.88, wpb=6882.9, bsz=253.8, num_updates=34800, lr=0.000339032, gnorm=0.305, loss_scale=64, train_wall=8, gb_free=21.8, wall=2903
2023-08-21 15:16:09 | INFO | train_inner | epoch 028:    749 / 1265 loss=2.947, nll_loss=1.306, ppl=2.47, wps=87996.5, ups=12.93, wpb=6803.4, bsz=251.5, num_updates=34900, lr=0.000338546, gnorm=0.315, loss_scale=64, train_wall=8, gb_free=21.9, wall=2910
2023-08-21 15:16:16 | INFO | train_inner | epoch 028:    849 / 1265 loss=2.941, nll_loss=1.302, ppl=2.47, wps=92617.1, ups=13.22, wpb=7008.3, bsz=259.8, num_updates=35000, lr=0.000338062, gnorm=0.306, loss_scale=64, train_wall=7, gb_free=21.9, wall=2918
2023-08-21 15:16:24 | INFO | train_inner | epoch 028:    949 / 1265 loss=2.946, nll_loss=1.306, ppl=2.47, wps=90336.1, ups=13.22, wpb=6835.2, bsz=245.4, num_updates=35100, lr=0.00033758, gnorm=0.311, loss_scale=64, train_wall=7, gb_free=21.7, wall=2926
2023-08-21 15:16:31 | INFO | train_inner | epoch 028:   1049 / 1265 loss=2.94, nll_loss=1.3, ppl=2.46, wps=90597.3, ups=13.17, wpb=6880.9, bsz=252.7, num_updates=35200, lr=0.0003371, gnorm=0.312, loss_scale=64, train_wall=7, gb_free=21.7, wall=2933
2023-08-21 15:16:39 | INFO | train_inner | epoch 028:   1149 / 1265 loss=2.943, nll_loss=1.303, ppl=2.47, wps=90161.3, ups=13.01, wpb=6929.6, bsz=243.3, num_updates=35300, lr=0.000336622, gnorm=0.31, loss_scale=64, train_wall=7, gb_free=21.7, wall=2941
2023-08-21 15:16:47 | INFO | train_inner | epoch 028:   1249 / 1265 loss=2.97, nll_loss=1.334, ppl=2.52, wps=86312.4, ups=12.67, wpb=6813.7, bsz=242.3, num_updates=35400, lr=0.000336146, gnorm=0.32, loss_scale=64, train_wall=8, gb_free=21.7, wall=2949
2023-08-21 15:16:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-08-21 15:16:50 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.734 | nll_loss 2.147 | ppl 4.43 | wps 140978 | wpb 3858.1 | bsz 131.6 | num_updates 35416 | best_loss 3.698
2023-08-21 15:16:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 35416 updates
2023-08-21 15:16:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint28.pt
2023-08-21 15:16:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enes-baseline/checkpoint28.pt
2023-08-21 15:16:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/mustc/enes-baseline/checkpoint28.pt (epoch 28 @ 35416 updates, score 3.734) (writing took 2.2142599229700863 seconds)
2023-08-21 15:16:53 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-21 15:16:53 | INFO | train | epoch 028 | loss 2.923 | nll_loss 1.279 | ppl 2.43 | wps 83181.1 | ups 12.09 | wpb 6881.3 | bsz 251 | num_updates 35416 | lr 0.00033607 | gnorm 0.308 | loss_scale 64 | train_wall 95 | gb_free 21.8 | wall 2955
2023-08-21 15:16:53 | INFO | fairseq_cli.train | done training in 2954.4 seconds
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/queues.py", line 111, in get
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 112 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
