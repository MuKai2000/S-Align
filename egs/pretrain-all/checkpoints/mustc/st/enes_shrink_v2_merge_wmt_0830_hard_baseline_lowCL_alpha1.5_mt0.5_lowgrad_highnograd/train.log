2023-08-30 18:27:18 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:10486
2023-08-30 18:27:18 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:10486
2023-08-30 18:27:18 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:10486
2023-08-30 18:27:18 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:10486
2023-08-30 18:27:18 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:10486
2023-08-30 18:27:18 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:10486
2023-08-30 18:27:18 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:10486
2023-08-30 18:27:18 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:10486
2023-08-30 18:27:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-30 18:27:18 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 18:27:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 18:27:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 18:27:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 18:27:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 18:27:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 18:27:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 18:27:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-30 18:27:19 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 18:27:19 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-30 18:27:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10486', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-30 18:27:23 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-30 18:27:23 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-30 18:27:23 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-30 18:27:23 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-30 18:27:23 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
2023-08-30 18:27:27 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-30 18:27:27 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enes_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-30 18:27:27 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-30 18:27:29 | INFO | root | load pretrained hubert
2023-08-30 18:27:36 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
2023-08-30 18:27:40 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt
2023-08-30 18:27:46 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt
2023-08-30 18:27:46 | INFO | root | share the sematic adapter and textual encoder
2023-08-30 18:27:46 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-30 18:27:46 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-30 18:27:46 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-30 18:27:46 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-30 18:27:46 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-30 18:27:46 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-30 18:27:46 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-30 18:27:46 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 18:27:46 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 18:27:47 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1312, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-30 18:28:02 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-30 18:28:02 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-30 18:28:02 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-30 18:28:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-30 18:28:02 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 18:28:02 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 18:28:02 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 18:28:02 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 18:28:02 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 18:28:02 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 18:28:02 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 18:28:02 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 18:28:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-30 18:28:02 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-30 18:28:02 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-30 18:28:02 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_last.pt
2023-08-30 18:28:02 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_last.pt
2023-08-30 18:28:02 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-30 18:28:02 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-30 18:28:02 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 18:28:02 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 18:28:04 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=260049, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-30 18:28:07 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=260049, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-30 18:28:54 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-30 18:28:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 18:28:54 | INFO | fairseq.trainer | begin training epoch 1
2023-08-30 18:28:54 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
2023-08-30 18:29:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
True False
None None None
2023-08-30 18:29:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
2023-08-30 18:30:04 | INFO | train_inner | epoch 001:    102 / 1826 loss=20.952, trans_loss=5.721, nll_loss=4.562, w2v_ctc_loss=23.803, task_loss=0, contrastive_loss=3.038, total=3940, n_correct=64.09, ppl=23.63, accuracy=1.627, wps=20736.7, ups=1.75, wpb=11837.1, bsz=400.3, num_updates=100, lr=4.098e-06, gnorm=3.737, clip=0, loss_scale=32, train_wall=62, gb_free=19.1, wall=122
2023-08-30 18:31:01 | INFO | train_inner | epoch 001:    202 / 1826 loss=16.418, trans_loss=5.712, nll_loss=4.576, w2v_ctc_loss=16.626, task_loss=0, contrastive_loss=3.213, total=4000.63, n_correct=69.65, ppl=23.86, accuracy=1.741, wps=21283.3, ups=1.77, wpb=12045.3, bsz=454.7, num_updates=200, lr=8.096e-06, gnorm=8.545, clip=32, loss_scale=32, train_wall=56, gb_free=19.6, wall=178
2023-08-30 18:31:58 | INFO | train_inner | epoch 001:    302 / 1826 loss=10.061, trans_loss=5.61, nll_loss=4.474, w2v_ctc_loss=6.956, task_loss=0, contrastive_loss=3.273, total=3981.48, n_correct=81.57, ppl=22.22, accuracy=2.049, wps=20888.9, ups=1.75, wpb=11963.3, bsz=445.6, num_updates=300, lr=1.2094e-05, gnorm=1.408, clip=0, loss_scale=32, train_wall=57, gb_free=18.6, wall=236
2023-08-30 18:32:55 | INFO | train_inner | epoch 001:    402 / 1826 loss=9.551, trans_loss=5.562, nll_loss=4.439, w2v_ctc_loss=6.249, task_loss=0, contrastive_loss=3.154, total=4003.3, n_correct=76.88, ppl=21.69, accuracy=1.92, wps=21137, ups=1.75, wpb=12045.6, bsz=429, num_updates=400, lr=1.6092e-05, gnorm=0.65, clip=0, loss_scale=32, train_wall=56, gb_free=18.6, wall=293
2023-08-30 18:33:52 | INFO | train_inner | epoch 001:    502 / 1826 loss=9.349, trans_loss=5.589, nll_loss=4.478, w2v_ctc_loss=5.914, task_loss=0, contrastive_loss=3.21, total=3993.19, n_correct=68.91, ppl=22.29, accuracy=1.726, wps=21211.4, ups=1.77, wpb=12009.5, bsz=443.2, num_updates=500, lr=2.009e-05, gnorm=0.48, clip=0, loss_scale=32, train_wall=56, gb_free=18.8, wall=349
2023-08-30 18:34:48 | INFO | train_inner | epoch 001:    602 / 1826 loss=9.095, trans_loss=5.565, nll_loss=4.459, w2v_ctc_loss=5.662, task_loss=0, contrastive_loss=3.116, total=3953.46, n_correct=85.94, ppl=22, accuracy=2.174, wps=21134, ups=1.78, wpb=11892.1, bsz=427.3, num_updates=600, lr=2.4088e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=56, gb_free=18.5, wall=406
2023-08-30 18:35:44 | INFO | train_inner | epoch 001:    702 / 1826 loss=8.773, trans_loss=5.56, nll_loss=4.453, w2v_ctc_loss=5.2, task_loss=0, contrastive_loss=3.094, total=3953.4, n_correct=94.34, ppl=21.9, accuracy=2.386, wps=21181.2, ups=1.78, wpb=11878.1, bsz=430.5, num_updates=700, lr=2.8086e-05, gnorm=0.658, clip=0, loss_scale=32, train_wall=56, gb_free=19.6, wall=462
2023-08-30 18:36:40 | INFO | train_inner | epoch 001:    802 / 1826 loss=8.497, trans_loss=5.546, nll_loss=4.438, w2v_ctc_loss=4.827, task_loss=0, contrastive_loss=3.035, total=3966.39, n_correct=95.01, ppl=21.68, accuracy=2.395, wps=21196.7, ups=1.78, wpb=11929.6, bsz=425.4, num_updates=800, lr=3.2084e-05, gnorm=0.73, clip=0, loss_scale=32, train_wall=56, gb_free=19.4, wall=518
2023-08-30 18:37:38 | INFO | train_inner | epoch 001:    902 / 1826 loss=8.318, trans_loss=5.58, nll_loss=4.471, w2v_ctc_loss=4.534, task_loss=0, contrastive_loss=3.048, total=4012.72, n_correct=76.76, ppl=22.17, accuracy=1.913, wps=20962.6, ups=1.74, wpb=12075, bsz=444.3, num_updates=900, lr=3.6082e-05, gnorm=0.904, clip=0, loss_scale=32, train_wall=57, gb_free=18.7, wall=576
2023-08-30 18:38:34 | INFO | train_inner | epoch 001:   1002 / 1826 loss=8.157, trans_loss=5.619, nll_loss=4.515, w2v_ctc_loss=4.393, task_loss=0, contrastive_loss=2.918, total=3976.3, n_correct=72.09, ppl=22.86, accuracy=1.813, wps=21308.5, ups=1.78, wpb=11963.4, bsz=446.5, num_updates=1000, lr=4.008e-05, gnorm=1.081, clip=0, loss_scale=32, train_wall=56, gb_free=19.3, wall=632
2023-08-30 18:39:31 | INFO | train_inner | epoch 001:   1102 / 1826 loss=7.941, trans_loss=5.605, nll_loss=4.503, w2v_ctc_loss=4.286, task_loss=0, contrastive_loss=2.76, total=3948.19, n_correct=72.2, ppl=22.68, accuracy=1.829, wps=21004.8, ups=1.77, wpb=11876.9, bsz=420.8, num_updates=1100, lr=4.4078e-05, gnorm=1.265, clip=0, loss_scale=32, train_wall=56, gb_free=19.6, wall=688
2023-08-30 18:40:27 | INFO | train_inner | epoch 001:   1202 / 1826 loss=7.775, trans_loss=5.604, nll_loss=4.505, w2v_ctc_loss=4.164, task_loss=0, contrastive_loss=2.597, total=3918.88, n_correct=71.53, ppl=22.71, accuracy=1.825, wps=20950.9, ups=1.78, wpb=11787.8, bsz=403.7, num_updates=1200, lr=4.8076e-05, gnorm=1.31, clip=0, loss_scale=32, train_wall=56, gb_free=19.1, wall=745
2023-08-30 18:41:24 | INFO | train_inner | epoch 001:   1302 / 1826 loss=7.667, trans_loss=5.59, nll_loss=4.49, w2v_ctc_loss=4.055, task_loss=0, contrastive_loss=2.67, total=3911.26, n_correct=71.52, ppl=22.48, accuracy=1.829, wps=20814.3, ups=1.77, wpb=11772.1, bsz=417, num_updates=1300, lr=5.2074e-05, gnorm=1.306, clip=0, loss_scale=32, train_wall=56, gb_free=18.8, wall=801
2023-08-30 18:42:19 | INFO | train_inner | epoch 001:   1402 / 1826 loss=7.572, trans_loss=5.603, nll_loss=4.505, w2v_ctc_loss=3.958, task_loss=0, contrastive_loss=2.55, total=3936.13, n_correct=73.97, ppl=22.7, accuracy=1.879, wps=21222.2, ups=1.79, wpb=11833, bsz=416.9, num_updates=1400, lr=5.6072e-05, gnorm=1.423, clip=0, loss_scale=32, train_wall=55, gb_free=18.7, wall=857
2023-08-30 18:43:17 | INFO | train_inner | epoch 001:   1502 / 1826 loss=7.476, trans_loss=5.603, nll_loss=4.505, w2v_ctc_loss=3.85, task_loss=0, contrastive_loss=2.567, total=3990.21, n_correct=76.23, ppl=22.71, accuracy=1.91, wps=20820.4, ups=1.74, wpb=11990.9, bsz=423.7, num_updates=1500, lr=6.007e-05, gnorm=1.404, clip=0, loss_scale=32, train_wall=57, gb_free=19.6, wall=915
2023-08-30 18:44:13 | INFO | train_inner | epoch 001:   1602 / 1826 loss=7.356, trans_loss=5.584, nll_loss=4.486, w2v_ctc_loss=3.78, task_loss=0, contrastive_loss=2.445, total=3876.5, n_correct=74.54, ppl=22.41, accuracy=1.923, wps=20950.8, ups=1.8, wpb=11665.9, bsz=410.3, num_updates=1600, lr=6.4068e-05, gnorm=1.344, clip=0, loss_scale=32, train_wall=55, gb_free=18.9, wall=970
2023-08-30 18:45:09 | INFO | train_inner | epoch 001:   1702 / 1826 loss=7.304, trans_loss=5.595, nll_loss=4.499, w2v_ctc_loss=3.693, task_loss=0, contrastive_loss=2.509, total=3948.37, n_correct=75.34, ppl=22.62, accuracy=1.908, wps=21258.3, ups=1.79, wpb=11883.6, bsz=426.7, num_updates=1700, lr=6.8066e-05, gnorm=1.434, clip=0, loss_scale=32, train_wall=55, gb_free=19.3, wall=1026
2023-08-30 18:46:04 | INFO | train_inner | epoch 001:   1802 / 1826 loss=7.203, trans_loss=5.586, nll_loss=4.488, w2v_ctc_loss=3.622, task_loss=0, contrastive_loss=2.419, total=3946.23, n_correct=77.7, ppl=22.44, accuracy=1.969, wps=21277.3, ups=1.79, wpb=11877.4, bsz=428.5, num_updates=1800, lr=7.2064e-05, gnorm=1.331, clip=0, loss_scale=32, train_wall=55, gb_free=19.6, wall=1082
2023-08-30 18:46:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 3 terminated with the following error:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 330, in train
    valid_losses, should_stop = validate_and_save(
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 421, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 458, in validate
    itr = trainer.get_valid_iterator(subset).next_epoch_itr(
  File "/mnt/zhangyh/fairseq-AT/fairseq/trainer.py", line 755, in get_valid_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/iterators.py", line 372, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/iterators.py", line 372, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/round_robin_zip_datasets.py", line 56, in __getitem__
    [
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/round_robin_zip_datasets.py", line 57, in <listcomp>
    (key, dataset[self._map_index(key, index)])
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/concat_dataset.py", line 39, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/audio/triple_dataset.py", line 184, in __getitem__
    source= get_features_or_waveform(
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/audio/audio_utils.py", line 188, in get_features_or_waveform
    return get_waveform(
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/audio/audio_utils.py", line 105, in get_waveform
    waveform, sample_rate = sf.read(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/soundfile.py", line 285, in read
    with SoundFile(file, 'r', samplerate, channels,
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/soundfile.py", line 658, in __init__
    self._file = self._open(file, mode_int, closefd)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/soundfile.py", line 1216, in _open
    raise LibsndfileError(err, prefix="Error opening {0!r}: ".format(self.name))
soundfile.LibsndfileError: Error opening '/workspace/DATA/mustc-enes/dev-split/dev_ted_824_164.wav': System error.

/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 16 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-30 19:32:14 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15246
2023-08-30 19:32:14 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15246
2023-08-30 19:32:14 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15246
2023-08-30 19:32:14 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15246
2023-08-30 19:32:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-30 19:32:14 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15246
2023-08-30 19:32:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-30 19:32:14 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15246
2023-08-30 19:32:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-30 19:32:14 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15246
2023-08-30 19:32:14 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15246
2023-08-30 19:32:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-30 19:32:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-30 19:32:15 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-30 19:32:15 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-30 19:32:15 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-30 19:32:15 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 19:32:15 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-30 19:32:15 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 19:32:15 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 19:32:15 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-30 19:32:15 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-30 19:32:15 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 19:32:15 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 19:32:15 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-30 19:32:15 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-30 19:32:15 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 19:32:15 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-30 19:32:15 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 19:32:15 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-30 19:32:15 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 19:32:15 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-30 19:32:18 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15246', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-30 19:32:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-30 19:32:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-30 19:32:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-30 19:32:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-30 19:32:18 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
2023-08-30 19:32:22 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-30 19:32:22 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enes_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-30 19:32:22 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-30 19:32:23 | INFO | root | load pretrained hubert
2023-08-30 19:32:30 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
2023-08-30 19:32:33 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt
2023-08-30 19:32:39 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt
2023-08-30 19:32:39 | INFO | root | share the sematic adapter and textual encoder
2023-08-30 19:32:39 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-30 19:32:39 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-30 19:32:39 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-30 19:32:39 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-30 19:32:39 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-30 19:32:39 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-30 19:32:39 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-30 19:32:39 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 19:32:39 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 19:32:39 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1312, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-30 19:32:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-30 19:32:57 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-30 19:32:57 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-30 19:32:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-30 19:32:58 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 19:32:58 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 19:32:58 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 19:32:58 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 19:32:58 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 19:32:58 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 19:32:58 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 19:32:58 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 19:32:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-30 19:32:58 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-30 19:32:58 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-30 19:32:58 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_last.pt
2023-08-30 19:32:58 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_last.pt
2023-08-30 19:32:58 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-30 19:32:58 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-30 19:32:58 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 19:32:58 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 19:33:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=260049, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-30 19:33:02 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=260049, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-30 19:33:49 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-30 19:33:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 19:33:49 | INFO | fairseq.trainer | begin training epoch 1
2023-08-30 19:33:49 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
2023-08-30 19:34:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
True False
None None None
2023-08-30 19:34:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
2023-08-30 19:35:00 | INFO | train_inner | epoch 001:    102 / 1826 loss=20.952, trans_loss=5.721, nll_loss=4.562, w2v_ctc_loss=23.803, task_loss=0, contrastive_loss=3.038, total=3940, n_correct=64.22, ppl=23.63, accuracy=1.63, wps=20759, ups=1.75, wpb=11837.1, bsz=400.3, num_updates=100, lr=4.098e-06, gnorm=3.737, clip=0, loss_scale=32, train_wall=64, gb_free=19.1, wall=122
2023-08-30 19:35:56 | INFO | train_inner | epoch 001:    202 / 1826 loss=16.418, trans_loss=5.712, nll_loss=4.576, w2v_ctc_loss=16.626, task_loss=0, contrastive_loss=3.213, total=4000.63, n_correct=69.81, ppl=23.86, accuracy=1.745, wps=21351.3, ups=1.77, wpb=12045.3, bsz=454.7, num_updates=200, lr=8.096e-06, gnorm=8.545, clip=32, loss_scale=32, train_wall=56, gb_free=19.6, wall=179
2023-08-30 19:36:53 | INFO | train_inner | epoch 001:    302 / 1826 loss=10.061, trans_loss=5.61, nll_loss=4.474, w2v_ctc_loss=6.956, task_loss=0, contrastive_loss=3.273, total=3981.48, n_correct=81.53, ppl=22.22, accuracy=2.048, wps=21121.6, ups=1.77, wpb=11963.3, bsz=445.6, num_updates=300, lr=1.2094e-05, gnorm=1.408, clip=0, loss_scale=32, train_wall=56, gb_free=18.6, wall=235
2023-08-30 19:37:50 | INFO | train_inner | epoch 001:    402 / 1826 loss=9.551, trans_loss=5.562, nll_loss=4.439, w2v_ctc_loss=6.249, task_loss=0, contrastive_loss=3.154, total=4003.3, n_correct=77.04, ppl=21.69, accuracy=1.924, wps=21003.9, ups=1.74, wpb=12045.6, bsz=429, num_updates=400, lr=1.6092e-05, gnorm=0.65, clip=0, loss_scale=32, train_wall=57, gb_free=18.6, wall=293
2023-08-30 19:38:47 | INFO | train_inner | epoch 001:    502 / 1826 loss=9.349, trans_loss=5.589, nll_loss=4.478, w2v_ctc_loss=5.914, task_loss=0, contrastive_loss=3.21, total=3993.19, n_correct=68.96, ppl=22.29, accuracy=1.727, wps=21230.4, ups=1.77, wpb=12009.5, bsz=443.2, num_updates=500, lr=2.009e-05, gnorm=0.48, clip=0, loss_scale=32, train_wall=56, gb_free=18.8, wall=349
2023-08-30 19:39:43 | INFO | train_inner | epoch 001:    602 / 1826 loss=9.095, trans_loss=5.565, nll_loss=4.46, w2v_ctc_loss=5.662, task_loss=0, contrastive_loss=3.116, total=3953.46, n_correct=85.85, ppl=22, accuracy=2.172, wps=21287.8, ups=1.79, wpb=11892.1, bsz=427.3, num_updates=600, lr=2.4088e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=55, gb_free=18.5, wall=405
2023-08-30 19:40:39 | INFO | train_inner | epoch 001:    702 / 1826 loss=8.773, trans_loss=5.56, nll_loss=4.453, w2v_ctc_loss=5.2, task_loss=0, contrastive_loss=3.094, total=3953.4, n_correct=93.7, ppl=21.9, accuracy=2.37, wps=21074.7, ups=1.77, wpb=11878.1, bsz=430.5, num_updates=700, lr=2.8086e-05, gnorm=0.658, clip=0, loss_scale=32, train_wall=56, gb_free=19.6, wall=462
2023-08-30 19:41:36 | INFO | train_inner | epoch 001:    802 / 1826 loss=8.497, trans_loss=5.546, nll_loss=4.439, w2v_ctc_loss=4.827, task_loss=0, contrastive_loss=3.035, total=3966.39, n_correct=95.29, ppl=21.68, accuracy=2.402, wps=21169.8, ups=1.78, wpb=11929.6, bsz=425.4, num_updates=800, lr=3.2084e-05, gnorm=0.729, clip=0, loss_scale=32, train_wall=56, gb_free=19.4, wall=518
2023-08-30 19:42:32 | INFO | train_inner | epoch 001:    902 / 1826 loss=8.318, trans_loss=5.581, nll_loss=4.471, w2v_ctc_loss=4.534, task_loss=0, contrastive_loss=3.048, total=4012.72, n_correct=76.89, ppl=22.18, accuracy=1.916, wps=21401.1, ups=1.77, wpb=12075, bsz=444.3, num_updates=900, lr=3.6082e-05, gnorm=0.904, clip=0, loss_scale=32, train_wall=56, gb_free=18.7, wall=574
2023-08-30 19:43:29 | INFO | train_inner | epoch 001:   1002 / 1826 loss=8.157, trans_loss=5.62, nll_loss=4.515, w2v_ctc_loss=4.393, task_loss=0, contrastive_loss=2.918, total=3976.3, n_correct=71.75, ppl=22.87, accuracy=1.804, wps=20995.6, ups=1.75, wpb=11963.4, bsz=446.5, num_updates=1000, lr=4.008e-05, gnorm=1.081, clip=0, loss_scale=32, train_wall=56, gb_free=19.3, wall=631
2023-08-30 19:44:25 | INFO | train_inner | epoch 001:   1102 / 1826 loss=7.941, trans_loss=5.606, nll_loss=4.504, w2v_ctc_loss=4.286, task_loss=0, contrastive_loss=2.76, total=3948.19, n_correct=71.89, ppl=22.69, accuracy=1.821, wps=21055.1, ups=1.77, wpb=11876.9, bsz=420.8, num_updates=1100, lr=4.4078e-05, gnorm=1.265, clip=0, loss_scale=32, train_wall=56, gb_free=19.6, wall=688
2023-08-30 19:45:21 | INFO | train_inner | epoch 001:   1202 / 1826 loss=7.776, trans_loss=5.605, nll_loss=4.506, w2v_ctc_loss=4.164, task_loss=0, contrastive_loss=2.597, total=3918.88, n_correct=71.83, ppl=22.72, accuracy=1.833, wps=21119.1, ups=1.79, wpb=11787.8, bsz=403.7, num_updates=1200, lr=4.8076e-05, gnorm=1.31, clip=0, loss_scale=32, train_wall=55, gb_free=19.1, wall=744
2023-08-30 19:46:18 | INFO | train_inner | epoch 001:   1302 / 1826 loss=7.667, trans_loss=5.591, nll_loss=4.491, w2v_ctc_loss=4.055, task_loss=0, contrastive_loss=2.67, total=3911.26, n_correct=71.26, ppl=22.49, accuracy=1.822, wps=20886.1, ups=1.77, wpb=11772.1, bsz=417, num_updates=1300, lr=5.2074e-05, gnorm=1.306, clip=0, loss_scale=32, train_wall=56, gb_free=18.8, wall=800
2023-08-30 19:47:14 | INFO | train_inner | epoch 001:   1402 / 1826 loss=7.573, trans_loss=5.603, nll_loss=4.505, w2v_ctc_loss=3.958, task_loss=0, contrastive_loss=2.55, total=3936.13, n_correct=73.56, ppl=22.71, accuracy=1.869, wps=21164.6, ups=1.79, wpb=11833, bsz=416.9, num_updates=1400, lr=5.6072e-05, gnorm=1.423, clip=0, loss_scale=32, train_wall=55, gb_free=18.7, wall=856
2023-08-30 19:48:10 | INFO | train_inner | epoch 001:   1502 / 1826 loss=7.476, trans_loss=5.603, nll_loss=4.505, w2v_ctc_loss=3.85, task_loss=0, contrastive_loss=2.567, total=3990.21, n_correct=76.05, ppl=22.71, accuracy=1.906, wps=21111.3, ups=1.76, wpb=11990.9, bsz=423.7, num_updates=1500, lr=6.007e-05, gnorm=1.404, clip=0, loss_scale=32, train_wall=56, gb_free=19.6, wall=913
2023-08-30 19:49:07 | INFO | train_inner | epoch 001:   1602 / 1826 loss=7.357, trans_loss=5.584, nll_loss=4.487, w2v_ctc_loss=3.78, task_loss=0, contrastive_loss=2.445, total=3876.5, n_correct=74.86, ppl=22.42, accuracy=1.931, wps=20722.4, ups=1.78, wpb=11665.9, bsz=410.3, num_updates=1600, lr=6.4068e-05, gnorm=1.344, clip=0, loss_scale=32, train_wall=56, gb_free=18.9, wall=969
2023-08-30 19:50:02 | INFO | train_inner | epoch 001:   1702 / 1826 loss=7.304, trans_loss=5.595, nll_loss=4.5, w2v_ctc_loss=3.693, task_loss=0, contrastive_loss=2.509, total=3948.37, n_correct=75.6, ppl=22.62, accuracy=1.915, wps=21423, ups=1.8, wpb=11883.6, bsz=426.7, num_updates=1700, lr=6.8066e-05, gnorm=1.433, clip=0, loss_scale=32, train_wall=55, gb_free=19.3, wall=1024
2023-08-30 19:50:58 | INFO | train_inner | epoch 001:   1802 / 1826 loss=7.203, trans_loss=5.586, nll_loss=4.488, w2v_ctc_loss=3.622, task_loss=0, contrastive_loss=2.419, total=3946.23, n_correct=77.95, ppl=22.44, accuracy=1.975, wps=21281.3, ups=1.79, wpb=11877.4, bsz=428.5, num_updates=1800, lr=7.2064e-05, gnorm=1.331, clip=0, loss_scale=32, train_wall=55, gb_free=19.6, wall=1080
2023-08-30 19:51:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-30 19:52:00 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 11.199 | trans_loss 12.121 | nll_loss 11.607 | w2v_ctc_loss 4.766 | task_loss 0 | contrastive_loss 3.371 | total 3505.91 | n_correct 74.0909 | ppl 3119.08 | accuracy 2.113 | uer 57.512 | wer 58.219 | raw_wer 58.219 | bleu 0 | wps 920 | wpb 3505.9 | bsz 119.3 | num_updates 1824
2023-08-30 19:52:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1824 updates
2023-08-30 19:52:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 19:52:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 19:52:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 1 @ 1824 updates, score 0.0) (writing took 4.629039785999339 seconds)
2023-08-30 19:52:05 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-30 19:52:05 | INFO | train | epoch 001 | loss 9.391 | trans_loss 5.602 | nll_loss 4.492 | w2v_ctc_loss 6.39 | task_loss 0 | contrastive_loss 2.867 | total 3956.49 | n_correct 76.5707 | ppl 22.5 | accuracy 1.935 | wps 20062.2 | ups 1.69 | wpb 11900.4 | bsz 427.3 | num_updates 1824 | lr 7.30235e-05 | gnorm 1.634 | clip 1.8 | loss_scale 32 | train_wall 1025 | gb_free 19 | wall 1147
2023-08-30 19:52:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 19:52:05 | INFO | fairseq.trainer | begin training epoch 2
2023-08-30 19:52:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 19:52:55 | INFO | train_inner | epoch 002:     76 / 1826 loss=7.123, trans_loss=5.587, nll_loss=4.49, w2v_ctc_loss=3.565, task_loss=0, contrastive_loss=2.354, total=3885.17, n_correct=76.89, ppl=22.47, accuracy=1.979, wps=9989.4, ups=0.85, wpb=11691.5, bsz=421.2, num_updates=1900, lr=7.6062e-05, gnorm=1.322, clip=0, loss_scale=32, train_wall=55, gb_free=18.8, wall=1197
2023-08-30 19:53:51 | INFO | train_inner | epoch 002:    176 / 1826 loss=7.02, trans_loss=5.571, nll_loss=4.472, w2v_ctc_loss=3.496, task_loss=0, contrastive_loss=2.301, total=3939.14, n_correct=78.32, ppl=22.19, accuracy=1.988, wps=21013.2, ups=1.77, wpb=11860.5, bsz=421.1, num_updates=2000, lr=8.006e-05, gnorm=1.316, clip=0, loss_scale=32, train_wall=56, gb_free=19, wall=1254
2023-08-30 19:53:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 19:54:43 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.084 | trans_loss 12.096 | nll_loss 11.579 | w2v_ctc_loss 4.628 | task_loss 0 | contrastive_loss 3.234 | total 3505.91 | n_correct 80.9091 | ppl 3059.51 | accuracy 2.308 | uer 56.254 | wer 56.714 | raw_wer 56.714 | bleu 0 | wps 857.4 | wpb 3505.9 | bsz 119.3 | num_updates 2000 | best_bleu 0
2023-08-30 19:54:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-30 19:54:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_2_2000.pt
2023-08-30 19:54:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_2_2000.pt
2023-08-30 19:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 12.496716041998297 seconds)
2023-08-30 19:55:52 | INFO | train_inner | epoch 002:    276 / 1826 loss=6.921, trans_loss=5.568, nll_loss=4.468, w2v_ctc_loss=3.415, task_loss=0, contrastive_loss=2.306, total=3981.06, n_correct=83.83, ppl=22.13, accuracy=2.106, wps=9936.4, ups=0.83, wpb=11978, bsz=428.1, num_updates=2100, lr=8.4058e-05, gnorm=1.28, clip=0, loss_scale=64, train_wall=56, gb_free=18.7, wall=1374
2023-08-30 19:56:48 | INFO | train_inner | epoch 002:    376 / 1826 loss=6.876, trans_loss=5.576, nll_loss=4.476, w2v_ctc_loss=3.384, task_loss=0, contrastive_loss=2.263, total=3954.48, n_correct=82.17, ppl=22.25, accuracy=2.078, wps=21267.5, ups=1.79, wpb=11892.4, bsz=425, num_updates=2200, lr=8.8056e-05, gnorm=1.24, clip=0, loss_scale=64, train_wall=55, gb_free=19.6, wall=1430
2023-08-30 19:57:44 | INFO | train_inner | epoch 002:    476 / 1826 loss=6.822, trans_loss=5.571, nll_loss=4.471, w2v_ctc_loss=3.291, task_loss=0, contrastive_loss=2.333, total=3995.64, n_correct=87.23, ppl=22.18, accuracy=2.183, wps=21618.6, ups=1.8, wpb=12018.1, bsz=454.7, num_updates=2300, lr=9.2054e-05, gnorm=1.292, clip=0, loss_scale=64, train_wall=55, gb_free=18.8, wall=1486
2023-08-30 19:58:40 | INFO | train_inner | epoch 002:    576 / 1826 loss=6.736, trans_loss=5.566, nll_loss=4.465, w2v_ctc_loss=3.259, task_loss=0, contrastive_loss=2.212, total=4002.43, n_correct=87.18, ppl=22.08, accuracy=2.178, wps=21492.4, ups=1.79, wpb=12035.7, bsz=442.2, num_updates=2400, lr=9.6052e-05, gnorm=1.207, clip=0, loss_scale=64, train_wall=55, gb_free=18.8, wall=1542
2023-08-30 19:59:35 | INFO | train_inner | epoch 002:    676 / 1826 loss=6.598, trans_loss=5.536, nll_loss=4.433, w2v_ctc_loss=3.235, task_loss=0, contrastive_loss=1.966, total=3871.25, n_correct=89.91, ppl=21.6, accuracy=2.323, wps=21054.2, ups=1.81, wpb=11663.4, bsz=399.1, num_updates=2500, lr=0.00010005, gnorm=1.242, clip=0, loss_scale=64, train_wall=55, gb_free=19.2, wall=1597
2023-08-30 20:00:31 | INFO | train_inner | epoch 002:    776 / 1826 loss=6.565, trans_loss=5.535, nll_loss=4.427, w2v_ctc_loss=3.196, task_loss=0, contrastive_loss=2.046, total=3955.15, n_correct=90.14, ppl=21.51, accuracy=2.279, wps=21111.8, ups=1.77, wpb=11899.7, bsz=428.8, num_updates=2600, lr=0.000104048, gnorm=1.279, clip=0, loss_scale=64, train_wall=56, gb_free=18.7, wall=1654
2023-08-30 20:01:28 | INFO | train_inner | epoch 002:    876 / 1826 loss=6.53, trans_loss=5.53, nll_loss=4.421, w2v_ctc_loss=3.166, task_loss=0, contrastive_loss=2.048, total=3982.41, n_correct=92.79, ppl=21.42, accuracy=2.33, wps=21254.7, ups=1.77, wpb=11985.5, bsz=440.8, num_updates=2700, lr=0.000108046, gnorm=1.265, clip=0, loss_scale=64, train_wall=56, gb_free=18.8, wall=1710
2023-08-30 20:02:24 | INFO | train_inner | epoch 002:    976 / 1826 loss=6.43, trans_loss=5.519, nll_loss=4.408, w2v_ctc_loss=3.141, task_loss=0, contrastive_loss=1.963, total=3948.73, n_correct=93.31, ppl=21.23, accuracy=2.363, wps=21171.7, ups=1.78, wpb=11881.6, bsz=425.3, num_updates=2800, lr=0.000112044, gnorm=1.161, clip=0, loss_scale=64, train_wall=56, gb_free=19.3, wall=1766
2023-08-30 20:03:20 | INFO | train_inner | epoch 002:   1076 / 1826 loss=6.376, trans_loss=5.537, nll_loss=4.426, w2v_ctc_loss=3.076, task_loss=0, contrastive_loss=1.973, total=3979.72, n_correct=94.99, ppl=21.49, accuracy=2.387, wps=21415.6, ups=1.79, wpb=11956.1, bsz=440.7, num_updates=2900, lr=0.000116042, gnorm=1.158, clip=0, loss_scale=64, train_wall=55, gb_free=18.6, wall=1822
2023-08-30 20:04:15 | INFO | train_inner | epoch 002:   1176 / 1826 loss=6.247, trans_loss=5.521, nll_loss=4.408, w2v_ctc_loss=3.071, task_loss=0, contrastive_loss=1.728, total=3886.8, n_correct=96.16, ppl=21.23, accuracy=2.474, wps=21130.5, ups=1.81, wpb=11681.6, bsz=389.9, num_updates=3000, lr=0.00012004, gnorm=1.308, clip=0, loss_scale=64, train_wall=55, gb_free=19.2, wall=1877
2023-08-30 20:04:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-30 20:04:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-30 20:04:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-30 20:04:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-30 20:04:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-30 20:05:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-30 20:05:33 | INFO | train_inner | epoch 002:   1282 / 1826 loss=5.579, trans_loss=4.843, nll_loss=3.504, w2v_ctc_loss=3.019, task_loss=0, contrastive_loss=1.622, total=3936.06, n_correct=461.74, ppl=11.35, accuracy=11.731, wps=15211.5, ups=1.29, wpb=11835.9, bsz=422.4, num_updates=3100, lr=0.000124038, gnorm=7.321, clip=18, loss_scale=1, train_wall=77, gb_free=12.9, wall=1955
2023-08-30 20:06:47 | INFO | train_inner | epoch 002:   1382 / 1826 loss=4.772, trans_loss=4.261, nll_loss=2.729, w2v_ctc_loss=2.783, task_loss=0, contrastive_loss=1.449, total=3997.31, n_correct=1024.36, ppl=6.63, accuracy=25.626, wps=16280.5, ups=1.35, wpb=12018.2, bsz=444.7, num_updates=3200, lr=0.000128036, gnorm=4.2, clip=4, loss_scale=1, train_wall=73, gb_free=17, wall=2029
2023-08-30 20:08:00 | INFO | train_inner | epoch 002:   1482 / 1826 loss=4.442, trans_loss=4.155, nll_loss=2.595, w2v_ctc_loss=2.627, task_loss=0, contrastive_loss=1.337, total=4015.71, n_correct=1163.89, ppl=6.04, accuracy=28.983, wps=16373.5, ups=1.36, wpb=12074.4, bsz=452, num_updates=3300, lr=0.000132034, gnorm=2.85, clip=0, loss_scale=1, train_wall=73, gb_free=10.9, wall=2103
2023-08-30 20:09:14 | INFO | train_inner | epoch 002:   1582 / 1826 loss=4.166, trans_loss=4.115, nll_loss=2.545, w2v_ctc_loss=2.526, task_loss=0, contrastive_loss=0.987, total=4004.34, n_correct=1205.35, ppl=5.84, accuracy=30.101, wps=16391.8, ups=1.36, wpb=12049.7, bsz=431, num_updates=3400, lr=0.000136032, gnorm=2.467, clip=1, loss_scale=1, train_wall=73, gb_free=14.9, wall=2176
2023-08-30 20:10:27 | INFO | train_inner | epoch 002:   1682 / 1826 loss=3.967, trans_loss=4.099, nll_loss=2.522, w2v_ctc_loss=2.398, task_loss=0, contrastive_loss=0.873, total=3955.75, n_correct=1212.59, ppl=5.75, accuracy=30.654, wps=16353.8, ups=1.38, wpb=11892.2, bsz=427.3, num_updates=3500, lr=0.00014003, gnorm=2.232, clip=0, loss_scale=1, train_wall=72, gb_free=12.2, wall=2249
2023-08-30 20:11:40 | INFO | train_inner | epoch 002:   1782 / 1826 loss=3.819, trans_loss=4.089, nll_loss=2.509, w2v_ctc_loss=2.326, task_loss=0, contrastive_loss=0.72, total=3951.4, n_correct=1226.05, ppl=5.69, accuracy=31.028, wps=16246.1, ups=1.37, wpb=11872.7, bsz=410.3, num_updates=3600, lr=0.000144028, gnorm=2.127, clip=0, loss_scale=1, train_wall=72, gb_free=16.7, wall=2322
2023-08-30 20:12:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 20:12:50 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 6.429 | trans_loss 7.627 | nll_loss 5.645 | w2v_ctc_loss 2.828 | task_loss 0 | contrastive_loss 0.816 | total 3505.91 | n_correct 1095.64 | ppl 50.04 | accuracy 31.251 | uer 37.246 | wer 38.43 | raw_wer 38.43 | bleu 0.37 | wps 1216.1 | wpb 3505.9 | bsz 119.3 | num_updates 3644 | best_bleu 0.37
2023-08-30 20:12:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 3644 updates
2023-08-30 20:12:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 20:12:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 20:13:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 2 @ 3644 updates, score 0.37) (writing took 11.068479924000712 seconds)
2023-08-30 20:13:01 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-30 20:13:01 | INFO | train | epoch 002 | loss 5.874 | trans_loss 5.089 | nll_loss 3.834 | w2v_ctc_loss 3.028 | task_loss 0 | contrastive_loss 1.772 | total 3956.26 | n_correct 431.284 | ppl 14.26 | accuracy 10.901 | wps 17242.4 | ups 1.45 | wpb 11899.8 | bsz 427.3 | num_updates 3644 | lr 0.000145787 | gnorm 2.022 | clip 1.3 | loss_scale 1 | train_wall 1124 | gb_free 16.6 | wall 2403
2023-08-30 20:13:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 20:13:01 | INFO | fairseq.trainer | begin training epoch 3
2023-08-30 20:13:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 20:13:50 | INFO | train_inner | epoch 003:     56 / 1826 loss=3.672, trans_loss=4.067, nll_loss=2.482, w2v_ctc_loss=2.247, task_loss=0, contrastive_loss=0.573, total=3871.67, n_correct=1216.43, ppl=5.59, accuracy=31.419, wps=8959.2, ups=0.77, wpb=11643.9, bsz=402.7, num_updates=3700, lr=0.000148026, gnorm=1.891, clip=0, loss_scale=1, train_wall=72, gb_free=15.9, wall=2452
2023-08-30 20:15:02 | INFO | train_inner | epoch 003:    156 / 1826 loss=3.589, trans_loss=4.052, nll_loss=2.466, w2v_ctc_loss=2.149, task_loss=0, contrastive_loss=0.632, total=3966.96, n_correct=1254.93, ppl=5.53, accuracy=31.635, wps=16492.1, ups=1.38, wpb=11941.2, bsz=440.6, num_updates=3800, lr=0.000152024, gnorm=1.683, clip=0, loss_scale=1, train_wall=72, gb_free=15, wall=2524
2023-08-30 20:16:15 | INFO | train_inner | epoch 003:    256 / 1826 loss=3.534, trans_loss=4.053, nll_loss=2.465, w2v_ctc_loss=2.109, task_loss=0, contrastive_loss=0.644, total=3999.48, n_correct=1277.81, ppl=5.52, accuracy=31.949, wps=16477.1, ups=1.37, wpb=12025.7, bsz=439.4, num_updates=3900, lr=0.000156022, gnorm=1.704, clip=0, loss_scale=1, train_wall=72, gb_free=15.9, wall=2597
2023-08-30 20:17:28 | INFO | train_inner | epoch 003:    356 / 1826 loss=3.476, trans_loss=4.047, nll_loss=2.456, w2v_ctc_loss=2.041, task_loss=0, contrastive_loss=0.683, total=4046.76, n_correct=1301.62, ppl=5.49, accuracy=32.164, wps=16645.2, ups=1.37, wpb=12166.6, bsz=462.4, num_updates=4000, lr=0.00016002, gnorm=1.649, clip=0, loss_scale=1, train_wall=72, gb_free=12.2, wall=2670
2023-08-30 20:17:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 20:18:05 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 6.218 | trans_loss 7.564 | nll_loss 5.563 | w2v_ctc_loss 2.507 | task_loss 0 | contrastive_loss 0.62 | total 3505.91 | n_correct 1117.27 | ppl 47.26 | accuracy 31.868 | uer 33.557 | wer 35.251 | raw_wer 35.251 | bleu 0.24 | wps 1255.2 | wpb 3505.9 | bsz 119.3 | num_updates 4000 | best_bleu 0.37
2023-08-30 20:18:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-30 20:18:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_3_4000.pt
2023-08-30 20:18:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_3_4000.pt
2023-08-30 20:18:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 0.24) (writing took 6.972701024998969 seconds)
2023-08-30 20:19:25 | INFO | train_inner | epoch 003:    456 / 1826 loss=3.383, trans_loss=4.044, nll_loss=2.453, w2v_ctc_loss=2.012, task_loss=0, contrastive_loss=0.502, total=3919.43, n_correct=1258.63, ppl=5.48, accuracy=32.113, wps=10083.4, ups=0.86, wpb=11789, bsz=420, num_updates=4100, lr=0.000164018, gnorm=1.495, clip=0, loss_scale=1, train_wall=72, gb_free=17.1, wall=2787
2023-08-30 20:20:39 | INFO | train_inner | epoch 003:    556 / 1826 loss=3.365, trans_loss=4.036, nll_loss=2.446, w2v_ctc_loss=1.989, task_loss=0, contrastive_loss=0.569, total=3966.8, n_correct=1289.35, ppl=5.45, accuracy=32.504, wps=16178, ups=1.35, wpb=11942.5, bsz=439.4, num_updates=4200, lr=0.000168016, gnorm=1.445, clip=0, loss_scale=1, train_wall=73, gb_free=15.2, wall=2861
2023-08-30 20:21:52 | INFO | train_inner | epoch 003:    656 / 1826 loss=3.27, trans_loss=4.026, nll_loss=2.432, w2v_ctc_loss=1.925, task_loss=0, contrastive_loss=0.408, total=4007.26, n_correct=1314.32, ppl=5.4, accuracy=32.798, wps=16464.6, ups=1.37, wpb=12060.7, bsz=444.4, num_updates=4300, lr=0.000172014, gnorm=1.4, clip=0, loss_scale=1, train_wall=73, gb_free=16.4, wall=2934
2023-08-30 20:23:05 | INFO | train_inner | epoch 003:    756 / 1826 loss=3.256, trans_loss=4.022, nll_loss=2.424, w2v_ctc_loss=1.922, task_loss=0, contrastive_loss=0.423, total=3980.14, n_correct=1310.53, ppl=5.37, accuracy=32.927, wps=16382.6, ups=1.37, wpb=11970.2, bsz=428.9, num_updates=4400, lr=0.000176012, gnorm=1.317, clip=0, loss_scale=1, train_wall=72, gb_free=14, wall=3007
2023-08-30 20:24:18 | INFO | train_inner | epoch 003:    856 / 1826 loss=3.191, trans_loss=4.023, nll_loss=2.426, w2v_ctc_loss=1.875, task_loss=0, contrastive_loss=0.358, total=3912.76, n_correct=1289.1, ppl=5.37, accuracy=32.946, wps=16107.5, ups=1.37, wpb=11765.5, bsz=407, num_updates=4500, lr=0.00018001, gnorm=1.34, clip=0, loss_scale=1, train_wall=73, gb_free=17.6, wall=3081
2023-08-30 20:25:31 | INFO | train_inner | epoch 003:    956 / 1826 loss=3.174, trans_loss=4.002, nll_loss=2.4, w2v_ctc_loss=1.842, task_loss=0, contrastive_loss=0.458, total=3981.42, n_correct=1324.34, ppl=5.28, accuracy=33.263, wps=16449.7, ups=1.37, wpb=11980.8, bsz=431.2, num_updates=4600, lr=0.000184008, gnorm=1.243, clip=0, loss_scale=1, train_wall=72, gb_free=17, wall=3153
2023-08-30 20:26:45 | INFO | train_inner | epoch 003:   1056 / 1826 loss=3.134, trans_loss=4.007, nll_loss=2.405, w2v_ctc_loss=1.824, task_loss=0, contrastive_loss=0.343, total=3975.52, n_correct=1333.27, ppl=5.3, accuracy=33.537, wps=16217.8, ups=1.36, wpb=11953.8, bsz=433, num_updates=4700, lr=0.000188006, gnorm=1.205, clip=0, loss_scale=1, train_wall=73, gb_free=16.9, wall=3227
2023-08-30 20:27:59 | INFO | train_inner | epoch 003:   1156 / 1826 loss=3.059, trans_loss=3.999, nll_loss=2.395, w2v_ctc_loss=1.767, task_loss=0, contrastive_loss=0.263, total=3902.5, n_correct=1312.81, ppl=5.26, accuracy=33.64, wps=15904.9, ups=1.35, wpb=11739.5, bsz=407.2, num_updates=4800, lr=0.000192004, gnorm=1.155, clip=0, loss_scale=1, train_wall=73, gb_free=17.4, wall=3301
2023-08-30 20:29:12 | INFO | train_inner | epoch 003:   1256 / 1826 loss=3.071, trans_loss=3.998, nll_loss=2.393, w2v_ctc_loss=1.77, task_loss=0, contrastive_loss=0.322, total=4000.14, n_correct=1361.21, ppl=5.25, accuracy=34.029, wps=16396.5, ups=1.36, wpb=12030.4, bsz=427.7, num_updates=4900, lr=0.000196002, gnorm=1.161, clip=0, loss_scale=1, train_wall=73, gb_free=16.2, wall=3374
2023-08-30 20:30:25 | INFO | train_inner | epoch 003:   1356 / 1826 loss=3.033, trans_loss=3.992, nll_loss=2.384, w2v_ctc_loss=1.745, task_loss=0, contrastive_loss=0.281, total=3942.18, n_correct=1346.49, ppl=5.22, accuracy=34.156, wps=16307.5, ups=1.38, wpb=11853, bsz=406.2, num_updates=5000, lr=0.0002, gnorm=1.127, clip=0, loss_scale=1, train_wall=72, gb_free=16.3, wall=3447
mt_weight tensor(0.5000)
asr_weight tensor(0.4956, device='cuda:0')
2023-08-30 20:31:37 | INFO | train_inner | epoch 003:   1456 / 1826 loss=3.013, trans_loss=3.972, nll_loss=2.359, w2v_ctc_loss=1.735, task_loss=0, contrastive_loss=0.282, total=3849.49, n_correct=1336.87, ppl=5.13, accuracy=34.728, wps=15968.6, ups=1.38, wpb=11578.7, bsz=412.1, num_updates=5100, lr=0.00019803, gnorm=0.832, clip=0, loss_scale=1, train_wall=72, gb_free=17.5, wall=3519
2023-08-30 20:32:50 | INFO | train_inner | epoch 003:   1556 / 1826 loss=3.019, trans_loss=3.971, nll_loss=2.359, w2v_ctc_loss=1.754, task_loss=0, contrastive_loss=0.276, total=3920.01, n_correct=1369.68, ppl=5.13, accuracy=34.941, wps=16108, ups=1.37, wpb=11794.1, bsz=410.5, num_updates=5200, lr=0.000196116, gnorm=0.85, clip=0, loss_scale=2, train_wall=73, gb_free=16.6, wall=3593
2023-08-30 20:34:04 | INFO | train_inner | epoch 003:   1656 / 1826 loss=3.026, trans_loss=3.948, nll_loss=2.328, w2v_ctc_loss=1.727, task_loss=0, contrastive_loss=0.44, total=3954.16, n_correct=1420.16, ppl=5.02, accuracy=35.916, wps=16143.2, ups=1.36, wpb=11892.7, bsz=434.5, num_updates=5300, lr=0.000194257, gnorm=0.826, clip=0, loss_scale=2, train_wall=73, gb_free=14.9, wall=3666
2023-08-30 20:35:17 | INFO | train_inner | epoch 003:   1756 / 1826 loss=2.982, trans_loss=3.918, nll_loss=2.288, w2v_ctc_loss=1.708, task_loss=0, contrastive_loss=0.398, total=3961.09, n_correct=1472.93, ppl=4.88, accuracy=37.185, wps=16364.9, ups=1.37, wpb=11907.8, bsz=437.9, num_updates=5400, lr=0.00019245, gnorm=0.84, clip=0, loss_scale=2, train_wall=72, gb_free=16, wall=3739
2023-08-30 20:36:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4956, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4956, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4956, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4956, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4956, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4956, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4956, device='cuda:1')
2023-08-30 20:36:44 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.525 | trans_loss 6.916 | nll_loss 4.716 | w2v_ctc_loss 1.964 | task_loss 0 | contrastive_loss 0.398 | total 3505.91 | n_correct 1416.36 | ppl 26.29 | accuracy 40.399 | uer 27.437 | wer 28.897 | raw_wer 28.897 | bleu 4.44 | wps 1257 | wpb 3505.9 | bsz 119.3 | num_updates 5470 | best_bleu 4.44
2023-08-30 20:36:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 5470 updates
2023-08-30 20:36:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 20:36:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 20:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 3 @ 5470 updates, score 4.44) (writing took 10.604604882002604 seconds)
2023-08-30 20:36:55 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-30 20:36:55 | INFO | train | epoch 003 | loss 3.214 | trans_loss 4.004 | nll_loss 2.402 | w2v_ctc_loss 1.881 | task_loss 0 | contrastive_loss 0.43 | total 3956.37 | n_correct 1331.59 | ppl 5.28 | accuracy 33.657 | wps 15156.2 | ups 1.27 | wpb 11900.1 | bsz 427.2 | num_updates 5470 | lr 0.000191215 | gnorm 1.257 | clip 0 | loss_scale 2 | train_wall 1323 | gb_free 17.2 | wall 3837
2023-08-30 20:36:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 20:36:55 | INFO | fairseq.trainer | begin training epoch 4
2023-08-30 20:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 20:37:24 | INFO | train_inner | epoch 004:     30 / 1826 loss=2.95, trans_loss=3.887, nll_loss=2.247, w2v_ctc_loss=1.71, task_loss=0, contrastive_loss=0.357, total=3990.73, n_correct=1531.16, ppl=4.75, accuracy=38.368, wps=9407.9, ups=0.78, wpb=11997.5, bsz=429.3, num_updates=5500, lr=0.000190693, gnorm=0.865, clip=0, loss_scale=2, train_wall=72, gb_free=16.2, wall=3867
2023-08-30 20:38:37 | INFO | train_inner | epoch 004:    130 / 1826 loss=2.849, trans_loss=3.835, nll_loss=2.182, w2v_ctc_loss=1.651, task_loss=0, contrastive_loss=0.277, total=3967.75, n_correct=1599.37, ppl=4.54, accuracy=40.309, wps=16424.1, ups=1.38, wpb=11943.8, bsz=430.8, num_updates=5600, lr=0.000188982, gnorm=0.869, clip=0, loss_scale=2, train_wall=72, gb_free=16.5, wall=3939
2023-08-30 20:39:50 | INFO | train_inner | epoch 004:    230 / 1826 loss=2.807, trans_loss=3.796, nll_loss=2.127, w2v_ctc_loss=1.647, task_loss=0, contrastive_loss=0.235, total=3992.78, n_correct=1686.11, ppl=4.37, accuracy=42.229, wps=16538.6, ups=1.38, wpb=12006.2, bsz=436.3, num_updates=5700, lr=0.000187317, gnorm=0.926, clip=0, loss_scale=2, train_wall=72, gb_free=17, wall=4012
2023-08-30 20:41:02 | INFO | train_inner | epoch 004:    330 / 1826 loss=2.807, trans_loss=3.746, nll_loss=2.062, w2v_ctc_loss=1.642, task_loss=0, contrastive_loss=0.388, total=3978.09, n_correct=1760.17, ppl=4.18, accuracy=44.247, wps=16426.6, ups=1.37, wpb=11959.8, bsz=444.7, num_updates=5800, lr=0.000185695, gnorm=0.862, clip=0, loss_scale=2, train_wall=72, gb_free=16.3, wall=4085
2023-08-30 20:42:16 | INFO | train_inner | epoch 004:    430 / 1826 loss=2.74, trans_loss=3.704, nll_loss=2.007, w2v_ctc_loss=1.644, task_loss=0, contrastive_loss=0.222, total=3976.78, n_correct=1825.48, ppl=4.02, accuracy=45.903, wps=16343.8, ups=1.37, wpb=11957.6, bsz=433.3, num_updates=5900, lr=0.000184115, gnorm=0.895, clip=0, loss_scale=2, train_wall=73, gb_free=16.5, wall=4158
2023-08-30 20:43:29 | INFO | train_inner | epoch 004:    530 / 1826 loss=2.741, trans_loss=3.683, nll_loss=1.98, w2v_ctc_loss=1.618, task_loss=0, contrastive_loss=0.469, total=3925.45, n_correct=1852.89, ppl=3.94, accuracy=47.202, wps=16081.9, ups=1.36, wpb=11802.8, bsz=421.8, num_updates=6000, lr=0.000182574, gnorm=0.855, clip=0, loss_scale=2, train_wall=73, gb_free=16.2, wall=4231
2023-08-30 20:43:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 20:44:08 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.925 | trans_loss 6.081 | nll_loss 3.601 | w2v_ctc_loss 1.925 | task_loss 0 | contrastive_loss 0.39 | total 3505.91 | n_correct 1853.82 | ppl 12.14 | accuracy 52.877 | uer 26.262 | wer 27.678 | raw_wer 27.678 | bleu 14.86 | wps 1159.1 | wpb 3505.9 | bsz 119.3 | num_updates 6000 | best_bleu 14.86
2023-08-30 20:44:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 6000 updates
2023-08-30 20:44:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_4_6000.pt
2023-08-30 20:44:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_4_6000.pt
2023-08-30 20:44:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_4_6000.pt (epoch 4 @ 6000 updates, score 14.86) (writing took 10.828683525000088 seconds)
2023-08-30 20:45:31 | INFO | train_inner | epoch 004:    630 / 1826 loss=2.685, trans_loss=3.651, nll_loss=1.936, w2v_ctc_loss=1.616, task_loss=0, contrastive_loss=0.275, total=4007.91, n_correct=1953.15, ppl=3.83, accuracy=48.732, wps=9861.8, ups=0.82, wpb=12044, bsz=437.6, num_updates=6100, lr=0.000181071, gnorm=0.795, clip=0, loss_scale=2, train_wall=71, gb_free=17.1, wall=4353
2023-08-30 20:46:44 | INFO | train_inner | epoch 004:    730 / 1826 loss=2.612, trans_loss=3.607, nll_loss=1.884, w2v_ctc_loss=1.593, task_loss=0, contrastive_loss=0.187, total=3919.08, n_correct=1963.82, ppl=3.69, accuracy=50.109, wps=16155.3, ups=1.37, wpb=11800.9, bsz=406.4, num_updates=6200, lr=0.000179605, gnorm=0.758, clip=0, loss_scale=2, train_wall=72, gb_free=15.4, wall=4427
2023-08-30 20:47:58 | INFO | train_inner | epoch 004:    830 / 1826 loss=2.658, trans_loss=3.583, nll_loss=1.85, w2v_ctc_loss=1.577, task_loss=0, contrastive_loss=0.446, total=4014.17, n_correct=2059.93, ppl=3.6, accuracy=51.316, wps=16373.9, ups=1.36, wpb=12071.2, bsz=451.3, num_updates=6300, lr=0.000178174, gnorm=0.747, clip=0, loss_scale=2, train_wall=73, gb_free=16.7, wall=4500
2023-08-30 20:49:11 | INFO | train_inner | epoch 004:    930 / 1826 loss=2.629, trans_loss=3.572, nll_loss=1.837, w2v_ctc_loss=1.597, task_loss=0, contrastive_loss=0.362, total=3970.82, n_correct=2061.7, ppl=3.57, accuracy=51.921, wps=16243.3, ups=1.36, wpb=11940, bsz=432.2, num_updates=6400, lr=0.000176777, gnorm=0.779, clip=0, loss_scale=2, train_wall=73, gb_free=16.8, wall=4574
2023-08-30 20:50:24 | INFO | train_inner | epoch 004:   1030 / 1826 loss=2.552, trans_loss=3.546, nll_loss=1.804, w2v_ctc_loss=1.565, task_loss=0, contrastive_loss=0.186, total=3921.72, n_correct=2066.37, ppl=3.49, accuracy=52.69, wps=16198.9, ups=1.37, wpb=11796.6, bsz=415.2, num_updates=6500, lr=0.000175412, gnorm=0.715, clip=0, loss_scale=2, train_wall=72, gb_free=13, wall=4647
2023-08-30 20:51:37 | INFO | train_inner | epoch 004:   1130 / 1826 loss=2.518, trans_loss=3.525, nll_loss=1.777, w2v_ctc_loss=1.55, task_loss=0, contrastive_loss=0.164, total=3904.68, n_correct=2093.18, ppl=3.43, accuracy=53.607, wps=16140.5, ups=1.37, wpb=11745.2, bsz=395.8, num_updates=6600, lr=0.000174078, gnorm=0.681, clip=0, loss_scale=2, train_wall=72, gb_free=16.3, wall=4719
2023-08-30 20:52:50 | INFO | train_inner | epoch 004:   1230 / 1826 loss=2.513, trans_loss=3.514, nll_loss=1.761, w2v_ctc_loss=1.535, task_loss=0, contrastive_loss=0.208, total=3980.69, n_correct=2158.57, ppl=3.39, accuracy=54.226, wps=16490.2, ups=1.38, wpb=11965.5, bsz=423.8, num_updates=6700, lr=0.000172774, gnorm=0.699, clip=0, loss_scale=2, train_wall=72, gb_free=15.1, wall=4792
2023-08-30 20:54:03 | INFO | train_inner | epoch 004:   1330 / 1826 loss=2.494, trans_loss=3.504, nll_loss=1.749, w2v_ctc_loss=1.54, task_loss=0, contrastive_loss=0.178, total=3850.3, n_correct=2109.91, ppl=3.36, accuracy=54.799, wps=15839.1, ups=1.37, wpb=11578.4, bsz=397.6, num_updates=6800, lr=0.000171499, gnorm=0.706, clip=0, loss_scale=2, train_wall=73, gb_free=9.9, wall=4865
2023-08-30 20:55:15 | INFO | train_inner | epoch 004:   1430 / 1826 loss=2.523, trans_loss=3.49, nll_loss=1.732, w2v_ctc_loss=1.515, task_loss=0, contrastive_loss=0.371, total=3980.52, n_correct=2206.39, ppl=3.32, accuracy=55.43, wps=16459.8, ups=1.37, wpb=11970.9, bsz=451.1, num_updates=6900, lr=0.000170251, gnorm=0.66, clip=0, loss_scale=2, train_wall=72, gb_free=16.8, wall=4938
2023-08-30 20:56:28 | INFO | train_inner | epoch 004:   1530 / 1826 loss=2.511, trans_loss=3.479, nll_loss=1.722, w2v_ctc_loss=1.507, task_loss=0, contrastive_loss=0.375, total=4014.75, n_correct=2244.16, ppl=3.3, accuracy=55.898, wps=16595.4, ups=1.37, wpb=12084.9, bsz=454.1, num_updates=7000, lr=0.000169031, gnorm=0.671, clip=0, loss_scale=2, train_wall=72, gb_free=17.5, wall=5011
2023-08-30 20:57:41 | INFO | train_inner | epoch 004:   1630 / 1826 loss=2.443, trans_loss=3.459, nll_loss=1.695, w2v_ctc_loss=1.503, task_loss=0, contrastive_loss=0.173, total=3950.61, n_correct=2230.92, ppl=3.24, accuracy=56.47, wps=16258.4, ups=1.37, wpb=11889.1, bsz=425.6, num_updates=7100, lr=0.000167836, gnorm=0.669, clip=0, loss_scale=2, train_wall=72, gb_free=15.9, wall=5084
2023-08-30 20:58:54 | INFO | train_inner | epoch 004:   1730 / 1826 loss=2.427, trans_loss=3.467, nll_loss=1.706, w2v_ctc_loss=1.493, task_loss=0, contrastive_loss=0.162, total=3877.11, n_correct=2190.48, ppl=3.26, accuracy=56.498, wps=16178.3, ups=1.39, wpb=11672.1, bsz=399.8, num_updates=7200, lr=0.000166667, gnorm=0.635, clip=0, loss_scale=4, train_wall=71, gb_free=16.4, wall=5156
2023-08-30 21:00:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 21:00:40 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.458 | trans_loss 5.495 | nll_loss 2.861 | w2v_ctc_loss 1.77 | task_loss 0 | contrastive_loss 0.352 | total 3505.91 | n_correct 2162.09 | ppl 7.26 | accuracy 61.67 | uer 24.695 | wer 26.282 | raw_wer 26.282 | bleu 23.92 | wps 1257.4 | wpb 3505.9 | bsz 119.3 | num_updates 7296 | best_bleu 23.92
2023-08-30 21:00:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 7296 updates
2023-08-30 21:00:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 21:00:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 21:00:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 4 @ 7296 updates, score 23.92) (writing took 13.941724614000123 seconds)
2023-08-30 21:00:55 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-30 21:00:55 | INFO | train | epoch 004 | loss 2.614 | trans_loss 3.595 | nll_loss 1.868 | w2v_ctc_loss 1.573 | task_loss 0 | contrastive_loss 0.278 | total 3956.37 | n_correct 2009.65 | ppl 3.65 | accuracy 50.795 | wps 15092.7 | ups 1.27 | wpb 11900.1 | bsz 427.2 | num_updates 7296 | lr 0.000165567 | gnorm 0.754 | clip 0 | loss_scale 4 | train_wall 1319 | gb_free 17.1 | wall 5277
2023-08-30 21:00:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 21:00:55 | INFO | fairseq.trainer | begin training epoch 5
2023-08-30 21:00:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 21:01:05 | INFO | train_inner | epoch 005:      4 / 1826 loss=2.416, trans_loss=3.454, nll_loss=1.686, w2v_ctc_loss=1.474, task_loss=0, contrastive_loss=0.185, total=3927.9, n_correct=2236.05, ppl=3.22, accuracy=56.927, wps=9005.2, ups=0.76, wpb=11812.8, bsz=419.6, num_updates=7300, lr=0.000165521, gnorm=0.633, clip=0, loss_scale=4, train_wall=72, gb_free=17, wall=5287
2023-08-30 21:02:17 | INFO | train_inner | epoch 005:    104 / 1826 loss=2.397, trans_loss=3.422, nll_loss=1.645, w2v_ctc_loss=1.41, task_loss=0, contrastive_loss=0.379, total=3935.9, n_correct=2280.34, ppl=3.13, accuracy=57.937, wps=16306.7, ups=1.38, wpb=11832.5, bsz=439.9, num_updates=7400, lr=0.000164399, gnorm=0.646, clip=0, loss_scale=4, train_wall=72, gb_free=16, wall=5360
2023-08-30 21:03:30 | INFO | train_inner | epoch 005:    204 / 1826 loss=2.353, trans_loss=3.415, nll_loss=1.64, w2v_ctc_loss=1.414, task_loss=0, contrastive_loss=0.179, total=3985.53, n_correct=2321.93, ppl=3.12, accuracy=58.259, wps=16509.1, ups=1.38, wpb=11999.9, bsz=449.7, num_updates=7500, lr=0.000163299, gnorm=0.619, clip=0, loss_scale=4, train_wall=72, gb_free=16, wall=5432
2023-08-30 21:04:43 | INFO | train_inner | epoch 005:    304 / 1826 loss=2.346, trans_loss=3.416, nll_loss=1.637, w2v_ctc_loss=1.419, task_loss=0, contrastive_loss=0.158, total=3957.96, n_correct=2309.31, ppl=3.11, accuracy=58.346, wps=16377.9, ups=1.38, wpb=11899, bsz=422.9, num_updates=7600, lr=0.000162221, gnorm=0.61, clip=0, loss_scale=4, train_wall=72, gb_free=16.7, wall=5505
2023-08-30 21:05:56 | INFO | train_inner | epoch 005:    404 / 1826 loss=2.379, trans_loss=3.419, nll_loss=1.642, w2v_ctc_loss=1.439, task_loss=0, contrastive_loss=0.232, total=3937.75, n_correct=2292.31, ppl=3.12, accuracy=58.214, wps=16220.2, ups=1.37, wpb=11843.6, bsz=413.3, num_updates=7700, lr=0.000161165, gnorm=0.614, clip=0, loss_scale=4, train_wall=72, gb_free=15.2, wall=5578
2023-08-30 21:07:09 | INFO | train_inner | epoch 005:    504 / 1826 loss=2.345, trans_loss=3.392, nll_loss=1.611, w2v_ctc_loss=1.381, task_loss=0, contrastive_loss=0.297, total=3982.86, n_correct=2349.93, ppl=3.05, accuracy=59.001, wps=16319.5, ups=1.36, wpb=11992.6, bsz=446.7, num_updates=7800, lr=0.000160128, gnorm=0.62, clip=0, loss_scale=4, train_wall=73, gb_free=16.4, wall=5651
2023-08-30 21:08:22 | INFO | train_inner | epoch 005:    604 / 1826 loss=2.353, trans_loss=3.404, nll_loss=1.623, w2v_ctc_loss=1.397, task_loss=0, contrastive_loss=0.296, total=3964.35, n_correct=2330.74, ppl=3.08, accuracy=58.792, wps=16278.7, ups=1.37, wpb=11924.1, bsz=421.7, num_updates=7900, lr=0.000159111, gnorm=0.615, clip=0, loss_scale=4, train_wall=73, gb_free=16.6, wall=5725
2023-08-30 21:09:35 | INFO | train_inner | epoch 005:    704 / 1826 loss=2.331, trans_loss=3.394, nll_loss=1.611, w2v_ctc_loss=1.391, task_loss=0, contrastive_loss=0.27, total=3884.31, n_correct=2299.92, ppl=3.06, accuracy=59.211, wps=16189.3, ups=1.39, wpb=11686.5, bsz=407.4, num_updates=8000, lr=0.000158114, gnorm=0.593, clip=0, loss_scale=4, train_wall=72, gb_free=16.9, wall=5797
2023-08-30 21:09:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 21:10:12 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.377 | trans_loss 5.386 | nll_loss 2.729 | w2v_ctc_loss 1.788 | task_loss 0 | contrastive_loss 0.318 | total 3505.91 | n_correct 2217.73 | ppl 6.63 | accuracy 63.257 | uer 23.526 | wer 25.253 | raw_wer 25.253 | bleu 25.34 | wps 1236.9 | wpb 3505.9 | bsz 119.3 | num_updates 8000 | best_bleu 25.34
2023-08-30 21:10:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 8000 updates
2023-08-30 21:10:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_5_8000.pt
2023-08-30 21:10:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_5_8000.pt
2023-08-30 21:10:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_5_8000.pt (epoch 5 @ 8000 updates, score 25.34) (writing took 11.740034766000463 seconds)
2023-08-30 21:11:36 | INFO | train_inner | epoch 005:    804 / 1826 loss=2.353, trans_loss=3.395, nll_loss=1.612, w2v_ctc_loss=1.396, task_loss=0, contrastive_loss=0.337, total=3876.66, n_correct=2289.88, ppl=3.06, accuracy=59.068, wps=9605, ups=0.82, wpb=11660.1, bsz=403.9, num_updates=8100, lr=0.000157135, gnorm=0.597, clip=0, loss_scale=4, train_wall=71, gb_free=16.4, wall=5918
2023-08-30 21:12:49 | INFO | train_inner | epoch 005:    904 / 1826 loss=2.315, trans_loss=3.39, nll_loss=1.608, w2v_ctc_loss=1.384, task_loss=0, contrastive_loss=0.193, total=4004.14, n_correct=2380.66, ppl=3.05, accuracy=59.455, wps=16587, ups=1.38, wpb=12054.4, bsz=445.8, num_updates=8200, lr=0.000156174, gnorm=0.591, clip=0, loss_scale=4, train_wall=72, gb_free=17.3, wall=5991
2023-08-30 21:14:02 | INFO | train_inner | epoch 005:   1004 / 1826 loss=2.325, trans_loss=3.391, nll_loss=1.608, w2v_ctc_loss=1.384, task_loss=0, contrastive_loss=0.245, total=3995.32, n_correct=2378.28, ppl=3.05, accuracy=59.527, wps=16401.6, ups=1.36, wpb=12020.1, bsz=425.6, num_updates=8300, lr=0.00015523, gnorm=0.597, clip=0, loss_scale=4, train_wall=73, gb_free=16.4, wall=6064
2023-08-30 21:15:15 | INFO | train_inner | epoch 005:   1104 / 1826 loss=2.317, trans_loss=3.386, nll_loss=1.601, w2v_ctc_loss=1.375, task_loss=0, contrastive_loss=0.267, total=3962.38, n_correct=2369.17, ppl=3.03, accuracy=59.792, wps=16397.5, ups=1.38, wpb=11917.5, bsz=447.3, num_updates=8400, lr=0.000154303, gnorm=0.59, clip=0, loss_scale=4, train_wall=72, gb_free=16.3, wall=6137
2023-08-30 21:16:28 | INFO | train_inner | epoch 005:   1204 / 1826 loss=2.269, trans_loss=3.382, nll_loss=1.595, w2v_ctc_loss=1.359, task_loss=0, contrastive_loss=0.145, total=3916.75, n_correct=2347.86, ppl=3.02, accuracy=59.944, wps=16047.3, ups=1.36, wpb=11776.4, bsz=406, num_updates=8500, lr=0.000153393, gnorm=0.595, clip=0, loss_scale=4, train_wall=73, gb_free=15.9, wall=6210
2023-08-30 21:17:40 | INFO | train_inner | epoch 005:   1304 / 1826 loss=2.282, trans_loss=3.372, nll_loss=1.582, w2v_ctc_loss=1.351, task_loss=0, contrastive_loss=0.237, total=3978.72, n_correct=2390.83, ppl=2.99, accuracy=60.09, wps=16551.8, ups=1.38, wpb=11965.4, bsz=433.5, num_updates=8600, lr=0.000152499, gnorm=0.598, clip=0, loss_scale=4, train_wall=72, gb_free=15.3, wall=6283
2023-08-30 21:18:53 | INFO | train_inner | epoch 005:   1404 / 1826 loss=2.268, trans_loss=3.381, nll_loss=1.591, w2v_ctc_loss=1.351, task_loss=0, contrastive_loss=0.148, total=3981.04, n_correct=2394.48, ppl=3.01, accuracy=60.147, wps=16534.6, ups=1.38, wpb=11963.1, bsz=429.3, num_updates=8700, lr=0.00015162, gnorm=0.666, clip=0, loss_scale=4, train_wall=72, gb_free=16.8, wall=6355
2023-08-30 21:20:06 | INFO | train_inner | epoch 005:   1504 / 1826 loss=2.274, trans_loss=3.372, nll_loss=1.584, w2v_ctc_loss=1.364, task_loss=0, contrastive_loss=0.155, total=3937.22, n_correct=2371.6, ppl=3, accuracy=60.235, wps=16252.2, ups=1.37, wpb=11847.9, bsz=414, num_updates=8800, lr=0.000150756, gnorm=0.589, clip=0, loss_scale=4, train_wall=72, gb_free=15.6, wall=6428
2023-08-30 21:21:19 | INFO | train_inner | epoch 005:   1604 / 1826 loss=2.254, trans_loss=3.366, nll_loss=1.575, w2v_ctc_loss=1.351, task_loss=0, contrastive_loss=0.126, total=4001.21, n_correct=2421.08, ppl=2.98, accuracy=60.509, wps=16382.2, ups=1.36, wpb=12033.7, bsz=430, num_updates=8900, lr=0.000149906, gnorm=0.572, clip=0, loss_scale=4, train_wall=73, gb_free=16.7, wall=6501
2023-08-30 21:22:32 | INFO | train_inner | epoch 005:   1704 / 1826 loss=2.259, trans_loss=3.375, nll_loss=1.584, w2v_ctc_loss=1.342, task_loss=0, contrastive_loss=0.159, total=3999.89, n_correct=2420.49, ppl=3, accuracy=60.514, wps=16566.7, ups=1.38, wpb=12016.4, bsz=431.6, num_updates=9000, lr=0.000149071, gnorm=0.572, clip=0, loss_scale=4, train_wall=72, gb_free=15.7, wall=6574
2023-08-30 21:23:45 | INFO | train_inner | epoch 005:   1804 / 1826 loss=2.271, trans_loss=3.364, nll_loss=1.573, w2v_ctc_loss=1.329, task_loss=0, contrastive_loss=0.249, total=3997.09, n_correct=2426.46, ppl=2.98, accuracy=60.706, wps=16470.1, ups=1.37, wpb=12018.6, bsz=442.5, num_updates=9100, lr=0.00014825, gnorm=0.585, clip=0, loss_scale=4, train_wall=72, gb_free=16.4, wall=6647
2023-08-30 21:24:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 21:24:38 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.251 | trans_loss 5.312 | nll_loss 2.64 | w2v_ctc_loss 1.536 | task_loss 0 | contrastive_loss 0.321 | total 3505.91 | n_correct 2256.09 | ppl 6.24 | accuracy 64.351 | uer 22.635 | wer 24.533 | raw_wer 24.533 | bleu 26.43 | wps 1247.2 | wpb 3505.9 | bsz 119.3 | num_updates 9122 | best_bleu 26.43
2023-08-30 21:24:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 9122 updates
2023-08-30 21:24:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 21:24:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 21:24:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 5 @ 9122 updates, score 26.43) (writing took 11.00531300199873 seconds)
2023-08-30 21:24:49 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-30 21:24:49 | INFO | train | epoch 005 | loss 2.315 | trans_loss 3.39 | nll_loss 1.606 | w2v_ctc_loss 1.379 | task_loss 0 | contrastive_loss 0.225 | total 3956.37 | n_correct 2351.79 | ppl 3.04 | accuracy 59.443 | wps 15149.1 | ups 1.27 | wpb 11900.1 | bsz 427.2 | num_updates 9122 | lr 0.000148071 | gnorm 0.604 | clip 0 | loss_scale 4 | train_wall 1318 | gb_free 17.2 | wall 6711
2023-08-30 21:24:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 21:24:49 | INFO | fairseq.trainer | begin training epoch 6
2023-08-30 21:24:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 21:25:53 | INFO | train_inner | epoch 006:     78 / 1826 loss=2.193, trans_loss=3.34, nll_loss=1.542, w2v_ctc_loss=1.281, task_loss=0, contrastive_loss=0.167, total=3898.11, n_correct=2394.24, ppl=2.91, accuracy=61.421, wps=9114.6, ups=0.78, wpb=11726.7, bsz=413, num_updates=9200, lr=0.000147442, gnorm=0.582, clip=0, loss_scale=4, train_wall=72, gb_free=15.9, wall=6776
2023-08-30 21:27:07 | INFO | train_inner | epoch 006:    178 / 1826 loss=2.213, trans_loss=3.346, nll_loss=1.549, w2v_ctc_loss=1.298, task_loss=0, contrastive_loss=0.172, total=3953.57, n_correct=2423.49, ppl=2.93, accuracy=61.299, wps=16071.1, ups=1.35, wpb=11890.2, bsz=415, num_updates=9300, lr=0.000146647, gnorm=0.566, clip=0, loss_scale=8, train_wall=73, gb_free=17.4, wall=6850
2023-08-30 21:28:20 | INFO | train_inner | epoch 006:    278 / 1826 loss=2.216, trans_loss=3.341, nll_loss=1.545, w2v_ctc_loss=1.298, task_loss=0, contrastive_loss=0.209, total=3921.02, n_correct=2404.92, ppl=2.92, accuracy=61.334, wps=16211.2, ups=1.37, wpb=11798.2, bsz=410.9, num_updates=9400, lr=0.000145865, gnorm=0.563, clip=0, loss_scale=8, train_wall=72, gb_free=17, wall=6922
2023-08-30 21:29:34 | INFO | train_inner | epoch 006:    378 / 1826 loss=2.242, trans_loss=3.328, nll_loss=1.528, w2v_ctc_loss=1.291, task_loss=0, contrastive_loss=0.324, total=3977.69, n_correct=2453.31, ppl=2.88, accuracy=61.677, wps=16230, ups=1.36, wpb=11972.5, bsz=437.6, num_updates=9500, lr=0.000145095, gnorm=0.579, clip=0, loss_scale=8, train_wall=73, gb_free=14.7, wall=6996
2023-08-30 21:30:46 | INFO | train_inner | epoch 006:    478 / 1826 loss=2.183, trans_loss=3.332, nll_loss=1.532, w2v_ctc_loss=1.287, task_loss=0, contrastive_loss=0.122, total=3925.99, n_correct=2416.41, ppl=2.89, accuracy=61.549, wps=16298.1, ups=1.38, wpb=11811.9, bsz=412.5, num_updates=9600, lr=0.000144338, gnorm=0.561, clip=0, loss_scale=8, train_wall=72, gb_free=17.5, wall=7069
2023-08-30 21:31:59 | INFO | train_inner | epoch 006:    578 / 1826 loss=2.203, trans_loss=3.338, nll_loss=1.538, w2v_ctc_loss=1.282, task_loss=0, contrastive_loss=0.228, total=3961.06, n_correct=2441.72, ppl=2.9, accuracy=61.643, wps=16370.1, ups=1.37, wpb=11910, bsz=424.8, num_updates=9700, lr=0.000143592, gnorm=0.555, clip=0, loss_scale=8, train_wall=72, gb_free=17.6, wall=7141
2023-08-30 21:33:11 | INFO | train_inner | epoch 006:    678 / 1826 loss=2.203, trans_loss=3.325, nll_loss=1.524, w2v_ctc_loss=1.27, task_loss=0, contrastive_loss=0.265, total=3962.11, n_correct=2455.5, ppl=2.88, accuracy=61.975, wps=16458.1, ups=1.38, wpb=11922.3, bsz=431.9, num_updates=9800, lr=0.000142857, gnorm=0.559, clip=0, loss_scale=8, train_wall=72, gb_free=17.1, wall=7214
2023-08-30 21:34:25 | INFO | train_inner | epoch 006:    778 / 1826 loss=2.197, trans_loss=3.328, nll_loss=1.527, w2v_ctc_loss=1.272, task_loss=0, contrastive_loss=0.215, total=3994.23, n_correct=2478.67, ppl=2.88, accuracy=62.056, wps=16319.6, ups=1.36, wpb=12010.9, bsz=435.9, num_updates=9900, lr=0.000142134, gnorm=0.565, clip=0, loss_scale=8, train_wall=73, gb_free=15.4, wall=7287
2023-08-30 21:35:37 | INFO | train_inner | epoch 006:    878 / 1826 loss=2.178, trans_loss=3.327, nll_loss=1.527, w2v_ctc_loss=1.267, task_loss=0, contrastive_loss=0.151, total=3963.99, n_correct=2452.71, ppl=2.88, accuracy=61.875, wps=16508.5, ups=1.38, wpb=11928, bsz=434.2, num_updates=10000, lr=0.000141421, gnorm=0.556, clip=0, loss_scale=8, train_wall=72, gb_free=17.2, wall=7360
2023-08-30 21:35:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 21:36:16 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.202 | trans_loss 5.246 | nll_loss 2.553 | w2v_ctc_loss 1.558 | task_loss 0 | contrastive_loss 0.289 | total 3505.91 | n_correct 2290.09 | ppl 5.87 | accuracy 65.321 | uer 21.135 | wer 22.878 | raw_wer 22.878 | bleu 27.23 | wps 1202.4 | wpb 3505.9 | bsz 119.3 | num_updates 10000 | best_bleu 27.23
2023-08-30 21:36:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 10000 updates
2023-08-30 21:36:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_6_10000.pt
2023-08-30 21:36:17 | ERROR | fairseq.checkpoint_utils | Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/serialization.py", line 441, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/serialization.py", line 655, in _save
    zip_file.write_record('data.pkl', data_value, len(data_value))
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq/checkpoint_utils.py", line 572, in _torch_persistent_save
    return torch.save(obj, f)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/serialization.py", line 442, in save
    return
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/serialization.py", line 305, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:337] . unexpected pos 64 vs 0

Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    buf = self._recv_byteTraceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/serialization.py", line 441, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/serialization.py", line 655, in _save
    zip_file.write_record('data.pkl', data_value, len(data_value))
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq/checkpoint_utils.py", line 557, in torch_persistent_save
    _torch_persistent_save(obj, f)
  File "/mnt/zhangyh/fairseq-AT/fairseq/checkpoint_utils.py", line 572, in _torch_persistent_save
    return torch.save(obj, f)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/serialization.py", line 442, in save
    return
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/serialization.py", line 305, in __exit__
    self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:337] . unexpected pos 64 vs 0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 330, in train
    valid_losses, should_stop = validate_and_save(
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 427, in validate_and_save
    checkpoint_utils.save_checkpoint(
  File "/mnt/zhangyh/fairseq-AT/fairseq/checkpoint_utils.py", line 115, in save_checkpoint
    trainer.save_checkpoint(checkpoints[0], extra_state)
  File "/mnt/zhangyh/fairseq-AT/fairseq/trainer.py", line 441, in save_checkpoint
    checkpoint_utils.torch_persistent_save(
  File "/mnt/zhangyh/fairseq-AT/fairseq/checkpoint_utils.py", line 557, in torch_persistent_save
    _torch_persistent_save(obj, f)
OSError: [Errno 28] No space left on device

/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 354 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-30 22:12:38 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15794
2023-08-30 22:12:38 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15794
2023-08-30 22:12:38 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15794
2023-08-30 22:12:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-30 22:12:38 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15794
2023-08-30 22:12:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-30 22:12:38 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15794
2023-08-30 22:12:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-30 22:12:38 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15794
2023-08-30 22:12:38 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15794
2023-08-30 22:12:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-30 22:12:38 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15794
2023-08-30 22:12:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-30 22:12:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-30 22:12:39 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-30 22:12:39 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-30 22:12:39 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:12:39 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-30 22:12:39 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:12:39 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-30 22:12:39 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:12:39 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:12:39 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:12:39 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-30 22:12:39 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-30 22:12:39 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-30 22:12:39 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:12:39 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:12:39 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-30 22:12:39 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-30 22:12:39 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:12:39 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-30 22:12:42 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15794', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-30 22:12:42 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-30 22:12:43 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-30 22:12:43 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-30 22:12:43 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-30 22:12:43 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
2023-08-30 22:12:47 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-30 22:12:47 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enes_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-30 22:12:47 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-30 22:12:48 | INFO | root | load pretrained hubert
2023-08-30 22:12:56 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
2023-08-30 22:12:59 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt
2023-08-30 22:13:05 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt
2023-08-30 22:13:05 | INFO | root | share the sematic adapter and textual encoder
2023-08-30 22:13:05 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-30 22:13:05 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-30 22:13:05 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-30 22:13:05 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-30 22:13:05 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-30 22:13:05 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-30 22:13:05 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-30 22:13:05 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 22:13:05 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 22:13:05 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1312, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-30 22:13:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-30 22:13:22 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-30 22:13:22 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-30 22:13:22 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-30 22:13:22 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 22:13:22 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 22:13:22 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 22:13:22 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 22:13:22 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 22:13:22 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 22:13:22 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 22:13:22 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 22:13:22 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-30 22:13:22 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-30 22:13:22 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-30 22:13:22 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_last.pt
2023-08-30 22:13:24 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.4956)
mt_weight tensor(0.5000)
2023-08-30 22:13:43 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-30 22:13:44 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_last.pt (epoch 6 @ 9122 updates)
2023-08-30 22:13:44 | INFO | fairseq.trainer | loading train data for epoch 6
2023-08-30 22:13:44 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-30 22:13:44 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 22:13:44 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-30 22:13:46 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=260049, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-30 22:13:48 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=260049, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(0.4956)
mt_weight tensor(0.5000)
asr_weight tensor(0.4956)
mt_weight tensor(0.5000)
asr_weight tensor(0.4956)
mt_weight tensor(0.5000)
asr_weight tensor(0.4956)
mt_weight tensor(0.5000)
2023-08-30 22:14:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 22:14:36 | INFO | fairseq.trainer | begin training epoch 6
2023-08-30 22:14:36 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(0.4956)
mt_weight tensor(0.5000)
asr_weight tensor(0.4956)
mt_weight tensor(0.5000)
asr_weight tensor(0.4956)
mt_weight tensor(0.5000)
2023-08-30 22:15:45 | INFO | train_inner | epoch 006:     78 / 1826 loss=2.185, trans_loss=3.337, nll_loss=1.537, w2v_ctc_loss=1.259, task_loss=0, contrastive_loss=0.185, total=3981.71, n_correct=2455.23, ppl=2.9, accuracy=61.663, wps=16202.1, ups=1.36, wpb=11972.9, bsz=434.1, num_updates=9200, lr=0.000147442, gnorm=0.572, clip=0, loss_scale=4, train_wall=60, gb_free=15.9, wall=143
2023-08-30 22:16:59 | INFO | train_inner | epoch 006:    178 / 1826 loss=2.216, trans_loss=3.347, nll_loss=1.55, w2v_ctc_loss=1.303, task_loss=0, contrastive_loss=0.172, total=3953.57, n_correct=2419.89, ppl=2.93, accuracy=61.208, wps=16042.3, ups=1.35, wpb=11890.2, bsz=415, num_updates=9300, lr=0.000146647, gnorm=0.577, clip=0, loss_scale=4, train_wall=73, gb_free=17.4, wall=217
2023-08-30 22:18:13 | INFO | train_inner | epoch 006:    278 / 1826 loss=2.219, trans_loss=3.342, nll_loss=1.546, w2v_ctc_loss=1.299, task_loss=0, contrastive_loss=0.21, total=3921.02, n_correct=2402.48, ppl=2.92, accuracy=61.272, wps=15925.4, ups=1.35, wpb=11798.2, bsz=410.9, num_updates=9400, lr=0.000145865, gnorm=0.583, clip=0, loss_scale=4, train_wall=73, gb_free=17, wall=291
2023-08-30 22:19:28 | INFO | train_inner | epoch 006:    378 / 1826 loss=2.244, trans_loss=3.328, nll_loss=1.528, w2v_ctc_loss=1.297, task_loss=0, contrastive_loss=0.322, total=3977.69, n_correct=2455.25, ppl=2.88, accuracy=61.726, wps=16064.2, ups=1.34, wpb=11972.5, bsz=437.6, num_updates=9500, lr=0.000145095, gnorm=0.582, clip=0, loss_scale=4, train_wall=74, gb_free=14.7, wall=366
2023-08-30 22:20:41 | INFO | train_inner | epoch 006:    478 / 1826 loss=2.188, trans_loss=3.331, nll_loss=1.531, w2v_ctc_loss=1.292, task_loss=0, contrastive_loss=0.121, total=3925.99, n_correct=2420.13, ppl=2.89, accuracy=61.644, wps=16138.4, ups=1.37, wpb=11811.9, bsz=412.5, num_updates=9600, lr=0.000144338, gnorm=0.561, clip=0, loss_scale=4, train_wall=72, gb_free=17.5, wall=439
2023-08-30 22:21:55 | INFO | train_inner | epoch 006:    578 / 1826 loss=2.202, trans_loss=3.337, nll_loss=1.538, w2v_ctc_loss=1.279, task_loss=0, contrastive_loss=0.228, total=3961.06, n_correct=2441.02, ppl=2.9, accuracy=61.625, wps=16113, ups=1.35, wpb=11910, bsz=424.8, num_updates=9700, lr=0.000143592, gnorm=0.558, clip=0, loss_scale=4, train_wall=73, gb_free=17.6, wall=513
2023-08-30 22:23:08 | INFO | train_inner | epoch 006:    678 / 1826 loss=2.209, trans_loss=3.325, nll_loss=1.525, w2v_ctc_loss=1.279, task_loss=0, contrastive_loss=0.265, total=3962.11, n_correct=2452.82, ppl=2.88, accuracy=61.907, wps=16234.7, ups=1.36, wpb=11922.3, bsz=431.9, num_updates=9800, lr=0.000142857, gnorm=0.56, clip=0, loss_scale=4, train_wall=72, gb_free=17.1, wall=586
2023-08-30 22:24:23 | INFO | train_inner | epoch 006:    778 / 1826 loss=2.19, trans_loss=3.328, nll_loss=1.526, w2v_ctc_loss=1.266, task_loss=0, contrastive_loss=0.212, total=3994.23, n_correct=2479.16, ppl=2.88, accuracy=62.069, wps=16199.7, ups=1.35, wpb=12010.9, bsz=435.9, num_updates=9900, lr=0.000142134, gnorm=0.559, clip=0, loss_scale=4, train_wall=73, gb_free=15.4, wall=660
2023-08-30 22:25:36 | INFO | train_inner | epoch 006:    878 / 1826 loss=2.177, trans_loss=3.326, nll_loss=1.526, w2v_ctc_loss=1.267, task_loss=0, contrastive_loss=0.15, total=3963.99, n_correct=2453.95, ppl=2.88, accuracy=61.906, wps=16295.4, ups=1.37, wpb=11928, bsz=434.2, num_updates=10000, lr=0.000141421, gnorm=0.561, clip=0, loss_scale=4, train_wall=72, gb_free=17.2, wall=734
2023-08-30 22:25:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-30 22:26:13 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.252 | nll_loss 2.556 | w2v_ctc_loss 1.592 | task_loss 0 | contrastive_loss 0.286 | total 3505.91 | n_correct 2293.91 | ppl 5.88 | accuracy 65.43 | uer 21.377 | wer 23.369 | raw_wer 23.369 | bleu 27.15 | wps 1226 | wpb 3505.9 | bsz 119.3 | num_updates 10000 | best_bleu 27.15
2023-08-30 22:26:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 10000 updates
2023-08-30 22:26:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_6_10000.pt
2023-08-30 22:26:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_6_10000.pt
2023-08-30 22:26:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_6_10000.pt (epoch 6 @ 10000 updates, score 27.15) (writing took 17.26922953599933 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-08-30 22:27:44 | INFO | train_inner | epoch 006:    978 / 1826 loss=2.192, trans_loss=3.328, nll_loss=1.525, w2v_ctc_loss=1.263, task_loss=0, contrastive_loss=0.241, total=4004.17, n_correct=2487.14, ppl=2.88, accuracy=62.114, wps=9400.4, ups=0.78, wpb=12032, bsz=444.8, num_updates=10100, lr=0.00014072, gnorm=0.474, clip=0, loss_scale=4, train_wall=72, gb_free=16.6, wall=862
2023-08-30 22:28:57 | INFO | train_inner | epoch 006:   1078 / 1826 loss=2.166, trans_loss=3.318, nll_loss=1.516, w2v_ctc_loss=1.272, task_loss=0, contrastive_loss=0.116, total=3952.95, n_correct=2464.17, ppl=2.86, accuracy=62.337, wps=16258, ups=1.37, wpb=11893.5, bsz=422.9, num_updates=10200, lr=0.000140028, gnorm=0.464, clip=0, loss_scale=4, train_wall=73, gb_free=16.4, wall=935
2023-08-30 22:30:10 | INFO | train_inner | epoch 006:   1178 / 1826 loss=2.169, trans_loss=3.322, nll_loss=1.52, w2v_ctc_loss=1.266, task_loss=0, contrastive_loss=0.14, total=3919.76, n_correct=2436.73, ppl=2.87, accuracy=62.165, wps=16224.3, ups=1.38, wpb=11794.6, bsz=423.3, num_updates=10300, lr=0.000139347, gnorm=0.465, clip=0, loss_scale=4, train_wall=72, gb_free=15.7, wall=1007
2023-08-30 22:31:24 | INFO | train_inner | epoch 006:   1278 / 1826 loss=2.194, trans_loss=3.309, nll_loss=1.504, w2v_ctc_loss=1.265, task_loss=0, contrastive_loss=0.259, total=3957.79, n_correct=2471.37, ppl=2.84, accuracy=62.443, wps=16094.5, ups=1.35, wpb=11907.5, bsz=441.4, num_updates=10400, lr=0.000138675, gnorm=0.456, clip=0, loss_scale=4, train_wall=73, gb_free=17.5, wall=1081
2023-08-30 22:32:37 | INFO | train_inner | epoch 006:   1378 / 1826 loss=2.164, trans_loss=3.319, nll_loss=1.515, w2v_ctc_loss=1.267, task_loss=0, contrastive_loss=0.131, total=3937.9, n_correct=2452.17, ppl=2.86, accuracy=62.271, wps=16088.9, ups=1.36, wpb=11838.1, bsz=409.6, num_updates=10500, lr=0.000138013, gnorm=0.474, clip=0, loss_scale=4, train_wall=73, gb_free=16.7, wall=1155
2023-08-30 22:33:51 | INFO | train_inner | epoch 006:   1478 / 1826 loss=2.2, trans_loss=3.32, nll_loss=1.515, w2v_ctc_loss=1.26, task_loss=0, contrastive_loss=0.333, total=3946.83, n_correct=2460.31, ppl=2.86, accuracy=62.336, wps=16050.3, ups=1.35, wpb=11859.6, bsz=426.1, num_updates=10600, lr=0.000137361, gnorm=0.461, clip=0, loss_scale=4, train_wall=73, gb_free=16.4, wall=1229
2023-08-30 22:35:05 | INFO | train_inner | epoch 006:   1578 / 1826 loss=2.189, trans_loss=3.323, nll_loss=1.52, w2v_ctc_loss=1.262, task_loss=0, contrastive_loss=0.256, total=3944.52, n_correct=2461.54, ppl=2.87, accuracy=62.404, wps=16112.5, ups=1.36, wpb=11859.3, bsz=421.2, num_updates=10700, lr=0.000136717, gnorm=0.461, clip=0, loss_scale=4, train_wall=73, gb_free=15.8, wall=1303
2023-08-30 22:36:17 | INFO | train_inner | epoch 006:   1678 / 1826 loss=2.132, trans_loss=3.307, nll_loss=1.501, w2v_ctc_loss=1.234, task_loss=0, contrastive_loss=0.112, total=3973.29, n_correct=2498.23, ppl=2.83, accuracy=62.876, wps=16426, ups=1.37, wpb=11948.7, bsz=433.7, num_updates=10800, lr=0.000136083, gnorm=0.445, clip=0, loss_scale=4, train_wall=72, gb_free=17.3, wall=1375
2023-08-30 22:37:30 | INFO | train_inner | epoch 006:   1778 / 1826 loss=2.163, trans_loss=3.316, nll_loss=1.516, w2v_ctc_loss=1.27, task_loss=0, contrastive_loss=0.126, total=3956.46, n_correct=2471.44, ppl=2.86, accuracy=62.466, wps=16414.4, ups=1.38, wpb=11909.1, bsz=429.1, num_updates=10900, lr=0.000135457, gnorm=0.446, clip=0, loss_scale=4, train_wall=72, gb_free=15.7, wall=1448
2023-08-30 22:38:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
2023-08-30 22:38:44 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.182 | trans_loss 5.211 | nll_loss 2.508 | w2v_ctc_loss 1.571 | task_loss 0 | contrastive_loss 0.288 | total 3505.91 | n_correct 2312.91 | ppl 5.69 | accuracy 65.972 | uer 21.522 | wer 23.58 | raw_wer 23.58 | bleu 27.78 | wps 1197.5 | wpb 3505.9 | bsz 119.3 | num_updates 10948 | best_bleu 27.78
2023-08-30 22:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 10948 updates
2023-08-30 22:38:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 22:38:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 22:38:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 6 @ 10948 updates, score 27.78) (writing took 11.542226740002661 seconds)
2023-08-30 22:38:56 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-30 22:38:56 | INFO | train | epoch 006 | loss 2.188 | trans_loss 3.325 | nll_loss 1.524 | w2v_ctc_loss 1.272 | task_loss 0 | contrastive_loss 0.198 | total 3956.37 | n_correct 2454.86 | ppl 2.88 | accuracy 62.048 | wps 15001.3 | ups 1.26 | wpb 11900.1 | bsz 427.2 | num_updates 10948 | lr 0.00013516 | gnorm 0.512 | clip 0 | loss_scale 4 | train_wall 1332 | gb_free 16.8 | wall 1534
2023-08-30 22:38:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 22:38:56 | INFO | fairseq.trainer | begin training epoch 7
2023-08-30 22:38:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 22:39:41 | INFO | train_inner | epoch 007:     52 / 1826 loss=2.14, trans_loss=3.296, nll_loss=1.489, w2v_ctc_loss=1.243, task_loss=0, contrastive_loss=0.147, total=3931.13, n_correct=2476.68, ppl=2.81, accuracy=63.002, wps=9030.8, ups=0.76, wpb=11831.4, bsz=427.9, num_updates=11000, lr=0.00013484, gnorm=0.457, clip=0, loss_scale=4, train_wall=73, gb_free=16.5, wall=1579
2023-08-30 22:40:54 | INFO | train_inner | epoch 007:    152 / 1826 loss=2.105, trans_loss=3.29, nll_loss=1.479, w2v_ctc_loss=1.208, task_loss=0, contrastive_loss=0.118, total=3953.01, n_correct=2503.08, ppl=2.79, accuracy=63.321, wps=16271.6, ups=1.37, wpb=11890.5, bsz=431.4, num_updates=11100, lr=0.000134231, gnorm=0.446, clip=0, loss_scale=4, train_wall=72, gb_free=13.2, wall=1652
2023-08-30 22:42:07 | INFO | train_inner | epoch 007:    252 / 1826 loss=2.113, trans_loss=3.293, nll_loss=1.482, w2v_ctc_loss=1.227, task_loss=0, contrastive_loss=0.108, total=3898.38, n_correct=2465.17, ppl=2.79, accuracy=63.236, wps=16033.2, ups=1.37, wpb=11720.9, bsz=401.6, num_updates=11200, lr=0.000133631, gnorm=0.448, clip=0, loss_scale=8, train_wall=72, gb_free=16, wall=1725
2023-08-30 22:43:20 | INFO | train_inner | epoch 007:    352 / 1826 loss=2.134, trans_loss=3.292, nll_loss=1.484, w2v_ctc_loss=1.2, task_loss=0, contrastive_loss=0.26, total=4034.29, n_correct=2553.68, ppl=2.8, accuracy=63.299, wps=16759.8, ups=1.38, wpb=12139.1, bsz=466.5, num_updates=11300, lr=0.000133038, gnorm=0.44, clip=0, loss_scale=8, train_wall=72, gb_free=17.1, wall=1797
2023-08-30 22:44:33 | INFO | train_inner | epoch 007:    452 / 1826 loss=2.122, trans_loss=3.289, nll_loss=1.479, w2v_ctc_loss=1.216, task_loss=0, contrastive_loss=0.179, total=3989.92, n_correct=2527.4, ppl=2.79, accuracy=63.345, wps=16454.9, ups=1.37, wpb=12006.9, bsz=444.5, num_updates=11400, lr=0.000132453, gnorm=0.447, clip=0, loss_scale=8, train_wall=72, gb_free=15.5, wall=1870
2023-08-30 22:45:46 | INFO | train_inner | epoch 007:    552 / 1826 loss=2.11, trans_loss=3.283, nll_loss=1.47, w2v_ctc_loss=1.218, task_loss=0, contrastive_loss=0.125, total=3952.57, n_correct=2517.74, ppl=2.77, accuracy=63.699, wps=16254.3, ups=1.37, wpb=11886.2, bsz=433.2, num_updates=11500, lr=0.000131876, gnorm=0.448, clip=0, loss_scale=8, train_wall=72, gb_free=17.1, wall=1944
2023-08-30 22:46:59 | INFO | train_inner | epoch 007:    652 / 1826 loss=2.129, trans_loss=3.287, nll_loss=1.476, w2v_ctc_loss=1.207, task_loss=0, contrastive_loss=0.28, total=3942.35, n_correct=2500.96, ppl=2.78, accuracy=63.438, wps=16126.7, ups=1.36, wpb=11857.5, bsz=423.7, num_updates=11600, lr=0.000131306, gnorm=0.442, clip=0, loss_scale=8, train_wall=73, gb_free=17.1, wall=2017
2023-08-30 22:48:12 | INFO | train_inner | epoch 007:    752 / 1826 loss=2.12, trans_loss=3.288, nll_loss=1.476, w2v_ctc_loss=1.193, task_loss=0, contrastive_loss=0.263, total=3949.88, n_correct=2514.3, ppl=2.78, accuracy=63.655, wps=16218.2, ups=1.37, wpb=11876.3, bsz=431.9, num_updates=11700, lr=0.000130744, gnorm=0.438, clip=0, loss_scale=8, train_wall=72, gb_free=15.8, wall=2090
2023-08-30 22:49:26 | INFO | train_inner | epoch 007:    852 / 1826 loss=2.1, trans_loss=3.288, nll_loss=1.476, w2v_ctc_loss=1.216, task_loss=0, contrastive_loss=0.11, total=3930.38, n_correct=2496.12, ppl=2.78, accuracy=63.508, wps=16125.1, ups=1.36, wpb=11820.2, bsz=404.7, num_updates=11800, lr=0.000130189, gnorm=0.442, clip=0, loss_scale=8, train_wall=73, gb_free=11.9, wall=2164
2023-08-30 22:50:39 | INFO | train_inner | epoch 007:    952 / 1826 loss=2.097, trans_loss=3.283, nll_loss=1.47, w2v_ctc_loss=1.205, task_loss=0, contrastive_loss=0.122, total=4048.82, n_correct=2578.56, ppl=2.77, accuracy=63.687, wps=16715.9, ups=1.37, wpb=12177.2, bsz=443.4, num_updates=11900, lr=0.000129641, gnorm=0.444, clip=0, loss_scale=8, train_wall=72, gb_free=16.2, wall=2237
2023-08-30 22:51:53 | INFO | train_inner | epoch 007:   1052 / 1826 loss=2.086, trans_loss=3.274, nll_loss=1.459, w2v_ctc_loss=1.198, task_loss=0, contrastive_loss=0.111, total=3928.57, n_correct=2511.03, ppl=2.75, accuracy=63.917, wps=15949.8, ups=1.35, wpb=11816.1, bsz=424.5, num_updates=12000, lr=0.000129099, gnorm=0.441, clip=0, loss_scale=8, train_wall=73, gb_free=14.3, wall=2311
2023-08-30 22:51:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 22:52:31 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.122 | trans_loss 5.164 | nll_loss 2.455 | w2v_ctc_loss 1.485 | task_loss 0 | contrastive_loss 0.282 | total 3505.91 | n_correct 2340.09 | ppl 5.48 | accuracy 66.747 | uer 20.137 | wer 22.041 | raw_wer 22.041 | bleu 28.43 | wps 1204.9 | wpb 3505.9 | bsz 119.3 | num_updates 12000 | best_bleu 28.43
2023-08-30 22:52:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 12000 updates
2023-08-30 22:52:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_7_12000.pt
2023-08-30 22:52:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_7_12000.pt
2023-08-30 22:52:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_7_12000.pt (epoch 7 @ 12000 updates, score 28.43) (writing took 12.06132810300187 seconds)
2023-08-30 22:53:57 | INFO | train_inner | epoch 007:   1152 / 1826 loss=2.115, trans_loss=3.284, nll_loss=1.474, w2v_ctc_loss=1.229, task_loss=0, contrastive_loss=0.138, total=3932.31, n_correct=2499.42, ppl=2.78, accuracy=63.561, wps=9526.9, ups=0.8, wpb=11834.7, bsz=408.4, num_updates=12100, lr=0.000128565, gnorm=0.448, clip=0, loss_scale=8, train_wall=73, gb_free=15.8, wall=2435
2023-08-30 22:55:10 | INFO | train_inner | epoch 007:   1252 / 1826 loss=2.125, trans_loss=3.285, nll_loss=1.474, w2v_ctc_loss=1.2, task_loss=0, contrastive_loss=0.257, total=3998.13, n_correct=2543.09, ppl=2.78, accuracy=63.607, wps=16421.9, ups=1.36, wpb=12030.8, bsz=433.4, num_updates=12200, lr=0.000128037, gnorm=0.447, clip=0, loss_scale=8, train_wall=73, gb_free=16, wall=2508
2023-08-30 22:56:23 | INFO | train_inner | epoch 007:   1352 / 1826 loss=2.09, trans_loss=3.278, nll_loss=1.466, w2v_ctc_loss=1.203, task_loss=0, contrastive_loss=0.114, total=3909.99, n_correct=2492.09, ppl=2.76, accuracy=63.736, wps=16235.6, ups=1.38, wpb=11765, bsz=411.2, num_updates=12300, lr=0.000127515, gnorm=0.447, clip=0, loss_scale=8, train_wall=72, gb_free=16.2, wall=2581
2023-08-30 22:57:36 | INFO | train_inner | epoch 007:   1452 / 1826 loss=2.162, trans_loss=3.287, nll_loss=1.475, w2v_ctc_loss=1.211, task_loss=0, contrastive_loss=0.389, total=3964.82, n_correct=2523.57, ppl=2.78, accuracy=63.649, wps=16175.5, ups=1.36, wpb=11915.6, bsz=435.9, num_updates=12400, lr=0.000127, gnorm=0.459, clip=0, loss_scale=8, train_wall=73, gb_free=17.6, wall=2654
2023-08-30 22:58:51 | INFO | train_inner | epoch 007:   1552 / 1826 loss=2.09, trans_loss=3.282, nll_loss=1.47, w2v_ctc_loss=1.198, task_loss=0, contrastive_loss=0.125, total=3929.01, n_correct=2507.22, ppl=2.77, accuracy=63.813, wps=15930.9, ups=1.35, wpb=11818.4, bsz=413.4, num_updates=12500, lr=0.000126491, gnorm=0.442, clip=0, loss_scale=8, train_wall=73, gb_free=12.2, wall=2728
2023-08-30 23:00:04 | INFO | train_inner | epoch 007:   1652 / 1826 loss=2.098, trans_loss=3.282, nll_loss=1.469, w2v_ctc_loss=1.178, task_loss=0, contrastive_loss=0.208, total=3986.3, n_correct=2544.38, ppl=2.77, accuracy=63.828, wps=16332.4, ups=1.36, wpb=11985.1, bsz=449.1, num_updates=12600, lr=0.000125988, gnorm=0.444, clip=0, loss_scale=8, train_wall=73, gb_free=16.3, wall=2802
2023-08-30 23:01:17 | INFO | train_inner | epoch 007:   1752 / 1826 loss=2.128, trans_loss=3.282, nll_loss=1.469, w2v_ctc_loss=1.207, task_loss=0, contrastive_loss=0.26, total=3979.89, n_correct=2541.3, ppl=2.77, accuracy=63.854, wps=16308.7, ups=1.36, wpb=11965.7, bsz=429.8, num_updates=12700, lr=0.000125491, gnorm=0.454, clip=0, loss_scale=8, train_wall=73, gb_free=17.5, wall=2875
2023-08-30 23:02:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 23:02:48 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.089 | trans_loss 5.144 | nll_loss 2.431 | w2v_ctc_loss 1.437 | task_loss 0 | contrastive_loss 0.263 | total 3505.91 | n_correct 2345.27 | ppl 5.39 | accuracy 66.895 | uer 19.845 | wer 21.756 | raw_wer 21.756 | bleu 28.99 | wps 1250.7 | wpb 3505.9 | bsz 119.3 | num_updates 12774 | best_bleu 28.99
2023-08-30 23:02:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 12774 updates
2023-08-30 23:02:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 23:02:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 23:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 7 @ 12774 updates, score 28.99) (writing took 11.64947152500099 seconds)
2023-08-30 23:03:00 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-30 23:03:00 | INFO | train | epoch 007 | loss 2.112 | trans_loss 3.285 | nll_loss 1.473 | w2v_ctc_loss 1.207 | task_loss 0 | contrastive_loss 0.184 | total 3956.37 | n_correct 2516.24 | ppl 2.78 | accuracy 63.6 | wps 15051.1 | ups 1.26 | wpb 11900.1 | bsz 427.2 | num_updates 12774 | lr 0.000125127 | gnorm 0.446 | clip 0 | loss_scale 8 | train_wall 1323 | gb_free 16.7 | wall 2977
2023-08-30 23:03:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 23:03:00 | INFO | fairseq.trainer | begin training epoch 8
2023-08-30 23:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 23:03:26 | INFO | train_inner | epoch 008:     26 / 1826 loss=2.08, trans_loss=3.27, nll_loss=1.456, w2v_ctc_loss=1.193, task_loss=0, contrastive_loss=0.123, total=3885.49, n_correct=2488.05, ppl=2.74, accuracy=64.034, wps=9084.2, ups=0.78, wpb=11693.8, bsz=401.5, num_updates=12800, lr=0.000125, gnorm=0.446, clip=0, loss_scale=8, train_wall=71, gb_free=9.8, wall=3004
2023-08-30 23:04:39 | INFO | train_inner | epoch 008:    126 / 1826 loss=2.056, trans_loss=3.256, nll_loss=1.437, w2v_ctc_loss=1.173, task_loss=0, contrastive_loss=0.11, total=3955.57, n_correct=2549.51, ppl=2.71, accuracy=64.454, wps=16341.6, ups=1.37, wpb=11904.6, bsz=420.5, num_updates=12900, lr=0.000124515, gnorm=0.45, clip=0, loss_scale=8, train_wall=72, gb_free=17.1, wall=3077
2023-08-30 23:05:53 | INFO | train_inner | epoch 008:    226 / 1826 loss=2.066, trans_loss=3.251, nll_loss=1.432, w2v_ctc_loss=1.153, task_loss=0, contrastive_loss=0.238, total=3921.96, n_correct=2536.12, ppl=2.7, accuracy=64.665, wps=15890.9, ups=1.35, wpb=11805, bsz=428, num_updates=13000, lr=0.000124035, gnorm=0.441, clip=0, loss_scale=8, train_wall=74, gb_free=16.1, wall=3151
2023-08-30 23:07:06 | INFO | train_inner | epoch 008:    326 / 1826 loss=2.043, trans_loss=3.255, nll_loss=1.436, w2v_ctc_loss=1.16, task_loss=0, contrastive_loss=0.108, total=3887.36, n_correct=2513.8, ppl=2.71, accuracy=64.666, wps=16069.7, ups=1.37, wpb=11693.5, bsz=406.4, num_updates=13100, lr=0.00012356, gnorm=0.441, clip=0, loss_scale=8, train_wall=72, gb_free=12.2, wall=3224
2023-08-30 23:08:20 | INFO | train_inner | epoch 008:    426 / 1826 loss=2.064, trans_loss=3.256, nll_loss=1.436, w2v_ctc_loss=1.153, task_loss=0, contrastive_loss=0.205, total=3929.14, n_correct=2536.27, ppl=2.71, accuracy=64.55, wps=16068.1, ups=1.36, wpb=11818.2, bsz=411.9, num_updates=13200, lr=0.000123091, gnorm=0.442, clip=0, loss_scale=8, train_wall=73, gb_free=15.8, wall=3297
2023-08-30 23:09:33 | INFO | train_inner | epoch 008:    526 / 1826 loss=2.06, trans_loss=3.259, nll_loss=1.44, w2v_ctc_loss=1.171, task_loss=0, contrastive_loss=0.128, total=3997.46, n_correct=2578.11, ppl=2.71, accuracy=64.494, wps=16281.3, ups=1.35, wpb=12027.4, bsz=435.5, num_updates=13300, lr=0.000122628, gnorm=0.446, clip=0, loss_scale=16, train_wall=73, gb_free=15.8, wall=3371
2023-08-30 23:10:46 | INFO | train_inner | epoch 008:    626 / 1826 loss=2.073, trans_loss=3.259, nll_loss=1.441, w2v_ctc_loss=1.154, task_loss=0, contrastive_loss=0.228, total=4026.89, n_correct=2602.96, ppl=2.71, accuracy=64.639, wps=16605.7, ups=1.37, wpb=12112.3, bsz=460.2, num_updates=13400, lr=0.000122169, gnorm=0.44, clip=0, loss_scale=16, train_wall=72, gb_free=16.7, wall=3444
2023-08-30 23:12:00 | INFO | train_inner | epoch 008:    726 / 1826 loss=2.054, trans_loss=3.261, nll_loss=1.442, w2v_ctc_loss=1.154, task_loss=0, contrastive_loss=0.155, total=3935.44, n_correct=2549.1, ppl=2.72, accuracy=64.773, wps=15963.4, ups=1.35, wpb=11831.7, bsz=421.4, num_updates=13500, lr=0.000121716, gnorm=0.432, clip=0, loss_scale=16, train_wall=73, gb_free=15.6, wall=3518
2023-08-30 23:13:14 | INFO | train_inner | epoch 008:    826 / 1826 loss=2.058, trans_loss=3.262, nll_loss=1.442, w2v_ctc_loss=1.153, task_loss=0, contrastive_loss=0.17, total=3996.46, n_correct=2583.39, ppl=2.72, accuracy=64.642, wps=16301.2, ups=1.36, wpb=12007.6, bsz=432.5, num_updates=13600, lr=0.000121268, gnorm=0.442, clip=0, loss_scale=16, train_wall=73, gb_free=16.7, wall=3592
2023-08-30 23:14:27 | INFO | train_inner | epoch 008:    926 / 1826 loss=2.04, trans_loss=3.253, nll_loss=1.433, w2v_ctc_loss=1.163, task_loss=0, contrastive_loss=0.092, total=3885.41, n_correct=2513.09, ppl=2.7, accuracy=64.68, wps=16041.1, ups=1.37, wpb=11686, bsz=406.3, num_updates=13700, lr=0.000120824, gnorm=0.442, clip=0, loss_scale=16, train_wall=72, gb_free=12, wall=3665
2023-08-30 23:15:40 | INFO | train_inner | epoch 008:   1026 / 1826 loss=2.051, trans_loss=3.25, nll_loss=1.43, w2v_ctc_loss=1.175, task_loss=0, contrastive_loss=0.105, total=3950.23, n_correct=2558.74, ppl=2.69, accuracy=64.774, wps=16243.6, ups=1.37, wpb=11884.1, bsz=413.4, num_updates=13800, lr=0.000120386, gnorm=0.438, clip=0, loss_scale=16, train_wall=72, gb_free=15.9, wall=3738
2023-08-30 23:16:53 | INFO | train_inner | epoch 008:   1126 / 1826 loss=2.065, trans_loss=3.25, nll_loss=1.429, w2v_ctc_loss=1.144, task_loss=0, contrastive_loss=0.246, total=3967.4, n_correct=2574.46, ppl=2.69, accuracy=64.89, wps=16377.4, ups=1.37, wpb=11931.2, bsz=436.8, num_updates=13900, lr=0.000119952, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=15.4, wall=3811
2023-08-30 23:18:07 | INFO | train_inner | epoch 008:   1226 / 1826 loss=2.056, trans_loss=3.25, nll_loss=1.428, w2v_ctc_loss=1.136, task_loss=0, contrastive_loss=0.227, total=4000.75, n_correct=2600.32, ppl=2.69, accuracy=64.996, wps=16320.7, ups=1.36, wpb=12030.1, bsz=442.5, num_updates=14000, lr=0.000119523, gnorm=0.439, clip=0, loss_scale=16, train_wall=73, gb_free=16.9, wall=3885
2023-08-30 23:18:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 23:18:45 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.071 | trans_loss 5.124 | nll_loss 2.404 | w2v_ctc_loss 1.427 | task_loss 0 | contrastive_loss 0.264 | total 3505.91 | n_correct 2359.82 | ppl 5.29 | accuracy 67.31 | uer 19.625 | wer 21.651 | raw_wer 21.651 | bleu 29.24 | wps 1224.5 | wpb 3505.9 | bsz 119.3 | num_updates 14000 | best_bleu 29.24
2023-08-30 23:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 14000 updates
2023-08-30 23:18:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_8_14000.pt
2023-08-30 23:18:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_8_14000.pt
2023-08-30 23:18:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_8_14000.pt (epoch 8 @ 14000 updates, score 29.24) (writing took 12.521477708993189 seconds)
2023-08-30 23:20:10 | INFO | train_inner | epoch 008:   1326 / 1826 loss=2.035, trans_loss=3.259, nll_loss=1.441, w2v_ctc_loss=1.154, task_loss=0, contrastive_loss=0.093, total=3927.23, n_correct=2539.16, ppl=2.71, accuracy=64.655, wps=9544.2, ups=0.81, wpb=11813, bsz=411.5, num_updates=14100, lr=0.000119098, gnorm=0.438, clip=0, loss_scale=16, train_wall=72, gb_free=16.3, wall=4008
2023-08-30 23:21:23 | INFO | train_inner | epoch 008:   1426 / 1826 loss=2.039, trans_loss=3.251, nll_loss=1.43, w2v_ctc_loss=1.112, task_loss=0, contrastive_loss=0.266, total=3987.61, n_correct=2584.42, ppl=2.69, accuracy=64.811, wps=16480.3, ups=1.37, wpb=11989.8, bsz=441.2, num_updates=14200, lr=0.000118678, gnorm=0.442, clip=0, loss_scale=16, train_wall=72, gb_free=16.4, wall=4081
2023-08-30 23:22:36 | INFO | train_inner | epoch 008:   1526 / 1826 loss=2.044, trans_loss=3.25, nll_loss=1.43, w2v_ctc_loss=1.145, task_loss=0, contrastive_loss=0.156, total=3997.99, n_correct=2595.29, ppl=2.7, accuracy=64.915, wps=16546.2, ups=1.38, wpb=12027.4, bsz=444.4, num_updates=14300, lr=0.000118262, gnorm=0.439, clip=0, loss_scale=16, train_wall=72, gb_free=16.4, wall=4154
2023-08-30 23:23:48 | INFO | train_inner | epoch 008:   1626 / 1826 loss=2.029, trans_loss=3.251, nll_loss=1.433, w2v_ctc_loss=1.146, task_loss=0, contrastive_loss=0.098, total=3947.23, n_correct=2555.55, ppl=2.7, accuracy=64.743, wps=16471.7, ups=1.39, wpb=11878.9, bsz=415.7, num_updates=14400, lr=0.000117851, gnorm=0.444, clip=0, loss_scale=16, train_wall=71, gb_free=17.1, wall=4226
2023-08-30 23:25:01 | INFO | train_inner | epoch 008:   1726 / 1826 loss=2.075, trans_loss=3.262, nll_loss=1.444, w2v_ctc_loss=1.153, task_loss=0, contrastive_loss=0.266, total=3957.64, n_correct=2554.18, ppl=2.72, accuracy=64.538, wps=16297.3, ups=1.37, wpb=11901.8, bsz=433.4, num_updates=14500, lr=0.000117444, gnorm=0.441, clip=0, loss_scale=16, train_wall=72, gb_free=15.4, wall=4299
2023-08-30 23:26:15 | INFO | train_inner | epoch 008:   1826 / 1826 loss=2.059, trans_loss=3.255, nll_loss=1.435, w2v_ctc_loss=1.154, task_loss=0, contrastive_loss=0.214, total=3953.77, n_correct=2559.98, ppl=2.7, accuracy=64.748, wps=16147.7, ups=1.36, wpb=11888.9, bsz=433.6, num_updates=14600, lr=0.000117041, gnorm=0.449, clip=0, loss_scale=16, train_wall=73, gb_free=16.8, wall=4373
2023-08-30 23:26:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 23:26:52 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.073 | trans_loss 5.119 | nll_loss 2.395 | w2v_ctc_loss 1.448 | task_loss 0 | contrastive_loss 0.262 | total 3505.91 | n_correct 2367.18 | ppl 5.26 | accuracy 67.52 | uer 19.636 | wer 21.666 | raw_wer 21.666 | bleu 29.17 | wps 1235.4 | wpb 3505.9 | bsz 119.3 | num_updates 14600 | best_bleu 29.24
2023-08-30 23:26:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 14600 updates
2023-08-30 23:26:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_29.1701.pt
2023-08-30 23:26:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_29.1701.pt
2023-08-30 23:26:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_29.1701.pt (epoch 8 @ 14600 updates, score 29.17) (writing took 7.224410287002684 seconds)
2023-08-30 23:27:00 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-30 23:27:00 | INFO | train | epoch 008 | loss 2.054 | trans_loss 3.255 | nll_loss 1.436 | w2v_ctc_loss 1.153 | task_loss 0 | contrastive_loss 0.173 | total 3956.37 | n_correct 2559.63 | ppl 2.71 | accuracy 64.697 | wps 15088 | ups 1.27 | wpb 11900.1 | bsz 427.2 | num_updates 14600 | lr 0.000117041 | gnorm 0.441 | clip 0 | loss_scale 16 | train_wall 1324 | gb_free 16.8 | wall 4418
2023-08-30 23:27:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 23:27:00 | INFO | fairseq.trainer | begin training epoch 9
2023-08-30 23:27:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 23:28:20 | INFO | train_inner | epoch 009:    100 / 1826 loss=2.002, trans_loss=3.23, nll_loss=1.402, w2v_ctc_loss=1.101, task_loss=0, contrastive_loss=0.189, total=3922.53, n_correct=2572.51, ppl=2.64, accuracy=65.583, wps=9446, ups=0.8, wpb=11792.7, bsz=419.4, num_updates=14700, lr=0.000116642, gnorm=0.438, clip=0, loss_scale=16, train_wall=71, gb_free=17.2, wall=4497
2023-08-30 23:29:32 | INFO | train_inner | epoch 009:    200 / 1826 loss=1.986, trans_loss=3.232, nll_loss=1.402, w2v_ctc_loss=1.103, task_loss=0, contrastive_loss=0.088, total=3983.09, n_correct=2615, ppl=2.64, accuracy=65.653, wps=16518.4, ups=1.38, wpb=11962.5, bsz=426.6, num_updates=14800, lr=0.000116248, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=15.9, wall=4570
2023-08-30 23:30:45 | INFO | train_inner | epoch 009:    300 / 1826 loss=2.003, trans_loss=3.23, nll_loss=1.403, w2v_ctc_loss=1.11, task_loss=0, contrastive_loss=0.125, total=4021.21, n_correct=2636.64, ppl=2.64, accuracy=65.568, wps=16605.5, ups=1.37, wpb=12092.6, bsz=445.2, num_updates=14900, lr=0.000115857, gnorm=0.432, clip=0, loss_scale=16, train_wall=72, gb_free=16.3, wall=4643
2023-08-30 23:31:58 | INFO | train_inner | epoch 009:    400 / 1826 loss=2.006, trans_loss=3.229, nll_loss=1.403, w2v_ctc_loss=1.109, task_loss=0, contrastive_loss=0.158, total=3972.29, n_correct=2605.57, ppl=2.64, accuracy=65.594, wps=16400.7, ups=1.37, wpb=11949.2, bsz=436.3, num_updates=15000, lr=0.00011547, gnorm=0.431, clip=0, loss_scale=16, train_wall=72, gb_free=17.4, wall=4716
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-08-30 23:32:49 | INFO | train_inner | epoch 009:    500 / 1826 loss=2.106, trans_loss=4.848, nll_loss=2.12, w2v_ctc_loss=0.859, task_loss=0, contrastive_loss=0.065, total=3930.64, n_correct=2565.03, ppl=4.35, accuracy=65.257, wps=15466.5, ups=1.96, wpb=7902.3, bsz=275.5, num_updates=15100, lr=0.000115087, gnorm=0.585, clip=0, loss_scale=16, train_wall=51, gb_free=17.3, wall=4767
2023-08-30 23:33:38 | INFO | train_inner | epoch 009:    600 / 1826 loss=2.11, trans_loss=4.871, nll_loss=2.128, w2v_ctc_loss=0.836, task_loss=0, contrastive_loss=0.132, total=3996.71, n_correct=2608.91, ppl=4.37, accuracy=65.276, wps=16073.2, ups=2.01, wpb=7993.4, bsz=293.4, num_updates=15200, lr=0.000114708, gnorm=0.59, clip=0, loss_scale=16, train_wall=49, gb_free=16.6, wall=4816
2023-08-30 23:34:28 | INFO | train_inner | epoch 009:    700 / 1826 loss=2.101, trans_loss=4.862, nll_loss=2.118, w2v_ctc_loss=0.844, task_loss=0, contrastive_loss=0.084, total=3922.45, n_correct=2573.56, ppl=4.34, accuracy=65.611, wps=15828.8, ups=2.02, wpb=7844.9, bsz=279.5, num_updates=15300, lr=0.000114332, gnorm=0.579, clip=0, loss_scale=32, train_wall=49, gb_free=16.1, wall=4866
2023-08-30 23:35:18 | INFO | train_inner | epoch 009:    800 / 1826 loss=2.117, trans_loss=4.878, nll_loss=2.137, w2v_ctc_loss=0.846, task_loss=0, contrastive_loss=0.152, total=3927.21, n_correct=2556.06, ppl=4.4, accuracy=65.086, wps=15846.4, ups=2.02, wpb=7854.4, bsz=282.8, num_updates=15400, lr=0.000113961, gnorm=0.582, clip=0, loss_scale=32, train_wall=49, gb_free=11.5, wall=4916
2023-08-30 23:36:07 | INFO | train_inner | epoch 009:    900 / 1826 loss=2.122, trans_loss=4.871, nll_loss=2.129, w2v_ctc_loss=0.861, task_loss=0, contrastive_loss=0.174, total=3925.04, n_correct=2563.05, ppl=4.37, accuracy=65.3, wps=15839.8, ups=2.02, wpb=7850.1, bsz=284.6, num_updates=15500, lr=0.000113592, gnorm=0.589, clip=0, loss_scale=32, train_wall=49, gb_free=15.7, wall=4965
2023-08-30 23:36:58 | INFO | train_inner | epoch 009:   1000 / 1826 loss=2.127, trans_loss=4.868, nll_loss=2.125, w2v_ctc_loss=0.862, task_loss=0, contrastive_loss=0.2, total=3978.13, n_correct=2595.75, ppl=4.36, accuracy=65.251, wps=15518.8, ups=1.95, wpb=7956.3, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.592, clip=0, loss_scale=32, train_wall=51, gb_free=16.9, wall=5016
2023-08-30 23:37:48 | INFO | train_inner | epoch 009:   1100 / 1826 loss=2.12, trans_loss=4.868, nll_loss=2.125, w2v_ctc_loss=0.857, task_loss=0, contrastive_loss=0.192, total=3936.56, n_correct=2571.33, ppl=4.36, accuracy=65.319, wps=15945.2, ups=2.03, wpb=7873.1, bsz=282.6, num_updates=15700, lr=0.000112867, gnorm=0.581, clip=0, loss_scale=32, train_wall=49, gb_free=11.7, wall=5066
2023-08-30 23:38:37 | INFO | train_inner | epoch 009:   1200 / 1826 loss=2.116, trans_loss=4.861, nll_loss=2.115, w2v_ctc_loss=0.856, task_loss=0, contrastive_loss=0.197, total=4012.94, n_correct=2627.5, ppl=4.33, accuracy=65.476, wps=16251.1, ups=2.02, wpb=8025.9, bsz=288.5, num_updates=15800, lr=0.000112509, gnorm=0.588, clip=0, loss_scale=32, train_wall=49, gb_free=16.7, wall=5115
2023-08-30 23:39:27 | INFO | train_inner | epoch 009:   1300 / 1826 loss=2.114, trans_loss=4.874, nll_loss=2.133, w2v_ctc_loss=0.865, task_loss=0, contrastive_loss=0.082, total=3903.69, n_correct=2545.17, ppl=4.39, accuracy=65.199, wps=15733.3, ups=2.02, wpb=7807.4, bsz=270.3, num_updates=15900, lr=0.000112154, gnorm=0.59, clip=0, loss_scale=32, train_wall=49, gb_free=14.6, wall=5165
2023-08-30 23:40:16 | INFO | train_inner | epoch 009:   1400 / 1826 loss=2.111, trans_loss=4.871, nll_loss=2.129, w2v_ctc_loss=0.848, task_loss=0, contrastive_loss=0.112, total=3983.29, n_correct=2601.93, ppl=4.38, accuracy=65.321, wps=16070.9, ups=2.02, wpb=7966.6, bsz=293.5, num_updates=16000, lr=0.000111803, gnorm=0.583, clip=0, loss_scale=32, train_wall=49, gb_free=17, wall=5214
2023-08-30 23:40:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
2023-08-30 23:40:54 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.052 | trans_loss 5.092 | nll_loss 2.364 | w2v_ctc_loss 1.428 | task_loss 0 | contrastive_loss 0.274 | total 3505.91 | n_correct 2378.45 | ppl 5.15 | accuracy 67.841 | uer 19.668 | wer 21.669 | raw_wer 21.669 | bleu 29.44 | wps 1263.6 | wpb 3505.9 | bsz 119.3 | num_updates 16000 | best_bleu 29.44
2023-08-30 23:40:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 16000 updates
2023-08-30 23:40:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_9_16000.pt
2023-08-30 23:40:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_9_16000.pt
2023-08-30 23:41:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_9_16000.pt (epoch 9 @ 16000 updates, score 29.44) (writing took 12.760060071996122 seconds)
2023-08-30 23:41:57 | INFO | train_inner | epoch 009:   1500 / 1826 loss=2.11, trans_loss=4.865, nll_loss=2.122, w2v_ctc_loss=0.863, task_loss=0, contrastive_loss=0.094, total=3939.43, n_correct=2579.96, ppl=4.35, accuracy=65.491, wps=7803.6, ups=0.99, wpb=7878.9, bsz=281.4, num_updates=16100, lr=0.000111456, gnorm=0.579, clip=0, loss_scale=32, train_wall=50, gb_free=16.9, wall=5315
2023-08-30 23:42:47 | INFO | train_inner | epoch 009:   1600 / 1826 loss=2.119, trans_loss=4.858, nll_loss=2.113, w2v_ctc_loss=0.855, task_loss=0, contrastive_loss=0.211, total=4013.71, n_correct=2633.34, ppl=4.32, accuracy=65.609, wps=16129.3, ups=2.01, wpb=8027.4, bsz=304.7, num_updates=16200, lr=0.000111111, gnorm=0.585, clip=0, loss_scale=32, train_wall=49, gb_free=16.2, wall=5365
2023-08-30 23:43:36 | INFO | train_inner | epoch 009:   1700 / 1826 loss=2.105, trans_loss=4.864, nll_loss=2.12, w2v_ctc_loss=0.86, task_loss=0, contrastive_loss=0.073, total=3918.49, n_correct=2566.59, ppl=4.35, accuracy=65.499, wps=15901.6, ups=2.03, wpb=7837, bsz=273.5, num_updates=16300, lr=0.00011077, gnorm=0.581, clip=0, loss_scale=32, train_wall=49, gb_free=16.9, wall=5414
2023-08-30 23:44:26 | INFO | train_inner | epoch 009:   1800 / 1826 loss=2.109, trans_loss=4.871, nll_loss=2.128, w2v_ctc_loss=0.864, task_loss=0, contrastive_loss=0.074, total=3940.79, n_correct=2576.57, ppl=4.37, accuracy=65.382, wps=16025.6, ups=2.03, wpb=7881.6, bsz=271.3, num_updates=16400, lr=0.000110432, gnorm=0.583, clip=0, loss_scale=32, train_wall=49, gb_free=17.8, wall=5464
2023-08-30 23:44:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 23:45:16 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.057 | trans_loss 5.089 | nll_loss 2.362 | w2v_ctc_loss 1.46 | task_loss 0 | contrastive_loss 0.261 | total 3505.91 | n_correct 2382.18 | ppl 5.14 | accuracy 67.948 | uer 19.722 | wer 21.628 | raw_wer 21.628 | bleu 29.76 | wps 1258.8 | wpb 3505.9 | bsz 119.3 | num_updates 16426 | best_bleu 29.76
2023-08-30 23:45:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 16426 updates
2023-08-30 23:45:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 23:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-30 23:45:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 9 @ 16426 updates, score 29.76) (writing took 11.873005616005685 seconds)
2023-08-30 23:45:28 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-30 23:45:28 | INFO | train | epoch 009 | loss 2.079 | trans_loss 4.379 | nll_loss 1.909 | w2v_ctc_loss 0.93 | task_loss 0 | contrastive_loss 0.134 | total 3956.37 | n_correct 2588.37 | ppl 3.76 | accuracy 65.423 | wps 14488.5 | ups 1.65 | wpb 8791.1 | bsz 316.4 | num_updates 16426 | lr 0.000110344 | gnorm 0.552 | clip 0 | loss_scale 32 | train_wall 989 | gb_free 17.8 | wall 5526
2023-08-30 23:45:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-30 23:45:28 | INFO | fairseq.trainer | begin training epoch 10
2023-08-30 23:45:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 23:46:12 | INFO | train_inner | epoch 010:     74 / 1826 loss=2.091, trans_loss=4.844, nll_loss=2.094, w2v_ctc_loss=0.843, task_loss=0, contrastive_loss=0.075, total=3937.23, n_correct=2598.36, ppl=4.27, accuracy=65.995, wps=7373.3, ups=0.94, wpb=7874.5, bsz=284.1, num_updates=16500, lr=0.000110096, gnorm=0.586, clip=0, loss_scale=32, train_wall=49, gb_free=11.8, wall=5570
2023-08-30 23:47:03 | INFO | train_inner | epoch 010:    174 / 1826 loss=2.097, trans_loss=4.851, nll_loss=2.103, w2v_ctc_loss=0.852, task_loss=0, contrastive_loss=0.077, total=3947.54, n_correct=2595.4, ppl=4.3, accuracy=65.747, wps=15672, ups=1.99, wpb=7895.1, bsz=278.6, num_updates=16600, lr=0.000109764, gnorm=0.585, clip=0, loss_scale=32, train_wall=50, gb_free=16.6, wall=5621
2023-08-30 23:47:52 | INFO | train_inner | epoch 010:    274 / 1826 loss=2.073, trans_loss=4.825, nll_loss=2.07, w2v_ctc_loss=0.822, task_loss=0, contrastive_loss=0.06, total=3941.33, n_correct=2613.55, ppl=4.2, accuracy=66.311, wps=15944.5, ups=2.02, wpb=7882.7, bsz=283, num_updates=16700, lr=0.000109435, gnorm=0.577, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=5670
2023-08-30 23:48:42 | INFO | train_inner | epoch 010:    374 / 1826 loss=2.116, trans_loss=4.852, nll_loss=2.104, w2v_ctc_loss=0.838, task_loss=0, contrastive_loss=0.27, total=3992.9, n_correct=2624.34, ppl=4.3, accuracy=65.725, wps=16052.5, ups=2.01, wpb=7985.8, bsz=302.7, num_updates=16800, lr=0.000109109, gnorm=0.602, clip=0, loss_scale=32, train_wall=49, gb_free=15.9, wall=5720
2023-08-30 23:49:32 | INFO | train_inner | epoch 010:    474 / 1826 loss=2.093, trans_loss=4.841, nll_loss=2.091, w2v_ctc_loss=0.846, task_loss=0, contrastive_loss=0.11, total=3983.02, n_correct=2629.53, ppl=4.26, accuracy=66.018, wps=16093.6, ups=2.02, wpb=7966, bsz=290.2, num_updates=16900, lr=0.000108786, gnorm=0.571, clip=0, loss_scale=32, train_wall=49, gb_free=16.9, wall=5769
2023-08-30 23:50:21 | INFO | train_inner | epoch 010:    574 / 1826 loss=2.086, trans_loss=4.838, nll_loss=2.086, w2v_ctc_loss=0.837, task_loss=0, contrastive_loss=0.076, total=3961.82, n_correct=2616.98, ppl=4.25, accuracy=66.055, wps=16038.7, ups=2.02, wpb=7923.6, bsz=291.1, num_updates=17000, lr=0.000108465, gnorm=0.578, clip=0, loss_scale=32, train_wall=49, gb_free=17.1, wall=5819
2023-08-30 23:51:11 | INFO | train_inner | epoch 010:    674 / 1826 loss=2.098, trans_loss=4.842, nll_loss=2.091, w2v_ctc_loss=0.833, task_loss=0, contrastive_loss=0.199, total=3914.87, n_correct=2580.63, ppl=4.26, accuracy=65.919, wps=15703.3, ups=2.01, wpb=7829.7, bsz=282, num_updates=17100, lr=0.000108148, gnorm=0.601, clip=0, loss_scale=32, train_wall=49, gb_free=12.7, wall=5869
2023-08-30 23:52:01 | INFO | train_inner | epoch 010:    774 / 1826 loss=2.085, trans_loss=4.835, nll_loss=2.083, w2v_ctc_loss=0.838, task_loss=0, contrastive_loss=0.079, total=3949.94, n_correct=2609.57, ppl=4.24, accuracy=66.066, wps=15756.6, ups=1.99, wpb=7899.9, bsz=283.6, num_updates=17200, lr=0.000107833, gnorm=0.59, clip=0, loss_scale=32, train_wall=49, gb_free=12.6, wall=5919
2023-08-30 23:52:51 | INFO | train_inner | epoch 010:    874 / 1826 loss=2.087, trans_loss=4.84, nll_loss=2.09, w2v_ctc_loss=0.842, task_loss=0, contrastive_loss=0.074, total=3945.73, n_correct=2607.51, ppl=4.26, accuracy=66.084, wps=15877.8, ups=2.01, wpb=7891.5, bsz=272.9, num_updates=17300, lr=0.000107521, gnorm=0.602, clip=0, loss_scale=32, train_wall=49, gb_free=11.5, wall=5969
2023-08-30 23:53:40 | INFO | train_inner | epoch 010:    974 / 1826 loss=2.107, trans_loss=4.846, nll_loss=2.097, w2v_ctc_loss=0.846, task_loss=0, contrastive_loss=0.195, total=4061.61, n_correct=2675.43, ppl=4.28, accuracy=65.871, wps=16476.4, ups=2.03, wpb=8123.2, bsz=301.5, num_updates=17400, lr=0.000107211, gnorm=0.574, clip=0, loss_scale=64, train_wall=49, gb_free=16.3, wall=6018
2023-08-30 23:54:29 | INFO | train_inner | epoch 010:   1074 / 1826 loss=2.095, trans_loss=4.855, nll_loss=2.108, w2v_ctc_loss=0.844, task_loss=0, contrastive_loss=0.082, total=3915.91, n_correct=2576.99, ppl=4.31, accuracy=65.808, wps=15921.9, ups=2.03, wpb=7831.8, bsz=277.1, num_updates=17500, lr=0.000106904, gnorm=0.592, clip=0, loss_scale=64, train_wall=49, gb_free=16.8, wall=6067
2023-08-30 23:55:19 | INFO | train_inner | epoch 010:   1174 / 1826 loss=2.083, trans_loss=4.83, nll_loss=2.077, w2v_ctc_loss=0.84, task_loss=0, contrastive_loss=0.076, total=3941.08, n_correct=2611.75, ppl=4.22, accuracy=66.27, wps=15755.1, ups=2, wpb=7882.2, bsz=282.6, num_updates=17600, lr=0.0001066, gnorm=0.58, clip=0, loss_scale=64, train_wall=49, gb_free=14.5, wall=6117
2023-08-30 23:56:10 | INFO | train_inner | epoch 010:   1274 / 1826 loss=2.107, trans_loss=4.846, nll_loss=2.098, w2v_ctc_loss=0.858, task_loss=0, contrastive_loss=0.151, total=4014.67, n_correct=2643.9, ppl=4.28, accuracy=65.856, wps=15945.3, ups=1.99, wpb=8029.3, bsz=299.4, num_updates=17700, lr=0.000106299, gnorm=0.581, clip=0, loss_scale=64, train_wall=49, gb_free=15.6, wall=6167
2023-08-30 23:56:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-30 23:57:00 | INFO | train_inner | epoch 010:   1375 / 1826 loss=2.09, trans_loss=4.842, nll_loss=2.092, w2v_ctc_loss=0.853, task_loss=0, contrastive_loss=0.063, total=3919.96, n_correct=2584.77, ppl=4.26, accuracy=65.939, wps=15615.1, ups=1.99, wpb=7839.9, bsz=265.5, num_updates=17800, lr=0.000106, gnorm=0.588, clip=0, loss_scale=32, train_wall=50, gb_free=14.6, wall=6218
2023-08-30 23:57:49 | INFO | train_inner | epoch 010:   1475 / 1826 loss=2.078, trans_loss=4.827, nll_loss=2.073, w2v_ctc_loss=0.829, task_loss=0, contrastive_loss=0.075, total=3908.82, n_correct=2591.78, ppl=4.21, accuracy=66.306, wps=15914.8, ups=2.04, wpb=7817.6, bsz=271.1, num_updates=17900, lr=0.000105703, gnorm=0.582, clip=0, loss_scale=32, train_wall=48, gb_free=16, wall=6267
2023-08-30 23:58:38 | INFO | train_inner | epoch 010:   1575 / 1826 loss=2.074, trans_loss=4.821, nll_loss=2.065, w2v_ctc_loss=0.828, task_loss=0, contrastive_loss=0.073, total=3958.9, n_correct=2630.94, ppl=4.19, accuracy=66.456, wps=16090.5, ups=2.03, wpb=7917.8, bsz=285.8, num_updates=18000, lr=0.000105409, gnorm=0.575, clip=0, loss_scale=32, train_wall=49, gb_free=15.4, wall=6316
2023-08-30 23:58:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 23:59:16 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.056 | trans_loss 5.074 | nll_loss 2.343 | w2v_ctc_loss 1.493 | task_loss 0 | contrastive_loss 0.262 | total 3505.91 | n_correct 2386.73 | ppl 5.07 | accuracy 68.077 | uer 19.582 | wer 21.482 | raw_wer 21.482 | bleu 30.11 | wps 1241.1 | wpb 3505.9 | bsz 119.3 | num_updates 18000 | best_bleu 30.11
2023-08-30 23:59:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 18000 updates
2023-08-30 23:59:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_10_18000.pt
2023-08-30 23:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_10_18000.pt
2023-08-30 23:59:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_10_18000.pt (epoch 10 @ 18000 updates, score 30.11) (writing took 11.45260098700237 seconds)
2023-08-31 00:00:17 | INFO | train_inner | epoch 010:   1675 / 1826 loss=2.085, trans_loss=4.837, nll_loss=2.087, w2v_ctc_loss=0.843, task_loss=0, contrastive_loss=0.071, total=3939.68, n_correct=2605.47, ppl=4.25, accuracy=66.134, wps=7952.5, ups=1.01, wpb=7879.4, bsz=278.2, num_updates=18100, lr=0.000105118, gnorm=0.574, clip=0, loss_scale=32, train_wall=49, gb_free=14.9, wall=6415
2023-08-31 00:01:08 | INFO | train_inner | epoch 010:   1775 / 1826 loss=2.113, trans_loss=4.844, nll_loss=2.096, w2v_ctc_loss=0.826, task_loss=0, contrastive_loss=0.313, total=3997.55, n_correct=2635.64, ppl=4.27, accuracy=65.931, wps=15788.2, ups=1.97, wpb=7995.1, bsz=302.4, num_updates=18200, lr=0.000104828, gnorm=0.578, clip=0, loss_scale=32, train_wall=50, gb_free=17.3, wall=6466
2023-08-31 00:01:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 00:02:11 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.049 | trans_loss 5.07 | nll_loss 2.338 | w2v_ctc_loss 1.48 | task_loss 0 | contrastive_loss 0.262 | total 3505.91 | n_correct 2384.64 | ppl 5.06 | accuracy 68.018 | uer 19.625 | wer 21.538 | raw_wer 21.538 | bleu 29.73 | wps 1239.3 | wpb 3505.9 | bsz 119.3 | num_updates 18251 | best_bleu 30.11
2023-08-31 00:02:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 18251 updates
2023-08-31 00:02:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_29.7308.pt
2023-08-31 00:02:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_29.7308.pt
2023-08-31 00:02:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_29.7308.pt (epoch 10 @ 18251 updates, score 29.73) (writing took 7.476995289995102 seconds)
2023-08-31 00:02:19 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-31 00:02:19 | INFO | train | epoch 010 | loss 2.092 | trans_loss 4.84 | nll_loss 2.089 | w2v_ctc_loss 0.84 | task_loss 0 | contrastive_loss 0.123 | total 3956.43 | n_correct 2612.32 | ppl 4.25 | accuracy 66.027 | wps 14285 | ups 1.81 | wpb 7912.9 | bsz 284.9 | num_updates 18251 | lr 0.000104682 | gnorm 0.585 | clip 0 | loss_scale 32 | train_wall 896 | gb_free 17.4 | wall 6537
2023-08-31 00:02:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 00:02:19 | INFO | fairseq.trainer | begin training epoch 11
2023-08-31 00:02:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 00:02:51 | INFO | train_inner | epoch 011:     49 / 1826 loss=2.09, trans_loss=4.827, nll_loss=2.073, w2v_ctc_loss=0.832, task_loss=0, contrastive_loss=0.218, total=3902.57, n_correct=2585.97, ppl=4.21, accuracy=66.263, wps=7590.9, ups=0.97, wpb=7805.1, bsz=280.6, num_updates=18300, lr=0.000104542, gnorm=0.592, clip=0, loss_scale=32, train_wall=49, gb_free=15.4, wall=6569
2023-08-31 00:03:41 | INFO | train_inner | epoch 011:    149 / 1826 loss=2.082, trans_loss=4.818, nll_loss=2.06, w2v_ctc_loss=0.822, task_loss=0, contrastive_loss=0.176, total=3987.55, n_correct=2652.35, ppl=4.17, accuracy=66.516, wps=15988.6, ups=2, wpb=7975.1, bsz=288.5, num_updates=18400, lr=0.000104257, gnorm=0.58, clip=0, loss_scale=32, train_wall=49, gb_free=15.8, wall=6618
2023-08-31 00:04:30 | INFO | train_inner | epoch 011:    249 / 1826 loss=2.073, trans_loss=4.816, nll_loss=2.06, w2v_ctc_loss=0.826, task_loss=0, contrastive_loss=0.086, total=3914.16, n_correct=2601.45, ppl=4.17, accuracy=66.463, wps=15956.1, ups=2.04, wpb=7828.3, bsz=278.6, num_updates=18500, lr=0.000103975, gnorm=0.579, clip=0, loss_scale=32, train_wall=49, gb_free=17.6, wall=6668
2023-08-31 00:05:19 | INFO | train_inner | epoch 011:    349 / 1826 loss=2.064, trans_loss=4.811, nll_loss=2.052, w2v_ctc_loss=0.821, task_loss=0, contrastive_loss=0.06, total=3936.35, n_correct=2624.14, ppl=4.15, accuracy=66.664, wps=15861.9, ups=2.01, wpb=7872.7, bsz=276.7, num_updates=18600, lr=0.000103695, gnorm=0.586, clip=0, loss_scale=32, train_wall=49, gb_free=16.5, wall=6717
2023-08-31 00:06:10 | INFO | train_inner | epoch 011:    449 / 1826 loss=2.067, trans_loss=4.811, nll_loss=2.052, w2v_ctc_loss=0.826, task_loss=0, contrastive_loss=0.066, total=3953.38, n_correct=2634.1, ppl=4.15, accuracy=66.629, wps=15664.3, ups=1.98, wpb=7906.8, bsz=281, num_updates=18700, lr=0.000103418, gnorm=0.589, clip=0, loss_scale=32, train_wall=50, gb_free=16.5, wall=6768
2023-08-31 00:06:59 | INFO | train_inner | epoch 011:    549 / 1826 loss=2.065, trans_loss=4.812, nll_loss=2.054, w2v_ctc_loss=0.821, task_loss=0, contrastive_loss=0.066, total=3939.99, n_correct=2629.02, ppl=4.15, accuracy=66.727, wps=15924.3, ups=2.02, wpb=7880, bsz=276.4, num_updates=18800, lr=0.000103142, gnorm=0.572, clip=0, loss_scale=32, train_wall=49, gb_free=15.8, wall=6817
2023-08-31 00:07:49 | INFO | train_inner | epoch 011:    649 / 1826 loss=2.074, trans_loss=4.819, nll_loss=2.063, w2v_ctc_loss=0.836, task_loss=0, contrastive_loss=0.072, total=3914.2, n_correct=2598.49, ppl=4.18, accuracy=66.386, wps=15871.1, ups=2.03, wpb=7828.4, bsz=276.9, num_updates=18900, lr=0.000102869, gnorm=0.58, clip=0, loss_scale=32, train_wall=49, gb_free=15.7, wall=6866
2023-08-31 00:08:38 | INFO | train_inner | epoch 011:    749 / 1826 loss=2.071, trans_loss=4.819, nll_loss=2.063, w2v_ctc_loss=0.823, task_loss=0, contrastive_loss=0.1, total=3946.93, n_correct=2629.29, ppl=4.18, accuracy=66.616, wps=15950.7, ups=2.02, wpb=7893.9, bsz=283, num_updates=19000, lr=0.000102598, gnorm=0.574, clip=0, loss_scale=32, train_wall=49, gb_free=17.8, wall=6916
2023-08-31 00:09:28 | INFO | train_inner | epoch 011:    849 / 1826 loss=2.072, trans_loss=4.819, nll_loss=2.063, w2v_ctc_loss=0.815, task_loss=0, contrastive_loss=0.118, total=3921.76, n_correct=2607.94, ppl=4.18, accuracy=66.499, wps=15794, ups=2.01, wpb=7843.5, bsz=278.4, num_updates=19100, lr=0.000102329, gnorm=0.583, clip=0, loss_scale=32, train_wall=49, gb_free=17.6, wall=6966
2023-08-31 00:10:18 | INFO | train_inner | epoch 011:    949 / 1826 loss=2.096, trans_loss=4.822, nll_loss=2.066, w2v_ctc_loss=0.832, task_loss=0, contrastive_loss=0.262, total=4002.83, n_correct=2657.52, ppl=4.19, accuracy=66.391, wps=15785, ups=1.97, wpb=8005.7, bsz=290.2, num_updates=19200, lr=0.000102062, gnorm=0.577, clip=0, loss_scale=32, train_wall=50, gb_free=17.3, wall=7016
2023-08-31 00:11:08 | INFO | train_inner | epoch 011:   1049 / 1826 loss=2.071, trans_loss=4.815, nll_loss=2.058, w2v_ctc_loss=0.833, task_loss=0, contrastive_loss=0.063, total=3960.75, n_correct=2636.77, ppl=4.16, accuracy=66.572, wps=16016.4, ups=2.02, wpb=7921.5, bsz=277.2, num_updates=19300, lr=0.000101797, gnorm=0.58, clip=0, loss_scale=32, train_wall=49, gb_free=16.1, wall=7066
2023-08-31 00:11:57 | INFO | train_inner | epoch 011:   1149 / 1826 loss=2.072, trans_loss=4.821, nll_loss=2.066, w2v_ctc_loss=0.831, task_loss=0, contrastive_loss=0.062, total=3937.31, n_correct=2618.83, ppl=4.19, accuracy=66.513, wps=16016.4, ups=2.03, wpb=7874.6, bsz=275.4, num_updates=19400, lr=0.000101535, gnorm=0.567, clip=0, loss_scale=32, train_wall=49, gb_free=17.5, wall=7115
2023-08-31 00:12:46 | INFO | train_inner | epoch 011:   1249 / 1826 loss=2.071, trans_loss=4.816, nll_loss=2.059, w2v_ctc_loss=0.832, task_loss=0, contrastive_loss=0.071, total=3868.03, n_correct=2574.56, ppl=4.17, accuracy=66.56, wps=15717.6, ups=2.03, wpb=7736.1, bsz=266, num_updates=19500, lr=0.000101274, gnorm=0.581, clip=0, loss_scale=32, train_wall=49, gb_free=16.6, wall=7164
2023-08-31 00:13:35 | INFO | train_inner | epoch 011:   1349 / 1826 loss=2.075, trans_loss=4.818, nll_loss=2.063, w2v_ctc_loss=0.825, task_loss=0, contrastive_loss=0.105, total=3981.57, n_correct=2650.98, ppl=4.18, accuracy=66.581, wps=16226.8, ups=2.04, wpb=7963.1, bsz=295.8, num_updates=19600, lr=0.000101015, gnorm=0.569, clip=0, loss_scale=32, train_wall=48, gb_free=12.9, wall=7213
2023-08-31 00:14:26 | INFO | train_inner | epoch 011:   1449 / 1826 loss=2.072, trans_loss=4.819, nll_loss=2.064, w2v_ctc_loss=0.826, task_loss=0, contrastive_loss=0.086, total=4009.25, n_correct=2670.03, ppl=4.18, accuracy=66.597, wps=15885.8, ups=1.98, wpb=8018.5, bsz=294.9, num_updates=19700, lr=0.000100759, gnorm=0.566, clip=0, loss_scale=32, train_wall=50, gb_free=16.1, wall=7264
2023-08-31 00:15:16 | INFO | train_inner | epoch 011:   1549 / 1826 loss=2.089, trans_loss=4.821, nll_loss=2.067, w2v_ctc_loss=0.823, task_loss=0, contrastive_loss=0.219, total=4012.16, n_correct=2672.91, ppl=4.19, accuracy=66.62, wps=16105.6, ups=2.01, wpb=8024.3, bsz=303.6, num_updates=19800, lr=0.000100504, gnorm=0.569, clip=0, loss_scale=64, train_wall=49, gb_free=15.8, wall=7314
2023-08-31 00:15:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-31 00:16:05 | INFO | train_inner | epoch 011:   1650 / 1826 loss=2.071, trans_loss=4.816, nll_loss=2.06, w2v_ctc_loss=0.826, task_loss=0, contrastive_loss=0.085, total=3976.69, n_correct=2653.21, ppl=4.17, accuracy=66.719, wps=16030, ups=2.02, wpb=7953.4, bsz=291, num_updates=19900, lr=0.000100251, gnorm=0.573, clip=0, loss_scale=32, train_wall=49, gb_free=16.4, wall=7363
2023-08-31 00:16:55 | INFO | train_inner | epoch 011:   1750 / 1826 loss=2.097, trans_loss=4.822, nll_loss=2.068, w2v_ctc_loss=0.819, task_loss=0, contrastive_loss=0.315, total=4033.09, n_correct=2681.22, ppl=4.19, accuracy=66.481, wps=16113.8, ups=2, wpb=8066.2, bsz=306.4, num_updates=20000, lr=0.0001, gnorm=0.578, clip=0, loss_scale=32, train_wall=49, gb_free=15.8, wall=7413
2023-08-31 00:16:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 00:17:33 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.031 | trans_loss 5.057 | nll_loss 2.321 | w2v_ctc_loss 1.453 | task_loss 0 | contrastive_loss 0.26 | total 3505.91 | n_correct 2398 | ppl 5 | accuracy 68.399 | uer 19.107 | wer 21.302 | raw_wer 21.302 | bleu 30.08 | wps 1249 | wpb 3505.9 | bsz 119.3 | num_updates 20000 | best_bleu 30.11
2023-08-31 00:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 20000 updates
2023-08-31 00:17:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_11_20000.pt
2023-08-31 00:17:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_11_20000.pt
2023-08-31 00:17:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_11_20000.pt (epoch 11 @ 20000 updates, score 30.08) (writing took 7.12696939700254 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-08-31 00:18:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
2023-08-31 00:18:56 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.019 | trans_loss 5.059 | nll_loss 2.324 | w2v_ctc_loss 1.409 | task_loss 0 | contrastive_loss 0.259 | total 3505.91 | n_correct 2394.64 | ppl 5.01 | accuracy 68.303 | uer 18.949 | wer 20.791 | raw_wer 20.791 | bleu 30.25 | wps 1242.3 | wpb 3505.9 | bsz 119.3 | num_updates 20076 | best_bleu 30.25
2023-08-31 00:18:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 20076 updates
2023-08-31 00:18:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 00:19:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 00:19:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 11 @ 20076 updates, score 30.25) (writing took 11.610237214998051 seconds)
2023-08-31 00:19:08 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-31 00:19:08 | INFO | train | epoch 011 | loss 2.075 | trans_loss 4.817 | nll_loss 2.06 | w2v_ctc_loss 0.825 | task_loss 0 | contrastive_loss 0.121 | total 3956.42 | n_correct 2633.85 | ppl 4.17 | accuracy 66.572 | wps 14307.9 | ups 1.81 | wpb 7912.8 | bsz 284.8 | num_updates 20076 | lr 9.98105e-05 | gnorm 0.577 | clip 0 | loss_scale 32 | train_wall 895 | gb_free 16 | wall 7546
2023-08-31 00:19:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 00:19:08 | INFO | fairseq.trainer | begin training epoch 12
2023-08-31 00:19:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 00:19:27 | INFO | train_inner | epoch 012:     24 / 1826 loss=2.057, trans_loss=4.804, nll_loss=2.044, w2v_ctc_loss=0.811, task_loss=0, contrastive_loss=0.066, total=3952.69, n_correct=2644.43, ppl=4.12, accuracy=66.902, wps=5204.1, ups=0.66, wpb=7905.4, bsz=289, num_updates=20100, lr=9.97509e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=48, gb_free=17.1, wall=7565
2023-08-31 00:20:17 | INFO | train_inner | epoch 012:    124 / 1826 loss=2.06, trans_loss=4.802, nll_loss=2.04, w2v_ctc_loss=0.825, task_loss=0, contrastive_loss=0.061, total=3862.92, n_correct=2583.79, ppl=4.11, accuracy=66.887, wps=15425.9, ups=2, wpb=7725.8, bsz=267, num_updates=20200, lr=9.95037e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=49, gb_free=15.7, wall=7615
2023-08-31 00:21:07 | INFO | train_inner | epoch 012:    224 / 1826 loss=2.056, trans_loss=4.794, nll_loss=2.031, w2v_ctc_loss=0.802, task_loss=0, contrastive_loss=0.114, total=3993.93, n_correct=2682.17, ppl=4.09, accuracy=67.156, wps=16229.8, ups=2.03, wpb=7987.9, bsz=292.7, num_updates=20300, lr=9.92583e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=49, gb_free=12.5, wall=7664
2023-08-31 00:21:56 | INFO | train_inner | epoch 012:    324 / 1826 loss=2.052, trans_loss=4.79, nll_loss=2.026, w2v_ctc_loss=0.793, task_loss=0, contrastive_loss=0.129, total=3964.38, n_correct=2665.47, ppl=4.07, accuracy=67.235, wps=16016.1, ups=2.02, wpb=7928.8, bsz=290.2, num_updates=20400, lr=9.90148e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=49, gb_free=16.5, wall=7714
2023-08-31 00:22:46 | INFO | train_inner | epoch 012:    424 / 1826 loss=2.063, trans_loss=4.798, nll_loss=2.036, w2v_ctc_loss=0.81, task_loss=0, contrastive_loss=0.151, total=3984.39, n_correct=2672.94, ppl=4.1, accuracy=67.085, wps=16043.6, ups=2.01, wpb=7968.8, bsz=293.8, num_updates=20500, lr=9.8773e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=49, gb_free=16.8, wall=7764
2023-08-31 00:23:35 | INFO | train_inner | epoch 012:    524 / 1826 loss=2.048, trans_loss=4.788, nll_loss=2.023, w2v_ctc_loss=0.805, task_loss=0, contrastive_loss=0.065, total=3956.92, n_correct=2656.83, ppl=4.07, accuracy=67.144, wps=16049.2, ups=2.03, wpb=7913.8, bsz=283.7, num_updates=20600, lr=9.85329e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=7813
2023-08-31 00:24:26 | INFO | train_inner | epoch 012:    624 / 1826 loss=2.052, trans_loss=4.795, nll_loss=2.032, w2v_ctc_loss=0.811, task_loss=0, contrastive_loss=0.065, total=3953.03, n_correct=2650.1, ppl=4.09, accuracy=67.04, wps=15676.5, ups=1.98, wpb=7906.1, bsz=280.1, num_updates=20700, lr=9.82946e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=50, gb_free=14.9, wall=7863
2023-08-31 00:25:15 | INFO | train_inner | epoch 012:    724 / 1826 loss=2.06, trans_loss=4.797, nll_loss=2.035, w2v_ctc_loss=0.813, task_loss=0, contrastive_loss=0.109, total=3952.49, n_correct=2651.06, ppl=4.1, accuracy=67.073, wps=15890.2, ups=2.01, wpb=7905, bsz=282.3, num_updates=20800, lr=9.80581e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=49, gb_free=17.4, wall=7913
2023-08-31 00:26:05 | INFO | train_inner | epoch 012:    824 / 1826 loss=2.056, trans_loss=4.8, nll_loss=2.038, w2v_ctc_loss=0.818, task_loss=0, contrastive_loss=0.053, total=3920.99, n_correct=2625.84, ppl=4.11, accuracy=66.969, wps=15814.9, ups=2.02, wpb=7842, bsz=265.2, num_updates=20900, lr=9.78232e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=49, gb_free=16.4, wall=7963
2023-08-31 00:26:55 | INFO | train_inner | epoch 012:    924 / 1826 loss=2.071, trans_loss=4.788, nll_loss=2.025, w2v_ctc_loss=0.804, task_loss=0, contrastive_loss=0.249, total=4064.59, n_correct=2730.44, ppl=4.07, accuracy=67.176, wps=16367.8, ups=2.01, wpb=8129.2, bsz=315.7, num_updates=21000, lr=9.759e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=49, gb_free=17.5, wall=8012
2023-08-31 00:27:44 | INFO | train_inner | epoch 012:   1024 / 1826 loss=2.052, trans_loss=4.778, nll_loss=2.011, w2v_ctc_loss=0.789, task_loss=0, contrastive_loss=0.203, total=4027.9, n_correct=2719.66, ppl=4.03, accuracy=67.521, wps=16352.5, ups=2.03, wpb=8055.8, bsz=307.1, num_updates=21100, lr=9.73585e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=49, gb_free=16.4, wall=8062
2023-08-31 00:28:33 | INFO | train_inner | epoch 012:   1124 / 1826 loss=2.055, trans_loss=4.791, nll_loss=2.027, w2v_ctc_loss=0.815, task_loss=0, contrastive_loss=0.079, total=3982.26, n_correct=2672.82, ppl=4.08, accuracy=67.118, wps=16033.3, ups=2.01, wpb=7964.5, bsz=286.6, num_updates=21200, lr=9.71286e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=49, gb_free=16.2, wall=8111
2023-08-31 00:29:24 | INFO | train_inner | epoch 012:   1224 / 1826 loss=2.065, trans_loss=4.803, nll_loss=2.043, w2v_ctc_loss=0.808, task_loss=0, contrastive_loss=0.171, total=3949.09, n_correct=2644.47, ppl=4.12, accuracy=66.964, wps=15551.1, ups=1.97, wpb=7898.2, bsz=285.4, num_updates=21300, lr=9.69003e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=50, gb_free=13.1, wall=8162
2023-08-31 00:30:13 | INFO | train_inner | epoch 012:   1324 / 1826 loss=2.06, trans_loss=4.798, nll_loss=2.036, w2v_ctc_loss=0.804, task_loss=0, contrastive_loss=0.16, total=3963.34, n_correct=2657.75, ppl=4.1, accuracy=67.058, wps=16108.5, ups=2.03, wpb=7926.7, bsz=290.9, num_updates=21400, lr=9.66736e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=48, gb_free=13.5, wall=8211
2023-08-31 00:31:03 | INFO | train_inner | epoch 012:   1424 / 1826 loss=2.055, trans_loss=4.795, nll_loss=2.033, w2v_ctc_loss=0.82, task_loss=0, contrastive_loss=0.058, total=3926.15, n_correct=2627.35, ppl=4.09, accuracy=66.919, wps=15900.7, ups=2.02, wpb=7852.3, bsz=267.9, num_updates=21500, lr=9.64486e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=49, gb_free=16, wall=8261
2023-08-31 00:31:52 | INFO | train_inner | epoch 012:   1524 / 1826 loss=2.079, trans_loss=4.819, nll_loss=2.065, w2v_ctc_loss=0.813, task_loss=0, contrastive_loss=0.197, total=4009.37, n_correct=2674.5, ppl=4.18, accuracy=66.706, wps=16218.8, ups=2.02, wpb=8018.7, bsz=300.2, num_updates=21600, lr=9.6225e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=49, gb_free=15.8, wall=8310
2023-08-31 00:32:42 | INFO | train_inner | epoch 012:   1624 / 1826 loss=2.063, trans_loss=4.81, nll_loss=2.051, w2v_ctc_loss=0.827, task_loss=0, contrastive_loss=0.059, total=3883.94, n_correct=2590.17, ppl=4.14, accuracy=66.689, wps=15524.3, ups=2, wpb=7767.9, bsz=262.9, num_updates=21700, lr=9.60031e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=8360
2023-08-31 00:33:32 | INFO | train_inner | epoch 012:   1724 / 1826 loss=2.063, trans_loss=4.805, nll_loss=2.046, w2v_ctc_loss=0.823, task_loss=0, contrastive_loss=0.1, total=3919.88, n_correct=2626.22, ppl=4.13, accuracy=66.997, wps=15631.1, ups=1.99, wpb=7839.8, bsz=283, num_updates=21800, lr=9.57826e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=50, gb_free=15.3, wall=8410
2023-08-31 00:34:22 | INFO | train_inner | epoch 012:   1824 / 1826 loss=2.045, trans_loss=4.786, nll_loss=2.021, w2v_ctc_loss=0.805, task_loss=0, contrastive_loss=0.057, total=3908.91, n_correct=2631.08, ppl=4.06, accuracy=67.31, wps=15931.1, ups=2.04, wpb=7817.8, bsz=269, num_updates=21900, lr=9.55637e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=48, gb_free=16.6, wall=8459
2023-08-31 00:34:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 00:35:00 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.029 | trans_loss 5.045 | nll_loss 2.308 | w2v_ctc_loss 1.48 | task_loss 0 | contrastive_loss 0.254 | total 3505.91 | n_correct 2401.36 | ppl 4.95 | accuracy 68.495 | uer 19.247 | wer 21.362 | raw_wer 21.362 | bleu 30.16 | wps 1248.2 | wpb 3505.9 | bsz 119.3 | num_updates 21902 | best_bleu 30.25
2023-08-31 00:35:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 21902 updates
2023-08-31 00:35:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.1607.pt
2023-08-31 00:35:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.1607.pt
2023-08-31 00:35:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.1607.pt (epoch 12 @ 21902 updates, score 30.16) (writing took 6.8609424349997425 seconds)
2023-08-31 00:35:07 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-31 00:35:07 | INFO | train | epoch 012 | loss 2.059 | trans_loss 4.796 | nll_loss 2.034 | w2v_ctc_loss 0.81 | task_loss 0 | contrastive_loss 0.118 | total 3956.37 | n_correct 2653.21 | ppl 4.1 | accuracy 67.062 | wps 15059.9 | ups 1.9 | wpb 7912.7 | bsz 284.8 | num_updates 21902 | lr 9.55593e-05 | gnorm 0.575 | clip 0 | loss_scale 64 | train_wall 895 | gb_free 10.9 | wall 8505
2023-08-31 00:35:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 00:35:08 | INFO | fairseq.trainer | begin training epoch 13
2023-08-31 00:35:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 00:36:03 | INFO | train_inner | epoch 013:     98 / 1826 loss=2.039, trans_loss=4.77, nll_loss=2.001, w2v_ctc_loss=0.782, task_loss=0, contrastive_loss=0.13, total=3964.32, n_correct=2683.23, ppl=4, accuracy=67.684, wps=7813, ups=0.99, wpb=7928.6, bsz=298.2, num_updates=22000, lr=9.53463e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=48, gb_free=17.7, wall=8561
2023-08-31 00:36:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 00:36:40 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.026 | trans_loss 5.045 | nll_loss 2.309 | w2v_ctc_loss 1.465 | task_loss 0 | contrastive_loss 0.258 | total 3505.91 | n_correct 2405.64 | ppl 4.96 | accuracy 68.617 | uer 19.048 | wer 21.061 | raw_wer 21.061 | bleu 30.35 | wps 1246.1 | wpb 3505.9 | bsz 119.3 | num_updates 22000 | best_bleu 30.35
2023-08-31 00:36:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 22000 updates
2023-08-31 00:36:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_13_22000.pt
2023-08-31 00:36:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_13_22000.pt
2023-08-31 00:36:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_13_22000.pt (epoch 13 @ 22000 updates, score 30.35) (writing took 13.467502346997207 seconds)
2023-08-31 00:37:44 | INFO | train_inner | epoch 013:    198 / 1826 loss=2.043, trans_loss=4.78, nll_loss=2.014, w2v_ctc_loss=0.802, task_loss=0, contrastive_loss=0.072, total=3968.9, n_correct=2678.08, ppl=4.04, accuracy=67.477, wps=7866.5, ups=0.99, wpb=7937.8, bsz=284.2, num_updates=22100, lr=9.51303e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=48, gb_free=16, wall=8662
2023-08-31 00:38:33 | INFO | train_inner | epoch 013:    298 / 1826 loss=2.035, trans_loss=4.779, nll_loss=2.011, w2v_ctc_loss=0.792, task_loss=0, contrastive_loss=0.061, total=3986, n_correct=2694.7, ppl=4.03, accuracy=67.604, wps=16190.8, ups=2.03, wpb=7972, bsz=284.1, num_updates=22200, lr=9.49158e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=49, gb_free=11.3, wall=8711
2023-08-31 00:39:24 | INFO | train_inner | epoch 013:    398 / 1826 loss=2.055, trans_loss=4.777, nll_loss=2.01, w2v_ctc_loss=0.78, task_loss=0, contrastive_loss=0.251, total=3998.65, n_correct=2697.75, ppl=4.03, accuracy=67.467, wps=15729.3, ups=1.97, wpb=7997.3, bsz=304.3, num_updates=22300, lr=9.47027e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=50, gb_free=16.8, wall=8762
2023-08-31 00:40:13 | INFO | train_inner | epoch 013:    498 / 1826 loss=2.058, trans_loss=4.773, nll_loss=2.004, w2v_ctc_loss=0.797, task_loss=0, contrastive_loss=0.269, total=3899.81, n_correct=2634.81, ppl=4.01, accuracy=67.563, wps=15805.8, ups=2.03, wpb=7799.6, bsz=284.4, num_updates=22400, lr=9.44911e-05, gnorm=0.584, clip=0, loss_scale=64, train_wall=49, gb_free=17.6, wall=8811
2023-08-31 00:41:02 | INFO | train_inner | epoch 013:    598 / 1826 loss=2.039, trans_loss=4.778, nll_loss=2.011, w2v_ctc_loss=0.796, task_loss=0, contrastive_loss=0.075, total=3901.11, n_correct=2632.74, ppl=4.03, accuracy=67.487, wps=15907.3, ups=2.04, wpb=7802.2, bsz=275.9, num_updates=22500, lr=9.42809e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=48, gb_free=16.2, wall=8860
2023-08-31 00:41:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-31 00:41:52 | INFO | train_inner | epoch 013:    699 / 1826 loss=2.047, trans_loss=4.782, nll_loss=2.017, w2v_ctc_loss=0.814, task_loss=0, contrastive_loss=0.069, total=3928.46, n_correct=2645.51, ppl=4.05, accuracy=67.342, wps=15807.3, ups=2.01, wpb=7856.9, bsz=270.9, num_updates=22600, lr=9.40721e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=49, gb_free=17.3, wall=8910
2023-08-31 00:42:42 | INFO | train_inner | epoch 013:    799 / 1826 loss=2.045, trans_loss=4.783, nll_loss=2.017, w2v_ctc_loss=0.796, task_loss=0, contrastive_loss=0.099, total=3984.41, n_correct=2684.08, ppl=4.05, accuracy=67.365, wps=16077.8, ups=2.02, wpb=7968.8, bsz=286, num_updates=22700, lr=9.38647e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=49, gb_free=17, wall=8960
2023-08-31 00:43:32 | INFO | train_inner | epoch 013:    899 / 1826 loss=2.036, trans_loss=4.773, nll_loss=2.005, w2v_ctc_loss=0.799, task_loss=0, contrastive_loss=0.056, total=3960.48, n_correct=2679.36, ppl=4.01, accuracy=67.652, wps=15688.3, ups=1.98, wpb=7921, bsz=282.4, num_updates=22800, lr=9.36586e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=50, gb_free=12.2, wall=9010
2023-08-31 00:44:21 | INFO | train_inner | epoch 013:    999 / 1826 loss=2.032, trans_loss=4.767, nll_loss=1.997, w2v_ctc_loss=0.788, task_loss=0, contrastive_loss=0.071, total=3909.32, n_correct=2643.97, ppl=3.99, accuracy=67.632, wps=16012.1, ups=2.05, wpb=7818.6, bsz=278.3, num_updates=22900, lr=9.34539e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=48, gb_free=15.7, wall=9059
2023-08-31 00:45:11 | INFO | train_inner | epoch 013:   1099 / 1826 loss=2.055, trans_loss=4.78, nll_loss=2.014, w2v_ctc_loss=0.806, task_loss=0, contrastive_loss=0.15, total=3990.21, n_correct=2689.04, ppl=4.04, accuracy=67.391, wps=16106.2, ups=2.02, wpb=7980.4, bsz=285.5, num_updates=23000, lr=9.32505e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=49, gb_free=16.7, wall=9108
2023-08-31 00:46:00 | INFO | train_inner | epoch 013:   1199 / 1826 loss=2.046, trans_loss=4.786, nll_loss=2.021, w2v_ctc_loss=0.801, task_loss=0, contrastive_loss=0.078, total=3993.59, n_correct=2691.06, ppl=4.06, accuracy=67.384, wps=16132, ups=2.02, wpb=7987.2, bsz=288.7, num_updates=23100, lr=9.30484e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=49, gb_free=16, wall=9158
2023-08-31 00:46:50 | INFO | train_inner | epoch 013:   1299 / 1826 loss=2.053, trans_loss=4.786, nll_loss=2.021, w2v_ctc_loss=0.8, task_loss=0, contrastive_loss=0.15, total=3979.84, n_correct=2681.85, ppl=4.06, accuracy=67.386, wps=16111.9, ups=2.02, wpb=7959.7, bsz=285, num_updates=23200, lr=9.28477e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=49, gb_free=15, wall=9207
2023-08-31 00:47:39 | INFO | train_inner | epoch 013:   1399 / 1826 loss=2.042, trans_loss=4.775, nll_loss=2.007, w2v_ctc_loss=0.789, task_loss=0, contrastive_loss=0.14, total=3968.45, n_correct=2683.77, ppl=4.02, accuracy=67.628, wps=16009.9, ups=2.02, wpb=7936.9, bsz=292.5, num_updates=23300, lr=9.26482e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=17.5, wall=9257
2023-08-31 00:48:29 | INFO | train_inner | epoch 013:   1499 / 1826 loss=2.033, trans_loss=4.776, nll_loss=2.009, w2v_ctc_loss=0.786, task_loss=0, contrastive_loss=0.063, total=3926.75, n_correct=2651.92, ppl=4.03, accuracy=67.535, wps=15816.9, ups=2.01, wpb=7853.5, bsz=276.5, num_updates=23400, lr=9.245e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=49, gb_free=17.5, wall=9307
2023-08-31 00:49:18 | INFO | train_inner | epoch 013:   1599 / 1826 loss=2.037, trans_loss=4.771, nll_loss=2.002, w2v_ctc_loss=0.793, task_loss=0, contrastive_loss=0.083, total=3880.79, n_correct=2620.82, ppl=4.01, accuracy=67.533, wps=15736.2, ups=2.03, wpb=7761.6, bsz=270.5, num_updates=23500, lr=9.22531e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=49, gb_free=14.8, wall=9356
2023-08-31 00:50:08 | INFO | train_inner | epoch 013:   1699 / 1826 loss=2.042, trans_loss=4.777, nll_loss=2.011, w2v_ctc_loss=0.804, task_loss=0, contrastive_loss=0.076, total=3971.14, n_correct=2680.56, ppl=4.03, accuracy=67.501, wps=15967.5, ups=2.01, wpb=7942.3, bsz=286.1, num_updates=23600, lr=9.20575e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=49, gb_free=17.1, wall=9406
2023-08-31 00:50:57 | INFO | train_inner | epoch 013:   1799 / 1826 loss=2.05, trans_loss=4.787, nll_loss=2.024, w2v_ctc_loss=0.788, task_loss=0, contrastive_loss=0.169, total=4018.64, n_correct=2705.24, ppl=4.07, accuracy=67.317, wps=16348.3, ups=2.03, wpb=8037.3, bsz=301.2, num_updates=23700, lr=9.1863e-05, gnorm=0.617, clip=0, loss_scale=32, train_wall=49, gb_free=17.6, wall=9455
2023-08-31 00:51:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 00:51:48 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.013 | trans_loss 5.042 | nll_loss 2.303 | w2v_ctc_loss 1.436 | task_loss 0 | contrastive_loss 0.251 | total 3505.91 | n_correct 2400 | ppl 4.93 | accuracy 68.456 | uer 19.306 | wer 21.226 | raw_wer 21.226 | bleu 30.36 | wps 1244.3 | wpb 3505.9 | bsz 119.3 | num_updates 23727 | best_bleu 30.36
2023-08-31 00:51:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 23727 updates
2023-08-31 00:51:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 00:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 00:52:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 13 @ 23727 updates, score 30.36) (writing took 12.930824700997618 seconds)
2023-08-31 00:52:01 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-31 00:52:01 | INFO | train | epoch 013 | loss 2.044 | trans_loss 4.778 | nll_loss 2.011 | w2v_ctc_loss 0.795 | task_loss 0 | contrastive_loss 0.115 | total 3955.96 | n_correct 2670.1 | ppl 4.03 | accuracy 67.495 | wps 14240.3 | ups 1.8 | wpb 7911.9 | bsz 284.7 | num_updates 23727 | lr 9.18108e-05 | gnorm 0.574 | clip 0 | loss_scale 32 | train_wall 892 | gb_free 12.3 | wall 9519
2023-08-31 00:52:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 00:52:02 | INFO | fairseq.trainer | begin training epoch 14
2023-08-31 00:52:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 00:52:46 | INFO | train_inner | epoch 014:     73 / 1826 loss=2.028, trans_loss=4.762, nll_loss=1.99, w2v_ctc_loss=0.79, task_loss=0, contrastive_loss=0.057, total=3899.23, n_correct=2643.78, ppl=3.97, accuracy=67.803, wps=7168.4, ups=0.92, wpb=7798.5, bsz=272.6, num_updates=23800, lr=9.16698e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=49, gb_free=16.8, wall=9564
2023-08-31 00:53:35 | INFO | train_inner | epoch 014:    173 / 1826 loss=2.023, trans_loss=4.755, nll_loss=1.981, w2v_ctc_loss=0.781, task_loss=0, contrastive_loss=0.067, total=3935.95, n_correct=2678.12, ppl=3.95, accuracy=68.043, wps=15878.4, ups=2.02, wpb=7871.9, bsz=287.7, num_updates=23900, lr=9.14779e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=49, gb_free=16.5, wall=9613
2023-08-31 00:54:25 | INFO | train_inner | epoch 014:    273 / 1826 loss=2.028, trans_loss=4.76, nll_loss=1.988, w2v_ctc_loss=0.78, task_loss=0, contrastive_loss=0.089, total=3979.38, n_correct=2705.66, ppl=3.97, accuracy=67.992, wps=16166.6, ups=2.03, wpb=7958.8, bsz=296.7, num_updates=24000, lr=9.12871e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=49, gb_free=16.2, wall=9662
2023-08-31 00:54:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 00:55:02 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.008 | trans_loss 5.03 | nll_loss 2.288 | w2v_ctc_loss 1.443 | task_loss 0 | contrastive_loss 0.256 | total 3505.91 | n_correct 2405.18 | ppl 4.88 | accuracy 68.604 | uer 19.019 | wer 21.08 | raw_wer 21.08 | bleu 30.35 | wps 1263.3 | wpb 3505.9 | bsz 119.3 | num_updates 24000 | best_bleu 30.36
2023-08-31 00:55:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 24000 updates
2023-08-31 00:55:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_14_24000.pt
2023-08-31 00:55:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_14_24000.pt
2023-08-31 00:55:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_14_24000.pt (epoch 14 @ 24000 updates, score 30.35) (writing took 7.054258036005194 seconds)
2023-08-31 00:55:59 | INFO | train_inner | epoch 014:    373 / 1826 loss=2.025, trans_loss=4.762, nll_loss=1.99, w2v_ctc_loss=0.779, task_loss=0, contrastive_loss=0.07, total=3917.42, n_correct=2655.56, ppl=3.97, accuracy=67.788, wps=8342.3, ups=1.06, wpb=7834.8, bsz=280.6, num_updates=24100, lr=9.10975e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=48, gb_free=16.5, wall=9756
2023-08-31 00:56:48 | INFO | train_inner | epoch 014:    473 / 1826 loss=2.027, trans_loss=4.761, nll_loss=1.989, w2v_ctc_loss=0.786, task_loss=0, contrastive_loss=0.07, total=3905.2, n_correct=2648.03, ppl=3.97, accuracy=67.808, wps=15921.2, ups=2.04, wpb=7810.4, bsz=273.4, num_updates=24200, lr=9.09091e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=48, gb_free=16.9, wall=9805
2023-08-31 00:57:37 | INFO | train_inner | epoch 014:    573 / 1826 loss=2.034, trans_loss=4.766, nll_loss=1.996, w2v_ctc_loss=0.787, task_loss=0, contrastive_loss=0.109, total=3930.18, n_correct=2665.24, ppl=3.99, accuracy=67.815, wps=15840.3, ups=2.02, wpb=7860.4, bsz=278.7, num_updates=24300, lr=9.07218e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=49, gb_free=12.8, wall=9855
2023-08-31 00:58:27 | INFO | train_inner | epoch 014:    673 / 1826 loss=2.041, trans_loss=4.763, nll_loss=1.992, w2v_ctc_loss=0.785, task_loss=0, contrastive_loss=0.175, total=3952.35, n_correct=2678.89, ppl=3.98, accuracy=67.78, wps=15817.3, ups=2, wpb=7904.7, bsz=293.4, num_updates=24400, lr=9.05357e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=49, gb_free=17.7, wall=9905
2023-08-31 00:59:16 | INFO | train_inner | epoch 014:    773 / 1826 loss=2.023, trans_loss=4.755, nll_loss=1.983, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.088, total=4024.53, n_correct=2738.68, ppl=3.95, accuracy=68.05, wps=16441.5, ups=2.04, wpb=8049.1, bsz=293.9, num_updates=24500, lr=9.03508e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=48, gb_free=13.2, wall=9954
2023-08-31 01:00:06 | INFO | train_inner | epoch 014:    873 / 1826 loss=2.03, trans_loss=4.764, nll_loss=1.993, w2v_ctc_loss=0.795, task_loss=0, contrastive_loss=0.053, total=3990.77, n_correct=2701.62, ppl=3.98, accuracy=67.697, wps=16096, ups=2.02, wpb=7981.5, bsz=270.1, num_updates=24600, lr=9.0167e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=49, gb_free=17.2, wall=10004
2023-08-31 01:00:56 | INFO | train_inner | epoch 014:    973 / 1826 loss=2.038, trans_loss=4.761, nll_loss=1.991, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.179, total=4049.46, n_correct=2752.92, ppl=3.97, accuracy=67.982, wps=16236.8, ups=2, wpb=8098.9, bsz=303.6, num_updates=24700, lr=8.99843e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=49, gb_free=15.9, wall=10054
2023-08-31 01:01:45 | INFO | train_inner | epoch 014:   1073 / 1826 loss=2.024, trans_loss=4.756, nll_loss=1.983, w2v_ctc_loss=0.783, task_loss=0, contrastive_loss=0.064, total=3948.34, n_correct=2680.03, ppl=3.95, accuracy=67.877, wps=15911.1, ups=2.01, wpb=7896.7, bsz=283.4, num_updates=24800, lr=8.98027e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=49, gb_free=16.5, wall=10103
2023-08-31 01:02:36 | INFO | train_inner | epoch 014:   1173 / 1826 loss=2.039, trans_loss=4.767, nll_loss=1.997, w2v_ctc_loss=0.784, task_loss=0, contrastive_loss=0.158, total=3961.44, n_correct=2681.59, ppl=3.99, accuracy=67.692, wps=15660.6, ups=1.98, wpb=7922.9, bsz=282.8, num_updates=24900, lr=8.96221e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=50, gb_free=14.8, wall=10154
2023-08-31 01:03:25 | INFO | train_inner | epoch 014:   1273 / 1826 loss=2.025, trans_loss=4.757, nll_loss=1.985, w2v_ctc_loss=0.77, task_loss=0, contrastive_loss=0.139, total=3955.89, n_correct=2690.99, ppl=3.96, accuracy=68.025, wps=16261, ups=2.06, wpb=7911.8, bsz=289.3, num_updates=25000, lr=8.94427e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=48, gb_free=17.4, wall=10202
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-08-31 01:03:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-31 01:04:15 | INFO | train_inner | epoch 014:   1374 / 1826 loss=2.063, trans_loss=4.77, nll_loss=2.002, w2v_ctc_loss=0.791, task_loss=0, contrastive_loss=0.357, total=3926.4, n_correct=2653.5, ppl=4.01, accuracy=67.581, wps=15639.3, ups=1.99, wpb=7852.8, bsz=289.2, num_updates=25100, lr=8.92644e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=50, gb_free=16.8, wall=10253
2023-08-31 01:05:04 | INFO | train_inner | epoch 014:   1474 / 1826 loss=2.031, trans_loss=4.768, nll_loss=1.999, w2v_ctc_loss=0.785, task_loss=0, contrastive_loss=0.078, total=3956.81, n_correct=2678.78, ppl=4, accuracy=67.7, wps=16067.6, ups=2.03, wpb=7913.6, bsz=280, num_updates=25200, lr=8.90871e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=49, gb_free=15.7, wall=10302
2023-08-31 01:05:54 | INFO | train_inner | epoch 014:   1574 / 1826 loss=2.025, trans_loss=4.763, nll_loss=1.991, w2v_ctc_loss=0.79, task_loss=0, contrastive_loss=0.052, total=3893.92, n_correct=2642.11, ppl=3.98, accuracy=67.852, wps=15724.2, ups=2.02, wpb=7787.8, bsz=265.4, num_updates=25300, lr=8.89108e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=49, gb_free=15.7, wall=10351
2023-08-31 01:06:44 | INFO | train_inner | epoch 014:   1674 / 1826 loss=2.029, trans_loss=4.769, nll_loss=2.001, w2v_ctc_loss=0.781, task_loss=0, contrastive_loss=0.071, total=4015.62, n_correct=2720.37, ppl=4, accuracy=67.745, wps=16024.6, ups=2, wpb=8031.2, bsz=297.5, num_updates=25400, lr=8.87357e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=50, gb_free=16.2, wall=10402
2023-08-31 01:07:33 | INFO | train_inner | epoch 014:   1774 / 1826 loss=2.031, trans_loss=4.756, nll_loss=1.985, w2v_ctc_loss=0.779, task_loss=0, contrastive_loss=0.142, total=3969.64, n_correct=2700.09, ppl=3.96, accuracy=68.019, wps=16094.8, ups=2.03, wpb=7939.3, bsz=286.7, num_updates=25500, lr=8.85615e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=49, gb_free=17, wall=10451
2023-08-31 01:07:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
2023-08-31 01:08:36 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.002 | trans_loss 5.022 | nll_loss 2.277 | w2v_ctc_loss 1.448 | task_loss 0 | contrastive_loss 0.247 | total 3505.91 | n_correct 2411.09 | ppl 4.85 | accuracy 68.772 | uer 18.549 | wer 20.498 | raw_wer 20.498 | bleu 30.8 | wps 1257 | wpb 3505.9 | bsz 119.3 | num_updates 25552 | best_bleu 30.8
2023-08-31 01:08:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 25552 updates
2023-08-31 01:08:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 01:08:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 01:08:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 14 @ 25552 updates, score 30.8) (writing took 13.121176463995653 seconds)
2023-08-31 01:08:49 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-31 01:08:49 | INFO | train | epoch 014 | loss 2.031 | trans_loss 4.762 | nll_loss 1.991 | w2v_ctc_loss 0.783 | task_loss 0 | contrastive_loss 0.113 | total 3956.09 | n_correct 2684.29 | ppl 3.98 | accuracy 67.852 | wps 14325.7 | ups 1.81 | wpb 7912.2 | bsz 284.9 | num_updates 25552 | lr 8.84713e-05 | gnorm 0.571 | clip 0 | loss_scale 32 | train_wall 893 | gb_free 17.3 | wall 10527
2023-08-31 01:08:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 01:08:50 | INFO | fairseq.trainer | begin training epoch 15
2023-08-31 01:08:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 01:09:21 | INFO | train_inner | epoch 015:     48 / 1826 loss=2.018, trans_loss=4.756, nll_loss=1.984, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.067, total=3896.19, n_correct=2655.38, ppl=3.96, accuracy=68.153, wps=7226.4, ups=0.93, wpb=7792.4, bsz=281.4, num_updates=25600, lr=8.83883e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=48, gb_free=17.5, wall=10559
2023-08-31 01:10:10 | INFO | train_inner | epoch 015:    148 / 1826 loss=2.017, trans_loss=4.747, nll_loss=1.971, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.069, total=3927.24, n_correct=2677.54, ppl=3.92, accuracy=68.179, wps=15901.5, ups=2.02, wpb=7854.5, bsz=279.7, num_updates=25700, lr=8.82162e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=49, gb_free=15.4, wall=10608
2023-08-31 01:11:00 | INFO | train_inner | epoch 015:    248 / 1826 loss=2.014, trans_loss=4.745, nll_loss=1.97, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.079, total=3950.05, n_correct=2695.59, ppl=3.92, accuracy=68.242, wps=15945.4, ups=2.02, wpb=7900.1, bsz=280.6, num_updates=25800, lr=8.80451e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=49, gb_free=17.1, wall=10658
2023-08-31 01:11:50 | INFO | train_inner | epoch 015:    348 / 1826 loss=2.013, trans_loss=4.737, nll_loss=1.959, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.088, total=3981.94, n_correct=2721.82, ppl=3.89, accuracy=68.354, wps=15848.6, ups=1.99, wpb=7963.9, bsz=285.7, num_updates=25900, lr=8.7875e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=50, gb_free=15.9, wall=10708
2023-08-31 01:12:39 | INFO | train_inner | epoch 015:    448 / 1826 loss=2.007, trans_loss=4.744, nll_loss=1.968, w2v_ctc_loss=0.764, task_loss=0, contrastive_loss=0.047, total=3884.54, n_correct=2649.52, ppl=3.91, accuracy=68.207, wps=15766.6, ups=2.03, wpb=7769.1, bsz=265.1, num_updates=26000, lr=8.77058e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=49, gb_free=11.7, wall=10757
2023-08-31 01:12:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 01:13:16 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.012 | trans_loss 5.026 | nll_loss 2.28 | w2v_ctc_loss 1.473 | task_loss 0 | contrastive_loss 0.25 | total 3505.91 | n_correct 2409.64 | ppl 4.86 | accuracy 68.731 | uer 18.662 | wer 20.551 | raw_wer 20.551 | bleu 30.87 | wps 1260.7 | wpb 3505.9 | bsz 119.3 | num_updates 26000 | best_bleu 30.87
2023-08-31 01:13:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 26000 updates
2023-08-31 01:13:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_15_26000.pt
2023-08-31 01:13:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_15_26000.pt
2023-08-31 01:13:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_15_26000.pt (epoch 15 @ 26000 updates, score 30.87) (writing took 13.484958732995437 seconds)
2023-08-31 01:14:19 | INFO | train_inner | epoch 015:    548 / 1826 loss=2.021, trans_loss=4.742, nll_loss=1.965, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.155, total=3934.61, n_correct=2682.03, ppl=3.91, accuracy=68.165, wps=7855.1, ups=1, wpb=7869.2, bsz=294.8, num_updates=26100, lr=8.75376e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=48, gb_free=16.8, wall=10857
2023-08-31 01:15:09 | INFO | train_inner | epoch 015:    648 / 1826 loss=2.016, trans_loss=4.743, nll_loss=1.967, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.073, total=3963.95, n_correct=2706.88, ppl=3.91, accuracy=68.287, wps=16158.3, ups=2.04, wpb=7927.9, bsz=292.7, num_updates=26200, lr=8.73704e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=48, gb_free=16.6, wall=10906
2023-08-31 01:15:57 | INFO | train_inner | epoch 015:    748 / 1826 loss=2.018, trans_loss=4.752, nll_loss=1.978, w2v_ctc_loss=0.776, task_loss=0, contrastive_loss=0.064, total=3889.93, n_correct=2650.56, ppl=3.94, accuracy=68.139, wps=15905.6, ups=2.04, wpb=7779.9, bsz=271.3, num_updates=26300, lr=8.72041e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=48, gb_free=16.8, wall=10955
2023-08-31 01:16:48 | INFO | train_inner | epoch 015:    848 / 1826 loss=2.015, trans_loss=4.743, nll_loss=1.967, w2v_ctc_loss=0.78, task_loss=0, contrastive_loss=0.059, total=3912.34, n_correct=2667.13, ppl=3.91, accuracy=68.172, wps=15538.2, ups=1.99, wpb=7824.7, bsz=270.8, num_updates=26400, lr=8.70388e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=50, gb_free=17.1, wall=11006
2023-08-31 01:16:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 01:17:38 | INFO | train_inner | epoch 015:    949 / 1826 loss=2.035, trans_loss=4.762, nll_loss=1.992, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.188, total=3986.99, n_correct=2707.46, ppl=3.98, accuracy=67.907, wps=15981.1, ups=2, wpb=7974, bsz=288.1, num_updates=26500, lr=8.68744e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=49, gb_free=12, wall=11056
2023-08-31 01:18:27 | INFO | train_inner | epoch 015:   1049 / 1826 loss=2.029, trans_loss=4.755, nll_loss=1.982, w2v_ctc_loss=0.771, task_loss=0, contrastive_loss=0.171, total=3984.81, n_correct=2710.87, ppl=3.95, accuracy=68.03, wps=16040.5, ups=2.01, wpb=7969.6, bsz=293.2, num_updates=26600, lr=8.6711e-05, gnorm=0.617, clip=0, loss_scale=16, train_wall=49, gb_free=14.9, wall=11105
2023-08-31 01:19:17 | INFO | train_inner | epoch 015:   1149 / 1826 loss=2.014, trans_loss=4.753, nll_loss=1.979, w2v_ctc_loss=0.77, task_loss=0, contrastive_loss=0.058, total=3977.04, n_correct=2709.04, ppl=3.94, accuracy=68.117, wps=16065.2, ups=2.02, wpb=7954.1, bsz=278.6, num_updates=26700, lr=8.65485e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=49, gb_free=12.5, wall=11155
2023-08-31 01:20:06 | INFO | train_inner | epoch 015:   1249 / 1826 loss=2.02, trans_loss=4.745, nll_loss=1.97, w2v_ctc_loss=0.771, task_loss=0, contrastive_loss=0.118, total=3973.86, n_correct=2713.43, ppl=3.92, accuracy=68.282, wps=16174.2, ups=2.04, wpb=7947.7, bsz=285.8, num_updates=26800, lr=8.63868e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=49, gb_free=16.1, wall=11204
2023-08-31 01:20:57 | INFO | train_inner | epoch 015:   1349 / 1826 loss=2.038, trans_loss=4.746, nll_loss=1.971, w2v_ctc_loss=0.764, task_loss=0, contrastive_loss=0.295, total=3976.34, n_correct=2710.89, ppl=3.92, accuracy=68.176, wps=15748.6, ups=1.98, wpb=7952.7, bsz=298.5, num_updates=26900, lr=8.62261e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=50, gb_free=17.5, wall=11254
2023-08-31 01:21:46 | INFO | train_inner | epoch 015:   1449 / 1826 loss=2.017, trans_loss=4.744, nll_loss=1.968, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.146, total=4020.69, n_correct=2746.24, ppl=3.91, accuracy=68.303, wps=16187.3, ups=2.01, wpb=8041.4, bsz=307.7, num_updates=27000, lr=8.60663e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=49, gb_free=14.7, wall=11304
2023-08-31 01:22:35 | INFO | train_inner | epoch 015:   1549 / 1826 loss=2.02, trans_loss=4.751, nll_loss=1.977, w2v_ctc_loss=0.782, task_loss=0, contrastive_loss=0.068, total=3928.65, n_correct=2676.49, ppl=3.94, accuracy=68.127, wps=16021.3, ups=2.04, wpb=7857.3, bsz=278.6, num_updates=27100, lr=8.59074e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=48, gb_free=17.3, wall=11353
2023-08-31 01:23:25 | INFO | train_inner | epoch 015:   1649 / 1826 loss=2.015, trans_loss=4.749, nll_loss=1.975, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.053, total=3972.5, n_correct=2707.01, ppl=3.93, accuracy=68.144, wps=16038.5, ups=2.02, wpb=7945, bsz=276.9, num_updates=27200, lr=8.57493e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=49, gb_free=15.3, wall=11403
2023-08-31 01:24:14 | INFO | train_inner | epoch 015:   1749 / 1826 loss=2.024, trans_loss=4.754, nll_loss=1.981, w2v_ctc_loss=0.786, task_loss=0, contrastive_loss=0.071, total=3976.02, n_correct=2704.12, ppl=3.95, accuracy=68.011, wps=16077.3, ups=2.02, wpb=7952, bsz=282, num_updates=27300, lr=8.55921e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=49, gb_free=17.7, wall=11452
2023-08-31 01:24:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 01:25:30 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.992 | trans_loss 5.019 | nll_loss 2.275 | w2v_ctc_loss 1.429 | task_loss 0 | contrastive_loss 0.246 | total 3505.91 | n_correct 2411.91 | ppl 4.84 | accuracy 68.796 | uer 18.477 | wer 20.42 | raw_wer 20.42 | bleu 30.54 | wps 1262.5 | wpb 3505.9 | bsz 119.3 | num_updates 27377 | best_bleu 30.87
2023-08-31 01:25:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 27377 updates
2023-08-31 01:25:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.5404.pt
2023-08-31 01:25:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.5404.pt
2023-08-31 01:25:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.5404.pt (epoch 15 @ 27377 updates, score 30.54) (writing took 7.751890662999358 seconds)
2023-08-31 01:25:39 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-31 01:25:39 | INFO | train | epoch 015 | loss 2.02 | trans_loss 4.748 | nll_loss 1.973 | w2v_ctc_loss 0.771 | task_loss 0 | contrastive_loss 0.11 | total 3956.39 | n_correct 2697.11 | ppl 3.93 | accuracy 68.171 | wps 14309.5 | ups 1.81 | wpb 7912.8 | bsz 284.8 | num_updates 27377 | lr 8.54716e-05 | gnorm 0.574 | clip 0 | loss_scale 16 | train_wall 893 | gb_free 15.8 | wall 11536
2023-08-31 01:25:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 01:25:39 | INFO | fairseq.trainer | begin training epoch 16
2023-08-31 01:25:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 01:25:58 | INFO | train_inner | epoch 016:     23 / 1826 loss=2.025, trans_loss=4.75, nll_loss=1.976, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.163, total=3975.21, n_correct=2711.01, ppl=3.93, accuracy=68.198, wps=7686, ups=0.97, wpb=7950.4, bsz=290.5, num_updates=27400, lr=8.54358e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=49, gb_free=16.3, wall=11556
2023-08-31 01:26:47 | INFO | train_inner | epoch 016:    123 / 1826 loss=1.996, trans_loss=4.728, nll_loss=1.947, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.068, total=4011.89, n_correct=2753.65, ppl=3.86, accuracy=68.637, wps=16188, ups=2.02, wpb=8023.8, bsz=300.8, num_updates=27500, lr=8.52803e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=49, gb_free=16.6, wall=11605
2023-08-31 01:27:37 | INFO | train_inner | epoch 016:    223 / 1826 loss=2.012, trans_loss=4.735, nll_loss=1.956, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.153, total=3965.21, n_correct=2715.96, ppl=3.88, accuracy=68.495, wps=16071.9, ups=2.03, wpb=7930.4, bsz=289.5, num_updates=27600, lr=8.51257e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=49, gb_free=15.8, wall=11655
2023-08-31 01:28:26 | INFO | train_inner | epoch 016:    323 / 1826 loss=2.009, trans_loss=4.733, nll_loss=1.954, w2v_ctc_loss=0.756, task_loss=0, contrastive_loss=0.121, total=3905.2, n_correct=2674.28, ppl=3.87, accuracy=68.48, wps=15754, ups=2.02, wpb=7810.4, bsz=278, num_updates=27700, lr=8.49719e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=49, gb_free=16, wall=11704
2023-08-31 01:29:15 | INFO | train_inner | epoch 016:    423 / 1826 loss=2.003, trans_loss=4.737, nll_loss=1.959, w2v_ctc_loss=0.756, task_loss=0, contrastive_loss=0.068, total=3984.93, n_correct=2731.21, ppl=3.89, accuracy=68.538, wps=16265.7, ups=2.04, wpb=7969.9, bsz=299.3, num_updates=27800, lr=8.48189e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=48, gb_free=17.8, wall=11753
2023-08-31 01:30:05 | INFO | train_inner | epoch 016:    523 / 1826 loss=2.01, trans_loss=4.738, nll_loss=1.96, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.105, total=3949.35, n_correct=2701.12, ppl=3.89, accuracy=68.394, wps=15940, ups=2.02, wpb=7898.7, bsz=277.3, num_updates=27900, lr=8.46668e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=49, gb_free=15.7, wall=11803
2023-08-31 01:30:55 | INFO | train_inner | epoch 016:    623 / 1826 loss=2.028, trans_loss=4.732, nll_loss=1.953, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.271, total=3937.39, n_correct=2696.14, ppl=3.87, accuracy=68.475, wps=15643.2, ups=1.99, wpb=7874.8, bsz=283.1, num_updates=28000, lr=8.45154e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=50, gb_free=14, wall=11853
2023-08-31 01:30:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 01:31:33 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.03 | trans_loss 5.02 | nll_loss 2.275 | w2v_ctc_loss 1.55 | task_loss 0 | contrastive_loss 0.242 | total 3505.91 | n_correct 2412.73 | ppl 4.84 | accuracy 68.819 | uer 18.836 | wer 20.694 | raw_wer 20.694 | bleu 30.78 | wps 1249.3 | wpb 3505.9 | bsz 119.3 | num_updates 28000 | best_bleu 30.87
2023-08-31 01:31:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 28000 updates
2023-08-31 01:31:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_16_28000.pt
2023-08-31 01:31:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_16_28000.pt
2023-08-31 01:31:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_16_28000.pt (epoch 16 @ 28000 updates, score 30.78) (writing took 8.18251278399839 seconds)
2023-08-31 01:32:31 | INFO | train_inner | epoch 016:    723 / 1826 loss=2.008, trans_loss=4.734, nll_loss=1.956, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.096, total=3963.14, n_correct=2715.5, ppl=3.88, accuracy=68.519, wps=8269.1, ups=1.04, wpb=7926.3, bsz=287.6, num_updates=28100, lr=8.43649e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=49, gb_free=15.3, wall=11949
2023-08-31 01:33:20 | INFO | train_inner | epoch 016:    823 / 1826 loss=2.005, trans_loss=4.735, nll_loss=1.956, w2v_ctc_loss=0.765, task_loss=0, contrastive_loss=0.053, total=3929.71, n_correct=2692.07, ppl=3.88, accuracy=68.506, wps=15879.2, ups=2.02, wpb=7859.4, bsz=274.4, num_updates=28200, lr=8.42152e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=49, gb_free=16.7, wall=11998
2023-08-31 01:34:10 | INFO | train_inner | epoch 016:    923 / 1826 loss=2.007, trans_loss=4.741, nll_loss=1.964, w2v_ctc_loss=0.766, task_loss=0, contrastive_loss=0.052, total=3932.85, n_correct=2688.91, ppl=3.9, accuracy=68.371, wps=16035.9, ups=2.04, wpb=7865.7, bsz=272.2, num_updates=28300, lr=8.40663e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=49, gb_free=13.3, wall=12047
2023-08-31 01:34:59 | INFO | train_inner | epoch 016:   1023 / 1826 loss=2.005, trans_loss=4.737, nll_loss=1.959, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.056, total=3929.66, n_correct=2686.92, ppl=3.89, accuracy=68.375, wps=16007.4, ups=2.04, wpb=7859.3, bsz=281.7, num_updates=28400, lr=8.39181e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=48, gb_free=12.6, wall=12097
2023-08-31 01:35:49 | INFO | train_inner | epoch 016:   1123 / 1826 loss=2.004, trans_loss=4.733, nll_loss=1.955, w2v_ctc_loss=0.761, task_loss=0, contrastive_loss=0.058, total=3988.26, n_correct=2732.52, ppl=3.88, accuracy=68.514, wps=15957.2, ups=2, wpb=7976.5, bsz=280.8, num_updates=28500, lr=8.37708e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=49, gb_free=16.4, wall=12147
2023-08-31 01:36:38 | INFO | train_inner | epoch 016:   1223 / 1826 loss=2.001, trans_loss=4.724, nll_loss=1.943, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.138, total=3963.52, n_correct=2724.93, ppl=3.85, accuracy=68.75, wps=16097.8, ups=2.03, wpb=7927, bsz=290.7, num_updates=28600, lr=8.36242e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=49, gb_free=17.2, wall=12196
2023-08-31 01:37:27 | INFO | train_inner | epoch 016:   1323 / 1826 loss=2.012, trans_loss=4.732, nll_loss=1.952, w2v_ctc_loss=0.767, task_loss=0, contrastive_loss=0.134, total=3907.39, n_correct=2675.61, ppl=3.87, accuracy=68.476, wps=15762.7, ups=2.02, wpb=7814.8, bsz=268.1, num_updates=28700, lr=8.34784e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=49, gb_free=15.1, wall=12245
2023-08-31 01:38:17 | INFO | train_inner | epoch 016:   1423 / 1826 loss=2.01, trans_loss=4.73, nll_loss=1.951, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.159, total=3965.35, n_correct=2719.09, ppl=3.87, accuracy=68.571, wps=16107.8, ups=2.03, wpb=7930.7, bsz=288, num_updates=28800, lr=8.33333e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=49, gb_free=16.6, wall=12295
2023-08-31 01:39:06 | INFO | train_inner | epoch 016:   1523 / 1826 loss=2.011, trans_loss=4.74, nll_loss=1.963, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.066, total=3946.03, n_correct=2698.18, ppl=3.9, accuracy=68.377, wps=16038.3, ups=2.03, wpb=7892.1, bsz=281.3, num_updates=28900, lr=8.3189e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=12344
2023-08-31 01:39:56 | INFO | train_inner | epoch 016:   1623 / 1826 loss=2.006, trans_loss=4.736, nll_loss=1.958, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.092, total=3992.41, n_correct=2735.74, ppl=3.89, accuracy=68.524, wps=15906.6, ups=1.99, wpb=7984.8, bsz=293.5, num_updates=29000, lr=8.30455e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=50, gb_free=14.6, wall=12394
2023-08-31 01:40:46 | INFO | train_inner | epoch 016:   1723 / 1826 loss=2.007, trans_loss=4.736, nll_loss=1.958, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.108, total=4015.55, n_correct=2752.1, ppl=3.89, accuracy=68.536, wps=16254.3, ups=2.02, wpb=8031.1, bsz=296.5, num_updates=29100, lr=8.29027e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=49, gb_free=17.3, wall=12443
2023-08-31 01:41:34 | INFO | train_inner | epoch 016:   1823 / 1826 loss=2.012, trans_loss=4.733, nll_loss=1.955, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.172, total=3968.67, n_correct=2720.23, ppl=3.88, accuracy=68.543, wps=16279.2, ups=2.05, wpb=7937.3, bsz=290.9, num_updates=29200, lr=8.27606e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=48, gb_free=16.8, wall=12492
2023-08-31 01:41:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 01:42:13 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.981 | trans_loss 5.012 | nll_loss 2.265 | w2v_ctc_loss 1.404 | task_loss 0 | contrastive_loss 0.246 | total 3505.91 | n_correct 2419.45 | ppl 4.81 | accuracy 69.011 | uer 18.351 | wer 20.243 | raw_wer 20.243 | bleu 30.95 | wps 1261.9 | wpb 3505.9 | bsz 119.3 | num_updates 29203 | best_bleu 30.95
2023-08-31 01:42:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 29203 updates
2023-08-31 01:42:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 01:42:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 01:42:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 16 @ 29203 updates, score 30.95) (writing took 11.91084133300319 seconds)
2023-08-31 01:42:25 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-31 01:42:25 | INFO | train | epoch 016 | loss 2.008 | trans_loss 4.734 | nll_loss 1.955 | w2v_ctc_loss 0.759 | task_loss 0 | contrastive_loss 0.109 | total 3956.37 | n_correct 2710.41 | ppl 3.88 | accuracy 68.507 | wps 14349 | ups 1.81 | wpb 7912.7 | bsz 284.8 | num_updates 29203 | lr 8.27563e-05 | gnorm 0.57 | clip 0 | loss_scale 32 | train_wall 892 | gb_free 16 | wall 12543
2023-08-31 01:42:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 01:42:26 | INFO | fairseq.trainer | begin training epoch 17
2023-08-31 01:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 01:43:21 | INFO | train_inner | epoch 017:     97 / 1826 loss=1.997, trans_loss=4.712, nll_loss=1.927, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.137, total=3928.4, n_correct=2709.83, ppl=3.8, accuracy=68.981, wps=7368.3, ups=0.94, wpb=7856.8, bsz=283.7, num_updates=29300, lr=8.26192e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=48, gb_free=17.7, wall=12599
2023-08-31 01:44:10 | INFO | train_inner | epoch 017:    197 / 1826 loss=1.987, trans_loss=4.703, nll_loss=1.916, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.077, total=3988.93, n_correct=2758.99, ppl=3.77, accuracy=69.166, wps=16254.5, ups=2.04, wpb=7977.9, bsz=302.4, num_updates=29400, lr=8.24786e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=16.5, wall=12648
2023-08-31 01:45:00 | INFO | train_inner | epoch 017:    297 / 1826 loss=1.995, trans_loss=4.723, nll_loss=1.941, w2v_ctc_loss=0.756, task_loss=0, contrastive_loss=0.046, total=3861.43, n_correct=2651.25, ppl=3.84, accuracy=68.66, wps=15491.4, ups=2.01, wpb=7722.9, bsz=260.6, num_updates=29500, lr=8.23387e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=49, gb_free=17.2, wall=12698
2023-08-31 01:45:49 | INFO | train_inner | epoch 017:    397 / 1826 loss=2.01, trans_loss=4.721, nll_loss=1.939, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.162, total=3958.44, n_correct=2719.03, ppl=3.83, accuracy=68.689, wps=16067.4, ups=2.03, wpb=7916.9, bsz=287.9, num_updates=29600, lr=8.21995e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=49, gb_free=13.5, wall=12747
2023-08-31 01:46:38 | INFO | train_inner | epoch 017:    497 / 1826 loss=2.004, trans_loss=4.724, nll_loss=1.942, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.161, total=4001.44, n_correct=2752.61, ppl=3.84, accuracy=68.79, wps=16334.5, ups=2.04, wpb=8002.9, bsz=300.2, num_updates=29700, lr=8.2061e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=48, gb_free=16.6, wall=12796
2023-08-31 01:47:28 | INFO | train_inner | epoch 017:    597 / 1826 loss=2.003, trans_loss=4.722, nll_loss=1.94, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.185, total=3977.51, n_correct=2736.23, ppl=3.84, accuracy=68.793, wps=16007.9, ups=2.01, wpb=7955, bsz=287.7, num_updates=29800, lr=8.19232e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=49, gb_free=16.5, wall=12846
2023-08-31 01:48:17 | INFO | train_inner | epoch 017:    697 / 1826 loss=2.002, trans_loss=4.73, nll_loss=1.95, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.076, total=3917.79, n_correct=2689.82, ppl=3.86, accuracy=68.657, wps=15883.6, ups=2.03, wpb=7835.6, bsz=278, num_updates=29900, lr=8.17861e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=49, gb_free=16.5, wall=12895
2023-08-31 01:49:07 | INFO | train_inner | epoch 017:    797 / 1826 loss=1.998, trans_loss=4.729, nll_loss=1.95, w2v_ctc_loss=0.756, task_loss=0, contrastive_loss=0.057, total=3902.07, n_correct=2682.88, ppl=3.86, accuracy=68.755, wps=15589.6, ups=2, wpb=7804.1, bsz=276.1, num_updates=30000, lr=8.16497e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=49, gb_free=16.1, wall=12945
2023-08-31 01:49:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 01:49:45 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.012 | trans_loss 5.017 | nll_loss 2.27 | w2v_ctc_loss 1.49 | task_loss 0 | contrastive_loss 0.25 | total 3505.91 | n_correct 2418.73 | ppl 4.82 | accuracy 68.99 | uer 18.643 | wer 20.72 | raw_wer 20.72 | bleu 30.82 | wps 1241.3 | wpb 3505.9 | bsz 119.3 | num_updates 30000 | best_bleu 30.95
2023-08-31 01:49:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 30000 updates
2023-08-31 01:49:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_17_30000.pt
2023-08-31 01:49:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_17_30000.pt
2023-08-31 01:49:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_17_30000.pt (epoch 17 @ 30000 updates, score 30.82) (writing took 6.688684756998555 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-08-31 01:50:41 | INFO | train_inner | epoch 017:    897 / 1826 loss=1.996, trans_loss=4.725, nll_loss=1.944, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.052, total=3981.01, n_correct=2733.83, ppl=3.85, accuracy=68.672, wps=8453.5, ups=1.06, wpb=7962, bsz=277.5, num_updates=30100, lr=8.15139e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=48, gb_free=16.5, wall=13039
2023-08-31 01:51:31 | INFO | train_inner | epoch 017:    997 / 1826 loss=1.998, trans_loss=4.724, nll_loss=1.942, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.1, total=3999.96, n_correct=2752.65, ppl=3.84, accuracy=68.817, wps=16265, ups=2.03, wpb=7999.9, bsz=288.6, num_updates=30200, lr=8.13788e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=49, gb_free=16.8, wall=13089
2023-08-31 01:52:20 | INFO | train_inner | epoch 017:   1097 / 1826 loss=1.996, trans_loss=4.725, nll_loss=1.943, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.059, total=3926.87, n_correct=2697.78, ppl=3.85, accuracy=68.701, wps=16039.2, ups=2.04, wpb=7853.7, bsz=272.3, num_updates=30300, lr=8.12444e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=48, gb_free=17.1, wall=13137
2023-08-31 01:53:09 | INFO | train_inner | epoch 017:   1197 / 1826 loss=1.99, trans_loss=4.72, nll_loss=1.937, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.066, total=3954.16, n_correct=2721.63, ppl=3.83, accuracy=68.83, wps=16166, ups=2.04, wpb=7908.3, bsz=284.2, num_updates=30400, lr=8.11107e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=48, gb_free=12.7, wall=13186
2023-08-31 01:53:58 | INFO | train_inner | epoch 017:   1297 / 1826 loss=1.998, trans_loss=4.722, nll_loss=1.941, w2v_ctc_loss=0.76, task_loss=0, contrastive_loss=0.062, total=3980.83, n_correct=2736.44, ppl=3.84, accuracy=68.74, wps=16093.8, ups=2.02, wpb=7961.7, bsz=287.4, num_updates=30500, lr=8.09776e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=13236
2023-08-31 01:54:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-31 01:54:48 | INFO | train_inner | epoch 017:   1398 / 1826 loss=1.993, trans_loss=4.717, nll_loss=1.934, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.053, total=3919.85, n_correct=2699.29, ppl=3.82, accuracy=68.862, wps=15668.5, ups=2, wpb=7839.7, bsz=276.6, num_updates=30600, lr=8.08452e-05, gnorm=0.588, clip=0, loss_scale=32, train_wall=49, gb_free=16.8, wall=13286
2023-08-31 01:55:38 | INFO | train_inner | epoch 017:   1498 / 1826 loss=2.032, trans_loss=4.738, nll_loss=1.961, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.312, total=3964.73, n_correct=2711.55, ppl=3.89, accuracy=68.392, wps=15770.1, ups=1.99, wpb=7929.5, bsz=301.2, num_updates=30700, lr=8.07134e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=50, gb_free=16.4, wall=13336
2023-08-31 01:56:28 | INFO | train_inner | epoch 017:   1598 / 1826 loss=2.013, trans_loss=4.734, nll_loss=1.956, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.169, total=3982.88, n_correct=2729.88, ppl=3.88, accuracy=68.54, wps=16119.9, ups=2.02, wpb=7965.8, bsz=294.1, num_updates=30800, lr=8.05823e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=49, gb_free=16.5, wall=13386
2023-08-31 01:57:17 | INFO | train_inner | epoch 017:   1698 / 1826 loss=1.993, trans_loss=4.724, nll_loss=1.944, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.065, total=4008.39, n_correct=2756.05, ppl=3.85, accuracy=68.757, wps=16202.9, ups=2.02, wpb=8016.8, bsz=287.6, num_updates=30900, lr=8.04518e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=49, gb_free=16, wall=13435
2023-08-31 01:58:07 | INFO | train_inner | epoch 017:   1798 / 1826 loss=1.994, trans_loss=4.72, nll_loss=1.937, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.058, total=3939.69, n_correct=2712.85, ppl=3.83, accuracy=68.859, wps=15836.7, ups=2.01, wpb=7879.4, bsz=278.3, num_updates=31000, lr=8.03219e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=49, gb_free=16.6, wall=13485
2023-08-31 01:58:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
2023-08-31 01:58:58 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.98 | trans_loss 5.005 | nll_loss 2.257 | w2v_ctc_loss 1.414 | task_loss 0 | contrastive_loss 0.25 | total 3505.91 | n_correct 2422 | ppl 4.78 | accuracy 69.083 | uer 18.286 | wer 20.239 | raw_wer 20.239 | bleu 30.58 | wps 1267.1 | wpb 3505.9 | bsz 119.3 | num_updates 31028 | best_bleu 30.95
2023-08-31 01:58:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 31028 updates
2023-08-31 01:58:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.5800.pt
2023-08-31 01:59:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.5800.pt
2023-08-31 01:59:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.5800.pt (epoch 17 @ 31028 updates, score 30.58) (writing took 6.57542972999363 seconds)
2023-08-31 01:59:05 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-31 01:59:05 | INFO | train | epoch 017 | loss 2 | trans_loss 4.723 | nll_loss 1.941 | w2v_ctc_loss 0.75 | task_loss 0 | contrastive_loss 0.106 | total 3956.43 | n_correct 2720.56 | ppl 3.84 | accuracy 68.763 | wps 14443.6 | ups 1.83 | wpb 7912.9 | bsz 284.9 | num_updates 31028 | lr 8.02857e-05 | gnorm 0.569 | clip 0 | loss_scale 32 | train_wall 892 | gb_free 14.1 | wall 13543
2023-08-31 01:59:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 01:59:06 | INFO | fairseq.trainer | begin training epoch 18
2023-08-31 01:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 01:59:48 | INFO | train_inner | epoch 018:     72 / 1826 loss=1.986, trans_loss=4.704, nll_loss=1.917, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.092, total=4008.34, n_correct=2775.9, ppl=3.78, accuracy=69.253, wps=7902.9, ups=0.99, wpb=8016.7, bsz=299.9, num_updates=31100, lr=8.01927e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=49, gb_free=15.5, wall=13586
2023-08-31 02:00:38 | INFO | train_inner | epoch 018:    172 / 1826 loss=1.986, trans_loss=4.703, nll_loss=1.916, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.134, total=4007.42, n_correct=2776.57, ppl=3.77, accuracy=69.286, wps=16130, ups=2.01, wpb=8014.8, bsz=302.5, num_updates=31200, lr=8.00641e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=17.2, wall=13636
2023-08-31 02:01:27 | INFO | train_inner | epoch 018:    272 / 1826 loss=1.973, trans_loss=4.701, nll_loss=1.914, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.054, total=3995.78, n_correct=2768.9, ppl=3.77, accuracy=69.296, wps=16307.2, ups=2.04, wpb=7991.6, bsz=288.8, num_updates=31300, lr=7.99361e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=48, gb_free=14, wall=13685
2023-08-31 02:02:17 | INFO | train_inner | epoch 018:    372 / 1826 loss=1.984, trans_loss=4.693, nll_loss=1.902, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.134, total=3958.9, n_correct=2743.1, ppl=3.74, accuracy=69.289, wps=15990.1, ups=2.02, wpb=7917.8, bsz=279.8, num_updates=31400, lr=7.98087e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=49, gb_free=17, wall=13735
2023-08-31 02:03:06 | INFO | train_inner | epoch 018:    472 / 1826 loss=1.998, trans_loss=4.709, nll_loss=1.923, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.143, total=3967.38, n_correct=2742.12, ppl=3.79, accuracy=69.117, wps=16043.4, ups=2.02, wpb=7934.8, bsz=289, num_updates=31500, lr=7.96819e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=49, gb_free=17.8, wall=13784
2023-08-31 02:03:56 | INFO | train_inner | epoch 018:    572 / 1826 loss=1.986, trans_loss=4.709, nll_loss=1.923, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.072, total=3990.39, n_correct=2757.75, ppl=3.79, accuracy=69.11, wps=16022.1, ups=2.01, wpb=7980.8, bsz=293, num_updates=31600, lr=7.95557e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=49, gb_free=13.4, wall=13834
2023-08-31 02:04:46 | INFO | train_inner | epoch 018:    672 / 1826 loss=1.994, trans_loss=4.714, nll_loss=1.93, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.097, total=3917.45, n_correct=2695.83, ppl=3.81, accuracy=68.816, wps=15759.6, ups=2.01, wpb=7834.9, bsz=272.5, num_updates=31700, lr=7.94301e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=49, gb_free=15.7, wall=13884
2023-08-31 02:05:35 | INFO | train_inner | epoch 018:    772 / 1826 loss=1.987, trans_loss=4.714, nll_loss=1.929, w2v_ctc_loss=0.732, task_loss=0, contrastive_loss=0.086, total=3952.82, n_correct=2724.24, ppl=3.81, accuracy=68.919, wps=16036, ups=2.03, wpb=7905.6, bsz=278.3, num_updates=31800, lr=7.93052e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=49, gb_free=16.8, wall=13933
2023-08-31 02:06:24 | INFO | train_inner | epoch 018:    872 / 1826 loss=1.979, trans_loss=4.704, nll_loss=1.917, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.057, total=3966.85, n_correct=2747.5, ppl=3.78, accuracy=69.262, wps=16176, ups=2.04, wpb=7933.7, bsz=280.9, num_updates=31900, lr=7.91808e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=48, gb_free=15.9, wall=13982
2023-08-31 02:07:13 | INFO | train_inner | epoch 018:    972 / 1826 loss=1.995, trans_loss=4.713, nll_loss=1.929, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.093, total=3939.06, n_correct=2718.3, ppl=3.81, accuracy=69.009, wps=16031.5, ups=2.03, wpb=7878.1, bsz=289.3, num_updates=32000, lr=7.90569e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=48, gb_free=16.6, wall=14031
2023-08-31 02:07:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 02:07:51 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.979 | trans_loss 5.008 | nll_loss 2.262 | w2v_ctc_loss 1.405 | task_loss 0 | contrastive_loss 0.247 | total 3505.91 | n_correct 2419.27 | ppl 4.8 | accuracy 69.006 | uer 18.538 | wer 20.431 | raw_wer 20.431 | bleu 30.72 | wps 1237.4 | wpb 3505.9 | bsz 119.3 | num_updates 32000 | best_bleu 30.95
2023-08-31 02:07:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 32000 updates
2023-08-31 02:07:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_18_32000.pt
2023-08-31 02:07:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_18_32000.pt
2023-08-31 02:07:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_18_32000.pt (epoch 18 @ 32000 updates, score 30.72) (writing took 7.169093035001424 seconds)
2023-08-31 02:08:49 | INFO | train_inner | epoch 018:   1072 / 1826 loss=2.008, trans_loss=4.713, nll_loss=1.929, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.267, total=4016.89, n_correct=2769.81, ppl=3.81, accuracy=68.954, wps=8385.1, ups=1.04, wpb=8033.8, bsz=303.7, num_updates=32100, lr=7.89337e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=50, gb_free=16.5, wall=14127
2023-08-31 02:09:38 | INFO | train_inner | epoch 018:   1172 / 1826 loss=1.979, trans_loss=4.705, nll_loss=1.918, w2v_ctc_loss=0.737, task_loss=0, contrastive_loss=0.047, total=3946.42, n_correct=2729.64, ppl=3.78, accuracy=69.167, wps=15949.6, ups=2.02, wpb=7892.8, bsz=279.5, num_updates=32200, lr=7.8811e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=49, gb_free=17.1, wall=14176
2023-08-31 02:10:27 | INFO | train_inner | epoch 018:   1272 / 1826 loss=1.985, trans_loss=4.71, nll_loss=1.925, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.05, total=3987.05, n_correct=2751.58, ppl=3.8, accuracy=69.013, wps=16322.4, ups=2.05, wpb=7974.1, bsz=281.8, num_updates=32300, lr=7.86889e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=48, gb_free=16.6, wall=14225
2023-08-31 02:11:17 | INFO | train_inner | epoch 018:   1372 / 1826 loss=1.987, trans_loss=4.719, nll_loss=1.937, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.067, total=3961.58, n_correct=2731.67, ppl=3.83, accuracy=68.954, wps=16090.3, ups=2.03, wpb=7923.2, bsz=289.3, num_updates=32400, lr=7.85674e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=49, gb_free=14.6, wall=14274
2023-08-31 02:12:06 | INFO | train_inner | epoch 018:   1472 / 1826 loss=1.992, trans_loss=4.709, nll_loss=1.924, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.146, total=3952, n_correct=2725.4, ppl=3.8, accuracy=68.963, wps=15999.6, ups=2.02, wpb=7904, bsz=285.6, num_updates=32500, lr=7.84465e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=49, gb_free=11.5, wall=14324
2023-08-31 02:12:56 | INFO | train_inner | epoch 018:   1572 / 1826 loss=1.991, trans_loss=4.714, nll_loss=1.931, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.056, total=3829.85, n_correct=2640.12, ppl=3.81, accuracy=68.935, wps=15427, ups=2.01, wpb=7659.7, bsz=261.4, num_updates=32600, lr=7.8326e-05, gnorm=0.589, clip=0, loss_scale=64, train_wall=49, gb_free=15, wall=14373
2023-08-31 02:13:45 | INFO | train_inner | epoch 018:   1672 / 1826 loss=2.004, trans_loss=4.72, nll_loss=1.939, w2v_ctc_loss=0.76, task_loss=0, contrastive_loss=0.12, total=3921.07, n_correct=2694.51, ppl=3.83, accuracy=68.719, wps=15775.2, ups=2.01, wpb=7842.1, bsz=277.5, num_updates=32700, lr=7.82062e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=49, gb_free=16.1, wall=14423
2023-08-31 02:14:35 | INFO | train_inner | epoch 018:   1772 / 1826 loss=1.991, trans_loss=4.727, nll_loss=1.946, w2v_ctc_loss=0.744, task_loss=0, contrastive_loss=0.059, total=3901.81, n_correct=2681.34, ppl=3.85, accuracy=68.72, wps=15849, ups=2.03, wpb=7803.6, bsz=274.2, num_updates=32800, lr=7.80869e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=49, gb_free=16.6, wall=14472
2023-08-31 02:14:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-31 02:15:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 02:15:38 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.991 | trans_loss 5.002 | nll_loss 2.253 | w2v_ctc_loss 1.466 | task_loss 0 | contrastive_loss 0.242 | total 3505.91 | n_correct 2424.91 | ppl 4.77 | accuracy 69.166 | uer 18.104 | wer 19.98 | raw_wer 19.98 | bleu 30.98 | wps 1244.4 | wpb 3505.9 | bsz 119.3 | num_updates 32853 | best_bleu 30.98
2023-08-31 02:15:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 32853 updates
2023-08-31 02:15:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 02:15:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 02:15:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 18 @ 32853 updates, score 30.98) (writing took 12.519848163996357 seconds)
2023-08-31 02:15:52 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-31 02:15:52 | INFO | train | epoch 018 | loss 1.989 | trans_loss 4.711 | nll_loss 1.926 | w2v_ctc_loss 0.741 | task_loss 0 | contrastive_loss 0.099 | total 3955.28 | n_correct 2730.49 | ppl 3.8 | accuracy 69.034 | wps 14347.5 | ups 1.81 | wpb 7910.6 | bsz 284.4 | num_updates 32853 | lr 7.80239e-05 | gnorm 0.571 | clip 0 | loss_scale 32 | train_wall 891 | gb_free 16 | wall 14549
2023-08-31 02:15:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 02:15:52 | INFO | fairseq.trainer | begin training epoch 19
2023-08-31 02:15:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 02:16:22 | INFO | train_inner | epoch 019:     47 / 1826 loss=1.987, trans_loss=4.714, nll_loss=1.93, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.054, total=3903.69, n_correct=2690.4, ppl=3.81, accuracy=68.919, wps=7276.4, ups=0.93, wpb=7807.4, bsz=274.2, num_updates=32900, lr=7.79681e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=49, gb_free=14.9, wall=14580
2023-08-31 02:17:11 | INFO | train_inner | epoch 019:    147 / 1826 loss=1.969, trans_loss=4.689, nll_loss=1.897, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.066, total=4000.63, n_correct=2779.8, ppl=3.73, accuracy=69.484, wps=16169.7, ups=2.02, wpb=8001.3, bsz=293.7, num_updates=33000, lr=7.78499e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=49, gb_free=17.7, wall=14629
2023-08-31 02:18:01 | INFO | train_inner | epoch 019:    247 / 1826 loss=1.97, trans_loss=4.689, nll_loss=1.898, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.048, total=3952.29, n_correct=2743.8, ppl=3.73, accuracy=69.423, wps=15843.3, ups=2, wpb=7904.6, bsz=278, num_updates=33100, lr=7.77322e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=49, gb_free=17.6, wall=14679
2023-08-31 02:18:51 | INFO | train_inner | epoch 019:    347 / 1826 loss=1.971, trans_loss=4.694, nll_loss=1.905, w2v_ctc_loss=0.723, task_loss=0, contrastive_loss=0.056, total=3956.11, n_correct=2748.44, ppl=3.74, accuracy=69.473, wps=16037.7, ups=2.03, wpb=7912.2, bsz=285.4, num_updates=33200, lr=7.76151e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=49, gb_free=16.8, wall=14728
2023-08-31 02:19:40 | INFO | train_inner | epoch 019:    447 / 1826 loss=1.98, trans_loss=4.694, nll_loss=1.904, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.094, total=3974.51, n_correct=2756.48, ppl=3.74, accuracy=69.354, wps=16164.8, ups=2.03, wpb=7949, bsz=286.6, num_updates=33300, lr=7.74984e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=16.1, wall=14778
2023-08-31 02:20:29 | INFO | train_inner | epoch 019:    547 / 1826 loss=1.982, trans_loss=4.699, nll_loss=1.911, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.101, total=3968.12, n_correct=2749.46, ppl=3.76, accuracy=69.289, wps=16077.2, ups=2.03, wpb=7936.2, bsz=283.1, num_updates=33400, lr=7.73823e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=49, gb_free=17.4, wall=14827
2023-08-31 02:21:18 | INFO | train_inner | epoch 019:    647 / 1826 loss=1.989, trans_loss=4.701, nll_loss=1.913, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.215, total=3987.93, n_correct=2764.02, ppl=3.77, accuracy=69.31, wps=16154.8, ups=2.03, wpb=7975.9, bsz=290.7, num_updates=33500, lr=7.72667e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=49, gb_free=16.6, wall=14876
2023-08-31 02:22:08 | INFO | train_inner | epoch 019:    747 / 1826 loss=1.976, trans_loss=4.698, nll_loss=1.91, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.072, total=3986.45, n_correct=2766.1, ppl=3.76, accuracy=69.388, wps=15980.3, ups=2, wpb=7972.9, bsz=287.8, num_updates=33600, lr=7.71517e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=49, gb_free=16.4, wall=14926
2023-08-31 02:22:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 02:22:58 | INFO | train_inner | epoch 019:    848 / 1826 loss=1.994, trans_loss=4.709, nll_loss=1.923, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.146, total=3919.81, n_correct=2707.61, ppl=3.79, accuracy=69.075, wps=15747.9, ups=2.01, wpb=7839.6, bsz=281.5, num_updates=33700, lr=7.70371e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=49, gb_free=16.9, wall=14976
2023-08-31 02:23:47 | INFO | train_inner | epoch 019:    948 / 1826 loss=1.972, trans_loss=4.692, nll_loss=1.902, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.052, total=3946.39, n_correct=2739.72, ppl=3.74, accuracy=69.423, wps=16021.2, ups=2.03, wpb=7892.8, bsz=287.9, num_updates=33800, lr=7.69231e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=49, gb_free=17, wall=15025
2023-08-31 02:24:37 | INFO | train_inner | epoch 019:   1048 / 1826 loss=1.977, trans_loss=4.697, nll_loss=1.908, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.061, total=4007.03, n_correct=2777.21, ppl=3.75, accuracy=69.308, wps=16344.6, ups=2.04, wpb=8014.1, bsz=287.4, num_updates=33900, lr=7.68095e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=48, gb_free=16.5, wall=15074
2023-08-31 02:25:25 | INFO | train_inner | epoch 019:   1148 / 1826 loss=1.974, trans_loss=4.698, nll_loss=1.909, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.052, total=3879.03, n_correct=2689.57, ppl=3.76, accuracy=69.336, wps=15865.5, ups=2.05, wpb=7758.1, bsz=275.4, num_updates=34000, lr=7.66965e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=48, gb_free=16.3, wall=15123
2023-08-31 02:25:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 02:26:03 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.974 | trans_loss 4.996 | nll_loss 2.244 | w2v_ctc_loss 1.421 | task_loss 0 | contrastive_loss 0.243 | total 3505.91 | n_correct 2425.73 | ppl 4.74 | accuracy 69.19 | uer 18.05 | wer 19.853 | raw_wer 19.853 | bleu 31.67 | wps 1254.2 | wpb 3505.9 | bsz 119.3 | num_updates 34000 | best_bleu 31.67
2023-08-31 02:26:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 34000 updates
2023-08-31 02:26:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_19_34000.pt
2023-08-31 02:26:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_19_34000.pt
2023-08-31 02:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_19_34000.pt (epoch 19 @ 34000 updates, score 31.67) (writing took 12.727542579996225 seconds)
2023-08-31 02:27:06 | INFO | train_inner | epoch 019:   1248 / 1826 loss=2, trans_loss=4.699, nll_loss=1.912, w2v_ctc_loss=0.729, task_loss=0, contrastive_loss=0.285, total=4000.63, n_correct=2773.65, ppl=3.76, accuracy=69.33, wps=7966.7, ups=1, wpb=8001.3, bsz=299, num_updates=34100, lr=7.6584e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=49, gb_free=11.9, wall=15224
2023-08-31 02:27:56 | INFO | train_inner | epoch 019:   1348 / 1826 loss=1.988, trans_loss=4.7, nll_loss=1.912, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.133, total=3875.32, n_correct=2678.88, ppl=3.76, accuracy=69.127, wps=15531.6, ups=2, wpb=7750.6, bsz=274.3, num_updates=34200, lr=7.64719e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=49, gb_free=13.8, wall=15274
2023-08-31 02:28:45 | INFO | train_inner | epoch 019:   1448 / 1826 loss=1.992, trans_loss=4.703, nll_loss=1.916, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.168, total=4001.78, n_correct=2770.42, ppl=3.77, accuracy=69.23, wps=16203.6, ups=2.02, wpb=8003.6, bsz=292.7, num_updates=34300, lr=7.63604e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=49, gb_free=16.5, wall=15323
2023-08-31 02:29:34 | INFO | train_inner | epoch 019:   1548 / 1826 loss=1.992, trans_loss=4.711, nll_loss=1.926, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.121, total=3931.11, n_correct=2715.26, ppl=3.8, accuracy=69.071, wps=16066, ups=2.04, wpb=7862.2, bsz=279.8, num_updates=34400, lr=7.62493e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=48, gb_free=15.5, wall=15372
2023-08-31 02:30:23 | INFO | train_inner | epoch 019:   1648 / 1826 loss=1.975, trans_loss=4.698, nll_loss=1.911, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.05, total=3953.66, n_correct=2741.09, ppl=3.76, accuracy=69.33, wps=16055.4, ups=2.03, wpb=7907.3, bsz=280.1, num_updates=34500, lr=7.61387e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=49, gb_free=16.4, wall=15421
2023-08-31 02:31:13 | INFO | train_inner | epoch 019:   1748 / 1826 loss=1.977, trans_loss=4.708, nll_loss=1.923, w2v_ctc_loss=0.723, task_loss=0, contrastive_loss=0.072, total=3974.95, n_correct=2753.46, ppl=3.79, accuracy=69.27, wps=16054.9, ups=2.02, wpb=7949.9, bsz=290.9, num_updates=34600, lr=7.60286e-05, gnorm=0.563, clip=0, loss_scale=16, train_wall=49, gb_free=16.6, wall=15471
2023-08-31 02:31:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 02:32:29 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.971 | trans_loss 5.003 | nll_loss 2.256 | w2v_ctc_loss 1.393 | task_loss 0 | contrastive_loss 0.248 | total 3505.91 | n_correct 2426.45 | ppl 4.78 | accuracy 69.21 | uer 17.728 | wer 19.545 | raw_wer 19.545 | bleu 31 | wps 1246.9 | wpb 3505.9 | bsz 119.3 | num_updates 34678 | best_bleu 31.67
2023-08-31 02:32:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 34678 updates
2023-08-31 02:32:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.0004.pt
2023-08-31 02:32:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.0004.pt
2023-08-31 02:32:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.0004.pt (epoch 19 @ 34678 updates, score 31.0) (writing took 7.889094011996349 seconds)
2023-08-31 02:32:38 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-31 02:32:38 | INFO | train | epoch 019 | loss 1.981 | trans_loss 4.699 | nll_loss 1.911 | w2v_ctc_loss 0.731 | task_loss 0 | contrastive_loss 0.104 | total 3956.34 | n_correct 2741.73 | ppl 3.76 | accuracy 69.3 | wps 14352.6 | ups 1.81 | wpb 7912.7 | bsz 284.9 | num_updates 34678 | lr 7.5943e-05 | gnorm 0.568 | clip 0 | loss_scale 16 | train_wall 890 | gb_free 17.1 | wall 15556
2023-08-31 02:32:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 02:32:38 | INFO | fairseq.trainer | begin training epoch 20
2023-08-31 02:32:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 02:32:56 | INFO | train_inner | epoch 020:     22 / 1826 loss=1.981, trans_loss=4.703, nll_loss=1.916, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.083, total=3918.35, n_correct=2711.04, ppl=3.77, accuracy=69.188, wps=7616.9, ups=0.97, wpb=7836.7, bsz=278.2, num_updates=34700, lr=7.5919e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=49, gb_free=15.3, wall=15574
2023-08-31 02:33:45 | INFO | train_inner | epoch 020:    122 / 1826 loss=1.957, trans_loss=4.682, nll_loss=1.888, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.053, total=3985.48, n_correct=2777.38, ppl=3.7, accuracy=69.687, wps=16289.9, ups=2.04, wpb=7971, bsz=289.1, num_updates=34800, lr=7.58098e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=48, gb_free=15.4, wall=15623
2023-08-31 02:34:34 | INFO | train_inner | epoch 020:    222 / 1826 loss=1.964, trans_loss=4.681, nll_loss=1.887, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.047, total=4019.73, n_correct=2802.69, ppl=3.7, accuracy=69.723, wps=16291.5, ups=2.03, wpb=8039.5, bsz=284.6, num_updates=34900, lr=7.57011e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=49, gb_free=16.3, wall=15672
2023-08-31 02:35:23 | INFO | train_inner | epoch 020:    322 / 1826 loss=1.966, trans_loss=4.689, nll_loss=1.898, w2v_ctc_loss=0.712, task_loss=0, contrastive_loss=0.077, total=4025.12, n_correct=2800.13, ppl=3.73, accuracy=69.566, wps=16505.7, ups=2.05, wpb=8050.2, bsz=297.1, num_updates=35000, lr=7.55929e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=48, gb_free=13.2, wall=15721
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-08-31 02:36:13 | INFO | train_inner | epoch 020:    422 / 1826 loss=1.967, trans_loss=4.684, nll_loss=1.891, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.056, total=3991.7, n_correct=2778.42, ppl=3.71, accuracy=69.605, wps=16022.3, ups=2.01, wpb=7983.4, bsz=291, num_updates=35100, lr=7.54851e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=49, gb_free=12.4, wall=15771
2023-08-31 02:37:02 | INFO | train_inner | epoch 020:    522 / 1826 loss=1.969, trans_loss=4.687, nll_loss=1.895, w2v_ctc_loss=0.712, task_loss=0, contrastive_loss=0.126, total=3928.38, n_correct=2734.73, ppl=3.72, accuracy=69.615, wps=15791.1, ups=2.01, wpb=7856.8, bsz=281, num_updates=35200, lr=7.53778e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=49, gb_free=17, wall=15820
2023-08-31 02:37:52 | INFO | train_inner | epoch 020:    622 / 1826 loss=1.966, trans_loss=4.688, nll_loss=1.896, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.055, total=3950.3, n_correct=2747.27, ppl=3.72, accuracy=69.546, wps=15919.5, ups=2.01, wpb=7900.6, bsz=280.7, num_updates=35300, lr=7.5271e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=49, gb_free=17.2, wall=15870
2023-08-31 02:38:41 | INFO | train_inner | epoch 020:    722 / 1826 loss=1.963, trans_loss=4.682, nll_loss=1.889, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.058, total=3930.59, n_correct=2740.14, ppl=3.7, accuracy=69.713, wps=15992.8, ups=2.03, wpb=7861.2, bsz=276.2, num_updates=35400, lr=7.51646e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=48, gb_free=16.2, wall=15919
2023-08-31 02:39:31 | INFO | train_inner | epoch 020:    822 / 1826 loss=1.979, trans_loss=4.697, nll_loss=1.909, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.153, total=3918.81, n_correct=2717.95, ppl=3.75, accuracy=69.357, wps=15913.7, ups=2.03, wpb=7837.6, bsz=275.5, num_updates=35500, lr=7.50587e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=49, gb_free=15.9, wall=15968
2023-08-31 02:40:20 | INFO | train_inner | epoch 020:    922 / 1826 loss=1.985, trans_loss=4.69, nll_loss=1.9, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.144, total=3863.44, n_correct=2681.14, ppl=3.73, accuracy=69.398, wps=15652.1, ups=2.03, wpb=7726.9, bsz=274.2, num_updates=35600, lr=7.49532e-05, gnorm=0.592, clip=0, loss_scale=16, train_wall=49, gb_free=16.3, wall=16018
2023-08-31 02:41:09 | INFO | train_inner | epoch 020:   1022 / 1826 loss=1.967, trans_loss=4.692, nll_loss=1.902, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.053, total=3941.45, n_correct=2739.5, ppl=3.74, accuracy=69.505, wps=15920.7, ups=2.02, wpb=7882.9, bsz=276.8, num_updates=35700, lr=7.48481e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=49, gb_free=11.4, wall=16067
2023-08-31 02:41:59 | INFO | train_inner | epoch 020:   1122 / 1826 loss=1.978, trans_loss=4.691, nll_loss=1.901, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.173, total=3985.43, n_correct=2772.73, ppl=3.73, accuracy=69.572, wps=16063.8, ups=2.02, wpb=7970.9, bsz=294.7, num_updates=35800, lr=7.47435e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=49, gb_free=17.2, wall=16117
2023-08-31 02:42:49 | INFO | train_inner | epoch 020:   1222 / 1826 loss=1.985, trans_loss=4.699, nll_loss=1.912, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.198, total=4008.65, n_correct=2781.55, ppl=3.76, accuracy=69.389, wps=16142.9, ups=2.01, wpb=8017.3, bsz=304, num_updates=35900, lr=7.46393e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=49, gb_free=12.9, wall=16167
2023-08-31 02:43:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 02:43:39 | INFO | train_inner | epoch 020:   1323 / 1826 loss=1.993, trans_loss=4.693, nll_loss=1.904, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.262, total=4032.22, n_correct=2800.09, ppl=3.74, accuracy=69.443, wps=16080.4, ups=1.99, wpb=8064.4, bsz=307.7, num_updates=36000, lr=7.45356e-05, gnorm=0.563, clip=0, loss_scale=16, train_wall=50, gb_free=17.2, wall=16217
2023-08-31 02:43:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
2023-08-31 02:44:16 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.979 | trans_loss 4.996 | nll_loss 2.245 | w2v_ctc_loss 1.441 | task_loss 0 | contrastive_loss 0.24 | total 3505.91 | n_correct 2430.64 | ppl 4.74 | accuracy 69.33 | uer 18.023 | wer 19.905 | raw_wer 19.905 | bleu 31.31 | wps 1273.1 | wpb 3505.9 | bsz 119.3 | num_updates 36000 | best_bleu 31.67
2023-08-31 02:44:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 36000 updates
2023-08-31 02:44:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_20_36000.pt
2023-08-31 02:44:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_20_36000.pt
2023-08-31 02:44:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_20_36000.pt (epoch 20 @ 36000 updates, score 31.31) (writing took 7.68978328799858 seconds)
2023-08-31 02:45:14 | INFO | train_inner | epoch 020:   1423 / 1826 loss=1.972, trans_loss=4.684, nll_loss=1.891, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.075, total=3880.39, n_correct=2700.64, ppl=3.71, accuracy=69.597, wps=8192.7, ups=1.06, wpb=7760.8, bsz=273.1, num_updates=36100, lr=7.44323e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=49, gb_free=16.5, wall=16311
2023-08-31 02:46:04 | INFO | train_inner | epoch 020:   1523 / 1826 loss=1.974, trans_loss=4.693, nll_loss=1.902, w2v_ctc_loss=0.737, task_loss=0, contrastive_loss=0.05, total=3895.33, n_correct=2701.57, ppl=3.74, accuracy=69.354, wps=15502.7, ups=1.99, wpb=7790.7, bsz=261.2, num_updates=36200, lr=7.43294e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=50, gb_free=15.3, wall=16362
2023-08-31 02:46:53 | INFO | train_inner | epoch 020:   1623 / 1826 loss=1.968, trans_loss=4.687, nll_loss=1.896, w2v_ctc_loss=0.729, task_loss=0, contrastive_loss=0.054, total=3977.06, n_correct=2768.47, ppl=3.72, accuracy=69.611, wps=16082.8, ups=2.02, wpb=7954.1, bsz=282.8, num_updates=36300, lr=7.4227e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=49, gb_free=16.5, wall=16411
2023-08-31 02:47:42 | INFO | train_inner | epoch 020:   1723 / 1826 loss=1.973, trans_loss=4.691, nll_loss=1.901, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.054, total=3941.58, n_correct=2733.27, ppl=3.73, accuracy=69.345, wps=16086.1, ups=2.04, wpb=7883.2, bsz=281.7, num_updates=36400, lr=7.41249e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=49, gb_free=16.1, wall=16460
2023-08-31 02:48:31 | INFO | train_inner | epoch 020:   1823 / 1826 loss=1.98, trans_loss=4.701, nll_loss=1.915, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.124, total=3961.06, n_correct=2748.81, ppl=3.77, accuracy=69.396, wps=16163.4, ups=2.04, wpb=7922.1, bsz=295.1, num_updates=36500, lr=7.40233e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=48, gb_free=17.2, wall=16509
2023-08-31 02:48:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 02:49:10 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.976 | trans_loss 4.996 | nll_loss 2.245 | w2v_ctc_loss 1.431 | task_loss 0 | contrastive_loss 0.241 | total 3505.91 | n_correct 2433.82 | ppl 4.74 | accuracy 69.42 | uer 17.822 | wer 19.733 | raw_wer 19.733 | bleu 31.35 | wps 1238.4 | wpb 3505.9 | bsz 119.3 | num_updates 36503 | best_bleu 31.67
2023-08-31 02:49:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 36503 updates
2023-08-31 02:49:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.3509.pt
2023-08-31 02:49:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.3509.pt
2023-08-31 02:49:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.3509.pt (epoch 20 @ 36503 updates, score 31.35) (writing took 7.684614395002427 seconds)
2023-08-31 02:49:18 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-31 02:49:18 | INFO | train | epoch 020 | loss 1.973 | trans_loss 4.689 | nll_loss 1.899 | w2v_ctc_loss 0.721 | task_loss 0 | contrastive_loss 0.102 | total 3956.44 | n_correct 2750.59 | ppl 3.73 | accuracy 69.522 | wps 14430.3 | ups 1.82 | wpb 7912.9 | bsz 284.9 | num_updates 36503 | lr 7.40203e-05 | gnorm 0.571 | clip 0 | loss_scale 16 | train_wall 891 | gb_free 15.8 | wall 16556
2023-08-31 02:49:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 02:49:19 | INFO | fairseq.trainer | begin training epoch 21
2023-08-31 02:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 02:50:14 | INFO | train_inner | epoch 021:     97 / 1826 loss=1.968, trans_loss=4.684, nll_loss=1.891, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.105, total=3944.57, n_correct=2749.23, ppl=3.71, accuracy=69.697, wps=7673.9, ups=0.97, wpb=7889.1, bsz=286.1, num_updates=36600, lr=7.39221e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=49, gb_free=16.1, wall=16612
2023-08-31 02:51:04 | INFO | train_inner | epoch 021:    197 / 1826 loss=1.956, trans_loss=4.669, nll_loss=1.872, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.128, total=3982.15, n_correct=2789.44, ppl=3.66, accuracy=70.049, wps=16046.1, ups=2.01, wpb=7964.3, bsz=294.2, num_updates=36700, lr=7.38213e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=49, gb_free=15.7, wall=16662
2023-08-31 02:51:54 | INFO | train_inner | epoch 021:    297 / 1826 loss=1.96, trans_loss=4.679, nll_loss=1.885, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.055, total=3942.32, n_correct=2751.39, ppl=3.69, accuracy=69.791, wps=15828.2, ups=2.01, wpb=7884.6, bsz=276.2, num_updates=36800, lr=7.3721e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=49, gb_free=16.5, wall=16712
2023-08-31 02:52:43 | INFO | train_inner | epoch 021:    397 / 1826 loss=1.963, trans_loss=4.67, nll_loss=1.873, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.148, total=4050.42, n_correct=2834.45, ppl=3.66, accuracy=69.979, wps=16430.1, ups=2.03, wpb=8100.8, bsz=305.5, num_updates=36900, lr=7.3621e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=49, gb_free=13.5, wall=16761
2023-08-31 02:53:32 | INFO | train_inner | epoch 021:    497 / 1826 loss=1.963, trans_loss=4.684, nll_loss=1.891, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.048, total=3970.88, n_correct=2765.44, ppl=3.71, accuracy=69.643, wps=16239.6, ups=2.04, wpb=7941.8, bsz=279.6, num_updates=37000, lr=7.35215e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=48, gb_free=17.1, wall=16810
2023-08-31 02:54:21 | INFO | train_inner | epoch 021:    597 / 1826 loss=1.959, trans_loss=4.684, nll_loss=1.892, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.049, total=3947.71, n_correct=2751.03, ppl=3.71, accuracy=69.687, wps=16085.2, ups=2.04, wpb=7895.4, bsz=280.3, num_updates=37100, lr=7.34223e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=48, gb_free=17.3, wall=16859
2023-08-31 02:55:11 | INFO | train_inner | epoch 021:    697 / 1826 loss=1.969, trans_loss=4.675, nll_loss=1.88, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.157, total=3975.34, n_correct=2775.76, ppl=3.68, accuracy=69.824, wps=15806.2, ups=1.99, wpb=7950.7, bsz=295.4, num_updates=37200, lr=7.33236e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=50, gb_free=16.3, wall=16909
2023-08-31 02:56:01 | INFO | train_inner | epoch 021:    797 / 1826 loss=1.963, trans_loss=4.684, nll_loss=1.892, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.043, total=3944.26, n_correct=2748.77, ppl=3.71, accuracy=69.69, wps=16003, ups=2.03, wpb=7888.5, bsz=275.9, num_updates=37300, lr=7.32252e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=49, gb_free=11.1, wall=16958
2023-08-31 02:56:50 | INFO | train_inner | epoch 021:    897 / 1826 loss=1.967, trans_loss=4.669, nll_loss=1.873, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.175, total=3932.14, n_correct=2746.91, ppl=3.66, accuracy=69.858, wps=15980, ups=2.03, wpb=7864.3, bsz=285.3, num_updates=37400, lr=7.31272e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=49, gb_free=16.3, wall=17008
2023-08-31 02:57:39 | INFO | train_inner | epoch 021:    997 / 1826 loss=1.962, trans_loss=4.682, nll_loss=1.889, w2v_ctc_loss=0.719, task_loss=0, contrastive_loss=0.051, total=3922.65, n_correct=2734.31, ppl=3.7, accuracy=69.706, wps=16070.6, ups=2.05, wpb=7845.3, bsz=279, num_updates=37500, lr=7.30297e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=48, gb_free=16.8, wall=17056
2023-08-31 02:58:28 | INFO | train_inner | epoch 021:   1097 / 1826 loss=1.97, trans_loss=4.675, nll_loss=1.88, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.168, total=3947.04, n_correct=2757.74, ppl=3.68, accuracy=69.869, wps=16062.2, ups=2.03, wpb=7894.1, bsz=290.5, num_updates=37600, lr=7.29325e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=49, gb_free=16.4, wall=17106
2023-08-31 02:59:17 | INFO | train_inner | epoch 021:   1197 / 1826 loss=1.964, trans_loss=4.683, nll_loss=1.89, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.058, total=3915.98, n_correct=2729.34, ppl=3.71, accuracy=69.697, wps=15832.6, ups=2.02, wpb=7832, bsz=273.1, num_updates=37700, lr=7.28357e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=49, gb_free=13, wall=17155
2023-08-31 03:00:07 | INFO | train_inner | epoch 021:   1297 / 1826 loss=1.964, trans_loss=4.681, nll_loss=1.887, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.058, total=3945.52, n_correct=2750.65, ppl=3.7, accuracy=69.716, wps=15845.7, ups=2.01, wpb=7891, bsz=279.4, num_updates=37800, lr=7.27393e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=49, gb_free=15.6, wall=17205
2023-08-31 03:00:57 | INFO | train_inner | epoch 021:   1397 / 1826 loss=1.973, trans_loss=4.689, nll_loss=1.898, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.07, total=3939.39, n_correct=2732, ppl=3.73, accuracy=69.351, wps=15891, ups=2.02, wpb=7878.8, bsz=271.4, num_updates=37900, lr=7.26433e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=49, gb_free=16.1, wall=17254
2023-08-31 03:01:46 | INFO | train_inner | epoch 021:   1497 / 1826 loss=1.967, trans_loss=4.682, nll_loss=1.89, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.109, total=3969.73, n_correct=2765.48, ppl=3.71, accuracy=69.664, wps=16087.8, ups=2.03, wpb=7939.5, bsz=289.2, num_updates=38000, lr=7.25476e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=49, gb_free=17.7, wall=17304
2023-08-31 03:01:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 03:02:23 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.962 | trans_loss 4.996 | nll_loss 2.245 | w2v_ctc_loss 1.386 | task_loss 0 | contrastive_loss 0.237 | total 3505.91 | n_correct 2426.27 | ppl 4.74 | accuracy 69.205 | uer 17.715 | wer 19.579 | raw_wer 19.579 | bleu 31.31 | wps 1272.4 | wpb 3505.9 | bsz 119.3 | num_updates 38000 | best_bleu 31.67
2023-08-31 03:02:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 38000 updates
2023-08-31 03:02:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_21_38000.pt
2023-08-31 03:02:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_21_38000.pt
2023-08-31 03:02:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_21_38000.pt (epoch 21 @ 38000 updates, score 31.31) (writing took 7.563575861000572 seconds)
2023-08-31 03:03:21 | INFO | train_inner | epoch 021:   1597 / 1826 loss=1.964, trans_loss=4.673, nll_loss=1.878, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.141, total=3987.36, n_correct=2785.47, ppl=3.67, accuracy=69.857, wps=8412.3, ups=1.05, wpb=7974.7, bsz=293.7, num_updates=38100, lr=7.24524e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=49, gb_free=16.5, wall=17399
2023-08-31 03:04:10 | INFO | train_inner | epoch 021:   1697 / 1826 loss=1.983, trans_loss=4.695, nll_loss=1.907, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.169, total=3959.43, n_correct=2750.11, ppl=3.75, accuracy=69.457, wps=15940.8, ups=2.01, wpb=7918.9, bsz=291.6, num_updates=38200, lr=7.23575e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=49, gb_free=15.8, wall=17448
2023-08-31 03:05:00 | INFO | train_inner | epoch 021:   1797 / 1826 loss=1.966, trans_loss=4.679, nll_loss=1.886, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.07, total=3935.52, n_correct=2745.85, ppl=3.7, accuracy=69.771, wps=15803.7, ups=2.01, wpb=7871, bsz=284, num_updates=38300, lr=7.22629e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=49, gb_free=12.2, wall=17498
2023-08-31 03:05:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 03:05:52 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.967 | trans_loss 4.996 | nll_loss 2.244 | w2v_ctc_loss 1.41 | task_loss 0 | contrastive_loss 0.23 | total 3505.91 | n_correct 2432.18 | ppl 4.74 | accuracy 69.374 | uer 17.884 | wer 19.842 | raw_wer 19.842 | bleu 31.28 | wps 1240.7 | wpb 3505.9 | bsz 119.3 | num_updates 38329 | best_bleu 31.67
2023-08-31 03:05:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 38329 updates
2023-08-31 03:05:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.2803.pt
2023-08-31 03:05:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.2803.pt
2023-08-31 03:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.2803.pt (epoch 21 @ 38329 updates, score 31.28) (writing took 6.820576474005065 seconds)
2023-08-31 03:05:59 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-31 03:05:59 | INFO | train | epoch 021 | loss 1.965 | trans_loss 4.68 | nll_loss 1.886 | w2v_ctc_loss 0.714 | task_loss 0 | contrastive_loss 0.101 | total 3956.37 | n_correct 2759.19 | ppl 3.7 | accuracy 69.74 | wps 14434.3 | ups 1.82 | wpb 7912.7 | bsz 284.8 | num_updates 38329 | lr 7.22356e-05 | gnorm 0.567 | clip 0 | loss_scale 32 | train_wall 892 | gb_free 15.6 | wall 17557
2023-08-31 03:06:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 03:06:00 | INFO | fairseq.trainer | begin training epoch 22
2023-08-31 03:06:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 03:06:42 | INFO | train_inner | epoch 022:     71 / 1826 loss=1.944, trans_loss=4.666, nll_loss=1.869, w2v_ctc_loss=0.691, task_loss=0, contrastive_loss=0.051, total=3950, n_correct=2771.75, ppl=3.65, accuracy=70.171, wps=7765.2, ups=0.98, wpb=7900, bsz=287.1, num_updates=38400, lr=7.21688e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=48, gb_free=17.4, wall=17600
2023-08-31 03:07:31 | INFO | train_inner | epoch 022:    171 / 1826 loss=1.978, trans_loss=4.673, nll_loss=1.877, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.251, total=3976.01, n_correct=2772.65, ppl=3.67, accuracy=69.734, wps=16063.6, ups=2.02, wpb=7952, bsz=292.1, num_updates=38500, lr=7.2075e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=49, gb_free=16.2, wall=17649
2023-08-31 03:08:21 | INFO | train_inner | epoch 022:    271 / 1826 loss=1.949, trans_loss=4.66, nll_loss=1.861, w2v_ctc_loss=0.708, task_loss=0, contrastive_loss=0.047, total=3988.08, n_correct=2799.2, ppl=3.63, accuracy=70.189, wps=16107, ups=2.02, wpb=7976.2, bsz=291.2, num_updates=38600, lr=7.19816e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=49, gb_free=13.6, wall=17699
2023-08-31 03:09:11 | INFO | train_inner | epoch 022:    371 / 1826 loss=1.951, trans_loss=4.665, nll_loss=1.867, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.062, total=3988.94, n_correct=2795.23, ppl=3.65, accuracy=70.075, wps=16106.2, ups=2.02, wpb=7977.9, bsz=298.9, num_updates=38700, lr=7.18885e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=49, gb_free=12.6, wall=17748
2023-08-31 03:10:00 | INFO | train_inner | epoch 022:    471 / 1826 loss=1.945, trans_loss=4.662, nll_loss=1.864, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.056, total=3953.34, n_correct=2774.24, ppl=3.64, accuracy=70.175, wps=15932.3, ups=2.02, wpb=7906.7, bsz=285.4, num_updates=38800, lr=7.17958e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=49, gb_free=12.4, wall=17798
2023-08-31 03:10:50 | INFO | train_inner | epoch 022:    571 / 1826 loss=1.965, trans_loss=4.676, nll_loss=1.882, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.15, total=3939.3, n_correct=2752.72, ppl=3.69, accuracy=69.878, wps=15947.7, ups=2.02, wpb=7878.6, bsz=291.3, num_updates=38900, lr=7.17035e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=49, gb_free=17.7, wall=17847
2023-08-31 03:11:39 | INFO | train_inner | epoch 022:    671 / 1826 loss=1.965, trans_loss=4.676, nll_loss=1.881, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.155, total=3954.61, n_correct=2762.46, ppl=3.68, accuracy=69.854, wps=16094.4, ups=2.03, wpb=7909.2, bsz=277.8, num_updates=39000, lr=7.16115e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=49, gb_free=17.7, wall=17897
2023-08-31 03:12:28 | INFO | train_inner | epoch 022:    771 / 1826 loss=1.961, trans_loss=4.671, nll_loss=1.875, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.099, total=3987.22, n_correct=2786.59, ppl=3.67, accuracy=69.888, wps=16019.2, ups=2.01, wpb=7974.4, bsz=277.9, num_updates=39100, lr=7.15199e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=49, gb_free=16.9, wall=17946
2023-08-31 03:13:18 | INFO | train_inner | epoch 022:    871 / 1826 loss=1.957, trans_loss=4.674, nll_loss=1.879, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.056, total=3990.35, n_correct=2792.05, ppl=3.68, accuracy=69.97, wps=16171.2, ups=2.03, wpb=7980.7, bsz=288.1, num_updates=39200, lr=7.14286e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=49, gb_free=16.1, wall=17996
2023-08-31 03:14:07 | INFO | train_inner | epoch 022:    971 / 1826 loss=1.953, trans_loss=4.676, nll_loss=1.882, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.073, total=3975.69, n_correct=2781.59, ppl=3.69, accuracy=69.965, wps=16017.4, ups=2.01, wpb=7951.4, bsz=285, num_updates=39300, lr=7.13376e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=49, gb_free=17.3, wall=18045
2023-08-31 03:14:57 | INFO | train_inner | epoch 022:   1071 / 1826 loss=1.96, trans_loss=4.68, nll_loss=1.886, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.051, total=3976.24, n_correct=2774.65, ppl=3.7, accuracy=69.781, wps=16144.4, ups=2.03, wpb=7952.5, bsz=282, num_updates=39400, lr=7.1247e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=49, gb_free=15.4, wall=18095
2023-08-31 03:15:46 | INFO | train_inner | epoch 022:   1171 / 1826 loss=1.956, trans_loss=4.671, nll_loss=1.875, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.056, total=3951.54, n_correct=2765.81, ppl=3.67, accuracy=69.993, wps=16119.3, ups=2.04, wpb=7903.1, bsz=277.9, num_updates=39500, lr=7.11568e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=48, gb_free=16.5, wall=18144
2023-08-31 03:16:35 | INFO | train_inner | epoch 022:   1271 / 1826 loss=1.965, trans_loss=4.669, nll_loss=1.873, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.179, total=3923.28, n_correct=2742.38, ppl=3.66, accuracy=69.9, wps=15908.9, ups=2.03, wpb=7846.6, bsz=285.1, num_updates=39600, lr=7.10669e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=49, gb_free=17.7, wall=18193
2023-08-31 03:17:24 | INFO | train_inner | epoch 022:   1371 / 1826 loss=1.951, trans_loss=4.669, nll_loss=1.873, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.045, total=3918.18, n_correct=2738.18, ppl=3.66, accuracy=69.884, wps=15992.1, ups=2.04, wpb=7836.4, bsz=274.2, num_updates=39700, lr=7.09773e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=48, gb_free=17.3, wall=18242
2023-08-31 03:18:14 | INFO | train_inner | epoch 022:   1471 / 1826 loss=1.975, trans_loss=4.676, nll_loss=1.883, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.201, total=3971.13, n_correct=2771.1, ppl=3.69, accuracy=69.781, wps=15798.4, ups=1.99, wpb=7942.3, bsz=296.2, num_updates=39800, lr=7.08881e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=50, gb_free=17.7, wall=18292
2023-08-31 03:19:04 | INFO | train_inner | epoch 022:   1571 / 1826 loss=1.949, trans_loss=4.665, nll_loss=1.868, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.057, total=3949.86, n_correct=2770.91, ppl=3.65, accuracy=70.152, wps=16063.3, ups=2.03, wpb=7899.7, bsz=289.4, num_updates=39900, lr=7.07992e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=49, gb_free=13.6, wall=18341
2023-08-31 03:19:53 | INFO | train_inner | epoch 022:   1671 / 1826 loss=1.961, trans_loss=4.668, nll_loss=1.871, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.126, total=3933.48, n_correct=2752.38, ppl=3.66, accuracy=69.973, wps=16081.5, ups=2.04, wpb=7867, bsz=282.9, num_updates=40000, lr=7.07107e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=48, gb_free=16.5, wall=18390
2023-08-31 03:19:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 03:20:30 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.973 | trans_loss 4.99 | nll_loss 2.237 | w2v_ctc_loss 1.435 | task_loss 0 | contrastive_loss 0.241 | total 3505.91 | n_correct 2438.55 | ppl 4.71 | accuracy 69.555 | uer 17.833 | wer 19.692 | raw_wer 19.692 | bleu 31.42 | wps 1248.4 | wpb 3505.9 | bsz 119.3 | num_updates 40000 | best_bleu 31.67
2023-08-31 03:20:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 40000 updates
2023-08-31 03:20:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_22_40000.pt
2023-08-31 03:20:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_22_40000.pt
2023-08-31 03:20:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_22_40000.pt (epoch 22 @ 40000 updates, score 31.42) (writing took 8.211161432001973 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-08-31 03:21:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-31 03:21:28 | INFO | train_inner | epoch 022:   1772 / 1826 loss=1.957, trans_loss=4.673, nll_loss=1.878, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.075, total=3932.04, n_correct=2749.05, ppl=3.68, accuracy=69.914, wps=8217.3, ups=1.04, wpb=7864.1, bsz=272.7, num_updates=40100, lr=7.06225e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=49, gb_free=16.6, wall=18486
2023-08-31 03:21:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
2023-08-31 03:22:32 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.968 | trans_loss 4.987 | nll_loss 2.231 | w2v_ctc_loss 1.428 | task_loss 0 | contrastive_loss 0.235 | total 3505.91 | n_correct 2436.64 | ppl 4.69 | accuracy 69.501 | uer 17.68 | wer 19.654 | raw_wer 19.654 | bleu 31.62 | wps 1260.2 | wpb 3505.9 | bsz 119.3 | num_updates 40154 | best_bleu 31.67
2023-08-31 03:22:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 40154 updates
2023-08-31 03:22:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.6208.pt
2023-08-31 03:22:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.6208.pt
2023-08-31 03:22:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.6208.pt (epoch 22 @ 40154 updates, score 31.62) (writing took 7.841163153003436 seconds)
2023-08-31 03:22:40 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-31 03:22:40 | INFO | train | epoch 022 | loss 1.958 | trans_loss 4.671 | nll_loss 1.875 | w2v_ctc_loss 0.706 | task_loss 0 | contrastive_loss 0.099 | total 3956.16 | n_correct 2767.37 | ppl 3.67 | accuracy 69.951 | wps 14427.4 | ups 1.82 | wpb 7912.3 | bsz 284.8 | num_updates 40154 | lr 7.0575e-05 | gnorm 0.567 | clip 0 | loss_scale 32 | train_wall 890 | gb_free 13.2 | wall 18558
2023-08-31 03:22:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 03:22:40 | INFO | fairseq.trainer | begin training epoch 23
2023-08-31 03:22:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 03:23:11 | INFO | train_inner | epoch 023:     46 / 1826 loss=1.957, trans_loss=4.677, nll_loss=1.881, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.043, total=3889.53, n_correct=2714.49, ppl=3.68, accuracy=69.79, wps=7568.4, ups=0.97, wpb=7779.1, bsz=263.8, num_updates=40200, lr=7.05346e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=48, gb_free=15.9, wall=18589
2023-08-31 03:24:01 | INFO | train_inner | epoch 023:    146 / 1826 loss=1.953, trans_loss=4.665, nll_loss=1.867, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.13, total=3974.32, n_correct=2789.16, ppl=3.65, accuracy=70.18, wps=15973.3, ups=2.01, wpb=7948.6, bsz=294.1, num_updates=40300, lr=7.0447e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=49, gb_free=15.8, wall=18639
2023-08-31 03:24:50 | INFO | train_inner | epoch 023:    246 / 1826 loss=1.949, trans_loss=4.656, nll_loss=1.856, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.077, total=3934.29, n_correct=2764.12, ppl=3.62, accuracy=70.257, wps=16000.9, ups=2.03, wpb=7868.6, bsz=282.4, num_updates=40400, lr=7.03598e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=48, gb_free=16.3, wall=18688
2023-08-31 03:25:39 | INFO | train_inner | epoch 023:    346 / 1826 loss=1.957, trans_loss=4.664, nll_loss=1.865, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.126, total=3906.92, n_correct=2741.29, ppl=3.64, accuracy=70.165, wps=15973.7, ups=2.04, wpb=7813.8, bsz=275, num_updates=40500, lr=7.02728e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=48, gb_free=15, wall=18737
2023-08-31 03:26:28 | INFO | train_inner | epoch 023:    446 / 1826 loss=1.953, trans_loss=4.655, nll_loss=1.855, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.164, total=4007.87, n_correct=2814.9, ppl=3.62, accuracy=70.234, wps=16210.8, ups=2.02, wpb=8015.7, bsz=301.9, num_updates=40600, lr=7.01862e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=49, gb_free=16.1, wall=18786
2023-08-31 03:27:17 | INFO | train_inner | epoch 023:    546 / 1826 loss=1.949, trans_loss=4.664, nll_loss=1.865, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.074, total=3952.3, n_correct=2774.57, ppl=3.64, accuracy=70.201, wps=16105, ups=2.04, wpb=7904.6, bsz=289.4, num_updates=40700, lr=7.01e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=48, gb_free=17, wall=18835
2023-08-31 03:28:07 | INFO | train_inner | epoch 023:    646 / 1826 loss=1.945, trans_loss=4.664, nll_loss=1.867, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.044, total=3963.31, n_correct=2781.53, ppl=3.65, accuracy=70.182, wps=15909.4, ups=2.01, wpb=7926.6, bsz=281.6, num_updates=40800, lr=7.0014e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=49, gb_free=12.9, wall=18885
2023-08-31 03:28:57 | INFO | train_inner | epoch 023:    746 / 1826 loss=1.948, trans_loss=4.664, nll_loss=1.866, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.047, total=3975.41, n_correct=2787.44, ppl=3.65, accuracy=70.117, wps=16101.3, ups=2.03, wpb=7950.8, bsz=281.8, num_updates=40900, lr=6.99284e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=15.6, wall=18935
2023-08-31 03:29:46 | INFO | train_inner | epoch 023:    846 / 1826 loss=1.95, trans_loss=4.662, nll_loss=1.865, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.051, total=3993.74, n_correct=2800.47, ppl=3.64, accuracy=70.121, wps=16279.4, ups=2.04, wpb=7987.5, bsz=291.2, num_updates=41000, lr=6.9843e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=48, gb_free=16.3, wall=18984
2023-08-31 03:30:35 | INFO | train_inner | epoch 023:    946 / 1826 loss=1.949, trans_loss=4.656, nll_loss=1.856, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.116, total=3954.06, n_correct=2780.06, ppl=3.62, accuracy=70.309, wps=16058.8, ups=2.03, wpb=7908.1, bsz=285.9, num_updates=41100, lr=6.9758e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=49, gb_free=17.7, wall=19033
2023-08-31 03:31:24 | INFO | train_inner | epoch 023:   1046 / 1826 loss=1.951, trans_loss=4.665, nll_loss=1.867, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.058, total=3945.08, n_correct=2759.05, ppl=3.65, accuracy=69.936, wps=16119.7, ups=2.04, wpb=7890.2, bsz=276.4, num_updates=41200, lr=6.96733e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=48, gb_free=16.5, wall=19082
2023-08-31 03:32:14 | INFO | train_inner | epoch 023:   1146 / 1826 loss=1.958, trans_loss=4.662, nll_loss=1.864, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.109, total=3983.71, n_correct=2791.84, ppl=3.64, accuracy=70.081, wps=15926.4, ups=2, wpb=7967.4, bsz=293, num_updates=41300, lr=6.95889e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=15.6, wall=19132
2023-08-31 03:33:04 | INFO | train_inner | epoch 023:   1246 / 1826 loss=1.956, trans_loss=4.654, nll_loss=1.853, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.197, total=3933.18, n_correct=2762.59, ppl=3.61, accuracy=70.238, wps=15836.3, ups=2.01, wpb=7866.4, bsz=283.3, num_updates=41400, lr=6.95048e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=15.2, wall=19181
2023-08-31 03:33:53 | INFO | train_inner | epoch 023:   1346 / 1826 loss=1.956, trans_loss=4.674, nll_loss=1.878, w2v_ctc_loss=0.708, task_loss=0, contrastive_loss=0.066, total=3899.1, n_correct=2723.47, ppl=3.68, accuracy=69.849, wps=15688.1, ups=2.01, wpb=7798.2, bsz=271.6, num_updates=41500, lr=6.9421e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=15.5, wall=19231
2023-08-31 03:34:43 | INFO | train_inner | epoch 023:   1446 / 1826 loss=1.948, trans_loss=4.67, nll_loss=1.874, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.05, total=3992.43, n_correct=2798.2, ppl=3.67, accuracy=70.088, wps=16178.7, ups=2.03, wpb=7984.9, bsz=294.9, num_updates=41600, lr=6.93375e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=49, gb_free=16.1, wall=19281
2023-08-31 03:35:32 | INFO | train_inner | epoch 023:   1546 / 1826 loss=1.953, trans_loss=4.664, nll_loss=1.867, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.057, total=3930.04, n_correct=2750.93, ppl=3.65, accuracy=69.998, wps=16006.8, ups=2.04, wpb=7860.1, bsz=282.8, num_updates=41700, lr=6.92543e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=49, gb_free=16, wall=19330
2023-08-31 03:36:21 | INFO | train_inner | epoch 023:   1646 / 1826 loss=1.958, trans_loss=4.662, nll_loss=1.863, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.15, total=3980.48, n_correct=2795.38, ppl=3.64, accuracy=70.227, wps=16059.5, ups=2.02, wpb=7961, bsz=292, num_updates=41800, lr=6.91714e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=49, gb_free=16.4, wall=19379
2023-08-31 03:37:12 | INFO | train_inner | epoch 023:   1746 / 1826 loss=1.958, trans_loss=4.669, nll_loss=1.873, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.107, total=3964.67, n_correct=2773.44, ppl=3.66, accuracy=69.954, wps=15794.2, ups=1.99, wpb=7929.3, bsz=281.9, num_updates=41900, lr=6.90889e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=50, gb_free=17, wall=19429
2023-08-31 03:37:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 03:38:29 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.964 | trans_loss 4.987 | nll_loss 2.234 | w2v_ctc_loss 1.417 | task_loss 0 | contrastive_loss 0.232 | total 3505.91 | n_correct 2434.18 | ppl 4.7 | accuracy 69.431 | uer 17.884 | wer 19.868 | raw_wer 19.868 | bleu 31.41 | wps 1254.7 | wpb 3505.9 | bsz 119.3 | num_updates 41980 | best_bleu 31.67
2023-08-31 03:38:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 41980 updates
2023-08-31 03:38:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.4103.pt
2023-08-31 03:38:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.4103.pt
2023-08-31 03:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.4103.pt (epoch 23 @ 41980 updates, score 31.41) (writing took 7.609551863999513 seconds)
2023-08-31 03:38:37 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-31 03:38:37 | INFO | train | epoch 023 | loss 1.953 | trans_loss 4.663 | nll_loss 1.865 | w2v_ctc_loss 0.701 | task_loss 0 | contrastive_loss 0.098 | total 3956.37 | n_correct 2774.09 | ppl 3.64 | accuracy 70.117 | wps 15099.9 | ups 1.91 | wpb 7912.7 | bsz 284.8 | num_updates 41980 | lr 6.9023e-05 | gnorm 0.57 | clip 0 | loss_scale 32 | train_wall 892 | gb_free 16.5 | wall 19515
2023-08-31 03:38:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 03:38:37 | INFO | fairseq.trainer | begin training epoch 24
2023-08-31 03:38:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 03:38:55 | INFO | train_inner | epoch 024:     20 / 1826 loss=1.97, trans_loss=4.666, nll_loss=1.869, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.248, total=3952.68, n_correct=2767.27, ppl=3.65, accuracy=70.01, wps=7665, ups=0.97, wpb=7905.4, bsz=281.4, num_updates=42000, lr=6.90066e-05, gnorm=0.606, clip=0, loss_scale=32, train_wall=49, gb_free=13.3, wall=19533
2023-08-31 03:38:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 03:39:32 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.966 | trans_loss 4.987 | nll_loss 2.234 | w2v_ctc_loss 1.423 | task_loss 0 | contrastive_loss 0.233 | total 3505.91 | n_correct 2435.09 | ppl 4.7 | accuracy 69.457 | uer 17.937 | wer 19.864 | raw_wer 19.864 | bleu 31.55 | wps 1266.2 | wpb 3505.9 | bsz 119.3 | num_updates 42000 | best_bleu 31.67
2023-08-31 03:39:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 42000 updates
2023-08-31 03:39:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_24_42000.pt
2023-08-31 03:39:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_24_42000.pt
2023-08-31 03:39:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_24_42000.pt (epoch 24 @ 42000 updates, score 31.55) (writing took 8.593890744996315 seconds)
2023-08-31 03:40:30 | INFO | train_inner | epoch 024:    120 / 1826 loss=1.947, trans_loss=4.648, nll_loss=1.846, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.172, total=4034.77, n_correct=2845.59, ppl=3.59, accuracy=70.527, wps=8460.3, ups=1.05, wpb=8069.5, bsz=307.2, num_updates=42100, lr=6.89246e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=49, gb_free=17.3, wall=19628
2023-08-31 03:41:20 | INFO | train_inner | epoch 024:    220 / 1826 loss=1.969, trans_loss=4.658, nll_loss=1.859, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.291, total=4050.07, n_correct=2851.14, ppl=3.63, accuracy=70.397, wps=16319.7, ups=2.01, wpb=8100.1, bsz=314.8, num_updates=42200, lr=6.88428e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=49, gb_free=15.8, wall=19678
2023-08-31 03:42:10 | INFO | train_inner | epoch 024:    320 / 1826 loss=1.931, trans_loss=4.637, nll_loss=1.83, w2v_ctc_loss=0.69, task_loss=0, contrastive_loss=0.041, total=3901.71, n_correct=2756.59, ppl=3.56, accuracy=70.651, wps=15653.7, ups=2.01, wpb=7803.4, bsz=275.4, num_updates=42300, lr=6.87614e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=49, gb_free=16.7, wall=19727
2023-08-31 03:42:59 | INFO | train_inner | epoch 024:    420 / 1826 loss=1.93, trans_loss=4.636, nll_loss=1.83, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.044, total=3977.96, n_correct=2809.9, ppl=3.56, accuracy=70.637, wps=16052.9, ups=2.02, wpb=7955.9, bsz=283.4, num_updates=42400, lr=6.86803e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=49, gb_free=15, wall=19777
2023-08-31 03:43:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-31 03:43:49 | INFO | train_inner | epoch 024:    521 / 1826 loss=1.947, trans_loss=4.662, nll_loss=1.862, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.059, total=3899.36, n_correct=2734.77, ppl=3.64, accuracy=70.134, wps=15709.4, ups=2.01, wpb=7798.7, bsz=266.7, num_updates=42500, lr=6.85994e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=19827
2023-08-31 03:44:38 | INFO | train_inner | epoch 024:    621 / 1826 loss=1.939, trans_loss=4.653, nll_loss=1.852, w2v_ctc_loss=0.69, task_loss=0, contrastive_loss=0.052, total=4006.81, n_correct=2823.11, ppl=3.61, accuracy=70.458, wps=16353.7, ups=2.04, wpb=8013.6, bsz=295.8, num_updates=42600, lr=6.85189e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=48, gb_free=16.7, wall=19876
2023-08-31 03:45:27 | INFO | train_inner | epoch 024:    721 / 1826 loss=1.951, trans_loss=4.656, nll_loss=1.856, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.079, total=3924.23, n_correct=2752.14, ppl=3.62, accuracy=70.132, wps=15983.7, ups=2.04, wpb=7848.5, bsz=278.2, num_updates=42700, lr=6.84386e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=19925
2023-08-31 03:46:17 | INFO | train_inner | epoch 024:    821 / 1826 loss=1.956, trans_loss=4.659, nll_loss=1.859, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.165, total=3976.98, n_correct=2792.59, ppl=3.63, accuracy=70.219, wps=15939, ups=2, wpb=7954, bsz=289.8, num_updates=42800, lr=6.83586e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=49, gb_free=17, wall=19975
2023-08-31 03:47:06 | INFO | train_inner | epoch 024:    921 / 1826 loss=1.945, trans_loss=4.661, nll_loss=1.862, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.065, total=3915.33, n_correct=2749.96, ppl=3.63, accuracy=70.236, wps=15764.1, ups=2.01, wpb=7830.7, bsz=281.3, num_updates=42900, lr=6.82789e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=49, gb_free=16.2, wall=20024
2023-08-31 03:47:56 | INFO | train_inner | epoch 024:   1021 / 1826 loss=1.949, trans_loss=4.662, nll_loss=1.863, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.12, total=3931.56, n_correct=2758.23, ppl=3.64, accuracy=70.156, wps=15919.8, ups=2.02, wpb=7863.1, bsz=275.5, num_updates=43000, lr=6.81994e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=49, gb_free=15.3, wall=20074
2023-08-31 03:48:45 | INFO | train_inner | epoch 024:   1121 / 1826 loss=1.944, trans_loss=4.651, nll_loss=1.849, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.066, total=3998.21, n_correct=2811.26, ppl=3.6, accuracy=70.313, wps=16282.4, ups=2.04, wpb=7996.4, bsz=291.9, num_updates=43100, lr=6.81203e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=48, gb_free=16.5, wall=20123
2023-08-31 03:49:34 | INFO | train_inner | epoch 024:   1221 / 1826 loss=1.944, trans_loss=4.657, nll_loss=1.858, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.038, total=3888.24, n_correct=2730.47, ppl=3.62, accuracy=70.224, wps=15854, ups=2.04, wpb=7776.5, bsz=262.3, num_updates=43200, lr=6.80414e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=48, gb_free=16.3, wall=20172
2023-08-31 03:50:23 | INFO | train_inner | epoch 024:   1321 / 1826 loss=1.95, trans_loss=4.664, nll_loss=1.867, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.116, total=3953.29, n_correct=2775.07, ppl=3.65, accuracy=70.196, wps=16024.7, ups=2.03, wpb=7906.6, bsz=289.1, num_updates=43300, lr=6.79628e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=17.1, wall=20221
2023-08-31 03:51:13 | INFO | train_inner | epoch 024:   1421 / 1826 loss=1.944, trans_loss=4.664, nll_loss=1.866, w2v_ctc_loss=0.691, task_loss=0, contrastive_loss=0.057, total=3998.91, n_correct=2805.64, ppl=3.65, accuracy=70.16, wps=16003.6, ups=2, wpb=7997.8, bsz=283.3, num_updates=43400, lr=6.78844e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=20271
2023-08-31 03:52:03 | INFO | train_inner | epoch 024:   1521 / 1826 loss=1.951, trans_loss=4.657, nll_loss=1.858, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.109, total=3985.88, n_correct=2800.87, ppl=3.62, accuracy=70.27, wps=16206, ups=2.03, wpb=7971.8, bsz=298.2, num_updates=43500, lr=6.78064e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=20320
2023-08-31 03:52:51 | INFO | train_inner | epoch 024:   1621 / 1826 loss=1.939, trans_loss=4.65, nll_loss=1.849, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.045, total=3870.79, n_correct=2725.67, ppl=3.6, accuracy=70.416, wps=15830.3, ups=2.04, wpb=7741.6, bsz=267.2, num_updates=43600, lr=6.77285e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=48, gb_free=15.4, wall=20369
2023-08-31 03:53:40 | INFO | train_inner | epoch 024:   1721 / 1826 loss=1.949, trans_loss=4.661, nll_loss=1.862, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.047, total=3920.38, n_correct=2748.72, ppl=3.63, accuracy=70.114, wps=15993.6, ups=2.04, wpb=7840.8, bsz=272.1, num_updates=43700, lr=6.7651e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=48, gb_free=16.7, wall=20418
2023-08-31 03:54:29 | INFO | train_inner | epoch 024:   1821 / 1826 loss=1.941, trans_loss=4.652, nll_loss=1.851, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.063, total=3990.53, n_correct=2809.59, ppl=3.61, accuracy=70.406, wps=16303.1, ups=2.04, wpb=7981.1, bsz=294.9, num_updates=43800, lr=6.75737e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=48, gb_free=16.8, wall=20467
2023-08-31 03:54:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 03:55:09 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.959 | trans_loss 4.983 | nll_loss 2.227 | w2v_ctc_loss 1.409 | task_loss 0 | contrastive_loss 0.238 | total 3505.91 | n_correct 2442.36 | ppl 4.68 | accuracy 69.664 | uer 17.538 | wer 19.354 | raw_wer 19.354 | bleu 31.19 | wps 1257.1 | wpb 3505.9 | bsz 119.3 | num_updates 43805 | best_bleu 31.67
2023-08-31 03:55:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 43805 updates
2023-08-31 03:55:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.1907.pt
2023-08-31 03:55:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.1907.pt
2023-08-31 03:55:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.1907.pt (epoch 24 @ 43805 updates, score 31.19) (writing took 7.961893820000114 seconds)
2023-08-31 03:55:18 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-31 03:55:18 | INFO | train | epoch 024 | loss 1.946 | trans_loss 4.655 | nll_loss 1.855 | w2v_ctc_loss 0.694 | task_loss 0 | contrastive_loss 0.097 | total 3956.76 | n_correct 2782.05 | ppl 3.62 | accuracy 70.311 | wps 14436.9 | ups 1.82 | wpb 7913.5 | bsz 284.9 | num_updates 43805 | lr 6.75699e-05 | gnorm 0.569 | clip 0 | loss_scale 32 | train_wall 890 | gb_free 17.3 | wall 20515
2023-08-31 03:55:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 03:55:18 | INFO | fairseq.trainer | begin training epoch 25
2023-08-31 03:55:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 03:56:13 | INFO | train_inner | epoch 025:     95 / 1826 loss=1.935, trans_loss=4.65, nll_loss=1.847, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.055, total=3970.23, n_correct=2799.07, ppl=3.6, accuracy=70.501, wps=7692.7, ups=0.97, wpb=7940.5, bsz=291, num_updates=43900, lr=6.74967e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=49, gb_free=12.7, wall=20571
2023-08-31 03:57:02 | INFO | train_inner | epoch 025:    195 / 1826 loss=1.933, trans_loss=4.639, nll_loss=1.834, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.127, total=3982.1, n_correct=2815.72, ppl=3.56, accuracy=70.709, wps=16104.7, ups=2.02, wpb=7964.2, bsz=294.3, num_updates=44000, lr=6.742e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=49, gb_free=15.8, wall=20620
2023-08-31 03:57:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 03:57:39 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.967 | trans_loss 4.987 | nll_loss 2.233 | w2v_ctc_loss 1.423 | task_loss 0 | contrastive_loss 0.238 | total 3505.91 | n_correct 2437.18 | ppl 4.7 | accuracy 69.516 | uer 17.43 | wer 19.279 | raw_wer 19.279 | bleu 31.32 | wps 1268.5 | wpb 3505.9 | bsz 119.3 | num_updates 44000 | best_bleu 31.67
2023-08-31 03:57:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 44000 updates
2023-08-31 03:57:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_25_44000.pt
2023-08-31 03:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_25_44000.pt
2023-08-31 03:57:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_25_44000.pt (epoch 25 @ 44000 updates, score 31.32) (writing took 8.203580864996184 seconds)
2023-08-31 03:58:37 | INFO | train_inner | epoch 025:    295 / 1826 loss=1.939, trans_loss=4.645, nll_loss=1.841, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.051, total=3966.94, n_correct=2792.83, ppl=3.58, accuracy=70.403, wps=8319.6, ups=1.05, wpb=7933.9, bsz=277.6, num_updates=44100, lr=6.73435e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=15, wall=20715
2023-08-31 03:59:26 | INFO | train_inner | epoch 025:    395 / 1826 loss=1.932, trans_loss=4.646, nll_loss=1.842, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.045, total=3885.05, n_correct=2736.45, ppl=3.59, accuracy=70.435, wps=15962.7, ups=2.05, wpb=7770.1, bsz=268.2, num_updates=44200, lr=6.72673e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=48, gb_free=16.7, wall=20764
2023-08-31 04:00:16 | INFO | train_inner | epoch 025:    495 / 1826 loss=1.938, trans_loss=4.65, nll_loss=1.848, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.045, total=3898.44, n_correct=2745.81, ppl=3.6, accuracy=70.434, wps=15732.1, ups=2.02, wpb=7796.9, bsz=265.7, num_updates=44300, lr=6.71913e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=49, gb_free=17.1, wall=20814
2023-08-31 04:01:05 | INFO | train_inner | epoch 025:    595 / 1826 loss=1.951, trans_loss=4.65, nll_loss=1.848, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.163, total=3928.25, n_correct=2762.71, ppl=3.6, accuracy=70.329, wps=15825.7, ups=2.01, wpb=7856.5, bsz=282.2, num_updates=44400, lr=6.71156e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=49, gb_free=17.8, wall=20863
2023-08-31 04:01:55 | INFO | train_inner | epoch 025:    695 / 1826 loss=1.937, trans_loss=4.651, nll_loss=1.85, w2v_ctc_loss=0.69, task_loss=0, contrastive_loss=0.05, total=3959.17, n_correct=2789.61, ppl=3.6, accuracy=70.459, wps=16095.9, ups=2.03, wpb=7918.3, bsz=286.4, num_updates=44500, lr=6.70402e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=49, gb_free=14.2, wall=20912
2023-08-31 04:02:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-31 04:02:44 | INFO | train_inner | epoch 025:    796 / 1826 loss=1.944, trans_loss=4.653, nll_loss=1.852, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.077, total=3978.86, n_correct=2801.31, ppl=3.61, accuracy=70.405, wps=15991.9, ups=2.01, wpb=7957.7, bsz=297.7, num_updates=44600, lr=6.6965e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=49, gb_free=15.4, wall=20962
2023-08-31 04:03:34 | INFO | train_inner | epoch 025:    896 / 1826 loss=1.948, trans_loss=4.649, nll_loss=1.847, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.162, total=3995.97, n_correct=2813.76, ppl=3.6, accuracy=70.415, wps=16207.8, ups=2.03, wpb=7991.9, bsz=286.6, num_updates=44700, lr=6.689e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=49, gb_free=16, wall=21012
2023-08-31 04:04:23 | INFO | train_inner | epoch 025:    996 / 1826 loss=1.933, trans_loss=4.638, nll_loss=1.833, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.122, total=4046.08, n_correct=2863.58, ppl=3.56, accuracy=70.774, wps=16336.6, ups=2.02, wpb=8092.2, bsz=295.4, num_updates=44800, lr=6.68153e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=49, gb_free=17.3, wall=21061
2023-08-31 04:05:13 | INFO | train_inner | epoch 025:   1096 / 1826 loss=1.947, trans_loss=4.643, nll_loss=1.84, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.158, total=3954.45, n_correct=2792.57, ppl=3.58, accuracy=70.618, wps=15934.6, ups=2.01, wpb=7908.9, bsz=294.1, num_updates=44900, lr=6.67409e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=49, gb_free=17.7, wall=21111
2023-08-31 04:06:02 | INFO | train_inner | epoch 025:   1196 / 1826 loss=1.929, trans_loss=4.641, nll_loss=1.837, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.049, total=4002.81, n_correct=2830.18, ppl=3.57, accuracy=70.705, wps=16183.3, ups=2.02, wpb=8005.6, bsz=294.1, num_updates=45000, lr=6.66667e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=49, gb_free=17.8, wall=21160
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:0')
2023-08-31 04:06:52 | INFO | train_inner | epoch 025:   1296 / 1826 loss=1.954, trans_loss=4.646, nll_loss=1.844, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.225, total=3968.78, n_correct=2792.78, ppl=3.59, accuracy=70.369, wps=16001.1, ups=2.02, wpb=7937.6, bsz=289.8, num_updates=45100, lr=6.65927e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=21210
2023-08-31 04:07:41 | INFO | train_inner | epoch 025:   1396 / 1826 loss=1.934, trans_loss=4.639, nll_loss=1.835, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.042, total=3910.18, n_correct=2758.22, ppl=3.57, accuracy=70.539, wps=15987.7, ups=2.04, wpb=7820.4, bsz=271.7, num_updates=45200, lr=6.6519e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=48, gb_free=15.1, wall=21259
2023-08-31 04:08:30 | INFO | train_inner | epoch 025:   1496 / 1826 loss=1.932, trans_loss=4.648, nll_loss=1.846, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.04, total=3927.96, n_correct=2767.86, ppl=3.59, accuracy=70.466, wps=15984.4, ups=2.03, wpb=7855.9, bsz=273.5, num_updates=45300, lr=6.64455e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=49, gb_free=17.3, wall=21308
2023-08-31 04:09:19 | INFO | train_inner | epoch 025:   1596 / 1826 loss=1.933, trans_loss=4.646, nll_loss=1.844, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.065, total=3875.31, n_correct=2729.46, ppl=3.59, accuracy=70.432, wps=15703.7, ups=2.03, wpb=7750.6, bsz=272.1, num_updates=45400, lr=6.63723e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=21357
2023-08-31 04:10:09 | INFO | train_inner | epoch 025:   1696 / 1826 loss=1.941, trans_loss=4.651, nll_loss=1.85, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.075, total=3940.67, n_correct=2777.38, ppl=3.6, accuracy=70.48, wps=15940.6, ups=2.02, wpb=7881.3, bsz=286.7, num_updates=45500, lr=6.62994e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=49, gb_free=17.1, wall=21407
2023-08-31 04:10:58 | INFO | train_inner | epoch 025:   1796 / 1826 loss=1.954, trans_loss=4.658, nll_loss=1.859, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.172, total=4001.31, n_correct=2809.44, ppl=3.63, accuracy=70.213, wps=16189.5, ups=2.02, wpb=8002.6, bsz=297.4, num_updates=45600, lr=6.62266e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=49, gb_free=15.7, wall=21456
2023-08-31 04:11:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2418, device='cuda:2')
2023-08-31 04:11:50 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.973 | trans_loss 4.994 | nll_loss 2.241 | w2v_ctc_loss 1.424 | task_loss 0 | contrastive_loss 0.245 | total 3505.91 | n_correct 2431.73 | ppl 4.73 | accuracy 69.361 | uer 17.696 | wer 19.466 | raw_wer 19.466 | bleu 31.29 | wps 1267.3 | wpb 3505.9 | bsz 119.3 | num_updates 45630 | best_bleu 31.67
2023-08-31 04:11:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 45630 updates
2023-08-31 04:11:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.2900.pt
2023-08-31 04:11:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.2900.pt
2023-08-31 04:11:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.2900.pt (epoch 25 @ 45630 updates, score 31.29) (writing took 7.8793090309991385 seconds)
2023-08-31 04:11:58 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-31 04:11:58 | INFO | train | epoch 025 | loss 1.94 | trans_loss 4.647 | nll_loss 1.844 | w2v_ctc_loss 0.686 | task_loss 0 | contrastive_loss 0.096 | total 3956.37 | n_correct 2788.8 | ppl 3.59 | accuracy 70.489 | wps 14429.3 | ups 1.82 | wpb 7912.7 | bsz 284.8 | num_updates 45630 | lr 6.62048e-05 | gnorm 0.569 | clip 0 | loss_scale 32 | train_wall 891 | gb_free 12.5 | wall 21516
2023-08-31 04:11:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 04:11:59 | INFO | fairseq.trainer | begin training epoch 26
2023-08-31 04:11:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 04:12:41 | INFO | train_inner | epoch 026:     70 / 1826 loss=1.924, trans_loss=4.627, nll_loss=1.819, w2v_ctc_loss=0.679, task_loss=0, contrastive_loss=0.045, total=3888.8, n_correct=2754.8, ppl=3.53, accuracy=70.839, wps=7588.2, ups=0.98, wpb=7777.6, bsz=269.7, num_updates=45700, lr=6.61541e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=48, gb_free=16.3, wall=21559
2023-08-31 04:13:30 | INFO | train_inner | epoch 026:    170 / 1826 loss=1.926, trans_loss=4.631, nll_loss=1.823, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.05, total=3911.85, n_correct=2769.8, ppl=3.54, accuracy=70.805, wps=16023.9, ups=2.05, wpb=7823.7, bsz=269.2, num_updates=45800, lr=6.60819e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=48, gb_free=17.3, wall=21607
2023-08-31 04:14:19 | INFO | train_inner | epoch 026:    270 / 1826 loss=1.93, trans_loss=4.637, nll_loss=1.832, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.059, total=3959.89, n_correct=2798.91, ppl=3.56, accuracy=70.682, wps=15893.9, ups=2.01, wpb=7919.8, bsz=291.7, num_updates=45900, lr=6.60098e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=49, gb_free=14.4, wall=21657
2023-08-31 04:15:09 | INFO | train_inner | epoch 026:    370 / 1826 loss=1.93, trans_loss=4.639, nll_loss=1.834, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.068, total=3976.8, n_correct=2810.79, ppl=3.56, accuracy=70.68, wps=16106.3, ups=2.03, wpb=7953.6, bsz=289.6, num_updates=46000, lr=6.5938e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=49, gb_free=17.6, wall=21707
2023-08-31 04:15:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 04:15:46 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.963 | trans_loss 4.994 | nll_loss 2.239 | w2v_ctc_loss 1.393 | task_loss 0 | contrastive_loss 0.241 | total 3505.91 | n_correct 2434.18 | ppl 4.72 | accuracy 69.431 | uer 17.586 | wer 19.425 | raw_wer 19.425 | bleu 31.15 | wps 1244.7 | wpb 3505.9 | bsz 119.3 | num_updates 46000 | best_bleu 31.67
2023-08-31 04:15:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 46000 updates
2023-08-31 04:15:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_26_46000.pt
2023-08-31 04:15:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_26_46000.pt
2023-08-31 04:15:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_26_46000.pt (epoch 26 @ 46000 updates, score 31.15) (writing took 9.158378483996785 seconds)
2023-08-31 04:16:45 | INFO | train_inner | epoch 026:    470 / 1826 loss=1.944, trans_loss=4.638, nll_loss=1.833, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.258, total=3979.19, n_correct=2814.49, ppl=3.56, accuracy=70.73, wps=8282.6, ups=1.04, wpb=7958.4, bsz=300.5, num_updates=46100, lr=6.58665e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=48, gb_free=17.7, wall=21803
2023-08-31 04:17:35 | INFO | train_inner | epoch 026:    570 / 1826 loss=1.943, trans_loss=4.637, nll_loss=1.832, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.202, total=4025.5, n_correct=2844.09, ppl=3.56, accuracy=70.652, wps=16183.7, ups=2.01, wpb=8051, bsz=306.2, num_updates=46200, lr=6.57952e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=49, gb_free=17, wall=21853
2023-08-31 04:18:23 | INFO | train_inner | epoch 026:    670 / 1826 loss=1.936, trans_loss=4.64, nll_loss=1.835, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.12, total=3972.74, n_correct=2809.45, ppl=3.57, accuracy=70.718, wps=16284, ups=2.05, wpb=7945.5, bsz=290.6, num_updates=46300, lr=6.57241e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=48, gb_free=16.5, wall=21901
2023-08-31 04:19:13 | INFO | train_inner | epoch 026:    770 / 1826 loss=1.937, trans_loss=4.652, nll_loss=1.851, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.05, total=3918.1, n_correct=2756.7, ppl=3.61, accuracy=70.358, wps=15767.6, ups=2.01, wpb=7836.2, bsz=272.1, num_updates=46400, lr=6.56532e-05, gnorm=0.604, clip=0, loss_scale=32, train_wall=49, gb_free=16.4, wall=21951
2023-08-31 04:20:02 | INFO | train_inner | epoch 026:    870 / 1826 loss=1.932, trans_loss=4.64, nll_loss=1.836, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.087, total=3981.81, n_correct=2814.61, ppl=3.57, accuracy=70.687, wps=16176.6, ups=2.03, wpb=7963.6, bsz=293.5, num_updates=46500, lr=6.55826e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=49, gb_free=15.6, wall=22000
2023-08-31 04:20:52 | INFO | train_inner | epoch 026:    970 / 1826 loss=1.927, trans_loss=4.638, nll_loss=1.833, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.053, total=3962.21, n_correct=2801.89, ppl=3.56, accuracy=70.715, wps=15941.1, ups=2.01, wpb=7924.4, bsz=282.1, num_updates=46600, lr=6.55122e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=49, gb_free=16.1, wall=22050
2023-08-31 04:21:41 | INFO | train_inner | epoch 026:   1070 / 1826 loss=1.935, trans_loss=4.634, nll_loss=1.828, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.134, total=3950, n_correct=2791.79, ppl=3.55, accuracy=70.678, wps=16052.5, ups=2.03, wpb=7900, bsz=280.1, num_updates=46700, lr=6.5442e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=48, gb_free=15.7, wall=22099
2023-08-31 04:22:30 | INFO | train_inner | epoch 026:   1170 / 1826 loss=1.933, trans_loss=4.644, nll_loss=1.841, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.072, total=4004.58, n_correct=2825.89, ppl=3.58, accuracy=70.566, wps=16369.7, ups=2.04, wpb=8009.2, bsz=291, num_updates=46800, lr=6.5372e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=48, gb_free=15, wall=22148
2023-08-31 04:22:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-31 04:22:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 04:23:21 | INFO | train_inner | epoch 026:   1272 / 1826 loss=1.931, trans_loss=4.639, nll_loss=1.834, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.048, total=3979.38, n_correct=2814.67, ppl=3.57, accuracy=70.731, wps=15785.7, ups=1.98, wpb=7958.8, bsz=283, num_updates=46900, lr=6.53023e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=50, gb_free=15.1, wall=22199
2023-08-31 04:24:11 | INFO | train_inner | epoch 026:   1372 / 1826 loss=1.94, trans_loss=4.639, nll_loss=1.834, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.124, total=3921.7, n_correct=2768, ppl=3.57, accuracy=70.582, wps=15638.7, ups=1.99, wpb=7843.4, bsz=274.3, num_updates=47000, lr=6.52328e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=50, gb_free=16.5, wall=22249
2023-08-31 04:25:01 | INFO | train_inner | epoch 026:   1472 / 1826 loss=1.93, trans_loss=4.638, nll_loss=1.833, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.044, total=3925.83, n_correct=2772.86, ppl=3.56, accuracy=70.631, wps=15676, ups=2, wpb=7851.7, bsz=277.2, num_updates=47100, lr=6.51635e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=50, gb_free=17.8, wall=22299
2023-08-31 04:25:50 | INFO | train_inner | epoch 026:   1572 / 1826 loss=1.93, trans_loss=4.635, nll_loss=1.828, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.052, total=3895.44, n_correct=2755.15, ppl=3.55, accuracy=70.728, wps=15903.7, ups=2.04, wpb=7790.9, bsz=267.3, num_updates=47200, lr=6.50945e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=48, gb_free=16.4, wall=22348
2023-08-31 04:26:39 | INFO | train_inner | epoch 026:   1672 / 1826 loss=1.933, trans_loss=4.643, nll_loss=1.84, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.055, total=3961.32, n_correct=2797.32, ppl=3.58, accuracy=70.616, wps=16041.6, ups=2.02, wpb=7922.6, bsz=284.1, num_updates=47300, lr=6.50256e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=49, gb_free=15.6, wall=22397
2023-08-31 04:27:28 | INFO | train_inner | epoch 026:   1772 / 1826 loss=1.938, trans_loss=4.647, nll_loss=1.845, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.067, total=4014.33, n_correct=2830.98, ppl=3.59, accuracy=70.522, wps=16327.3, ups=2.03, wpb=8028.7, bsz=298.7, num_updates=47400, lr=6.4957e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=49, gb_free=14.1, wall=22446
2023-08-31 04:27:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 04:28:32 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.967 | trans_loss 4.983 | nll_loss 2.229 | w2v_ctc_loss 1.43 | task_loss 0 | contrastive_loss 0.242 | total 3505.91 | n_correct 2437 | ppl 4.69 | accuracy 69.511 | uer 17.406 | wer 19.23 | raw_wer 19.23 | bleu 31.22 | wps 1258.7 | wpb 3505.9 | bsz 119.3 | num_updates 47454 | best_bleu 31.67
2023-08-31 04:28:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 47454 updates
2023-08-31 04:28:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_last.pt
2023-08-31 04:28:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_last.pt
2023-08-31 04:28:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_last.pt (epoch 26 @ 47454 updates, score 31.22) (writing took 7.150668072004919 seconds)
2023-08-31 04:28:39 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-31 04:28:39 | INFO | train | epoch 026 | loss 1.933 | trans_loss 4.639 | nll_loss 1.834 | w2v_ctc_loss 0.68 | task_loss 0 | contrastive_loss 0.089 | total 3955.45 | n_correct 2794.99 | ppl 3.57 | accuracy 70.662 | wps 14415 | ups 1.82 | wpb 7910.9 | bsz 284.4 | num_updates 47454 | lr 6.492e-05 | gnorm 0.573 | clip 0 | loss_scale 16 | train_wall 890 | gb_free 15.5 | wall 22517
2023-08-31 04:28:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 04:28:40 | INFO | fairseq.trainer | begin training epoch 27
2023-08-31 04:28:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 04:29:10 | INFO | train_inner | epoch 027:     46 / 1826 loss=1.921, trans_loss=4.631, nll_loss=1.825, w2v_ctc_loss=0.669, task_loss=0, contrastive_loss=0.051, total=3894.74, n_correct=2760.75, ppl=3.54, accuracy=70.884, wps=7664.9, ups=0.98, wpb=7789.5, bsz=280.5, num_updates=47500, lr=6.48886e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=49, gb_free=12.2, wall=22548
2023-08-31 04:29:59 | INFO | train_inner | epoch 027:    146 / 1826 loss=1.922, trans_loss=4.619, nll_loss=1.808, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.136, total=3937.13, n_correct=2800.37, ppl=3.5, accuracy=71.127, wps=15994, ups=2.03, wpb=7874.3, bsz=282.6, num_updates=47600, lr=6.48204e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=49, gb_free=16.8, wall=22597
2023-08-31 04:30:48 | INFO | train_inner | epoch 027:    246 / 1826 loss=1.936, trans_loss=4.631, nll_loss=1.823, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.174, total=3944.93, n_correct=2794.51, ppl=3.54, accuracy=70.838, wps=16067.8, ups=2.04, wpb=7889.9, bsz=283.7, num_updates=47700, lr=6.47524e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=48, gb_free=16.4, wall=22646
2023-08-31 04:31:37 | INFO | train_inner | epoch 027:    346 / 1826 loss=1.923, trans_loss=4.63, nll_loss=1.822, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.077, total=3973.1, n_correct=2818.22, ppl=3.54, accuracy=70.933, wps=16277, ups=2.05, wpb=7946.2, bsz=299.5, num_updates=47800, lr=6.46846e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=48, gb_free=16.9, wall=22695
2023-08-31 04:32:26 | INFO | train_inner | epoch 027:    446 / 1826 loss=1.917, trans_loss=4.623, nll_loss=1.813, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.042, total=3895.6, n_correct=2770.24, ppl=3.51, accuracy=71.112, wps=15859.1, ups=2.04, wpb=7791.2, bsz=274, num_updates=47900, lr=6.46171e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=49, gb_free=17.6, wall=22744
2023-08-31 04:33:17 | INFO | train_inner | epoch 027:    546 / 1826 loss=1.92, trans_loss=4.627, nll_loss=1.819, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.053, total=4046.55, n_correct=2872.38, ppl=3.53, accuracy=70.983, wps=16143.3, ups=1.99, wpb=8093.1, bsz=303.1, num_updates=48000, lr=6.45497e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=50, gb_free=10.2, wall=22794
2023-08-31 04:33:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 04:33:54 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.964 | trans_loss 4.987 | nll_loss 2.23 | w2v_ctc_loss 1.417 | task_loss 0 | contrastive_loss 0.233 | total 3505.91 | n_correct 2434.82 | ppl 4.69 | accuracy 69.449 | uer 17.409 | wer 19.346 | raw_wer 19.346 | bleu 31.45 | wps 1262.3 | wpb 3505.9 | bsz 119.3 | num_updates 48000 | best_bleu 31.67
2023-08-31 04:33:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 48000 updates
2023-08-31 04:33:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_27_48000.pt
2023-08-31 04:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_27_48000.pt
2023-08-31 04:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_27_48000.pt (epoch 27 @ 48000 updates, score 31.45) (writing took 7.802607416997489 seconds)
2023-08-31 04:34:52 | INFO | train_inner | epoch 027:    646 / 1826 loss=1.939, trans_loss=4.645, nll_loss=1.842, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.12, total=3870.16, n_correct=2726.53, ppl=3.58, accuracy=70.45, wps=8143.3, ups=1.05, wpb=7740.3, bsz=268.1, num_updates=48100, lr=6.44826e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=49, gb_free=13.1, wall=22889
2023-08-31 04:35:41 | INFO | train_inner | epoch 027:    746 / 1826 loss=1.937, trans_loss=4.628, nll_loss=1.821, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.19, total=3932.91, n_correct=2786.34, ppl=3.53, accuracy=70.847, wps=15918.1, ups=2.02, wpb=7865.8, bsz=290.6, num_updates=48200, lr=6.44157e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=49, gb_free=16.4, wall=22939
2023-08-31 04:36:31 | INFO | train_inner | epoch 027:    846 / 1826 loss=1.934, trans_loss=4.631, nll_loss=1.825, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.161, total=4044.18, n_correct=2864.41, ppl=3.54, accuracy=70.828, wps=16295.7, ups=2.01, wpb=8088.4, bsz=296.6, num_updates=48300, lr=6.43489e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=49, gb_free=12.1, wall=22989
2023-08-31 04:37:20 | INFO | train_inner | epoch 027:    946 / 1826 loss=1.927, trans_loss=4.638, nll_loss=1.833, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.043, total=3969.26, n_correct=2805.4, ppl=3.56, accuracy=70.678, wps=16026.8, ups=2.02, wpb=7938.5, bsz=278.2, num_updates=48400, lr=6.42824e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=49, gb_free=17.8, wall=23038
2023-08-31 04:38:10 | INFO | train_inner | epoch 027:   1046 / 1826 loss=1.922, trans_loss=4.634, nll_loss=1.827, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.039, total=3965.03, n_correct=2809.44, ppl=3.55, accuracy=70.855, wps=15943.3, ups=2.01, wpb=7930.1, bsz=278.5, num_updates=48500, lr=6.42161e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=49, gb_free=16.5, wall=23088
2023-08-31 04:38:59 | INFO | train_inner | epoch 027:   1146 / 1826 loss=1.93, trans_loss=4.638, nll_loss=1.833, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.051, total=3940.95, n_correct=2785.4, ppl=3.56, accuracy=70.678, wps=15935.5, ups=2.02, wpb=7881.9, bsz=278.5, num_updates=48600, lr=6.415e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=49, gb_free=15.7, wall=23137
2023-08-31 04:39:49 | INFO | train_inner | epoch 027:   1246 / 1826 loss=1.936, trans_loss=4.639, nll_loss=1.834, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.102, total=3960.96, n_correct=2799.22, ppl=3.57, accuracy=70.67, wps=16022.5, ups=2.02, wpb=7921.9, bsz=285.5, num_updates=48700, lr=6.40841e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=49, gb_free=16, wall=23187
2023-08-31 04:40:38 | INFO | train_inner | epoch 027:   1346 / 1826 loss=1.921, trans_loss=4.621, nll_loss=1.812, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.056, total=3972.75, n_correct=2822.3, ppl=3.51, accuracy=71.041, wps=16128, ups=2.03, wpb=7945.5, bsz=284.4, num_updates=48800, lr=6.40184e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=49, gb_free=16.3, wall=23236
2023-08-31 04:41:27 | INFO | train_inner | epoch 027:   1446 / 1826 loss=1.93, trans_loss=4.637, nll_loss=1.832, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.054, total=3965.81, n_correct=2802.71, ppl=3.56, accuracy=70.672, wps=16204.1, ups=2.04, wpb=7931.6, bsz=277.4, num_updates=48900, lr=6.39529e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=48, gb_free=16.1, wall=23285
2023-08-31 04:42:17 | INFO | train_inner | epoch 027:   1546 / 1826 loss=1.926, trans_loss=4.631, nll_loss=1.824, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.051, total=3884.69, n_correct=2748.84, ppl=3.54, accuracy=70.761, wps=15615.3, ups=2.01, wpb=7769.4, bsz=270.7, num_updates=49000, lr=6.38877e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=49, gb_free=16.1, wall=23335
2023-08-31 04:43:07 | INFO | train_inner | epoch 027:   1646 / 1826 loss=1.94, trans_loss=4.637, nll_loss=1.831, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.156, total=3960.41, n_correct=2800.48, ppl=3.56, accuracy=70.712, wps=15897.3, ups=2.01, wpb=7920.8, bsz=288.6, num_updates=49100, lr=6.38226e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=49, gb_free=16.5, wall=23385
2023-08-31 04:43:56 | INFO | train_inner | epoch 027:   1746 / 1826 loss=1.944, trans_loss=4.652, nll_loss=1.851, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.153, total=4003.3, n_correct=2821.82, ppl=3.61, accuracy=70.487, wps=16160.6, ups=2.02, wpb=8006.6, bsz=295.5, num_updates=49200, lr=6.37577e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=49, gb_free=16.1, wall=23434
2023-08-31 04:44:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 04:45:13 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.957 | trans_loss 4.982 | nll_loss 2.227 | w2v_ctc_loss 1.408 | task_loss 0 | contrastive_loss 0.233 | total 3505.91 | n_correct 2439.73 | ppl 4.68 | accuracy 69.589 | uer 17.481 | wer 19.316 | raw_wer 19.316 | bleu 31.54 | wps 1242.1 | wpb 3505.9 | bsz 119.3 | num_updates 49280 | best_bleu 31.67
2023-08-31 04:45:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 49280 updates
2023-08-31 04:45:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.5408.pt
2023-08-31 04:45:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.5408.pt
2023-08-31 04:45:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.5408.pt (epoch 27 @ 49280 updates, score 31.54) (writing took 7.34930831699603 seconds)
2023-08-31 04:45:21 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-31 04:45:21 | INFO | train | epoch 027 | loss 1.929 | trans_loss 4.633 | nll_loss 1.826 | w2v_ctc_loss 0.675 | task_loss 0 | contrastive_loss 0.094 | total 3956.37 | n_correct 2801.66 | ppl 3.55 | accuracy 70.814 | wps 14430.2 | ups 1.82 | wpb 7912.7 | bsz 284.8 | num_updates 49280 | lr 6.37059e-05 | gnorm 0.574 | clip 0 | loss_scale 32 | train_wall 891 | gb_free 17.2 | wall 23518
2023-08-31 04:45:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 04:45:21 | INFO | fairseq.trainer | begin training epoch 28
2023-08-31 04:45:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 04:45:38 | INFO | train_inner | epoch 028:     20 / 1826 loss=1.919, trans_loss=4.626, nll_loss=1.818, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.046, total=3965.35, n_correct=2816.42, ppl=3.53, accuracy=71.026, wps=7764.5, ups=0.98, wpb=7930.7, bsz=297.7, num_updates=49300, lr=6.3693e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=48, gb_free=15.7, wall=23536
2023-08-31 04:46:27 | INFO | train_inner | epoch 028:    120 / 1826 loss=1.914, trans_loss=4.618, nll_loss=1.806, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.041, total=3926.83, n_correct=2792.95, ppl=3.5, accuracy=71.125, wps=16004.1, ups=2.04, wpb=7853.7, bsz=282.2, num_updates=49400, lr=6.36285e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=48, gb_free=15.9, wall=23585
2023-08-31 04:47:17 | INFO | train_inner | epoch 028:    220 / 1826 loss=1.924, trans_loss=4.624, nll_loss=1.815, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.077, total=3971.99, n_correct=2818.48, ppl=3.52, accuracy=70.959, wps=15871, ups=2, wpb=7944, bsz=281.6, num_updates=49500, lr=6.35642e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=50, gb_free=16.8, wall=23635
2023-08-31 04:48:07 | INFO | train_inner | epoch 028:    320 / 1826 loss=1.918, trans_loss=4.62, nll_loss=1.809, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.052, total=3985.91, n_correct=2831.33, ppl=3.5, accuracy=71.033, wps=16166.3, ups=2.03, wpb=7971.8, bsz=289.8, num_updates=49600, lr=6.35001e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=49, gb_free=15.9, wall=23685
2023-08-31 04:48:56 | INFO | train_inner | epoch 028:    420 / 1826 loss=1.925, trans_loss=4.625, nll_loss=1.816, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.114, total=4004.43, n_correct=2845.76, ppl=3.52, accuracy=71.065, wps=16285.9, ups=2.03, wpb=8008.9, bsz=299.2, num_updates=49700, lr=6.34361e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=48, gb_free=16, wall=23734
2023-08-31 04:49:45 | INFO | train_inner | epoch 028:    520 / 1826 loss=1.93, trans_loss=4.628, nll_loss=1.819, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.146, total=3952.95, n_correct=2803.64, ppl=3.53, accuracy=70.925, wps=15999.3, ups=2.02, wpb=7905.9, bsz=278.2, num_updates=49800, lr=6.33724e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=49, gb_free=17.2, wall=23783
2023-08-31 04:50:35 | INFO | train_inner | epoch 028:    620 / 1826 loss=1.936, trans_loss=4.622, nll_loss=1.812, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.241, total=3935.49, n_correct=2795.18, ppl=3.51, accuracy=71.025, wps=15963.2, ups=2.03, wpb=7871, bsz=287.1, num_updates=49900, lr=6.33089e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=49, gb_free=16.3, wall=23833
2023-08-31 04:51:25 | INFO | train_inner | epoch 028:    720 / 1826 loss=1.938, trans_loss=4.637, nll_loss=1.831, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.155, total=3930.78, n_correct=2780.12, ppl=3.56, accuracy=70.727, wps=15684.5, ups=2, wpb=7861.6, bsz=278.3, num_updates=50000, lr=6.32456e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=50, gb_free=10.6, wall=23883
2023-08-31 04:51:25 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-31 04:51:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-31 04:52:02 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.966 | trans_loss 4.98 | nll_loss 2.222 | w2v_ctc_loss 1.443 | task_loss 0 | contrastive_loss 0.233 | total 3505.91 | n_correct 2438.91 | ppl 4.66 | accuracy 69.566 | uer 16.993 | wer 18.915 | raw_wer 18.915 | bleu 31.61 | wps 1269.4 | wpb 3505.9 | bsz 119.3 | num_updates 50000 | best_bleu 31.67
2023-08-31 04:52:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 50000 updates
2023-08-31 04:52:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_28_50000.pt
2023-08-31 04:52:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_28_50000.pt
2023-08-31 04:52:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0830_hard_baseline_lowCL_alpha1.5_mt0.5_lowgrad_highnograd/checkpoint_28_50000.pt (epoch 28 @ 50000 updates, score 31.61) (writing took 6.845974875002867 seconds)
2023-08-31 04:52:09 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-31 04:52:09 | INFO | train | epoch 028 | loss 1.926 | trans_loss 4.624 | nll_loss 1.815 | w2v_ctc_loss 0.67 | task_loss 0 | contrastive_loss 0.116 | total 3958.32 | n_correct 2810.38 | ppl 3.52 | accuracy 70.999 | wps 13952.2 | ups 1.76 | wpb 7916.6 | bsz 285.8 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.576 | clip 0 | loss_scale 32 | train_wall 352 | gb_free 10.6 | wall 23927
2023-08-31 04:52:09 | INFO | fairseq_cli.train | done training in 23852.7 seconds
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-9:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1056 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
