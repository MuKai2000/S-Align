2023-08-27 13:36:20 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:10938
2023-08-27 13:36:20 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:10938
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:10938
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:10938
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:10938
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:10938
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:10938
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:10938
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 13:36:21 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-27 13:36:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-27 13:36:25 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10938', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-27 13:36:25 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-27 13:36:25 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-27 13:36:25 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-27 13:36:25 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-27 13:36:25 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 13:36:29 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-27 13:36:29 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-27 13:36:29 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-27 13:36:31 | INFO | root | load pretrained hubert
2023-08-27 13:36:38 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 13:36:42 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 13:36:48 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 13:36:48 | INFO | root | share the sematic adapter and textual encoder
2023-08-27 13:36:49 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-27 13:36:49 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-27 13:36:49 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-27 13:36:49 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-27 13:36:49 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-27 13:36:49 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-27 13:36:49 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-27 13:36:49 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 13:36:49 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 13:36:49 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-27 13:37:04 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-27 13:37:04 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-27 13:37:04 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-27 13:37:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-27 13:37:05 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 13:37:05 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 13:37:05 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 13:37:05 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 13:37:05 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 13:37:05 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 13:37:05 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 13:37:05 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 13:37:05 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-27 13:37:05 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-27 13:37:05 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-27 13:37:05 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-27 13:37:05 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-27 13:37:05 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-27 13:37:05 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-27 13:37:05 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 13:37:05 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 13:37:07 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-27 13:37:09 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-27 13:38:01 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-27 13:38:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 13:38:01 | INFO | fairseq.trainer | begin training epoch 1
2023-08-27 13:38:01 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
2023-08-27 13:38:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
2023-08-27 13:39:19 | INFO | train_inner | epoch 001:    101 / 1191 loss=19.269, trans_loss=5.217, nll_loss=3.719, w2v_ctc_loss=21.358, task_loss=3.07, contrastive_loss=3.71, total=6744.77, n_correct=488.33, ppl=13.17, accuracy=7.24, wps=28979.4, ups=1.49, wpb=19532.8, bsz=684.7, num_updates=100, lr=4.098e-06, gnorm=1.298, clip=0, loss_scale=64, train_wall=70, gb_free=17.9, wall=134
2023-08-27 13:40:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-27 13:40:27 | INFO | train_inner | epoch 001:    202 / 1191 loss=17.007, trans_loss=5.206, nll_loss=3.764, w2v_ctc_loss=17.967, task_loss=2.977, contrastive_loss=3.671, total=6677.06, n_correct=437.31, ppl=13.58, accuracy=6.549, wps=28705.1, ups=1.48, wpb=19351.4, bsz=676.1, num_updates=200, lr=8.096e-06, gnorm=4.766, clip=2, loss_scale=32, train_wall=67, gb_free=18.1, wall=202
2023-08-27 13:41:35 | INFO | train_inner | epoch 001:    302 / 1191 loss=9.906, trans_loss=5.398, nll_loss=4.024, w2v_ctc_loss=6.792, task_loss=2.392, contrastive_loss=3.708, total=6864.64, n_correct=439.36, ppl=16.27, accuracy=6.4, wps=28956.2, ups=1.46, wpb=19894.5, bsz=719.8, num_updates=300, lr=1.2094e-05, gnorm=2.315, clip=2, loss_scale=32, train_wall=68, gb_free=18.4, wall=271
2023-08-27 13:42:42 | INFO | train_inner | epoch 001:    402 / 1191 loss=9.177, trans_loss=5.397, nll_loss=4.038, w2v_ctc_loss=5.812, task_loss=2.608, contrastive_loss=3.565, total=6664.2, n_correct=430.94, ppl=16.43, accuracy=6.466, wps=28807.1, ups=1.49, wpb=19324, bsz=657.6, num_updates=400, lr=1.6092e-05, gnorm=0.643, clip=0, loss_scale=32, train_wall=66, gb_free=18.2, wall=338
2023-08-27 13:43:49 | INFO | train_inner | epoch 001:    502 / 1191 loss=9.09, trans_loss=5.546, nll_loss=4.219, w2v_ctc_loss=5.534, task_loss=2.32, contrastive_loss=3.575, total=6743.88, n_correct=466.41, ppl=18.62, accuracy=6.916, wps=29306.2, ups=1.5, wpb=19536.7, bsz=687.8, num_updates=500, lr=2.009e-05, gnorm=0.458, clip=0, loss_scale=32, train_wall=66, gb_free=18, wall=404
2023-08-27 13:44:56 | INFO | train_inner | epoch 001:    602 / 1191 loss=9.018, trans_loss=5.661, nll_loss=4.362, w2v_ctc_loss=5.408, task_loss=2.245, contrastive_loss=3.47, total=6761.26, n_correct=422.62, ppl=20.56, accuracy=6.251, wps=29336.7, ups=1.5, wpb=19590.9, bsz=685.7, num_updates=600, lr=2.4088e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=66, gb_free=19.2, wall=471
2023-08-27 13:46:02 | INFO | train_inner | epoch 001:    702 / 1191 loss=8.802, trans_loss=5.621, nll_loss=4.314, w2v_ctc_loss=5.285, task_loss=2.22, contrastive_loss=3.402, total=6642.51, n_correct=436.95, ppl=19.89, accuracy=6.578, wps=28963.4, ups=1.51, wpb=19237.1, bsz=677.7, num_updates=700, lr=2.8086e-05, gnorm=0.789, clip=0, loss_scale=32, train_wall=66, gb_free=17.9, wall=538
2023-08-27 13:47:09 | INFO | train_inner | epoch 001:    802 / 1191 loss=8.594, trans_loss=5.542, nll_loss=4.222, w2v_ctc_loss=5.192, task_loss=2.113, contrastive_loss=3.263, total=6747.81, n_correct=469.75, ppl=18.66, accuracy=6.962, wps=29347.4, ups=1.5, wpb=19542.8, bsz=688.1, num_updates=800, lr=3.2084e-05, gnorm=1.122, clip=0, loss_scale=32, train_wall=66, gb_free=18, wall=604
2023-08-27 13:48:16 | INFO | train_inner | epoch 001:    902 / 1191 loss=8.307, trans_loss=5.472, nll_loss=4.139, w2v_ctc_loss=5.054, task_loss=2.228, contrastive_loss=3.126, total=6700.77, n_correct=501.46, ppl=17.62, accuracy=7.484, wps=28824.3, ups=1.48, wpb=19418, bsz=674.4, num_updates=900, lr=3.6082e-05, gnorm=1.396, clip=0, loss_scale=32, train_wall=67, gb_free=19.2, wall=672
2023-08-27 13:49:23 | INFO | train_inner | epoch 001:   1002 / 1191 loss=8.032, trans_loss=5.434, nll_loss=4.098, w2v_ctc_loss=4.918, task_loss=2.298, contrastive_loss=2.935, total=6678.46, n_correct=518.74, ppl=17.13, accuracy=7.767, wps=28987.5, ups=1.5, wpb=19348.8, bsz=662.4, num_updates=1000, lr=4.008e-05, gnorm=1.886, clip=0, loss_scale=32, train_wall=66, gb_free=19.2, wall=738
2023-08-27 13:50:29 | INFO | train_inner | epoch 001:   1102 / 1191 loss=7.74, trans_loss=5.399, nll_loss=4.056, w2v_ctc_loss=4.747, task_loss=2.317, contrastive_loss=2.721, total=6555.89, n_correct=535.93, ppl=16.64, accuracy=8.175, wps=28955.9, ups=1.53, wpb=18987.4, bsz=643.4, num_updates=1100, lr=4.4078e-05, gnorm=2.077, clip=0, loss_scale=32, train_wall=65, gb_free=19.2, wall=804
2023-08-27 13:51:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-27 13:52:10 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 10.449 | trans_loss 10.883 | nll_loss 9.903 | w2v_ctc_loss 6.296 | task_loss 14.026 | contrastive_loss 3.648 | total 6138.43 | n_correct 629.714 | ppl 957.35 | accuracy 10.259 | uer 84.51 | wer 82.96 | raw_wer 82.96 | bleu 0.01 | wps 1224.6 | wpb 6138.4 | bsz 201.1 | num_updates 1189
2023-08-27 13:52:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1189 updates
2023-08-27 13:52:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 13:52:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 13:52:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 1 @ 1189 updates, score 0.01) (writing took 3.717787827976281 seconds)
2023-08-27 13:52:14 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-27 13:52:14 | INFO | train | epoch 001 | loss 10.237 | trans_loss 5.439 | nll_loss 4.081 | w2v_ctc_loss 7.758 | task_loss 2.416 | contrastive_loss 3.329 | total 6703.15 | n_correct 475.943 | ppl 16.93 | accuracy 7.1 | wps 27413.7 | ups 1.41 | wpb 19421.1 | bsz 678 | num_updates 1189 | lr 4.76362e-05 | gnorm 1.613 | clip 0.3 | loss_scale 32 | train_wall 790 | gb_free 18.8 | wall 909
2023-08-27 13:52:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 13:52:14 | INFO | fairseq.trainer | begin training epoch 2
2023-08-27 13:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 13:52:29 | INFO | train_inner | epoch 002:     11 / 1191 loss=7.492, trans_loss=5.359, nll_loss=4.011, w2v_ctc_loss=4.561, task_loss=2.157, contrastive_loss=2.677, total=6641.52, n_correct=573.56, ppl=16.13, accuracy=8.636, wps=15971.3, ups=0.83, wpb=19248.9, bsz=683.9, num_updates=1200, lr=4.8076e-05, gnorm=2.121, clip=0, loss_scale=32, train_wall=65, gb_free=19, wall=924
2023-08-27 13:53:35 | INFO | train_inner | epoch 002:    111 / 1191 loss=7.189, trans_loss=5.358, nll_loss=4.008, w2v_ctc_loss=4.388, task_loss=2.264, contrastive_loss=2.44, total=6614.37, n_correct=575.08, ppl=16.09, accuracy=8.694, wps=29060.2, ups=1.52, wpb=19154.9, bsz=661.2, num_updates=1300, lr=5.2074e-05, gnorm=2.19, clip=0, loss_scale=32, train_wall=65, gb_free=18.3, wall=990
2023-08-27 13:54:42 | INFO | train_inner | epoch 002:    211 / 1191 loss=6.94, trans_loss=5.34, nll_loss=3.987, w2v_ctc_loss=4.221, task_loss=2.225, contrastive_loss=2.226, total=6725.54, n_correct=596.85, ppl=15.86, accuracy=8.874, wps=29126, ups=1.5, wpb=19480.3, bsz=673.3, num_updates=1400, lr=5.6072e-05, gnorm=2.385, clip=0, loss_scale=32, train_wall=66, gb_free=18.3, wall=1057
2023-08-27 13:55:49 | INFO | train_inner | epoch 002:    311 / 1191 loss=6.72, trans_loss=5.328, nll_loss=3.973, w2v_ctc_loss=4.059, task_loss=2.124, contrastive_loss=2.086, total=6761.98, n_correct=612.27, ppl=15.71, accuracy=9.055, wps=29136.5, ups=1.49, wpb=19593.7, bsz=688.1, num_updates=1500, lr=6.007e-05, gnorm=2.437, clip=0, loss_scale=32, train_wall=67, gb_free=18.5, wall=1124
2023-08-27 13:56:55 | INFO | train_inner | epoch 002:    411 / 1191 loss=6.516, trans_loss=5.322, nll_loss=3.967, w2v_ctc_loss=3.898, task_loss=2.15, contrastive_loss=2.007, total=6723.78, n_correct=611.97, ppl=15.63, accuracy=9.102, wps=29407.1, ups=1.51, wpb=19488.4, bsz=690.5, num_updates=1600, lr=6.4068e-05, gnorm=2.431, clip=0, loss_scale=32, train_wall=66, gb_free=18.8, wall=1191
2023-08-27 13:58:02 | INFO | train_inner | epoch 002:    511 / 1191 loss=6.318, trans_loss=5.311, nll_loss=3.954, w2v_ctc_loss=3.757, task_loss=2.22, contrastive_loss=1.923, total=6699.63, n_correct=618.05, ppl=15.49, accuracy=9.225, wps=29218.9, ups=1.5, wpb=19416.3, bsz=681.4, num_updates=1700, lr=6.8066e-05, gnorm=2.234, clip=0, loss_scale=32, train_wall=66, gb_free=17.8, wall=1257
2023-08-27 13:59:08 | INFO | train_inner | epoch 002:    611 / 1191 loss=6.097, trans_loss=5.297, nll_loss=3.933, w2v_ctc_loss=3.605, task_loss=2.286, contrastive_loss=1.772, total=6630.47, n_correct=625.34, ppl=15.28, accuracy=9.431, wps=29042.3, ups=1.51, wpb=19200, bsz=655.2, num_updates=1800, lr=7.2064e-05, gnorm=2.218, clip=0, loss_scale=32, train_wall=65, gb_free=18.5, wall=1323
2023-08-27 14:00:14 | INFO | train_inner | epoch 002:    711 / 1191 loss=5.955, trans_loss=5.282, nll_loss=3.915, w2v_ctc_loss=3.458, task_loss=2.096, contrastive_loss=1.701, total=6799.26, n_correct=658.79, ppl=15.09, accuracy=9.689, wps=29723.4, ups=1.51, wpb=19684.8, bsz=702.6, num_updates=1900, lr=7.6062e-05, gnorm=2.009, clip=0, loss_scale=32, train_wall=66, gb_free=17.9, wall=1390
2023-08-27 14:01:21 | INFO | train_inner | epoch 002:    811 / 1191 loss=5.772, trans_loss=5.26, nll_loss=3.89, w2v_ctc_loss=3.35, task_loss=2.15, contrastive_loss=1.5, total=6733.17, n_correct=671.72, ppl=14.82, accuracy=9.976, wps=29381.9, ups=1.51, wpb=19507.2, bsz=675.5, num_updates=2000, lr=8.006e-05, gnorm=2.152, clip=0, loss_scale=32, train_wall=66, gb_free=19.3, wall=1456
2023-08-27 14:01:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 14:02:04 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.019 | trans_loss 10.495 | nll_loss 9.421 | w2v_ctc_loss 4.359 | task_loss 14.015 | contrastive_loss 2.035 | total 6138.43 | n_correct 688 | ppl 685.72 | accuracy 11.208 | uer 63.349 | wer 61.078 | raw_wer 61.078 | bleu 0.02 | wps 1221.4 | wpb 6138.4 | bsz 201.1 | num_updates 2000 | best_bleu 0.02
2023-08-27 14:02:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-27 14:02:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_2_2000.pt
2023-08-27 14:02:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_2_2000.pt
2023-08-27 14:02:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.02) (writing took 11.16015330798109 seconds)
2023-08-27 14:03:22 | INFO | train_inner | epoch 002:    911 / 1191 loss=5.64, trans_loss=5.244, nll_loss=3.87, w2v_ctc_loss=3.227, task_loss=2.109, contrastive_loss=1.585, total=6730.16, n_correct=687.59, ppl=14.62, accuracy=10.217, wps=16127.7, ups=0.83, wpb=19506, bsz=703.6, num_updates=2100, lr=8.4058e-05, gnorm=1.775, clip=0, loss_scale=32, train_wall=66, gb_free=19.3, wall=1577
2023-08-27 14:04:28 | INFO | train_inner | epoch 002:   1011 / 1191 loss=5.493, trans_loss=5.225, nll_loss=3.848, w2v_ctc_loss=3.142, task_loss=2.164, contrastive_loss=1.419, total=6779.61, n_correct=715.08, ppl=14.4, accuracy=10.548, wps=29658.4, ups=1.51, wpb=19656.6, bsz=690.2, num_updates=2200, lr=8.8056e-05, gnorm=1.537, clip=0, loss_scale=32, train_wall=66, gb_free=18.6, wall=1643
2023-08-27 14:05:34 | INFO | train_inner | epoch 002:   1111 / 1191 loss=5.346, trans_loss=5.204, nll_loss=3.817, w2v_ctc_loss=3.051, task_loss=2.265, contrastive_loss=1.288, total=6673.29, n_correct=737.77, ppl=14.1, accuracy=11.056, wps=29239.7, ups=1.51, wpb=19328.4, bsz=659.8, num_updates=2300, lr=9.2054e-05, gnorm=1.506, clip=0, loss_scale=64, train_wall=65, gb_free=18.1, wall=1709
2023-08-27 14:06:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 14:07:10 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.504 | trans_loss 10.198 | nll_loss 9.049 | w2v_ctc_loss 3.839 | task_loss 14.015 | contrastive_loss 1.574 | total 6138.43 | n_correct 845 | ppl 529.51 | accuracy 13.766 | uer 58.348 | wer 56.348 | raw_wer 56.348 | bleu 0.06 | wps 1225.9 | wpb 6138.4 | bsz 201.1 | num_updates 2380 | best_bleu 0.06
2023-08-27 14:07:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2380 updates
2023-08-27 14:07:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 14:07:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 14:07:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 2 @ 2380 updates, score 0.06) (writing took 11.881895639991853 seconds)
2023-08-27 14:07:23 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-27 14:07:23 | INFO | train | epoch 002 | loss 6.129 | trans_loss 5.283 | nll_loss 3.917 | w2v_ctc_loss 3.613 | task_loss 2.194 | contrastive_loss 1.789 | total 6703.69 | n_correct 651.573 | ppl 15.1 | accuracy 9.72 | wps 25457.7 | ups 1.31 | wpb 19422.7 | bsz 678.2 | num_updates 2380 | lr 9.52524e-05 | gnorm 2.039 | clip 0 | loss_scale 64 | train_wall 783 | gb_free 18 | wall 1818
2023-08-27 14:07:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 14:07:23 | INFO | fairseq.trainer | begin training epoch 3
2023-08-27 14:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 14:07:44 | INFO | train_inner | epoch 003:     20 / 1191 loss=5.25, trans_loss=5.191, nll_loss=3.803, w2v_ctc_loss=2.981, task_loss=2.332, contrastive_loss=1.311, total=6595.48, n_correct=740.09, ppl=13.96, accuracy=11.221, wps=14744.6, ups=0.77, wpb=19119.7, bsz=656.3, num_updates=2400, lr=9.6052e-05, gnorm=1.451, clip=0, loss_scale=64, train_wall=66, gb_free=18.5, wall=1839
2023-08-27 14:08:50 | INFO | train_inner | epoch 003:    120 / 1191 loss=5.143, trans_loss=5.165, nll_loss=3.772, w2v_ctc_loss=2.886, task_loss=2.17, contrastive_loss=1.262, total=6692.7, n_correct=781.27, ppl=13.66, accuracy=11.673, wps=29076.1, ups=1.5, wpb=19403.6, bsz=684.3, num_updates=2500, lr=0.00010005, gnorm=1.283, clip=0, loss_scale=64, train_wall=66, gb_free=19.4, wall=1906
2023-08-27 14:09:57 | INFO | train_inner | epoch 003:    220 / 1191 loss=5.036, trans_loss=5.157, nll_loss=3.76, w2v_ctc_loss=2.793, task_loss=2.119, contrastive_loss=1.22, total=6725.36, n_correct=798.74, ppl=13.55, accuracy=11.877, wps=29267.6, ups=1.5, wpb=19489.1, bsz=687.9, num_updates=2600, lr=0.000104048, gnorm=1.231, clip=0, loss_scale=64, train_wall=66, gb_free=17.7, wall=1972
2023-08-27 14:11:03 | INFO | train_inner | epoch 003:    320 / 1191 loss=4.916, trans_loss=5.142, nll_loss=3.738, w2v_ctc_loss=2.766, task_loss=2.52, contrastive_loss=1.027, total=6563.99, n_correct=796.49, ppl=13.35, accuracy=12.134, wps=28867.3, ups=1.52, wpb=19008, bsz=622.1, num_updates=2700, lr=0.000108046, gnorm=1.205, clip=0, loss_scale=64, train_wall=65, gb_free=17.8, wall=2038
2023-08-27 14:12:08 | INFO | train_inner | epoch 003:    420 / 1191 loss=4.863, trans_loss=5.119, nll_loss=3.711, w2v_ctc_loss=2.673, task_loss=2.172, contrastive_loss=1.157, total=6684.68, n_correct=838.32, ppl=13.1, accuracy=12.541, wps=29585.7, ups=1.53, wpb=19370.9, bsz=686, num_updates=2800, lr=0.000112044, gnorm=0.96, clip=0, loss_scale=64, train_wall=65, gb_free=18.3, wall=2104
2023-08-27 14:13:15 | INFO | train_inner | epoch 003:    520 / 1191 loss=4.787, trans_loss=5.114, nll_loss=3.705, w2v_ctc_loss=2.643, task_loss=2.154, contrastive_loss=0.961, total=6758.8, n_correct=853.85, ppl=13.04, accuracy=12.633, wps=29514, ups=1.51, wpb=19583.9, bsz=680.5, num_updates=2900, lr=0.000116042, gnorm=0.975, clip=0, loss_scale=64, train_wall=66, gb_free=18.6, wall=2170
2023-08-27 14:14:21 | INFO | train_inner | epoch 003:    620 / 1191 loss=4.71, trans_loss=5.093, nll_loss=3.679, w2v_ctc_loss=2.598, task_loss=2.227, contrastive_loss=0.939, total=6749.81, n_correct=877.04, ppl=12.81, accuracy=12.994, wps=29348.2, ups=1.5, wpb=19563.6, bsz=664, num_updates=3000, lr=0.00012004, gnorm=0.933, clip=0, loss_scale=64, train_wall=66, gb_free=18.4, wall=2237
2023-08-27 14:14:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-27 14:14:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-27 14:14:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-27 14:14:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-27 14:16:11 | INFO | train_inner | epoch 003:    724 / 1191 loss=3.911, trans_loss=4.307, nll_loss=2.643, w2v_ctc_loss=2.261, task_loss=1.546, contrastive_loss=0.933, total=6725.16, n_correct=2065.6, ppl=6.25, accuracy=30.715, wps=17821.5, ups=0.91, wpb=19491.2, bsz=695.5, num_updates=3100, lr=0.000124038, gnorm=2.026, clip=1, loss_scale=4, train_wall=109, gb_free=14.5, wall=2346
2023-08-27 14:17:54 | INFO | train_inner | epoch 003:    824 / 1191 loss=3.346, trans_loss=4.016, nll_loss=2.262, w2v_ctc_loss=1.985, task_loss=1.448, contrastive_loss=0.672, total=6767.26, n_correct=2665.39, ppl=4.8, accuracy=39.387, wps=19054.4, ups=0.97, wpb=19615.8, bsz=703.5, num_updates=3200, lr=0.000128036, gnorm=1.203, clip=0, loss_scale=4, train_wall=102, gb_free=13.7, wall=2449
2023-08-27 14:19:36 | INFO | train_inner | epoch 003:    924 / 1191 loss=3.156, trans_loss=3.926, nll_loss=2.141, w2v_ctc_loss=1.859, task_loss=1.395, contrastive_loss=0.589, total=6810.72, n_correct=2919.08, ppl=4.41, accuracy=42.86, wps=19206.7, ups=0.97, wpb=19727.4, bsz=717.9, num_updates=3300, lr=0.000132034, gnorm=1.175, clip=0, loss_scale=4, train_wall=102, gb_free=13.1, wall=2552
2023-08-27 14:21:21 | INFO | train_inner | epoch 003:   1024 / 1191 loss=3.027, trans_loss=3.887, nll_loss=2.089, w2v_ctc_loss=1.81, task_loss=1.791, contrastive_loss=0.471, total=6546.4, n_correct=2902.11, ppl=4.26, accuracy=44.331, wps=18164.9, ups=0.96, wpb=18970.7, bsz=618.6, num_updates=3400, lr=0.000136032, gnorm=1.083, clip=0, loss_scale=4, train_wall=104, gb_free=13.5, wall=2656
2023-08-27 14:23:06 | INFO | train_inner | epoch 003:   1124 / 1191 loss=2.913, trans_loss=3.82, nll_loss=2, w2v_ctc_loss=1.701, task_loss=1.483, contrastive_loss=0.506, total=6759.46, n_correct=3177.15, ppl=4, accuracy=47.003, wps=18638.8, ups=0.95, wpb=19569.3, bsz=704, num_updates=3500, lr=0.00014003, gnorm=0.955, clip=0, loss_scale=4, train_wall=104, gb_free=14, wall=2761
2023-08-27 14:24:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 14:24:55 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.939 | trans_loss 6.182 | nll_loss 3.687 | w2v_ctc_loss 2.062 | task_loss 7.536 | contrastive_loss 0.544 | total 6138.43 | n_correct 3211.14 | ppl 12.88 | accuracy 52.312 | uer 33.236 | wer 32.704 | raw_wer 32.704 | bleu 13.05 | wps 1337.7 | wpb 6138.4 | bsz 201.1 | num_updates 3567 | best_bleu 13.05
2023-08-27 14:24:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3567 updates
2023-08-27 14:24:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 14:25:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 14:25:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 3 @ 3567 updates, score 13.05) (writing took 11.687949011015007 seconds)
2023-08-27 14:25:07 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-27 14:25:07 | INFO | train | epoch 003 | loss 4.107 | trans_loss 4.576 | nll_loss 2.997 | w2v_ctc_loss 2.33 | task_loss 1.887 | contrastive_loss 0.871 | total 6703.78 | n_correct 1766.45 | ppl 7.98 | accuracy 26.35 | wps 21662.6 | ups 1.12 | wpb 19423 | bsz 678.3 | num_updates 3567 | lr 0.000142709 | gnorm 1.172 | clip 0.1 | loss_scale 4 | train_wall 997 | gb_free 15.2 | wall 2882
2023-08-27 14:25:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 14:25:07 | INFO | fairseq.trainer | begin training epoch 4
2023-08-27 14:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 14:25:49 | INFO | train_inner | epoch 004:     33 / 1191 loss=2.817, trans_loss=3.786, nll_loss=1.953, w2v_ctc_loss=1.646, task_loss=1.606, contrastive_loss=0.434, total=6584.98, n_correct=3188.49, ppl=3.87, accuracy=48.421, wps=11649.9, ups=0.61, wpb=19058.3, bsz=650.5, num_updates=3600, lr=0.000144028, gnorm=0.917, clip=0, loss_scale=4, train_wall=104, gb_free=13.6, wall=2925
2023-08-27 14:27:34 | INFO | train_inner | epoch 004:    133 / 1191 loss=2.723, trans_loss=3.738, nll_loss=1.893, w2v_ctc_loss=1.584, task_loss=1.586, contrastive_loss=0.359, total=6725.65, n_correct=3367.7, ppl=3.71, accuracy=50.072, wps=18600.8, ups=0.95, wpb=19481.6, bsz=657.2, num_updates=3700, lr=0.000148026, gnorm=0.889, clip=0, loss_scale=4, train_wall=104, gb_free=12.3, wall=3029
2023-08-27 14:29:18 | INFO | train_inner | epoch 004:    233 / 1191 loss=2.71, trans_loss=3.713, nll_loss=1.862, w2v_ctc_loss=1.541, task_loss=1.494, contrastive_loss=0.527, total=6748.29, n_correct=3451.79, ppl=3.63, accuracy=51.151, wps=18901.7, ups=0.97, wpb=19555.5, bsz=700.2, num_updates=3800, lr=0.000152024, gnorm=0.885, clip=0, loss_scale=4, train_wall=103, gb_free=11.9, wall=3133
2023-08-27 14:31:00 | INFO | train_inner | epoch 004:    333 / 1191 loss=2.628, trans_loss=3.695, nll_loss=1.837, w2v_ctc_loss=1.516, task_loss=1.539, contrastive_loss=0.339, total=6673.75, n_correct=3473.04, ppl=3.57, accuracy=52.04, wps=18833, ups=0.97, wpb=19340, bsz=664.8, num_updates=3900, lr=0.000156022, gnorm=0.823, clip=0, loss_scale=4, train_wall=102, gb_free=13.4, wall=3236
2023-08-27 14:32:44 | INFO | train_inner | epoch 004:    433 / 1191 loss=2.625, trans_loss=3.679, nll_loss=1.818, w2v_ctc_loss=1.494, task_loss=1.556, contrastive_loss=0.471, total=6706.67, n_correct=3532.8, ppl=3.53, accuracy=52.676, wps=18671.8, ups=0.96, wpb=19435.3, bsz=683.2, num_updates=4000, lr=0.00016002, gnorm=0.829, clip=0, loss_scale=4, train_wall=104, gb_free=14.4, wall=3340
2023-08-27 14:32:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 14:33:20 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.612 | trans_loss 5.868 | nll_loss 3.272 | w2v_ctc_loss 1.799 | task_loss 7.921 | contrastive_loss 0.416 | total 6138.43 | n_correct 3513.71 | ppl 9.66 | accuracy 57.241 | uer 28.636 | wer 29.26 | raw_wer 29.26 | bleu 17.77 | wps 1501.9 | wpb 6138.4 | bsz 201.1 | num_updates 4000 | best_bleu 17.77
2023-08-27 14:33:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4000 updates
2023-08-27 14:33:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_4_4000.pt
2023-08-27 14:33:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_4_4000.pt
2023-08-27 14:33:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_4_4000.pt (epoch 4 @ 4000 updates, score 17.77) (writing took 12.09924909300753 seconds)
2023-08-27 14:35:16 | INFO | train_inner | epoch 004:    533 / 1191 loss=2.547, trans_loss=3.658, nll_loss=1.789, w2v_ctc_loss=1.46, task_loss=1.589, contrastive_loss=0.291, total=6664.83, n_correct=3572.44, ppl=3.46, accuracy=53.601, wps=12728.4, ups=0.66, wpb=19309.1, bsz=662.9, num_updates=4100, lr=0.000164018, gnorm=0.785, clip=0, loss_scale=4, train_wall=103, gb_free=13, wall=3491
2023-08-27 14:37:01 | INFO | train_inner | epoch 004:    633 / 1191 loss=2.54, trans_loss=3.644, nll_loss=1.773, w2v_ctc_loss=1.435, task_loss=1.463, contrastive_loss=0.394, total=6836.09, n_correct=3709.95, ppl=3.42, accuracy=54.27, wps=18954.6, ups=0.96, wpb=19815.3, bsz=714.8, num_updates=4200, lr=0.000168016, gnorm=0.782, clip=0, loss_scale=4, train_wall=104, gb_free=15.2, wall=3596
2023-08-27 14:38:43 | INFO | train_inner | epoch 004:    733 / 1191 loss=2.502, trans_loss=3.627, nll_loss=1.749, w2v_ctc_loss=1.402, task_loss=1.529, contrastive_loss=0.401, total=6692.34, n_correct=3679.05, ppl=3.36, accuracy=54.974, wps=18896, ups=0.97, wpb=19385.6, bsz=683.6, num_updates=4300, lr=0.000172014, gnorm=0.753, clip=0, loss_scale=4, train_wall=102, gb_free=15, wall=3699
2023-08-27 14:40:28 | INFO | train_inner | epoch 004:    833 / 1191 loss=2.47, trans_loss=3.622, nll_loss=1.743, w2v_ctc_loss=1.376, task_loss=1.437, contrastive_loss=0.374, total=6858.25, n_correct=3802.73, ppl=3.35, accuracy=55.448, wps=18949.5, ups=0.95, wpb=19861.5, bsz=722.4, num_updates=4400, lr=0.000176012, gnorm=0.748, clip=0, loss_scale=4, train_wall=104, gb_free=11.5, wall=3803
2023-08-27 14:42:12 | INFO | train_inner | epoch 004:    933 / 1191 loss=2.44, trans_loss=3.602, nll_loss=1.716, w2v_ctc_loss=1.363, task_loss=1.467, contrastive_loss=0.341, total=6733.97, n_correct=3790.92, ppl=3.28, accuracy=56.295, wps=18715.5, ups=0.96, wpb=19496.2, bsz=702.5, num_updates=4500, lr=0.00018001, gnorm=0.732, clip=0, loss_scale=4, train_wall=103, gb_free=13.1, wall=3908
2023-08-27 14:43:57 | INFO | train_inner | epoch 004:   1033 / 1191 loss=2.427, trans_loss=3.604, nll_loss=1.72, w2v_ctc_loss=1.365, task_loss=1.642, contrastive_loss=0.302, total=6643.72, n_correct=3736.23, ppl=3.29, accuracy=56.237, wps=18285.5, ups=0.95, wpb=19244.1, bsz=662.2, num_updates=4600, lr=0.000184008, gnorm=0.732, clip=0, loss_scale=4, train_wall=105, gb_free=14.4, wall=4013
2023-08-27 14:45:41 | INFO | train_inner | epoch 004:   1133 / 1191 loss=2.377, trans_loss=3.584, nll_loss=1.697, w2v_ctc_loss=1.343, task_loss=1.657, contrastive_loss=0.216, total=6564.89, n_correct=3730.02, ppl=3.24, accuracy=56.818, wps=18358.9, ups=0.96, wpb=19032.7, bsz=632.2, num_updates=4700, lr=0.000188006, gnorm=0.711, clip=0, loss_scale=4, train_wall=103, gb_free=14.3, wall=4116
2023-08-27 14:46:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 14:47:15 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.346 | trans_loss 5.619 | nll_loss 2.946 | w2v_ctc_loss 1.543 | task_loss 8.07 | contrastive_loss 0.338 | total 6138.43 | n_correct 3742 | ppl 7.71 | accuracy 60.96 | uer 25.387 | wer 26.679 | raw_wer 26.679 | bleu 21.08 | wps 1591.1 | wpb 6138.4 | bsz 201.1 | num_updates 4758 | best_bleu 21.08
2023-08-27 14:47:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4758 updates
2023-08-27 14:47:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 14:47:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 14:47:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 4 @ 4758 updates, score 21.08) (writing took 12.183522454986814 seconds)
2023-08-27 14:47:28 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-27 14:47:28 | INFO | train | epoch 004 | loss 2.543 | trans_loss 3.651 | nll_loss 1.781 | w2v_ctc_loss 1.444 | task_loss 1.547 | contrastive_loss 0.36 | total 6703.69 | n_correct 3618.94 | ppl 3.44 | accuracy 53.984 | wps 17248 | ups 0.89 | wpb 19422.7 | bsz 678.2 | num_updates 4758 | lr 0.000190325 | gnorm 0.788 | clip 0 | loss_scale 4 | train_wall 1231 | gb_free 13.5 | wall 4223
2023-08-27 14:47:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 14:47:28 | INFO | fairseq.trainer | begin training epoch 5
2023-08-27 14:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 14:48:18 | INFO | train_inner | epoch 005:     42 / 1191 loss=2.356, trans_loss=3.554, nll_loss=1.657, w2v_ctc_loss=1.306, task_loss=1.453, contrastive_loss=0.3, total=6756.35, n_correct=3908.75, ppl=3.15, accuracy=57.853, wps=12497.2, ups=0.64, wpb=19580.7, bsz=706.7, num_updates=4800, lr=0.000192004, gnorm=0.714, clip=0, loss_scale=4, train_wall=102, gb_free=13.6, wall=4273
2023-08-27 14:50:03 | INFO | train_inner | epoch 005:    142 / 1191 loss=2.331, trans_loss=3.551, nll_loss=1.652, w2v_ctc_loss=1.281, task_loss=1.537, contrastive_loss=0.302, total=6729.54, n_correct=3918.72, ppl=3.14, accuracy=58.232, wps=18622.3, ups=0.96, wpb=19497.4, bsz=684.1, num_updates=4900, lr=0.000196002, gnorm=0.702, clip=0, loss_scale=4, train_wall=104, gb_free=13.6, wall=4378
2023-08-27 14:51:46 | INFO | train_inner | epoch 005:    242 / 1191 loss=2.304, trans_loss=3.537, nll_loss=1.635, w2v_ctc_loss=1.263, task_loss=1.411, contrastive_loss=0.26, total=6861.39, n_correct=4034.94, ppl=3.11, accuracy=58.806, wps=19185.1, ups=0.97, wpb=19875.8, bsz=728.4, num_updates=5000, lr=0.0002, gnorm=0.689, clip=0, loss_scale=4, train_wall=103, gb_free=13.6, wall=4482
mt_weight tensor(0.5000)
asr_weight tensor(0.4888, device='cuda:0')
2023-08-27 14:53:30 | INFO | train_inner | epoch 005:    342 / 1191 loss=2.285, trans_loss=3.536, nll_loss=1.632, w2v_ctc_loss=1.253, task_loss=1.615, contrastive_loss=0.264, total=6617.98, n_correct=3902.09, ppl=3.1, accuracy=58.962, wps=18429.5, ups=0.96, wpb=19172.5, bsz=661.2, num_updates=5100, lr=0.00019803, gnorm=0.443, clip=0, loss_scale=8, train_wall=103, gb_free=14.3, wall=4586
2023-08-27 14:55:14 | INFO | train_inner | epoch 005:    442 / 1191 loss=2.294, trans_loss=3.529, nll_loss=1.626, w2v_ctc_loss=1.258, task_loss=1.546, contrastive_loss=0.298, total=6686.19, n_correct=3952.26, ppl=3.09, accuracy=59.111, wps=18639.9, ups=0.96, wpb=19384.7, bsz=678.6, num_updates=5200, lr=0.000196116, gnorm=0.447, clip=0, loss_scale=8, train_wall=103, gb_free=13.7, wall=4690
2023-08-27 14:56:59 | INFO | train_inner | epoch 005:    542 / 1191 loss=2.288, trans_loss=3.527, nll_loss=1.622, w2v_ctc_loss=1.239, task_loss=1.574, contrastive_loss=0.348, total=6670.49, n_correct=3957.79, ppl=3.08, accuracy=59.333, wps=18474.9, ups=0.96, wpb=19320.9, bsz=674.2, num_updates=5300, lr=0.000194257, gnorm=0.456, clip=0, loss_scale=8, train_wall=104, gb_free=12.9, wall=4794
2023-08-27 14:58:42 | INFO | train_inner | epoch 005:    642 / 1191 loss=2.25, trans_loss=3.521, nll_loss=1.612, w2v_ctc_loss=1.236, task_loss=1.562, contrastive_loss=0.199, total=6700.63, n_correct=4004.69, ppl=3.06, accuracy=59.766, wps=18846.1, ups=0.97, wpb=19400.3, bsz=669.7, num_updates=5400, lr=0.00019245, gnorm=0.438, clip=0, loss_scale=8, train_wall=102, gb_free=14, wall=4897
2023-08-27 15:00:27 | INFO | train_inner | epoch 005:    742 / 1191 loss=2.255, trans_loss=3.508, nll_loss=1.601, w2v_ctc_loss=1.222, task_loss=1.543, contrastive_loss=0.298, total=6723.35, n_correct=4039.89, ppl=3.03, accuracy=60.087, wps=18611, ups=0.95, wpb=19489.5, bsz=686.6, num_updates=5500, lr=0.000190693, gnorm=0.434, clip=0, loss_scale=8, train_wall=104, gb_free=14.5, wall=5002
2023-08-27 15:02:11 | INFO | train_inner | epoch 005:    842 / 1191 loss=2.234, trans_loss=3.503, nll_loss=1.592, w2v_ctc_loss=1.207, task_loss=1.509, contrastive_loss=0.278, total=6774.08, n_correct=4087.67, ppl=3.01, accuracy=60.343, wps=18857.4, ups=0.96, wpb=19618.7, bsz=688.1, num_updates=5600, lr=0.000188982, gnorm=0.436, clip=0, loss_scale=8, train_wall=103, gb_free=14.1, wall=5106
2023-08-27 15:03:55 | INFO | train_inner | epoch 005:    942 / 1191 loss=2.229, trans_loss=3.506, nll_loss=1.599, w2v_ctc_loss=1.213, task_loss=1.642, contrastive_loss=0.258, total=6585.76, n_correct=3972.09, ppl=3.03, accuracy=60.313, wps=18234.7, ups=0.96, wpb=19088.7, bsz=652.1, num_updates=5700, lr=0.000187317, gnorm=0.431, clip=0, loss_scale=8, train_wall=104, gb_free=10.6, wall=5211
2023-08-27 15:05:39 | INFO | train_inner | epoch 005:   1042 / 1191 loss=2.215, trans_loss=3.503, nll_loss=1.593, w2v_ctc_loss=1.201, task_loss=1.644, contrastive_loss=0.24, total=6644.61, n_correct=4023.55, ppl=3.02, accuracy=60.554, wps=18482.4, ups=0.96, wpb=19250.1, bsz=649.3, num_updates=5800, lr=0.000185695, gnorm=0.424, clip=0, loss_scale=8, train_wall=104, gb_free=14.7, wall=5315
2023-08-27 15:07:23 | INFO | train_inner | epoch 005:   1142 / 1191 loss=2.215, trans_loss=3.497, nll_loss=1.586, w2v_ctc_loss=1.197, task_loss=1.57, contrastive_loss=0.252, total=6713.59, n_correct=4081.31, ppl=3, accuracy=60.792, wps=18781.9, ups=0.97, wpb=19450.3, bsz=671.6, num_updates=5900, lr=0.000184115, gnorm=0.429, clip=0, loss_scale=8, train_wall=103, gb_free=14, wall=5418
2023-08-27 15:08:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4888, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4888, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4888, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4888, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4888, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4888, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4888, device='cuda:3')
2023-08-27 15:08:47 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.167 | trans_loss 5.459 | nll_loss 2.741 | w2v_ctc_loss 1.32 | task_loss 8.251 | contrastive_loss 0.33 | total 6138.43 | n_correct 3892 | ppl 6.69 | accuracy 63.404 | uer 21.793 | wer 23.347 | raw_wer 23.347 | bleu 23.21 | wps 1699.9 | wpb 6138.4 | bsz 201.1 | num_updates 5949 | best_bleu 23.21
2023-08-27 15:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5949 updates
2023-08-27 15:08:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 15:08:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 15:08:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 5 @ 5949 updates, score 23.21) (writing took 12.487200078991009 seconds)
2023-08-27 15:09:00 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-27 15:09:00 | INFO | train | epoch 005 | loss 2.264 | trans_loss 3.519 | nll_loss 1.613 | w2v_ctc_loss 1.233 | task_loss 1.551 | contrastive_loss 0.276 | total 6703.69 | n_correct 4000.53 | ppl 3.06 | accuracy 59.676 | wps 17907.5 | ups 0.92 | wpb 19422.7 | bsz 678.2 | num_updates 5949 | lr 0.000183355 | gnorm 0.49 | clip 0 | loss_scale 8 | train_wall 1230 | gb_free 11.4 | wall 5515
2023-08-27 15:09:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 15:09:00 | INFO | fairseq.trainer | begin training epoch 6
2023-08-27 15:09:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 15:09:59 | INFO | train_inner | epoch 006:     51 / 1191 loss=2.17, trans_loss=3.466, nll_loss=1.547, w2v_ctc_loss=1.151, task_loss=1.581, contrastive_loss=0.281, total=6648.35, n_correct=4103.65, ppl=2.92, accuracy=61.724, wps=12344.9, ups=0.64, wpb=19266.5, bsz=660.3, num_updates=6000, lr=0.000182574, gnorm=0.415, clip=0, loss_scale=8, train_wall=102, gb_free=13.2, wall=5574
2023-08-27 15:09:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 15:10:35 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.164 | trans_loss 5.446 | nll_loss 2.714 | w2v_ctc_loss 1.356 | task_loss 8.242 | contrastive_loss 0.316 | total 6138.43 | n_correct 3919 | ppl 6.56 | accuracy 63.844 | uer 21.611 | wer 23.187 | raw_wer 23.187 | bleu 23.44 | wps 1601.4 | wpb 6138.4 | bsz 201.1 | num_updates 6000 | best_bleu 23.44
2023-08-27 15:10:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6000 updates
2023-08-27 15:10:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_6_6000.pt
2023-08-27 15:10:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_6_6000.pt
2023-08-27 15:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_6_6000.pt (epoch 6 @ 6000 updates, score 23.44) (writing took 11.769050814997172 seconds)
2023-08-27 15:12:30 | INFO | train_inner | epoch 006:    151 / 1191 loss=2.138, trans_loss=3.46, nll_loss=1.535, w2v_ctc_loss=1.13, task_loss=1.559, contrastive_loss=0.227, total=6729.16, n_correct=4172.16, ppl=2.9, accuracy=62.001, wps=12863.7, ups=0.66, wpb=19481, bsz=681.4, num_updates=6100, lr=0.000181071, gnorm=0.411, clip=0, loss_scale=8, train_wall=103, gb_free=12.3, wall=5726
2023-08-27 15:14:15 | INFO | train_inner | epoch 006:    251 / 1191 loss=2.153, trans_loss=3.451, nll_loss=1.528, w2v_ctc_loss=1.13, task_loss=1.464, contrastive_loss=0.289, total=6816.33, n_correct=4250.39, ppl=2.88, accuracy=62.356, wps=18861.8, ups=0.96, wpb=19749, bsz=710.9, num_updates=6200, lr=0.000179605, gnorm=0.419, clip=0, loss_scale=8, train_wall=104, gb_free=15, wall=5831
2023-08-27 15:16:01 | INFO | train_inner | epoch 006:    351 / 1191 loss=2.129, trans_loss=3.456, nll_loss=1.532, w2v_ctc_loss=1.131, task_loss=1.557, contrastive_loss=0.187, total=6739.97, n_correct=4194.41, ppl=2.89, accuracy=62.232, wps=18508.3, ups=0.95, wpb=19518.7, bsz=680.9, num_updates=6300, lr=0.000178174, gnorm=0.411, clip=0, loss_scale=8, train_wall=105, gb_free=10.4, wall=5936
2023-08-27 15:17:43 | INFO | train_inner | epoch 006:    451 / 1191 loss=2.144, trans_loss=3.454, nll_loss=1.532, w2v_ctc_loss=1.142, task_loss=1.63, contrastive_loss=0.256, total=6567.77, n_correct=4084.9, ppl=2.89, accuracy=62.196, wps=18609.1, ups=0.98, wpb=19034.6, bsz=647.5, num_updates=6400, lr=0.000176777, gnorm=0.421, clip=0, loss_scale=8, train_wall=102, gb_free=14.1, wall=6038
2023-08-27 15:19:27 | INFO | train_inner | epoch 006:    551 / 1191 loss=2.11, trans_loss=3.447, nll_loss=1.524, w2v_ctc_loss=1.121, task_loss=1.589, contrastive_loss=0.175, total=6698.06, n_correct=4184.58, ppl=2.88, accuracy=62.475, wps=18672.5, ups=0.96, wpb=19417.2, bsz=666, num_updates=6500, lr=0.000175412, gnorm=0.408, clip=0, loss_scale=8, train_wall=103, gb_free=14.5, wall=6142
2023-08-27 15:21:11 | INFO | train_inner | epoch 006:    651 / 1191 loss=2.119, trans_loss=3.455, nll_loss=1.531, w2v_ctc_loss=1.112, task_loss=1.642, contrastive_loss=0.245, total=6670.55, n_correct=4166.2, ppl=2.89, accuracy=62.457, wps=18491.2, ups=0.96, wpb=19319.8, bsz=653.8, num_updates=6600, lr=0.000174078, gnorm=0.404, clip=0, loss_scale=8, train_wall=104, gb_free=9.9, wall=6247
2023-08-27 15:22:55 | INFO | train_inner | epoch 006:    751 / 1191 loss=2.136, trans_loss=3.443, nll_loss=1.518, w2v_ctc_loss=1.113, task_loss=1.449, contrastive_loss=0.312, total=6837.55, n_correct=4292.71, ppl=2.86, accuracy=62.781, wps=19093, ups=0.96, wpb=19807.9, bsz=721.1, num_updates=6700, lr=0.000172774, gnorm=0.417, clip=0, loss_scale=8, train_wall=103, gb_free=13.7, wall=6350
2023-08-27 15:24:40 | INFO | train_inner | epoch 006:    851 / 1191 loss=2.119, trans_loss=3.442, nll_loss=1.52, w2v_ctc_loss=1.119, task_loss=1.602, contrastive_loss=0.225, total=6622.6, n_correct=4151.53, ppl=2.87, accuracy=62.687, wps=18317.6, ups=0.95, wpb=19204.8, bsz=672.6, num_updates=6800, lr=0.000171499, gnorm=0.407, clip=0, loss_scale=8, train_wall=104, gb_free=14.3, wall=6455
2023-08-27 15:26:25 | INFO | train_inner | epoch 006:    951 / 1191 loss=2.134, trans_loss=3.457, nll_loss=1.536, w2v_ctc_loss=1.119, task_loss=1.7, contrastive_loss=0.292, total=6630.12, n_correct=4138.63, ppl=2.9, accuracy=62.422, wps=18336.9, ups=0.95, wpb=19206, bsz=642.3, num_updates=6900, lr=0.000170251, gnorm=0.409, clip=0, loss_scale=8, train_wall=104, gb_free=15, wall=6560
2023-08-27 15:28:08 | INFO | train_inner | epoch 006:   1051 / 1191 loss=2.109, trans_loss=3.438, nll_loss=1.513, w2v_ctc_loss=1.095, task_loss=1.556, contrastive_loss=0.288, total=6685.75, n_correct=4211.1, ppl=2.85, accuracy=62.986, wps=18722.2, ups=0.97, wpb=19375.3, bsz=672.5, num_updates=7000, lr=0.000169031, gnorm=0.409, clip=0, loss_scale=8, train_wall=103, gb_free=13.6, wall=6664
2023-08-27 15:29:51 | INFO | train_inner | epoch 006:   1151 / 1191 loss=2.073, trans_loss=3.43, nll_loss=1.504, w2v_ctc_loss=1.082, task_loss=1.427, contrastive_loss=0.166, total=6760.7, n_correct=4283.69, ppl=2.84, accuracy=63.362, wps=19157.8, ups=0.98, wpb=19594.8, bsz=714.1, num_updates=7100, lr=0.000167836, gnorm=0.402, clip=0, loss_scale=16, train_wall=102, gb_free=14.4, wall=6766
2023-08-27 15:30:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 15:31:05 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.075 | trans_loss 5.363 | nll_loss 2.62 | w2v_ctc_loss 1.259 | task_loss 8.354 | contrastive_loss 0.296 | total 6138.43 | n_correct 3973.43 | ppl 6.15 | accuracy 64.73 | uer 21.001 | wer 22.811 | raw_wer 22.811 | bleu 24.82 | wps 1688 | wpb 6138.4 | bsz 201.1 | num_updates 7140 | best_bleu 24.82
2023-08-27 15:31:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 7140 updates
2023-08-27 15:31:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 15:31:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 15:31:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 6 @ 7140 updates, score 24.82) (writing took 10.115402413008269 seconds)
2023-08-27 15:31:15 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-27 15:31:15 | INFO | train | epoch 006 | loss 2.123 | trans_loss 3.448 | nll_loss 1.524 | w2v_ctc_loss 1.116 | task_loss 1.555 | contrastive_loss 0.242 | total 6703.69 | n_correct 4193.79 | ppl 2.88 | accuracy 62.559 | wps 17322.7 | ups 0.89 | wpb 19422.7 | bsz 678.2 | num_updates 7140 | lr 0.000167365 | gnorm 0.41 | clip 0 | loss_scale 16 | train_wall 1229 | gb_free 13.7 | wall 6851
2023-08-27 15:31:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 15:31:16 | INFO | fairseq.trainer | begin training epoch 7
2023-08-27 15:31:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 15:32:25 | INFO | train_inner | epoch 007:     60 / 1191 loss=2.077, trans_loss=3.421, nll_loss=1.489, w2v_ctc_loss=1.067, task_loss=1.505, contrastive_loss=0.275, total=6736.11, n_correct=4285.66, ppl=2.81, accuracy=63.622, wps=12657.9, ups=0.65, wpb=19500.7, bsz=693.1, num_updates=7200, lr=0.000166667, gnorm=0.397, clip=0, loss_scale=16, train_wall=103, gb_free=14.5, wall=6920
2023-08-27 15:34:09 | INFO | train_inner | epoch 007:    160 / 1191 loss=2.052, trans_loss=3.407, nll_loss=1.475, w2v_ctc_loss=1.052, task_loss=1.61, contrastive_loss=0.255, total=6654.46, n_correct=4253.09, ppl=2.78, accuracy=63.913, wps=18492.7, ups=0.96, wpb=19304.2, bsz=668.5, num_updates=7300, lr=0.000165521, gnorm=0.397, clip=0, loss_scale=16, train_wall=104, gb_free=12.9, wall=7024
2023-08-27 15:35:52 | INFO | train_inner | epoch 007:    260 / 1191 loss=2.039, trans_loss=3.403, nll_loss=1.467, w2v_ctc_loss=1.056, task_loss=1.544, contrastive_loss=0.169, total=6696.07, n_correct=4297.01, ppl=2.76, accuracy=64.172, wps=18777, ups=0.97, wpb=19401.8, bsz=677, num_updates=7400, lr=0.000164399, gnorm=0.398, clip=0, loss_scale=16, train_wall=103, gb_free=14.4, wall=7128
2023-08-27 15:37:34 | INFO | train_inner | epoch 007:    360 / 1191 loss=2.011, trans_loss=3.394, nll_loss=1.457, w2v_ctc_loss=1.028, task_loss=1.497, contrastive_loss=0.15, total=6730.93, n_correct=4346.85, ppl=2.75, accuracy=64.58, wps=19175.8, ups=0.98, wpb=19507.5, bsz=689.7, num_updates=7500, lr=0.000163299, gnorm=0.395, clip=0, loss_scale=16, train_wall=101, gb_free=12.6, wall=7229
2023-08-27 15:39:17 | INFO | train_inner | epoch 007:    460 / 1191 loss=2.041, trans_loss=3.405, nll_loss=1.472, w2v_ctc_loss=1.039, task_loss=1.451, contrastive_loss=0.245, total=6794.45, n_correct=4360.49, ppl=2.77, accuracy=64.177, wps=19159, ups=0.97, wpb=19686.8, bsz=712.1, num_updates=7600, lr=0.000162221, gnorm=0.398, clip=0, loss_scale=16, train_wall=102, gb_free=14.2, wall=7332
2023-08-27 15:41:01 | INFO | train_inner | epoch 007:    560 / 1191 loss=2.032, trans_loss=3.409, nll_loss=1.475, w2v_ctc_loss=1.048, task_loss=1.61, contrastive_loss=0.17, total=6686.65, n_correct=4286.89, ppl=2.78, accuracy=64.111, wps=18536.1, ups=0.96, wpb=19371.4, bsz=667.1, num_updates=7700, lr=0.000161165, gnorm=0.396, clip=0, loss_scale=16, train_wall=104, gb_free=11.3, wall=7437
2023-08-27 15:42:46 | INFO | train_inner | epoch 007:    660 / 1191 loss=2.039, trans_loss=3.409, nll_loss=1.476, w2v_ctc_loss=1.033, task_loss=1.526, contrastive_loss=0.25, total=6757.98, n_correct=4336.65, ppl=2.78, accuracy=64.171, wps=18665.5, ups=0.95, wpb=19580.8, bsz=692.3, num_updates=7800, lr=0.000160128, gnorm=0.395, clip=0, loss_scale=16, train_wall=104, gb_free=13.5, wall=7542
2023-08-27 15:44:30 | INFO | train_inner | epoch 007:    760 / 1191 loss=2.02, trans_loss=3.407, nll_loss=1.473, w2v_ctc_loss=1.037, task_loss=1.583, contrastive_loss=0.161, total=6682.96, n_correct=4297.97, ppl=2.78, accuracy=64.312, wps=18625, ups=0.96, wpb=19354.4, bsz=672.3, num_updates=7900, lr=0.000159111, gnorm=0.392, clip=0, loss_scale=16, train_wall=103, gb_free=14.1, wall=7645
2023-08-27 15:46:14 | INFO | train_inner | epoch 007:    860 / 1191 loss=2.036, trans_loss=3.412, nll_loss=1.48, w2v_ctc_loss=1.026, task_loss=1.611, contrastive_loss=0.275, total=6668.17, n_correct=4276.07, ppl=2.79, accuracy=64.127, wps=18539.9, ups=0.96, wpb=19310.4, bsz=660.1, num_updates=8000, lr=0.000158114, gnorm=0.4, clip=0, loss_scale=16, train_wall=103, gb_free=13.7, wall=7750
2023-08-27 15:46:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 15:46:47 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.059 | trans_loss 5.317 | nll_loss 2.557 | w2v_ctc_loss 1.323 | task_loss 8.395 | contrastive_loss 0.289 | total 6138.43 | n_correct 4019 | ppl 5.88 | accuracy 65.473 | uer 19.453 | wer 21.175 | raw_wer 21.175 | bleu 25.44 | wps 1737.2 | wpb 6138.4 | bsz 201.1 | num_updates 8000 | best_bleu 25.44
2023-08-27 15:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8000 updates
2023-08-27 15:46:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_7_8000.pt
2023-08-27 15:46:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_7_8000.pt
2023-08-27 15:46:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_7_8000.pt (epoch 7 @ 8000 updates, score 25.44) (writing took 11.635264800977893 seconds)
2023-08-27 15:48:44 | INFO | train_inner | epoch 007:    960 / 1191 loss=2.011, trans_loss=3.404, nll_loss=1.471, w2v_ctc_loss=1.031, task_loss=1.666, contrastive_loss=0.17, total=6620, n_correct=4266.17, ppl=2.77, accuracy=64.444, wps=12838.2, ups=0.67, wpb=19182.2, bsz=639.6, num_updates=8100, lr=0.000157135, gnorm=0.393, clip=0, loss_scale=16, train_wall=104, gb_free=12.4, wall=7899
2023-08-27 15:50:28 | INFO | train_inner | epoch 007:   1060 / 1191 loss=2.036, trans_loss=3.401, nll_loss=1.466, w2v_ctc_loss=1.028, task_loss=1.513, contrastive_loss=0.275, total=6677.74, n_correct=4310.36, ppl=2.76, accuracy=64.548, wps=18611.8, ups=0.96, wpb=19332.8, bsz=694.2, num_updates=8200, lr=0.000156174, gnorm=0.398, clip=0, loss_scale=16, train_wall=103, gb_free=13.5, wall=8003
2023-08-27 15:52:12 | INFO | train_inner | epoch 007:   1160 / 1191 loss=2.03, trans_loss=3.405, nll_loss=1.474, w2v_ctc_loss=1.03, task_loss=1.565, contrastive_loss=0.252, total=6739.69, n_correct=4339.91, ppl=2.78, accuracy=64.393, wps=18703.3, ups=0.96, wpb=19534.9, bsz=683.8, num_updates=8300, lr=0.00015523, gnorm=0.396, clip=0, loss_scale=16, train_wall=104, gb_free=13.3, wall=8107
2023-08-27 15:52:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 15:53:18 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.026 | trans_loss 5.314 | nll_loss 2.557 | w2v_ctc_loss 1.223 | task_loss 8.34 | contrastive_loss 0.279 | total 6138.43 | n_correct 4022.43 | ppl 5.88 | accuracy 65.529 | uer 19.236 | wer 21.09 | raw_wer 21.09 | bleu 25.22 | wps 1668.4 | wpb 6138.4 | bsz 201.1 | num_updates 8331 | best_bleu 25.44
2023-08-27 15:53:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8331 updates
2023-08-27 15:53:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_25.2204.pt
2023-08-27 15:53:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_25.2204.pt
2023-08-27 15:53:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_25.2204.pt (epoch 7 @ 8331 updates, score 25.22) (writing took 6.598870454006828 seconds)
2023-08-27 15:53:25 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-27 15:53:25 | INFO | train | epoch 007 | loss 2.033 | trans_loss 3.405 | nll_loss 1.472 | w2v_ctc_loss 1.038 | task_loss 1.559 | contrastive_loss 0.221 | total 6703.69 | n_correct 4307.33 | ppl 2.77 | accuracy 64.253 | wps 17399.6 | ups 0.9 | wpb 19422.7 | bsz 678.2 | num_updates 8331 | lr 0.000154941 | gnorm 0.396 | clip 0 | loss_scale 16 | train_wall 1228 | gb_free 12.9 | wall 8180
2023-08-27 15:53:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 15:53:25 | INFO | fairseq.trainer | begin training epoch 8
2023-08-27 15:53:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 15:54:44 | INFO | train_inner | epoch 008:     69 / 1191 loss=1.969, trans_loss=3.379, nll_loss=1.437, w2v_ctc_loss=0.991, task_loss=1.566, contrastive_loss=0.135, total=6722.88, n_correct=4386.67, ppl=2.71, accuracy=65.25, wps=12817.8, ups=0.66, wpb=19470.2, bsz=667.6, num_updates=8400, lr=0.000154303, gnorm=0.385, clip=0, loss_scale=16, train_wall=103, gb_free=13.9, wall=8259
2023-08-27 15:56:28 | INFO | train_inner | epoch 008:    169 / 1191 loss=1.99, trans_loss=3.37, nll_loss=1.429, w2v_ctc_loss=0.983, task_loss=1.505, contrastive_loss=0.284, total=6742.72, n_correct=4405.22, ppl=2.69, accuracy=65.333, wps=18859.6, ups=0.96, wpb=19552.4, bsz=709.6, num_updates=8500, lr=0.000153393, gnorm=0.389, clip=0, loss_scale=16, train_wall=103, gb_free=10.2, wall=8363
2023-08-27 15:58:12 | INFO | train_inner | epoch 008:    269 / 1191 loss=1.978, trans_loss=3.375, nll_loss=1.433, w2v_ctc_loss=0.986, task_loss=1.535, contrastive_loss=0.207, total=6747.41, n_correct=4413.37, ppl=2.7, accuracy=65.408, wps=18710, ups=0.96, wpb=19548.2, bsz=695.3, num_updates=8600, lr=0.000152499, gnorm=0.385, clip=0, loss_scale=16, train_wall=104, gb_free=14.8, wall=8467
2023-08-27 15:59:58 | INFO | train_inner | epoch 008:    369 / 1191 loss=1.965, trans_loss=3.382, nll_loss=1.444, w2v_ctc_loss=0.995, task_loss=1.718, contrastive_loss=0.132, total=6627.92, n_correct=4308.74, ppl=2.72, accuracy=65.009, wps=18161.3, ups=0.95, wpb=19213, bsz=633.5, num_updates=8700, lr=0.00015162, gnorm=0.382, clip=0, loss_scale=16, train_wall=105, gb_free=13.8, wall=8573
2023-08-27 16:01:43 | INFO | train_inner | epoch 008:    469 / 1191 loss=1.979, trans_loss=3.375, nll_loss=1.435, w2v_ctc_loss=0.99, task_loss=1.573, contrastive_loss=0.204, total=6675.94, n_correct=4358.1, ppl=2.7, accuracy=65.281, wps=18472.8, ups=0.95, wpb=19348.3, bsz=672.2, num_updates=8800, lr=0.000150756, gnorm=0.391, clip=0, loss_scale=16, train_wall=104, gb_free=14.1, wall=8678
2023-08-27 16:03:26 | INFO | train_inner | epoch 008:    569 / 1191 loss=1.963, trans_loss=3.376, nll_loss=1.436, w2v_ctc_loss=0.974, task_loss=1.616, contrastive_loss=0.212, total=6678.98, n_correct=4361.83, ppl=2.71, accuracy=65.307, wps=18656.9, ups=0.96, wpb=19354.9, bsz=669.3, num_updates=8900, lr=0.000149906, gnorm=0.385, clip=0, loss_scale=16, train_wall=103, gb_free=15.2, wall=8782
2023-08-27 16:05:09 | INFO | train_inner | epoch 008:    669 / 1191 loss=1.956, trans_loss=3.378, nll_loss=1.438, w2v_ctc_loss=0.98, task_loss=1.527, contrastive_loss=0.138, total=6739.84, n_correct=4409.77, ppl=2.71, accuracy=65.428, wps=19030.9, ups=0.97, wpb=19522.9, bsz=681.8, num_updates=9000, lr=0.000149071, gnorm=0.388, clip=0, loss_scale=16, train_wall=102, gb_free=14.4, wall=8884
2023-08-27 16:06:52 | INFO | train_inner | epoch 008:    769 / 1191 loss=1.972, trans_loss=3.38, nll_loss=1.442, w2v_ctc_loss=0.983, task_loss=1.591, contrastive_loss=0.217, total=6673.2, n_correct=4356.33, ppl=2.72, accuracy=65.281, wps=18694.3, ups=0.97, wpb=19340.5, bsz=668.7, num_updates=9100, lr=0.00014825, gnorm=0.388, clip=0, loss_scale=16, train_wall=103, gb_free=13.8, wall=8988
2023-08-27 16:08:36 | INFO | train_inner | epoch 008:    869 / 1191 loss=1.964, trans_loss=3.371, nll_loss=1.43, w2v_ctc_loss=0.984, task_loss=1.459, contrastive_loss=0.167, total=6799.01, n_correct=4464.79, ppl=2.69, accuracy=65.668, wps=19035.9, ups=0.97, wpb=19701.4, bsz=704.6, num_updates=9200, lr=0.000147442, gnorm=0.393, clip=0, loss_scale=32, train_wall=103, gb_free=14, wall=9091
2023-08-27 16:10:20 | INFO | train_inner | epoch 008:    969 / 1191 loss=1.985, trans_loss=3.389, nll_loss=1.451, w2v_ctc_loss=0.981, task_loss=1.611, contrastive_loss=0.261, total=6662.29, n_correct=4342.39, ppl=2.73, accuracy=65.179, wps=18539.8, ups=0.96, wpb=19292.3, bsz=660.9, num_updates=9300, lr=0.000146647, gnorm=0.387, clip=0, loss_scale=32, train_wall=104, gb_free=12.6, wall=9195
2023-08-27 16:12:04 | INFO | train_inner | epoch 008:   1069 / 1191 loss=1.954, trans_loss=3.384, nll_loss=1.442, w2v_ctc_loss=0.981, task_loss=1.611, contrastive_loss=0.123, total=6679.42, n_correct=4367.28, ppl=2.72, accuracy=65.384, wps=18576.8, ups=0.96, wpb=19325.2, bsz=659, num_updates=9400, lr=0.000145865, gnorm=0.386, clip=0, loss_scale=32, train_wall=103, gb_free=12.1, wall=9299
2023-08-27 16:13:47 | INFO | train_inner | epoch 008:   1169 / 1191 loss=1.976, trans_loss=3.365, nll_loss=1.425, w2v_ctc_loss=0.96, task_loss=1.434, contrastive_loss=0.313, total=6731.13, n_correct=4426.84, ppl=2.68, accuracy=65.767, wps=18952.3, ups=0.97, wpb=19507.7, bsz=720.8, num_updates=9500, lr=0.000145095, gnorm=0.389, clip=0, loss_scale=32, train_wall=102, gb_free=11.7, wall=9402
2023-08-27 16:14:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 16:14:42 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 3.999 | trans_loss 5.285 | nll_loss 2.519 | w2v_ctc_loss 1.201 | task_loss 8.429 | contrastive_loss 0.278 | total 6138.43 | n_correct 4051.71 | ppl 5.73 | accuracy 66.006 | uer 18.413 | wer 20.13 | raw_wer 20.13 | bleu 25.92 | wps 1759.4 | wpb 6138.4 | bsz 201.1 | num_updates 9522 | best_bleu 25.92
2023-08-27 16:14:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 9522 updates
2023-08-27 16:14:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 16:14:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 16:14:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 8 @ 9522 updates, score 25.92) (writing took 10.70643211598508 seconds)
2023-08-27 16:14:53 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-27 16:14:53 | INFO | train | epoch 008 | loss 1.97 | trans_loss 3.376 | nll_loss 1.436 | w2v_ctc_loss 0.981 | task_loss 1.561 | contrastive_loss 0.205 | total 6703.69 | n_correct 4383.07 | ppl 2.71 | accuracy 65.383 | wps 17956.8 | ups 0.92 | wpb 19422.7 | bsz 678.2 | num_updates 9522 | lr 0.000144928 | gnorm 0.387 | clip 0 | loss_scale 32 | train_wall 1229 | gb_free 14.2 | wall 9468
2023-08-27 16:14:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 16:14:53 | INFO | fairseq.trainer | begin training epoch 9
2023-08-27 16:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 16:16:20 | INFO | train_inner | epoch 009:     78 / 1191 loss=1.931, trans_loss=3.35, nll_loss=1.402, w2v_ctc_loss=0.942, task_loss=1.574, contrastive_loss=0.227, total=6670.48, n_correct=4417.58, ppl=2.64, accuracy=66.226, wps=12605.6, ups=0.65, wpb=19326.3, bsz=674.1, num_updates=9600, lr=0.000144338, gnorm=0.383, clip=0, loss_scale=32, train_wall=102, gb_free=5.2, wall=9556
2023-08-27 16:18:05 | INFO | train_inner | epoch 009:    178 / 1191 loss=1.913, trans_loss=3.342, nll_loss=1.393, w2v_ctc_loss=0.928, task_loss=1.515, contrastive_loss=0.198, total=6766.29, n_correct=4496.19, ppl=2.63, accuracy=66.45, wps=18783.6, ups=0.96, wpb=19611.7, bsz=696.1, num_updates=9700, lr=0.000143592, gnorm=0.377, clip=0, loss_scale=32, train_wall=104, gb_free=14.4, wall=9660
2023-08-27 16:19:48 | INFO | train_inner | epoch 009:    278 / 1191 loss=1.923, trans_loss=3.356, nll_loss=1.408, w2v_ctc_loss=0.95, task_loss=1.475, contrastive_loss=0.143, total=6807.67, n_correct=4503.3, ppl=2.65, accuracy=66.15, wps=19066, ups=0.97, wpb=19706.5, bsz=702.6, num_updates=9800, lr=0.000142857, gnorm=0.379, clip=0, loss_scale=32, train_wall=103, gb_free=14.2, wall=9763
2023-08-27 16:21:34 | INFO | train_inner | epoch 009:    378 / 1191 loss=1.922, trans_loss=3.353, nll_loss=1.407, w2v_ctc_loss=0.937, task_loss=1.542, contrastive_loss=0.198, total=6763.31, n_correct=4476.67, ppl=2.65, accuracy=66.191, wps=18520.2, ups=0.94, wpb=19598.5, bsz=692.1, num_updates=9900, lr=0.000142134, gnorm=0.38, clip=0, loss_scale=32, train_wall=105, gb_free=13.8, wall=9869
2023-08-27 16:23:19 | INFO | train_inner | epoch 009:    478 / 1191 loss=1.935, trans_loss=3.355, nll_loss=1.411, w2v_ctc_loss=0.951, task_loss=1.556, contrastive_loss=0.184, total=6706.27, n_correct=4442.62, ppl=2.66, accuracy=66.246, wps=18525, ups=0.95, wpb=19436.3, bsz=686.6, num_updates=10000, lr=0.000141421, gnorm=0.389, clip=0, loss_scale=32, train_wall=104, gb_free=15, wall=9974
2023-08-27 16:23:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 16:23:52 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.991 | trans_loss 5.27 | nll_loss 2.499 | w2v_ctc_loss 1.22 | task_loss 8.484 | contrastive_loss 0.257 | total 6138.43 | n_correct 4072.14 | ppl 5.65 | accuracy 66.339 | uer 18.086 | wer 19.807 | raw_wer 19.807 | bleu 25.99 | wps 1707.8 | wpb 6138.4 | bsz 201.1 | num_updates 10000 | best_bleu 25.99
2023-08-27 16:23:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10000 updates
2023-08-27 16:23:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_9_10000.pt
2023-08-27 16:23:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_9_10000.pt
2023-08-27 16:24:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_9_10000.pt (epoch 9 @ 10000 updates, score 25.99) (writing took 12.70058321399847 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492, device='cuda:0')
2023-08-27 16:25:47 | INFO | train_inner | epoch 009:    578 / 1191 loss=1.915, trans_loss=3.351, nll_loss=1.405, w2v_ctc_loss=0.932, task_loss=1.585, contrastive_loss=0.187, total=6629.95, n_correct=4394.94, ppl=2.65, accuracy=66.289, wps=12972.9, ups=0.68, wpb=19209.9, bsz=668.2, num_updates=10100, lr=0.00014072, gnorm=0.312, clip=0, loss_scale=32, train_wall=102, gb_free=14.1, wall=10122
2023-08-27 16:27:30 | INFO | train_inner | epoch 009:    678 / 1191 loss=1.934, trans_loss=3.363, nll_loss=1.418, w2v_ctc_loss=0.945, task_loss=1.727, contrastive_loss=0.226, total=6560.8, n_correct=4327.99, ppl=2.67, accuracy=65.967, wps=18351, ups=0.97, wpb=18998.2, bsz=624.1, num_updates=10200, lr=0.000140028, gnorm=0.315, clip=0, loss_scale=32, train_wall=103, gb_free=12.7, wall=10226
2023-08-27 16:29:14 | INFO | train_inner | epoch 009:    778 / 1191 loss=1.937, trans_loss=3.357, nll_loss=1.414, w2v_ctc_loss=0.936, task_loss=1.56, contrastive_loss=0.247, total=6690.96, n_correct=4429.91, ppl=2.67, accuracy=66.207, wps=18659, ups=0.96, wpb=19392.1, bsz=683.6, num_updates=10300, lr=0.000139347, gnorm=0.317, clip=0, loss_scale=32, train_wall=103, gb_free=11.4, wall=10330
2023-08-27 16:30:59 | INFO | train_inner | epoch 009:    878 / 1191 loss=1.914, trans_loss=3.36, nll_loss=1.417, w2v_ctc_loss=0.94, task_loss=1.577, contrastive_loss=0.147, total=6723.4, n_correct=4444.7, ppl=2.67, accuracy=66.108, wps=18708.3, ups=0.96, wpb=19482.4, bsz=667.5, num_updates=10400, lr=0.000138675, gnorm=0.311, clip=0, loss_scale=32, train_wall=104, gb_free=14.1, wall=10434
2023-08-27 16:32:43 | INFO | train_inner | epoch 009:    978 / 1191 loss=1.925, trans_loss=3.355, nll_loss=1.411, w2v_ctc_loss=0.937, task_loss=1.554, contrastive_loss=0.205, total=6716.16, n_correct=4449.65, ppl=2.66, accuracy=66.253, wps=18642.8, ups=0.96, wpb=19454.7, bsz=682.1, num_updates=10500, lr=0.000138013, gnorm=0.315, clip=0, loss_scale=32, train_wall=104, gb_free=13.8, wall=10538
2023-08-27 16:34:26 | INFO | train_inner | epoch 009:   1078 / 1191 loss=1.935, trans_loss=3.354, nll_loss=1.411, w2v_ctc_loss=0.935, task_loss=1.537, contrastive_loss=0.268, total=6668, n_correct=4422.26, ppl=2.66, accuracy=66.321, wps=18658.5, ups=0.97, wpb=19324.5, bsz=679.8, num_updates=10600, lr=0.000137361, gnorm=0.313, clip=0, loss_scale=32, train_wall=103, gb_free=13.3, wall=10642
2023-08-27 16:36:10 | INFO | train_inner | epoch 009:   1178 / 1191 loss=1.919, trans_loss=3.355, nll_loss=1.411, w2v_ctc_loss=0.951, task_loss=1.611, contrastive_loss=0.133, total=6696.66, n_correct=4431.23, ppl=2.66, accuracy=66.171, wps=18750.5, ups=0.97, wpb=19407.4, bsz=660.1, num_updates=10700, lr=0.000136717, gnorm=0.312, clip=0, loss_scale=32, train_wall=103, gb_free=12.8, wall=10745
2023-08-27 16:36:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2492, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2492, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2492, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2492, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2492, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2492, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2492, device='cuda:3')
2023-08-27 16:36:57 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.972 | trans_loss 5.262 | nll_loss 2.488 | w2v_ctc_loss 1.17 | task_loss 8.464 | contrastive_loss 0.27 | total 6138.43 | n_correct 4078.57 | ppl 5.61 | accuracy 66.443 | uer 18.257 | wer 19.989 | raw_wer 19.989 | bleu 25.87 | wps 1678.5 | wpb 6138.4 | bsz 201.1 | num_updates 10713 | best_bleu 25.99
2023-08-27 16:36:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10713 updates
2023-08-27 16:36:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_25.8701.pt
2023-08-27 16:36:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_25.8701.pt
2023-08-27 16:37:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_25.8701.pt (epoch 9 @ 10713 updates, score 25.87) (writing took 7.405177726002876 seconds)
2023-08-27 16:37:05 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-27 16:37:05 | INFO | train | epoch 009 | loss 1.924 | trans_loss 3.354 | nll_loss 1.408 | w2v_ctc_loss 0.939 | task_loss 1.561 | contrastive_loss 0.194 | total 6703.69 | n_correct 4440.11 | ppl 2.65 | accuracy 66.234 | wps 17367.3 | ups 0.89 | wpb 19422.7 | bsz 678.2 | num_updates 10713 | lr 0.000136634 | gnorm 0.341 | clip 0 | loss_scale 32 | train_wall 1230 | gb_free 14.5 | wall 10800
2023-08-27 16:37:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 16:37:05 | INFO | fairseq.trainer | begin training epoch 10
2023-08-27 16:37:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 16:38:42 | INFO | train_inner | epoch 010:     87 / 1191 loss=1.867, trans_loss=3.324, nll_loss=1.371, w2v_ctc_loss=0.9, task_loss=1.599, contrastive_loss=0.127, total=6628.51, n_correct=4460.13, ppl=2.59, accuracy=67.287, wps=12594.8, ups=0.66, wpb=19205.8, bsz=661.7, num_updates=10800, lr=0.000136083, gnorm=0.308, clip=0, loss_scale=32, train_wall=102, gb_free=6.8, wall=10898
2023-08-27 16:40:27 | INFO | train_inner | epoch 010:    187 / 1191 loss=1.892, trans_loss=3.337, nll_loss=1.387, w2v_ctc_loss=0.911, task_loss=1.561, contrastive_loss=0.189, total=6685.99, n_correct=4471.13, ppl=2.62, accuracy=66.873, wps=18569.1, ups=0.96, wpb=19371, bsz=684.8, num_updates=10900, lr=0.000135457, gnorm=0.309, clip=0, loss_scale=32, train_wall=104, gb_free=14.3, wall=11002
2023-08-27 16:42:10 | INFO | train_inner | epoch 010:    287 / 1191 loss=1.892, trans_loss=3.331, nll_loss=1.378, w2v_ctc_loss=0.902, task_loss=1.544, contrastive_loss=0.23, total=6738.39, n_correct=4518.78, ppl=2.6, accuracy=67.06, wps=18916.2, ups=0.97, wpb=19519.6, bsz=684.2, num_updates=11000, lr=0.00013484, gnorm=0.307, clip=0, loss_scale=32, train_wall=102, gb_free=13.6, wall=11105
2023-08-27 16:43:55 | INFO | train_inner | epoch 010:    387 / 1191 loss=1.914, trans_loss=3.334, nll_loss=1.384, w2v_ctc_loss=0.91, task_loss=1.423, contrastive_loss=0.275, total=6868.36, n_correct=4601.07, ppl=2.61, accuracy=66.989, wps=18908.2, ups=0.95, wpb=19898.4, bsz=739.5, num_updates=11100, lr=0.000134231, gnorm=0.311, clip=0, loss_scale=32, train_wall=105, gb_free=14.8, wall=11211
2023-08-27 16:45:39 | INFO | train_inner | epoch 010:    487 / 1191 loss=1.891, trans_loss=3.335, nll_loss=1.383, w2v_ctc_loss=0.924, task_loss=1.584, contrastive_loss=0.145, total=6729.04, n_correct=4506.44, ppl=2.61, accuracy=66.97, wps=18792, ups=0.96, wpb=19483.7, bsz=671, num_updates=11200, lr=0.000133631, gnorm=0.31, clip=0, loss_scale=64, train_wall=103, gb_free=12.2, wall=11314
2023-08-27 16:47:22 | INFO | train_inner | epoch 010:    587 / 1191 loss=1.891, trans_loss=3.338, nll_loss=1.389, w2v_ctc_loss=0.91, task_loss=1.589, contrastive_loss=0.19, total=6683.64, n_correct=4468.26, ppl=2.62, accuracy=66.854, wps=18783.9, ups=0.97, wpb=19361.2, bsz=663.3, num_updates=11300, lr=0.000133038, gnorm=0.309, clip=0, loss_scale=64, train_wall=102, gb_free=15.2, wall=11417
2023-08-27 16:49:07 | INFO | train_inner | epoch 010:    687 / 1191 loss=1.896, trans_loss=3.336, nll_loss=1.388, w2v_ctc_loss=0.914, task_loss=1.524, contrastive_loss=0.184, total=6763.77, n_correct=4526.67, ppl=2.62, accuracy=66.925, wps=18673.8, ups=0.95, wpb=19601.9, bsz=698.1, num_updates=11400, lr=0.000132453, gnorm=0.311, clip=0, loss_scale=64, train_wall=104, gb_free=15.5, wall=11522
2023-08-27 16:50:51 | INFO | train_inner | epoch 010:    787 / 1191 loss=1.868, trans_loss=3.334, nll_loss=1.385, w2v_ctc_loss=0.908, task_loss=1.63, contrastive_loss=0.106, total=6659.27, n_correct=4463.65, ppl=2.61, accuracy=67.029, wps=18618.8, ups=0.96, wpb=19295.1, bsz=657.1, num_updates=11500, lr=0.000131876, gnorm=0.307, clip=0, loss_scale=64, train_wall=103, gb_free=14.2, wall=11626
2023-08-27 16:52:36 | INFO | train_inner | epoch 010:    887 / 1191 loss=1.899, trans_loss=3.341, nll_loss=1.394, w2v_ctc_loss=0.921, task_loss=1.714, contrastive_loss=0.189, total=6535.93, n_correct=4364.12, ppl=2.63, accuracy=66.771, wps=17961, ups=0.95, wpb=18942.2, bsz=635.2, num_updates=11600, lr=0.000131306, gnorm=0.316, clip=0, loss_scale=64, train_wall=105, gb_free=8.9, wall=11731
2023-08-27 16:54:19 | INFO | train_inner | epoch 010:    987 / 1191 loss=1.878, trans_loss=3.333, nll_loss=1.385, w2v_ctc_loss=0.909, task_loss=1.505, contrastive_loss=0.138, total=6746.84, n_correct=4523.04, ppl=2.61, accuracy=67.039, wps=18918.7, ups=0.97, wpb=19548.2, bsz=682.1, num_updates=11700, lr=0.000130744, gnorm=0.308, clip=0, loss_scale=64, train_wall=103, gb_free=13.3, wall=11835
2023-08-27 16:56:03 | INFO | train_inner | epoch 010:   1087 / 1191 loss=1.886, trans_loss=3.331, nll_loss=1.384, w2v_ctc_loss=0.919, task_loss=1.54, contrastive_loss=0.137, total=6690.18, n_correct=4485, ppl=2.61, accuracy=67.039, wps=18643.4, ups=0.96, wpb=19398, bsz=682.6, num_updates=11800, lr=0.000130189, gnorm=0.309, clip=0, loss_scale=64, train_wall=103, gb_free=15, wall=11939
2023-08-27 16:56:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-27 16:57:48 | INFO | train_inner | epoch 010:   1188 / 1191 loss=1.904, trans_loss=3.34, nll_loss=1.392, w2v_ctc_loss=0.907, task_loss=1.537, contrastive_loss=0.269, total=6728.45, n_correct=4495.97, ppl=2.62, accuracy=66.82, wps=18665.6, ups=0.96, wpb=19487, bsz=684.2, num_updates=11900, lr=0.000129641, gnorm=0.312, clip=0, loss_scale=32, train_wall=104, gb_free=14.5, wall=12043
2023-08-27 16:57:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 16:58:23 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.956 | trans_loss 5.239 | nll_loss 2.461 | w2v_ctc_loss 1.169 | task_loss 8.507 | contrastive_loss 0.269 | total 6138.43 | n_correct 4105.86 | ppl 5.51 | accuracy 66.888 | uer 17.68 | wer 19.509 | raw_wer 19.509 | bleu 26.17 | wps 1771.9 | wpb 6138.4 | bsz 201.1 | num_updates 11903 | best_bleu 26.17
2023-08-27 16:58:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11903 updates
2023-08-27 16:58:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 16:58:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 16:58:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 10 @ 11903 updates, score 26.17) (writing took 11.642533876001835 seconds)
2023-08-27 16:58:35 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-27 16:58:35 | INFO | train | epoch 010 | loss 1.89 | trans_loss 3.334 | nll_loss 1.385 | w2v_ctc_loss 0.911 | task_loss 1.563 | contrastive_loss 0.183 | total 6703.41 | n_correct 4489.43 | ppl 2.61 | accuracy 66.972 | wps 17910 | ups 0.92 | wpb 19421.8 | bsz 677.9 | num_updates 11903 | lr 0.000129624 | gnorm 0.31 | clip 0 | loss_scale 32 | train_wall 1230 | gb_free 12.3 | wall 12091
2023-08-27 16:58:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 16:58:36 | INFO | fairseq.trainer | begin training epoch 11
2023-08-27 16:58:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 17:00:24 | INFO | train_inner | epoch 011:     97 / 1191 loss=1.862, trans_loss=3.313, nll_loss=1.357, w2v_ctc_loss=0.894, task_loss=1.668, contrastive_loss=0.158, total=6629.5, n_correct=4479, ppl=2.56, accuracy=67.562, wps=12341.4, ups=0.64, wpb=19215.2, bsz=646.6, num_updates=12000, lr=0.000129099, gnorm=0.312, clip=0, loss_scale=32, train_wall=103, gb_free=12.9, wall=12199
2023-08-27 17:00:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 17:00:56 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.984 | trans_loss 5.255 | nll_loss 2.473 | w2v_ctc_loss 1.228 | task_loss 8.53 | contrastive_loss 0.269 | total 6138.43 | n_correct 4091 | ppl 5.55 | accuracy 66.646 | uer 18.116 | wer 19.888 | raw_wer 19.888 | bleu 26.19 | wps 1747.8 | wpb 6138.4 | bsz 201.1 | num_updates 12000 | best_bleu 26.19
2023-08-27 17:00:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12000 updates
2023-08-27 17:00:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_11_12000.pt
2023-08-27 17:00:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_11_12000.pt
2023-08-27 17:01:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_11_12000.pt (epoch 11 @ 12000 updates, score 26.19) (writing took 11.918447130999994 seconds)
2023-08-27 17:02:52 | INFO | train_inner | epoch 011:    197 / 1191 loss=1.857, trans_loss=3.313, nll_loss=1.356, w2v_ctc_loss=0.872, task_loss=1.531, contrastive_loss=0.221, total=6695.87, n_correct=4535.32, ppl=2.56, accuracy=67.733, wps=13098.4, ups=0.68, wpb=19390.4, bsz=686.9, num_updates=12100, lr=0.000128565, gnorm=0.308, clip=0, loss_scale=32, train_wall=102, gb_free=14.4, wall=12347
2023-08-27 17:04:35 | INFO | train_inner | epoch 011:    297 / 1191 loss=1.854, trans_loss=3.312, nll_loss=1.356, w2v_ctc_loss=0.881, task_loss=1.596, contrastive_loss=0.182, total=6605.27, n_correct=4470.88, ppl=2.56, accuracy=67.687, wps=18464.8, ups=0.96, wpb=19137.7, bsz=664.2, num_updates=12200, lr=0.000128037, gnorm=0.309, clip=0, loss_scale=32, train_wall=103, gb_free=13.3, wall=12451
2023-08-27 17:06:19 | INFO | train_inner | epoch 011:    397 / 1191 loss=1.87, trans_loss=3.315, nll_loss=1.362, w2v_ctc_loss=0.884, task_loss=1.608, contrastive_loss=0.235, total=6597.68, n_correct=4456.57, ppl=2.57, accuracy=67.548, wps=18469.5, ups=0.97, wpb=19125.4, bsz=664.1, num_updates=12300, lr=0.000127515, gnorm=0.311, clip=0, loss_scale=32, train_wall=103, gb_free=10.9, wall=12554
2023-08-27 17:08:04 | INFO | train_inner | epoch 011:    497 / 1191 loss=1.854, trans_loss=3.322, nll_loss=1.371, w2v_ctc_loss=0.894, task_loss=1.675, contrastive_loss=0.108, total=6643.92, n_correct=4479.01, ppl=2.59, accuracy=67.415, wps=18323.8, ups=0.95, wpb=19259.8, bsz=646.3, num_updates=12400, lr=0.000127, gnorm=0.31, clip=0, loss_scale=32, train_wall=104, gb_free=11.1, wall=12659
2023-08-27 17:09:48 | INFO | train_inner | epoch 011:    597 / 1191 loss=1.851, trans_loss=3.317, nll_loss=1.366, w2v_ctc_loss=0.893, task_loss=1.565, contrastive_loss=0.107, total=6663.6, n_correct=4499.29, ppl=2.58, accuracy=67.52, wps=18636.6, ups=0.96, wpb=19323.3, bsz=673.3, num_updates=12500, lr=0.000126491, gnorm=0.305, clip=0, loss_scale=32, train_wall=103, gb_free=13.5, wall=12763
2023-08-27 17:11:33 | INFO | train_inner | epoch 011:    697 / 1191 loss=1.854, trans_loss=3.317, nll_loss=1.365, w2v_ctc_loss=0.883, task_loss=1.617, contrastive_loss=0.156, total=6694.31, n_correct=4524.13, ppl=2.58, accuracy=67.582, wps=18435, ups=0.95, wpb=19409, bsz=667.3, num_updates=12600, lr=0.000125988, gnorm=0.308, clip=0, loss_scale=32, train_wall=104, gb_free=4.9, wall=12868
2023-08-27 17:13:18 | INFO | train_inner | epoch 011:    797 / 1191 loss=1.875, trans_loss=3.324, nll_loss=1.373, w2v_ctc_loss=0.896, task_loss=1.521, contrastive_loss=0.175, total=6797.24, n_correct=4583.14, ppl=2.59, accuracy=67.426, wps=18761.4, ups=0.95, wpb=19694.2, bsz=704.4, num_updates=12700, lr=0.000125491, gnorm=0.31, clip=0, loss_scale=32, train_wall=104, gb_free=12, wall=12973
2023-08-27 17:15:02 | INFO | train_inner | epoch 011:    897 / 1191 loss=1.855, trans_loss=3.325, nll_loss=1.372, w2v_ctc_loss=0.877, task_loss=1.54, contrastive_loss=0.162, total=6767.48, n_correct=4565.46, ppl=2.59, accuracy=67.462, wps=18770.2, ups=0.96, wpb=19590.9, bsz=680, num_updates=12800, lr=0.000125, gnorm=0.306, clip=0, loss_scale=32, train_wall=104, gb_free=11, wall=13078
2023-08-27 17:16:48 | INFO | train_inner | epoch 011:    997 / 1191 loss=1.865, trans_loss=3.32, nll_loss=1.367, w2v_ctc_loss=0.867, task_loss=1.462, contrastive_loss=0.241, total=6800.24, n_correct=4601.77, ppl=2.58, accuracy=67.671, wps=18626.9, ups=0.95, wpb=19686.1, bsz=710.6, num_updates=12900, lr=0.000124515, gnorm=0.308, clip=0, loss_scale=32, train_wall=105, gb_free=14.5, wall=13183
2023-08-27 17:18:32 | INFO | train_inner | epoch 011:   1097 / 1191 loss=1.875, trans_loss=3.318, nll_loss=1.366, w2v_ctc_loss=0.883, task_loss=1.462, contrastive_loss=0.258, total=6767.7, n_correct=4577.69, ppl=2.58, accuracy=67.64, wps=18846.4, ups=0.96, wpb=19611.7, bsz=704, num_updates=13000, lr=0.000124035, gnorm=0.309, clip=0, loss_scale=32, train_wall=103, gb_free=13.2, wall=13287
2023-08-27 17:20:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 17:20:43 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.958 | trans_loss 5.233 | nll_loss 2.45 | w2v_ctc_loss 1.197 | task_loss 8.482 | contrastive_loss 0.259 | total 6138.43 | n_correct 4115.57 | ppl 5.47 | accuracy 67.046 | uer 17.479 | wer 19.126 | raw_wer 19.126 | bleu 26.49 | wps 1671.8 | wpb 6138.4 | bsz 201.1 | num_updates 13094 | best_bleu 26.49
2023-08-27 17:20:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 13094 updates
2023-08-27 17:20:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 17:20:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 17:20:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 11 @ 13094 updates, score 26.49) (writing took 11.847980104008457 seconds)
2023-08-27 17:20:56 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-27 17:20:56 | INFO | train | epoch 011 | loss 1.861 | trans_loss 3.318 | nll_loss 1.365 | w2v_ctc_loss 0.884 | task_loss 1.561 | contrastive_loss 0.181 | total 6703.69 | n_correct 4529.08 | ppl 2.58 | accuracy 67.561 | wps 17256.5 | ups 0.89 | wpb 19422.7 | bsz 678.2 | num_updates 13094 | lr 0.000123589 | gnorm 0.309 | clip 0 | loss_scale 32 | train_wall 1233 | gb_free 13.4 | wall 13431
2023-08-27 17:20:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 17:20:56 | INFO | fairseq.trainer | begin training epoch 12
2023-08-27 17:20:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-27 17:21:10 | INFO | train_inner | epoch 012:      6 / 1191 loss=1.855, trans_loss=3.323, nll_loss=1.37, w2v_ctc_loss=0.88, task_loss=1.468, contrastive_loss=0.156, total=6794.94, n_correct=4591.5, ppl=2.59, accuracy=67.572, wps=12470.5, ups=0.63, wpb=19667.6, bsz=708.4, num_updates=13100, lr=0.00012356, gnorm=0.307, clip=0, loss_scale=32, train_wall=103, gb_free=12.2, wall=13445
2023-08-27 17:22:54 | INFO | train_inner | epoch 012:    106 / 1191 loss=1.81, trans_loss=3.294, nll_loss=1.334, w2v_ctc_loss=0.853, task_loss=1.578, contrastive_loss=0.105, total=6733.34, n_correct=4604.81, ppl=2.52, accuracy=68.388, wps=18711.9, ups=0.96, wpb=19508, bsz=668.8, num_updates=13200, lr=0.000123091, gnorm=0.304, clip=0, loss_scale=32, train_wall=104, gb_free=13.9, wall=13549
2023-08-27 17:24:38 | INFO | train_inner | epoch 012:    206 / 1191 loss=1.831, trans_loss=3.3, nll_loss=1.341, w2v_ctc_loss=0.86, task_loss=1.57, contrastive_loss=0.174, total=6717.37, n_correct=4575.42, ppl=2.53, accuracy=68.113, wps=18763.8, ups=0.96, wpb=19462.2, bsz=668.3, num_updates=13300, lr=0.000122628, gnorm=0.307, clip=0, loss_scale=32, train_wall=103, gb_free=12.2, wall=13653
2023-08-27 17:26:22 | INFO | train_inner | epoch 012:    306 / 1191 loss=1.849, trans_loss=3.303, nll_loss=1.347, w2v_ctc_loss=0.862, task_loss=1.53, contrastive_loss=0.234, total=6703.8, n_correct=4565.21, ppl=2.54, accuracy=68.099, wps=18606.6, ups=0.96, wpb=19428.9, bsz=689.6, num_updates=13400, lr=0.000122169, gnorm=0.308, clip=0, loss_scale=32, train_wall=104, gb_free=13.9, wall=13757
2023-08-27 17:28:05 | INFO | train_inner | epoch 012:    406 / 1191 loss=1.831, trans_loss=3.301, nll_loss=1.344, w2v_ctc_loss=0.847, task_loss=1.459, contrastive_loss=0.208, total=6770.13, n_correct=4616.45, ppl=2.54, accuracy=68.188, wps=18982.3, ups=0.97, wpb=19616.1, bsz=706, num_updates=13500, lr=0.000121716, gnorm=0.307, clip=0, loss_scale=32, train_wall=103, gb_free=14.6, wall=13861
2023-08-27 17:29:49 | INFO | train_inner | epoch 012:    506 / 1191 loss=1.812, trans_loss=3.299, nll_loss=1.341, w2v_ctc_loss=0.849, task_loss=1.491, contrastive_loss=0.113, total=6749.24, n_correct=4611.54, ppl=2.53, accuracy=68.327, wps=18924.6, ups=0.97, wpb=19550.5, bsz=693.1, num_updates=13600, lr=0.000121268, gnorm=0.309, clip=0, loss_scale=32, train_wall=103, gb_free=15.3, wall=13964
2023-08-27 17:31:33 | INFO | train_inner | epoch 012:    606 / 1191 loss=1.845, trans_loss=3.305, nll_loss=1.349, w2v_ctc_loss=0.867, task_loss=1.615, contrastive_loss=0.197, total=6723.44, n_correct=4573.85, ppl=2.55, accuracy=68.028, wps=18623.9, ups=0.96, wpb=19479, bsz=675.6, num_updates=13700, lr=0.000120824, gnorm=0.312, clip=0, loss_scale=32, train_wall=104, gb_free=14.8, wall=14069
2023-08-27 17:32:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-27 17:33:18 | INFO | train_inner | epoch 012:    707 / 1191 loss=1.834, trans_loss=3.296, nll_loss=1.341, w2v_ctc_loss=0.862, task_loss=1.511, contrastive_loss=0.195, total=6750.58, n_correct=4603.85, ppl=2.53, accuracy=68.199, wps=18658.1, ups=0.95, wpb=19574.8, bsz=689.2, num_updates=13800, lr=0.000120386, gnorm=0.307, clip=0, loss_scale=16, train_wall=104, gb_free=14.3, wall=14174
2023-08-27 17:35:03 | INFO | train_inner | epoch 012:    807 / 1191 loss=1.839, trans_loss=3.313, nll_loss=1.357, w2v_ctc_loss=0.868, task_loss=1.613, contrastive_loss=0.155, total=6655.82, n_correct=4518.03, ppl=2.56, accuracy=67.881, wps=18488.4, ups=0.96, wpb=19273.2, bsz=663.1, num_updates=13900, lr=0.000119952, gnorm=0.311, clip=0, loss_scale=16, train_wall=104, gb_free=12, wall=14278
2023-08-27 17:36:47 | INFO | train_inner | epoch 012:    907 / 1191 loss=1.848, trans_loss=3.318, nll_loss=1.365, w2v_ctc_loss=0.869, task_loss=1.659, contrastive_loss=0.181, total=6656.61, n_correct=4511.68, ppl=2.58, accuracy=67.777, wps=18456, ups=0.96, wpb=19280.3, bsz=657.1, num_updates=14000, lr=0.000119523, gnorm=0.311, clip=0, loss_scale=16, train_wall=104, gb_free=13.6, wall=14382
2023-08-27 17:36:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 17:37:21 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.956 | trans_loss 5.23 | nll_loss 2.447 | w2v_ctc_loss 1.197 | task_loss 8.493 | contrastive_loss 0.26 | total 6138.43 | n_correct 4109.43 | ppl 5.45 | accuracy 66.946 | uer 17.835 | wer 19.688 | raw_wer 19.688 | bleu 26.61 | wps 1614.1 | wpb 6138.4 | bsz 201.1 | num_updates 14000 | best_bleu 26.61
2023-08-27 17:37:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14000 updates
2023-08-27 17:37:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_12_14000.pt
2023-08-27 17:37:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_12_14000.pt
2023-08-27 17:37:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_12_14000.pt (epoch 12 @ 14000 updates, score 26.61) (writing took 11.117063634010265 seconds)
2023-08-27 17:39:16 | INFO | train_inner | epoch 012:   1007 / 1191 loss=1.839, trans_loss=3.308, nll_loss=1.356, w2v_ctc_loss=0.874, task_loss=1.616, contrastive_loss=0.148, total=6593.96, n_correct=4480.01, ppl=2.56, accuracy=67.941, wps=12865.6, ups=0.67, wpb=19121.5, bsz=661.7, num_updates=14100, lr=0.000119098, gnorm=0.312, clip=0, loss_scale=16, train_wall=102, gb_free=14.8, wall=14531
2023-08-27 17:41:00 | INFO | train_inner | epoch 012:   1107 / 1191 loss=1.844, trans_loss=3.312, nll_loss=1.358, w2v_ctc_loss=0.863, task_loss=1.59, contrastive_loss=0.202, total=6662.47, n_correct=4526.96, ppl=2.56, accuracy=67.947, wps=18498.5, ups=0.96, wpb=19297.1, bsz=674.6, num_updates=14200, lr=0.000118678, gnorm=0.311, clip=0, loss_scale=16, train_wall=104, gb_free=14, wall=14635
2023-08-27 17:42:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-27 17:43:00 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.954 | trans_loss 5.222 | nll_loss 2.437 | w2v_ctc_loss 1.21 | task_loss 8.48 | contrastive_loss 0.259 | total 6138.43 | n_correct 4124.43 | ppl 5.42 | accuracy 67.19 | uer 17.471 | wer 19.107 | raw_wer 19.107 | bleu 27.1 | wps 1695.1 | wpb 6138.4 | bsz 201.1 | num_updates 14284 | best_bleu 27.1
2023-08-27 17:43:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14284 updates
2023-08-27 17:43:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 17:43:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-27 17:43:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 12 @ 14284 updates, score 27.1) (writing took 11.143109548982466 seconds)
2023-08-27 17:43:12 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-27 17:43:12 | INFO | train | epoch 012 | loss 1.834 | trans_loss 3.305 | nll_loss 1.349 | w2v_ctc_loss 0.862 | task_loss 1.564 | contrastive_loss 0.169 | total 6702.49 | n_correct 4563.07 | ppl 2.55 | accuracy 68.08 | wps 17299.8 | ups 0.89 | wpb 19419 | bsz 677.5 | num_updates 14284 | lr 0.000118329 | gnorm 0.309 | clip 0 | loss_scale 16 | train_wall 1230 | gb_free 14.3 | wall 14767
2023-08-27 17:43:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-27 17:43:12 | INFO | fairseq.trainer | begin training epoch 13
2023-08-27 17:43:12 | INFO | fairseq_cli.train | Start iterating over samples
Exception in thread Thread-64:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
Exception in thread Thread-64:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
Exception in thread Thread-64:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
Exception in thread Thread-64:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
Exception in thread Thread-64:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
Exception in thread Thread-64:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
Exception in thread Thread-64:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/zhangyh/cache/tmp/pymp-2ubhe2yt/listener-zjfu2h7a'
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/shutil.py", line 709, in rmtree
    onerror(os.lstat, path, sys.exc_info())
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/shutil.py", line 707, in rmtree
    orig_st = os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/zhangyh/cache/tmp/pymp-2ubhe2yt'
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/zhangyh/cache/tmp/pymp-men79bdk/listener-9ydpv8px'
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/shutil.py", line 709, in rmtree
    onerror(os.lstat, path, sys.exc_info())
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/shutil.py", line 707, in rmtree
    orig_st = os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/zhangyh/cache/tmp/pymp-men79bdk'
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/zhangyh/cache/tmp/pymp-9kri39xb/listener-r_coc49h'
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/shutil.py", line 709, in rmtree
    onerror(os.lstat, path, sys.exc_info())
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/shutil.py", line 707, in rmtree
    orig_st = os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/zhangyh/cache/tmp/pymp-9kri39xb'
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 6 terminated with the following error:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 312, in train
    for i, samples in enumerate(progress):
  File "/mnt/zhangyh/fairseq-AT/fairseq/logging/progress_bar.py", line 272, in __iter__
    for i, obj in enumerate(self.iterable, start=self.n):
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/iterators.py", line 57, in __next__
    x = next(self._itr)
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/iterators.py", line 614, in _chunk_iterator
    for x in itr:
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/iterators.py", line 57, in __next__
    x = next(self._itr)
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/iterators.py", line 747, in __next__
    raise item
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/iterators.py", line 677, in run
    for item in self._source:
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1328, in _next_data
    idx, data = self._get_data()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1289, in _get_data
    raise RuntimeError('Pin memory thread exited unexpectedly')
RuntimeError: Pin memory thread exited unexpectedly

Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/zhangyh/cache/tmp/pymp-vn8mlr7y/listener-1i6syt_1'
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 300, in _run_finalizers
    finalizer()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 224, in __call__
    res = self._callback(*self._args, **self._kwargs)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/util.py", line 133, in _remove_temp_dir
    rmtree(tempdir)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/shutil.py", line 709, in rmtree
    onerror(os.lstat, path, sys.exc_info())
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/shutil.py", line 707, in rmtree
    orig_st = os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/mnt/zhangyh/cache/tmp/pymp-vn8mlr7y'
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 563 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-27 17:45:37 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15772
2023-08-27 17:45:37 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15772
2023-08-27 17:45:37 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15772
2023-08-27 17:45:37 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15772
2023-08-27 17:45:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-27 17:45:37 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15772
2023-08-27 17:45:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-27 17:45:37 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15772
2023-08-27 17:45:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-27 17:45:37 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15772
2023-08-27 17:45:37 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15772
2023-08-27 17:45:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-27 17:45:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-27 17:45:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-27 17:45:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-27 17:45:38 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-27 17:45:38 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 17:45:38 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-27 17:45:38 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 17:45:38 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 17:45:38 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-27 17:45:38 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-27 17:45:38 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 17:45:38 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-27 17:45:38 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 17:45:38 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-27 17:45:38 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 17:45:38 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-27 17:45:38 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 17:45:38 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 17:45:38 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-27 17:45:38 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-27 17:45:41 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15772', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-27 17:45:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-27 17:45:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-27 17:45:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-27 17:45:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-27 17:45:41 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 17:45:45 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-27 17:45:45 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-27 17:45:45 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-27 17:45:47 | INFO | root | load pretrained hubert
2023-08-27 17:45:55 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 17:45:58 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 4 terminated with signal SIGKILL
2023-08-27 18:25:19 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19157
2023-08-27 18:25:19 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19157
2023-08-27 18:25:19 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19157
2023-08-27 18:25:19 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:19157
2023-08-27 18:25:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-27 18:25:19 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:19157
2023-08-27 18:25:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-27 18:25:19 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:19157
2023-08-27 18:25:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-27 18:25:19 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:19157
2023-08-27 18:25:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-27 18:25:19 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19157
2023-08-27 18:25:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-27 18:25:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-27 18:25:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-27 18:25:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-27 18:25:20 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:25:20 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:25:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-27 18:25:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-27 18:25:20 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:25:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-27 18:25:20 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:25:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-27 18:25:20 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:25:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-27 18:25:20 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:25:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-27 18:25:20 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:25:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-27 18:25:20 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:25:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-27 18:25:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19157', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-27 18:25:23 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-27 18:25:23 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-27 18:25:23 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-27 18:25:23 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-27 18:25:23 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 18:25:27 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-27 18:25:27 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-27 18:25:27 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-27 18:25:29 | INFO | root | load pretrained hubert
2023-08-27 18:25:38 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 18:25:44 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 18:25:53 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 18:25:53 | INFO | root | share the sematic adapter and textual encoder
2023-08-27 18:25:54 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-27 18:25:54 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-27 18:25:54 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-27 18:25:54 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-27 18:25:54 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-27 18:25:54 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-27 18:25:54 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-27 18:25:54 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 18:25:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 18:25:54 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 7 terminated with signal SIGKILL
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16875
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16875
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:16875
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:16875
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16875
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16875
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:16875
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:16875
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:31:20 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-27 18:31:20 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-27 18:31:24 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16875', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-27 18:31:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-27 18:31:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-27 18:31:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-27 18:31:24 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-27 18:31:24 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 18:31:28 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-27 18:31:28 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-27 18:31:28 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-27 18:31:29 | INFO | root | load pretrained hubert
2023-08-27 18:31:37 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 18:31:41 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 18:31:48 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 18:31:48 | INFO | root | share the sematic adapter and textual encoder
2023-08-27 18:31:48 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-27 18:31:48 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-27 18:31:48 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-27 18:31:48 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-27 18:31:48 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-27 18:31:48 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-27 18:31:48 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-27 18:31:48 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 18:31:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 18:31:48 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 5 terminated with signal SIGKILL
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 5 terminated with signal SIGKILL
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19775
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19775
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:19775
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:19775
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19775
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:19775
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19775
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:19775
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-27 19:42:43 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:42:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-27 19:42:47 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19775', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-27 19:42:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-27 19:42:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-27 19:42:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-27 19:42:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-27 19:42:47 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 19:42:51 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-27 19:42:51 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-27 19:42:51 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-27 19:42:53 | INFO | root | load pretrained hubert
2023-08-27 19:43:00 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 7 terminated with signal SIGKILL
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13892
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13892
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13892
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13892
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13892
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13892
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13892
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13892
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-27 19:50:48 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 19:50:48 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-27 19:50:51 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13892', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-27 19:50:51 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-27 19:50:51 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-27 19:50:51 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-27 19:50:51 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-27 19:50:51 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 19:50:56 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-27 19:50:56 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-27 19:50:56 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-27 19:50:57 | INFO | root | load pretrained hubert
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 2 terminated with signal SIGKILL
2023-08-27 20:03:03 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18683
2023-08-27 20:03:03 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18683
2023-08-27 20:03:03 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18683
2023-08-27 20:03:03 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18683
2023-08-27 20:03:03 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-27 20:03:03 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18683
2023-08-27 20:03:03 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-27 20:03:03 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18683
2023-08-27 20:03:03 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-27 20:03:03 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18683
2023-08-27 20:03:03 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-27 20:03:03 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18683
2023-08-27 20:03:03 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-27 20:03:04 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-27 20:03:04 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-27 20:03:04 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-27 20:03:04 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:03:04 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-27 20:03:04 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:03:04 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-27 20:03:04 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:03:04 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:03:04 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:03:04 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-27 20:03:04 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-27 20:03:04 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-27 20:03:04 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:03:04 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:03:04 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-27 20:03:04 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-27 20:03:04 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:03:04 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-27 20:03:07 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18683', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-27 20:03:07 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-27 20:03:07 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-27 20:03:07 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-27 20:03:07 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-27 20:03:07 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 20:03:11 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-27 20:03:11 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-27 20:03:11 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-27 20:03:14 | INFO | root | load pretrained hubert
2023-08-27 20:03:16 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 20:03:17 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 20:03:19 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 20:03:19 | INFO | root | share the sematic adapter and textual encoder
2023-08-27 20:03:19 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-27 20:03:19 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-27 20:03:19 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-27 20:03:19 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-27 20:03:19 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-27 20:03:19 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-27 20:03:19 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-27 20:03:19 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 20:03:19 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 20:03:19 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-27 20:03:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-27 20:03:20 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-27 20:03:20 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-27 20:03:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-27 20:03:20 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:03:20 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:03:20 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:03:20 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:03:20 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:03:20 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:03:20 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:03:20 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:03:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-27 20:03:20 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-27 20:03:20 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-27 20:03:20 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-27 20:03:24 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-27 20:03:26 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-27 20:03:27 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 13 @ 14284 updates)
2023-08-27 20:03:27 | INFO | fairseq.trainer | loading train data for epoch 13
2023-08-27 20:03:27 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-27 20:03:27 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 20:03:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 20:03:31 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-27 20:03:36 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 1 terminated with signal SIGKILL
2023-08-27 20:05:21 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18136
2023-08-27 20:05:21 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18136
2023-08-27 20:05:21 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18136
2023-08-27 20:05:21 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18136
2023-08-27 20:05:21 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18136
2023-08-27 20:05:21 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18136
2023-08-27 20:05:21 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18136
2023-08-27 20:05:21 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18136
2023-08-27 20:05:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:05:22 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-27 20:05:22 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-27 20:05:22 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:05:22 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:05:22 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:05:22 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-27 20:05:22 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-27 20:05:22 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:05:22 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-27 20:05:28 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18136', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-27 20:05:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-27 20:05:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-27 20:05:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-27 20:05:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-27 20:05:28 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 20:05:37 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-27 20:05:37 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-27 20:05:37 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-27 20:05:41 | INFO | root | load pretrained hubert
2023-08-27 20:05:43 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 20:05:45 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 20:05:48 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 20:05:48 | INFO | root | share the sematic adapter and textual encoder
2023-08-27 20:05:48 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-27 20:05:48 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-27 20:05:48 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-27 20:05:48 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-27 20:05:48 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-27 20:05:48 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-27 20:05:48 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-27 20:05:48 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 20:05:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 20:05:49 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-27 20:05:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-27 20:05:50 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-27 20:05:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-27 20:05:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-27 20:05:51 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:05:51 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:05:51 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:05:51 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:05:51 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:05:51 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:05:51 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:05:51 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:05:51 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-27 20:05:51 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-27 20:05:51 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-27 20:05:51 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-27 20:05:55 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-27 20:05:57 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-27 20:05:59 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 13 @ 14284 updates)
2023-08-27 20:05:59 | INFO | fairseq.trainer | loading train data for epoch 13
2023-08-27 20:05:59 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-27 20:05:59 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 20:05:59 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 2 terminated with signal SIGKILL
2023-08-27 20:08:13 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11147
2023-08-27 20:08:13 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11147
2023-08-27 20:08:13 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11147
2023-08-27 20:08:13 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11147
2023-08-27 20:08:13 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11147
2023-08-27 20:08:13 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11147
2023-08-27 20:08:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-27 20:08:13 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11147
2023-08-27 20:08:13 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11147
2023-08-27 20:08:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-27 20:08:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:08:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:08:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:08:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:08:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:08:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:08:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-27 20:08:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-27 20:08:14 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 20:08:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-27 20:08:20 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11147', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-27 20:08:20 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-27 20:08:20 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-27 20:08:20 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-27 20:08:20 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-27 20:08:20 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 20:08:28 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-27 20:08:28 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-27 20:08:28 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-27 20:08:31 | INFO | root | load pretrained hubert
2023-08-27 20:08:32 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 20:08:33 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 20:08:34 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-27 20:08:34 | INFO | root | share the sematic adapter and textual encoder
2023-08-27 20:08:34 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-27 20:08:34 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-27 20:08:34 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-27 20:08:34 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-27 20:08:34 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-27 20:08:34 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-27 20:08:34 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-27 20:08:34 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 20:08:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 20:08:34 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-27 20:08:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-27 20:08:41 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-27 20:08:41 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-27 20:08:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-27 20:08:42 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:08:42 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:08:42 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:08:42 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:08:42 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:08:42 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:08:42 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:08:42 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-27 20:08:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-27 20:08:42 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-27 20:08:42 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-27 20:08:42 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-27 20:08:45 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-27 20:08:47 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-27 20:08:48 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 13 @ 14284 updates)
2023-08-27 20:08:48 | INFO | fairseq.trainer | loading train data for epoch 13
2023-08-27 20:08:48 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-27 20:08:48 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 20:08:48 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-27 20:08:52 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-27 20:08:56 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/draw/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 3 terminated with signal SIGKILL
2023-08-27 21:16:28 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15646
2023-08-27 21:16:28 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15646
2023-08-27 21:16:28 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15646
2023-08-27 21:16:28 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15646
2023-08-27 21:16:28 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15646
2023-08-27 21:16:28 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15646
2023-08-27 21:16:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-27 21:16:28 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15646
2023-08-27 21:16:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-27 21:16:28 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15646
2023-08-27 21:16:28 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 21:16:29 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 21:16:29 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 21:16:29 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 21:16:29 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 21:16:29 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-27 21:16:29 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 21:16:29 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-27 21:16:29 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-27 21:16:29 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-27 21:16:35 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15646', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-27 21:16:35 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-27 21:16:35 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-27 21:16:35 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-27 21:16:35 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-27 21:16:35 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 21:16:43 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-27 21:16:43 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-27 21:16:43 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-27 21:16:46 | INFO | root | load pretrained hubert
2023-08-27 21:16:56 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-27 21:17:00 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL
2023-08-28 09:43:08 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11684
2023-08-28 09:43:08 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11684
2023-08-28 09:43:08 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11684
2023-08-28 09:43:08 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11684
2023-08-28 09:43:08 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11684
2023-08-28 09:43:08 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11684
2023-08-28 09:43:08 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11684
2023-08-28 09:43:08 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11684
2023-08-28 09:43:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 09:43:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:43:09 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:43:09 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:43:09 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 09:43:09 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:43:09 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 09:43:09 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:43:09 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 09:43:09 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:43:09 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 09:43:13 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11684', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 09:43:13 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 09:43:13 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 09:43:13 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 09:43:14 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 09:43:14 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 09:43:23 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 09:43:23 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 09:43:23 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 09:43:25 | INFO | root | load pretrained hubert
2023-08-28 09:43:32 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 09:43:38 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 09:43:44 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 09:43:44 | INFO | root | share the sematic adapter and textual encoder
2023-08-28 09:43:44 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-28 09:43:44 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-28 09:43:44 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-28 09:43:44 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-28 09:43:44 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-28 09:43:44 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-28 09:43:44 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-28 09:43:44 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 09:43:44 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 09:43:44 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-28 09:44:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-28 09:44:00 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-28 09:44:00 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-28 09:44:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-28 09:44:01 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 09:44:01 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 09:44:01 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 09:44:01 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 09:44:01 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 09:44:01 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 09:44:01 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 09:44:01 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 09:44:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-28 09:44:01 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-28 09:44:01 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-28 09:44:01 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17768
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17768
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:17768
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17768
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:17768
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:17768
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17768
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:17768
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 09:46:36 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 09:46:36 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 09:46:43 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17768', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 09:46:43 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 09:46:43 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 09:46:43 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 09:46:43 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 09:46:43 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 09:46:52 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 09:46:52 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 09:46:52 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 09:46:55 | INFO | root | load pretrained hubert
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 4 terminated with signal SIGKILL
2023-08-28 15:08:51 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13477
2023-08-28 15:08:51 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13477
2023-08-28 15:08:51 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13477
2023-08-28 15:08:51 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13477
2023-08-28 15:08:51 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13477
2023-08-28 15:08:51 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13477
2023-08-28 15:08:51 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13477
2023-08-28 15:08:51 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13477
2023-08-28 15:08:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 15:08:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:08:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:08:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:08:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:08:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 15:08:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:08:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:08:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 15:08:52 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:08:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 15:08:57 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13477', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 15:08:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 15:08:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 15:08:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 15:08:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 15:08:57 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 2 terminated with signal SIGKILL
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:10703
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:10703
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:10703
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:10703
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:10703
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:10703
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:10703
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:10703
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 15:11:24 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:11:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 15:11:27 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10703', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 15:11:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 15:11:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 15:11:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 15:11:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 15:11:27 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-28 15:11:33 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 15:11:33 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 15:11:33 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 15:11:35 | INFO | root | load pretrained hubert
2023-08-28 15:11:44 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-28 15:11:50 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 6 terminated with the following error:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 96, in main
    model = task.build_model(cfg.model)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining_merge.py", line 420, in build_model
    models = super(SpeechToTextTask, self).build_model(args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/fairseq_task.py", line 675, in build_model
    model = models.build_model(args, self, from_checkpoint)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 106, in build_model
    return model.build_model(cfg, task)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 613, in build_model
    decoder = cls.build_decoder(args, task, decoder_embed_tokens)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 563, in build_decoder
    decoder.load_state_dict(state["model"], strict=True)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/modules/module.py", line 2041, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for TransformerDecoderScriptable:
	size mismatch for embed_tokens.weight: copying a param with shape torch.Size([10000, 512]) from checkpoint, the shape in current model is torch.Size([9998, 512]).
	size mismatch for output_projection.weight: copying a param with shape torch.Size([10000, 512]) from checkpoint, the shape in current model is torch.Size([9998, 512]).

2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17246
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:17246
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17246
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:17246
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17246
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:17246
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:17246
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17246
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 15:17:23 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:17:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 15:17:26 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17246', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 15:17:26 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 15:17:26 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 15:17:26 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 15:17:26 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 15:17:26 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 15:17:32 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 15:17:32 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 15:17:32 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 15:17:35 | INFO | root | load pretrained hubert
2023-08-28 15:17:43 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 15:17:49 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 15:17:57 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 15:17:57 | INFO | root | share the sematic adapter and textual encoder
2023-08-28 15:17:57 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-28 15:17:57 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-28 15:17:57 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-28 15:17:57 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-28 15:17:57 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-28 15:17:57 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-28 15:17:57 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-28 15:17:57 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 15:17:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 15:17:57 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 3 terminated with signal SIGKILL
2023-08-28 15:19:57 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:17141
2023-08-28 15:19:57 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17141
2023-08-28 15:19:57 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:17141
2023-08-28 15:19:57 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17141
2023-08-28 15:19:57 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 15:19:57 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 15:19:57 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:17141
2023-08-28 15:19:57 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 15:19:57 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17141
2023-08-28 15:19:57 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17141
2023-08-28 15:19:57 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 15:19:57 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:17141
2023-08-28 15:19:57 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 15:19:57 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 15:19:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 15:19:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 15:19:58 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:19:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 15:19:58 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:19:58 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:19:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 15:19:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 15:19:58 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:19:58 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:19:58 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:19:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 15:19:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 15:19:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 15:19:58 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:19:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 15:19:58 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 15:19:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 15:20:03 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17141', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 15:20:03 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 15:20:03 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 15:20:03 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 15:20:03 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 15:20:03 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 15:20:08 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 15:20:08 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 15:20:08 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 15:20:09 | INFO | root | load pretrained hubert
2023-08-28 15:20:17 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 15:20:20 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 15:20:27 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 15:20:27 | INFO | root | share the sematic adapter and textual encoder
2023-08-28 15:20:27 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-28 15:20:27 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-28 15:20:27 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-28 15:20:27 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-28 15:20:27 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-28 15:20:27 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-28 15:20:27 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-28 15:20:27 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 15:20:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 15:20:27 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-28 15:20:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-28 15:20:42 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-28 15:20:42 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-28 15:20:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-28 15:20:43 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 15:20:43 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 15:20:43 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 15:20:43 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 15:20:43 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 15:20:43 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 15:20:43 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 15:20:43 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 15:20:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-28 15:20:43 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-28 15:20:43 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-28 15:20:43 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-28 15:20:49 | INFO | fairseq.trainer | load the task parameters
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 1 terminated with signal SIGKILL
2023-08-28 16:07:57 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12240
2023-08-28 16:07:57 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12240
2023-08-28 16:07:57 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12240
2023-08-28 16:07:57 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 16:07:57 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12240
2023-08-28 16:07:57 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 16:07:57 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12240
2023-08-28 16:07:57 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 16:07:58 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12240
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 16:07:58 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12240
2023-08-28 16:07:58 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12240
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:07:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:07:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:07:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:07:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:07:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:07:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 16:07:58 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:07:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 16:07:58 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 16 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-28 16:08:30 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12938
2023-08-28 16:08:30 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12938
2023-08-28 16:08:30 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12938
2023-08-28 16:08:30 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12938
2023-08-28 16:08:30 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12938
2023-08-28 16:08:30 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12938
2023-08-28 16:08:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 16:08:30 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12938
2023-08-28 16:08:30 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12938
2023-08-28 16:08:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 16:08:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:08:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:08:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:08:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:08:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:08:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:08:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:08:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 16:08:31 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:08:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 16:08:34 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12938', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 16:08:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 16:08:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 16:08:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 16:08:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 16:08:34 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-28 16:08:38 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 16:08:38 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 16:08:38 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 16:08:41 | INFO | root | load pretrained hubert
2023-08-28 16:08:48 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-28 16:08:52 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 1 terminated with the following error:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 96, in main
    model = task.build_model(cfg.model)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining_merge.py", line 420, in build_model
    models = super(SpeechToTextTask, self).build_model(args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/fairseq_task.py", line 675, in build_model
    model = models.build_model(args, self, from_checkpoint)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/__init__.py", line 106, in build_model
    return model.build_model(cfg, task)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 613, in build_model
    decoder = cls.build_decoder(args, task, decoder_embed_tokens)
  File "/mnt/zhangyh/fairseq-AT/fairseq/models/speech_to_text/s2t_joint.py", line 563, in build_decoder
    decoder.load_state_dict(state["model"], strict=True)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/modules/module.py", line 2041, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for TransformerDecoderScriptable:
	size mismatch for embed_tokens.weight: copying a param with shape torch.Size([10000, 512]) from checkpoint, the shape in current model is torch.Size([9998, 512]).
	size mismatch for output_projection.weight: copying a param with shape torch.Size([10000, 512]) from checkpoint, the shape in current model is torch.Size([9998, 512]).

2023-08-28 16:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17143
2023-08-28 16:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:17143
2023-08-28 16:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17143
2023-08-28 16:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:17143
2023-08-28 16:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:17143
2023-08-28 16:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17143
2023-08-28 16:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17143
2023-08-28 16:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:17143
2023-08-28 16:09:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 16:09:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 16:09:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:09:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:09:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:09:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:09:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:09:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:09:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:09:24 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 16:09:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 16:09:24 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 16:09:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17143', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 16:09:30 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 16:09:30 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 16:09:30 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 16:09:30 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 16:09:30 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 16:09:38 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 16:09:38 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 16:09:38 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 16:09:42 | INFO | root | load pretrained hubert
2023-08-28 16:09:51 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 16:09:57 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:14281
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:14281
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:14281
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:14281
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:14281
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:14281
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:14281
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:14281
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 17:42:42 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:42:42 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 17:42:46 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14281', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 17:42:46 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 17:42:46 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 17:42:46 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 17:42:46 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 17:42:46 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 17:42:55 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 17:42:55 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 17:42:55 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 17:42:57 | INFO | root | load pretrained hubert
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 2 terminated with signal SIGKILL
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15805
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15805
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15805
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15805
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15805
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15805
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15805
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15805
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:51:35 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 17:51:35 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 17:51:41 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15805', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 17:51:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 17:51:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 17:51:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 17:51:41 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 17:51:41 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 17:51:49 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 17:51:49 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 17:51:49 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 17:51:53 | INFO | root | load pretrained hubert
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 4 terminated with signal SIGKILL
2023-08-28 18:15:46 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:17622
2023-08-28 18:15:46 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:17622
2023-08-28 18:15:46 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:17622
2023-08-28 18:15:46 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17622
2023-08-28 18:15:46 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17622
2023-08-28 18:15:46 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17622
2023-08-28 18:15:46 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17622
2023-08-28 18:15:46 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 18:15:46 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:17622
2023-08-28 18:15:46 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 18:15:46 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:15:47 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 18:15:47 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:15:47 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:15:47 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:15:47 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:15:47 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:15:47 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 18:15:47 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:15:47 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 18:15:53 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17622', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-08-28 18:15:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 18:15:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 18:15:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 18:15:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 18:15:53 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/st/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/st/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/st/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 1 terminated with signal SIGKILL
2023-08-28 18:16:55 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15524
2023-08-28 18:16:55 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15524
2023-08-28 18:16:55 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15524
2023-08-28 18:16:55 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15524
2023-08-28 18:16:55 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15524
2023-08-28 18:16:55 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15524
2023-08-28 18:16:55 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15524
2023-08-28 18:16:55 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15524
2023-08-28 18:16:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 18:16:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:16:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:16:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 18:16:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:16:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 18:16:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:16:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:16:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 18:16:56 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:16:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 18:17:00 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15524', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-08-28 18:17:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 18:17:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 18:17:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 18:17:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 18:17:00 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/st/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/st/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/st/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 7 terminated with signal SIGKILL
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 26, in <module>
    import numpy as np
ModuleNotFoundError: No module named 'numpy'
2023-08-28 18:20:53 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13577
2023-08-28 18:20:53 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13577
2023-08-28 18:20:53 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13577
2023-08-28 18:20:53 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13577
2023-08-28 18:20:53 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13577
2023-08-28 18:20:53 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13577
2023-08-28 18:20:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 18:20:53 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13577
2023-08-28 18:20:53 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13577
2023-08-28 18:20:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 18:20:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:20:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:20:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:20:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 18:20:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:20:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:20:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:20:54 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 18:20:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 18:20:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 18:20:57 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13577', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-08-28 18:20:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 18:20:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 18:20:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 18:20:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 18:20:57 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/st/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/st/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/st/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 5 terminated with signal SIGKILL
2023-08-28 20:11:50 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11003
2023-08-28 20:11:50 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11003
2023-08-28 20:11:50 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11003
2023-08-28 20:11:50 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11003
2023-08-28 20:11:50 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11003
2023-08-28 20:11:50 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11003
2023-08-28 20:11:50 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11003
2023-08-28 20:11:50 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11003
2023-08-28 20:11:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:11:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:11:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:11:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:11:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:11:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 20:11:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:11:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 20:11:51 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:11:51 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 20:11:55 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11003', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 20:11:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 20:11:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 20:11:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 20:11:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 20:11:55 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 20:11:59 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 20:11:59 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 20:11:59 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 20:12:00 | INFO | root | load pretrained hubert
2023-08-28 20:12:08 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 20:12:13 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 20:12:19 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 20:12:19 | INFO | root | share the sematic adapter and textual encoder
2023-08-28 20:12:19 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-28 20:12:19 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-28 20:12:19 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-28 20:12:19 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-28 20:12:19 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-28 20:12:19 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-28 20:12:19 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-28 20:12:19 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:12:19 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:12:19 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-28 20:12:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-28 20:12:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-28 20:12:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-28 20:12:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-28 20:12:36 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:12:36 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:12:36 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:12:36 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:12:36 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:12:36 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:12:36 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:12:36 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:12:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-28 20:12:36 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-28 20:12:36 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-28 20:12:36 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-28 20:12:41 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-28 20:13:01 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-28 20:13:01 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 11 @ 12000 updates)
2023-08-28 20:13:01 | INFO | fairseq.trainer | loading train data for epoch 11
2023-08-28 20:13:01 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-28 20:13:01 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:13:01 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:13:04 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-28 20:13:06 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-28 20:13:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-28 20:13:56 | INFO | fairseq.trainer | begin training epoch 11
2023-08-28 20:13:56 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-28 20:16:12 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18359
2023-08-28 20:16:13 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18359
2023-08-28 20:16:13 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18359
2023-08-28 20:16:13 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18359
2023-08-28 20:16:13 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18359
2023-08-28 20:16:13 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18359
2023-08-28 20:16:13 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18359
2023-08-28 20:16:13 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18359
2023-08-28 20:16:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 20:16:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 20:16:13 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:16:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 20:16:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:16:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 20:16:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:16:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 20:16:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 20:16:14 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:16:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 20:16:14 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 20:16:17 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18359', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 20:16:17 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 20:16:17 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 20:16:17 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 20:16:17 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 20:16:17 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 20:16:21 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 20:16:21 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 20:16:21 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 20:16:23 | INFO | root | load pretrained hubert
2023-08-28 20:16:30 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 20:16:34 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 20:16:40 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 20:16:40 | INFO | root | share the sematic adapter and textual encoder
2023-08-28 20:16:40 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-28 20:16:40 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-28 20:16:40 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-28 20:16:40 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-28 20:16:40 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-28 20:16:40 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-28 20:16:40 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-28 20:16:40 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:16:40 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:16:40 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-28 20:16:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-28 20:16:56 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-28 20:16:56 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-28 20:16:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-28 20:16:57 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:16:57 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:16:57 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:16:57 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:16:57 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:16:57 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:16:57 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:16:57 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:16:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-28 20:16:57 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-28 20:16:57 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-28 20:16:57 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-28 20:17:03 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-28 20:17:22 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-28 20:17:22 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 13 @ 14284 updates)
2023-08-28 20:17:22 | INFO | fairseq.trainer | loading train data for epoch 13
2023-08-28 20:17:22 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-28 20:17:22 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:17:22 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:17:25 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-28 20:17:27 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-28 20:18:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 20:18:17 | INFO | fairseq.trainer | begin training epoch 13
2023-08-28 20:18:17 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-28 20:18:49 | INFO | train_inner | epoch 013:     16 / 1191 loss=1.798, trans_loss=3.273, nll_loss=1.31, w2v_ctc_loss=0.821, task_loss=1.41, contrastive_loss=0.185, total=6874.81, n_correct=4739.19, ppl=2.48, accuracy=68.936, wps=17552.4, ups=0.89, wpb=19936.5, bsz=725.8, num_updates=14300, lr=0.000118262, gnorm=0.302, clip=0, loss_scale=16, train_wall=25, gb_free=11.8, wall=112
2023-08-28 20:20:44 | INFO | train_inner | epoch 013:    116 / 1191 loss=1.809, trans_loss=3.282, nll_loss=1.32, w2v_ctc_loss=0.839, task_loss=1.638, contrastive_loss=0.176, total=6709.84, n_correct=4612.59, ppl=2.5, accuracy=68.744, wps=16981.9, ups=0.87, wpb=19443.8, bsz=663.9, num_updates=14400, lr=0.000117851, gnorm=0.302, clip=0, loss_scale=16, train_wall=114, gb_free=12, wall=227
2023-08-28 20:22:42 | INFO | train_inner | epoch 013:    216 / 1191 loss=1.816, trans_loss=3.293, nll_loss=1.334, w2v_ctc_loss=0.835, task_loss=1.551, contrastive_loss=0.218, total=6635.65, n_correct=4546.97, ppl=2.52, accuracy=68.523, wps=16366.9, ups=0.85, wpb=19225.6, bsz=687.8, num_updates=14500, lr=0.000117444, gnorm=0.309, clip=0, loss_scale=16, train_wall=117, gb_free=14.4, wall=344
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGTERM
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 131 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-28 20:24:55 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16898
2023-08-28 20:24:55 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16898
2023-08-28 20:24:55 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16898
2023-08-28 20:24:55 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16898
2023-08-28 20:24:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-28 20:24:55 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:16898
2023-08-28 20:24:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-28 20:24:55 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:16898
2023-08-28 20:24:55 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:16898
2023-08-28 20:24:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-28 20:24:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-28 20:24:55 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:16898
2023-08-28 20:24:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-28 20:24:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-28 20:24:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-28 20:24:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-28 20:24:56 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:24:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-28 20:24:56 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:24:56 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:24:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-28 20:24:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-28 20:24:56 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:24:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-28 20:24:56 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:24:56 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:24:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-28 20:24:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-28 20:24:56 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:24:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-28 20:24:56 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-28 20:24:56 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-28 20:25:00 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16898', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-28 20:25:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-28 20:25:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-28 20:25:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-28 20:25:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-28 20:25:00 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 20:25:04 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-28 20:25:04 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-28 20:25:04 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-28 20:25:06 | INFO | root | load pretrained hubert
2023-08-28 20:25:13 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-28 20:25:17 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 20:25:23 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-28 20:25:23 | INFO | root | share the sematic adapter and textual encoder
2023-08-28 20:25:23 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-28 20:25:23 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-28 20:25:23 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-28 20:25:23 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-28 20:25:23 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-28 20:25:23 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-28 20:25:23 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-28 20:25:23 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:25:23 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:25:23 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-28 20:25:39 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-28 20:25:39 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-28 20:25:39 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-28 20:25:39 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-28 20:25:39 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:25:39 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:25:39 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:25:39 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:25:39 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:25:39 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:25:39 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:25:39 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-28 20:25:39 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-28 20:25:39 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-28 20:25:39 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-28 20:25:39 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-28 20:25:41 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-28 20:26:00 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-28 20:26:01 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 13 @ 14284 updates)
2023-08-28 20:26:01 | INFO | fairseq.trainer | loading train data for epoch 13
2023-08-28 20:26:01 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-28 20:26:01 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:26:01 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-28 20:26:03 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-28 20:26:05 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
2023-08-28 20:26:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 20:26:57 | INFO | fairseq.trainer | begin training epoch 13
2023-08-28 20:26:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 20:27:24 | INFO | train_inner | epoch 013:     16 / 1191 loss=1.798, trans_loss=3.273, nll_loss=1.31, w2v_ctc_loss=0.821, task_loss=1.41, contrastive_loss=0.185, total=6874.81, n_correct=4739.19, ppl=2.48, accuracy=68.936, wps=17424.9, ups=0.88, wpb=19936.5, bsz=725.8, num_updates=14300, lr=0.000118262, gnorm=0.302, clip=0, loss_scale=16, train_wall=20, gb_free=11.8, wall=105
2023-08-28 20:29:14 | INFO | train_inner | epoch 013:    116 / 1191 loss=1.809, trans_loss=3.282, nll_loss=1.32, w2v_ctc_loss=0.839, task_loss=1.638, contrastive_loss=0.176, total=6709.84, n_correct=4612.59, ppl=2.5, accuracy=68.744, wps=17773.5, ups=0.91, wpb=19443.8, bsz=663.9, num_updates=14400, lr=0.000117851, gnorm=0.302, clip=0, loss_scale=16, train_wall=109, gb_free=12, wall=214
2023-08-28 20:30:59 | INFO | train_inner | epoch 013:    216 / 1191 loss=1.816, trans_loss=3.293, nll_loss=1.334, w2v_ctc_loss=0.835, task_loss=1.551, contrastive_loss=0.218, total=6635.65, n_correct=4546.97, ppl=2.52, accuracy=68.523, wps=18171.8, ups=0.95, wpb=19225.6, bsz=687.8, num_updates=14500, lr=0.000117444, gnorm=0.309, clip=0, loss_scale=16, train_wall=105, gb_free=14.4, wall=320
2023-08-28 20:32:49 | INFO | train_inner | epoch 013:    316 / 1191 loss=1.835, trans_loss=3.288, nll_loss=1.328, w2v_ctc_loss=0.825, task_loss=1.454, contrastive_loss=0.317, total=6732.12, n_correct=4627.3, ppl=2.51, accuracy=68.735, wps=17784, ups=0.91, wpb=19501.5, bsz=716.2, num_updates=14600, lr=0.000117041, gnorm=0.307, clip=0, loss_scale=16, train_wall=109, gb_free=13.1, wall=430
2023-08-28 20:34:39 | INFO | train_inner | epoch 013:    416 / 1191 loss=1.804, trans_loss=3.293, nll_loss=1.334, w2v_ctc_loss=0.849, task_loss=1.546, contrastive_loss=0.097, total=6753.67, n_correct=4622.98, ppl=2.52, accuracy=68.451, wps=17838.8, ups=0.91, wpb=19572.6, bsz=678.7, num_updates=14700, lr=0.000116642, gnorm=0.306, clip=0, loss_scale=16, train_wall=109, gb_free=13.5, wall=539
2023-08-28 20:36:25 | INFO | train_inner | epoch 013:    516 / 1191 loss=1.82, trans_loss=3.298, nll_loss=1.34, w2v_ctc_loss=0.842, task_loss=1.662, contrastive_loss=0.194, total=6638.04, n_correct=4534.35, ppl=2.53, accuracy=68.309, wps=18095.4, ups=0.94, wpb=19233.6, bsz=655.6, num_updates=14800, lr=0.000116248, gnorm=0.311, clip=0, loss_scale=16, train_wall=106, gb_free=14.9, wall=646
2023-08-28 20:38:16 | INFO | train_inner | epoch 013:    616 / 1191 loss=1.813, trans_loss=3.296, nll_loss=1.337, w2v_ctc_loss=0.848, task_loss=1.614, contrastive_loss=0.143, total=6702.58, n_correct=4580.38, ppl=2.53, accuracy=68.338, wps=17541.9, ups=0.9, wpb=19417.2, bsz=654.1, num_updates=14900, lr=0.000115857, gnorm=0.305, clip=0, loss_scale=16, train_wall=110, gb_free=13.6, wall=756
2023-08-28 20:40:07 | INFO | train_inner | epoch 013:    716 / 1191 loss=1.803, trans_loss=3.297, nll_loss=1.338, w2v_ctc_loss=0.847, task_loss=1.646, contrastive_loss=0.102, total=6640, n_correct=4539.32, ppl=2.53, accuracy=68.363, wps=17272, ups=0.9, wpb=19234, bsz=654.1, num_updates=15000, lr=0.00011547, gnorm=0.31, clip=0, loss_scale=16, train_wall=111, gb_free=15.2, wall=868
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-28 20:41:51 | INFO | train_inner | epoch 013:    816 / 1191 loss=1.917, trans_loss=4.75, nll_loss=1.928, w2v_ctc_loss=0.608, task_loss=2.253, contrastive_loss=0.121, total=6754.21, n_correct=4622.68, ppl=3.8, accuracy=68.441, wps=13008.2, ups=0.96, wpb=13574.6, bsz=462.3, num_updates=15100, lr=0.000115087, gnorm=0.385, clip=0, loss_scale=16, train_wall=104, gb_free=14.1, wall=972
2023-08-28 20:43:31 | INFO | train_inner | epoch 013:    916 / 1191 loss=1.929, trans_loss=4.783, nll_loss=1.949, w2v_ctc_loss=0.625, task_loss=2.591, contrastive_loss=0.1, total=6564.2, n_correct=4474.66, ppl=3.86, accuracy=68.168, wps=13194.4, ups=1.01, wpb=13128.4, bsz=422.2, num_updates=15200, lr=0.000114708, gnorm=0.394, clip=0, loss_scale=16, train_wall=99, gb_free=13.3, wall=1072
2023-08-28 20:45:26 | INFO | train_inner | epoch 013:   1016 / 1191 loss=1.914, trans_loss=4.774, nll_loss=1.939, w2v_ctc_loss=0.605, task_loss=2.235, contrastive_loss=0.082, total=6796.22, n_correct=4655.71, ppl=3.84, accuracy=68.504, wps=11868.4, ups=0.87, wpb=13592.4, bsz=468.6, num_updates=15300, lr=0.000114332, gnorm=0.384, clip=0, loss_scale=16, train_wall=106, gb_free=12.4, wall=1186
2023-08-28 20:47:13 | INFO | train_inner | epoch 013:   1116 / 1191 loss=1.925, trans_loss=4.78, nll_loss=1.947, w2v_ctc_loss=0.614, task_loss=2.263, contrastive_loss=0.145, total=6753.73, n_correct=4610.24, ppl=3.86, accuracy=68.262, wps=12569.4, ups=0.93, wpb=13507.5, bsz=465.1, num_updates=15400, lr=0.000113961, gnorm=0.387, clip=0, loss_scale=16, train_wall=107, gb_free=13.6, wall=1294
2023-08-28 20:48:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-28 20:49:08 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.929 | trans_loss 5.213 | nll_loss 2.426 | w2v_ctc_loss 1.15 | task_loss 8.489 | contrastive_loss 0.257 | total 6138.43 | n_correct 4128.29 | ppl 5.37 | accuracy 67.253 | uer 16.995 | wer 18.695 | raw_wer 18.695 | bleu 26.68 | wps 1281.2 | wpb 6138.4 | bsz 201.1 | num_updates 15475 | best_bleu 27.1
2023-08-28 20:49:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 15475 updates
2023-08-28 20:49:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_26.6802.pt
2023-08-28 20:49:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_26.6802.pt
2023-08-28 20:49:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_26.6802.pt (epoch 13 @ 15475 updates, score 26.68) (writing took 6.113870801000303 seconds)
2023-08-28 20:49:15 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-28 20:49:15 | INFO | train | epoch 013 | loss 1.848 | trans_loss 3.759 | nll_loss 1.525 | w2v_ctc_loss 0.768 | task_loss 1.805 | contrastive_loss 0.161 | total 6703.69 | n_correct 4588.17 | ppl 2.88 | accuracy 68.442 | wps 15252.2 | ups 0.9 | wpb 17022.9 | bsz 587.5 | num_updates 15475 | lr 0.000113684 | gnorm 0.339 | clip 0 | loss_scale 16 | train_wall 1275 | gb_free 9.9 | wall 1416
2023-08-28 20:49:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 20:49:15 | INFO | fairseq.trainer | begin training epoch 14
2023-08-28 20:49:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 20:49:40 | INFO | train_inner | epoch 014:     25 / 1191 loss=1.919, trans_loss=4.769, nll_loss=1.933, w2v_ctc_loss=0.611, task_loss=2.189, contrastive_loss=0.137, total=6745.72, n_correct=4624.79, ppl=3.82, accuracy=68.559, wps=9200.7, ups=0.68, wpb=13491.4, bsz=465.6, num_updates=15500, lr=0.000113592, gnorm=0.387, clip=0, loss_scale=16, train_wall=99, gb_free=14, wall=1441
2023-08-28 20:50:53 | INFO | train_inner | epoch 014:    125 / 1191 loss=1.91, trans_loss=4.746, nll_loss=1.902, w2v_ctc_loss=0.602, task_loss=2.309, contrastive_loss=0.155, total=6649.06, n_correct=4588.18, ppl=3.74, accuracy=69.005, wps=18167.1, ups=1.37, wpb=13298.1, bsz=449.5, num_updates=15600, lr=0.000113228, gnorm=0.387, clip=0, loss_scale=16, train_wall=73, gb_free=14.3, wall=1514
2023-08-28 20:52:05 | INFO | train_inner | epoch 014:    225 / 1191 loss=1.903, trans_loss=4.752, nll_loss=1.908, w2v_ctc_loss=0.598, task_loss=2.389, contrastive_loss=0.086, total=6640.19, n_correct=4575.28, ppl=3.75, accuracy=68.903, wps=18347.4, ups=1.38, wpb=13280.4, bsz=445.2, num_updates=15700, lr=0.000112867, gnorm=0.389, clip=0, loss_scale=16, train_wall=72, gb_free=14.1, wall=1586
2023-08-28 20:53:18 | INFO | train_inner | epoch 014:    325 / 1191 loss=1.912, trans_loss=4.754, nll_loss=1.912, w2v_ctc_loss=0.602, task_loss=2.396, contrastive_loss=0.153, total=6727.18, n_correct=4628.75, ppl=3.76, accuracy=68.807, wps=18524.2, ups=1.38, wpb=13454.4, bsz=448.4, num_updates=15800, lr=0.000112509, gnorm=0.392, clip=0, loss_scale=16, train_wall=72, gb_free=15.3, wall=1659
2023-08-28 20:54:31 | INFO | train_inner | epoch 014:    425 / 1191 loss=1.901, trans_loss=4.752, nll_loss=1.909, w2v_ctc_loss=0.595, task_loss=2.233, contrastive_loss=0.09, total=6815.51, n_correct=4694.65, ppl=3.76, accuracy=68.882, wps=18579.6, ups=1.36, wpb=13631, bsz=469.3, num_updates=15900, lr=0.000112154, gnorm=0.385, clip=0, loss_scale=16, train_wall=73, gb_free=10.1, wall=1732
2023-08-28 20:55:44 | INFO | train_inner | epoch 014:    525 / 1191 loss=1.915, trans_loss=4.754, nll_loss=1.913, w2v_ctc_loss=0.6, task_loss=2.313, contrastive_loss=0.18, total=6712.88, n_correct=4619.29, ppl=3.77, accuracy=68.812, wps=18581.1, ups=1.38, wpb=13425.8, bsz=457.4, num_updates=16000, lr=0.000111803, gnorm=0.388, clip=0, loss_scale=16, train_wall=71, gb_free=11.3, wall=1804
2023-08-28 20:55:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 20:56:16 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.938 | trans_loss 5.22 | nll_loss 2.435 | w2v_ctc_loss 1.164 | task_loss 8.532 | contrastive_loss 0.252 | total 6138.43 | n_correct 4127.86 | ppl 5.41 | accuracy 67.246 | uer 17.533 | wer 19.342 | raw_wer 19.342 | bleu 26.82 | wps 1757.5 | wpb 6138.4 | bsz 201.1 | num_updates 16000 | best_bleu 27.1
2023-08-28 20:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16000 updates
2023-08-28 20:56:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_14_16000.pt
2023-08-28 20:56:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_14_16000.pt
2023-08-28 20:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_14_16000.pt (epoch 14 @ 16000 updates, score 26.82) (writing took 7.426501885000107 seconds)
2023-08-28 20:57:37 | INFO | train_inner | epoch 014:    625 / 1191 loss=1.908, trans_loss=4.757, nll_loss=1.918, w2v_ctc_loss=0.603, task_loss=2.276, contrastive_loss=0.11, total=6813.07, n_correct=4689.61, ppl=3.78, accuracy=68.833, wps=11972.1, ups=0.88, wpb=13626.1, bsz=465.5, num_updates=16100, lr=0.000111456, gnorm=0.38, clip=0, loss_scale=16, train_wall=73, gb_free=13.1, wall=1918
2023-08-28 20:58:50 | INFO | train_inner | epoch 014:    725 / 1191 loss=1.92, trans_loss=4.759, nll_loss=1.92, w2v_ctc_loss=0.609, task_loss=2.366, contrastive_loss=0.166, total=6696.46, n_correct=4596.21, ppl=3.78, accuracy=68.636, wps=18395.7, ups=1.37, wpb=13392.9, bsz=448.9, num_updates=16200, lr=0.000111111, gnorm=0.389, clip=0, loss_scale=16, train_wall=72, gb_free=14, wall=1991
2023-08-28 21:00:03 | INFO | train_inner | epoch 014:    825 / 1191 loss=1.92, trans_loss=4.767, nll_loss=1.931, w2v_ctc_loss=0.604, task_loss=2.367, contrastive_loss=0.201, total=6693.66, n_correct=4591.38, ppl=3.81, accuracy=68.593, wps=18327, ups=1.37, wpb=13387.3, bsz=458.7, num_updates=16300, lr=0.00011077, gnorm=0.391, clip=0, loss_scale=16, train_wall=72, gb_free=13, wall=2064
2023-08-28 21:01:16 | INFO | train_inner | epoch 014:    925 / 1191 loss=1.909, trans_loss=4.761, nll_loss=1.923, w2v_ctc_loss=0.608, task_loss=2.365, contrastive_loss=0.083, total=6650.35, n_correct=4573.73, ppl=3.79, accuracy=68.774, wps=18420.2, ups=1.38, wpb=13300.7, bsz=446.5, num_updates=16400, lr=0.000110432, gnorm=0.39, clip=0, loss_scale=32, train_wall=71, gb_free=14.3, wall=2136
2023-08-28 21:02:29 | INFO | train_inner | epoch 014:   1025 / 1191 loss=1.918, trans_loss=4.773, nll_loss=1.937, w2v_ctc_loss=0.617, task_loss=2.639, contrastive_loss=0.072, total=6555.51, n_correct=4489.93, ppl=3.83, accuracy=68.491, wps=17942.4, ups=1.37, wpb=13111, bsz=417.3, num_updates=16500, lr=0.000110096, gnorm=0.394, clip=0, loss_scale=32, train_wall=72, gb_free=14.1, wall=2209
2023-08-28 21:03:42 | INFO | train_inner | epoch 014:   1125 / 1191 loss=1.908, trans_loss=4.758, nll_loss=1.921, w2v_ctc_loss=0.602, task_loss=2.154, contrastive_loss=0.123, total=6806.29, n_correct=4692.81, ppl=3.79, accuracy=68.948, wps=18471.1, ups=1.36, wpb=13612.6, bsz=476.8, num_updates=16600, lr=0.000109764, gnorm=0.388, clip=0, loss_scale=32, train_wall=73, gb_free=13.5, wall=2283
2023-08-28 21:04:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 21:05:03 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.937 | trans_loss 5.211 | nll_loss 2.425 | w2v_ctc_loss 1.179 | task_loss 8.487 | contrastive_loss 0.256 | total 6138.43 | n_correct 4122.14 | ppl 5.37 | accuracy 67.153 | uer 17.447 | wer 19.208 | raw_wer 19.208 | bleu 26.68 | wps 1648.3 | wpb 6138.4 | bsz 201.1 | num_updates 16666 | best_bleu 27.1
2023-08-28 21:05:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16666 updates
2023-08-28 21:05:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_26.6803.pt
2023-08-28 21:05:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_26.6803.pt
2023-08-28 21:05:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_26.6803.pt (epoch 14 @ 16666 updates, score 26.68) (writing took 8.124676419000025 seconds)
2023-08-28 21:05:12 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-28 21:05:12 | INFO | train | epoch 014 | loss 1.911 | trans_loss 4.758 | nll_loss 1.918 | w2v_ctc_loss 0.604 | task_loss 2.344 | contrastive_loss 0.127 | total 6703.69 | n_correct 4611.52 | ppl 3.78 | accuracy 68.791 | wps 16686.2 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 16666 | lr 0.000109547 | gnorm 0.389 | clip 0 | loss_scale 32 | train_wall 859 | gb_free 14.6 | wall 2373
2023-08-28 21:05:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 21:05:12 | INFO | fairseq.trainer | begin training epoch 15
2023-08-28 21:05:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 21:05:43 | INFO | train_inner | epoch 015:     34 / 1191 loss=1.909, trans_loss=4.752, nll_loss=1.912, w2v_ctc_loss=0.601, task_loss=2.331, contrastive_loss=0.133, total=6697.04, n_correct=4618.02, ppl=3.76, accuracy=68.956, wps=11070.7, ups=0.83, wpb=13394.1, bsz=449.8, num_updates=16700, lr=0.000109435, gnorm=0.389, clip=0, loss_scale=32, train_wall=71, gb_free=10.7, wall=2404
2023-08-28 21:06:55 | INFO | train_inner | epoch 015:    134 / 1191 loss=1.896, trans_loss=4.732, nll_loss=1.884, w2v_ctc_loss=0.595, task_loss=2.282, contrastive_loss=0.124, total=6739.18, n_correct=4672.74, ppl=3.69, accuracy=69.337, wps=18692.3, ups=1.39, wpb=13478.4, bsz=457.1, num_updates=16800, lr=0.000109109, gnorm=0.386, clip=0, loss_scale=32, train_wall=71, gb_free=10.5, wall=2476
2023-08-28 21:08:07 | INFO | train_inner | epoch 015:    234 / 1191 loss=1.895, trans_loss=4.734, nll_loss=1.887, w2v_ctc_loss=0.595, task_loss=2.346, contrastive_loss=0.098, total=6688.79, n_correct=4635.66, ppl=3.7, accuracy=69.305, wps=18633.1, ups=1.39, wpb=13377.6, bsz=447.4, num_updates=16900, lr=0.000108786, gnorm=0.39, clip=0, loss_scale=32, train_wall=71, gb_free=13, wall=2548
2023-08-28 21:09:19 | INFO | train_inner | epoch 015:    334 / 1191 loss=1.892, trans_loss=4.732, nll_loss=1.885, w2v_ctc_loss=0.592, task_loss=2.339, contrastive_loss=0.092, total=6673.73, n_correct=4631.37, ppl=3.69, accuracy=69.397, wps=18549.8, ups=1.39, wpb=13347.5, bsz=448.7, num_updates=17000, lr=0.000108465, gnorm=0.388, clip=0, loss_scale=32, train_wall=71, gb_free=12.3, wall=2620
2023-08-28 21:10:32 | INFO | train_inner | epoch 015:    434 / 1191 loss=1.905, trans_loss=4.748, nll_loss=1.906, w2v_ctc_loss=0.601, task_loss=2.374, contrastive_loss=0.12, total=6726.63, n_correct=4640.05, ppl=3.75, accuracy=68.98, wps=18384.9, ups=1.37, wpb=13453.3, bsz=455.2, num_updates=17100, lr=0.000108148, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=2693
2023-08-28 21:11:46 | INFO | train_inner | epoch 015:    534 / 1191 loss=1.906, trans_loss=4.743, nll_loss=1.899, w2v_ctc_loss=0.606, task_loss=2.316, contrastive_loss=0.131, total=6705.59, n_correct=4632.53, ppl=3.73, accuracy=69.085, wps=18341.8, ups=1.37, wpb=13411.2, bsz=461.1, num_updates=17200, lr=0.000107833, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=2766
2023-08-28 21:12:58 | INFO | train_inner | epoch 015:    634 / 1191 loss=1.912, trans_loss=4.753, nll_loss=1.911, w2v_ctc_loss=0.609, task_loss=2.659, contrastive_loss=0.116, total=6595.1, n_correct=4542.71, ppl=3.76, accuracy=68.88, wps=18281, ups=1.39, wpb=13190.2, bsz=409.9, num_updates=17300, lr=0.000107521, gnorm=0.395, clip=0, loss_scale=32, train_wall=71, gb_free=11.8, wall=2838
2023-08-28 21:14:10 | INFO | train_inner | epoch 015:    734 / 1191 loss=1.907, trans_loss=4.743, nll_loss=1.9, w2v_ctc_loss=0.596, task_loss=2.37, contrastive_loss=0.203, total=6640.82, n_correct=4587.67, ppl=3.73, accuracy=69.083, wps=18463.6, ups=1.39, wpb=13281.6, bsz=453.9, num_updates=17400, lr=0.000107211, gnorm=0.394, clip=0, loss_scale=32, train_wall=71, gb_free=14.6, wall=2910
2023-08-28 21:15:22 | INFO | train_inner | epoch 015:    834 / 1191 loss=1.896, trans_loss=4.745, nll_loss=1.903, w2v_ctc_loss=0.598, task_loss=2.327, contrastive_loss=0.075, total=6727.33, n_correct=4652.26, ppl=3.74, accuracy=69.155, wps=18488.7, ups=1.37, wpb=13454.7, bsz=449.3, num_updates=17500, lr=0.000106904, gnorm=0.384, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=2983
2023-08-28 21:16:36 | INFO | train_inner | epoch 015:    934 / 1191 loss=1.9, trans_loss=4.743, nll_loss=1.901, w2v_ctc_loss=0.588, task_loss=2.258, contrastive_loss=0.178, total=6736.99, n_correct=4662.8, ppl=3.73, accuracy=69.212, wps=18378.1, ups=1.36, wpb=13474, bsz=469.3, num_updates=17600, lr=0.0001066, gnorm=0.385, clip=0, loss_scale=32, train_wall=73, gb_free=13, wall=3056
2023-08-28 21:17:49 | INFO | train_inner | epoch 015:   1034 / 1191 loss=1.9, trans_loss=4.749, nll_loss=1.908, w2v_ctc_loss=0.599, task_loss=2.299, contrastive_loss=0.099, total=6724.38, n_correct=4652.83, ppl=3.75, accuracy=69.193, wps=18246.8, ups=1.36, wpb=13448.8, bsz=459.4, num_updates=17700, lr=0.000106299, gnorm=0.389, clip=0, loss_scale=32, train_wall=73, gb_free=10.6, wall=3130
2023-08-28 21:19:02 | INFO | train_inner | epoch 015:   1134 / 1191 loss=1.91, trans_loss=4.759, nll_loss=1.921, w2v_ctc_loss=0.606, task_loss=2.388, contrastive_loss=0.113, total=6747.19, n_correct=4647.01, ppl=3.79, accuracy=68.873, wps=18637.5, ups=1.38, wpb=13494.4, bsz=445.6, num_updates=17800, lr=0.000106, gnorm=0.387, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=3203
2023-08-28 21:19:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 21:20:15 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.929 | trans_loss 5.2 | nll_loss 2.41 | w2v_ctc_loss 1.177 | task_loss 8.54 | contrastive_loss 0.254 | total 6138.43 | n_correct 4137.57 | ppl 5.32 | accuracy 67.404 | uer 17.263 | wer 19.041 | raw_wer 19.041 | bleu 26.82 | wps 1743.8 | wpb 6138.4 | bsz 201.1 | num_updates 17857 | best_bleu 27.1
2023-08-28 21:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 17857 updates
2023-08-28 21:20:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_26.8206.pt
2023-08-28 21:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_26.8206.pt
2023-08-28 21:20:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_26.8206.pt (epoch 15 @ 17857 updates, score 26.82) (writing took 7.23179717900166 seconds)
2023-08-28 21:20:23 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-28 21:20:23 | INFO | train | epoch 015 | loss 1.902 | trans_loss 4.744 | nll_loss 1.901 | w2v_ctc_loss 0.598 | task_loss 2.346 | contrastive_loss 0.126 | total 6703.69 | n_correct 4634.68 | ppl 3.73 | accuracy 69.136 | wps 17532 | ups 1.31 | wpb 13407.4 | bsz 452.1 | num_updates 17857 | lr 0.00010583 | gnorm 0.389 | clip 0 | loss_scale 32 | train_wall 854 | gb_free 11.6 | wall 3283
2023-08-28 21:20:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 21:20:23 | INFO | fairseq.trainer | begin training epoch 16
2023-08-28 21:20:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 21:21:00 | INFO | train_inner | epoch 016:     43 / 1191 loss=1.904, trans_loss=4.741, nll_loss=1.899, w2v_ctc_loss=0.593, task_loss=2.317, contrastive_loss=0.187, total=6671.04, n_correct=4615.82, ppl=3.73, accuracy=69.192, wps=11246.4, ups=0.84, wpb=13342.1, bsz=452, num_updates=17900, lr=0.000105703, gnorm=0.389, clip=0, loss_scale=32, train_wall=71, gb_free=13.2, wall=3321
2023-08-28 21:22:13 | INFO | train_inner | epoch 016:    143 / 1191 loss=1.887, trans_loss=4.723, nll_loss=1.873, w2v_ctc_loss=0.59, task_loss=2.393, contrastive_loss=0.108, total=6727.55, n_correct=4689.18, ppl=3.66, accuracy=69.701, wps=18559, ups=1.38, wpb=13455.1, bsz=447.6, num_updates=18000, lr=0.000105409, gnorm=0.384, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=3394
2023-08-28 21:22:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 21:22:46 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.936 | trans_loss 5.205 | nll_loss 2.415 | w2v_ctc_loss 1.195 | task_loss 8.548 | contrastive_loss 0.251 | total 6138.43 | n_correct 4145.86 | ppl 5.33 | accuracy 67.539 | uer 17.038 | wer 18.795 | raw_wer 18.795 | bleu 27.26 | wps 1703.7 | wpb 6138.4 | bsz 201.1 | num_updates 18000 | best_bleu 27.26
2023-08-28 21:22:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 18000 updates
2023-08-28 21:22:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_16_18000.pt
2023-08-28 21:22:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_16_18000.pt
2023-08-28 21:22:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_16_18000.pt (epoch 16 @ 18000 updates, score 27.26) (writing took 10.455250724999132 seconds)
2023-08-28 21:24:09 | INFO | train_inner | epoch 016:    243 / 1191 loss=1.892, trans_loss=4.724, nll_loss=1.874, w2v_ctc_loss=0.591, task_loss=2.422, contrastive_loss=0.123, total=6703.68, n_correct=4658.83, ppl=3.67, accuracy=69.497, wps=11533.9, ups=0.86, wpb=13407.4, bsz=441.7, num_updates=18100, lr=0.000105118, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=11.3, wall=3510
2023-08-28 21:25:22 | INFO | train_inner | epoch 016:    343 / 1191 loss=1.893, trans_loss=4.729, nll_loss=1.883, w2v_ctc_loss=0.592, task_loss=2.261, contrastive_loss=0.123, total=6757.96, n_correct=4697.64, ppl=3.69, accuracy=69.513, wps=18697.7, ups=1.38, wpb=13515.9, bsz=459.6, num_updates=18200, lr=0.000104828, gnorm=0.386, clip=0, loss_scale=32, train_wall=71, gb_free=5.5, wall=3582
2023-08-28 21:26:33 | INFO | train_inner | epoch 016:    443 / 1191 loss=1.887, trans_loss=4.728, nll_loss=1.881, w2v_ctc_loss=0.591, task_loss=2.344, contrastive_loss=0.078, total=6672.75, n_correct=4638.81, ppl=3.68, accuracy=69.519, wps=18733.2, ups=1.4, wpb=13345.5, bsz=447.8, num_updates=18300, lr=0.000104542, gnorm=0.391, clip=0, loss_scale=32, train_wall=71, gb_free=13.5, wall=3653
2023-08-28 21:27:45 | INFO | train_inner | epoch 016:    543 / 1191 loss=1.892, trans_loss=4.727, nll_loss=1.88, w2v_ctc_loss=0.589, task_loss=2.34, contrastive_loss=0.13, total=6701.81, n_correct=4657.98, ppl=3.68, accuracy=69.503, wps=18543.8, ups=1.38, wpb=13403.6, bsz=450.1, num_updates=18400, lr=0.000104257, gnorm=0.387, clip=0, loss_scale=64, train_wall=72, gb_free=14, wall=3726
2023-08-28 21:28:58 | INFO | train_inner | epoch 016:    643 / 1191 loss=1.897, trans_loss=4.734, nll_loss=1.889, w2v_ctc_loss=0.592, task_loss=2.368, contrastive_loss=0.145, total=6700.81, n_correct=4649.41, ppl=3.7, accuracy=69.386, wps=18372.5, ups=1.37, wpb=13401.6, bsz=454.6, num_updates=18500, lr=0.000103975, gnorm=0.391, clip=0, loss_scale=64, train_wall=72, gb_free=13.4, wall=3799
2023-08-28 21:30:10 | INFO | train_inner | epoch 016:    743 / 1191 loss=1.891, trans_loss=4.727, nll_loss=1.88, w2v_ctc_loss=0.594, task_loss=2.383, contrastive_loss=0.105, total=6649.19, n_correct=4618.82, ppl=3.68, accuracy=69.464, wps=18381.6, ups=1.38, wpb=13298.4, bsz=447.1, num_updates=18600, lr=0.000103695, gnorm=0.393, clip=0, loss_scale=64, train_wall=72, gb_free=14.2, wall=3871
2023-08-28 21:31:23 | INFO | train_inner | epoch 016:    843 / 1191 loss=1.896, trans_loss=4.741, nll_loss=1.898, w2v_ctc_loss=0.594, task_loss=2.471, contrastive_loss=0.105, total=6691.36, n_correct=4635.73, ppl=3.73, accuracy=69.279, wps=18296.8, ups=1.37, wpb=13382.7, bsz=437.7, num_updates=18700, lr=0.000103418, gnorm=0.386, clip=0, loss_scale=64, train_wall=72, gb_free=15, wall=3944
2023-08-28 21:32:35 | INFO | train_inner | epoch 016:    943 / 1191 loss=1.891, trans_loss=4.735, nll_loss=1.892, w2v_ctc_loss=0.589, task_loss=2.227, contrastive_loss=0.118, total=6750.81, n_correct=4686.76, ppl=3.71, accuracy=69.425, wps=18795.8, ups=1.39, wpb=13501.6, bsz=470.2, num_updates=18800, lr=0.000103142, gnorm=0.391, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=4016
2023-08-28 21:33:48 | INFO | train_inner | epoch 016:   1043 / 1191 loss=1.896, trans_loss=4.733, nll_loss=1.889, w2v_ctc_loss=0.598, task_loss=2.334, contrastive_loss=0.138, total=6681, n_correct=4632.27, ppl=3.7, accuracy=69.335, wps=18490.1, ups=1.38, wpb=13362, bsz=456.4, num_updates=18900, lr=0.000102869, gnorm=0.391, clip=0, loss_scale=64, train_wall=72, gb_free=14.1, wall=4088
2023-08-28 21:34:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-28 21:35:01 | INFO | train_inner | epoch 016:   1144 / 1191 loss=1.896, trans_loss=4.742, nll_loss=1.902, w2v_ctc_loss=0.598, task_loss=2.241, contrastive_loss=0.112, total=6771.9, n_correct=4692.25, ppl=3.74, accuracy=69.29, wps=18347.6, ups=1.35, wpb=13543.8, bsz=469.7, num_updates=19000, lr=0.000102598, gnorm=0.382, clip=0, loss_scale=32, train_wall=73, gb_free=13.7, wall=4162
2023-08-28 21:35:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 21:36:07 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.927 | trans_loss 5.197 | nll_loss 2.406 | w2v_ctc_loss 1.179 | task_loss 8.509 | contrastive_loss 0.256 | total 6138.43 | n_correct 4144.57 | ppl 5.3 | accuracy 67.518 | uer 17.046 | wer 18.788 | raw_wer 18.788 | bleu 27.15 | wps 1755.2 | wpb 6138.4 | bsz 201.1 | num_updates 19047 | best_bleu 27.26
2023-08-28 21:36:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 19047 updates
2023-08-28 21:36:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1508.pt
2023-08-28 21:36:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1508.pt
2023-08-28 21:36:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1508.pt (epoch 16 @ 19047 updates, score 27.15) (writing took 6.253040145998966 seconds)
2023-08-28 21:36:14 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-28 21:36:14 | INFO | train | epoch 016 | loss 1.893 | trans_loss 4.731 | nll_loss 1.885 | w2v_ctc_loss 0.592 | task_loss 2.349 | contrastive_loss 0.122 | total 6701.85 | n_correct 4653.77 | ppl 3.69 | accuracy 69.44 | wps 16768.3 | ups 1.25 | wpb 13403.7 | bsz 451.5 | num_updates 19047 | lr 0.000102471 | gnorm 0.389 | clip 0 | loss_scale 32 | train_wall 852 | gb_free 13.8 | wall 4235
2023-08-28 21:36:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 21:36:14 | INFO | fairseq.trainer | begin training epoch 17
2023-08-28 21:36:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 21:37:01 | INFO | train_inner | epoch 017:     53 / 1191 loss=1.891, trans_loss=4.727, nll_loss=1.88, w2v_ctc_loss=0.585, task_loss=2.44, contrastive_loss=0.147, total=6599.44, n_correct=4584.6, ppl=3.68, accuracy=69.47, wps=11068.2, ups=0.84, wpb=13198.9, bsz=438, num_updates=19100, lr=0.000102329, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=4281
2023-08-28 21:38:13 | INFO | train_inner | epoch 017:    153 / 1191 loss=1.879, trans_loss=4.708, nll_loss=1.856, w2v_ctc_loss=0.58, task_loss=2.384, contrastive_loss=0.13, total=6686.83, n_correct=4677.05, ppl=3.62, accuracy=69.944, wps=18512.7, ups=1.38, wpb=13373.7, bsz=447.9, num_updates=19200, lr=0.000102062, gnorm=0.386, clip=0, loss_scale=32, train_wall=71, gb_free=14.5, wall=4354
2023-08-28 21:39:25 | INFO | train_inner | epoch 017:    253 / 1191 loss=1.87, trans_loss=4.701, nll_loss=1.847, w2v_ctc_loss=0.578, task_loss=2.201, contrastive_loss=0.082, total=6836.91, n_correct=4800.99, ppl=3.6, accuracy=70.222, wps=18857.8, ups=1.38, wpb=13673.8, bsz=477.7, num_updates=19300, lr=0.000101797, gnorm=0.382, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=4426
2023-08-28 21:40:37 | INFO | train_inner | epoch 017:    353 / 1191 loss=1.883, trans_loss=4.719, nll_loss=1.87, w2v_ctc_loss=0.588, task_loss=2.413, contrastive_loss=0.082, total=6636.25, n_correct=4625.17, ppl=3.66, accuracy=69.696, wps=18440.9, ups=1.39, wpb=13272.5, bsz=441.6, num_updates=19400, lr=0.000101535, gnorm=0.392, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=4498
2023-08-28 21:41:49 | INFO | train_inner | epoch 017:    453 / 1191 loss=1.891, trans_loss=4.726, nll_loss=1.879, w2v_ctc_loss=0.589, task_loss=2.406, contrastive_loss=0.131, total=6699.29, n_correct=4660.34, ppl=3.68, accuracy=69.565, wps=18637.6, ups=1.39, wpb=13398.6, bsz=443.3, num_updates=19500, lr=0.000101274, gnorm=0.39, clip=0, loss_scale=32, train_wall=71, gb_free=10.3, wall=4570
2023-08-28 21:43:02 | INFO | train_inner | epoch 017:    553 / 1191 loss=1.892, trans_loss=4.726, nll_loss=1.879, w2v_ctc_loss=0.586, task_loss=2.365, contrastive_loss=0.162, total=6686.83, n_correct=4652.87, ppl=3.68, accuracy=69.583, wps=18464.7, ups=1.38, wpb=13373.7, bsz=443.6, num_updates=19600, lr=0.000101015, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=4642
2023-08-28 21:44:14 | INFO | train_inner | epoch 017:    653 / 1191 loss=1.882, trans_loss=4.719, nll_loss=1.87, w2v_ctc_loss=0.584, task_loss=2.314, contrastive_loss=0.101, total=6693.12, n_correct=4670.25, ppl=3.66, accuracy=69.777, wps=18455.4, ups=1.38, wpb=13386.2, bsz=457.7, num_updates=19700, lr=0.000100759, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=11.9, wall=4715
2023-08-28 21:45:26 | INFO | train_inner | epoch 017:    753 / 1191 loss=1.887, trans_loss=4.729, nll_loss=1.883, w2v_ctc_loss=0.591, task_loss=2.449, contrastive_loss=0.069, total=6658.69, n_correct=4630.12, ppl=3.69, accuracy=69.535, wps=18497.6, ups=1.39, wpb=13317.4, bsz=433.5, num_updates=19800, lr=0.000100504, gnorm=0.39, clip=0, loss_scale=32, train_wall=71, gb_free=13.4, wall=4787
2023-08-28 21:46:39 | INFO | train_inner | epoch 017:    853 / 1191 loss=1.897, trans_loss=4.731, nll_loss=1.886, w2v_ctc_loss=0.592, task_loss=2.529, contrastive_loss=0.163, total=6597.99, n_correct=4585.83, ppl=3.7, accuracy=69.503, wps=18164.7, ups=1.38, wpb=13196, bsz=434.5, num_updates=19900, lr=0.000100251, gnorm=0.398, clip=0, loss_scale=32, train_wall=72, gb_free=13.2, wall=4860
2023-08-28 21:47:51 | INFO | train_inner | epoch 017:    953 / 1191 loss=1.885, trans_loss=4.716, nll_loss=1.869, w2v_ctc_loss=0.571, task_loss=2.056, contrastive_loss=0.221, total=6827, n_correct=4773.17, ppl=3.65, accuracy=69.916, wps=19034.6, ups=1.39, wpb=13654, bsz=497.7, num_updates=20000, lr=0.0001, gnorm=0.383, clip=0, loss_scale=32, train_wall=71, gb_free=14.4, wall=4931
2023-08-28 21:47:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 21:48:23 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.926 | trans_loss 5.199 | nll_loss 2.409 | w2v_ctc_loss 1.17 | task_loss 8.58 | contrastive_loss 0.254 | total 6138.43 | n_correct 4152.43 | ppl 5.31 | accuracy 67.646 | uer 16.84 | wer 18.416 | raw_wer 18.416 | bleu 26.9 | wps 1779.6 | wpb 6138.4 | bsz 201.1 | num_updates 20000 | best_bleu 27.26
2023-08-28 21:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20000 updates
2023-08-28 21:48:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_17_20000.pt
2023-08-28 21:48:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_17_20000.pt
2023-08-28 21:48:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_17_20000.pt (epoch 17 @ 20000 updates, score 26.9) (writing took 8.601471010999376 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-28 21:49:44 | INFO | train_inner | epoch 017:   1053 / 1191 loss=1.881, trans_loss=4.719, nll_loss=1.871, w2v_ctc_loss=0.581, task_loss=2.397, contrastive_loss=0.117, total=6650.1, n_correct=4639.79, ppl=3.66, accuracy=69.77, wps=11716.1, ups=0.88, wpb=13300.2, bsz=443.2, num_updates=20100, lr=9.97509e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=71, gb_free=13.1, wall=5045
2023-08-28 21:50:57 | INFO | train_inner | epoch 017:   1153 / 1191 loss=1.885, trans_loss=4.723, nll_loss=1.877, w2v_ctc_loss=0.591, task_loss=2.342, contrastive_loss=0.101, total=6758.75, n_correct=4715.23, ppl=3.67, accuracy=69.765, wps=18532.2, ups=1.37, wpb=13517.5, bsz=451.8, num_updates=20200, lr=9.95037e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=72, gb_free=5.4, wall=5118
2023-08-28 21:51:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-28 21:51:58 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.925 | trans_loss 5.196 | nll_loss 2.405 | w2v_ctc_loss 1.178 | task_loss 8.555 | contrastive_loss 0.251 | total 6138.43 | n_correct 4147 | ppl 5.3 | accuracy 67.558 | uer 17.081 | wer 18.75 | raw_wer 18.75 | bleu 27.15 | wps 1694.6 | wpb 6138.4 | bsz 201.1 | num_updates 20238 | best_bleu 27.26
2023-08-28 21:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20238 updates
2023-08-28 21:51:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1504.pt
2023-08-28 21:52:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1504.pt
2023-08-28 21:52:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1504.pt (epoch 17 @ 20238 updates, score 27.15) (writing took 19.935236657000132 seconds)
2023-08-28 21:52:18 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-28 21:52:18 | INFO | train | epoch 017 | loss 1.884 | trans_loss 4.72 | nll_loss 1.871 | w2v_ctc_loss 0.584 | task_loss 2.346 | contrastive_loss 0.123 | total 6703.69 | n_correct 4675.93 | ppl 3.66 | accuracy 69.752 | wps 16564.1 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 20238 | lr 9.94103e-05 | gnorm 0.389 | clip 0 | loss_scale 32 | train_wall 852 | gb_free 14.4 | wall 5199
2023-08-28 21:52:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 21:52:18 | INFO | fairseq.trainer | begin training epoch 18
2023-08-28 21:52:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 21:53:09 | INFO | train_inner | epoch 018:     62 / 1191 loss=1.871, trans_loss=4.701, nll_loss=1.848, w2v_ctc_loss=0.57, task_loss=2.25, contrastive_loss=0.117, total=6800.71, n_correct=4772.59, ppl=3.6, accuracy=70.178, wps=10291.7, ups=0.76, wpb=13601.4, bsz=463.8, num_updates=20300, lr=9.92583e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=5250
2023-08-28 21:54:22 | INFO | train_inner | epoch 018:    162 / 1191 loss=1.876, trans_loss=4.707, nll_loss=1.854, w2v_ctc_loss=0.581, task_loss=2.579, contrastive_loss=0.079, total=6654.58, n_correct=4659.2, ppl=3.61, accuracy=70.015, wps=18368, ups=1.38, wpb=13309.2, bsz=425.6, num_updates=20400, lr=9.90148e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=5322
2023-08-28 21:55:34 | INFO | train_inner | epoch 018:    262 / 1191 loss=1.881, trans_loss=4.703, nll_loss=1.849, w2v_ctc_loss=0.579, task_loss=2.393, contrastive_loss=0.184, total=6609.78, n_correct=4638.03, ppl=3.6, accuracy=70.169, wps=18378.9, ups=1.39, wpb=13219.6, bsz=444.8, num_updates=20500, lr=9.8773e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=71, gb_free=13.3, wall=5394
2023-08-28 21:56:46 | INFO | train_inner | epoch 018:    362 / 1191 loss=1.876, trans_loss=4.704, nll_loss=1.852, w2v_ctc_loss=0.575, task_loss=2.299, contrastive_loss=0.151, total=6733.43, n_correct=4720.07, ppl=3.61, accuracy=70.099, wps=18533.2, ups=1.38, wpb=13466.9, bsz=460.8, num_updates=20600, lr=9.85329e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=5467
2023-08-28 21:57:59 | INFO | train_inner | epoch 018:    462 / 1191 loss=1.873, trans_loss=4.708, nll_loss=1.857, w2v_ctc_loss=0.576, task_loss=2.326, contrastive_loss=0.097, total=6707.66, n_correct=4698.72, ppl=3.62, accuracy=70.05, wps=18451.6, ups=1.38, wpb=13415.3, bsz=455, num_updates=20700, lr=9.82946e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=5540
2023-08-28 21:59:11 | INFO | train_inner | epoch 018:    562 / 1191 loss=1.874, trans_loss=4.707, nll_loss=1.856, w2v_ctc_loss=0.576, task_loss=2.188, contrastive_loss=0.115, total=6819.92, n_correct=4781.62, ppl=3.62, accuracy=70.113, wps=18996.4, ups=1.39, wpb=13639.8, bsz=475.9, num_updates=20800, lr=9.80581e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=71, gb_free=12.1, wall=5612
2023-08-28 22:00:23 | INFO | train_inner | epoch 018:    662 / 1191 loss=1.874, trans_loss=4.706, nll_loss=1.854, w2v_ctc_loss=0.577, task_loss=2.492, contrastive_loss=0.096, total=6575.74, n_correct=4603.22, ppl=3.61, accuracy=70.003, wps=18369.9, ups=1.4, wpb=13151.5, bsz=431, num_updates=20900, lr=9.78232e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=71, gb_free=13.7, wall=5683
2023-08-28 22:01:35 | INFO | train_inner | epoch 018:    762 / 1191 loss=1.874, trans_loss=4.715, nll_loss=1.866, w2v_ctc_loss=0.579, task_loss=2.244, contrastive_loss=0.082, total=6831.22, n_correct=4778.68, ppl=3.65, accuracy=69.954, wps=18757.6, ups=1.37, wpb=13662.4, bsz=469.7, num_updates=21000, lr=9.759e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=72, gb_free=12.5, wall=5756
2023-08-28 22:02:48 | INFO | train_inner | epoch 018:    862 / 1191 loss=1.886, trans_loss=4.723, nll_loss=1.876, w2v_ctc_loss=0.584, task_loss=2.343, contrastive_loss=0.139, total=6718.12, n_correct=4683.19, ppl=3.67, accuracy=69.71, wps=18418, ups=1.37, wpb=13436.2, bsz=454.2, num_updates=21100, lr=9.73585e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=72, gb_free=13.7, wall=5829
2023-08-28 22:04:00 | INFO | train_inner | epoch 018:    962 / 1191 loss=1.875, trans_loss=4.711, nll_loss=1.861, w2v_ctc_loss=0.585, task_loss=2.298, contrastive_loss=0.074, total=6705.9, n_correct=4693.95, ppl=3.63, accuracy=69.997, wps=18652.6, ups=1.39, wpb=13411.8, bsz=452.4, num_updates=21200, lr=9.71286e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=71, gb_free=14.5, wall=5901
2023-08-28 22:05:12 | INFO | train_inner | epoch 018:   1062 / 1191 loss=1.884, trans_loss=4.718, nll_loss=1.871, w2v_ctc_loss=0.584, task_loss=2.452, contrastive_loss=0.134, total=6588.48, n_correct=4598.63, ppl=3.66, accuracy=69.798, wps=18327.4, ups=1.39, wpb=13177, bsz=435.7, num_updates=21300, lr=9.69003e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=71, gb_free=8.8, wall=5973
2023-08-28 22:06:25 | INFO | train_inner | epoch 018:   1162 / 1191 loss=1.886, trans_loss=4.717, nll_loss=1.87, w2v_ctc_loss=0.585, task_loss=2.311, contrastive_loss=0.147, total=6762.37, n_correct=4719.8, ppl=3.65, accuracy=69.795, wps=18640.8, ups=1.38, wpb=13524.7, bsz=464.9, num_updates=21400, lr=9.66736e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=72, gb_free=15.4, wall=6045
2023-08-28 22:06:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 22:07:17 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.931 | trans_loss 5.192 | nll_loss 2.4 | w2v_ctc_loss 1.204 | task_loss 8.578 | contrastive_loss 0.256 | total 6138.43 | n_correct 4147.57 | ppl 5.28 | accuracy 67.567 | uer 16.851 | wer 18.591 | raw_wer 18.591 | bleu 27.16 | wps 1769.2 | wpb 6138.4 | bsz 201.1 | num_updates 21429 | best_bleu 27.26
2023-08-28 22:07:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 21429 updates
2023-08-28 22:07:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1607.pt
2023-08-28 22:07:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1607.pt
2023-08-28 22:07:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1607.pt (epoch 18 @ 21429 updates, score 27.16) (writing took 6.487411361998966 seconds)
2023-08-28 22:07:24 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-28 22:07:24 | INFO | train | epoch 018 | loss 1.877 | trans_loss 4.709 | nll_loss 1.858 | w2v_ctc_loss 0.579 | task_loss 2.345 | contrastive_loss 0.121 | total 6703.69 | n_correct 4693.03 | ppl 3.63 | accuracy 70.007 | wps 17623.3 | ups 1.31 | wpb 13407.4 | bsz 452.1 | num_updates 21429 | lr 9.66082e-05 | gnorm 0.389 | clip 0 | loss_scale 64 | train_wall 850 | gb_free 14 | wall 6105
2023-08-28 22:07:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 22:07:24 | INFO | fairseq.trainer | begin training epoch 19
2023-08-28 22:07:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 22:08:24 | INFO | train_inner | epoch 019:     71 / 1191 loss=1.869, trans_loss=4.696, nll_loss=1.84, w2v_ctc_loss=0.571, task_loss=2.497, contrastive_loss=0.123, total=6584.81, n_correct=4627.43, ppl=3.58, accuracy=70.274, wps=11078.1, ups=0.84, wpb=13169.6, bsz=425.5, num_updates=21500, lr=9.64486e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=71, gb_free=13.4, wall=6164
2023-08-28 22:09:35 | INFO | train_inner | epoch 019:    171 / 1191 loss=1.862, trans_loss=4.687, nll_loss=1.829, w2v_ctc_loss=0.572, task_loss=2.367, contrastive_loss=0.073, total=6686.09, n_correct=4712.64, ppl=3.55, accuracy=70.484, wps=18746, ups=1.4, wpb=13372.2, bsz=446.8, num_updates=21600, lr=9.6225e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=70, gb_free=13.2, wall=6236
2023-08-28 22:10:48 | INFO | train_inner | epoch 019:    271 / 1191 loss=1.859, trans_loss=4.683, nll_loss=1.824, w2v_ctc_loss=0.563, task_loss=2.223, contrastive_loss=0.126, total=6770.02, n_correct=4775.87, ppl=3.54, accuracy=70.544, wps=18454.1, ups=1.36, wpb=13540, bsz=465.5, num_updates=21700, lr=9.60031e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=72, gb_free=14.4, wall=6309
2023-08-28 22:12:00 | INFO | train_inner | epoch 019:    371 / 1191 loss=1.863, trans_loss=4.695, nll_loss=1.84, w2v_ctc_loss=0.569, task_loss=2.336, contrastive_loss=0.065, total=6690.01, n_correct=4704.61, ppl=3.58, accuracy=70.323, wps=18691.2, ups=1.4, wpb=13380, bsz=444, num_updates=21800, lr=9.57826e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=6381
2023-08-28 22:13:12 | INFO | train_inner | epoch 019:    471 / 1191 loss=1.869, trans_loss=4.696, nll_loss=1.841, w2v_ctc_loss=0.565, task_loss=2.181, contrastive_loss=0.165, total=6788.2, n_correct=4771.3, ppl=3.58, accuracy=70.288, wps=18827.9, ups=1.39, wpb=13576.4, bsz=477.7, num_updates=21900, lr=9.55637e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=6453
2023-08-28 22:14:25 | INFO | train_inner | epoch 019:    571 / 1191 loss=1.868, trans_loss=4.702, nll_loss=1.85, w2v_ctc_loss=0.574, task_loss=2.314, contrastive_loss=0.092, total=6755.36, n_correct=4746.27, ppl=3.61, accuracy=70.259, wps=18579.8, ups=1.38, wpb=13510.7, bsz=463.5, num_updates=22000, lr=9.53463e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=72, gb_free=11.6, wall=6525
2023-08-28 22:14:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 22:14:57 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.923 | trans_loss 5.194 | nll_loss 2.402 | w2v_ctc_loss 1.178 | task_loss 8.526 | contrastive_loss 0.248 | total 6138.43 | n_correct 4150.14 | ppl 5.28 | accuracy 67.609 | uer 16.952 | wer 18.669 | raw_wer 18.669 | bleu 27.23 | wps 1746.1 | wpb 6138.4 | bsz 201.1 | num_updates 22000 | best_bleu 27.26
2023-08-28 22:14:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22000 updates
2023-08-28 22:14:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_19_22000.pt
2023-08-28 22:14:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_19_22000.pt
2023-08-28 22:15:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_19_22000.pt (epoch 19 @ 22000 updates, score 27.23) (writing took 7.201425631999882 seconds)
2023-08-28 22:16:16 | INFO | train_inner | epoch 019:    671 / 1191 loss=1.874, trans_loss=4.697, nll_loss=1.843, w2v_ctc_loss=0.571, task_loss=2.352, contrastive_loss=0.189, total=6659.23, n_correct=4679.01, ppl=3.59, accuracy=70.264, wps=11943.2, ups=0.9, wpb=13318.5, bsz=451.5, num_updates=22100, lr=9.51303e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=71, gb_free=10, wall=6637
2023-08-28 22:17:29 | INFO | train_inner | epoch 019:    771 / 1191 loss=1.869, trans_loss=4.701, nll_loss=1.85, w2v_ctc_loss=0.575, task_loss=2.31, contrastive_loss=0.097, total=6749.44, n_correct=4739.83, ppl=3.6, accuracy=70.226, wps=18495.9, ups=1.37, wpb=13498.9, bsz=460.8, num_updates=22200, lr=9.49158e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=72, gb_free=14.6, wall=6710
2023-08-28 22:18:41 | INFO | train_inner | epoch 019:    871 / 1191 loss=1.883, trans_loss=4.708, nll_loss=1.857, w2v_ctc_loss=0.585, task_loss=2.436, contrastive_loss=0.16, total=6614.36, n_correct=4628.44, ppl=3.62, accuracy=69.976, wps=18399.7, ups=1.39, wpb=13228.7, bsz=439.8, num_updates=22300, lr=9.47027e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=71, gb_free=14.5, wall=6782
2023-08-28 22:19:53 | INFO | train_inner | epoch 019:    971 / 1191 loss=1.873, trans_loss=4.705, nll_loss=1.854, w2v_ctc_loss=0.578, task_loss=2.521, contrastive_loss=0.099, total=6609.99, n_correct=4630.76, ppl=3.61, accuracy=70.057, wps=18479.8, ups=1.4, wpb=13220, bsz=433, num_updates=22400, lr=9.44911e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=71, gb_free=14.5, wall=6853
2023-08-28 22:21:04 | INFO | train_inner | epoch 019:   1071 / 1191 loss=1.871, trans_loss=4.703, nll_loss=1.852, w2v_ctc_loss=0.572, task_loss=2.281, contrastive_loss=0.121, total=6738.42, n_correct=4726.79, ppl=3.61, accuracy=70.147, wps=18786.8, ups=1.39, wpb=13476.8, bsz=456.5, num_updates=22500, lr=9.42809e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=71, gb_free=14.4, wall=6925
2023-08-28 22:22:18 | INFO | train_inner | epoch 019:   1171 / 1191 loss=1.879, trans_loss=4.717, nll_loss=1.871, w2v_ctc_loss=0.575, task_loss=2.354, contrastive_loss=0.143, total=6775.43, n_correct=4734.28, ppl=3.66, accuracy=69.874, wps=18491.9, ups=1.36, wpb=13550.9, bsz=453.5, num_updates=22600, lr=9.40721e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=72, gb_free=14, wall=6998
2023-08-28 22:22:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 22:23:04 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.937 | trans_loss 5.194 | nll_loss 2.403 | w2v_ctc_loss 1.216 | task_loss 8.485 | contrastive_loss 0.259 | total 6138.43 | n_correct 4154.71 | ppl 5.29 | accuracy 67.684 | uer 16.998 | wer 18.851 | raw_wer 18.851 | bleu 27.11 | wps 1741.6 | wpb 6138.4 | bsz 201.1 | num_updates 22620 | best_bleu 27.26
2023-08-28 22:23:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22620 updates
2023-08-28 22:23:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1105.pt
2023-08-28 22:23:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1105.pt
2023-08-28 22:23:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1105.pt (epoch 19 @ 22620 updates, score 27.11) (writing took 6.298668917999748 seconds)
2023-08-28 22:23:11 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-28 22:23:11 | INFO | train | epoch 019 | loss 1.87 | trans_loss 4.699 | nll_loss 1.846 | w2v_ctc_loss 0.573 | task_loss 2.345 | contrastive_loss 0.119 | total 6703.69 | n_correct 4707.72 | ppl 3.6 | accuracy 70.226 | wps 16864.4 | ups 1.26 | wpb 13407.4 | bsz 452.1 | num_updates 22620 | lr 9.40305e-05 | gnorm 0.388 | clip 0 | loss_scale 64 | train_wall 850 | gb_free 14.4 | wall 7052
2023-08-28 22:23:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 22:23:11 | INFO | fairseq.trainer | begin training epoch 20
2023-08-28 22:23:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 22:24:16 | INFO | train_inner | epoch 020:     80 / 1191 loss=1.858, trans_loss=4.681, nll_loss=1.823, w2v_ctc_loss=0.563, task_loss=2.351, contrastive_loss=0.105, total=6711.92, n_correct=4743.51, ppl=3.54, accuracy=70.673, wps=11316.7, ups=0.84, wpb=13423.8, bsz=456.2, num_updates=22700, lr=9.38647e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=72, gb_free=11.6, wall=7117
2023-08-28 22:25:28 | INFO | train_inner | epoch 020:    180 / 1191 loss=1.859, trans_loss=4.679, nll_loss=1.819, w2v_ctc_loss=0.565, task_loss=2.431, contrastive_loss=0.121, total=6603.18, n_correct=4663.61, ppl=3.53, accuracy=70.627, wps=18401.3, ups=1.39, wpb=13206.4, bsz=438.4, num_updates=22800, lr=9.36586e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=7189
2023-08-28 22:26:40 | INFO | train_inner | epoch 020:    280 / 1191 loss=1.863, trans_loss=4.689, nll_loss=1.833, w2v_ctc_loss=0.563, task_loss=2.311, contrastive_loss=0.128, total=6772.8, n_correct=4770.8, ppl=3.56, accuracy=70.441, wps=18898.3, ups=1.4, wpb=13545.6, bsz=458.6, num_updates=22900, lr=9.34539e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=71, gb_free=15.3, wall=7260
2023-08-28 22:27:51 | INFO | train_inner | epoch 020:    380 / 1191 loss=1.857, trans_loss=4.688, nll_loss=1.832, w2v_ctc_loss=0.567, task_loss=2.237, contrastive_loss=0.074, total=6788.01, n_correct=4786.42, ppl=3.56, accuracy=70.513, wps=18924.8, ups=1.39, wpb=13576, bsz=465.3, num_updates=23000, lr=9.32505e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=7332
2023-08-28 22:28:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-28 22:29:04 | INFO | train_inner | epoch 020:    481 / 1191 loss=1.859, trans_loss=4.685, nll_loss=1.828, w2v_ctc_loss=0.562, task_loss=2.36, contrastive_loss=0.11, total=6680.17, n_correct=4713.87, ppl=3.55, accuracy=70.565, wps=18484, ups=1.38, wpb=13360.3, bsz=443.7, num_updates=23100, lr=9.30484e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=72, gb_free=12.6, wall=7404
2023-08-28 22:30:17 | INFO | train_inner | epoch 020:    581 / 1191 loss=1.876, trans_loss=4.694, nll_loss=1.84, w2v_ctc_loss=0.57, task_loss=2.437, contrastive_loss=0.215, total=6611.79, n_correct=4649.56, ppl=3.58, accuracy=70.322, wps=18184.2, ups=1.38, wpb=13223.6, bsz=439.9, num_updates=23200, lr=9.28477e-05, gnorm=0.396, clip=0, loss_scale=64, train_wall=72, gb_free=4.9, wall=7477
2023-08-28 22:30:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-28 22:31:29 | INFO | train_inner | epoch 020:    682 / 1191 loss=1.859, trans_loss=4.689, nll_loss=1.833, w2v_ctc_loss=0.558, task_loss=2.215, contrastive_loss=0.135, total=6712.97, n_correct=4736.62, ppl=3.56, accuracy=70.559, wps=18512.3, ups=1.38, wpb=13425.9, bsz=468.4, num_updates=23300, lr=9.26482e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=7550
2023-08-28 22:32:41 | INFO | train_inner | epoch 020:    782 / 1191 loss=1.862, trans_loss=4.69, nll_loss=1.835, w2v_ctc_loss=0.566, task_loss=2.244, contrastive_loss=0.118, total=6749.91, n_correct=4758.29, ppl=3.57, accuracy=70.494, wps=18864.3, ups=1.4, wpb=13499.8, bsz=458.6, num_updates=23400, lr=9.245e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=71, gb_free=13.8, wall=7621
2023-08-28 22:33:53 | INFO | train_inner | epoch 020:    882 / 1191 loss=1.863, trans_loss=4.695, nll_loss=1.842, w2v_ctc_loss=0.569, task_loss=2.408, contrastive_loss=0.081, total=6725.15, n_correct=4733.15, ppl=3.58, accuracy=70.38, wps=18645.4, ups=1.39, wpb=13450.3, bsz=447.2, num_updates=23500, lr=9.22531e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=71, gb_free=13.3, wall=7693
2023-08-28 22:35:05 | INFO | train_inner | epoch 020:    982 / 1191 loss=1.862, trans_loss=4.696, nll_loss=1.843, w2v_ctc_loss=0.566, task_loss=2.532, contrastive_loss=0.073, total=6666.28, n_correct=4687.94, ppl=3.59, accuracy=70.323, wps=18353.3, ups=1.38, wpb=13332.6, bsz=433.5, num_updates=23600, lr=9.20575e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=13.3, wall=7766
2023-08-28 22:36:17 | INFO | train_inner | epoch 020:   1082 / 1191 loss=1.862, trans_loss=4.693, nll_loss=1.84, w2v_ctc_loss=0.574, task_loss=2.313, contrastive_loss=0.069, total=6748.86, n_correct=4750.8, ppl=3.58, accuracy=70.394, wps=18784.2, ups=1.39, wpb=13497.7, bsz=458, num_updates=23700, lr=9.1863e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=71, gb_free=13.3, wall=7838
2023-08-28 22:37:30 | INFO | train_inner | epoch 020:   1182 / 1191 loss=1.871, trans_loss=4.706, nll_loss=1.857, w2v_ctc_loss=0.572, task_loss=2.369, contrastive_loss=0.112, total=6683.47, n_correct=4690.4, ppl=3.62, accuracy=70.179, wps=18405.3, ups=1.38, wpb=13366.9, bsz=452.7, num_updates=23800, lr=9.16698e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=14.1, wall=7911
2023-08-28 22:37:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 22:38:09 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.915 | trans_loss 5.188 | nll_loss 2.393 | w2v_ctc_loss 1.16 | task_loss 8.519 | contrastive_loss 0.255 | total 6138.43 | n_correct 4162.29 | ppl 5.25 | accuracy 67.807 | uer 16.621 | wer 18.576 | raw_wer 18.576 | bleu 27.16 | wps 1761.4 | wpb 6138.4 | bsz 201.1 | num_updates 23809 | best_bleu 27.26
2023-08-28 22:38:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 23809 updates
2023-08-28 22:38:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1609.pt
2023-08-28 22:38:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1609.pt
2023-08-28 22:38:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.1609.pt (epoch 20 @ 23809 updates, score 27.16) (writing took 7.275541135997628 seconds)
2023-08-28 22:38:16 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-28 22:38:16 | INFO | train | epoch 020 | loss 1.863 | trans_loss 4.69 | nll_loss 1.835 | w2v_ctc_loss 0.566 | task_loss 2.351 | contrastive_loss 0.116 | total 6701.61 | n_correct 4721.47 | ppl 3.57 | accuracy 70.453 | wps 17600.2 | ups 1.31 | wpb 13403.2 | bsz 451.4 | num_updates 23809 | lr 9.16525e-05 | gnorm 0.39 | clip 0 | loss_scale 32 | train_wall 850 | gb_free 15.4 | wall 7957
2023-08-28 22:38:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 22:38:17 | INFO | fairseq.trainer | begin training epoch 21
2023-08-28 22:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 22:39:29 | INFO | train_inner | epoch 021:     91 / 1191 loss=1.857, trans_loss=4.67, nll_loss=1.809, w2v_ctc_loss=0.55, task_loss=2.199, contrastive_loss=0.227, total=6760.63, n_correct=4792.5, ppl=3.5, accuracy=70.888, wps=11357.1, ups=0.84, wpb=13521.3, bsz=474.7, num_updates=23900, lr=9.14779e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=71, gb_free=12.5, wall=8030
2023-08-28 22:40:41 | INFO | train_inner | epoch 021:    191 / 1191 loss=1.844, trans_loss=4.665, nll_loss=1.803, w2v_ctc_loss=0.554, task_loss=2.208, contrastive_loss=0.096, total=6783.08, n_correct=4817.98, ppl=3.49, accuracy=71.029, wps=18847.9, ups=1.39, wpb=13566.2, bsz=471.6, num_updates=24000, lr=9.12871e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=71, gb_free=14.2, wall=8102
2023-08-28 22:40:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 22:41:14 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.932 | trans_loss 5.194 | nll_loss 2.399 | w2v_ctc_loss 1.205 | task_loss 8.517 | contrastive_loss 0.251 | total 6138.43 | n_correct 4161 | ppl 5.27 | accuracy 67.786 | uer 16.829 | wer 18.713 | raw_wer 18.713 | bleu 27.13 | wps 1663.2 | wpb 6138.4 | bsz 201.1 | num_updates 24000 | best_bleu 27.26
2023-08-28 22:41:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 24000 updates
2023-08-28 22:41:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_21_24000.pt
2023-08-28 22:41:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_21_24000.pt
2023-08-28 22:41:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_21_24000.pt (epoch 21 @ 24000 updates, score 27.13) (writing took 6.853358862997993 seconds)
2023-08-28 22:42:34 | INFO | train_inner | epoch 021:    291 / 1191 loss=1.85, trans_loss=4.676, nll_loss=1.815, w2v_ctc_loss=0.561, task_loss=2.434, contrastive_loss=0.062, total=6641.78, n_correct=4705.17, ppl=3.52, accuracy=70.842, wps=11793.3, ups=0.89, wpb=13283.6, bsz=436, num_updates=24100, lr=9.10975e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=70, gb_free=15.4, wall=8214
2023-08-28 22:43:46 | INFO | train_inner | epoch 021:    391 / 1191 loss=1.849, trans_loss=4.677, nll_loss=1.819, w2v_ctc_loss=0.555, task_loss=2.371, contrastive_loss=0.082, total=6675.38, n_correct=4728.21, ppl=3.53, accuracy=70.831, wps=18425.3, ups=1.38, wpb=13350.8, bsz=450.4, num_updates=24200, lr=9.09091e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=72, gb_free=12.7, wall=8287
2023-08-28 22:44:58 | INFO | train_inner | epoch 021:    491 / 1191 loss=1.856, trans_loss=4.677, nll_loss=1.818, w2v_ctc_loss=0.564, task_loss=2.456, contrastive_loss=0.1, total=6679.69, n_correct=4723.71, ppl=3.53, accuracy=70.718, wps=18569.5, ups=1.39, wpb=13359.4, bsz=437.8, num_updates=24300, lr=9.07218e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=71, gb_free=13.2, wall=8359
2023-08-28 22:46:10 | INFO | train_inner | epoch 021:    591 / 1191 loss=1.861, trans_loss=4.688, nll_loss=1.832, w2v_ctc_loss=0.572, task_loss=2.523, contrastive_loss=0.063, total=6618.89, n_correct=4667.06, ppl=3.56, accuracy=70.511, wps=18422.9, ups=1.39, wpb=13237.8, bsz=424, num_updates=24400, lr=9.05357e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=71, gb_free=13.1, wall=8431
2023-08-28 22:47:22 | INFO | train_inner | epoch 021:    691 / 1191 loss=1.86, trans_loss=4.684, nll_loss=1.827, w2v_ctc_loss=0.564, task_loss=2.304, contrastive_loss=0.131, total=6724.83, n_correct=4751.34, ppl=3.55, accuracy=70.654, wps=18511.4, ups=1.38, wpb=13449.7, bsz=465.4, num_updates=24500, lr=9.03508e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=72, gb_free=7.6, wall=8503
2023-08-28 22:48:35 | INFO | train_inner | epoch 021:    791 / 1191 loss=1.866, trans_loss=4.686, nll_loss=1.83, w2v_ctc_loss=0.563, task_loss=2.438, contrastive_loss=0.182, total=6629.21, n_correct=4674.22, ppl=3.56, accuracy=70.509, wps=18402.8, ups=1.39, wpb=13258.4, bsz=443.8, num_updates=24600, lr=9.0167e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=8575
2023-08-28 22:49:46 | INFO | train_inner | epoch 021:    891 / 1191 loss=1.862, trans_loss=4.686, nll_loss=1.83, w2v_ctc_loss=0.565, task_loss=2.318, contrastive_loss=0.125, total=6739.57, n_correct=4755.02, ppl=3.56, accuracy=70.554, wps=18736.3, ups=1.39, wpb=13479.1, bsz=453.1, num_updates=24700, lr=8.99843e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=71, gb_free=14.6, wall=8647
2023-08-28 22:50:59 | INFO | train_inner | epoch 021:    991 / 1191 loss=1.859, trans_loss=4.692, nll_loss=1.839, w2v_ctc_loss=0.559, task_loss=2.246, contrastive_loss=0.127, total=6793.05, n_correct=4789.65, ppl=3.58, accuracy=70.508, wps=18694.9, ups=1.38, wpb=13586.1, bsz=464, num_updates=24800, lr=8.98027e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=72, gb_free=12.1, wall=8720
2023-08-28 22:52:12 | INFO | train_inner | epoch 021:   1091 / 1191 loss=1.863, trans_loss=4.693, nll_loss=1.839, w2v_ctc_loss=0.568, task_loss=2.288, contrastive_loss=0.106, total=6727.98, n_correct=4733.98, ppl=3.58, accuracy=70.363, wps=18563.7, ups=1.38, wpb=13456, bsz=456.2, num_updates=24900, lr=8.96221e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=8792
2023-08-28 22:53:24 | INFO | train_inner | epoch 021:   1191 / 1191 loss=1.862, trans_loss=4.69, nll_loss=1.837, w2v_ctc_loss=0.563, task_loss=2.385, contrastive_loss=0.131, total=6662.99, n_correct=4698.61, ppl=3.57, accuracy=70.518, wps=18383.7, ups=1.38, wpb=13326, bsz=453.1, num_updates=25000, lr=8.94427e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=8865
2023-08-28 22:53:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 22:53:57 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.928 | trans_loss 5.187 | nll_loss 2.392 | w2v_ctc_loss 1.21 | task_loss 8.578 | contrastive_loss 0.247 | total 6138.43 | n_correct 4163.29 | ppl 5.25 | accuracy 67.823 | uer 16.771 | wer 18.605 | raw_wer 18.605 | bleu 27.2 | wps 1682.7 | wpb 6138.4 | bsz 201.1 | num_updates 25000 | best_bleu 27.26
2023-08-28 22:53:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 25000 updates
2023-08-28 22:53:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.2008.pt
2023-08-28 22:54:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.2008.pt
2023-08-28 22:54:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.2008.pt (epoch 21 @ 25000 updates, score 27.2) (writing took 5.848218220999115 seconds)
2023-08-28 22:54:03 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-28 22:54:03 | INFO | train | epoch 021 | loss 1.857 | trans_loss 4.682 | nll_loss 1.824 | w2v_ctc_loss 0.561 | task_loss 2.346 | contrastive_loss 0.117 | total 6703.69 | n_correct 4737.48 | ppl 3.54 | accuracy 70.67 | wps 16859.4 | ups 1.26 | wpb 13407.4 | bsz 452.1 | num_updates 25000 | lr 8.94427e-05 | gnorm 0.39 | clip 0 | loss_scale 32 | train_wall 850 | gb_free 13.6 | wall 8904
2023-08-28 22:54:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 22:54:04 | INFO | fairseq.trainer | begin training epoch 22
2023-08-28 22:54:04 | INFO | fairseq_cli.train | Start iterating over samples
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-28 22:55:23 | INFO | train_inner | epoch 022:    100 / 1191 loss=1.835, trans_loss=4.656, nll_loss=1.791, w2v_ctc_loss=0.541, task_loss=2.296, contrastive_loss=0.084, total=6760.58, n_correct=4818.72, ppl=3.46, accuracy=71.277, wps=11407.8, ups=0.84, wpb=13521.2, bsz=458.1, num_updates=25100, lr=8.92644e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=71, gb_free=11.6, wall=8983
2023-08-28 22:56:35 | INFO | train_inner | epoch 022:    200 / 1191 loss=1.846, trans_loss=4.668, nll_loss=1.806, w2v_ctc_loss=0.551, task_loss=2.415, contrastive_loss=0.105, total=6653.73, n_correct=4726.91, ppl=3.5, accuracy=71.042, wps=18384.8, ups=1.38, wpb=13307.5, bsz=443.7, num_updates=25200, lr=8.90871e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=72, gb_free=14.8, wall=9056
2023-08-28 22:57:47 | INFO | train_inner | epoch 022:    300 / 1191 loss=1.846, trans_loss=4.663, nll_loss=1.8, w2v_ctc_loss=0.55, task_loss=2.26, contrastive_loss=0.141, total=6760.38, n_correct=4805.06, ppl=3.48, accuracy=71.077, wps=18785, ups=1.39, wpb=13520.8, bsz=468.9, num_updates=25300, lr=8.89108e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=71, gb_free=13.5, wall=9128
2023-08-28 22:59:00 | INFO | train_inner | epoch 022:    400 / 1191 loss=1.843, trans_loss=4.667, nll_loss=1.806, w2v_ctc_loss=0.552, task_loss=2.338, contrastive_loss=0.073, total=6656.15, n_correct=4726.51, ppl=3.5, accuracy=71.01, wps=18313.5, ups=1.38, wpb=13312.3, bsz=453.8, num_updates=25400, lr=8.87357e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=72, gb_free=10.3, wall=9200
2023-08-28 23:00:12 | INFO | train_inner | epoch 022:    500 / 1191 loss=1.855, trans_loss=4.677, nll_loss=1.819, w2v_ctc_loss=0.562, task_loss=2.341, contrastive_loss=0.133, total=6717.53, n_correct=4761.58, ppl=3.53, accuracy=70.883, wps=18493.2, ups=1.38, wpb=13435.1, bsz=458.6, num_updates=25500, lr=8.85615e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=72, gb_free=13.4, wall=9273
2023-08-28 23:01:24 | INFO | train_inner | epoch 022:    600 / 1191 loss=1.846, trans_loss=4.673, nll_loss=1.813, w2v_ctc_loss=0.553, task_loss=2.353, contrastive_loss=0.074, total=6723.14, n_correct=4765.11, ppl=3.51, accuracy=70.876, wps=18725.6, ups=1.39, wpb=13446.3, bsz=451.4, num_updates=25600, lr=8.83883e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=71, gb_free=13.7, wall=9345
2023-08-28 23:02:36 | INFO | train_inner | epoch 022:    700 / 1191 loss=1.85, trans_loss=4.674, nll_loss=1.815, w2v_ctc_loss=0.549, task_loss=2.294, contrastive_loss=0.139, total=6706.45, n_correct=4755.27, ppl=3.52, accuracy=70.906, wps=18676.2, ups=1.39, wpb=13412.9, bsz=453.7, num_updates=25700, lr=8.82162e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=71, gb_free=15, wall=9417
2023-08-28 23:03:48 | INFO | train_inner | epoch 022:    800 / 1191 loss=1.851, trans_loss=4.672, nll_loss=1.812, w2v_ctc_loss=0.556, task_loss=2.43, contrastive_loss=0.128, total=6575.84, n_correct=4665.03, ppl=3.51, accuracy=70.942, wps=18388.7, ups=1.4, wpb=13151.7, bsz=435.9, num_updates=25800, lr=8.80451e-05, gnorm=0.396, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=9488
2023-08-28 23:05:01 | INFO | train_inner | epoch 022:    900 / 1191 loss=1.867, trans_loss=4.689, nll_loss=1.834, w2v_ctc_loss=0.561, task_loss=2.379, contrastive_loss=0.193, total=6693.43, n_correct=4717.07, ppl=3.57, accuracy=70.473, wps=18295.2, ups=1.37, wpb=13386.9, bsz=450.5, num_updates=25900, lr=8.7875e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=72, gb_free=13.7, wall=9561
2023-08-28 23:06:13 | INFO | train_inner | epoch 022:   1000 / 1191 loss=1.853, trans_loss=4.68, nll_loss=1.823, w2v_ctc_loss=0.558, task_loss=2.237, contrastive_loss=0.097, total=6841.71, n_correct=4837.34, ppl=3.54, accuracy=70.704, wps=18996.9, ups=1.39, wpb=13683.4, bsz=466.9, num_updates=26000, lr=8.77058e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=71, gb_free=4.3, wall=9633
2023-08-28 23:06:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-28 23:06:45 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.91 | trans_loss 5.182 | nll_loss 2.388 | w2v_ctc_loss 1.165 | task_loss 8.54 | contrastive_loss 0.244 | total 6138.43 | n_correct 4167.71 | ppl 5.24 | accuracy 67.895 | uer 16.589 | wer 18.457 | raw_wer 18.457 | bleu 27.25 | wps 1759.4 | wpb 6138.4 | bsz 201.1 | num_updates 26000 | best_bleu 27.26
2023-08-28 23:06:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 26000 updates
2023-08-28 23:06:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_22_26000.pt
2023-08-28 23:06:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_22_26000.pt
2023-08-28 23:06:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_22_26000.pt (epoch 22 @ 26000 updates, score 27.25) (writing took 6.723166603002028 seconds)
2023-08-28 23:08:03 | INFO | train_inner | epoch 022:   1100 / 1191 loss=1.848, trans_loss=4.675, nll_loss=1.817, w2v_ctc_loss=0.552, task_loss=2.319, contrastive_loss=0.101, total=6717.97, n_correct=4758.62, ppl=3.52, accuracy=70.834, wps=12173.2, ups=0.91, wpb=13435.9, bsz=450.9, num_updates=26100, lr=8.75376e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=70, gb_free=14.5, wall=9744
2023-08-28 23:09:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 23:09:42 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.925 | trans_loss 5.186 | nll_loss 2.391 | w2v_ctc_loss 1.204 | task_loss 8.528 | contrastive_loss 0.247 | total 6138.43 | n_correct 4165 | ppl 5.24 | accuracy 67.851 | uer 16.744 | wer 18.587 | raw_wer 18.587 | bleu 27.4 | wps 1688.4 | wpb 6138.4 | bsz 201.1 | num_updates 26191 | best_bleu 27.4
2023-08-28 23:09:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 26191 updates
2023-08-28 23:09:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-28 23:09:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-28 23:09:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 22 @ 26191 updates, score 27.4) (writing took 10.280843595999613 seconds)
2023-08-28 23:09:53 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-28 23:09:53 | INFO | train | epoch 022 | loss 1.85 | trans_loss 4.673 | nll_loss 1.814 | w2v_ctc_loss 0.554 | task_loss 2.345 | contrastive_loss 0.115 | total 6703.69 | n_correct 4751.94 | ppl 3.52 | accuracy 70.885 | wps 16818.5 | ups 1.25 | wpb 13407.4 | bsz 452.1 | num_updates 26191 | lr 8.73854e-05 | gnorm 0.391 | clip 0 | loss_scale 64 | train_wall 851 | gb_free 13.7 | wall 9854
2023-08-28 23:09:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 23:09:53 | INFO | fairseq.trainer | begin training epoch 23
2023-08-28 23:09:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 23:10:07 | INFO | train_inner | epoch 023:      9 / 1191 loss=1.856, trans_loss=4.684, nll_loss=1.828, w2v_ctc_loss=0.56, task_loss=2.498, contrastive_loss=0.103, total=6647.72, n_correct=4698.05, ppl=3.55, accuracy=70.672, wps=10766.1, ups=0.81, wpb=13295.4, bsz=431.8, num_updates=26200, lr=8.73704e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=72, gb_free=12.1, wall=9867
2023-08-28 23:11:19 | INFO | train_inner | epoch 023:    109 / 1191 loss=1.839, trans_loss=4.655, nll_loss=1.789, w2v_ctc_loss=0.548, task_loss=2.475, contrastive_loss=0.093, total=6639.61, n_correct=4735.39, ppl=3.45, accuracy=71.32, wps=18394.9, ups=1.39, wpb=13279.2, bsz=435.9, num_updates=26300, lr=8.72041e-05, gnorm=0.395, clip=0, loss_scale=64, train_wall=72, gb_free=14.4, wall=9939
2023-08-28 23:12:31 | INFO | train_inner | epoch 023:    209 / 1191 loss=1.837, trans_loss=4.658, nll_loss=1.795, w2v_ctc_loss=0.547, task_loss=2.213, contrastive_loss=0.087, total=6811.39, n_correct=4848.38, ppl=3.47, accuracy=71.18, wps=18904, ups=1.39, wpb=13622.8, bsz=475.4, num_updates=26400, lr=8.70388e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=10012
2023-08-28 23:13:43 | INFO | train_inner | epoch 023:    309 / 1191 loss=1.829, trans_loss=4.652, nll_loss=1.786, w2v_ctc_loss=0.539, task_loss=2.24, contrastive_loss=0.059, total=6814.53, n_correct=4870.1, ppl=3.45, accuracy=71.466, wps=18986, ups=1.39, wpb=13629.1, bsz=463.2, num_updates=26500, lr=8.68744e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=71, gb_free=14.3, wall=10083
2023-08-28 23:14:55 | INFO | train_inner | epoch 023:    409 / 1191 loss=1.852, trans_loss=4.671, nll_loss=1.81, w2v_ctc_loss=0.554, task_loss=2.419, contrastive_loss=0.135, total=6735.37, n_correct=4776.81, ppl=3.51, accuracy=70.921, wps=18677.6, ups=1.39, wpb=13470.7, bsz=440.8, num_updates=26600, lr=8.6711e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=71, gb_free=12.2, wall=10155
2023-08-28 23:16:07 | INFO | train_inner | epoch 023:    509 / 1191 loss=1.844, trans_loss=4.662, nll_loss=1.8, w2v_ctc_loss=0.54, task_loss=2.324, contrastive_loss=0.164, total=6697.56, n_correct=4763.96, ppl=3.48, accuracy=71.13, wps=18634.7, ups=1.39, wpb=13395.1, bsz=452.7, num_updates=26700, lr=8.65485e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=10227
2023-08-28 23:17:19 | INFO | train_inner | epoch 023:    609 / 1191 loss=1.845, trans_loss=4.666, nll_loss=1.806, w2v_ctc_loss=0.548, task_loss=2.291, contrastive_loss=0.12, total=6678.26, n_correct=4747.42, ppl=3.5, accuracy=71.088, wps=18554.6, ups=1.39, wpb=13356.5, bsz=455.9, num_updates=26800, lr=8.63868e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=71, gb_free=11.5, wall=10299
2023-08-28 23:18:32 | INFO | train_inner | epoch 023:    709 / 1191 loss=1.849, trans_loss=4.669, nll_loss=1.807, w2v_ctc_loss=0.544, task_loss=2.415, contrastive_loss=0.173, total=6657.33, n_correct=4732.35, ppl=3.5, accuracy=71.085, wps=18218.1, ups=1.37, wpb=13314.7, bsz=442.5, num_updates=26900, lr=8.62261e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=72, gb_free=12.2, wall=10372
2023-08-28 23:19:45 | INFO | train_inner | epoch 023:    809 / 1191 loss=1.844, trans_loss=4.673, nll_loss=1.815, w2v_ctc_loss=0.551, task_loss=2.38, contrastive_loss=0.077, total=6736.31, n_correct=4781.31, ppl=3.52, accuracy=70.978, wps=18504.2, ups=1.37, wpb=13472.6, bsz=448.7, num_updates=27000, lr=8.60663e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=72, gb_free=4.4, wall=10445
2023-08-28 23:20:56 | INFO | train_inner | epoch 023:    909 / 1191 loss=1.841, trans_loss=4.663, nll_loss=1.802, w2v_ctc_loss=0.556, task_loss=2.259, contrastive_loss=0.071, total=6708.19, n_correct=4779.07, ppl=3.49, accuracy=71.242, wps=18824.9, ups=1.4, wpb=13416.4, bsz=464, num_updates=27100, lr=8.59074e-05, gnorm=0.393, clip=0, loss_scale=64, train_wall=70, gb_free=14.5, wall=10517
2023-08-28 23:22:08 | INFO | train_inner | epoch 023:   1009 / 1191 loss=1.848, trans_loss=4.67, nll_loss=1.812, w2v_ctc_loss=0.557, task_loss=2.263, contrastive_loss=0.116, total=6663.73, n_correct=4730.72, ppl=3.51, accuracy=70.992, wps=18521.6, ups=1.39, wpb=13327.5, bsz=463.1, num_updates=27200, lr=8.57493e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=71, gb_free=15.3, wall=10588
2023-08-28 23:23:20 | INFO | train_inner | epoch 023:   1109 / 1191 loss=1.85, trans_loss=4.677, nll_loss=1.819, w2v_ctc_loss=0.553, task_loss=2.459, contrastive_loss=0.113, total=6637.7, n_correct=4703.19, ppl=3.53, accuracy=70.856, wps=18348.6, ups=1.38, wpb=13275.4, bsz=439.9, num_updates=27300, lr=8.55921e-05, gnorm=0.393, clip=0, loss_scale=64, train_wall=72, gb_free=12.9, wall=10661
2023-08-28 23:24:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-28 23:24:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 23:24:53 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.916 | trans_loss 5.181 | nll_loss 2.386 | w2v_ctc_loss 1.183 | task_loss 8.523 | contrastive_loss 0.251 | total 6138.43 | n_correct 4170.14 | ppl 5.23 | accuracy 67.935 | uer 16.369 | wer 18.148 | raw_wer 18.148 | bleu 27.28 | wps 1687 | wpb 6138.4 | bsz 201.1 | num_updates 27381 | best_bleu 27.4
2023-08-28 23:24:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 27381 updates
2023-08-28 23:24:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.2806.pt
2023-08-28 23:24:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.2806.pt
2023-08-28 23:25:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.2806.pt (epoch 23 @ 27381 updates, score 27.28) (writing took 7.8094946929995785 seconds)
2023-08-28 23:25:01 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-28 23:25:01 | INFO | train | epoch 023 | loss 1.844 | trans_loss 4.666 | nll_loss 1.805 | w2v_ctc_loss 0.549 | task_loss 2.344 | contrastive_loss 0.113 | total 6703.29 | n_correct 4765.63 | ppl 3.49 | accuracy 71.094 | wps 17569.7 | ups 1.31 | wpb 13406.6 | bsz 452 | num_updates 27381 | lr 8.54654e-05 | gnorm 0.391 | clip 0 | loss_scale 64 | train_wall 852 | gb_free 14.7 | wall 10762
2023-08-28 23:25:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 23:25:01 | INFO | fairseq.trainer | begin training epoch 24
2023-08-28 23:25:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 23:25:22 | INFO | train_inner | epoch 024:     19 / 1191 loss=1.855, trans_loss=4.675, nll_loss=1.816, w2v_ctc_loss=0.557, task_loss=2.442, contrastive_loss=0.151, total=6657.97, n_correct=4717.54, ppl=3.52, accuracy=70.856, wps=10944.5, ups=0.82, wpb=13315.9, bsz=439, num_updates=27400, lr=8.54358e-05, gnorm=0.4, clip=0, loss_scale=64, train_wall=72, gb_free=11.8, wall=10783
2023-08-28 23:26:33 | INFO | train_inner | epoch 024:    119 / 1191 loss=1.832, trans_loss=4.649, nll_loss=1.783, w2v_ctc_loss=0.539, task_loss=2.196, contrastive_loss=0.112, total=6770.69, n_correct=4841.08, ppl=3.44, accuracy=71.501, wps=18919.2, ups=1.4, wpb=13541.4, bsz=478, num_updates=27500, lr=8.52803e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=71, gb_free=14, wall=10854
2023-08-28 23:27:45 | INFO | train_inner | epoch 024:    219 / 1191 loss=1.834, trans_loss=4.648, nll_loss=1.782, w2v_ctc_loss=0.532, task_loss=2.157, contrastive_loss=0.183, total=6808.43, n_correct=4868.6, ppl=3.44, accuracy=71.508, wps=19098.9, ups=1.4, wpb=13616.9, bsz=478.7, num_updates=27600, lr=8.51257e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=71, gb_free=14.8, wall=10925
2023-08-28 23:28:57 | INFO | train_inner | epoch 024:    319 / 1191 loss=1.84, trans_loss=4.658, nll_loss=1.794, w2v_ctc_loss=0.546, task_loss=2.349, contrastive_loss=0.124, total=6739.01, n_correct=4801.41, ppl=3.47, accuracy=71.248, wps=18763.4, ups=1.39, wpb=13478, bsz=450.4, num_updates=27700, lr=8.49719e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=10997
2023-08-28 23:30:09 | INFO | train_inner | epoch 024:    419 / 1191 loss=1.835, trans_loss=4.654, nll_loss=1.789, w2v_ctc_loss=0.543, task_loss=2.452, contrastive_loss=0.084, total=6663.22, n_correct=4755.02, ppl=3.46, accuracy=71.362, wps=18401, ups=1.38, wpb=13326.4, bsz=436.9, num_updates=27800, lr=8.48189e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=72, gb_free=13.8, wall=11070
2023-08-28 23:31:22 | INFO | train_inner | epoch 024:    519 / 1191 loss=1.85, trans_loss=4.663, nll_loss=1.801, w2v_ctc_loss=0.552, task_loss=2.422, contrastive_loss=0.177, total=6651.11, n_correct=4727.29, ppl=3.48, accuracy=71.075, wps=18310.3, ups=1.38, wpb=13302.2, bsz=454.4, num_updates=27900, lr=8.46668e-05, gnorm=0.398, clip=0, loss_scale=64, train_wall=72, gb_free=11.9, wall=11142
2023-08-28 23:32:32 | INFO | train_inner | epoch 024:    619 / 1191 loss=1.837, trans_loss=4.659, nll_loss=1.794, w2v_ctc_loss=0.548, task_loss=2.526, contrastive_loss=0.053, total=6545.91, n_correct=4662.67, ppl=3.47, accuracy=71.23, wps=18479.4, ups=1.41, wpb=13091.8, bsz=419.5, num_updates=28000, lr=8.45154e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=70, gb_free=14.2, wall=11213
2023-08-28 23:32:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 23:33:04 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.931 | trans_loss 5.188 | nll_loss 2.393 | w2v_ctc_loss 1.216 | task_loss 8.523 | contrastive_loss 0.253 | total 6138.43 | n_correct 4168 | ppl 5.25 | accuracy 67.9 | uer 16.621 | wer 18.393 | raw_wer 18.393 | bleu 27.27 | wps 1774.5 | wpb 6138.4 | bsz 201.1 | num_updates 28000 | best_bleu 27.4
2023-08-28 23:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28000 updates
2023-08-28 23:33:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_24_28000.pt
2023-08-28 23:33:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_24_28000.pt
2023-08-28 23:33:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_24_28000.pt (epoch 24 @ 28000 updates, score 27.27) (writing took 6.657060468998679 seconds)
2023-08-28 23:34:24 | INFO | train_inner | epoch 024:    719 / 1191 loss=1.835, trans_loss=4.655, nll_loss=1.792, w2v_ctc_loss=0.541, task_loss=2.231, contrastive_loss=0.11, total=6744.37, n_correct=4815.03, ppl=3.46, accuracy=71.393, wps=12121.7, ups=0.9, wpb=13488.7, bsz=468, num_updates=28100, lr=8.43649e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=71, gb_free=14.3, wall=11324
2023-08-28 23:35:35 | INFO | train_inner | epoch 024:    819 / 1191 loss=1.836, trans_loss=4.655, nll_loss=1.792, w2v_ctc_loss=0.549, task_loss=2.326, contrastive_loss=0.073, total=6726.26, n_correct=4797.07, ppl=3.46, accuracy=71.319, wps=18814, ups=1.4, wpb=13452.5, bsz=450, num_updates=28200, lr=8.42152e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=71, gb_free=14.2, wall=11396
2023-08-28 23:36:48 | INFO | train_inner | epoch 024:    919 / 1191 loss=1.832, trans_loss=4.66, nll_loss=1.798, w2v_ctc_loss=0.538, task_loss=2.297, contrastive_loss=0.07, total=6729.03, n_correct=4798.01, ppl=3.48, accuracy=71.303, wps=18488.7, ups=1.37, wpb=13458.1, bsz=457.1, num_updates=28300, lr=8.40663e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=72, gb_free=14.4, wall=11469
2023-08-28 23:38:01 | INFO | train_inner | epoch 024:   1019 / 1191 loss=1.85, trans_loss=4.67, nll_loss=1.81, w2v_ctc_loss=0.546, task_loss=2.454, contrastive_loss=0.175, total=6600.79, n_correct=4688.18, ppl=3.51, accuracy=71.025, wps=18074.6, ups=1.37, wpb=13201.6, bsz=442.6, num_updates=28400, lr=8.39181e-05, gnorm=0.396, clip=0, loss_scale=64, train_wall=72, gb_free=8.5, wall=11542
2023-08-28 23:39:15 | INFO | train_inner | epoch 024:   1119 / 1191 loss=1.84, trans_loss=4.666, nll_loss=1.805, w2v_ctc_loss=0.548, task_loss=2.462, contrastive_loss=0.063, total=6701.65, n_correct=4762.24, ppl=3.5, accuracy=71.061, wps=18244.6, ups=1.36, wpb=13403.3, bsz=434.4, num_updates=28500, lr=8.37708e-05, gnorm=0.393, clip=0, loss_scale=64, train_wall=73, gb_free=10.5, wall=11615
2023-08-28 23:40:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 23:40:39 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.914 | trans_loss 5.181 | nll_loss 2.388 | w2v_ctc_loss 1.174 | task_loss 8.569 | contrastive_loss 0.255 | total 6138.43 | n_correct 4162.29 | ppl 5.24 | accuracy 67.807 | uer 16.482 | wer 18.133 | raw_wer 18.133 | bleu 27.2 | wps 1741.7 | wpb 6138.4 | bsz 201.1 | num_updates 28572 | best_bleu 27.4
2023-08-28 23:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28572 updates
2023-08-28 23:40:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.2007.pt
2023-08-28 23:40:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.2007.pt
2023-08-28 23:40:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.2007.pt (epoch 24 @ 28572 updates, score 27.2) (writing took 6.205286901000363 seconds)
2023-08-28 23:40:46 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-28 23:40:46 | INFO | train | epoch 024 | loss 1.839 | trans_loss 4.658 | nll_loss 1.795 | w2v_ctc_loss 0.544 | task_loss 2.346 | contrastive_loss 0.112 | total 6703.69 | n_correct 4777.76 | ppl 3.47 | accuracy 71.271 | wps 16903.2 | ups 1.26 | wpb 13407.4 | bsz 452.1 | num_updates 28572 | lr 8.36652e-05 | gnorm 0.39 | clip 0 | loss_scale 64 | train_wall 851 | gb_free 15.2 | wall 11706
2023-08-28 23:40:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 23:40:46 | INFO | fairseq.trainer | begin training epoch 25
2023-08-28 23:40:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 23:41:13 | INFO | train_inner | epoch 025:     28 / 1191 loss=1.838, trans_loss=4.657, nll_loss=1.794, w2v_ctc_loss=0.543, task_loss=2.374, contrastive_loss=0.109, total=6711.33, n_correct=4784.8, ppl=3.47, accuracy=71.294, wps=11310.4, ups=0.84, wpb=13422.7, bsz=448, num_updates=28600, lr=8.36242e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=71, gb_free=11.5, wall=11734
2023-08-28 23:42:25 | INFO | train_inner | epoch 025:    128 / 1191 loss=1.833, trans_loss=4.638, nll_loss=1.768, w2v_ctc_loss=0.536, task_loss=2.475, contrastive_loss=0.16, total=6586.44, n_correct=4723.35, ppl=3.41, accuracy=71.713, wps=18368.5, ups=1.39, wpb=13172.9, bsz=437.6, num_updates=28700, lr=8.34784e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=71, gb_free=13.9, wall=11806
2023-08-28 23:43:38 | INFO | train_inner | epoch 025:    228 / 1191 loss=1.821, trans_loss=4.642, nll_loss=1.775, w2v_ctc_loss=0.529, task_loss=2.243, contrastive_loss=0.069, total=6778.05, n_correct=4860.6, ppl=3.42, accuracy=71.711, wps=18670.5, ups=1.38, wpb=13556.1, bsz=471.2, num_updates=28800, lr=8.33333e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=72, gb_free=12.8, wall=11878
2023-08-28 23:44:50 | INFO | train_inner | epoch 025:    328 / 1191 loss=1.838, trans_loss=4.652, nll_loss=1.787, w2v_ctc_loss=0.553, task_loss=2.47, contrastive_loss=0.088, total=6617.04, n_correct=4721.29, ppl=3.45, accuracy=71.35, wps=18318.9, ups=1.38, wpb=13234.1, bsz=431.9, num_updates=28900, lr=8.3189e-05, gnorm=0.397, clip=0, loss_scale=64, train_wall=72, gb_free=13.6, wall=11951
2023-08-28 23:46:02 | INFO | train_inner | epoch 025:    428 / 1191 loss=1.835, trans_loss=4.654, nll_loss=1.789, w2v_ctc_loss=0.543, task_loss=2.612, contrastive_loss=0.076, total=6575.62, n_correct=4688.79, ppl=3.45, accuracy=71.306, wps=18228.3, ups=1.39, wpb=13151.2, bsz=420.1, num_updates=29000, lr=8.30455e-05, gnorm=0.398, clip=0, loss_scale=64, train_wall=71, gb_free=7, wall=12023
2023-08-28 23:47:14 | INFO | train_inner | epoch 025:    528 / 1191 loss=1.826, trans_loss=4.646, nll_loss=1.78, w2v_ctc_loss=0.535, task_loss=2.148, contrastive_loss=0.09, total=6838.68, n_correct=4897.63, ppl=3.43, accuracy=71.617, wps=18973.5, ups=1.39, wpb=13677.4, bsz=483.1, num_updates=29100, lr=8.29027e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=71, gb_free=14.3, wall=12095
2023-08-28 23:48:26 | INFO | train_inner | epoch 025:    628 / 1191 loss=1.826, trans_loss=4.647, nll_loss=1.781, w2v_ctc_loss=0.532, task_loss=2.289, contrastive_loss=0.095, total=6770.08, n_correct=4852.05, ppl=3.44, accuracy=71.669, wps=18948, ups=1.4, wpb=13540.2, bsz=453.3, num_updates=29200, lr=8.27606e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=12166
2023-08-28 23:49:38 | INFO | train_inner | epoch 025:    728 / 1191 loss=1.845, trans_loss=4.657, nll_loss=1.794, w2v_ctc_loss=0.545, task_loss=2.382, contrastive_loss=0.186, total=6681.7, n_correct=4764, ppl=3.47, accuracy=71.299, wps=18461.3, ups=1.38, wpb=13363.4, bsz=450.3, num_updates=29300, lr=8.26192e-05, gnorm=0.397, clip=0, loss_scale=64, train_wall=72, gb_free=12.5, wall=12239
2023-08-28 23:50:50 | INFO | train_inner | epoch 025:    828 / 1191 loss=1.834, trans_loss=4.655, nll_loss=1.792, w2v_ctc_loss=0.538, task_loss=2.307, contrastive_loss=0.107, total=6725.05, n_correct=4799.94, ppl=3.46, accuracy=71.374, wps=18639.8, ups=1.39, wpb=13450.1, bsz=454.5, num_updates=29400, lr=8.24786e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=71, gb_free=11.1, wall=12311
2023-08-28 23:51:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-28 23:52:04 | INFO | train_inner | epoch 025:    929 / 1191 loss=1.826, trans_loss=4.65, nll_loss=1.785, w2v_ctc_loss=0.536, task_loss=2.221, contrastive_loss=0.073, total=6772.85, n_correct=4841.95, ppl=3.45, accuracy=71.491, wps=18438.5, ups=1.36, wpb=13545.7, bsz=469, num_updates=29500, lr=8.23387e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=73, gb_free=12.6, wall=12384
2023-08-28 23:53:15 | INFO | train_inner | epoch 025:   1029 / 1191 loss=1.838, trans_loss=4.664, nll_loss=1.804, w2v_ctc_loss=0.539, task_loss=2.321, contrastive_loss=0.115, total=6654.71, n_correct=4733.23, ppl=3.49, accuracy=71.126, wps=18739.5, ups=1.41, wpb=13309.4, bsz=451.1, num_updates=29600, lr=8.21995e-05, gnorm=0.395, clip=0, loss_scale=64, train_wall=70, gb_free=12.7, wall=12455
2023-08-28 23:54:26 | INFO | train_inner | epoch 025:   1129 / 1191 loss=1.836, trans_loss=4.657, nll_loss=1.794, w2v_ctc_loss=0.546, task_loss=2.422, contrastive_loss=0.102, total=6685.06, n_correct=4771.46, ppl=3.47, accuracy=71.375, wps=18625.6, ups=1.39, wpb=13370.1, bsz=444.3, num_updates=29700, lr=8.2061e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=71, gb_free=12.1, wall=12527
2023-08-28 23:54:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-28 23:55:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 23:55:43 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.917 | trans_loss 5.177 | nll_loss 2.382 | w2v_ctc_loss 1.196 | task_loss 8.581 | contrastive_loss 0.25 | total 6138.43 | n_correct 4179.14 | ppl 5.21 | accuracy 68.082 | uer 16.391 | wer 18.044 | raw_wer 18.044 | bleu 27.47 | wps 1783.8 | wpb 6138.4 | bsz 201.1 | num_updates 29761 | best_bleu 27.47
2023-08-28 23:55:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 29761 updates
2023-08-28 23:55:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-28 23:55:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-28 23:55:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 25 @ 29761 updates, score 27.47) (writing took 12.289105543000915 seconds)
2023-08-28 23:55:56 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-28 23:55:56 | INFO | train | epoch 025 | loss 1.833 | trans_loss 4.652 | nll_loss 1.787 | w2v_ctc_loss 0.54 | task_loss 2.348 | contrastive_loss 0.106 | total 6701.44 | n_correct 4787.9 | ppl 3.45 | accuracy 71.446 | wps 17499.7 | ups 1.31 | wpb 13402.9 | bsz 451.4 | num_updates 29761 | lr 8.19769e-05 | gnorm 0.392 | clip 0 | loss_scale 32 | train_wall 850 | gb_free 11.7 | wall 12617
2023-08-28 23:55:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-28 23:55:56 | INFO | fairseq.trainer | begin training epoch 26
2023-08-28 23:55:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-28 23:56:31 | INFO | train_inner | epoch 026:     39 / 1191 loss=1.833, trans_loss=4.653, nll_loss=1.79, w2v_ctc_loss=0.538, task_loss=2.263, contrastive_loss=0.106, total=6803.66, n_correct=4859.87, ppl=3.46, accuracy=71.43, wps=10895.7, ups=0.8, wpb=13607.3, bsz=459.8, num_updates=29800, lr=8.19232e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=72, gb_free=12.5, wall=12652
2023-08-28 23:57:44 | INFO | train_inner | epoch 026:    139 / 1191 loss=1.819, trans_loss=4.633, nll_loss=1.762, w2v_ctc_loss=0.529, task_loss=2.347, contrastive_loss=0.09, total=6718.44, n_correct=4829.71, ppl=3.39, accuracy=71.887, wps=18514.5, ups=1.38, wpb=13436.9, bsz=456.6, num_updates=29900, lr=8.17861e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=12725
2023-08-28 23:58:55 | INFO | train_inner | epoch 026:    239 / 1191 loss=1.822, trans_loss=4.631, nll_loss=1.76, w2v_ctc_loss=0.531, task_loss=2.331, contrastive_loss=0.119, total=6678.33, n_correct=4800.98, ppl=3.39, accuracy=71.889, wps=18726.3, ups=1.4, wpb=13356.7, bsz=451.1, num_updates=30000, lr=8.16497e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=71, gb_free=12, wall=12796
2023-08-28 23:58:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-28 23:59:28 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.916 | trans_loss 5.179 | nll_loss 2.384 | w2v_ctc_loss 1.188 | task_loss 8.503 | contrastive_loss 0.249 | total 6138.43 | n_correct 4168.29 | ppl 5.22 | accuracy 67.905 | uer 16.476 | wer 18.349 | raw_wer 18.349 | bleu 27.36 | wps 1691 | wpb 6138.4 | bsz 201.1 | num_updates 30000 | best_bleu 27.47
2023-08-28 23:59:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30000 updates
2023-08-28 23:59:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_26_30000.pt
2023-08-28 23:59:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_26_30000.pt
2023-08-28 23:59:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_26_30000.pt (epoch 26 @ 30000 updates, score 27.36) (writing took 6.870490762001282 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-29 00:00:48 | INFO | train_inner | epoch 026:    339 / 1191 loss=1.824, trans_loss=4.636, nll_loss=1.769, w2v_ctc_loss=0.527, task_loss=2.045, contrastive_loss=0.154, total=6888.24, n_correct=4950.18, ppl=3.41, accuracy=71.864, wps=12233.1, ups=0.89, wpb=13776.5, bsz=498.1, num_updates=30100, lr=8.15139e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=72, gb_free=12.9, wall=12909
2023-08-29 00:02:00 | INFO | train_inner | epoch 026:    439 / 1191 loss=1.831, trans_loss=4.643, nll_loss=1.775, w2v_ctc_loss=0.538, task_loss=2.523, contrastive_loss=0.114, total=6569.92, n_correct=4709.7, ppl=3.42, accuracy=71.686, wps=18319.5, ups=1.39, wpb=13139.8, bsz=423, num_updates=30200, lr=8.13788e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=71, gb_free=10.9, wall=12980
2023-08-29 00:03:12 | INFO | train_inner | epoch 026:    539 / 1191 loss=1.829, trans_loss=4.643, nll_loss=1.776, w2v_ctc_loss=0.533, task_loss=2.367, contrastive_loss=0.127, total=6684.51, n_correct=4788.58, ppl=3.42, accuracy=71.637, wps=18406.9, ups=1.38, wpb=13369, bsz=453.1, num_updates=30300, lr=8.12444e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=14.8, wall=13053
2023-08-29 00:04:24 | INFO | train_inner | epoch 026:    639 / 1191 loss=1.831, trans_loss=4.647, nll_loss=1.781, w2v_ctc_loss=0.533, task_loss=2.541, contrastive_loss=0.119, total=6606.67, n_correct=4726.52, ppl=3.44, accuracy=71.542, wps=18438.9, ups=1.4, wpb=13213.3, bsz=426.7, num_updates=30400, lr=8.11107e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=71, gb_free=12.3, wall=13125
2023-08-29 00:05:36 | INFO | train_inner | epoch 026:    739 / 1191 loss=1.827, trans_loss=4.646, nll_loss=1.78, w2v_ctc_loss=0.534, task_loss=2.362, contrastive_loss=0.073, total=6778.79, n_correct=4852.54, ppl=3.43, accuracy=71.584, wps=18701.5, ups=1.38, wpb=13557.6, bsz=446.5, num_updates=30500, lr=8.09776e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=13197
2023-08-29 00:06:48 | INFO | train_inner | epoch 026:    839 / 1191 loss=1.829, trans_loss=4.645, nll_loss=1.778, w2v_ctc_loss=0.532, task_loss=2.307, contrastive_loss=0.126, total=6679.03, n_correct=4786.8, ppl=3.43, accuracy=71.669, wps=18619.1, ups=1.39, wpb=13358.1, bsz=455.9, num_updates=30600, lr=8.08452e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=71, gb_free=13.4, wall=13269
2023-08-29 00:08:00 | INFO | train_inner | epoch 026:    939 / 1191 loss=1.84, trans_loss=4.655, nll_loss=1.791, w2v_ctc_loss=0.543, task_loss=2.383, contrastive_loss=0.142, total=6677.41, n_correct=4761.37, ppl=3.46, accuracy=71.306, wps=18570.2, ups=1.39, wpb=13354.8, bsz=447.2, num_updates=30700, lr=8.07134e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=71, gb_free=14, wall=13341
2023-08-29 00:09:12 | INFO | train_inner | epoch 026:   1039 / 1191 loss=1.831, trans_loss=4.653, nll_loss=1.79, w2v_ctc_loss=0.542, task_loss=2.371, contrastive_loss=0.072, total=6701.65, n_correct=4782.92, ppl=3.46, accuracy=71.369, wps=18569.2, ups=1.39, wpb=13403.3, bsz=447.7, num_updates=30800, lr=8.05823e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=13413
2023-08-29 00:10:25 | INFO | train_inner | epoch 026:   1139 / 1191 loss=1.833, trans_loss=4.658, nll_loss=1.796, w2v_ctc_loss=0.537, task_loss=2.243, contrastive_loss=0.102, total=6787.9, n_correct=4847.32, ppl=3.47, accuracy=71.411, wps=18638.7, ups=1.37, wpb=13575.8, bsz=474.7, num_updates=30900, lr=8.04518e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=13486
2023-08-29 00:11:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-29 00:11:36 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.923 | trans_loss 5.184 | nll_loss 2.392 | w2v_ctc_loss 1.2 | task_loss 8.514 | contrastive_loss 0.256 | total 6138.43 | n_correct 4167.43 | ppl 5.25 | accuracy 67.891 | uer 16.487 | wer 18.271 | raw_wer 18.271 | bleu 27.51 | wps 1680.9 | wpb 6138.4 | bsz 201.1 | num_updates 30952 | best_bleu 27.51
2023-08-29 00:11:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30952 updates
2023-08-29 00:11:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-29 00:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-29 00:11:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 26 @ 30952 updates, score 27.51) (writing took 11.286410987999261 seconds)
2023-08-29 00:11:48 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-29 00:11:48 | INFO | train | epoch 026 | loss 1.829 | trans_loss 4.645 | nll_loss 1.779 | w2v_ctc_loss 0.535 | task_loss 2.345 | contrastive_loss 0.11 | total 6703.69 | n_correct 4800.88 | ppl 3.43 | accuracy 71.615 | wps 16778.1 | ups 1.25 | wpb 13407.4 | bsz 452.1 | num_updates 30952 | lr 8.03842e-05 | gnorm 0.392 | clip 0 | loss_scale 32 | train_wall 851 | gb_free 12.7 | wall 13569
2023-08-29 00:11:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 00:11:48 | INFO | fairseq.trainer | begin training epoch 27
2023-08-29 00:11:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 00:12:30 | INFO | train_inner | epoch 027:     48 / 1191 loss=1.826, trans_loss=4.642, nll_loss=1.775, w2v_ctc_loss=0.54, task_loss=2.406, contrastive_loss=0.068, total=6621.11, n_correct=4748.47, ppl=3.42, accuracy=71.717, wps=10575.7, ups=0.8, wpb=13242.2, bsz=439, num_updates=31000, lr=8.03219e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=72, gb_free=15.5, wall=13611
2023-08-29 00:13:43 | INFO | train_inner | epoch 027:    148 / 1191 loss=1.825, trans_loss=4.629, nll_loss=1.757, w2v_ctc_loss=0.529, task_loss=2.296, contrastive_loss=0.159, total=6726.66, n_correct=4837.83, ppl=3.38, accuracy=71.92, wps=18528.8, ups=1.38, wpb=13453.3, bsz=464.7, num_updates=31100, lr=8.01927e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=14.1, wall=13684
2023-08-29 00:14:55 | INFO | train_inner | epoch 027:    248 / 1191 loss=1.816, trans_loss=4.627, nll_loss=1.757, w2v_ctc_loss=0.522, task_loss=2.144, contrastive_loss=0.127, total=6820.93, n_correct=4913.01, ppl=3.38, accuracy=72.028, wps=19044.1, ups=1.4, wpb=13641.9, bsz=482.9, num_updates=31200, lr=8.00641e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=71, gb_free=14.6, wall=13755
2023-08-29 00:16:07 | INFO | train_inner | epoch 027:    348 / 1191 loss=1.811, trans_loss=4.623, nll_loss=1.751, w2v_ctc_loss=0.518, task_loss=2.233, contrastive_loss=0.096, total=6731.11, n_correct=4856.69, ppl=3.37, accuracy=72.153, wps=18647.5, ups=1.39, wpb=13462.2, bsz=466.9, num_updates=31300, lr=7.99361e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=72, gb_free=12.8, wall=13827
2023-08-29 00:17:19 | INFO | train_inner | epoch 027:    448 / 1191 loss=1.833, trans_loss=4.649, nll_loss=1.784, w2v_ctc_loss=0.539, task_loss=2.492, contrastive_loss=0.108, total=6617.99, n_correct=4731.86, ppl=3.44, accuracy=71.5, wps=18281.8, ups=1.38, wpb=13236, bsz=437.6, num_updates=31400, lr=7.98087e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=72, gb_free=6.4, wall=13900
2023-08-29 00:18:31 | INFO | train_inner | epoch 027:    548 / 1191 loss=1.816, trans_loss=4.632, nll_loss=1.763, w2v_ctc_loss=0.526, task_loss=2.215, contrastive_loss=0.084, total=6786.76, n_correct=4881.19, ppl=3.39, accuracy=71.922, wps=18850.1, ups=1.39, wpb=13573.5, bsz=467.9, num_updates=31500, lr=7.96819e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=13972
2023-08-29 00:19:43 | INFO | train_inner | epoch 027:    648 / 1191 loss=1.83, trans_loss=4.642, nll_loss=1.774, w2v_ctc_loss=0.53, task_loss=2.399, contrastive_loss=0.157, total=6681.62, n_correct=4790.47, ppl=3.42, accuracy=71.696, wps=18657.7, ups=1.4, wpb=13363.2, bsz=444.4, num_updates=31600, lr=7.95557e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=71, gb_free=12, wall=14043
2023-08-29 00:20:55 | INFO | train_inner | epoch 027:    748 / 1191 loss=1.824, trans_loss=4.641, nll_loss=1.774, w2v_ctc_loss=0.532, task_loss=2.445, contrastive_loss=0.084, total=6672.74, n_correct=4784.93, ppl=3.42, accuracy=71.709, wps=18570.4, ups=1.39, wpb=13345.5, bsz=442.4, num_updates=31700, lr=7.94301e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=71, gb_free=12.9, wall=14115
2023-08-29 00:22:07 | INFO | train_inner | epoch 027:    848 / 1191 loss=1.823, trans_loss=4.641, nll_loss=1.774, w2v_ctc_loss=0.531, task_loss=2.475, contrastive_loss=0.076, total=6644.45, n_correct=4764.73, ppl=3.42, accuracy=71.71, wps=18430.2, ups=1.39, wpb=13288.9, bsz=439.2, num_updates=31800, lr=7.93052e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=71, gb_free=13.2, wall=14187
2023-08-29 00:22:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-29 00:23:20 | INFO | train_inner | epoch 027:    949 / 1191 loss=1.827, trans_loss=4.651, nll_loss=1.786, w2v_ctc_loss=0.534, task_loss=2.574, contrastive_loss=0.051, total=6624.81, n_correct=4737.6, ppl=3.45, accuracy=71.513, wps=18140.9, ups=1.37, wpb=13249.6, bsz=418.1, num_updates=31900, lr=7.91808e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=72, gb_free=12.8, wall=14260
2023-08-29 00:24:32 | INFO | train_inner | epoch 027:   1049 / 1191 loss=1.828, trans_loss=4.646, nll_loss=1.782, w2v_ctc_loss=0.528, task_loss=2.357, contrastive_loss=0.145, total=6652.45, n_correct=4765.63, ppl=3.44, accuracy=71.637, wps=18479.1, ups=1.39, wpb=13304.9, bsz=450.6, num_updates=32000, lr=7.90569e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=14332
2023-08-29 00:24:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 00:25:05 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.931 | trans_loss 5.18 | nll_loss 2.385 | w2v_ctc_loss 1.239 | task_loss 8.523 | contrastive_loss 0.249 | total 6138.43 | n_correct 4174.43 | ppl 5.22 | accuracy 68.005 | uer 16.861 | wer 18.788 | raw_wer 18.788 | bleu 27.41 | wps 1676.6 | wpb 6138.4 | bsz 201.1 | num_updates 32000 | best_bleu 27.51
2023-08-29 00:25:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 32000 updates
2023-08-29 00:25:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_27_32000.pt
2023-08-29 00:25:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_27_32000.pt
2023-08-29 00:25:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_27_32000.pt (epoch 27 @ 32000 updates, score 27.41) (writing took 6.137734275002003 seconds)
2023-08-29 00:26:24 | INFO | train_inner | epoch 027:   1149 / 1191 loss=1.826, trans_loss=4.647, nll_loss=1.781, w2v_ctc_loss=0.528, task_loss=2.296, contrastive_loss=0.114, total=6753.53, n_correct=4837.53, ppl=3.44, accuracy=71.63, wps=12073.1, ups=0.89, wpb=13507.1, bsz=452.5, num_updates=32100, lr=7.89337e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=71, gb_free=10.8, wall=14444
2023-08-29 00:26:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 00:27:27 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.932 | trans_loss 5.18 | nll_loss 2.383 | w2v_ctc_loss 1.245 | task_loss 8.613 | contrastive_loss 0.243 | total 6138.43 | n_correct 4177 | ppl 5.22 | accuracy 68.047 | uer 16.49 | wer 18.26 | raw_wer 18.26 | bleu 27.51 | wps 1677 | wpb 6138.4 | bsz 201.1 | num_updates 32142 | best_bleu 27.51
2023-08-29 00:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 32142 updates
2023-08-29 00:27:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-29 00:27:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-29 00:27:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 27 @ 32142 updates, score 27.51) (writing took 10.89887710399853 seconds)
2023-08-29 00:27:38 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-29 00:27:38 | INFO | train | epoch 027 | loss 1.823 | trans_loss 4.638 | nll_loss 1.77 | w2v_ctc_loss 0.529 | task_loss 2.346 | contrastive_loss 0.106 | total 6702.34 | n_correct 4811.34 | ppl 3.41 | accuracy 71.786 | wps 16788.6 | ups 1.25 | wpb 13404.7 | bsz 451.6 | num_updates 32142 | lr 7.88821e-05 | gnorm 0.391 | clip 0 | loss_scale 32 | train_wall 851 | gb_free 13.4 | wall 14519
2023-08-29 00:27:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 00:27:38 | INFO | fairseq.trainer | begin training epoch 28
2023-08-29 00:27:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 00:28:27 | INFO | train_inner | epoch 028:     58 / 1191 loss=1.812, trans_loss=4.622, nll_loss=1.75, w2v_ctc_loss=0.521, task_loss=2.288, contrastive_loss=0.102, total=6702.18, n_correct=4827.47, ppl=3.36, accuracy=72.028, wps=10850.3, ups=0.81, wpb=13404.4, bsz=456.4, num_updates=32200, lr=7.8811e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=71, gb_free=14.4, wall=14568
2023-08-29 00:29:39 | INFO | train_inner | epoch 028:    158 / 1191 loss=1.816, trans_loss=4.626, nll_loss=1.754, w2v_ctc_loss=0.534, task_loss=2.453, contrastive_loss=0.055, total=6676.02, n_correct=4808.72, ppl=3.37, accuracy=72.03, wps=18556, ups=1.39, wpb=13352, bsz=432.6, num_updates=32300, lr=7.86889e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=14640
2023-08-29 00:30:51 | INFO | train_inner | epoch 028:    258 / 1191 loss=1.819, trans_loss=4.632, nll_loss=1.761, w2v_ctc_loss=0.529, task_loss=2.361, contrastive_loss=0.098, total=6680.3, n_correct=4803.69, ppl=3.39, accuracy=71.908, wps=18480.7, ups=1.38, wpb=13360.6, bsz=450.4, num_updates=32400, lr=7.85674e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=71, gb_free=10.4, wall=14712
2023-08-29 00:32:03 | INFO | train_inner | epoch 028:    358 / 1191 loss=1.811, trans_loss=4.626, nll_loss=1.755, w2v_ctc_loss=0.522, task_loss=2.307, contrastive_loss=0.069, total=6733.45, n_correct=4849.17, ppl=3.37, accuracy=72.016, wps=18711.8, ups=1.39, wpb=13466.9, bsz=460.2, num_updates=32500, lr=7.84465e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=71, gb_free=14.2, wall=14784
2023-08-29 00:33:16 | INFO | train_inner | epoch 028:    458 / 1191 loss=1.825, trans_loss=4.631, nll_loss=1.761, w2v_ctc_loss=0.523, task_loss=2.229, contrastive_loss=0.188, total=6786.13, n_correct=4888.48, ppl=3.39, accuracy=72.036, wps=18635.3, ups=1.37, wpb=13572.3, bsz=473.9, num_updates=32600, lr=7.8326e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=14857
2023-08-29 00:34:27 | INFO | train_inner | epoch 028:    558 / 1191 loss=1.808, trans_loss=4.627, nll_loss=1.756, w2v_ctc_loss=0.519, task_loss=2.313, contrastive_loss=0.056, total=6699.39, n_correct=4830.92, ppl=3.38, accuracy=72.11, wps=18864.5, ups=1.41, wpb=13398.8, bsz=453, num_updates=32700, lr=7.82062e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=70, gb_free=14, wall=14928
2023-08-29 00:35:39 | INFO | train_inner | epoch 028:    658 / 1191 loss=1.817, trans_loss=4.629, nll_loss=1.759, w2v_ctc_loss=0.524, task_loss=2.289, contrastive_loss=0.123, total=6757.2, n_correct=4866.54, ppl=3.38, accuracy=72.02, wps=18851.2, ups=1.39, wpb=13514.4, bsz=457.5, num_updates=32800, lr=7.80869e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=15000
2023-08-29 00:36:51 | INFO | train_inner | epoch 028:    758 / 1191 loss=1.819, trans_loss=4.634, nll_loss=1.766, w2v_ctc_loss=0.528, task_loss=2.35, contrastive_loss=0.086, total=6689.37, n_correct=4808.81, ppl=3.4, accuracy=71.887, wps=18483.7, ups=1.38, wpb=13378.7, bsz=453.8, num_updates=32900, lr=7.79681e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=15072
2023-08-29 00:38:03 | INFO | train_inner | epoch 028:    858 / 1191 loss=1.815, trans_loss=4.632, nll_loss=1.762, w2v_ctc_loss=0.523, task_loss=2.34, contrastive_loss=0.09, total=6644.99, n_correct=4785.98, ppl=3.39, accuracy=72.024, wps=18515, ups=1.39, wpb=13290, bsz=451.4, num_updates=33000, lr=7.78499e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=71, gb_free=12.6, wall=15144
2023-08-29 00:39:15 | INFO | train_inner | epoch 028:    958 / 1191 loss=1.829, trans_loss=4.643, nll_loss=1.777, w2v_ctc_loss=0.535, task_loss=2.449, contrastive_loss=0.122, total=6647.77, n_correct=4761.98, ppl=3.43, accuracy=71.633, wps=18520.9, ups=1.39, wpb=13295.5, bsz=438, num_updates=33100, lr=7.77322e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=71, gb_free=14.7, wall=15216
2023-08-29 00:40:27 | INFO | train_inner | epoch 028:   1058 / 1191 loss=1.829, trans_loss=4.646, nll_loss=1.78, w2v_ctc_loss=0.518, task_loss=2.439, contrastive_loss=0.183, total=6683.12, n_correct=4791.84, ppl=3.43, accuracy=71.701, wps=18486.1, ups=1.38, wpb=13366.2, bsz=439.6, num_updates=33200, lr=7.76151e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=15288
2023-08-29 00:41:40 | INFO | train_inner | epoch 028:   1158 / 1191 loss=1.82, trans_loss=4.643, nll_loss=1.777, w2v_ctc_loss=0.523, task_loss=2.415, contrastive_loss=0.092, total=6679.78, n_correct=4791.15, ppl=3.43, accuracy=71.726, wps=18398.1, ups=1.38, wpb=13359.6, bsz=445.2, num_updates=33300, lr=7.74984e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=15361
2023-08-29 00:42:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 00:42:37 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.918 | trans_loss 5.182 | nll_loss 2.387 | w2v_ctc_loss 1.189 | task_loss 8.54 | contrastive_loss 0.249 | total 6138.43 | n_correct 4177.14 | ppl 5.23 | accuracy 68.049 | uer 16.442 | wer 18.23 | raw_wer 18.23 | bleu 27.36 | wps 1669.2 | wpb 6138.4 | bsz 201.1 | num_updates 33333 | best_bleu 27.51
2023-08-29 00:42:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 33333 updates
2023-08-29 00:42:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.3604.pt
2023-08-29 00:42:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.3604.pt
2023-08-29 00:42:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.3604.pt (epoch 28 @ 33333 updates, score 27.36) (writing took 6.19126937299734 seconds)
2023-08-29 00:42:43 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-29 00:42:43 | INFO | train | epoch 028 | loss 1.818 | trans_loss 4.632 | nll_loss 1.763 | w2v_ctc_loss 0.525 | task_loss 2.342 | contrastive_loss 0.107 | total 6703.69 | n_correct 4822.67 | ppl 3.39 | accuracy 71.941 | wps 17639 | ups 1.32 | wpb 13407.4 | bsz 452.1 | num_updates 33333 | lr 7.74601e-05 | gnorm 0.392 | clip 0 | loss_scale 32 | train_wall 849 | gb_free 13.4 | wall 15424
2023-08-29 00:42:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 00:42:44 | INFO | fairseq.trainer | begin training epoch 29
2023-08-29 00:42:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 00:43:40 | INFO | train_inner | epoch 029:     67 / 1191 loss=1.806, trans_loss=4.615, nll_loss=1.741, w2v_ctc_loss=0.513, task_loss=2.141, contrastive_loss=0.101, total=6806.79, n_correct=4923.69, ppl=3.34, accuracy=72.335, wps=11347.6, ups=0.83, wpb=13613.6, bsz=476.8, num_updates=33400, lr=7.73823e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=15481
2023-08-29 00:44:52 | INFO | train_inner | epoch 029:    167 / 1191 loss=1.805, trans_loss=4.615, nll_loss=1.739, w2v_ctc_loss=0.516, task_loss=2.396, contrastive_loss=0.06, total=6676.33, n_correct=4829.47, ppl=3.34, accuracy=72.337, wps=18573.3, ups=1.39, wpb=13352.7, bsz=438, num_updates=33500, lr=7.72667e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=71, gb_free=12, wall=15552
2023-08-29 00:46:04 | INFO | train_inner | epoch 029:    267 / 1191 loss=1.819, trans_loss=4.624, nll_loss=1.752, w2v_ctc_loss=0.509, task_loss=2.347, contrastive_loss=0.196, total=6670.27, n_correct=4813.63, ppl=3.37, accuracy=72.165, wps=18434.4, ups=1.38, wpb=13340.5, bsz=453.4, num_updates=33600, lr=7.71517e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=15625
2023-08-29 00:47:17 | INFO | train_inner | epoch 029:    367 / 1191 loss=1.81, trans_loss=4.625, nll_loss=1.753, w2v_ctc_loss=0.523, task_loss=2.348, contrastive_loss=0.061, total=6747.17, n_correct=4863.75, ppl=3.37, accuracy=72.086, wps=18539.1, ups=1.37, wpb=13494.3, bsz=452, num_updates=33700, lr=7.70371e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=15698
2023-08-29 00:48:29 | INFO | train_inner | epoch 029:    467 / 1191 loss=1.81, trans_loss=4.623, nll_loss=1.751, w2v_ctc_loss=0.513, task_loss=2.267, contrastive_loss=0.111, total=6772.8, n_correct=4891.48, ppl=3.37, accuracy=72.222, wps=18736.2, ups=1.38, wpb=13545.6, bsz=464.8, num_updates=33800, lr=7.69231e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=15770
2023-08-29 00:49:42 | INFO | train_inner | epoch 029:    567 / 1191 loss=1.823, trans_loss=4.634, nll_loss=1.765, w2v_ctc_loss=0.536, task_loss=2.584, contrastive_loss=0.095, total=6577.57, n_correct=4724.32, ppl=3.4, accuracy=71.825, wps=18051.7, ups=1.37, wpb=13155.1, bsz=421.4, num_updates=33900, lr=7.68095e-05, gnorm=0.4, clip=0, loss_scale=64, train_wall=72, gb_free=14.5, wall=15843
2023-08-29 00:50:53 | INFO | train_inner | epoch 029:    667 / 1191 loss=1.807, trans_loss=4.618, nll_loss=1.744, w2v_ctc_loss=0.515, task_loss=2.208, contrastive_loss=0.09, total=6760.39, n_correct=4885.81, ppl=3.35, accuracy=72.271, wps=18990.5, ups=1.4, wpb=13520.8, bsz=469.3, num_updates=34000, lr=7.66965e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=71, gb_free=12.1, wall=15914
2023-08-29 00:50:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 00:51:26 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.915 | trans_loss 5.181 | nll_loss 2.385 | w2v_ctc_loss 1.185 | task_loss 8.535 | contrastive_loss 0.244 | total 6138.43 | n_correct 4179.71 | ppl 5.22 | accuracy 68.091 | uer 16.434 | wer 18.26 | raw_wer 18.26 | bleu 27.16 | wps 1675.5 | wpb 6138.4 | bsz 201.1 | num_updates 34000 | best_bleu 27.51
2023-08-29 00:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34000 updates
2023-08-29 00:51:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_29_34000.pt
2023-08-29 00:51:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_29_34000.pt
2023-08-29 00:51:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_29_34000.pt (epoch 29 @ 34000 updates, score 27.16) (writing took 6.406797530002223 seconds)
2023-08-29 00:52:44 | INFO | train_inner | epoch 029:    767 / 1191 loss=1.809, trans_loss=4.625, nll_loss=1.755, w2v_ctc_loss=0.516, task_loss=2.362, contrastive_loss=0.088, total=6664.13, n_correct=4808.86, ppl=3.37, accuracy=72.16, wps=11991.7, ups=0.9, wpb=13328.3, bsz=450.3, num_updates=34100, lr=7.6584e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=71, gb_free=7.6, wall=16025
2023-08-29 00:53:56 | INFO | train_inner | epoch 029:    867 / 1191 loss=1.815, trans_loss=4.634, nll_loss=1.766, w2v_ctc_loss=0.524, task_loss=2.45, contrastive_loss=0.063, total=6659.43, n_correct=4791.52, ppl=3.4, accuracy=71.951, wps=18548.1, ups=1.39, wpb=13318.9, bsz=435.3, num_updates=34200, lr=7.64719e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=71, gb_free=11, wall=16097
2023-08-29 00:54:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-29 00:55:09 | INFO | train_inner | epoch 029:    968 / 1191 loss=1.82, trans_loss=4.634, nll_loss=1.765, w2v_ctc_loss=0.528, task_loss=2.385, contrastive_loss=0.109, total=6694.25, n_correct=4814.29, ppl=3.4, accuracy=71.917, wps=18301.9, ups=1.37, wpb=13388.5, bsz=450.1, num_updates=34300, lr=7.63604e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=13.2, wall=16170
2023-08-29 00:56:21 | INFO | train_inner | epoch 029:   1068 / 1191 loss=1.822, trans_loss=4.636, nll_loss=1.769, w2v_ctc_loss=0.526, task_loss=2.32, contrastive_loss=0.132, total=6722.03, n_correct=4836.11, ppl=3.41, accuracy=71.944, wps=18702.2, ups=1.39, wpb=13444.1, bsz=457.9, num_updates=34400, lr=7.62493e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=71, gb_free=14.4, wall=16242
2023-08-29 00:57:34 | INFO | train_inner | epoch 029:   1168 / 1191 loss=1.811, trans_loss=4.631, nll_loss=1.761, w2v_ctc_loss=0.513, task_loss=2.267, contrastive_loss=0.102, total=6758.08, n_correct=4871.5, ppl=3.39, accuracy=72.084, wps=18707.9, ups=1.38, wpb=13516.2, bsz=463.1, num_updates=34500, lr=7.61387e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=71, gb_free=10.1, wall=16314
2023-08-29 00:57:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 00:58:23 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.924 | trans_loss 5.184 | nll_loss 2.389 | w2v_ctc_loss 1.21 | task_loss 8.546 | contrastive_loss 0.244 | total 6138.43 | n_correct 4163 | ppl 5.24 | accuracy 67.819 | uer 16.543 | wer 18.17 | raw_wer 18.17 | bleu 27.05 | wps 1721.1 | wpb 6138.4 | bsz 201.1 | num_updates 34523 | best_bleu 27.51
2023-08-29 00:58:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34523 updates
2023-08-29 00:58:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 00:58:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 00:58:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 29 @ 34523 updates, score 27.05) (writing took 5.936434470000677 seconds)
2023-08-29 00:58:29 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-29 00:58:29 | INFO | train | epoch 029 | loss 1.813 | trans_loss 4.626 | nll_loss 1.755 | w2v_ctc_loss 0.519 | task_loss 2.349 | contrastive_loss 0.1 | total 6701.62 | n_correct 4832.17 | ppl 3.38 | accuracy 72.105 | wps 16873.5 | ups 1.26 | wpb 13403.2 | bsz 451.3 | num_updates 34523 | lr 7.61133e-05 | gnorm 0.392 | clip 0 | loss_scale 32 | train_wall 850 | gb_free 13.7 | wall 16369
2023-08-29 00:58:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 00:58:29 | INFO | fairseq.trainer | begin training epoch 30
2023-08-29 00:58:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 00:59:31 | INFO | train_inner | epoch 030:     77 / 1191 loss=1.799, trans_loss=4.61, nll_loss=1.734, w2v_ctc_loss=0.508, task_loss=2.109, contrastive_loss=0.098, total=6834.34, n_correct=4959.13, ppl=3.33, accuracy=72.562, wps=11653.1, ups=0.85, wpb=13668.7, bsz=482.5, num_updates=34600, lr=7.60286e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=71, gb_free=14.1, wall=16432
2023-08-29 01:00:42 | INFO | train_inner | epoch 030:    177 / 1191 loss=1.804, trans_loss=4.61, nll_loss=1.733, w2v_ctc_loss=0.513, task_loss=2.337, contrastive_loss=0.1, total=6675.83, n_correct=4834.42, ppl=3.32, accuracy=72.417, wps=18728.5, ups=1.4, wpb=13351.7, bsz=447.1, num_updates=34700, lr=7.5919e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=71, gb_free=13.7, wall=16503
2023-08-29 01:01:54 | INFO | train_inner | epoch 030:    277 / 1191 loss=1.803, trans_loss=4.608, nll_loss=1.731, w2v_ctc_loss=0.51, task_loss=2.263, contrastive_loss=0.103, total=6761.75, n_correct=4903.57, ppl=3.32, accuracy=72.519, wps=18748.2, ups=1.39, wpb=13523.5, bsz=461.1, num_updates=34800, lr=7.58098e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=71, gb_free=13.9, wall=16575
2023-08-29 01:03:07 | INFO | train_inner | epoch 030:    377 / 1191 loss=1.801, trans_loss=4.611, nll_loss=1.736, w2v_ctc_loss=0.508, task_loss=2.121, contrastive_loss=0.102, total=6854.16, n_correct=4966.4, ppl=3.33, accuracy=72.458, wps=18812.5, ups=1.37, wpb=13708.3, bsz=487.8, num_updates=34900, lr=7.57011e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=16648
2023-08-29 01:04:19 | INFO | train_inner | epoch 030:    477 / 1191 loss=1.809, trans_loss=4.619, nll_loss=1.745, w2v_ctc_loss=0.518, task_loss=2.444, contrastive_loss=0.094, total=6643.16, n_correct=4797.14, ppl=3.35, accuracy=72.212, wps=18513.6, ups=1.39, wpb=13286.3, bsz=443.7, num_updates=35000, lr=7.55929e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=71, gb_free=14.5, wall=16720
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-29 01:05:31 | INFO | train_inner | epoch 030:    577 / 1191 loss=1.813, trans_loss=4.625, nll_loss=1.753, w2v_ctc_loss=0.516, task_loss=2.408, contrastive_loss=0.112, total=6672.12, n_correct=4812.82, ppl=3.37, accuracy=72.133, wps=18429.4, ups=1.38, wpb=13344.2, bsz=443.1, num_updates=35100, lr=7.54851e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=12.8, wall=16792
2023-08-29 01:06:43 | INFO | train_inner | epoch 030:    677 / 1191 loss=1.814, trans_loss=4.625, nll_loss=1.752, w2v_ctc_loss=0.525, task_loss=2.562, contrastive_loss=0.078, total=6569.5, n_correct=4732.63, ppl=3.37, accuracy=72.039, wps=18303.1, ups=1.39, wpb=13139, bsz=422.2, num_updates=35200, lr=7.53778e-05, gnorm=0.399, clip=0, loss_scale=32, train_wall=71, gb_free=12.8, wall=16864
2023-08-29 01:07:56 | INFO | train_inner | epoch 030:    777 / 1191 loss=1.827, trans_loss=4.63, nll_loss=1.76, w2v_ctc_loss=0.525, task_loss=2.466, contrastive_loss=0.179, total=6649.43, n_correct=4781.63, ppl=3.39, accuracy=71.91, wps=18221.4, ups=1.37, wpb=13298.9, bsz=438, num_updates=35300, lr=7.5271e-05, gnorm=0.404, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=16937
2023-08-29 01:09:08 | INFO | train_inner | epoch 030:    877 / 1191 loss=1.809, trans_loss=4.623, nll_loss=1.752, w2v_ctc_loss=0.511, task_loss=2.398, contrastive_loss=0.107, total=6691.44, n_correct=4832.34, ppl=3.37, accuracy=72.217, wps=18542.8, ups=1.39, wpb=13382.9, bsz=447.9, num_updates=35400, lr=7.51646e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=17009
2023-08-29 01:10:21 | INFO | train_inner | epoch 030:    977 / 1191 loss=1.817, trans_loss=4.63, nll_loss=1.761, w2v_ctc_loss=0.524, task_loss=2.449, contrastive_loss=0.11, total=6640.53, n_correct=4776.37, ppl=3.39, accuracy=71.928, wps=18297.8, ups=1.38, wpb=13281.1, bsz=444.6, num_updates=35500, lr=7.50587e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=72, gb_free=13.4, wall=17082
2023-08-29 01:11:33 | INFO | train_inner | epoch 030:   1077 / 1191 loss=1.81, trans_loss=4.628, nll_loss=1.758, w2v_ctc_loss=0.52, task_loss=2.298, contrastive_loss=0.064, total=6764.46, n_correct=4878.12, ppl=3.38, accuracy=72.114, wps=18669.4, ups=1.38, wpb=13528.9, bsz=456.1, num_updates=35600, lr=7.49532e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=14.7, wall=17154
2023-08-29 01:12:46 | INFO | train_inner | epoch 030:   1177 / 1191 loss=1.815, trans_loss=4.636, nll_loss=1.769, w2v_ctc_loss=0.514, task_loss=2.325, contrastive_loss=0.121, total=6687.11, n_correct=4813.46, ppl=3.41, accuracy=71.981, wps=18518.9, ups=1.38, wpb=13374.2, bsz=453.8, num_updates=35700, lr=7.48481e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=71, gb_free=10.5, wall=17226
2023-08-29 01:12:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-29 01:13:28 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.909 | trans_loss 5.175 | nll_loss 2.377 | w2v_ctc_loss 1.175 | task_loss 8.581 | contrastive_loss 0.251 | total 6138.43 | n_correct 4170 | ppl 5.2 | accuracy 67.933 | uer 16.286 | wer 18.096 | raw_wer 18.096 | bleu 27.46 | wps 1762.3 | wpb 6138.4 | bsz 201.1 | num_updates 35714 | best_bleu 27.51
2023-08-29 01:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 35714 updates
2023-08-29 01:13:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.4604.pt
2023-08-29 01:13:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.4604.pt
2023-08-29 01:13:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.4604.pt (epoch 30 @ 35714 updates, score 27.46) (writing took 6.491137309996702 seconds)
2023-08-29 01:13:35 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-29 01:13:35 | INFO | train | epoch 030 | loss 1.81 | trans_loss 4.621 | nll_loss 1.749 | w2v_ctc_loss 0.516 | task_loss 2.344 | contrastive_loss 0.106 | total 6703.69 | n_correct 4840.79 | ppl 3.36 | accuracy 72.211 | wps 17621.7 | ups 1.31 | wpb 13407.4 | bsz 452.1 | num_updates 35714 | lr 7.48334e-05 | gnorm 0.394 | clip 0 | loss_scale 32 | train_wall 851 | gb_free 14.5 | wall 17276
2023-08-29 01:13:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 01:13:35 | INFO | fairseq.trainer | begin training epoch 31
2023-08-29 01:13:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 01:14:44 | INFO | train_inner | epoch 031:     86 / 1191 loss=1.807, trans_loss=4.611, nll_loss=1.734, w2v_ctc_loss=0.518, task_loss=2.565, contrastive_loss=0.079, total=6599.42, n_correct=4779.55, ppl=3.33, accuracy=72.424, wps=11108.2, ups=0.84, wpb=13198.8, bsz=419.2, num_updates=35800, lr=7.47435e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=71, gb_free=11.4, wall=17345
2023-08-29 01:15:57 | INFO | train_inner | epoch 031:    186 / 1191 loss=1.797, trans_loss=4.606, nll_loss=1.728, w2v_ctc_loss=0.508, task_loss=2.296, contrastive_loss=0.076, total=6732.09, n_correct=4888.58, ppl=3.31, accuracy=72.616, wps=18448.6, ups=1.37, wpb=13464.2, bsz=458.4, num_updates=35900, lr=7.46393e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=72, gb_free=12.3, wall=17418
2023-08-29 01:17:09 | INFO | train_inner | epoch 031:    286 / 1191 loss=1.81, trans_loss=4.613, nll_loss=1.737, w2v_ctc_loss=0.518, task_loss=2.535, contrastive_loss=0.113, total=6560.21, n_correct=4750.17, ppl=3.33, accuracy=72.409, wps=18259.3, ups=1.39, wpb=13120.4, bsz=431.9, num_updates=36000, lr=7.45356e-05, gnorm=0.4, clip=0, loss_scale=32, train_wall=71, gb_free=13, wall=17490
2023-08-29 01:17:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 01:17:42 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.912 | trans_loss 5.177 | nll_loss 2.379 | w2v_ctc_loss 1.182 | task_loss 8.596 | contrastive_loss 0.251 | total 6138.43 | n_correct 4179.86 | ppl 5.2 | accuracy 68.093 | uer 16.222 | wer 18.178 | raw_wer 18.178 | bleu 27.54 | wps 1705.6 | wpb 6138.4 | bsz 201.1 | num_updates 36000 | best_bleu 27.54
2023-08-29 01:17:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36000 updates
2023-08-29 01:17:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_31_36000.pt
2023-08-29 01:17:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_31_36000.pt
2023-08-29 01:17:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_31_36000.pt (epoch 31 @ 36000 updates, score 27.54) (writing took 12.425867754001956 seconds)
2023-08-29 01:19:07 | INFO | train_inner | epoch 031:    386 / 1191 loss=1.799, trans_loss=4.612, nll_loss=1.737, w2v_ctc_loss=0.513, task_loss=2.326, contrastive_loss=0.056, total=6740.71, n_correct=4882.08, ppl=3.33, accuracy=72.427, wps=11447.7, ups=0.85, wpb=13481.4, bsz=456.6, num_updates=36100, lr=7.44323e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=71, gb_free=15.3, wall=17608
2023-08-29 01:20:19 | INFO | train_inner | epoch 031:    486 / 1191 loss=1.81, trans_loss=4.624, nll_loss=1.752, w2v_ctc_loss=0.516, task_loss=2.547, contrastive_loss=0.079, total=6663.24, n_correct=4809.16, ppl=3.37, accuracy=72.174, wps=18521.5, ups=1.39, wpb=13326.5, bsz=427.4, num_updates=36200, lr=7.43294e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=71, gb_free=13.7, wall=17680
2023-08-29 01:21:31 | INFO | train_inner | epoch 031:    586 / 1191 loss=1.811, trans_loss=4.616, nll_loss=1.742, w2v_ctc_loss=0.515, task_loss=2.321, contrastive_loss=0.14, total=6690.15, n_correct=4838.3, ppl=3.34, accuracy=72.32, wps=18589, ups=1.39, wpb=13380.3, bsz=452.9, num_updates=36300, lr=7.4227e-05, gnorm=0.399, clip=0, loss_scale=32, train_wall=71, gb_free=12.7, wall=17752
2023-08-29 01:22:43 | INFO | train_inner | epoch 031:    686 / 1191 loss=1.805, trans_loss=4.613, nll_loss=1.739, w2v_ctc_loss=0.51, task_loss=2.167, contrastive_loss=0.127, total=6828.19, n_correct=4946.96, ppl=3.34, accuracy=72.449, wps=18999.5, ups=1.39, wpb=13656.4, bsz=475.7, num_updates=36400, lr=7.41249e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=71, gb_free=9, wall=17824
2023-08-29 01:23:55 | INFO | train_inner | epoch 031:    786 / 1191 loss=1.804, trans_loss=4.616, nll_loss=1.744, w2v_ctc_loss=0.512, task_loss=2.19, contrastive_loss=0.108, total=6799.81, n_correct=4924.19, ppl=3.35, accuracy=72.417, wps=18800.5, ups=1.38, wpb=13599.6, bsz=477.8, num_updates=36500, lr=7.40233e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=72, gb_free=13, wall=17896
2023-08-29 01:25:08 | INFO | train_inner | epoch 031:    886 / 1191 loss=1.813, trans_loss=4.624, nll_loss=1.753, w2v_ctc_loss=0.515, task_loss=2.394, contrastive_loss=0.134, total=6621.33, n_correct=4776.83, ppl=3.37, accuracy=72.143, wps=18302.7, ups=1.38, wpb=13242.7, bsz=446.7, num_updates=36600, lr=7.39221e-05, gnorm=0.397, clip=0, loss_scale=64, train_wall=72, gb_free=6.3, wall=17968
2023-08-29 01:26:20 | INFO | train_inner | epoch 031:    986 / 1191 loss=1.811, trans_loss=4.622, nll_loss=1.75, w2v_ctc_loss=0.517, task_loss=2.339, contrastive_loss=0.119, total=6696.19, n_correct=4836.73, ppl=3.36, accuracy=72.231, wps=18597.1, ups=1.39, wpb=13392.4, bsz=451.6, num_updates=36700, lr=7.38213e-05, gnorm=0.398, clip=0, loss_scale=64, train_wall=71, gb_free=10.3, wall=18040
2023-08-29 01:27:32 | INFO | train_inner | epoch 031:   1086 / 1191 loss=1.8, trans_loss=4.616, nll_loss=1.744, w2v_ctc_loss=0.507, task_loss=2.056, contrastive_loss=0.098, total=6891.63, n_correct=4987.3, ppl=3.35, accuracy=72.367, wps=19144.7, ups=1.39, wpb=13783.3, bsz=490.4, num_updates=36800, lr=7.3721e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=71, gb_free=4.5, wall=18112
2023-08-29 01:28:44 | INFO | train_inner | epoch 031:   1186 / 1191 loss=1.81, trans_loss=4.622, nll_loss=1.751, w2v_ctc_loss=0.515, task_loss=2.378, contrastive_loss=0.122, total=6644.22, n_correct=4796.22, ppl=3.37, accuracy=72.186, wps=18433.3, ups=1.39, wpb=13288.4, bsz=443.7, num_updates=36900, lr=7.3621e-05, gnorm=0.396, clip=0, loss_scale=64, train_wall=71, gb_free=14.7, wall=18184
2023-08-29 01:28:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 01:29:20 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.895 | trans_loss 5.176 | nll_loss 2.379 | w2v_ctc_loss 1.137 | task_loss 8.517 | contrastive_loss 0.241 | total 6138.43 | n_correct 4180.71 | ppl 5.2 | accuracy 68.107 | uer 16.059 | wer 17.917 | raw_wer 17.917 | bleu 27.55 | wps 1759 | wpb 6138.4 | bsz 201.1 | num_updates 36905 | best_bleu 27.55
2023-08-29 01:29:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36905 updates
2023-08-29 01:29:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-29 01:29:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-29 01:29:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 31 @ 36905 updates, score 27.55) (writing took 12.966661668997403 seconds)
2023-08-29 01:29:33 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-29 01:29:33 | INFO | train | epoch 031 | loss 1.807 | trans_loss 4.616 | nll_loss 1.742 | w2v_ctc_loss 0.513 | task_loss 2.341 | contrastive_loss 0.104 | total 6703.69 | n_correct 4849.9 | ppl 3.35 | accuracy 72.347 | wps 16660.9 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 36905 | lr 7.3616e-05 | gnorm 0.395 | clip 0 | loss_scale 64 | train_wall 850 | gb_free 10.3 | wall 18234
2023-08-29 01:29:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 01:29:33 | INFO | fairseq.trainer | begin training epoch 32
2023-08-29 01:29:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 01:30:48 | INFO | train_inner | epoch 032:     95 / 1191 loss=1.79, trans_loss=4.592, nll_loss=1.711, w2v_ctc_loss=0.502, task_loss=2.273, contrastive_loss=0.08, total=6699.21, n_correct=4883.69, ppl=3.27, accuracy=72.899, wps=10766.6, ups=0.8, wpb=13398.4, bsz=454.5, num_updates=37000, lr=7.35215e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=71, gb_free=11.9, wall=18309
2023-08-29 01:32:00 | INFO | train_inner | epoch 032:    195 / 1191 loss=1.809, trans_loss=4.607, nll_loss=1.731, w2v_ctc_loss=0.51, task_loss=2.242, contrastive_loss=0.177, total=6807.88, n_correct=4937, ppl=3.32, accuracy=72.519, wps=18962, ups=1.39, wpb=13615.8, bsz=467.3, num_updates=37100, lr=7.34223e-05, gnorm=0.393, clip=0, loss_scale=64, train_wall=71, gb_free=14.4, wall=18381
2023-08-29 01:33:12 | INFO | train_inner | epoch 032:    295 / 1191 loss=1.798, trans_loss=4.608, nll_loss=1.732, w2v_ctc_loss=0.506, task_loss=2.401, contrastive_loss=0.07, total=6684.79, n_correct=4846.9, ppl=3.32, accuracy=72.506, wps=18519.9, ups=1.39, wpb=13369.6, bsz=446.4, num_updates=37200, lr=7.33236e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=71, gb_free=13.1, wall=18453
2023-08-29 01:34:24 | INFO | train_inner | epoch 032:    395 / 1191 loss=1.792, trans_loss=4.597, nll_loss=1.717, w2v_ctc_loss=0.502, task_loss=2.271, contrastive_loss=0.076, total=6766.95, n_correct=4925.33, ppl=3.29, accuracy=72.785, wps=18795.8, ups=1.39, wpb=13533.9, bsz=460.3, num_updates=37300, lr=7.32252e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=71, gb_free=10.8, wall=18525
2023-08-29 01:35:37 | INFO | train_inner | epoch 032:    495 / 1191 loss=1.798, trans_loss=4.611, nll_loss=1.736, w2v_ctc_loss=0.509, task_loss=2.323, contrastive_loss=0.063, total=6728, n_correct=4877.34, ppl=3.33, accuracy=72.493, wps=18513.7, ups=1.38, wpb=13456, bsz=452.3, num_updates=37400, lr=7.31272e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=72, gb_free=14.2, wall=18598
2023-08-29 01:36:49 | INFO | train_inner | epoch 032:    595 / 1191 loss=1.8, trans_loss=4.611, nll_loss=1.736, w2v_ctc_loss=0.515, task_loss=2.394, contrastive_loss=0.057, total=6688.29, n_correct=4849.12, ppl=3.33, accuracy=72.502, wps=18592.6, ups=1.39, wpb=13376.6, bsz=443.7, num_updates=37500, lr=7.30297e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=18669
2023-08-29 01:38:02 | INFO | train_inner | epoch 032:    695 / 1191 loss=1.802, trans_loss=4.61, nll_loss=1.734, w2v_ctc_loss=0.507, task_loss=2.525, contrastive_loss=0.102, total=6660.06, n_correct=4828.57, ppl=3.33, accuracy=72.5, wps=18262.1, ups=1.37, wpb=13320.1, bsz=435.2, num_updates=37600, lr=7.29325e-05, gnorm=0.395, clip=0, loss_scale=64, train_wall=72, gb_free=8.7, wall=18742
2023-08-29 01:39:14 | INFO | train_inner | epoch 032:    795 / 1191 loss=1.81, trans_loss=4.614, nll_loss=1.74, w2v_ctc_loss=0.509, task_loss=2.266, contrastive_loss=0.163, total=6785.45, n_correct=4910.41, ppl=3.34, accuracy=72.367, wps=18654.6, ups=1.37, wpb=13570.9, bsz=469.8, num_updates=37700, lr=7.28357e-05, gnorm=0.397, clip=0, loss_scale=64, train_wall=72, gb_free=14.3, wall=18815
2023-08-29 01:40:27 | INFO | train_inner | epoch 032:    895 / 1191 loss=1.81, trans_loss=4.619, nll_loss=1.746, w2v_ctc_loss=0.513, task_loss=2.435, contrastive_loss=0.12, total=6681.76, n_correct=4829.58, ppl=3.35, accuracy=72.28, wps=18488.4, ups=1.38, wpb=13363.5, bsz=442.9, num_updates=37800, lr=7.27393e-05, gnorm=0.399, clip=0, loss_scale=64, train_wall=71, gb_free=14.5, wall=18887
2023-08-29 01:41:39 | INFO | train_inner | epoch 032:    995 / 1191 loss=1.805, trans_loss=4.618, nll_loss=1.745, w2v_ctc_loss=0.514, task_loss=2.378, contrastive_loss=0.087, total=6611.9, n_correct=4785.25, ppl=3.35, accuracy=72.373, wps=18393.6, ups=1.39, wpb=13223.8, bsz=442, num_updates=37900, lr=7.26433e-05, gnorm=0.395, clip=0, loss_scale=64, train_wall=71, gb_free=12.5, wall=18959
2023-08-29 01:42:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-29 01:42:51 | INFO | train_inner | epoch 032:   1096 / 1191 loss=1.803, trans_loss=4.62, nll_loss=1.747, w2v_ctc_loss=0.512, task_loss=2.458, contrastive_loss=0.053, total=6612.63, n_correct=4778.09, ppl=3.36, accuracy=72.257, wps=18284.7, ups=1.38, wpb=13225.3, bsz=431.8, num_updates=38000, lr=7.25476e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=71, gb_free=15.2, wall=19032
2023-08-29 01:42:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 01:43:23 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.899 | trans_loss 5.17 | nll_loss 2.374 | w2v_ctc_loss 1.163 | task_loss 8.578 | contrastive_loss 0.239 | total 6138.43 | n_correct 4174.71 | ppl 5.18 | accuracy 68.009 | uer 16.094 | wer 17.929 | raw_wer 17.929 | bleu 27.57 | wps 1772.8 | wpb 6138.4 | bsz 201.1 | num_updates 38000 | best_bleu 27.57
2023-08-29 01:43:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 38000 updates
2023-08-29 01:43:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_32_38000.pt
2023-08-29 01:43:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_32_38000.pt
2023-08-29 01:43:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_32_38000.pt (epoch 32 @ 38000 updates, score 27.57) (writing took 13.403645319998759 seconds)
2023-08-29 01:44:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 01:45:17 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.92 | trans_loss 5.181 | nll_loss 2.386 | w2v_ctc_loss 1.205 | task_loss 8.546 | contrastive_loss 0.247 | total 6138.43 | n_correct 4173.71 | ppl 5.23 | accuracy 67.993 | uer 16.198 | wer 18.144 | raw_wer 18.144 | bleu 27.27 | wps 1763.2 | wpb 6138.4 | bsz 201.1 | num_updates 38095 | best_bleu 27.57
2023-08-29 01:45:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 38095 updates
2023-08-29 01:45:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 01:45:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 01:45:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 32 @ 38095 updates, score 27.27) (writing took 5.729366599000059 seconds)
2023-08-29 01:45:23 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-29 01:45:23 | INFO | train | epoch 032 | loss 1.802 | trans_loss 4.61 | nll_loss 1.735 | w2v_ctc_loss 0.508 | task_loss 2.342 | contrastive_loss 0.104 | total 6703.86 | n_correct 4860.2 | ppl 3.33 | accuracy 72.498 | wps 16804.5 | ups 1.25 | wpb 13407.7 | bsz 452.3 | num_updates 38095 | lr 7.24571e-05 | gnorm 0.394 | clip 0 | loss_scale 32 | train_wall 847 | gb_free 11.5 | wall 19183
2023-08-29 01:45:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 01:45:23 | INFO | fairseq.trainer | begin training epoch 33
2023-08-29 01:45:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 01:45:34 | INFO | train_inner | epoch 033:      5 / 1191 loss=1.807, trans_loss=4.619, nll_loss=1.747, w2v_ctc_loss=0.499, task_loss=2.17, contrastive_loss=0.218, total=6703.57, n_correct=4856.79, ppl=3.36, accuracy=72.451, wps=8222, ups=0.61, wpb=13407.1, bsz=482.5, num_updates=38100, lr=7.24524e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=70, gb_free=14.3, wall=19195
2023-08-29 01:46:47 | INFO | train_inner | epoch 033:    105 / 1191 loss=1.785, trans_loss=4.593, nll_loss=1.712, w2v_ctc_loss=0.493, task_loss=2.251, contrastive_loss=0.067, total=6806.82, n_correct=4962.47, ppl=3.28, accuracy=72.904, wps=18619.4, ups=1.37, wpb=13613.6, bsz=467.7, num_updates=38200, lr=7.23575e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=72, gb_free=14.1, wall=19268
2023-08-29 01:47:59 | INFO | train_inner | epoch 033:    205 / 1191 loss=1.792, trans_loss=4.594, nll_loss=1.714, w2v_ctc_loss=0.501, task_loss=2.27, contrastive_loss=0.09, total=6763.38, n_correct=4926.65, ppl=3.28, accuracy=72.843, wps=18962, ups=1.4, wpb=13526.8, bsz=455.5, num_updates=38300, lr=7.22629e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=70, gb_free=12.8, wall=19339
2023-08-29 01:49:11 | INFO | train_inner | epoch 033:    305 / 1191 loss=1.802, trans_loss=4.602, nll_loss=1.724, w2v_ctc_loss=0.509, task_loss=2.51, contrastive_loss=0.121, total=6595.67, n_correct=4792.72, ppl=3.3, accuracy=72.665, wps=18144.3, ups=1.38, wpb=13191.3, bsz=434, num_updates=38400, lr=7.21688e-05, gnorm=0.403, clip=0, loss_scale=32, train_wall=72, gb_free=12.4, wall=19412
2023-08-29 01:50:22 | INFO | train_inner | epoch 033:    405 / 1191 loss=1.798, trans_loss=4.603, nll_loss=1.725, w2v_ctc_loss=0.505, task_loss=2.463, contrastive_loss=0.101, total=6592.1, n_correct=4789.35, ppl=3.31, accuracy=72.653, wps=18524.8, ups=1.41, wpb=13184.2, bsz=432.6, num_updates=38500, lr=7.2075e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=70, gb_free=4.3, wall=19483
2023-08-29 01:51:33 | INFO | train_inner | epoch 033:    505 / 1191 loss=1.792, trans_loss=4.6, nll_loss=1.722, w2v_ctc_loss=0.496, task_loss=2.281, contrastive_loss=0.1, total=6691.29, n_correct=4870.56, ppl=3.3, accuracy=72.79, wps=18884.9, ups=1.41, wpb=13382.6, bsz=456.4, num_updates=38600, lr=7.19816e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=70, gb_free=15.1, wall=19554
2023-08-29 01:52:46 | INFO | train_inner | epoch 033:    605 / 1191 loss=1.798, trans_loss=4.602, nll_loss=1.724, w2v_ctc_loss=0.512, task_loss=2.408, contrastive_loss=0.078, total=6673.5, n_correct=4845.5, ppl=3.3, accuracy=72.608, wps=18326.6, ups=1.37, wpb=13347, bsz=446.7, num_updates=38700, lr=7.18885e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=72, gb_free=11.6, wall=19627
2023-08-29 01:53:59 | INFO | train_inner | epoch 033:    705 / 1191 loss=1.8, trans_loss=4.609, nll_loss=1.733, w2v_ctc_loss=0.509, task_loss=2.396, contrastive_loss=0.086, total=6684.47, n_correct=4848.08, ppl=3.32, accuracy=72.528, wps=18370, ups=1.37, wpb=13368.9, bsz=443.1, num_updates=38800, lr=7.17958e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=4.5, wall=19700
2023-08-29 01:55:11 | INFO | train_inner | epoch 033:    805 / 1191 loss=1.794, trans_loss=4.601, nll_loss=1.723, w2v_ctc_loss=0.494, task_loss=2.213, contrastive_loss=0.14, total=6794.84, n_correct=4948.43, ppl=3.3, accuracy=72.826, wps=18852.9, ups=1.39, wpb=13589.7, bsz=467.9, num_updates=38900, lr=7.17035e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=71, gb_free=13.9, wall=19772
2023-08-29 01:56:23 | INFO | train_inner | epoch 033:    905 / 1191 loss=1.799, trans_loss=4.609, nll_loss=1.734, w2v_ctc_loss=0.509, task_loss=2.279, contrastive_loss=0.085, total=6754.04, n_correct=4899.24, ppl=3.33, accuracy=72.538, wps=18666.6, ups=1.38, wpb=13508.1, bsz=463.2, num_updates=39000, lr=7.16115e-05, gnorm=0.399, clip=0, loss_scale=32, train_wall=72, gb_free=13.2, wall=19844
2023-08-29 01:57:36 | INFO | train_inner | epoch 033:   1005 / 1191 loss=1.81, trans_loss=4.623, nll_loss=1.752, w2v_ctc_loss=0.516, task_loss=2.466, contrastive_loss=0.083, total=6679.84, n_correct=4822.32, ppl=3.37, accuracy=72.192, wps=18354.2, ups=1.37, wpb=13359.7, bsz=440.5, num_updates=39100, lr=7.15199e-05, gnorm=0.403, clip=0, loss_scale=32, train_wall=72, gb_free=4.6, wall=19917
2023-08-29 01:58:49 | INFO | train_inner | epoch 033:   1105 / 1191 loss=1.805, trans_loss=4.614, nll_loss=1.741, w2v_ctc_loss=0.509, task_loss=2.3, contrastive_loss=0.128, total=6749.49, n_correct=4887.2, ppl=3.34, accuracy=72.408, wps=18520.5, ups=1.37, wpb=13499, bsz=463.2, num_updates=39200, lr=7.14286e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=72, gb_free=12.8, wall=19990
2023-08-29 01:59:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 02:00:24 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.92 | trans_loss 5.174 | nll_loss 2.377 | w2v_ctc_loss 1.215 | task_loss 8.567 | contrastive_loss 0.245 | total 6138.43 | n_correct 4179.29 | ppl 5.2 | accuracy 68.084 | uer 16.254 | wer 18.126 | raw_wer 18.126 | bleu 27.21 | wps 1751.7 | wpb 6138.4 | bsz 201.1 | num_updates 39286 | best_bleu 27.57
2023-08-29 02:00:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 39286 updates
2023-08-29 02:00:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 02:00:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 02:00:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 33 @ 39286 updates, score 27.21) (writing took 5.901876310999796 seconds)
2023-08-29 02:00:30 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-29 02:00:30 | INFO | train | epoch 033 | loss 1.798 | trans_loss 4.605 | nll_loss 1.729 | w2v_ctc_loss 0.505 | task_loss 2.345 | contrastive_loss 0.103 | total 6703.69 | n_correct 4868.36 | ppl 3.31 | accuracy 72.622 | wps 17609.6 | ups 1.31 | wpb 13407.4 | bsz 452.1 | num_updates 39286 | lr 7.13503e-05 | gnorm 0.397 | clip 0 | loss_scale 32 | train_wall 850 | gb_free 10.6 | wall 20090
2023-08-29 02:00:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 02:00:30 | INFO | fairseq.trainer | begin training epoch 34
2023-08-29 02:00:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 02:00:47 | INFO | train_inner | epoch 034:     14 / 1191 loss=1.803, trans_loss=4.608, nll_loss=1.733, w2v_ctc_loss=0.508, task_loss=2.255, contrastive_loss=0.156, total=6714.43, n_correct=4873.83, ppl=3.32, accuracy=72.587, wps=11350.2, ups=0.85, wpb=13428.9, bsz=468.7, num_updates=39300, lr=7.13376e-05, gnorm=0.399, clip=0, loss_scale=32, train_wall=71, gb_free=13.7, wall=20108
2023-08-29 02:01:59 | INFO | train_inner | epoch 034:    114 / 1191 loss=1.792, trans_loss=4.589, nll_loss=1.708, w2v_ctc_loss=0.49, task_loss=2.142, contrastive_loss=0.179, total=6812.86, n_correct=4972.58, ppl=3.27, accuracy=72.988, wps=19037.9, ups=1.4, wpb=13625.7, bsz=478.9, num_updates=39400, lr=7.1247e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=71, gb_free=14.6, wall=20180
2023-08-29 02:03:11 | INFO | train_inner | epoch 034:    214 / 1191 loss=1.796, trans_loss=4.594, nll_loss=1.714, w2v_ctc_loss=0.503, task_loss=2.415, contrastive_loss=0.118, total=6669.32, n_correct=4853.99, ppl=3.28, accuracy=72.781, wps=18425.1, ups=1.38, wpb=13338.6, bsz=448.9, num_updates=39500, lr=7.11568e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=72, gb_free=12.9, wall=20252
2023-08-29 02:04:23 | INFO | train_inner | epoch 034:    314 / 1191 loss=1.788, trans_loss=4.594, nll_loss=1.714, w2v_ctc_loss=0.5, task_loss=2.504, contrastive_loss=0.053, total=6597.66, n_correct=4808.14, ppl=3.28, accuracy=72.876, wps=18407.9, ups=1.4, wpb=13195.3, bsz=431.8, num_updates=39600, lr=7.10669e-05, gnorm=0.399, clip=0, loss_scale=32, train_wall=71, gb_free=13.7, wall=20324
2023-08-29 02:05:36 | INFO | train_inner | epoch 034:    414 / 1191 loss=1.791, trans_loss=4.599, nll_loss=1.72, w2v_ctc_loss=0.501, task_loss=2.479, contrastive_loss=0.061, total=6670.6, n_correct=4852.8, ppl=3.29, accuracy=72.749, wps=18247.2, ups=1.37, wpb=13341.2, bsz=433.1, num_updates=39700, lr=7.09773e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=20397
2023-08-29 02:06:48 | INFO | train_inner | epoch 034:    514 / 1191 loss=1.796, trans_loss=4.604, nll_loss=1.727, w2v_ctc_loss=0.503, task_loss=2.455, contrastive_loss=0.09, total=6672.9, n_correct=4850.34, ppl=3.31, accuracy=72.687, wps=18451.9, ups=1.38, wpb=13345.8, bsz=440, num_updates=39800, lr=7.08881e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=71, gb_free=5.4, wall=20469
2023-08-29 02:08:01 | INFO | train_inner | epoch 034:    614 / 1191 loss=1.798, trans_loss=4.601, nll_loss=1.723, w2v_ctc_loss=0.501, task_loss=2.285, contrastive_loss=0.129, total=6739.24, n_correct=4897.44, ppl=3.3, accuracy=72.671, wps=18594.8, ups=1.38, wpb=13478.5, bsz=463.2, num_updates=39900, lr=7.07992e-05, gnorm=0.402, clip=0, loss_scale=32, train_wall=72, gb_free=12.7, wall=20542
2023-08-29 02:09:12 | INFO | train_inner | epoch 034:    714 / 1191 loss=1.797, trans_loss=4.604, nll_loss=1.727, w2v_ctc_loss=0.506, task_loss=2.391, contrastive_loss=0.085, total=6627.68, n_correct=4812.76, ppl=3.31, accuracy=72.616, wps=18543.5, ups=1.4, wpb=13255.4, bsz=441.5, num_updates=40000, lr=7.07107e-05, gnorm=0.4, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=20613
2023-08-29 02:09:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 02:09:46 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.935 | trans_loss 5.178 | nll_loss 2.382 | w2v_ctc_loss 1.256 | task_loss 8.585 | contrastive_loss 0.249 | total 6138.43 | n_correct 4171.43 | ppl 5.21 | accuracy 67.956 | uer 16.431 | wer 18.315 | raw_wer 18.315 | bleu 27.64 | wps 1680.9 | wpb 6138.4 | bsz 201.1 | num_updates 40000 | best_bleu 27.64
2023-08-29 02:09:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40000 updates
2023-08-29 02:09:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_34_40000.pt
2023-08-29 02:09:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_34_40000.pt
2023-08-29 02:09:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_34_40000.pt (epoch 34 @ 40000 updates, score 27.64) (writing took 10.217817597000248 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-29 02:11:08 | INFO | train_inner | epoch 034:    814 / 1191 loss=1.795, trans_loss=4.602, nll_loss=1.724, w2v_ctc_loss=0.507, task_loss=2.379, contrastive_loss=0.081, total=6664.33, n_correct=4847.87, ppl=3.3, accuracy=72.744, wps=11530.2, ups=0.87, wpb=13328.7, bsz=454.5, num_updates=40100, lr=7.06225e-05, gnorm=0.398, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=20729
2023-08-29 02:12:20 | INFO | train_inner | epoch 034:    914 / 1191 loss=1.795, trans_loss=4.603, nll_loss=1.726, w2v_ctc_loss=0.504, task_loss=2.49, contrastive_loss=0.074, total=6654.7, n_correct=4840.76, ppl=3.31, accuracy=72.742, wps=18450.9, ups=1.39, wpb=13309.4, bsz=428.5, num_updates=40200, lr=7.05346e-05, gnorm=0.402, clip=0, loss_scale=64, train_wall=71, gb_free=14.4, wall=20801
2023-08-29 02:13:32 | INFO | train_inner | epoch 034:   1014 / 1191 loss=1.796, trans_loss=4.613, nll_loss=1.738, w2v_ctc_loss=0.504, task_loss=2.401, contrastive_loss=0.061, total=6667.27, n_correct=4838.37, ppl=3.34, accuracy=72.569, wps=18505.1, ups=1.39, wpb=13334.5, bsz=439.7, num_updates=40300, lr=7.0447e-05, gnorm=0.397, clip=0, loss_scale=64, train_wall=71, gb_free=12.3, wall=20873
2023-08-29 02:14:45 | INFO | train_inner | epoch 034:   1114 / 1191 loss=1.791, trans_loss=4.605, nll_loss=1.73, w2v_ctc_loss=0.496, task_loss=2.149, contrastive_loss=0.097, total=6861.81, n_correct=4988.28, ppl=3.32, accuracy=72.696, wps=18986.2, ups=1.38, wpb=13723.6, bsz=480.5, num_updates=40400, lr=7.03598e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=71, gb_free=13.5, wall=20945
2023-08-29 02:15:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-29 02:16:13 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.923 | trans_loss 5.177 | nll_loss 2.381 | w2v_ctc_loss 1.221 | task_loss 8.555 | contrastive_loss 0.245 | total 6138.43 | n_correct 4174.71 | ppl 5.21 | accuracy 68.009 | uer 16.281 | wer 18.051 | raw_wer 18.051 | bleu 27.42 | wps 1690.9 | wpb 6138.4 | bsz 201.1 | num_updates 40477 | best_bleu 27.64
2023-08-29 02:16:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40477 updates
2023-08-29 02:16:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.4209.pt
2023-08-29 02:16:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.4209.pt
2023-08-29 02:16:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.4209.pt (epoch 34 @ 40477 updates, score 27.42) (writing took 5.904223833000287 seconds)
2023-08-29 02:16:20 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-29 02:16:20 | INFO | train | epoch 034 | loss 1.794 | trans_loss 4.601 | nll_loss 1.723 | w2v_ctc_loss 0.501 | task_loss 2.345 | contrastive_loss 0.102 | total 6703.69 | n_correct 4876.02 | ppl 3.3 | accuracy 72.736 | wps 16808.2 | ups 1.25 | wpb 13407.4 | bsz 452.1 | num_updates 40477 | lr 7.02928e-05 | gnorm 0.397 | clip 0 | loss_scale 64 | train_wall 849 | gb_free 14 | wall 21040
2023-08-29 02:16:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 02:16:20 | INFO | fairseq.trainer | begin training epoch 35
2023-08-29 02:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 02:16:44 | INFO | train_inner | epoch 035:     23 / 1191 loss=1.798, trans_loss=4.603, nll_loss=1.727, w2v_ctc_loss=0.498, task_loss=2.204, contrastive_loss=0.164, total=6766.65, n_correct=4918.03, ppl=3.31, accuracy=72.68, wps=11378.4, ups=0.84, wpb=13533.3, bsz=471.5, num_updates=40500, lr=7.02728e-05, gnorm=0.395, clip=0, loss_scale=64, train_wall=71, gb_free=10.9, wall=21064
2023-08-29 02:17:55 | INFO | train_inner | epoch 035:    123 / 1191 loss=1.783, trans_loss=4.586, nll_loss=1.703, w2v_ctc_loss=0.498, task_loss=2.348, contrastive_loss=0.061, total=6708.25, n_correct=4903.26, ppl=3.26, accuracy=73.093, wps=18762.4, ups=1.4, wpb=13416.5, bsz=451.4, num_updates=40600, lr=7.01862e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=71, gb_free=13.6, wall=21136
2023-08-29 02:19:07 | INFO | train_inner | epoch 035:    223 / 1191 loss=1.793, trans_loss=4.588, nll_loss=1.706, w2v_ctc_loss=0.494, task_loss=2.427, contrastive_loss=0.178, total=6627.47, n_correct=4837.31, ppl=3.26, accuracy=72.989, wps=18475.1, ups=1.39, wpb=13254.9, bsz=444.5, num_updates=40700, lr=7.01e-05, gnorm=0.398, clip=0, loss_scale=64, train_wall=71, gb_free=14.7, wall=21207
2023-08-29 02:20:19 | INFO | train_inner | epoch 035:    323 / 1191 loss=1.782, trans_loss=4.581, nll_loss=1.698, w2v_ctc_loss=0.49, task_loss=2.251, contrastive_loss=0.115, total=6767.84, n_correct=4955.68, ppl=3.24, accuracy=73.224, wps=18771.6, ups=1.39, wpb=13535.7, bsz=463.2, num_updates=40800, lr=7.0014e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=71, gb_free=13.1, wall=21280
2023-08-29 02:21:32 | INFO | train_inner | epoch 035:    423 / 1191 loss=1.791, trans_loss=4.597, nll_loss=1.717, w2v_ctc_loss=0.502, task_loss=2.627, contrastive_loss=0.05, total=6574.17, n_correct=4785.31, ppl=3.29, accuracy=72.79, wps=18028.3, ups=1.37, wpb=13148.3, bsz=420.7, num_updates=40900, lr=6.99284e-05, gnorm=0.4, clip=0, loss_scale=64, train_wall=72, gb_free=15, wall=21353
2023-08-29 02:22:44 | INFO | train_inner | epoch 035:    523 / 1191 loss=1.787, trans_loss=4.59, nll_loss=1.71, w2v_ctc_loss=0.497, task_loss=2.328, contrastive_loss=0.079, total=6726.43, n_correct=4906.93, ppl=3.27, accuracy=72.95, wps=18679.8, ups=1.39, wpb=13452.9, bsz=456.8, num_updates=41000, lr=6.9843e-05, gnorm=0.396, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=21425
2023-08-29 02:23:57 | INFO | train_inner | epoch 035:    623 / 1191 loss=1.787, trans_loss=4.593, nll_loss=1.713, w2v_ctc_loss=0.494, task_loss=2.378, contrastive_loss=0.087, total=6707.79, n_correct=4890.01, ppl=3.28, accuracy=72.9, wps=18428.4, ups=1.37, wpb=13415.6, bsz=446.9, num_updates=41100, lr=6.9758e-05, gnorm=0.397, clip=0, loss_scale=64, train_wall=72, gb_free=12.6, wall=21497
2023-08-29 02:25:09 | INFO | train_inner | epoch 035:    723 / 1191 loss=1.796, trans_loss=4.601, nll_loss=1.723, w2v_ctc_loss=0.501, task_loss=2.356, contrastive_loss=0.123, total=6699.36, n_correct=4874.41, ppl=3.3, accuracy=72.759, wps=18559.7, ups=1.39, wpb=13398.7, bsz=453.1, num_updates=41200, lr=6.96733e-05, gnorm=0.403, clip=0, loss_scale=64, train_wall=71, gb_free=11.4, wall=21570
2023-08-29 02:26:21 | INFO | train_inner | epoch 035:    823 / 1191 loss=1.796, trans_loss=4.606, nll_loss=1.73, w2v_ctc_loss=0.5, task_loss=2.258, contrastive_loss=0.113, total=6757, n_correct=4909.8, ppl=3.32, accuracy=72.662, wps=18708.7, ups=1.38, wpb=13514, bsz=459.2, num_updates=41300, lr=6.95889e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=21642
2023-08-29 02:27:33 | INFO | train_inner | epoch 035:    923 / 1191 loss=1.791, trans_loss=4.597, nll_loss=1.719, w2v_ctc_loss=0.488, task_loss=2.165, contrastive_loss=0.139, total=6767.2, n_correct=4932.68, ppl=3.29, accuracy=72.891, wps=18781, ups=1.39, wpb=13534.4, bsz=472.7, num_updates=41400, lr=6.95048e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=71, gb_free=12.1, wall=21714
2023-08-29 02:28:45 | INFO | train_inner | epoch 035:   1023 / 1191 loss=1.789, trans_loss=4.597, nll_loss=1.718, w2v_ctc_loss=0.499, task_loss=2.391, contrastive_loss=0.066, total=6722.28, n_correct=4896.89, ppl=3.29, accuracy=72.846, wps=18786.9, ups=1.4, wpb=13444.6, bsz=441.5, num_updates=41500, lr=6.9421e-05, gnorm=0.393, clip=0, loss_scale=64, train_wall=71, gb_free=15.4, wall=21785
2023-08-29 02:29:57 | INFO | train_inner | epoch 035:   1123 / 1191 loss=1.793, trans_loss=4.608, nll_loss=1.734, w2v_ctc_loss=0.502, task_loss=2.417, contrastive_loss=0.061, total=6632.06, n_correct=4816.71, ppl=3.33, accuracy=72.628, wps=18370.1, ups=1.38, wpb=13264.1, bsz=443.9, num_updates=41600, lr=6.93375e-05, gnorm=0.396, clip=0, loss_scale=64, train_wall=71, gb_free=9.2, wall=21858
2023-08-29 02:30:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 02:31:18 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 3.925 | trans_loss 5.176 | nll_loss 2.38 | w2v_ctc_loss 1.225 | task_loss 8.549 | contrastive_loss 0.251 | total 6138.43 | n_correct 4179.57 | ppl 5.2 | accuracy 68.089 | uer 16.535 | wer 18.3 | raw_wer 18.3 | bleu 27.49 | wps 1760.4 | wpb 6138.4 | bsz 201.1 | num_updates 41668 | best_bleu 27.64
2023-08-29 02:31:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 41668 updates
2023-08-29 02:31:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.4904.pt
2023-08-29 02:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.4904.pt
2023-08-29 02:31:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.4904.pt (epoch 35 @ 41668 updates, score 27.49) (writing took 8.483614485001453 seconds)
2023-08-29 02:31:27 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-08-29 02:31:27 | INFO | train | epoch 035 | loss 1.79 | trans_loss 4.595 | nll_loss 1.716 | w2v_ctc_loss 0.497 | task_loss 2.344 | contrastive_loss 0.101 | total 6703.69 | n_correct 4885.65 | ppl 3.29 | accuracy 72.88 | wps 17596.9 | ups 1.31 | wpb 13407.4 | bsz 452.1 | num_updates 41668 | lr 6.92809e-05 | gnorm 0.396 | clip 0 | loss_scale 64 | train_wall 848 | gb_free 14.3 | wall 21948
2023-08-29 02:31:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 02:31:27 | INFO | fairseq.trainer | begin training epoch 36
2023-08-29 02:31:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 02:31:58 | INFO | train_inner | epoch 036:     32 / 1191 loss=1.791, trans_loss=4.596, nll_loss=1.718, w2v_ctc_loss=0.49, task_loss=2.247, contrastive_loss=0.131, total=6736.56, n_correct=4912.2, ppl=3.29, accuracy=72.919, wps=11164.6, ups=0.83, wpb=13473.1, bsz=468.8, num_updates=41700, lr=6.92543e-05, gnorm=0.396, clip=0, loss_scale=64, train_wall=71, gb_free=14, wall=21978
2023-08-29 02:33:09 | INFO | train_inner | epoch 036:    132 / 1191 loss=1.786, trans_loss=4.578, nll_loss=1.693, w2v_ctc_loss=0.491, task_loss=2.403, contrastive_loss=0.146, total=6631.33, n_correct=4855.93, ppl=3.23, accuracy=73.227, wps=18601.2, ups=1.4, wpb=13262.7, bsz=441.6, num_updates=41800, lr=6.91714e-05, gnorm=0.4, clip=0, loss_scale=64, train_wall=71, gb_free=12.1, wall=22050
2023-08-29 02:34:21 | INFO | train_inner | epoch 036:    232 / 1191 loss=1.771, trans_loss=4.571, nll_loss=1.686, w2v_ctc_loss=0.486, task_loss=2.209, contrastive_loss=0.058, total=6729.56, n_correct=4943.76, ppl=3.22, accuracy=73.463, wps=18755.8, ups=1.39, wpb=13459.1, bsz=469.7, num_updates=41900, lr=6.90889e-05, gnorm=0.395, clip=0, loss_scale=64, train_wall=71, gb_free=6.3, wall=22121
2023-08-29 02:35:33 | INFO | train_inner | epoch 036:    332 / 1191 loss=1.776, trans_loss=4.582, nll_loss=1.699, w2v_ctc_loss=0.487, task_loss=2.239, contrastive_loss=0.064, total=6782.01, n_correct=4966.8, ppl=3.25, accuracy=73.235, wps=18892.2, ups=1.39, wpb=13564, bsz=465.5, num_updates=42000, lr=6.90066e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=71, gb_free=10, wall=22193
2023-08-29 02:35:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 02:36:06 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.945 | trans_loss 5.182 | nll_loss 2.384 | w2v_ctc_loss 1.279 | task_loss 8.583 | contrastive_loss 0.25 | total 6138.43 | n_correct 4184 | ppl 5.22 | accuracy 68.161 | uer 16.578 | wer 18.442 | raw_wer 18.442 | bleu 27.24 | wps 1669.3 | wpb 6138.4 | bsz 201.1 | num_updates 42000 | best_bleu 27.64
2023-08-29 02:36:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42000 updates
2023-08-29 02:36:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_36_42000.pt
2023-08-29 02:36:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_36_42000.pt
2023-08-29 02:36:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_36_42000.pt (epoch 36 @ 42000 updates, score 27.24) (writing took 5.845566357998905 seconds)
2023-08-29 02:37:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-29 02:37:26 | INFO | train_inner | epoch 036:    433 / 1191 loss=1.783, trans_loss=4.587, nll_loss=1.706, w2v_ctc_loss=0.491, task_loss=2.227, contrastive_loss=0.1, total=6791.26, n_correct=4967.87, ppl=3.26, accuracy=73.151, wps=12013.7, ups=0.88, wpb=13582.5, bsz=469.7, num_updates=42100, lr=6.89246e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=73, gb_free=13.9, wall=22306
2023-08-29 02:38:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-29 02:38:38 | INFO | train_inner | epoch 036:    534 / 1191 loss=1.795, trans_loss=4.595, nll_loss=1.716, w2v_ctc_loss=0.496, task_loss=2.217, contrastive_loss=0.164, total=6795.4, n_correct=4955.6, ppl=3.28, accuracy=72.926, wps=18720.5, ups=1.38, wpb=13590.8, bsz=472.4, num_updates=42200, lr=6.88428e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=72, gb_free=12.9, wall=22379
2023-08-29 02:39:50 | INFO | train_inner | epoch 036:    634 / 1191 loss=1.783, trans_loss=4.589, nll_loss=1.707, w2v_ctc_loss=0.496, task_loss=2.401, contrastive_loss=0.054, total=6667.35, n_correct=4870.75, ppl=3.27, accuracy=73.054, wps=18470.1, ups=1.39, wpb=13334.7, bsz=440.8, num_updates=42300, lr=6.87614e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=71, gb_free=14.7, wall=22451
2023-08-29 02:41:03 | INFO | train_inner | epoch 036:    734 / 1191 loss=1.789, trans_loss=4.593, nll_loss=1.714, w2v_ctc_loss=0.491, task_loss=2.371, contrastive_loss=0.122, total=6721.83, n_correct=4902.64, ppl=3.28, accuracy=72.936, wps=18617.7, ups=1.38, wpb=13443.7, bsz=450.1, num_updates=42400, lr=6.86803e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=71, gb_free=14.1, wall=22523
2023-08-29 02:42:15 | INFO | train_inner | epoch 036:    834 / 1191 loss=1.785, trans_loss=4.598, nll_loss=1.72, w2v_ctc_loss=0.492, task_loss=2.408, contrastive_loss=0.059, total=6678.35, n_correct=4870.02, ppl=3.29, accuracy=72.923, wps=18391.6, ups=1.38, wpb=13356.7, bsz=447.4, num_updates=42500, lr=6.85994e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=22596
2023-08-29 02:43:27 | INFO | train_inner | epoch 036:    934 / 1191 loss=1.802, trans_loss=4.605, nll_loss=1.728, w2v_ctc_loss=0.501, task_loss=2.544, contrastive_loss=0.146, total=6679.59, n_correct=4854.02, ppl=3.31, accuracy=72.669, wps=18498, ups=1.38, wpb=13359.2, bsz=429.9, num_updates=42600, lr=6.85189e-05, gnorm=0.408, clip=0, loss_scale=32, train_wall=71, gb_free=13.5, wall=22668
2023-08-29 02:44:39 | INFO | train_inner | epoch 036:   1034 / 1191 loss=1.786, trans_loss=4.596, nll_loss=1.718, w2v_ctc_loss=0.495, task_loss=2.244, contrastive_loss=0.084, total=6715.41, n_correct=4894.23, ppl=3.29, accuracy=72.881, wps=18862, ups=1.4, wpb=13430.8, bsz=465.8, num_updates=42700, lr=6.84386e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=70, gb_free=15.1, wall=22739
2023-08-29 02:45:51 | INFO | train_inner | epoch 036:   1134 / 1191 loss=1.794, trans_loss=4.602, nll_loss=1.726, w2v_ctc_loss=0.506, task_loss=2.486, contrastive_loss=0.058, total=6605.28, n_correct=4801.65, ppl=3.31, accuracy=72.694, wps=18317, ups=1.39, wpb=13210.6, bsz=432.4, num_updates=42800, lr=6.83586e-05, gnorm=0.403, clip=0, loss_scale=32, train_wall=71, gb_free=13.8, wall=22811
2023-08-29 02:46:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 02:47:05 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.943 | trans_loss 5.179 | nll_loss 2.383 | w2v_ctc_loss 1.281 | task_loss 8.597 | contrastive_loss 0.245 | total 6138.43 | n_correct 4169.29 | ppl 5.22 | accuracy 67.921 | uer 16.455 | wer 18.315 | raw_wer 18.315 | bleu 27.24 | wps 1654.2 | wpb 6138.4 | bsz 201.1 | num_updates 42857 | best_bleu 27.64
2023-08-29 02:47:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42857 updates
2023-08-29 02:47:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 02:47:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 02:47:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 36 @ 42857 updates, score 27.24) (writing took 5.825854711001739 seconds)
2023-08-29 02:47:11 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-08-29 02:47:11 | INFO | train | epoch 036 | loss 1.787 | trans_loss 4.591 | nll_loss 1.711 | w2v_ctc_loss 0.494 | task_loss 2.347 | contrastive_loss 0.098 | total 6702.93 | n_correct 4892.56 | ppl 3.27 | accuracy 72.991 | wps 16885.3 | ups 1.26 | wpb 13405.9 | bsz 451.7 | num_updates 42857 | lr 6.83131e-05 | gnorm 0.398 | clip 0 | loss_scale 32 | train_wall 848 | gb_free 12.9 | wall 22892
2023-08-29 02:47:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 02:47:11 | INFO | fairseq.trainer | begin training epoch 37
2023-08-29 02:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 02:47:50 | INFO | train_inner | epoch 037:     43 / 1191 loss=1.792, trans_loss=4.596, nll_loss=1.717, w2v_ctc_loss=0.497, task_loss=2.445, contrastive_loss=0.106, total=6672.81, n_correct=4862.21, ppl=3.29, accuracy=72.866, wps=11189.7, ups=0.84, wpb=13345.6, bsz=440.3, num_updates=42900, lr=6.82789e-05, gnorm=0.407, clip=0, loss_scale=32, train_wall=72, gb_free=15.3, wall=22931
2023-08-29 02:49:02 | INFO | train_inner | epoch 037:    143 / 1191 loss=1.788, trans_loss=4.58, nll_loss=1.696, w2v_ctc_loss=0.489, task_loss=2.224, contrastive_loss=0.179, total=6762.6, n_correct=4948.74, ppl=3.24, accuracy=73.178, wps=18751.1, ups=1.39, wpb=13525.2, bsz=464, num_updates=43000, lr=6.81994e-05, gnorm=0.4, clip=0, loss_scale=32, train_wall=72, gb_free=12.9, wall=23003
2023-08-29 02:50:14 | INFO | train_inner | epoch 037:    243 / 1191 loss=1.781, trans_loss=4.58, nll_loss=1.696, w2v_ctc_loss=0.491, task_loss=2.374, contrastive_loss=0.087, total=6696.92, n_correct=4903.87, ppl=3.24, accuracy=73.226, wps=18723.3, ups=1.4, wpb=13393.8, bsz=449.2, num_updates=43100, lr=6.81203e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=71, gb_free=11.8, wall=23074
2023-08-29 02:51:26 | INFO | train_inner | epoch 037:    343 / 1191 loss=1.781, trans_loss=4.579, nll_loss=1.695, w2v_ctc_loss=0.493, task_loss=2.407, contrastive_loss=0.08, total=6637.72, n_correct=4859.12, ppl=3.24, accuracy=73.205, wps=18416.2, ups=1.39, wpb=13275.4, bsz=440.5, num_updates=43200, lr=6.80414e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=71, gb_free=13.7, wall=23146
2023-08-29 02:52:38 | INFO | train_inner | epoch 037:    443 / 1191 loss=1.776, trans_loss=4.576, nll_loss=1.691, w2v_ctc_loss=0.486, task_loss=2.349, contrastive_loss=0.076, total=6703.75, n_correct=4918.41, ppl=3.23, accuracy=73.368, wps=18592.6, ups=1.39, wpb=13407.5, bsz=446.8, num_updates=43300, lr=6.79628e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=71, gb_free=14.6, wall=23219
2023-08-29 02:53:50 | INFO | train_inner | epoch 037:    543 / 1191 loss=1.784, trans_loss=4.585, nll_loss=1.703, w2v_ctc_loss=0.495, task_loss=2.405, contrastive_loss=0.096, total=6639.95, n_correct=4853.24, ppl=3.26, accuracy=73.092, wps=18320.1, ups=1.38, wpb=13279.9, bsz=449.3, num_updates=43400, lr=6.78844e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=23291
2023-08-29 02:55:03 | INFO | train_inner | epoch 037:    643 / 1191 loss=1.788, trans_loss=4.595, nll_loss=1.715, w2v_ctc_loss=0.492, task_loss=2.51, contrastive_loss=0.086, total=6631.82, n_correct=4834.31, ppl=3.28, accuracy=72.896, wps=18250.2, ups=1.38, wpb=13263.6, bsz=428.1, num_updates=43500, lr=6.78064e-05, gnorm=0.403, clip=0, loss_scale=32, train_wall=72, gb_free=12.4, wall=23364
2023-08-29 02:56:15 | INFO | train_inner | epoch 037:    743 / 1191 loss=1.787, trans_loss=4.59, nll_loss=1.71, w2v_ctc_loss=0.494, task_loss=2.336, contrastive_loss=0.103, total=6719.07, n_correct=4907.34, ppl=3.27, accuracy=73.036, wps=18718.4, ups=1.39, wpb=13438.1, bsz=451.8, num_updates=43600, lr=6.77285e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=71, gb_free=13.5, wall=23436
2023-08-29 02:57:28 | INFO | train_inner | epoch 037:    843 / 1191 loss=1.782, trans_loss=4.59, nll_loss=1.71, w2v_ctc_loss=0.487, task_loss=2.244, contrastive_loss=0.102, total=6808.88, n_correct=4977.04, ppl=3.27, accuracy=73.096, wps=18724.8, ups=1.38, wpb=13617.8, bsz=466.8, num_updates=43700, lr=6.7651e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=72, gb_free=14.4, wall=23508
2023-08-29 02:58:40 | INFO | train_inner | epoch 037:    943 / 1191 loss=1.781, trans_loss=4.585, nll_loss=1.705, w2v_ctc_loss=0.484, task_loss=2.058, contrastive_loss=0.136, total=6855.49, n_correct=5013.3, ppl=3.26, accuracy=73.128, wps=18945.3, ups=1.38, wpb=13711, bsz=499.9, num_updates=43800, lr=6.75737e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=72, gb_free=13.2, wall=23581
2023-08-29 02:59:52 | INFO | train_inner | epoch 037:   1043 / 1191 loss=1.784, trans_loss=4.593, nll_loss=1.714, w2v_ctc_loss=0.494, task_loss=2.446, contrastive_loss=0.053, total=6689.96, n_correct=4886.06, ppl=3.28, accuracy=73.036, wps=18487.8, ups=1.38, wpb=13379.9, bsz=441.4, num_updates=43900, lr=6.74967e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=71, gb_free=13.9, wall=23653
2023-08-29 03:01:04 | INFO | train_inner | epoch 037:   1143 / 1191 loss=1.796, trans_loss=4.601, nll_loss=1.725, w2v_ctc_loss=0.498, task_loss=2.431, contrastive_loss=0.127, total=6631.9, n_correct=4827.72, ppl=3.31, accuracy=72.795, wps=18416.7, ups=1.39, wpb=13263.8, bsz=443.6, num_updates=44000, lr=6.742e-05, gnorm=0.405, clip=0, loss_scale=32, train_wall=71, gb_free=14.7, wall=23725
2023-08-29 03:01:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 03:01:37 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.922 | trans_loss 5.174 | nll_loss 2.376 | w2v_ctc_loss 1.228 | task_loss 8.564 | contrastive_loss 0.245 | total 6138.43 | n_correct 4187 | ppl 5.19 | accuracy 68.21 | uer 16.121 | wer 17.899 | raw_wer 17.899 | bleu 27.59 | wps 1718.8 | wpb 6138.4 | bsz 201.1 | num_updates 44000 | best_bleu 27.64
2023-08-29 03:01:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 44000 updates
2023-08-29 03:01:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_37_44000.pt
2023-08-29 03:01:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_37_44000.pt
2023-08-29 03:01:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_37_44000.pt (epoch 37 @ 44000 updates, score 27.59) (writing took 7.848632881999947 seconds)
2023-08-29 03:02:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 03:02:53 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.919 | trans_loss 5.173 | nll_loss 2.377 | w2v_ctc_loss 1.218 | task_loss 8.528 | contrastive_loss 0.246 | total 6138.43 | n_correct 4180.86 | ppl 5.19 | accuracy 68.11 | uer 16.383 | wer 18.141 | raw_wer 18.141 | bleu 27.24 | wps 1690.4 | wpb 6138.4 | bsz 201.1 | num_updates 44048 | best_bleu 27.64
2023-08-29 03:02:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 44048 updates
2023-08-29 03:02:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 03:02:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 03:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 37 @ 44048 updates, score 27.24) (writing took 6.092739692001487 seconds)
2023-08-29 03:02:59 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-08-29 03:02:59 | INFO | train | epoch 037 | loss 1.784 | trans_loss 4.587 | nll_loss 1.705 | w2v_ctc_loss 0.491 | task_loss 2.345 | contrastive_loss 0.1 | total 6703.69 | n_correct 4899.96 | ppl 3.26 | accuracy 73.094 | wps 16850.8 | ups 1.26 | wpb 13407.4 | bsz 452.1 | num_updates 44048 | lr 6.73832e-05 | gnorm 0.398 | clip 0 | loss_scale 32 | train_wall 850 | gb_free 13.7 | wall 23839
2023-08-29 03:02:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 03:02:59 | INFO | fairseq.trainer | begin training epoch 38
2023-08-29 03:02:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 03:03:43 | INFO | train_inner | epoch 038:     52 / 1191 loss=1.782, trans_loss=4.589, nll_loss=1.708, w2v_ctc_loss=0.493, task_loss=2.471, contrastive_loss=0.056, total=6590.11, n_correct=4816.09, ppl=3.27, accuracy=73.081, wps=8295, ups=0.63, wpb=13180.2, bsz=432.1, num_updates=44100, lr=6.73435e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=71, gb_free=12, wall=23884
2023-08-29 03:04:55 | INFO | train_inner | epoch 038:    152 / 1191 loss=1.772, trans_loss=4.569, nll_loss=1.682, w2v_ctc_loss=0.481, task_loss=2.316, contrastive_loss=0.076, total=6707.39, n_correct=4930.22, ppl=3.21, accuracy=73.504, wps=18640.5, ups=1.39, wpb=13414.8, bsz=449.4, num_updates=44200, lr=6.72673e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=71, gb_free=8.2, wall=23956
2023-08-29 03:06:08 | INFO | train_inner | epoch 038:    252 / 1191 loss=1.788, trans_loss=4.58, nll_loss=1.696, w2v_ctc_loss=0.485, task_loss=2.337, contrastive_loss=0.192, total=6683.44, n_correct=4894.67, ppl=3.24, accuracy=73.236, wps=18450.9, ups=1.38, wpb=13366.9, bsz=456.5, num_updates=44300, lr=6.71913e-05, gnorm=0.401, clip=0, loss_scale=64, train_wall=72, gb_free=14, wall=24028
2023-08-29 03:07:20 | INFO | train_inner | epoch 038:    352 / 1191 loss=1.775, trans_loss=4.574, nll_loss=1.689, w2v_ctc_loss=0.491, task_loss=2.413, contrastive_loss=0.058, total=6695.6, n_correct=4914.17, ppl=3.22, accuracy=73.394, wps=18506.5, ups=1.38, wpb=13391.2, bsz=443, num_updates=44400, lr=6.71156e-05, gnorm=0.396, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=24101
2023-08-29 03:08:33 | INFO | train_inner | epoch 038:    452 / 1191 loss=1.778, trans_loss=4.578, nll_loss=1.695, w2v_ctc_loss=0.485, task_loss=2.21, contrastive_loss=0.119, total=6755.69, n_correct=4952.51, ppl=3.24, accuracy=73.309, wps=18549.4, ups=1.37, wpb=13511.4, bsz=476.3, num_updates=44500, lr=6.70402e-05, gnorm=0.398, clip=0, loss_scale=64, train_wall=72, gb_free=13.2, wall=24174
2023-08-29 03:09:45 | INFO | train_inner | epoch 038:    552 / 1191 loss=1.78, trans_loss=4.581, nll_loss=1.698, w2v_ctc_loss=0.484, task_loss=2.269, contrastive_loss=0.114, total=6799.96, n_correct=4986.3, ppl=3.24, accuracy=73.328, wps=18840.6, ups=1.39, wpb=13599.9, bsz=463.7, num_updates=44600, lr=6.6965e-05, gnorm=0.393, clip=0, loss_scale=64, train_wall=71, gb_free=11.9, wall=24246
2023-08-29 03:10:58 | INFO | train_inner | epoch 038:    652 / 1191 loss=1.781, trans_loss=4.587, nll_loss=1.707, w2v_ctc_loss=0.48, task_loss=2.157, contrastive_loss=0.124, total=6826.7, n_correct=4996.97, ppl=3.26, accuracy=73.197, wps=18769.8, ups=1.37, wpb=13653.4, bsz=474.6, num_updates=44700, lr=6.689e-05, gnorm=0.395, clip=0, loss_scale=64, train_wall=72, gb_free=12.1, wall=24319
2023-08-29 03:12:10 | INFO | train_inner | epoch 038:    752 / 1191 loss=1.781, trans_loss=4.586, nll_loss=1.705, w2v_ctc_loss=0.487, task_loss=2.289, contrastive_loss=0.114, total=6730.12, n_correct=4925.7, ppl=3.26, accuracy=73.189, wps=18692.6, ups=1.39, wpb=13460.2, bsz=464.2, num_updates=44800, lr=6.68153e-05, gnorm=0.402, clip=0, loss_scale=64, train_wall=71, gb_free=13.4, wall=24391
2023-08-29 03:13:22 | INFO | train_inner | epoch 038:    852 / 1191 loss=1.782, trans_loss=4.588, nll_loss=1.707, w2v_ctc_loss=0.493, task_loss=2.447, contrastive_loss=0.052, total=6687.39, n_correct=4884.29, ppl=3.26, accuracy=73.037, wps=18487.8, ups=1.38, wpb=13374.8, bsz=435.4, num_updates=44900, lr=6.67409e-05, gnorm=0.397, clip=0, loss_scale=64, train_wall=72, gb_free=11.8, wall=24463
2023-08-29 03:14:35 | INFO | train_inner | epoch 038:    952 / 1191 loss=1.784, trans_loss=4.59, nll_loss=1.71, w2v_ctc_loss=0.492, task_loss=2.367, contrastive_loss=0.076, total=6685.88, n_correct=4883.29, ppl=3.27, accuracy=73.039, wps=18375.8, ups=1.37, wpb=13371.8, bsz=446, num_updates=45000, lr=6.66667e-05, gnorm=0.403, clip=0, loss_scale=64, train_wall=72, gb_free=10.8, wall=24536
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-29 03:15:46 | INFO | train_inner | epoch 038:   1052 / 1191 loss=1.788, trans_loss=4.589, nll_loss=1.709, w2v_ctc_loss=0.495, task_loss=2.459, contrastive_loss=0.107, total=6622.97, n_correct=4836.35, ppl=3.27, accuracy=73.024, wps=18583.1, ups=1.4, wpb=13245.9, bsz=440.1, num_updates=45100, lr=6.65927e-05, gnorm=0.402, clip=0, loss_scale=64, train_wall=71, gb_free=12.4, wall=24607
2023-08-29 03:16:58 | INFO | train_inner | epoch 038:   1152 / 1191 loss=1.78, trans_loss=4.588, nll_loss=1.707, w2v_ctc_loss=0.486, task_loss=2.353, contrastive_loss=0.083, total=6688.64, n_correct=4887.4, ppl=3.26, accuracy=73.07, wps=18565.1, ups=1.39, wpb=13377.3, bsz=448.4, num_updates=45200, lr=6.6519e-05, gnorm=0.402, clip=0, loss_scale=64, train_wall=71, gb_free=13.2, wall=24679
2023-08-29 03:17:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-29 03:17:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
mt_weight tensor(0.5000)
asr_weight tensor(0.2492)
2023-08-29 03:17:58 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 3.921 | trans_loss 5.18 | nll_loss 2.384 | w2v_ctc_loss 1.209 | task_loss 8.576 | contrastive_loss 0.244 | total 6138.43 | n_correct 4173.29 | ppl 5.22 | accuracy 67.986 | uer 16.145 | wer 18.066 | raw_wer 18.066 | bleu 27.6 | wps 1782.5 | wpb 6138.4 | bsz 201.1 | num_updates 45238 | best_bleu 27.64
2023-08-29 03:17:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 45238 updates
2023-08-29 03:17:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.6004.pt
2023-08-29 03:18:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.6004.pt
2023-08-29 03:18:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.6004.pt (epoch 38 @ 45238 updates, score 27.6) (writing took 6.815549646002182 seconds)
2023-08-29 03:18:06 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-08-29 03:18:06 | INFO | train | epoch 038 | loss 1.781 | trans_loss 4.583 | nll_loss 1.701 | w2v_ctc_loss 0.487 | task_loss 2.342 | contrastive_loss 0.099 | total 6704.56 | n_correct 4908.86 | ppl 3.25 | accuracy 73.217 | wps 17589.9 | ups 1.31 | wpb 13409.1 | bsz 452.3 | num_updates 45238 | lr 6.64911e-05 | gnorm 0.398 | clip 0 | loss_scale 32 | train_wall 850 | gb_free 14.1 | wall 24747
2023-08-29 03:18:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 03:18:06 | INFO | fairseq.trainer | begin training epoch 39
2023-08-29 03:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 03:18:59 | INFO | train_inner | epoch 039:     62 / 1191 loss=1.78, trans_loss=4.584, nll_loss=1.701, w2v_ctc_loss=0.489, task_loss=2.649, contrastive_loss=0.058, total=6531.91, n_correct=4785.68, ppl=3.25, accuracy=73.266, wps=10867, ups=0.83, wpb=13063.8, bsz=420.7, num_updates=45300, lr=6.64455e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=72, gb_free=14.4, wall=24799
2023-08-29 03:20:11 | INFO | train_inner | epoch 039:    162 / 1191 loss=1.769, trans_loss=4.565, nll_loss=1.677, w2v_ctc_loss=0.483, task_loss=2.368, contrastive_loss=0.058, total=6693.26, n_correct=4923.18, ppl=3.2, accuracy=73.554, wps=18483, ups=1.38, wpb=13386.5, bsz=442.6, num_updates=45400, lr=6.63723e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=72, gb_free=12.2, wall=24872
2023-08-29 03:21:23 | INFO | train_inner | epoch 039:    262 / 1191 loss=1.781, trans_loss=4.58, nll_loss=1.696, w2v_ctc_loss=0.487, task_loss=2.426, contrastive_loss=0.128, total=6667.98, n_correct=4884.26, ppl=3.24, accuracy=73.249, wps=18461.7, ups=1.38, wpb=13336, bsz=443.1, num_updates=45500, lr=6.62994e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=71, gb_free=13.3, wall=24944
2023-08-29 03:22:36 | INFO | train_inner | epoch 039:    362 / 1191 loss=1.777, trans_loss=4.576, nll_loss=1.691, w2v_ctc_loss=0.487, task_loss=2.555, contrastive_loss=0.079, total=6598.38, n_correct=4839.71, ppl=3.23, accuracy=73.347, wps=18165.6, ups=1.38, wpb=13196.8, bsz=427.5, num_updates=45600, lr=6.62266e-05, gnorm=0.404, clip=0, loss_scale=32, train_wall=72, gb_free=10.6, wall=25017
2023-08-29 03:23:48 | INFO | train_inner | epoch 039:    462 / 1191 loss=1.778, trans_loss=4.576, nll_loss=1.693, w2v_ctc_loss=0.479, task_loss=2.27, contrastive_loss=0.133, total=6750.43, n_correct=4949.59, ppl=3.23, accuracy=73.323, wps=18677.4, ups=1.38, wpb=13500.9, bsz=462.1, num_updates=45700, lr=6.61541e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=71, gb_free=13.7, wall=25089
2023-08-29 03:25:00 | INFO | train_inner | epoch 039:    562 / 1191 loss=1.771, trans_loss=4.572, nll_loss=1.686, w2v_ctc_loss=0.478, task_loss=2.336, contrastive_loss=0.087, total=6701.53, n_correct=4922.72, ppl=3.22, accuracy=73.457, wps=18564.3, ups=1.39, wpb=13403.1, bsz=451.9, num_updates=45800, lr=6.60819e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=71, gb_free=14.1, wall=25161
2023-08-29 03:26:13 | INFO | train_inner | epoch 039:    662 / 1191 loss=1.782, trans_loss=4.584, nll_loss=1.702, w2v_ctc_loss=0.486, task_loss=2.312, contrastive_loss=0.12, total=6717.92, n_correct=4920.39, ppl=3.25, accuracy=73.243, wps=18489.2, ups=1.38, wpb=13435.8, bsz=463.2, num_updates=45900, lr=6.60098e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=72, gb_free=6.4, wall=25234
2023-08-29 03:27:26 | INFO | train_inner | epoch 039:    762 / 1191 loss=1.78, trans_loss=4.583, nll_loss=1.701, w2v_ctc_loss=0.488, task_loss=2.333, contrastive_loss=0.102, total=6736.15, n_correct=4933.62, ppl=3.25, accuracy=73.241, wps=18541.4, ups=1.38, wpb=13472.3, bsz=455.3, num_updates=46000, lr=6.5938e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=72, gb_free=12.9, wall=25306
2023-08-29 03:27:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 03:27:58 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.924 | trans_loss 5.178 | nll_loss 2.381 | w2v_ctc_loss 1.227 | task_loss 8.567 | contrastive_loss 0.242 | total 6138.43 | n_correct 4178 | ppl 5.21 | accuracy 68.063 | uer 16.308 | wer 18.133 | raw_wer 18.133 | bleu 27.48 | wps 1742.7 | wpb 6138.4 | bsz 201.1 | num_updates 46000 | best_bleu 27.64
2023-08-29 03:27:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46000 updates
2023-08-29 03:27:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_39_46000.pt
2023-08-29 03:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_39_46000.pt
2023-08-29 03:28:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_39_46000.pt (epoch 39 @ 46000 updates, score 27.48) (writing took 7.003363991003425 seconds)
2023-08-29 03:29:18 | INFO | train_inner | epoch 039:    862 / 1191 loss=1.778, trans_loss=4.585, nll_loss=1.703, w2v_ctc_loss=0.484, task_loss=2.222, contrastive_loss=0.094, total=6798.2, n_correct=4977.22, ppl=3.26, accuracy=73.214, wps=12145.6, ups=0.89, wpb=13596.4, bsz=472.1, num_updates=46100, lr=6.58665e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=71, gb_free=13.7, wall=25418
2023-08-29 03:30:30 | INFO | train_inner | epoch 039:    962 / 1191 loss=1.772, trans_loss=4.572, nll_loss=1.688, w2v_ctc_loss=0.476, task_loss=2.153, contrastive_loss=0.121, total=6835.31, n_correct=5020.63, ppl=3.22, accuracy=73.451, wps=18981.1, ups=1.39, wpb=13670.6, bsz=480.9, num_updates=46200, lr=6.57952e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=71, gb_free=13.9, wall=25490
2023-08-29 03:31:41 | INFO | train_inner | epoch 039:   1062 / 1191 loss=1.777, trans_loss=4.58, nll_loss=1.697, w2v_ctc_loss=0.481, task_loss=2.277, contrastive_loss=0.104, total=6757.98, n_correct=4953.62, ppl=3.24, accuracy=73.3, wps=18901.5, ups=1.4, wpb=13516, bsz=459.7, num_updates=46300, lr=6.57241e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=71, gb_free=14.5, wall=25562
2023-08-29 03:32:53 | INFO | train_inner | epoch 039:   1162 / 1191 loss=1.786, trans_loss=4.59, nll_loss=1.71, w2v_ctc_loss=0.496, task_loss=2.461, contrastive_loss=0.081, total=6582.59, n_correct=4806.14, ppl=3.27, accuracy=73.013, wps=18357.4, ups=1.39, wpb=13165.2, bsz=428.8, num_updates=46400, lr=6.56532e-05, gnorm=0.407, clip=0, loss_scale=32, train_wall=71, gb_free=14.3, wall=25634
2023-08-29 03:33:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 03:33:46 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.913 | trans_loss 5.178 | nll_loss 2.381 | w2v_ctc_loss 1.193 | task_loss 8.558 | contrastive_loss 0.237 | total 6138.43 | n_correct 4180.29 | ppl 5.21 | accuracy 68.1 | uer 16.129 | wer 18.022 | raw_wer 18.022 | bleu 27.72 | wps 1738.2 | wpb 6138.4 | bsz 201.1 | num_updates 46429 | best_bleu 27.72
2023-08-29 03:33:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46429 updates
2023-08-29 03:33:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-29 03:33:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt
2023-08-29 03:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_best.pt (epoch 39 @ 46429 updates, score 27.72) (writing took 11.05220546300552 seconds)
2023-08-29 03:33:57 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-08-29 03:33:57 | INFO | train | epoch 039 | loss 1.777 | trans_loss 4.578 | nll_loss 1.695 | w2v_ctc_loss 0.484 | task_loss 2.345 | contrastive_loss 0.098 | total 6703.69 | n_correct 4915 | ppl 3.24 | accuracy 73.318 | wps 16780.3 | ups 1.25 | wpb 13407.4 | bsz 452.1 | num_updates 46429 | lr 6.56327e-05 | gnorm 0.398 | clip 0 | loss_scale 32 | train_wall 850 | gb_free 13.3 | wall 25698
2023-08-29 03:33:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 03:33:58 | INFO | fairseq.trainer | begin training epoch 40
2023-08-29 03:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 03:34:55 | INFO | train_inner | epoch 040:     71 / 1191 loss=1.765, trans_loss=4.562, nll_loss=1.673, w2v_ctc_loss=0.475, task_loss=2.232, contrastive_loss=0.084, total=6767.38, n_correct=4985.93, ppl=3.19, accuracy=73.676, wps=11045.1, ups=0.82, wpb=13534.8, bsz=468.9, num_updates=46500, lr=6.55826e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=71, gb_free=13.4, wall=25756
2023-08-29 03:36:07 | INFO | train_inner | epoch 040:    171 / 1191 loss=1.766, trans_loss=4.562, nll_loss=1.673, w2v_ctc_loss=0.484, task_loss=2.334, contrastive_loss=0.049, total=6723.92, n_correct=4957.49, ppl=3.19, accuracy=73.729, wps=18737.5, ups=1.39, wpb=13447.8, bsz=450.2, num_updates=46600, lr=6.55122e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=71, gb_free=14.1, wall=25828
2023-08-29 03:37:20 | INFO | train_inner | epoch 040:    271 / 1191 loss=1.767, trans_loss=4.565, nll_loss=1.677, w2v_ctc_loss=0.477, task_loss=2.225, contrastive_loss=0.083, total=6753.31, n_correct=4969.07, ppl=3.2, accuracy=73.58, wps=18595.3, ups=1.38, wpb=13506.6, bsz=465.8, num_updates=46700, lr=6.5442e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=72, gb_free=15, wall=25901
2023-08-29 03:38:33 | INFO | train_inner | epoch 040:    371 / 1191 loss=1.778, trans_loss=4.573, nll_loss=1.687, w2v_ctc_loss=0.484, task_loss=2.495, contrastive_loss=0.109, total=6618.47, n_correct=4858.79, ppl=3.22, accuracy=73.413, wps=18213.7, ups=1.38, wpb=13236.9, bsz=438.2, num_updates=46800, lr=6.5372e-05, gnorm=0.407, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=25973
2023-08-29 03:39:44 | INFO | train_inner | epoch 040:    471 / 1191 loss=1.77, trans_loss=4.574, nll_loss=1.689, w2v_ctc_loss=0.485, task_loss=2.314, contrastive_loss=0.051, total=6719.05, n_correct=4936.54, ppl=3.22, accuracy=73.471, wps=18784.1, ups=1.4, wpb=13438.1, bsz=454.8, num_updates=46900, lr=6.53023e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=71, gb_free=14, wall=26045
2023-08-29 03:40:56 | INFO | train_inner | epoch 040:    571 / 1191 loss=1.775, trans_loss=4.574, nll_loss=1.689, w2v_ctc_loss=0.474, task_loss=2.287, contrastive_loss=0.158, total=6684.61, n_correct=4914.75, ppl=3.23, accuracy=73.523, wps=18593.5, ups=1.39, wpb=13369.2, bsz=455.8, num_updates=47000, lr=6.52328e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=71, gb_free=12.1, wall=26117
2023-08-29 03:42:09 | INFO | train_inner | epoch 040:    671 / 1191 loss=1.787, trans_loss=4.581, nll_loss=1.698, w2v_ctc_loss=0.487, task_loss=2.372, contrastive_loss=0.165, total=6699.46, n_correct=4903.74, ppl=3.24, accuracy=73.196, wps=18380.8, ups=1.37, wpb=13398.9, bsz=447.6, num_updates=47100, lr=6.51635e-05, gnorm=0.403, clip=0, loss_scale=32, train_wall=72, gb_free=7.9, wall=26190
2023-08-29 03:43:21 | INFO | train_inner | epoch 040:    771 / 1191 loss=1.776, trans_loss=4.58, nll_loss=1.696, w2v_ctc_loss=0.489, task_loss=2.408, contrastive_loss=0.062, total=6659.73, n_correct=4881.99, ppl=3.24, accuracy=73.306, wps=18499.1, ups=1.39, wpb=13319.5, bsz=443.6, num_updates=47200, lr=6.50945e-05, gnorm=0.403, clip=0, loss_scale=32, train_wall=71, gb_free=12.5, wall=26262
2023-08-29 03:44:34 | INFO | train_inner | epoch 040:    871 / 1191 loss=1.782, trans_loss=4.583, nll_loss=1.702, w2v_ctc_loss=0.49, task_loss=2.429, contrastive_loss=0.092, total=6696.57, n_correct=4903.07, ppl=3.25, accuracy=73.218, wps=18353, ups=1.37, wpb=13393.1, bsz=441.7, num_updates=47300, lr=6.50256e-05, gnorm=0.402, clip=0, loss_scale=64, train_wall=72, gb_free=14.4, wall=26335
2023-08-29 03:45:46 | INFO | train_inner | epoch 040:    971 / 1191 loss=1.782, trans_loss=4.585, nll_loss=1.704, w2v_ctc_loss=0.484, task_loss=2.297, contrastive_loss=0.127, total=6694.1, n_correct=4902.63, ppl=3.26, accuracy=73.238, wps=18706, ups=1.4, wpb=13388.2, bsz=455.1, num_updates=47400, lr=6.4957e-05, gnorm=0.403, clip=0, loss_scale=64, train_wall=71, gb_free=10.4, wall=26406
2023-08-29 03:46:58 | INFO | train_inner | epoch 040:   1071 / 1191 loss=1.78, trans_loss=4.583, nll_loss=1.702, w2v_ctc_loss=0.492, task_loss=2.342, contrastive_loss=0.082, total=6744.49, n_correct=4937.45, ppl=3.25, accuracy=73.207, wps=18486.1, ups=1.37, wpb=13489, bsz=455.8, num_updates=47500, lr=6.48886e-05, gnorm=0.397, clip=0, loss_scale=64, train_wall=72, gb_free=12.9, wall=26479
2023-08-29 03:47:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-29 03:48:11 | INFO | train_inner | epoch 040:   1172 / 1191 loss=1.776, trans_loss=4.58, nll_loss=1.698, w2v_ctc_loss=0.479, task_loss=2.272, contrastive_loss=0.113, total=6710.8, n_correct=4917.86, ppl=3.24, accuracy=73.283, wps=18513.3, ups=1.38, wpb=13421.6, bsz=463.1, num_updates=47600, lr=6.48204e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=72, gb_free=12.9, wall=26552
2023-08-29 03:48:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 03:48:58 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 3.918 | trans_loss 5.175 | nll_loss 2.378 | w2v_ctc_loss 1.215 | task_loss 8.539 | contrastive_loss 0.237 | total 6138.43 | n_correct 4185 | ppl 5.2 | accuracy 68.177 | uer 15.955 | wer 17.839 | raw_wer 17.839 | bleu 27.54 | wps 1696.6 | wpb 6138.4 | bsz 201.1 | num_updates 47619 | best_bleu 27.72
2023-08-29 03:48:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 47619 updates
2023-08-29 03:48:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.5409.pt
2023-08-29 03:49:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.5409.pt
2023-08-29 03:49:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint.best_bleu_27.5409.pt (epoch 40 @ 47619 updates, score 27.54) (writing took 10.05033118600113 seconds)
2023-08-29 03:49:08 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-08-29 03:49:08 | INFO | train | epoch 040 | loss 1.776 | trans_loss 4.575 | nll_loss 1.691 | w2v_ctc_loss 0.484 | task_loss 2.341 | contrastive_loss 0.098 | total 6704.54 | n_correct 4921.02 | ppl 3.23 | accuracy 73.398 | wps 17520.2 | ups 1.31 | wpb 13409.1 | bsz 452.3 | num_updates 47619 | lr 6.48074e-05 | gnorm 0.399 | clip 0 | loss_scale 32 | train_wall 850 | gb_free 12.3 | wall 26609
2023-08-29 03:49:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 03:49:08 | INFO | fairseq.trainer | begin training epoch 41
2023-08-29 03:49:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 03:50:14 | INFO | train_inner | epoch 041:     81 / 1191 loss=1.769, trans_loss=4.565, nll_loss=1.678, w2v_ctc_loss=0.474, task_loss=2.306, contrastive_loss=0.117, total=6722.93, n_correct=4951.86, ppl=3.2, accuracy=73.656, wps=10950.9, ups=0.81, wpb=13445.9, bsz=464.5, num_updates=47700, lr=6.47524e-05, gnorm=0.402, clip=0, loss_scale=32, train_wall=71, gb_free=14.2, wall=26674
2023-08-29 03:51:25 | INFO | train_inner | epoch 041:    181 / 1191 loss=1.776, trans_loss=4.565, nll_loss=1.676, w2v_ctc_loss=0.477, task_loss=2.398, contrastive_loss=0.148, total=6672.05, n_correct=4908.98, ppl=3.2, accuracy=73.575, wps=18649.7, ups=1.4, wpb=13344.1, bsz=445, num_updates=47800, lr=6.46846e-05, gnorm=0.405, clip=0, loss_scale=32, train_wall=71, gb_free=11.8, wall=26746
2023-08-29 03:52:38 | INFO | train_inner | epoch 041:    281 / 1191 loss=1.767, trans_loss=4.565, nll_loss=1.679, w2v_ctc_loss=0.473, task_loss=2.196, contrastive_loss=0.103, total=6804.18, n_correct=5012.85, ppl=3.2, accuracy=73.673, wps=18746, ups=1.38, wpb=13608.4, bsz=478.8, num_updates=47900, lr=6.46171e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=72, gb_free=13.2, wall=26819
2023-08-29 03:53:50 | INFO | train_inner | epoch 041:    381 / 1191 loss=1.764, trans_loss=4.564, nll_loss=1.676, w2v_ctc_loss=0.478, task_loss=2.263, contrastive_loss=0.052, total=6779.91, n_correct=4992.81, ppl=3.2, accuracy=73.641, wps=18685.5, ups=1.38, wpb=13559.8, bsz=459.7, num_updates=48000, lr=6.45497e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=26891
2023-08-29 03:53:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 03:54:23 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.928 | trans_loss 5.182 | nll_loss 2.384 | w2v_ctc_loss 1.231 | task_loss 8.578 | contrastive_loss 0.242 | total 6138.43 | n_correct 4181.86 | ppl 5.22 | accuracy 68.126 | uer 16.094 | wer 17.932 | raw_wer 17.932 | bleu 27.49 | wps 1697 | wpb 6138.4 | bsz 201.1 | num_updates 48000 | best_bleu 27.72
2023-08-29 03:54:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48000 updates
2023-08-29 03:54:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_41_48000.pt
2023-08-29 03:54:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_41_48000.pt
2023-08-29 03:54:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_41_48000.pt (epoch 41 @ 48000 updates, score 27.49) (writing took 5.981228775999625 seconds)
2023-08-29 03:55:41 | INFO | train_inner | epoch 041:    481 / 1191 loss=1.766, trans_loss=4.567, nll_loss=1.68, w2v_ctc_loss=0.482, task_loss=2.257, contrastive_loss=0.049, total=6790.05, n_correct=5000.7, ppl=3.2, accuracy=73.647, wps=12248.6, ups=0.9, wpb=13580.1, bsz=461.9, num_updates=48100, lr=6.44826e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=71, gb_free=12.5, wall=27002
2023-08-29 03:56:53 | INFO | train_inner | epoch 041:    581 / 1191 loss=1.763, trans_loss=4.563, nll_loss=1.675, w2v_ctc_loss=0.47, task_loss=2.247, contrastive_loss=0.07, total=6773.53, n_correct=4992.57, ppl=3.19, accuracy=73.707, wps=18948.1, ups=1.4, wpb=13547.1, bsz=458, num_updates=48200, lr=6.44157e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=71, gb_free=11.2, wall=27074
2023-08-29 03:58:05 | INFO | train_inner | epoch 041:    681 / 1191 loss=1.774, trans_loss=4.572, nll_loss=1.686, w2v_ctc_loss=0.485, task_loss=2.363, contrastive_loss=0.094, total=6677.75, n_correct=4902.18, ppl=3.22, accuracy=73.411, wps=18539.9, ups=1.39, wpb=13355.5, bsz=448.7, num_updates=48300, lr=6.43489e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=71, gb_free=10.6, wall=27146
2023-08-29 03:59:17 | INFO | train_inner | epoch 041:    781 / 1191 loss=1.776, trans_loss=4.575, nll_loss=1.691, w2v_ctc_loss=0.485, task_loss=2.565, contrastive_loss=0.083, total=6547.43, n_correct=4805.35, ppl=3.23, accuracy=73.393, wps=18064.6, ups=1.38, wpb=13094.9, bsz=422.4, num_updates=48400, lr=6.42824e-05, gnorm=0.405, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=27218
2023-08-29 04:00:30 | INFO | train_inner | epoch 041:    881 / 1191 loss=1.778, trans_loss=4.576, nll_loss=1.692, w2v_ctc_loss=0.486, task_loss=2.512, contrastive_loss=0.089, total=6581.95, n_correct=4831.22, ppl=3.23, accuracy=73.401, wps=18106.2, ups=1.38, wpb=13163.9, bsz=427.6, num_updates=48500, lr=6.42161e-05, gnorm=0.406, clip=0, loss_scale=32, train_wall=72, gb_free=10.7, wall=27291
2023-08-29 04:01:43 | INFO | train_inner | epoch 041:    981 / 1191 loss=1.781, trans_loss=4.581, nll_loss=1.698, w2v_ctc_loss=0.485, task_loss=2.444, contrastive_loss=0.116, total=6677.96, n_correct=4887.84, ppl=3.25, accuracy=73.194, wps=18306.6, ups=1.37, wpb=13355.9, bsz=444.6, num_updates=48600, lr=6.415e-05, gnorm=0.405, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=27364
2023-08-29 04:02:55 | INFO | train_inner | epoch 041:   1081 / 1191 loss=1.771, trans_loss=4.576, nll_loss=1.693, w2v_ctc_loss=0.476, task_loss=2.174, contrastive_loss=0.108, total=6841.34, n_correct=5022.84, ppl=3.23, accuracy=73.419, wps=18909.6, ups=1.38, wpb=13682.7, bsz=478.7, num_updates=48700, lr=6.40841e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=72, gb_free=14.4, wall=27436
2023-08-29 04:04:07 | INFO | train_inner | epoch 041:   1181 / 1191 loss=1.781, trans_loss=4.582, nll_loss=1.699, w2v_ctc_loss=0.484, task_loss=2.48, contrastive_loss=0.133, total=6589.42, n_correct=4829.54, ppl=3.25, accuracy=73.292, wps=18358.9, ups=1.39, wpb=13178.8, bsz=431.4, num_updates=48800, lr=6.40184e-05, gnorm=0.405, clip=0, loss_scale=32, train_wall=71, gb_free=13.4, wall=27508
2023-08-29 04:04:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 04:04:47 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.92 | trans_loss 5.179 | nll_loss 2.383 | w2v_ctc_loss 1.209 | task_loss 8.572 | contrastive_loss 0.243 | total 6138.43 | n_correct 4180.43 | ppl 5.22 | accuracy 68.103 | uer 16.292 | wer 18.248 | raw_wer 18.248 | bleu 27.47 | wps 1689.7 | wpb 6138.4 | bsz 201.1 | num_updates 48810 | best_bleu 27.72
2023-08-29 04:04:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48810 updates
2023-08-29 04:04:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 04:04:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt
2023-08-29 04:04:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_last.pt (epoch 41 @ 48810 updates, score 27.47) (writing took 6.170671715000935 seconds)
2023-08-29 04:04:53 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-08-29 04:04:53 | INFO | train | epoch 041 | loss 1.772 | trans_loss 4.571 | nll_loss 1.685 | w2v_ctc_loss 0.48 | task_loss 2.343 | contrastive_loss 0.097 | total 6703.69 | n_correct 4927.63 | ppl 3.22 | accuracy 73.506 | wps 16895 | ups 1.26 | wpb 13407.4 | bsz 452.1 | num_updates 48810 | lr 6.40119e-05 | gnorm 0.4 | clip 0 | loss_scale 32 | train_wall 850 | gb_free 11.5 | wall 27554
2023-08-29 04:04:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-29 04:04:54 | INFO | fairseq.trainer | begin training epoch 42
2023-08-29 04:04:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-29 04:06:05 | INFO | train_inner | epoch 042:     90 / 1191 loss=1.76, trans_loss=4.551, nll_loss=1.66, w2v_ctc_loss=0.467, task_loss=2.109, contrastive_loss=0.117, total=6824.86, n_correct=5049.72, ppl=3.16, accuracy=73.99, wps=11561, ups=0.85, wpb=13649.7, bsz=483.3, num_updates=48900, lr=6.39529e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=70, gb_free=13.9, wall=27626
2023-08-29 04:07:18 | INFO | train_inner | epoch 042:    190 / 1191 loss=1.776, trans_loss=4.564, nll_loss=1.676, w2v_ctc_loss=0.476, task_loss=2.424, contrastive_loss=0.171, total=6671.53, n_correct=4905.97, ppl=3.19, accuracy=73.536, wps=18425.5, ups=1.38, wpb=13343.1, bsz=441.1, num_updates=49000, lr=6.38877e-05, gnorm=0.402, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=27698
2023-08-29 04:08:30 | INFO | train_inner | epoch 042:    290 / 1191 loss=1.767, trans_loss=4.558, nll_loss=1.668, w2v_ctc_loss=0.479, task_loss=2.398, contrastive_loss=0.097, total=6650.86, n_correct=4906.2, ppl=3.18, accuracy=73.768, wps=18287.3, ups=1.37, wpb=13301.7, bsz=445.5, num_updates=49100, lr=6.38226e-05, gnorm=0.402, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=27771
2023-08-29 04:09:42 | INFO | train_inner | epoch 042:    390 / 1191 loss=1.767, trans_loss=4.564, nll_loss=1.676, w2v_ctc_loss=0.478, task_loss=2.403, contrastive_loss=0.087, total=6626.36, n_correct=4881.49, ppl=3.19, accuracy=73.668, wps=18422.9, ups=1.39, wpb=13252.7, bsz=447.3, num_updates=49200, lr=6.37577e-05, gnorm=0.404, clip=0, loss_scale=32, train_wall=71, gb_free=14.1, wall=27843
2023-08-29 04:10:55 | INFO | train_inner | epoch 042:    490 / 1191 loss=1.769, trans_loss=4.571, nll_loss=1.685, w2v_ctc_loss=0.477, task_loss=2.627, contrastive_loss=0.046, total=6622.87, n_correct=4865.98, ppl=3.21, accuracy=73.472, wps=18245.4, ups=1.38, wpb=13245.7, bsz=418.4, num_updates=49300, lr=6.3693e-05, gnorm=0.4, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=27916
2023-08-29 04:12:07 | INFO | train_inner | epoch 042:    590 / 1191 loss=1.781, trans_loss=4.578, nll_loss=1.694, w2v_ctc_loss=0.488, task_loss=2.506, contrastive_loss=0.126, total=6598.24, n_correct=4837.77, ppl=3.24, accuracy=73.319, wps=18228.8, ups=1.38, wpb=13196.5, bsz=431.9, num_updates=49400, lr=6.36285e-05, gnorm=0.411, clip=0, loss_scale=32, train_wall=72, gb_free=12.3, wall=27988
2023-08-29 04:13:19 | INFO | train_inner | epoch 042:    690 / 1191 loss=1.765, trans_loss=4.565, nll_loss=1.679, w2v_ctc_loss=0.468, task_loss=2.141, contrastive_loss=0.107, total=6827.49, n_correct=5030.9, ppl=3.2, accuracy=73.686, wps=18990.8, ups=1.39, wpb=13655, bsz=480.8, num_updates=49500, lr=6.35642e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=71, gb_free=8.7, wall=28060
2023-08-29 04:14:32 | INFO | train_inner | epoch 042:    790 / 1191 loss=1.772, trans_loss=4.576, nll_loss=1.693, w2v_ctc_loss=0.479, task_loss=2.248, contrastive_loss=0.092, total=6715.54, n_correct=4936.68, ppl=3.23, accuracy=73.511, wps=18606.6, ups=1.39, wpb=13431.1, bsz=463.9, num_updates=49600, lr=6.35001e-05, gnorm=0.399, clip=0, loss_scale=32, train_wall=72, gb_free=13.4, wall=28132
2023-08-29 04:15:43 | INFO | train_inner | epoch 042:    890 / 1191 loss=1.764, trans_loss=4.564, nll_loss=1.677, w2v_ctc_loss=0.476, task_loss=2.406, contrastive_loss=0.055, total=6567.62, n_correct=4834.19, ppl=3.2, accuracy=73.606, wps=18430.2, ups=1.4, wpb=13135.2, bsz=440.7, num_updates=49700, lr=6.34361e-05, gnorm=0.404, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=28203
2023-08-29 04:16:55 | INFO | train_inner | epoch 042:    990 / 1191 loss=1.77, trans_loss=4.57, nll_loss=1.685, w2v_ctc_loss=0.474, task_loss=2.129, contrastive_loss=0.128, total=6827.16, n_correct=5019.39, ppl=3.22, accuracy=73.521, wps=18876.8, ups=1.38, wpb=13654.3, bsz=484, num_updates=49800, lr=6.33724e-05, gnorm=0.397, clip=0, loss_scale=64, train_wall=72, gb_free=14.7, wall=28276
2023-08-29 04:18:07 | INFO | train_inner | epoch 042:   1090 / 1191 loss=1.768, trans_loss=4.571, nll_loss=1.685, w2v_ctc_loss=0.476, task_loss=2.553, contrastive_loss=0.042, total=6664.62, n_correct=4903.23, ppl=3.21, accuracy=73.571, wps=18534.6, ups=1.39, wpb=13329.2, bsz=421.6, num_updates=49900, lr=6.33089e-05, gnorm=0.399, clip=0, loss_scale=64, train_wall=71, gb_free=13.7, wall=28348
2023-08-29 04:19:20 | INFO | train_inner | epoch 042:   1190 / 1191 loss=1.769, trans_loss=4.573, nll_loss=1.688, w2v_ctc_loss=0.48, task_loss=2.263, contrastive_loss=0.073, total=6824.38, n_correct=5019.59, ppl=3.22, accuracy=73.554, wps=18734.4, ups=1.37, wpb=13648.8, bsz=463.9, num_updates=50000, lr=6.32456e-05, gnorm=0.395, clip=0, loss_scale=64, train_wall=72, gb_free=14.4, wall=28421
2023-08-29 04:19:20 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-29 04:19:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-29 04:19:53 | INFO | dev_st | epoch 042 | valid on 'dev_st' subset | loss 3.917 | trans_loss 5.176 | nll_loss 2.38 | w2v_ctc_loss 1.208 | task_loss 8.56 | contrastive_loss 0.236 | total 6138.43 | n_correct 4184.14 | ppl 5.2 | accuracy 68.163 | uer 15.987 | wer 17.787 | raw_wer 17.787 | bleu 27.69 | wps 1725 | wpb 6138.4 | bsz 201.1 | num_updates 50000 | best_bleu 27.72
2023-08-29 04:19:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 50000 updates
2023-08-29 04:19:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_42_50000.pt
2023-08-29 04:19:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_42_50000.pt
2023-08-29 04:20:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_mustc_0827_both_topCL_AT_sentence_mixup0307_scale2.5_alpha1.5_mt0.5_nograd/checkpoint_42_50000.pt (epoch 42 @ 50000 updates, score 27.69) (writing took 7.443422398006078 seconds)
2023-08-29 04:20:01 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-08-29 04:20:01 | INFO | train | epoch 042 | loss 1.769 | trans_loss 4.567 | nll_loss 1.681 | w2v_ctc_loss 0.476 | task_loss 2.34 | contrastive_loss 0.096 | total 6705.54 | n_correct 4935.45 | ppl 3.21 | accuracy 73.603 | wps 17586 | ups 1.31 | wpb 13411.1 | bsz 452.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.4 | clip 0 | loss_scale 64 | train_wall 850 | gb_free 14.4 | wall 28462
2023-08-29 04:20:01 | INFO | fairseq_cli.train | done training in 28384.2 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1232 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
