2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11458
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11458
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11458
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11458
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11458
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11458
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11458
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11458
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 16:21:00 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-21 16:21:00 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-21 16:21:04 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11458', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-21 16:21:04 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-21 16:21:04 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-21 16:21:04 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-21 16:21:04 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-21 16:21:04 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-21 16:21:08 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-21 16:21:08 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-21 16:21:08 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-21 16:21:10 | INFO | root | load pretrained hubert
2023-08-21 16:21:18 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-21 16:21:21 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-21 16:21:28 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-21 16:21:28 | INFO | root | share the sematic adapter and textual encoder
2023-08-21 16:21:28 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-21 16:21:28 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-21 16:21:28 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-21 16:21:28 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-21 16:21:28 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-21 16:21:28 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-21 16:21:28 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-21 16:21:28 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-21 16:21:28 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-21 16:21:28 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-21 16:21:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-21 16:21:43 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-21 16:21:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-21 16:21:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-21 16:21:44 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 16:21:44 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 16:21:44 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 16:21:44 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 16:21:44 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 16:21:44 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 16:21:44 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 16:21:44 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 16:21:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-21 16:21:44 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-21 16:21:44 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-21 16:21:44 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-21 16:21:44 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-21 16:21:44 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-21 16:21:44 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-21 16:21:44 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-21 16:21:44 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-21 16:21:46 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-21 16:21:48 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-21 16:22:40 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-21 16:22:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 837
2023-08-21 16:22:40 | INFO | fairseq.trainer | begin training epoch 1
2023-08-21 16:22:40 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
2023-08-21 16:22:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
2023-08-21 16:24:06 | INFO | train_inner | epoch 001:    101 / 837 loss=19.916, trans_loss=5.222, nll_loss=3.728, w2v_ctc_loss=21.872, task_loss=0, contrastive_loss=3.944, total=9583.54, n_correct=706.66, ppl=13.25, accuracy=7.374, wps=37730, ups=1.36, wpb=27766.2, bsz=981.8, num_updates=100, lr=4.098e-06, gnorm=1.277, clip=0, loss_scale=64, train_wall=77, gb_free=16.9, wall=142
2023-08-21 16:24:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-21 16:25:20 | INFO | train_inner | epoch 001:    202 / 837 loss=18.249, trans_loss=5.223, nll_loss=3.784, w2v_ctc_loss=19.238, task_loss=0, contrastive_loss=3.931, total=9541.19, n_correct=696.06, ppl=13.78, accuracy=7.295, wps=37522, ups=1.36, wpb=27657.7, bsz=976.6, num_updates=200, lr=8.096e-06, gnorm=4.194, clip=0, loss_scale=32, train_wall=73, gb_free=16.5, wall=216
2023-08-21 16:26:34 | INFO | train_inner | epoch 001:    302 / 837 loss=10.842, trans_loss=5.626, nll_loss=4.297, w2v_ctc_loss=7.419, task_loss=0, contrastive_loss=3.966, total=9526.68, n_correct=506.53, ppl=19.66, accuracy=5.317, wps=37218.2, ups=1.35, wpb=27584.6, bsz=953.5, num_updates=300, lr=1.2094e-05, gnorm=2.814, clip=0, loss_scale=32, train_wall=74, gb_free=17, wall=290
2023-08-21 16:27:47 | INFO | train_inner | epoch 001:    402 / 837 loss=9.931, trans_loss=5.555, nll_loss=4.234, w2v_ctc_loss=5.968, task_loss=0, contrastive_loss=4.036, total=9650.84, n_correct=495.38, ppl=18.82, accuracy=5.133, wps=38433.2, ups=1.37, wpb=27967.8, bsz=1001.3, num_updates=400, lr=1.6092e-05, gnorm=0.593, clip=0, loss_scale=32, train_wall=72, gb_free=17.3, wall=363
2023-08-21 16:28:59 | INFO | train_inner | epoch 001:    502 / 837 loss=9.677, trans_loss=5.551, nll_loss=4.246, w2v_ctc_loss=5.656, task_loss=0, contrastive_loss=3.982, total=9626.49, n_correct=469.09, ppl=18.97, accuracy=4.873, wps=38360, ups=1.38, wpb=27889.6, bsz=974.9, num_updates=500, lr=2.009e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=72, gb_free=16.5, wall=435
2023-08-21 16:30:12 | INFO | train_inner | epoch 001:    602 / 837 loss=9.552, trans_loss=5.642, nll_loss=4.362, w2v_ctc_loss=5.489, task_loss=0, contrastive_loss=3.9, total=9439.45, n_correct=395.34, ppl=20.57, accuracy=4.188, wps=37416.5, ups=1.37, wpb=27339.8, bsz=931.4, num_updates=600, lr=2.4088e-05, gnorm=0.273, clip=0, loss_scale=32, train_wall=72, gb_free=16.5, wall=509
2023-08-21 16:31:27 | INFO | train_inner | epoch 001:    702 / 837 loss=9.481, trans_loss=5.735, nll_loss=4.476, w2v_ctc_loss=5.307, task_loss=0, contrastive_loss=3.84, total=9441.26, n_correct=382.62, ppl=22.26, accuracy=4.053, wps=36508.6, ups=1.33, wpb=27370, bsz=925.7, num_updates=700, lr=2.8086e-05, gnorm=0.283, clip=0, loss_scale=32, train_wall=74, gb_free=17.5, wall=583
2023-08-21 16:31:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-21 16:32:47 | INFO | train_inner | epoch 001:    803 / 837 loss=9.247, trans_loss=5.757, nll_loss=4.495, w2v_ctc_loss=4.934, task_loss=0, contrastive_loss=3.877, total=9590.31, n_correct=424.52, ppl=22.55, accuracy=4.427, wps=34866.5, ups=1.25, wpb=27786.8, bsz=981.4, num_updates=800, lr=3.2084e-05, gnorm=0.34, clip=0, loss_scale=16, train_wall=76, gb_free=16.9, wall=663
2023-08-21 16:33:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-21 16:33:55 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 12.374 | trans_loss 12.071 | nll_loss 11.337 | w2v_ctc_loss 6.561 | task_loss 0 | contrastive_loss 5.494 | total 8593.8 | n_correct 514.4 | ppl 2587.53 | accuracy 5.986 | uer 84.24 | wer 82.555 | raw_wer 82.555 | bleu 0 | wps 1264.4 | wpb 8593.8 | bsz 281.6 | num_updates 834
2023-08-21 16:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 834 updates
2023-08-21 16:33:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 16:33:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 16:34:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 834 updates, score 0.0) (writing took 5.027287843055092 seconds)
2023-08-21 16:34:00 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-21 16:34:00 | INFO | train | epoch 001 | loss 11.992 | trans_loss 5.546 | nll_loss 4.213 | w2v_ctc_loss 9.302 | task_loss 0 | contrastive_loss 3.932 | total 9536.83 | n_correct 508.129 | ppl 18.54 | accuracy 5.328 | wps 34532.9 | ups 1.25 | wpb 27631.3 | bsz 964 | num_updates 834 | lr 3.34433e-05 | gnorm 1.232 | clip 0 | loss_scale 16 | train_wall 613 | gb_free 16.7 | wall 736
2023-08-21 16:34:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 837
2023-08-21 16:34:00 | INFO | fairseq.trainer | begin training epoch 2
2023-08-21 16:34:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 16:34:55 | INFO | train_inner | epoch 002:     66 / 837 loss=8.897, trans_loss=5.702, nll_loss=4.421, w2v_ctc_loss=4.531, task_loss=0, contrastive_loss=3.846, total=9525.3, n_correct=516.04, ppl=21.42, accuracy=5.418, wps=21492.2, ups=0.78, wpb=27573.5, bsz=996.5, num_updates=900, lr=3.6082e-05, gnorm=0.37, clip=0, loss_scale=16, train_wall=70, gb_free=17.3, wall=791
2023-08-21 16:36:07 | INFO | train_inner | epoch 002:    166 / 837 loss=8.559, trans_loss=5.683, nll_loss=4.395, w2v_ctc_loss=4.253, task_loss=0, contrastive_loss=3.595, total=9451.32, n_correct=548.74, ppl=21.05, accuracy=5.806, wps=38178.4, ups=1.39, wpb=27387.8, bsz=923, num_updates=1000, lr=4.008e-05, gnorm=0.448, clip=0, loss_scale=16, train_wall=71, gb_free=17.4, wall=863
2023-08-21 16:37:19 | INFO | train_inner | epoch 002:    266 / 837 loss=8.301, trans_loss=5.665, nll_loss=4.37, w2v_ctc_loss=4.007, task_loss=0, contrastive_loss=3.559, total=9477.06, n_correct=554.08, ppl=20.67, accuracy=5.847, wps=38295.3, ups=1.39, wpb=27473.8, bsz=951.4, num_updates=1100, lr=4.4078e-05, gnorm=0.623, clip=0, loss_scale=16, train_wall=71, gb_free=17.2, wall=935
2023-08-21 16:38:30 | INFO | train_inner | epoch 002:    366 / 837 loss=8.093, trans_loss=5.642, nll_loss=4.339, w2v_ctc_loss=3.844, task_loss=0, contrastive_loss=3.396, total=9511.99, n_correct=561.05, ppl=20.24, accuracy=5.898, wps=38625.9, ups=1.4, wpb=27568.1, bsz=942.2, num_updates=1200, lr=4.8076e-05, gnorm=0.751, clip=0, loss_scale=16, train_wall=71, gb_free=17.4, wall=1006
2023-08-21 16:39:42 | INFO | train_inner | epoch 002:    466 / 837 loss=7.909, trans_loss=5.612, nll_loss=4.299, w2v_ctc_loss=3.666, task_loss=0, contrastive_loss=3.37, total=9691.71, n_correct=594.2, ppl=19.69, accuracy=6.131, wps=39155.1, ups=1.39, wpb=28073.3, bsz=1007.8, num_updates=1300, lr=5.2074e-05, gnorm=0.794, clip=0, loss_scale=16, train_wall=71, gb_free=16.9, wall=1078
2023-08-21 16:40:55 | INFO | train_inner | epoch 002:    566 / 837 loss=7.718, trans_loss=5.615, nll_loss=4.302, w2v_ctc_loss=3.548, task_loss=0, contrastive_loss=3.23, total=9514.9, n_correct=570.12, ppl=19.72, accuracy=5.992, wps=37727.2, ups=1.37, wpb=27559.6, bsz=956.4, num_updates=1400, lr=5.6072e-05, gnorm=0.887, clip=0, loss_scale=16, train_wall=72, gb_free=16.7, wall=1151
2023-08-21 16:42:07 | INFO | train_inner | epoch 002:    666 / 837 loss=7.554, trans_loss=5.593, nll_loss=4.277, w2v_ctc_loss=3.422, task_loss=0, contrastive_loss=3.131, total=9559.4, n_correct=567.41, ppl=19.39, accuracy=5.936, wps=38677.2, ups=1.4, wpb=27711, bsz=960.5, num_updates=1500, lr=6.007e-05, gnorm=0.887, clip=0, loss_scale=16, train_wall=71, gb_free=17.9, wall=1223
2023-08-21 16:43:18 | INFO | train_inner | epoch 002:    766 / 837 loss=7.405, trans_loss=5.562, nll_loss=4.239, w2v_ctc_loss=3.321, task_loss=0, contrastive_loss=3.076, total=9621.64, n_correct=591.88, ppl=18.88, accuracy=6.152, wps=39048.3, ups=1.4, wpb=27867.7, bsz=1017.6, num_updates=1600, lr=6.4068e-05, gnorm=0.929, clip=0, loss_scale=16, train_wall=71, gb_free=17.2, wall=1294
2023-08-21 16:44:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 16:44:42 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.847 | trans_loss 11.568 | nll_loss 10.661 | w2v_ctc_loss 4.344 | task_loss 0 | contrastive_loss 4.077 | total 8593.8 | n_correct 553.6 | ppl 1619.36 | accuracy 6.442 | uer 57.489 | wer 58.103 | raw_wer 58.103 | bleu 0.01 | wps 1771.9 | wpb 8593.8 | bsz 281.6 | num_updates 1671 | best_bleu 0.01
2023-08-21 16:44:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 1671 updates
2023-08-21 16:44:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 16:44:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 16:44:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 1671 updates, score 0.01) (writing took 13.338272932043765 seconds)
2023-08-21 16:44:56 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-21 16:44:56 | INFO | train | epoch 002 | loss 7.948 | trans_loss 5.626 | nll_loss 4.319 | w2v_ctc_loss 3.742 | task_loss 0 | contrastive_loss 3.34 | total 9538.94 | n_correct 565.707 | ppl 19.97 | accuracy 5.931 | wps 35246.2 | ups 1.28 | wpb 27637.3 | bsz 965.1 | num_updates 1671 | lr 6.69066e-05 | gnorm 0.748 | clip 0 | loss_scale 16 | train_wall 595 | gb_free 16.5 | wall 1392
2023-08-21 16:44:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 837
2023-08-21 16:44:56 | INFO | fairseq.trainer | begin training epoch 3
2023-08-21 16:44:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 16:45:24 | INFO | train_inner | epoch 003:     29 / 837 loss=7.205, trans_loss=5.576, nll_loss=4.256, w2v_ctc_loss=3.236, task_loss=0, contrastive_loss=2.881, total=9402.23, n_correct=562.31, ppl=19.1, accuracy=5.981, wps=21534.1, ups=0.79, wpb=27230.5, bsz=913.2, num_updates=1700, lr=6.8066e-05, gnorm=1.017, clip=0, loss_scale=16, train_wall=70, gb_free=16.8, wall=1421
2023-08-21 16:46:36 | INFO | train_inner | epoch 003:    129 / 837 loss=7.076, trans_loss=5.536, nll_loss=4.211, w2v_ctc_loss=3.154, task_loss=0, contrastive_loss=2.874, total=9546.25, n_correct=574.16, ppl=18.52, accuracy=6.015, wps=38496.1, ups=1.39, wpb=27665.5, bsz=985, num_updates=1800, lr=7.2064e-05, gnorm=0.97, clip=0, loss_scale=16, train_wall=71, gb_free=16.5, wall=1492
2023-08-21 16:47:49 | INFO | train_inner | epoch 003:    229 / 837 loss=6.922, trans_loss=5.527, nll_loss=4.2, w2v_ctc_loss=3.101, task_loss=0, contrastive_loss=2.676, total=9631.58, n_correct=580.18, ppl=18.38, accuracy=6.024, wps=38272.9, ups=1.37, wpb=27900.8, bsz=980.4, num_updates=1900, lr=7.6062e-05, gnorm=1.383, clip=0, loss_scale=16, train_wall=72, gb_free=16.9, wall=1565
2023-08-21 16:49:01 | INFO | train_inner | epoch 003:    329 / 837 loss=6.738, trans_loss=5.511, nll_loss=4.182, w2v_ctc_loss=3.043, task_loss=0, contrastive_loss=2.538, total=9367.36, n_correct=564.08, ppl=18.15, accuracy=6.022, wps=37806.5, ups=1.39, wpb=27144.1, bsz=912.2, num_updates=2000, lr=8.006e-05, gnorm=1.373, clip=0, loss_scale=16, train_wall=71, gb_free=18.2, wall=1637
2023-08-21 16:49:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 16:49:35 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 10.523 | trans_loss 11.543 | nll_loss 10.631 | w2v_ctc_loss 4.053 | task_loss 0 | contrastive_loss 3.513 | total 8593.8 | n_correct 527.8 | ppl 1585.56 | accuracy 6.142 | uer 54.968 | wer 54.868 | raw_wer 54.868 | bleu 0.01 | wps 1780.3 | wpb 8593.8 | bsz 281.6 | num_updates 2000 | best_bleu 0.01
2023-08-21 16:49:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 2000 updates
2023-08-21 16:49:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_3_2000.pt
2023-08-21 16:49:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_3_2000.pt
2023-08-21 16:49:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_3_2000.pt (epoch 3 @ 2000 updates, score 0.01) (writing took 14.674033802992199 seconds)
2023-08-21 16:51:01 | INFO | train_inner | epoch 003:    429 / 837 loss=6.594, trans_loss=5.476, nll_loss=4.141, w2v_ctc_loss=3.003, task_loss=0, contrastive_loss=2.392, total=9437.42, n_correct=574.78, ppl=17.64, accuracy=6.09, wps=22758.2, ups=0.83, wpb=27339, bsz=927.6, num_updates=2100, lr=8.4058e-05, gnorm=1.411, clip=0, loss_scale=16, train_wall=70, gb_free=17.3, wall=1757
2023-08-21 16:52:13 | INFO | train_inner | epoch 003:    529 / 837 loss=6.478, trans_loss=5.421, nll_loss=4.08, w2v_ctc_loss=2.955, task_loss=0, contrastive_loss=2.406, total=9615.13, n_correct=625.49, ppl=16.92, accuracy=6.505, wps=38587.5, ups=1.38, wpb=27864.5, bsz=1000.8, num_updates=2200, lr=8.8056e-05, gnorm=1.348, clip=0, loss_scale=16, train_wall=71, gb_free=17.1, wall=1829
2023-08-21 16:53:25 | INFO | train_inner | epoch 003:    629 / 837 loss=6.329, trans_loss=5.402, nll_loss=4.059, w2v_ctc_loss=2.926, task_loss=0, contrastive_loss=2.236, total=9547.89, n_correct=613.71, ppl=16.67, accuracy=6.428, wps=38536.5, ups=1.39, wpb=27668.3, bsz=955, num_updates=2300, lr=9.2054e-05, gnorm=1.576, clip=0, loss_scale=16, train_wall=71, gb_free=16.7, wall=1901
2023-08-21 16:54:37 | INFO | train_inner | epoch 003:    729 / 837 loss=6.203, trans_loss=5.372, nll_loss=4.026, w2v_ctc_loss=2.883, task_loss=0, contrastive_loss=2.156, total=9522.54, n_correct=621.33, ppl=16.29, accuracy=6.525, wps=38528.7, ups=1.4, wpb=27590.1, bsz=957.1, num_updates=2400, lr=9.6052e-05, gnorm=1.51, clip=0, loss_scale=16, train_wall=71, gb_free=17, wall=1973
2023-08-21 16:55:49 | INFO | train_inner | epoch 003:    829 / 837 loss=6.122, trans_loss=5.338, nll_loss=3.987, w2v_ctc_loss=2.861, task_loss=0, contrastive_loss=2.205, total=9679.03, n_correct=660.08, ppl=15.86, accuracy=6.82, wps=38590.6, ups=1.38, wpb=28041.9, bsz=1007.8, num_updates=2500, lr=0.00010005, gnorm=1.899, clip=0, loss_scale=16, train_wall=72, gb_free=17.3, wall=2046
2023-08-21 16:55:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 16:56:29 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 9.731 | trans_loss 10.939 | nll_loss 9.936 | w2v_ctc_loss 3.846 | task_loss 0 | contrastive_loss 2.751 | total 8593.8 | n_correct 613.8 | ppl 979.61 | accuracy 7.142 | uer 51.801 | wer 52.577 | raw_wer 52.577 | bleu 0.01 | wps 1777.8 | wpb 8593.8 | bsz 281.6 | num_updates 2508 | best_bleu 0.01
2023-08-21 16:56:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 2508 updates
2023-08-21 16:56:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 16:56:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 16:56:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 3 @ 2508 updates, score 0.01) (writing took 17.31625721103046 seconds)
2023-08-21 16:56:46 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-21 16:56:46 | INFO | train | epoch 003 | loss 6.573 | trans_loss 5.451 | nll_loss 4.114 | w2v_ctc_loss 2.996 | task_loss 0 | contrastive_loss 2.449 | total 9538.94 | n_correct 601.392 | ppl 17.31 | accuracy 6.305 | wps 32574 | ups 1.18 | wpb 27637.3 | bsz 965.1 | num_updates 2508 | lr 0.00010037 | gnorm 1.426 | clip 0 | loss_scale 16 | train_wall 595 | gb_free 16.5 | wall 2102
2023-08-21 16:56:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 837
2023-08-21 16:56:46 | INFO | fairseq.trainer | begin training epoch 4
2023-08-21 16:56:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 16:58:00 | INFO | train_inner | epoch 004:     92 / 837 loss=5.994, trans_loss=5.316, nll_loss=3.964, w2v_ctc_loss=2.826, task_loss=0, contrastive_loss=2.071, total=9543.12, n_correct=659.54, ppl=15.6, accuracy=6.911, wps=21259.2, ups=0.77, wpb=27646.1, bsz=983.5, num_updates=2600, lr=0.000104048, gnorm=1.69, clip=0, loss_scale=16, train_wall=70, gb_free=17.9, wall=2176
2023-08-21 16:59:11 | INFO | train_inner | epoch 004:    192 / 837 loss=5.868, trans_loss=5.324, nll_loss=3.973, w2v_ctc_loss=2.794, task_loss=0, contrastive_loss=1.922, total=9490.59, n_correct=630.2, ppl=15.7, accuracy=6.64, wps=38367.3, ups=1.4, wpb=27482, bsz=923, num_updates=2700, lr=0.000108046, gnorm=1.747, clip=0, loss_scale=16, train_wall=71, gb_free=18.4, wall=2247
2023-08-21 17:00:23 | INFO | train_inner | epoch 004:    292 / 837 loss=5.809, trans_loss=5.289, nll_loss=3.935, w2v_ctc_loss=2.784, task_loss=0, contrastive_loss=1.898, total=9422.51, n_correct=651.09, ppl=15.3, accuracy=6.91, wps=38263.2, ups=1.4, wpb=27328, bsz=946.1, num_updates=2800, lr=0.000112044, gnorm=1.749, clip=0, loss_scale=32, train_wall=71, gb_free=16.7, wall=2319
2023-08-21 17:01:34 | INFO | train_inner | epoch 004:    392 / 837 loss=5.728, trans_loss=5.279, nll_loss=3.922, w2v_ctc_loss=2.736, task_loss=0, contrastive_loss=1.798, total=9545.26, n_correct=675.45, ppl=15.15, accuracy=7.076, wps=38859.6, ups=1.4, wpb=27666.2, bsz=982.1, num_updates=2900, lr=0.000116042, gnorm=1.782, clip=0, loss_scale=32, train_wall=71, gb_free=17.1, wall=2390
2023-08-21 17:02:47 | INFO | train_inner | epoch 004:    492 / 837 loss=5.681, trans_loss=5.281, nll_loss=3.927, w2v_ctc_loss=2.727, task_loss=0, contrastive_loss=1.824, total=9592, n_correct=672.71, ppl=15.21, accuracy=7.013, wps=38214.3, ups=1.37, wpb=27799, bsz=980.6, num_updates=3000, lr=0.00012004, gnorm=2.293, clip=0, loss_scale=32, train_wall=72, gb_free=18.7, wall=2463
2023-08-21 17:02:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-21 17:02:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-21 17:02:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-21 17:02:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-21 17:02:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-21 17:04:36 | INFO | train_inner | epoch 004:    597 / 837 loss=4.33, trans_loss=4.205, nll_loss=2.514, w2v_ctc_loss=2.409, task_loss=0, contrastive_loss=1.33, total=9592.33, n_correct=3039.95, ppl=5.71, accuracy=31.691, wps=25309.5, ups=0.91, wpb=27791.2, bsz=1000.3, num_updates=3100, lr=0.000124038, gnorm=3.551, clip=6, loss_scale=1, train_wall=109, gb_free=10.6, wall=2572
2023-08-21 17:06:20 | INFO | train_inner | epoch 004:    697 / 837 loss=3.624, trans_loss=3.982, nll_loss=2.217, w2v_ctc_loss=2.117, task_loss=0, contrastive_loss=0.842, total=9506, n_correct=3703.37, ppl=4.65, accuracy=38.958, wps=26490.6, ups=0.96, wpb=27540.8, bsz=930, num_updates=3200, lr=0.000128036, gnorm=1.971, clip=0, loss_scale=1, train_wall=103, gb_free=11.7, wall=2676
2023-08-21 17:08:05 | INFO | train_inner | epoch 004:    797 / 837 loss=3.363, trans_loss=3.877, nll_loss=2.077, w2v_ctc_loss=1.98, task_loss=0, contrastive_loss=0.688, total=9569.96, n_correct=4172.48, ppl=4.22, accuracy=43.6, wps=26566.3, ups=0.96, wpb=27717.8, bsz=956.6, num_updates=3300, lr=0.000132034, gnorm=1.89, clip=0, loss_scale=1, train_wall=104, gb_free=9.8, wall=2781
2023-08-21 17:08:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 17:09:15 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.388 | trans_loss 6.31 | nll_loss 3.86 | w2v_ctc_loss 2.489 | task_loss 0 | contrastive_loss 0.858 | total 8593.8 | n_correct 4288 | ppl 14.52 | accuracy 49.896 | uer 35.37 | wer 35.846 | raw_wer 35.846 | bleu 9.58 | wps 2110.1 | wpb 8593.8 | bsz 281.6 | num_updates 3340 | best_bleu 9.58
2023-08-21 17:09:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 3340 updates
2023-08-21 17:09:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 17:09:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 17:09:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 4 @ 3340 updates, score 9.58) (writing took 10.63314317096956 seconds)
2023-08-21 17:09:26 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-21 17:09:26 | INFO | train | epoch 004 | loss 4.953 | trans_loss 4.766 | nll_loss 3.246 | w2v_ctc_loss 2.514 | task_loss 0 | contrastive_loss 1.501 | total 9539.4 | n_correct 1912.75 | ppl 9.49 | accuracy 20.051 | wps 30254.8 | ups 1.09 | wpb 27638.9 | bsz 964.8 | num_updates 3340 | lr 0.000133633 | gnorm 2.069 | clip 0.7 | loss_scale 1 | train_wall 706 | gb_free 9.4 | wall 2862
2023-08-21 17:09:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 837
2023-08-21 17:09:26 | INFO | fairseq.trainer | begin training epoch 5
2023-08-21 17:09:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 17:10:37 | INFO | train_inner | epoch 005:     60 / 837 loss=3.184, trans_loss=3.801, nll_loss=1.976, w2v_ctc_loss=1.862, task_loss=0, contrastive_loss=0.704, total=9511.9, n_correct=4457.63, ppl=3.93, accuracy=46.864, wps=18138.4, ups=0.66, wpb=27545.8, bsz=980.9, num_updates=3400, lr=0.000136032, gnorm=1.542, clip=0, loss_scale=1, train_wall=103, gb_free=9.8, wall=2933
2023-08-21 17:12:21 | INFO | train_inner | epoch 005:    160 / 837 loss=3.013, trans_loss=3.74, nll_loss=1.897, w2v_ctc_loss=1.759, task_loss=0, contrastive_loss=0.613, total=9642.08, n_correct=4756.75, ppl=3.73, accuracy=49.333, wps=26727.6, ups=0.96, wpb=27935.8, bsz=988.1, num_updates=3500, lr=0.00014003, gnorm=1.289, clip=0, loss_scale=1, train_wall=104, gb_free=10.9, wall=3037
2023-08-21 17:14:05 | INFO | train_inner | epoch 005:    260 / 837 loss=2.925, trans_loss=3.697, nll_loss=1.841, w2v_ctc_loss=1.694, task_loss=0, contrastive_loss=0.611, total=9625.81, n_correct=4934.06, ppl=3.58, accuracy=51.259, wps=26721.6, ups=0.96, wpb=27897.1, bsz=1027.9, num_updates=3600, lr=0.000144028, gnorm=1.248, clip=0, loss_scale=1, train_wall=104, gb_free=11.5, wall=3142
2023-08-21 17:15:50 | INFO | train_inner | epoch 005:    360 / 837 loss=2.817, trans_loss=3.677, nll_loss=1.813, w2v_ctc_loss=1.661, task_loss=0, contrastive_loss=0.444, total=9421.98, n_correct=4917.82, ppl=3.51, accuracy=52.195, wps=26127.8, ups=0.96, wpb=27295.3, bsz=925.7, num_updates=3700, lr=0.000148026, gnorm=1.201, clip=0, loss_scale=1, train_wall=104, gb_free=11.9, wall=3246
2023-08-21 17:17:33 | INFO | train_inner | epoch 005:    460 / 837 loss=2.764, trans_loss=3.657, nll_loss=1.786, w2v_ctc_loss=1.621, task_loss=0, contrastive_loss=0.447, total=9580.15, n_correct=5107.16, ppl=3.45, accuracy=53.31, wps=26785.1, ups=0.97, wpb=27746.7, bsz=963.1, num_updates=3800, lr=0.000152024, gnorm=1.058, clip=0, loss_scale=1, train_wall=103, gb_free=10.6, wall=3350
2023-08-21 17:19:18 | INFO | train_inner | epoch 005:    560 / 837 loss=2.695, trans_loss=3.628, nll_loss=1.748, w2v_ctc_loss=1.552, task_loss=0, contrastive_loss=0.472, total=9693.03, n_correct=5289.45, ppl=3.36, accuracy=54.57, wps=26991.4, ups=0.96, wpb=28074.3, bsz=991.9, num_updates=3900, lr=0.000156022, gnorm=1.013, clip=0, loss_scale=1, train_wall=103, gb_free=11.8, wall=3454
2023-08-21 17:21:02 | INFO | train_inner | epoch 005:    660 / 837 loss=2.622, trans_loss=3.625, nll_loss=1.747, w2v_ctc_loss=1.517, task_loss=0, contrastive_loss=0.377, total=9354.62, n_correct=5127.63, ppl=3.36, accuracy=54.814, wps=25965.4, ups=0.96, wpb=27114.8, bsz=896.2, num_updates=4000, lr=0.00016002, gnorm=0.923, clip=0, loss_scale=1, train_wall=104, gb_free=8.4, wall=3558
2023-08-21 17:21:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 17:21:31 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.714 | trans_loss 5.757 | nll_loss 3.111 | w2v_ctc_loss 1.872 | task_loss 0 | contrastive_loss 0.518 | total 8593.8 | n_correct 5042.8 | ppl 8.64 | accuracy 58.68 | uer 28.535 | wer 28.966 | raw_wer 28.966 | bleu 18.51 | wps 2155.1 | wpb 8593.8 | bsz 281.6 | num_updates 4000 | best_bleu 18.51
2023-08-21 17:21:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 4000 updates
2023-08-21 17:21:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_5_4000.pt
2023-08-21 17:21:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_5_4000.pt
2023-08-21 17:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_5_4000.pt (epoch 5 @ 4000 updates, score 18.51) (writing took 16.09157953201793 seconds)
2023-08-21 17:23:31 | INFO | train_inner | epoch 005:    760 / 837 loss=2.58, trans_loss=3.588, nll_loss=1.699, w2v_ctc_loss=1.482, task_loss=0, contrastive_loss=0.365, total=9606.84, n_correct=5399.23, ppl=3.25, accuracy=56.202, wps=18719.5, ups=0.67, wpb=27840.4, bsz=977.5, num_updates=4100, lr=0.000164018, gnorm=0.899, clip=0, loss_scale=1, train_wall=103, gb_free=11.2, wall=3707
2023-08-21 17:24:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 17:25:20 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.672 | trans_loss 5.718 | nll_loss 3.063 | w2v_ctc_loss 1.843 | task_loss 0 | contrastive_loss 0.494 | total 8593.8 | n_correct 5120 | ppl 8.36 | accuracy 59.578 | uer 28.981 | wer 29.282 | raw_wer 29.282 | bleu 19.48 | wps 2135.9 | wpb 8593.8 | bsz 281.6 | num_updates 4177 | best_bleu 19.48
2023-08-21 17:25:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 4177 updates
2023-08-21 17:25:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 17:25:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 17:25:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 4177 updates, score 19.48) (writing took 10.49786798900459 seconds)
2023-08-21 17:25:31 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-21 17:25:31 | INFO | train | epoch 005 | loss 2.78 | trans_loss 3.662 | nll_loss 1.794 | w2v_ctc_loss 1.614 | task_loss 0 | contrastive_loss 0.486 | total 9538.94 | n_correct 5054.11 | ppl 3.47 | accuracy 52.984 | wps 23979.3 | ups 0.87 | wpb 27637.3 | bsz 965.1 | num_updates 4177 | lr 0.000167096 | gnorm 1.097 | clip 0 | loss_scale 1 | train_wall 866 | gb_free 11.3 | wall 3827
2023-08-21 17:25:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 837
2023-08-21 17:25:31 | INFO | fairseq.trainer | begin training epoch 6
2023-08-21 17:25:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 17:26:02 | INFO | train_inner | epoch 006:     23 / 837 loss=2.551, trans_loss=3.586, nll_loss=1.696, w2v_ctc_loss=1.447, task_loss=0, contrastive_loss=0.4, total=9445.27, n_correct=5338.77, ppl=3.24, accuracy=56.523, wps=18040.6, ups=0.66, wpb=27368.6, bsz=952.1, num_updates=4200, lr=0.000168016, gnorm=0.895, clip=0, loss_scale=1, train_wall=103, gb_free=11.7, wall=3858
2023-08-21 17:27:46 | INFO | train_inner | epoch 006:    123 / 837 loss=2.465, trans_loss=3.552, nll_loss=1.65, w2v_ctc_loss=1.39, task_loss=0, contrastive_loss=0.327, total=9552.49, n_correct=5518.65, ppl=3.14, accuracy=57.772, wps=26695.7, ups=0.96, wpb=27671.7, bsz=968.4, num_updates=4300, lr=0.000172014, gnorm=0.765, clip=0, loss_scale=1, train_wall=103, gb_free=10.8, wall=3962
2023-08-21 17:29:30 | INFO | train_inner | epoch 006:    223 / 837 loss=2.443, trans_loss=3.545, nll_loss=1.644, w2v_ctc_loss=1.379, task_loss=0, contrastive_loss=0.31, total=9514.5, n_correct=5523.89, ppl=3.12, accuracy=58.058, wps=26571.6, ups=0.96, wpb=27584.2, bsz=953.5, num_updates=4400, lr=0.000176012, gnorm=0.784, clip=0, loss_scale=1, train_wall=103, gb_free=10.4, wall=4066
2023-08-21 17:29:38 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 1.81 GiB (GPU 4; 23.70 GiB total capacity; 5.54 GiB already allocated; 1.79 GiB free; 20.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-08-21 17:29:38 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-21 17:29:38 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-21 17:29:38 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-21 17:29:38 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-21 17:29:38 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 2         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5669 MiB |  20036 MiB | 336019 GiB | 336014 GiB |
|       from large pool |   5542 MiB |  19966 MiB | 331985 GiB | 331980 GiB |
|       from small pool |    127 MiB |    132 MiB |   4033 GiB |   4033 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   5669 MiB |  20036 MiB | 336019 GiB | 336014 GiB |
|       from large pool |   5542 MiB |  19966 MiB | 331985 GiB | 331980 GiB |
|       from small pool |    127 MiB |    132 MiB |   4033 GiB |   4033 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5641 MiB |  19993 MiB | 335395 GiB | 335390 GiB |
|       from large pool |   5514 MiB |  19923 MiB | 331364 GiB | 331358 GiB |
|       from small pool |    127 MiB |    132 MiB |   4031 GiB |   4031 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  21026 MiB |  21474 MiB |  32616 MiB |  11590 MiB |
|       from large pool |  20890 MiB |  21030 MiB |  31840 MiB |  10950 MiB |
|       from small pool |    136 MiB |    444 MiB |    776 MiB |    640 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  15356 MiB |  16262 MiB | 334001 GiB | 333986 GiB |
|       from large pool |  15347 MiB |  16253 MiB | 329791 GiB | 329776 GiB |
|       from small pool |      8 MiB |     61 MiB |   4210 GiB |   4210 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    1013    |    1515    |   29620 K  |   29619 K  |
|       from large pool |     172    |     832    |   13576 K  |   13576 K  |
|       from small pool |     841    |     856    |   16043 K  |   16043 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    1013    |    1515    |   29620 K  |   29619 K  |
|       from large pool |     172    |     832    |   13576 K  |   13576 K  |
|       from small pool |     841    |     856    |   16043 K  |   16043 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     115    |     270    |     445    |     330    |
|       from large pool |      47    |      48    |      57    |      10    |
|       from small pool |      68    |     222    |     388    |     320    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      81    |     113    |   15013 K  |   15013 K  |
|       from large pool |      49    |      59    |    7096 K  |    7096 K  |
|       from small pool |      32    |      84    |    7917 K  |    7917 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-21 17:29:38 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-21 17:29:38 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-21 17:29:38 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-21 17:29:38 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 4 terminated with signal SIGTERM
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 329 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-21 17:44:16 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:10437
2023-08-21 17:44:16 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:10437
2023-08-21 17:44:16 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:10437
2023-08-21 17:44:16 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:10437
2023-08-21 17:44:16 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:10437
2023-08-21 17:44:16 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:10437
2023-08-21 17:44:16 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:10437
2023-08-21 17:44:16 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:10437
2023-08-21 17:44:16 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 17:44:17 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-21 17:44:17 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 17:44:17 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 17:44:17 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-21 17:44:17 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 17:44:17 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-21 17:44:17 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-21 17:44:17 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-21 17:44:17 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-21 17:44:21 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10437', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 12000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 12000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=12000, max_tokens_valid=12000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=12000, max_tokens_valid=12000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=12000, max_tokens_valid=12000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-21 17:44:21 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-21 17:44:21 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-21 17:44:21 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-21 17:44:21 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-21 17:44:21 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-21 17:44:25 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-21 17:44:25 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-21 17:44:25 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-21 17:44:27 | INFO | root | load pretrained hubert
2023-08-21 17:44:35 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-21 17:44:38 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-21 17:44:45 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-21 17:44:45 | INFO | root | share the sematic adapter and textual encoder
2023-08-21 17:44:45 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-21 17:44:45 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-21 17:44:45 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-21 17:44:45 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-21 17:44:45 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-21 17:44:45 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-21 17:44:45 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-21 17:44:45 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-21 17:44:45 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-21 17:44:45 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-21 17:45:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-21 17:45:01 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-21 17:45:01 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-21 17:45:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-21 17:45:01 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 17:45:01 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 17:45:01 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 17:45:01 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 17:45:01 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 17:45:01 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 17:45:01 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 17:45:01 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-21 17:45:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-21 17:45:01 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-21 17:45:01 | INFO | fairseq_cli.train | max tokens per device = 12000 and max sentences per device = None
2023-08-21 17:45:01 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-21 17:45:03 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(1.)
mt_weight tensor(0.5000)
2023-08-21 17:45:20 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-21 17:45:21 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt (epoch 6 @ 4177 updates)
2023-08-21 17:45:21 | INFO | fairseq.trainer | loading train data for epoch 6
2023-08-21 17:45:21 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-21 17:45:21 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-21 17:45:21 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-21 17:45:25 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-21 17:45:27 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-21 17:46:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 17:46:17 | INFO | fairseq.trainer | begin training epoch 6
2023-08-21 17:46:17 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
2023-08-21 17:46:53 | INFO | train_inner | epoch 006:     23 / 1080 loss=2.481, trans_loss=3.574, nll_loss=1.679, w2v_ctc_loss=1.445, task_loss=0, contrastive_loss=0.24, total=7287.52, n_correct=4137.74, ppl=3.2, accuracy=56.778, wps=22423.2, ups=1.06, wpb=21113.6, bsz=707.5, num_updates=4200, lr=0.000168016, gnorm=0.982, clip=0, loss_scale=1, train_wall=28, gb_free=9.2, wall=112
2023-08-21 17:48:26 | INFO | train_inner | epoch 006:    123 / 1080 loss=2.493, trans_loss=3.561, nll_loss=1.661, w2v_ctc_loss=1.427, task_loss=0, contrastive_loss=0.358, total=7467.2, n_correct=4296.33, ppl=3.16, accuracy=57.536, wps=23182.3, ups=1.07, wpb=21624.5, bsz=777.6, num_updates=4300, lr=0.000172014, gnorm=0.859, clip=0, loss_scale=1, train_wall=93, gb_free=12, wall=205
2023-08-21 17:49:59 | INFO | train_inner | epoch 006:    223 / 1080 loss=2.481, trans_loss=3.559, nll_loss=1.661, w2v_ctc_loss=1.418, task_loss=0, contrastive_loss=0.375, total=7400.3, n_correct=4262.93, ppl=3.16, accuracy=57.605, wps=23224.4, ups=1.08, wpb=21446.9, bsz=749, num_updates=4400, lr=0.000176012, gnorm=0.841, clip=0, loss_scale=1, train_wall=92, gb_free=12, wall=297
2023-08-21 17:51:29 | INFO | train_inner | epoch 006:    323 / 1080 loss=2.428, trans_loss=3.549, nll_loss=1.649, w2v_ctc_loss=1.392, task_loss=0, contrastive_loss=0.27, total=7258.29, n_correct=4206.46, ppl=3.14, accuracy=57.954, wps=23275.5, ups=1.11, wpb=21043.2, bsz=706.8, num_updates=4500, lr=0.00018001, gnorm=0.818, clip=0, loss_scale=1, train_wall=90, gb_free=12.7, wall=388
2023-08-21 17:53:01 | INFO | train_inner | epoch 006:    423 / 1080 loss=2.4, trans_loss=3.541, nll_loss=1.636, w2v_ctc_loss=1.366, task_loss=0, contrastive_loss=0.24, total=7470.99, n_correct=4370.21, ppl=3.11, accuracy=58.496, wps=23625, ups=1.09, wpb=21632, bsz=764.4, num_updates=4600, lr=0.000184008, gnorm=0.766, clip=0, loss_scale=1, train_wall=91, gb_free=14.9, wall=479
2023-08-21 17:54:33 | INFO | train_inner | epoch 006:    523 / 1080 loss=2.404, trans_loss=3.548, nll_loss=1.647, w2v_ctc_loss=1.38, task_loss=0, contrastive_loss=0.244, total=7318.55, n_correct=4270.97, ppl=3.13, accuracy=58.358, wps=22959, ups=1.08, wpb=21207.3, bsz=707, num_updates=4700, lr=0.000188006, gnorm=0.777, clip=0, loss_scale=1, train_wall=92, gb_free=14, wall=572
2023-08-21 17:56:05 | INFO | train_inner | epoch 006:    623 / 1080 loss=2.402, trans_loss=3.533, nll_loss=1.629, w2v_ctc_loss=1.339, task_loss=0, contrastive_loss=0.365, total=7494.2, n_correct=4426.95, ppl=3.09, accuracy=59.072, wps=23566.7, ups=1.09, wpb=21714.5, bsz=789.8, num_updates=4800, lr=0.000192004, gnorm=0.747, clip=0, loss_scale=1, train_wall=92, gb_free=12.9, wall=664
2023-08-21 17:57:37 | INFO | train_inner | epoch 006:    723 / 1080 loss=2.352, trans_loss=3.525, nll_loss=1.618, w2v_ctc_loss=1.324, task_loss=0, contrastive_loss=0.242, total=7466.51, n_correct=4429.13, ppl=3.07, accuracy=59.32, wps=23656.5, ups=1.09, wpb=21637.9, bsz=755.7, num_updates=4900, lr=0.000196002, gnorm=0.736, clip=0, loss_scale=1, train_wall=91, gb_free=13.4, wall=755
2023-08-21 17:59:08 | INFO | train_inner | epoch 006:    823 / 1080 loss=2.382, trans_loss=3.531, nll_loss=1.626, w2v_ctc_loss=1.325, task_loss=0, contrastive_loss=0.371, total=7307.85, n_correct=4321.95, ppl=3.09, accuracy=59.141, wps=23177.9, ups=1.09, wpb=21173.6, bsz=727, num_updates=5000, lr=0.0002, gnorm=0.764, clip=0, loss_scale=1, train_wall=91, gb_free=9.8, wall=846
mt_weight tensor(0.5000)
asr_weight tensor(0.4412, device='cuda:0')
2023-08-21 18:00:39 | INFO | train_inner | epoch 006:    923 / 1080 loss=2.331, trans_loss=3.517, nll_loss=1.607, w2v_ctc_loss=1.301, task_loss=0, contrastive_loss=0.265, total=7462.95, n_correct=4468.48, ppl=3.05, accuracy=59.876, wps=23765.1, ups=1.1, wpb=21610.1, bsz=757.9, num_updates=5100, lr=0.00019803, gnorm=0.434, clip=0, loss_scale=1, train_wall=90, gb_free=14, wall=937
2023-08-21 18:02:10 | INFO | train_inner | epoch 006:   1023 / 1080 loss=2.303, trans_loss=3.505, nll_loss=1.593, w2v_ctc_loss=1.281, task_loss=0, contrastive_loss=0.244, total=7405.41, n_correct=4462.54, ppl=3.02, accuracy=60.261, wps=23658.4, ups=1.1, wpb=21451.7, bsz=758.4, num_updates=5200, lr=0.000196116, gnorm=0.421, clip=0, loss_scale=1, train_wall=90, gb_free=13.1, wall=1028
2023-08-21 18:03:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4412, device='cuda:6')
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.4412, device='cuda:7')
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.4412, device='cuda:2')
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.4412, device='cuda:3')
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.4412, device='cuda:4')
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.4412, device='cuda:1')
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mt_weight tensor(0.5000)
asr_weight tensor(0.4412, device='cuda:5')
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-21 18:03:41 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.368 | trans_loss 5.473 | nll_loss 2.753 | w2v_ctc_loss 1.542 | task_loss 0 | contrastive_loss 0.343 | total 6138.43 | n_correct 3882 | ppl 6.74 | accuracy 63.241 | uer 23.804 | wer 25.095 | raw_wer 25.095 | bleu 22.6 | wps 1282.3 | wpb 6138.4 | bsz 201.1 | num_updates 5257 | best_bleu 22.6
2023-08-21 18:03:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 5257 updates
2023-08-21 18:03:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 18:03:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 18:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 6 @ 5257 updates, score 22.6) (writing took 10.307512970990501 seconds)
2023-08-21 18:03:51 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-21 18:03:51 | INFO | train | epoch 006 | loss 2.394 | trans_loss 3.536 | nll_loss 1.632 | w2v_ctc_loss 1.353 | task_loss 0 | contrastive_loss 0.293 | total 7392.68 | n_correct 4347.14 | ppl 3.1 | accuracy 58.803 | wps 22245 | ups 1.04 | wpb 21418.9 | bsz 747.9 | num_updates 5257 | lr 0.00019505 | gnorm 0.707 | clip 0 | loss_scale 1 | train_wall 990 | gb_free 12.3 | wall 1130
2023-08-21 18:03:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 18:03:51 | INFO | fairseq.trainer | begin training epoch 7
2023-08-21 18:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 18:04:38 | INFO | train_inner | epoch 007:     43 / 1080 loss=2.275, trans_loss=3.489, nll_loss=1.573, w2v_ctc_loss=1.259, task_loss=0, contrastive_loss=0.22, total=7333.9, n_correct=4463.78, ppl=2.97, accuracy=60.865, wps=14346, ups=0.68, wpb=21251.7, bsz=760.6, num_updates=5300, lr=0.000194257, gnorm=0.429, clip=0, loss_scale=1, train_wall=90, gb_free=12.5, wall=1176
2023-08-21 18:06:09 | INFO | train_inner | epoch 007:    143 / 1080 loss=2.261, trans_loss=3.47, nll_loss=1.547, w2v_ctc_loss=1.227, task_loss=0, contrastive_loss=0.304, total=7428.34, n_correct=4571.78, ppl=2.92, accuracy=61.545, wps=23546.2, ups=1.09, wpb=21515.7, bsz=780.7, num_updates=5400, lr=0.00019245, gnorm=0.419, clip=0, loss_scale=1, train_wall=91, gb_free=13.6, wall=1268
2023-08-21 18:07:41 | INFO | train_inner | epoch 007:    243 / 1080 loss=2.218, trans_loss=3.467, nll_loss=1.546, w2v_ctc_loss=1.215, task_loss=0, contrastive_loss=0.184, total=7453.33, n_correct=4593.73, ppl=2.92, accuracy=61.633, wps=23575.3, ups=1.09, wpb=21603.5, bsz=754.3, num_updates=5500, lr=0.000190693, gnorm=0.405, clip=0, loss_scale=1, train_wall=91, gb_free=13.5, wall=1359
2023-08-21 18:09:11 | INFO | train_inner | epoch 007:    343 / 1080 loss=2.222, trans_loss=3.46, nll_loss=1.535, w2v_ctc_loss=1.207, task_loss=0, contrastive_loss=0.229, total=7581.16, n_correct=4692.32, ppl=2.9, accuracy=61.894, wps=24200.9, ups=1.1, wpb=21964.8, bsz=805.7, num_updates=5600, lr=0.000188982, gnorm=0.409, clip=0, loss_scale=1, train_wall=90, gb_free=13.9, wall=1450
2023-08-21 18:10:43 | INFO | train_inner | epoch 007:    443 / 1080 loss=2.25, trans_loss=3.48, nll_loss=1.559, w2v_ctc_loss=1.234, task_loss=0, contrastive_loss=0.274, total=7349.55, n_correct=4511.22, ppl=2.95, accuracy=61.381, wps=23220.8, ups=1.09, wpb=21282.5, bsz=711.4, num_updates=5700, lr=0.000187317, gnorm=0.422, clip=0, loss_scale=1, train_wall=91, gb_free=14.2, wall=1542
2023-08-21 18:12:14 | INFO | train_inner | epoch 007:    543 / 1080 loss=2.213, trans_loss=3.465, nll_loss=1.543, w2v_ctc_loss=1.216, task_loss=0, contrastive_loss=0.191, total=7246.91, n_correct=4485.39, ppl=2.91, accuracy=61.894, wps=23110.2, ups=1.1, wpb=21002.4, bsz=715.9, num_updates=5800, lr=0.000185695, gnorm=0.408, clip=0, loss_scale=1, train_wall=90, gb_free=11.9, wall=1633
2023-08-21 18:13:45 | INFO | train_inner | epoch 007:    643 / 1080 loss=2.204, trans_loss=3.468, nll_loss=1.548, w2v_ctc_loss=1.204, task_loss=0, contrastive_loss=0.182, total=7434.87, n_correct=4601.16, ppl=2.92, accuracy=61.886, wps=23565.8, ups=1.09, wpb=21542, bsz=741.1, num_updates=5900, lr=0.000184115, gnorm=0.401, clip=0, loss_scale=1, train_wall=91, gb_free=14.2, wall=1724
2023-08-21 18:15:18 | INFO | train_inner | epoch 007:    743 / 1080 loss=2.218, trans_loss=3.463, nll_loss=1.542, w2v_ctc_loss=1.194, task_loss=0, contrastive_loss=0.303, total=7324.32, n_correct=4550.08, ppl=2.91, accuracy=62.123, wps=22939.1, ups=1.08, wpb=21228, bsz=722.9, num_updates=6000, lr=0.000182574, gnorm=0.414, clip=0, loss_scale=1, train_wall=92, gb_free=13.9, wall=1817
2023-08-21 18:15:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 18:15:58 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.302 | trans_loss 5.414 | nll_loss 2.666 | w2v_ctc_loss 1.476 | task_loss 0 | contrastive_loss 0.328 | total 6138.43 | n_correct 3945.57 | ppl 6.35 | accuracy 64.277 | uer 22.638 | wer 24.061 | raw_wer 24.061 | bleu 24.19 | wps 1263.6 | wpb 6138.4 | bsz 201.1 | num_updates 6000 | best_bleu 24.19
2023-08-21 18:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 6000 updates
2023-08-21 18:15:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_7_6000.pt
2023-08-21 18:16:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_7_6000.pt
2023-08-21 18:16:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_7_6000.pt (epoch 7 @ 6000 updates, score 24.19) (writing took 10.642667092964984 seconds)
2023-08-21 18:17:39 | INFO | train_inner | epoch 007:    843 / 1080 loss=2.191, trans_loss=3.454, nll_loss=1.531, w2v_ctc_loss=1.179, task_loss=0, contrastive_loss=0.249, total=7357.17, n_correct=4594.1, ppl=2.89, accuracy=62.444, wps=15089.2, ups=0.71, wpb=21320.8, bsz=734.4, num_updates=6100, lr=0.000181071, gnorm=0.396, clip=0, loss_scale=1, train_wall=90, gb_free=12.2, wall=1958
2023-08-21 18:19:10 | INFO | train_inner | epoch 007:    943 / 1080 loss=2.195, trans_loss=3.455, nll_loss=1.533, w2v_ctc_loss=1.183, task_loss=0, contrastive_loss=0.234, total=7426.88, n_correct=4632.34, ppl=2.89, accuracy=62.373, wps=23682.9, ups=1.1, wpb=21525.2, bsz=767.8, num_updates=6200, lr=0.000179605, gnorm=0.407, clip=0, loss_scale=1, train_wall=90, gb_free=14, wall=2049
2023-08-21 18:20:40 | INFO | train_inner | epoch 007:   1043 / 1080 loss=2.195, trans_loss=3.45, nll_loss=1.525, w2v_ctc_loss=1.165, task_loss=0, contrastive_loss=0.323, total=7423.38, n_correct=4646.31, ppl=2.88, accuracy=62.59, wps=23839.9, ups=1.11, wpb=21497.9, bsz=764.9, num_updates=6300, lr=0.000178174, gnorm=0.395, clip=0, loss_scale=2, train_wall=90, gb_free=13.6, wall=2139
2023-08-21 18:21:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 18:21:53 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.24 | trans_loss 5.362 | nll_loss 2.61 | w2v_ctc_loss 1.4 | task_loss 0 | contrastive_loss 0.312 | total 6138.43 | n_correct 3996.86 | ppl 6.1 | accuracy 65.112 | uer 21.293 | wer 22.86 | raw_wer 22.86 | bleu 24.86 | wps 1299.1 | wpb 6138.4 | bsz 201.1 | num_updates 6337 | best_bleu 24.86
2023-08-21 18:21:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 6337 updates
2023-08-21 18:21:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 18:21:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 18:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 7 @ 6337 updates, score 24.86) (writing took 10.851617353968322 seconds)
2023-08-21 18:22:04 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-21 18:22:04 | INFO | train | epoch 007 | loss 2.216 | trans_loss 3.463 | nll_loss 1.541 | w2v_ctc_loss 1.203 | task_loss 0 | contrastive_loss 0.242 | total 7392.68 | n_correct 4580.77 | ppl 2.91 | accuracy 61.964 | wps 21172.6 | ups 0.99 | wpb 21418.9 | bsz 747.9 | num_updates 6337 | lr 0.000177653 | gnorm 0.407 | clip 0 | loss_scale 2 | train_wall 976 | gb_free 13.2 | wall 2222
2023-08-21 18:22:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 18:22:04 | INFO | fairseq.trainer | begin training epoch 8
2023-08-21 18:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 18:23:09 | INFO | train_inner | epoch 008:     63 / 1080 loss=2.118, trans_loss=3.43, nll_loss=1.5, w2v_ctc_loss=1.127, task_loss=0, contrastive_loss=0.146, total=7326.38, n_correct=4635.76, ppl=2.83, accuracy=63.275, wps=14285.5, ups=0.67, wpb=21232.2, bsz=743, num_updates=6400, lr=0.000176777, gnorm=0.386, clip=0, loss_scale=2, train_wall=90, gb_free=11.4, wall=2288
2023-08-21 18:24:41 | INFO | train_inner | epoch 008:    163 / 1080 loss=2.128, trans_loss=3.419, nll_loss=1.487, w2v_ctc_loss=1.124, task_loss=0, contrastive_loss=0.223, total=7394.47, n_correct=4704.34, ppl=2.8, accuracy=63.62, wps=23210.2, ups=1.08, wpb=21438.8, bsz=744.7, num_updates=6500, lr=0.000175412, gnorm=0.377, clip=0, loss_scale=2, train_wall=92, gb_free=12.4, wall=2380
2023-08-21 18:26:12 | INFO | train_inner | epoch 008:    263 / 1080 loss=2.116, trans_loss=3.417, nll_loss=1.483, w2v_ctc_loss=1.114, task_loss=0, contrastive_loss=0.211, total=7384.47, n_correct=4701.6, ppl=2.8, accuracy=63.669, wps=23498.5, ups=1.1, wpb=21394.7, bsz=753.4, num_updates=6600, lr=0.000174078, gnorm=0.38, clip=0, loss_scale=2, train_wall=90, gb_free=13.1, wall=2471
2023-08-21 18:27:43 | INFO | train_inner | epoch 008:    363 / 1080 loss=2.113, trans_loss=3.423, nll_loss=1.489, w2v_ctc_loss=1.12, task_loss=0, contrastive_loss=0.179, total=7425.91, n_correct=4723.14, ppl=2.81, accuracy=63.604, wps=23711.4, ups=1.1, wpb=21504.2, bsz=740.4, num_updates=6700, lr=0.000172774, gnorm=0.38, clip=0, loss_scale=2, train_wall=90, gb_free=13, wall=2562
2023-08-21 18:29:14 | INFO | train_inner | epoch 008:    463 / 1080 loss=2.12, trans_loss=3.419, nll_loss=1.488, w2v_ctc_loss=1.117, task_loss=0, contrastive_loss=0.231, total=7405.56, n_correct=4717.51, ppl=2.8, accuracy=63.702, wps=23570, ups=1.1, wpb=21462.5, bsz=759.6, num_updates=6800, lr=0.000171499, gnorm=0.382, clip=0, loss_scale=2, train_wall=90, gb_free=11.5, wall=2653
2023-08-21 18:30:45 | INFO | train_inner | epoch 008:    563 / 1080 loss=2.093, trans_loss=3.419, nll_loss=1.486, w2v_ctc_loss=1.098, task_loss=0, contrastive_loss=0.178, total=7480.97, n_correct=4772.37, ppl=2.8, accuracy=63.793, wps=23832.5, ups=1.1, wpb=21666.5, bsz=747.1, num_updates=6900, lr=0.000170251, gnorm=0.374, clip=0, loss_scale=2, train_wall=90, gb_free=14.2, wall=2744
2023-08-21 18:32:17 | INFO | train_inner | epoch 008:    663 / 1080 loss=2.101, trans_loss=3.419, nll_loss=1.488, w2v_ctc_loss=1.099, task_loss=0, contrastive_loss=0.22, total=7391.12, n_correct=4713.62, ppl=2.8, accuracy=63.774, wps=23271.8, ups=1.09, wpb=21418.1, bsz=745, num_updates=7000, lr=0.000169031, gnorm=0.376, clip=0, loss_scale=2, train_wall=91, gb_free=14, wall=2836
2023-08-21 18:33:48 | INFO | train_inner | epoch 008:    763 / 1080 loss=2.105, trans_loss=3.414, nll_loss=1.479, w2v_ctc_loss=1.082, task_loss=0, contrastive_loss=0.271, total=7444.33, n_correct=4772.45, ppl=2.79, accuracy=64.109, wps=23591.4, ups=1.09, wpb=21551.2, bsz=775.4, num_updates=7100, lr=0.000167836, gnorm=0.381, clip=0, loss_scale=2, train_wall=91, gb_free=9.7, wall=2927
2023-08-21 18:35:19 | INFO | train_inner | epoch 008:    863 / 1080 loss=2.097, trans_loss=3.424, nll_loss=1.493, w2v_ctc_loss=1.106, task_loss=0, contrastive_loss=0.169, total=7306.57, n_correct=4654.68, ppl=2.82, accuracy=63.705, wps=23384.1, ups=1.11, wpb=21161.5, bsz=713.8, num_updates=7200, lr=0.000166667, gnorm=0.377, clip=0, loss_scale=2, train_wall=90, gb_free=13.4, wall=3018
2023-08-21 18:36:49 | INFO | train_inner | epoch 008:    963 / 1080 loss=2.083, trans_loss=3.412, nll_loss=1.48, w2v_ctc_loss=1.097, task_loss=0, contrastive_loss=0.155, total=7314.52, n_correct=4692.43, ppl=2.79, accuracy=64.152, wps=23426.2, ups=1.11, wpb=21194.2, bsz=724.6, num_updates=7300, lr=0.000165521, gnorm=0.379, clip=0, loss_scale=2, train_wall=90, gb_free=11.9, wall=3108
2023-08-21 18:38:20 | INFO | train_inner | epoch 008:   1063 / 1080 loss=2.111, trans_loss=3.416, nll_loss=1.486, w2v_ctc_loss=1.085, task_loss=0, contrastive_loss=0.3, total=7407.58, n_correct=4742.95, ppl=2.8, accuracy=64.028, wps=23660.7, ups=1.1, wpb=21472.6, bsz=766.8, num_updates=7400, lr=0.000164399, gnorm=0.373, clip=0, loss_scale=2, train_wall=90, gb_free=12.5, wall=3199
2023-08-21 18:38:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 18:39:14 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.186 | trans_loss 5.321 | nll_loss 2.557 | w2v_ctc_loss 1.335 | task_loss 0 | contrastive_loss 0.291 | total 6138.43 | n_correct 4025.57 | ppl 5.89 | accuracy 65.58 | uer 19.656 | wer 20.959 | raw_wer 20.959 | bleu 25.27 | wps 1295.8 | wpb 6138.4 | bsz 201.1 | num_updates 7417 | best_bleu 25.27
2023-08-21 18:39:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 7417 updates
2023-08-21 18:39:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 18:39:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 18:39:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 7417 updates, score 25.27) (writing took 11.42403977504 seconds)
2023-08-21 18:39:26 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-21 18:39:26 | INFO | train | epoch 008 | loss 2.106 | trans_loss 3.418 | nll_loss 1.485 | w2v_ctc_loss 1.104 | task_loss 0 | contrastive_loss 0.213 | total 7392.68 | n_correct 4718.08 | ppl 2.8 | accuracy 63.821 | wps 22196.4 | ups 1.04 | wpb 21418.9 | bsz 747.9 | num_updates 7417 | lr 0.00016421 | gnorm 0.378 | clip 0 | loss_scale 2 | train_wall 976 | gb_free 11.5 | wall 3265
2023-08-21 18:39:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 18:39:26 | INFO | fairseq.trainer | begin training epoch 9
2023-08-21 18:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 18:40:50 | INFO | train_inner | epoch 009:     83 / 1080 loss=2.041, trans_loss=3.384, nll_loss=1.44, w2v_ctc_loss=1.036, task_loss=0, contrastive_loss=0.214, total=7446.67, n_correct=4850.84, ppl=2.71, accuracy=65.141, wps=14363.1, ups=0.67, wpb=21561.9, bsz=785.8, num_updates=7500, lr=0.000163299, gnorm=0.367, clip=0, loss_scale=2, train_wall=91, gb_free=13.1, wall=3349
2023-08-21 18:42:21 | INFO | train_inner | epoch 009:    183 / 1080 loss=2.038, trans_loss=3.383, nll_loss=1.44, w2v_ctc_loss=1.035, task_loss=0, contrastive_loss=0.219, total=7463.33, n_correct=4853.5, ppl=2.71, accuracy=65.031, wps=23920.6, ups=1.11, wpb=21617.5, bsz=761.8, num_updates=7600, lr=0.000162221, gnorm=0.363, clip=0, loss_scale=2, train_wall=90, gb_free=12.7, wall=3439
2023-08-21 18:43:52 | INFO | train_inner | epoch 009:    283 / 1080 loss=2.031, trans_loss=3.388, nll_loss=1.448, w2v_ctc_loss=1.052, task_loss=0, contrastive_loss=0.136, total=7363.22, n_correct=4782.53, ppl=2.73, accuracy=64.952, wps=23251.5, ups=1.09, wpb=21336.7, bsz=737.5, num_updates=7700, lr=0.000161165, gnorm=0.368, clip=0, loss_scale=2, train_wall=91, gb_free=12.7, wall=3531
2023-08-21 18:45:23 | INFO | train_inner | epoch 009:    383 / 1080 loss=2.038, trans_loss=3.393, nll_loss=1.453, w2v_ctc_loss=1.047, task_loss=0, contrastive_loss=0.183, total=7385.48, n_correct=4787.46, ppl=2.74, accuracy=64.823, wps=23581.5, ups=1.1, wpb=21394.5, bsz=744.2, num_updates=7800, lr=0.000160128, gnorm=0.364, clip=0, loss_scale=2, train_wall=90, gb_free=5.7, wall=3622
2023-08-21 18:46:54 | INFO | train_inner | epoch 009:    483 / 1080 loss=2.037, trans_loss=3.383, nll_loss=1.442, w2v_ctc_loss=1.034, task_loss=0, contrastive_loss=0.231, total=7429.55, n_correct=4844.49, ppl=2.72, accuracy=65.206, wps=23633.5, ups=1.1, wpb=21524.6, bsz=770.2, num_updates=7900, lr=0.000159111, gnorm=0.364, clip=0, loss_scale=2, train_wall=90, gb_free=13.6, wall=3713
2023-08-21 18:48:27 | INFO | train_inner | epoch 009:    583 / 1080 loss=2.05, trans_loss=3.392, nll_loss=1.455, w2v_ctc_loss=1.046, task_loss=0, contrastive_loss=0.235, total=7276.04, n_correct=4712.94, ppl=2.74, accuracy=64.773, wps=22864.8, ups=1.08, wpb=21092.8, bsz=726.5, num_updates=8000, lr=0.000158114, gnorm=0.373, clip=0, loss_scale=2, train_wall=92, gb_free=14, wall=3805
2023-08-21 18:48:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 18:49:05 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.154 | trans_loss 5.305 | nll_loss 2.536 | w2v_ctc_loss 1.267 | task_loss 0 | contrastive_loss 0.292 | total 6138.43 | n_correct 4040.14 | ppl 5.8 | accuracy 65.817 | uer 19.234 | wer 20.848 | raw_wer 20.848 | bleu 25.38 | wps 1316.3 | wpb 6138.4 | bsz 201.1 | num_updates 8000 | best_bleu 25.38
2023-08-21 18:49:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 8000 updates
2023-08-21 18:49:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_9_8000.pt
2023-08-21 18:49:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_9_8000.pt
2023-08-21 18:49:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_9_8000.pt (epoch 9 @ 8000 updates, score 25.38) (writing took 14.065277984016575 seconds)
2023-08-21 18:50:51 | INFO | train_inner | epoch 009:    683 / 1080 loss=2.035, trans_loss=3.39, nll_loss=1.451, w2v_ctc_loss=1.036, task_loss=0, contrastive_loss=0.207, total=7438.28, n_correct=4833.66, ppl=2.73, accuracy=64.984, wps=14957.2, ups=0.69, wpb=21549.4, bsz=746.1, num_updates=8100, lr=0.000157135, gnorm=0.366, clip=0, loss_scale=2, train_wall=90, gb_free=13.7, wall=3949
2023-08-21 18:52:22 | INFO | train_inner | epoch 009:    783 / 1080 loss=2.025, trans_loss=3.386, nll_loss=1.447, w2v_ctc_loss=1.023, task_loss=0, contrastive_loss=0.203, total=7420.58, n_correct=4829.93, ppl=2.73, accuracy=65.088, wps=23594.1, ups=1.1, wpb=21496.2, bsz=757.4, num_updates=8200, lr=0.000156174, gnorm=0.364, clip=0, loss_scale=2, train_wall=90, gb_free=12.5, wall=4040
2023-08-21 18:53:52 | INFO | train_inner | epoch 009:    883 / 1080 loss=2.029, trans_loss=3.389, nll_loss=1.451, w2v_ctc_loss=1.024, task_loss=0, contrastive_loss=0.235, total=7368.55, n_correct=4795.3, ppl=2.73, accuracy=65.078, wps=23530.6, ups=1.1, wpb=21350.8, bsz=744, num_updates=8300, lr=0.00015523, gnorm=0.36, clip=0, loss_scale=4, train_wall=90, gb_free=13.3, wall=4131
2023-08-21 18:55:24 | INFO | train_inner | epoch 009:    983 / 1080 loss=2.016, trans_loss=3.391, nll_loss=1.454, w2v_ctc_loss=1.022, task_loss=0, contrastive_loss=0.187, total=7371.36, n_correct=4792.77, ppl=2.74, accuracy=65.019, wps=23452, ups=1.1, wpb=21364.6, bsz=721.4, num_updates=8400, lr=0.000154303, gnorm=0.362, clip=0, loss_scale=4, train_wall=90, gb_free=14.3, wall=4222
2023-08-21 18:56:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 18:57:30 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.142 | trans_loss 5.287 | nll_loss 2.521 | w2v_ctc_loss 1.274 | task_loss 0 | contrastive_loss 0.284 | total 6138.43 | n_correct 4058.29 | ppl 5.74 | accuracy 66.113 | uer 19.156 | wer 20.814 | raw_wer 20.814 | bleu 26.01 | wps 1308.5 | wpb 6138.4 | bsz 201.1 | num_updates 8497 | best_bleu 26.01
2023-08-21 18:57:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 8497 updates
2023-08-21 18:57:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 18:57:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 18:57:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 9 @ 8497 updates, score 26.01) (writing took 10.782012097071856 seconds)
2023-08-21 18:57:42 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-21 18:57:42 | INFO | train | epoch 009 | loss 2.031 | trans_loss 3.387 | nll_loss 1.448 | w2v_ctc_loss 1.034 | task_loss 0 | contrastive_loss 0.196 | total 7392.68 | n_correct 4808.14 | ppl 2.73 | accuracy 65.039 | wps 21108.2 | ups 0.99 | wpb 21418.9 | bsz 747.9 | num_updates 8497 | lr 0.00015342 | gnorm 0.365 | clip 0 | loss_scale 4 | train_wall 977 | gb_free 13.8 | wall 4360
2023-08-21 18:57:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 18:57:42 | INFO | fairseq.trainer | begin training epoch 10
2023-08-21 18:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 18:57:52 | INFO | train_inner | epoch 010:      3 / 1080 loss=2.003, trans_loss=3.384, nll_loss=1.447, w2v_ctc_loss=1.026, task_loss=0, contrastive_loss=0.122, total=7259.02, n_correct=4731.53, ppl=2.73, accuracy=65.181, wps=14141.9, ups=0.67, wpb=21041.7, bsz=712.1, num_updates=8500, lr=0.000153393, gnorm=0.369, clip=0, loss_scale=4, train_wall=90, gb_free=14.9, wall=4371
2023-08-21 18:59:22 | INFO | train_inner | epoch 010:    103 / 1080 loss=1.953, trans_loss=3.352, nll_loss=1.402, w2v_ctc_loss=0.973, task_loss=0, contrastive_loss=0.115, total=7480.13, n_correct=4958.21, ppl=2.64, accuracy=66.285, wps=24134.6, ups=1.11, wpb=21667.1, bsz=758.9, num_updates=8600, lr=0.000152499, gnorm=0.349, clip=0, loss_scale=4, train_wall=89, gb_free=13, wall=4461
2023-08-21 19:00:53 | INFO | train_inner | epoch 010:    203 / 1080 loss=1.998, trans_loss=3.363, nll_loss=1.418, w2v_ctc_loss=0.991, task_loss=0, contrastive_loss=0.261, total=7379.97, n_correct=4866.63, ppl=2.67, accuracy=65.944, wps=23434.4, ups=1.1, wpb=21388.5, bsz=750.2, num_updates=8700, lr=0.00015162, gnorm=0.362, clip=0, loss_scale=4, train_wall=91, gb_free=13.8, wall=4552
2023-08-21 19:02:25 | INFO | train_inner | epoch 010:    303 / 1080 loss=1.991, trans_loss=3.363, nll_loss=1.416, w2v_ctc_loss=0.984, task_loss=0, contrastive_loss=0.225, total=7422.07, n_correct=4894.59, ppl=2.67, accuracy=65.946, wps=23566, ups=1.1, wpb=21495.9, bsz=754.1, num_updates=8800, lr=0.000150756, gnorm=0.364, clip=0, loss_scale=4, train_wall=91, gb_free=12.6, wall=4643
2023-08-21 19:03:54 | INFO | train_inner | epoch 010:    403 / 1080 loss=1.981, trans_loss=3.366, nll_loss=1.422, w2v_ctc_loss=0.995, task_loss=0, contrastive_loss=0.153, total=7345.62, n_correct=4842.01, ppl=2.68, accuracy=65.917, wps=23757.4, ups=1.12, wpb=21281.4, bsz=744.5, num_updates=8900, lr=0.000149906, gnorm=0.36, clip=0, loss_scale=4, train_wall=89, gb_free=13.1, wall=4733
2023-08-21 19:05:27 | INFO | train_inner | epoch 010:    503 / 1080 loss=1.975, trans_loss=3.36, nll_loss=1.412, w2v_ctc_loss=0.976, task_loss=0, contrastive_loss=0.183, total=7545.6, n_correct=4993.54, ppl=2.66, accuracy=66.178, wps=23664.3, ups=1.08, wpb=21851.7, bsz=785.5, num_updates=9000, lr=0.000149071, gnorm=0.354, clip=0, loss_scale=4, train_wall=92, gb_free=12.4, wall=4825
2023-08-21 19:06:57 | INFO | train_inner | epoch 010:    603 / 1080 loss=1.977, trans_loss=3.368, nll_loss=1.423, w2v_ctc_loss=0.99, task_loss=0, contrastive_loss=0.157, total=7295.23, n_correct=4809.63, ppl=2.68, accuracy=65.928, wps=23245.8, ups=1.1, wpb=21128.3, bsz=715.2, num_updates=9100, lr=0.00014825, gnorm=0.362, clip=0, loss_scale=4, train_wall=90, gb_free=9.8, wall=4916
2023-08-21 19:08:28 | INFO | train_inner | epoch 010:    703 / 1080 loss=1.983, trans_loss=3.368, nll_loss=1.426, w2v_ctc_loss=0.995, task_loss=0, contrastive_loss=0.171, total=7323.33, n_correct=4816.82, ppl=2.69, accuracy=65.774, wps=23398.7, ups=1.1, wpb=21227, bsz=723.6, num_updates=9200, lr=0.000147442, gnorm=0.361, clip=0, loss_scale=4, train_wall=90, gb_free=11.4, wall=5007
2023-08-21 19:09:59 | INFO | train_inner | epoch 010:    803 / 1080 loss=1.972, trans_loss=3.365, nll_loss=1.421, w2v_ctc_loss=0.986, task_loss=0, contrastive_loss=0.159, total=7415.97, n_correct=4893.63, ppl=2.68, accuracy=65.988, wps=23577.3, ups=1.1, wpb=21485.5, bsz=734.6, num_updates=9300, lr=0.000146647, gnorm=0.354, clip=0, loss_scale=4, train_wall=90, gb_free=6.3, wall=5098
2023-08-21 19:11:30 | INFO | train_inner | epoch 010:    903 / 1080 loss=1.963, trans_loss=3.363, nll_loss=1.42, w2v_ctc_loss=0.982, task_loss=0, contrastive_loss=0.124, total=7401.87, n_correct=4886.11, ppl=2.68, accuracy=66.012, wps=23664.1, ups=1.1, wpb=21449.8, bsz=748.8, num_updates=9400, lr=0.000145865, gnorm=0.361, clip=0, loss_scale=4, train_wall=90, gb_free=13.8, wall=5189
2023-08-21 19:13:01 | INFO | train_inner | epoch 010:   1003 / 1080 loss=1.97, trans_loss=3.367, nll_loss=1.426, w2v_ctc_loss=0.982, task_loss=0, contrastive_loss=0.162, total=7359.84, n_correct=4854.79, ppl=2.69, accuracy=65.963, wps=23339.7, ups=1.09, wpb=21326.9, bsz=751.4, num_updates=9500, lr=0.000145095, gnorm=0.358, clip=0, loss_scale=4, train_wall=91, gb_free=13.7, wall=5280
2023-08-21 19:14:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 19:14:50 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.117 | trans_loss 5.262 | nll_loss 2.481 | w2v_ctc_loss 1.258 | task_loss 0 | contrastive_loss 0.275 | total 6138.43 | n_correct 4085.29 | ppl 5.58 | accuracy 66.553 | uer 18.49 | wer 19.989 | raw_wer 19.989 | bleu 26.28 | wps 1304.1 | wpb 6138.4 | bsz 201.1 | num_updates 9577 | best_bleu 26.28
2023-08-21 19:14:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 9577 updates
2023-08-21 19:14:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 19:14:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 19:15:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 10 @ 9577 updates, score 26.28) (writing took 10.208718782989308 seconds)
2023-08-21 19:15:01 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-21 19:15:01 | INFO | train | epoch 010 | loss 1.978 | trans_loss 3.363 | nll_loss 1.419 | w2v_ctc_loss 0.984 | task_loss 0 | contrastive_loss 0.183 | total 7392.68 | n_correct 4878.21 | ppl 2.67 | accuracy 65.987 | wps 22265.1 | ups 1.04 | wpb 21418.9 | bsz 747.9 | num_updates 9577 | lr 0.000144511 | gnorm 0.359 | clip 0 | loss_scale 4 | train_wall 974 | gb_free 13.4 | wall 5399
2023-08-21 19:15:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 19:15:01 | INFO | fairseq.trainer | begin training epoch 11
2023-08-21 19:15:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 19:15:29 | INFO | train_inner | epoch 011:     23 / 1080 loss=1.979, trans_loss=3.361, nll_loss=1.418, w2v_ctc_loss=0.958, task_loss=0, contrastive_loss=0.287, total=7353.82, n_correct=4863.55, ppl=2.67, accuracy=66.136, wps=14407.3, ups=0.68, wpb=21315.6, bsz=752.6, num_updates=9600, lr=0.000144338, gnorm=0.364, clip=0, loss_scale=4, train_wall=90, gb_free=14, wall=5428
2023-08-21 19:16:59 | INFO | train_inner | epoch 011:    123 / 1080 loss=1.954, trans_loss=3.337, nll_loss=1.386, w2v_ctc_loss=0.946, task_loss=0, contrastive_loss=0.242, total=7442.19, n_correct=4970.19, ppl=2.61, accuracy=66.784, wps=23978.1, ups=1.11, wpb=21568.5, bsz=783.8, num_updates=9700, lr=0.000143592, gnorm=0.351, clip=0, loss_scale=4, train_wall=89, gb_free=13.7, wall=5518
2023-08-21 19:18:30 | INFO | train_inner | epoch 011:    223 / 1080 loss=1.925, trans_loss=3.339, nll_loss=1.388, w2v_ctc_loss=0.939, task_loss=0, contrastive_loss=0.166, total=7270.55, n_correct=4854.74, ppl=2.62, accuracy=66.773, wps=23333.8, ups=1.11, wpb=21074.8, bsz=705.6, num_updates=9800, lr=0.000142857, gnorm=0.353, clip=0, loss_scale=4, train_wall=90, gb_free=11.5, wall=5608
2023-08-21 19:20:00 | INFO | train_inner | epoch 011:    323 / 1080 loss=1.937, trans_loss=3.341, nll_loss=1.392, w2v_ctc_loss=0.942, task_loss=0, contrastive_loss=0.197, total=7366.04, n_correct=4914.07, ppl=2.62, accuracy=66.713, wps=23559.2, ups=1.1, wpb=21346.8, bsz=749, num_updates=9900, lr=0.000142134, gnorm=0.352, clip=0, loss_scale=4, train_wall=90, gb_free=13, wall=5699
2023-08-21 19:21:32 | INFO | train_inner | epoch 011:    423 / 1080 loss=1.916, trans_loss=3.342, nll_loss=1.392, w2v_ctc_loss=0.941, task_loss=0, contrastive_loss=0.097, total=7355.74, n_correct=4911.23, ppl=2.62, accuracy=66.767, wps=23195.7, ups=1.09, wpb=21311.7, bsz=735.1, num_updates=10000, lr=0.000141421, gnorm=0.353, clip=0, loss_scale=4, train_wall=91, gb_free=13.5, wall=5791
2023-08-21 19:21:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 19:22:11 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.116 | trans_loss 5.266 | nll_loss 2.488 | w2v_ctc_loss 1.241 | task_loss 0 | contrastive_loss 0.28 | total 6138.43 | n_correct 4072.57 | ppl 5.61 | accuracy 66.346 | uer 18.493 | wer 20.208 | raw_wer 20.208 | bleu 26.29 | wps 1308.7 | wpb 6138.4 | bsz 201.1 | num_updates 10000 | best_bleu 26.29
2023-08-21 19:22:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 10000 updates
2023-08-21 19:22:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_11_10000.pt
2023-08-21 19:22:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_11_10000.pt
2023-08-21 19:22:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_11_10000.pt (epoch 11 @ 10000 updates, score 26.29) (writing took 11.294628427946009 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:0')
2023-08-21 19:23:54 | INFO | train_inner | epoch 011:    523 / 1080 loss=1.926, trans_loss=3.353, nll_loss=1.405, w2v_ctc_loss=0.958, task_loss=0, contrastive_loss=0.086, total=7268.47, n_correct=4832.64, ppl=2.65, accuracy=66.488, wps=14876.1, ups=0.71, wpb=21050.6, bsz=688.8, num_updates=10100, lr=0.00014072, gnorm=0.305, clip=0, loss_scale=4, train_wall=90, gb_free=13.3, wall=5932
2023-08-21 19:25:24 | INFO | train_inner | epoch 011:    623 / 1080 loss=1.94, trans_loss=3.351, nll_loss=1.404, w2v_ctc_loss=0.946, task_loss=0, contrastive_loss=0.162, total=7438.72, n_correct=4953.55, ppl=2.65, accuracy=66.591, wps=23781.4, ups=1.1, wpb=21539.8, bsz=754.1, num_updates=10200, lr=0.000140028, gnorm=0.303, clip=0, loss_scale=4, train_wall=90, gb_free=12.7, wall=6023
2023-08-21 19:26:55 | INFO | train_inner | epoch 011:    723 / 1080 loss=1.938, trans_loss=3.343, nll_loss=1.397, w2v_ctc_loss=0.951, task_loss=0, contrastive_loss=0.157, total=7496.82, n_correct=5000.14, ppl=2.63, accuracy=66.697, wps=24008.5, ups=1.1, wpb=21727.7, bsz=783.4, num_updates=10300, lr=0.000139347, gnorm=0.302, clip=0, loss_scale=4, train_wall=90, gb_free=11.5, wall=6113
2023-08-21 19:28:25 | INFO | train_inner | epoch 011:    823 / 1080 loss=1.943, trans_loss=3.344, nll_loss=1.395, w2v_ctc_loss=0.935, task_loss=0, contrastive_loss=0.22, total=7544, n_correct=5039.92, ppl=2.63, accuracy=66.807, wps=24110.3, ups=1.1, wpb=21849.6, bsz=789.6, num_updates=10400, lr=0.000138675, gnorm=0.308, clip=0, loss_scale=8, train_wall=90, gb_free=11.7, wall=6204
2023-08-21 19:29:57 | INFO | train_inner | epoch 011:    923 / 1080 loss=1.947, trans_loss=3.352, nll_loss=1.407, w2v_ctc_loss=0.951, task_loss=0, contrastive_loss=0.194, total=7431.85, n_correct=4947.31, ppl=2.65, accuracy=66.569, wps=23488.8, ups=1.09, wpb=21539.1, bsz=754.1, num_updates=10500, lr=0.000138013, gnorm=0.304, clip=0, loss_scale=8, train_wall=91, gb_free=14.3, wall=6296
2023-08-21 19:31:28 | INFO | train_inner | epoch 011:   1023 / 1080 loss=1.954, trans_loss=3.345, nll_loss=1.397, w2v_ctc_loss=0.948, task_loss=0, contrastive_loss=0.261, total=7313.44, n_correct=4878.41, ppl=2.63, accuracy=66.705, wps=23379.6, ups=1.1, wpb=21185.5, bsz=732.5, num_updates=10600, lr=0.000137361, gnorm=0.308, clip=0, loss_scale=8, train_wall=90, gb_free=11.9, wall=6386
2023-08-21 19:32:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:1')
2023-08-21 19:32:58 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.103 | trans_loss 5.246 | nll_loss 2.467 | w2v_ctc_loss 1.251 | task_loss 0 | contrastive_loss 0.273 | total 6138.43 | n_correct 4095.14 | ppl 5.53 | accuracy 66.713 | uer 18.092 | wer 19.881 | raw_wer 19.881 | bleu 26.46 | wps 1297.8 | wpb 6138.4 | bsz 201.1 | num_updates 10657 | best_bleu 26.46
2023-08-21 19:32:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 10657 updates
2023-08-21 19:32:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 19:33:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 19:33:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 11 @ 10657 updates, score 26.46) (writing took 10.57622274395544 seconds)
2023-08-21 19:33:09 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-21 19:33:09 | INFO | train | epoch 011 | loss 1.936 | trans_loss 3.345 | nll_loss 1.396 | w2v_ctc_loss 0.945 | task_loss 0 | contrastive_loss 0.174 | total 7392.68 | n_correct 4931.34 | ppl 2.63 | accuracy 66.706 | wps 21264.6 | ups 0.99 | wpb 21418.9 | bsz 747.9 | num_updates 10657 | lr 0.000136993 | gnorm 0.323 | clip 0 | loss_scale 8 | train_wall 972 | gb_free 14.1 | wall 6487
2023-08-21 19:33:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 19:33:09 | INFO | fairseq.trainer | begin training epoch 12
2023-08-21 19:33:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 19:33:55 | INFO | train_inner | epoch 012:     43 / 1080 loss=1.913, trans_loss=3.33, nll_loss=1.378, w2v_ctc_loss=0.927, task_loss=0, contrastive_loss=0.152, total=7398.26, n_correct=4974.67, ppl=2.6, accuracy=67.241, wps=14503.2, ups=0.68, wpb=21433, bsz=769.9, num_updates=10700, lr=0.000136717, gnorm=0.302, clip=0, loss_scale=8, train_wall=89, gb_free=14, wall=6534
2023-08-21 19:35:26 | INFO | train_inner | epoch 012:    143 / 1080 loss=1.911, trans_loss=3.326, nll_loss=1.372, w2v_ctc_loss=0.918, task_loss=0, contrastive_loss=0.203, total=7350.43, n_correct=4941.73, ppl=2.59, accuracy=67.23, wps=23525.5, ups=1.1, wpb=21303.5, bsz=728.9, num_updates=10800, lr=0.000136083, gnorm=0.299, clip=0, loss_scale=8, train_wall=90, gb_free=9.7, wall=6625
2023-08-21 19:36:57 | INFO | train_inner | epoch 012:    243 / 1080 loss=1.895, trans_loss=3.321, nll_loss=1.366, w2v_ctc_loss=0.907, task_loss=0, contrastive_loss=0.155, total=7522.48, n_correct=5079.84, ppl=2.58, accuracy=67.529, wps=23902.6, ups=1.1, wpb=21789.8, bsz=764.6, num_updates=10900, lr=0.000135457, gnorm=0.296, clip=0, loss_scale=8, train_wall=91, gb_free=13.1, wall=6716
2023-08-21 19:38:28 | INFO | train_inner | epoch 012:    343 / 1080 loss=1.888, trans_loss=3.32, nll_loss=1.367, w2v_ctc_loss=0.913, task_loss=0, contrastive_loss=0.112, total=7521.75, n_correct=5075.67, ppl=2.58, accuracy=67.48, wps=23937.9, ups=1.1, wpb=21813.6, bsz=779.8, num_updates=11000, lr=0.00013484, gnorm=0.296, clip=0, loss_scale=8, train_wall=90, gb_free=9.2, wall=6807
2023-08-21 19:39:59 | INFO | train_inner | epoch 012:    443 / 1080 loss=1.92, trans_loss=3.328, nll_loss=1.374, w2v_ctc_loss=0.907, task_loss=0, contrastive_loss=0.252, total=7530.65, n_correct=5074.87, ppl=2.59, accuracy=67.39, wps=23964.3, ups=1.1, wpb=21807.6, bsz=787, num_updates=11100, lr=0.000134231, gnorm=0.3, clip=0, loss_scale=8, train_wall=90, gb_free=12.4, wall=6898
2023-08-21 19:41:30 | INFO | train_inner | epoch 012:    543 / 1080 loss=1.9, trans_loss=3.325, nll_loss=1.371, w2v_ctc_loss=0.898, task_loss=0, contrastive_loss=0.211, total=7399.47, n_correct=4994, ppl=2.59, accuracy=67.491, wps=23558.7, ups=1.1, wpb=21430.9, bsz=762.5, num_updates=11200, lr=0.000133631, gnorm=0.296, clip=0, loss_scale=8, train_wall=90, gb_free=13.2, wall=6989
2023-08-21 19:43:01 | INFO | train_inner | epoch 012:    643 / 1080 loss=1.919, trans_loss=3.336, nll_loss=1.385, w2v_ctc_loss=0.926, task_loss=0, contrastive_loss=0.194, total=7278.13, n_correct=4879.64, ppl=2.61, accuracy=67.045, wps=23343.8, ups=1.11, wpb=21084.1, bsz=709, num_updates=11300, lr=0.000133038, gnorm=0.31, clip=0, loss_scale=8, train_wall=90, gb_free=13.9, wall=7079
2023-08-21 19:44:30 | INFO | train_inner | epoch 012:    743 / 1080 loss=1.901, trans_loss=3.328, nll_loss=1.377, w2v_ctc_loss=0.916, task_loss=0, contrastive_loss=0.154, total=7279.28, n_correct=4897.01, ppl=2.6, accuracy=67.273, wps=23475.8, ups=1.11, wpb=21097, bsz=730.1, num_updates=11400, lr=0.000132453, gnorm=0.303, clip=0, loss_scale=8, train_wall=89, gb_free=14.4, wall=7169
2023-08-21 19:46:02 | INFO | train_inner | epoch 012:    843 / 1080 loss=1.904, trans_loss=3.335, nll_loss=1.384, w2v_ctc_loss=0.92, task_loss=0, contrastive_loss=0.145, total=7304.75, n_correct=4911, ppl=2.61, accuracy=67.23, wps=23212.1, ups=1.1, wpb=21156.4, bsz=730.3, num_updates=11500, lr=0.000131876, gnorm=0.302, clip=0, loss_scale=8, train_wall=91, gb_free=12.4, wall=7260
2023-08-21 19:47:32 | INFO | train_inner | epoch 012:    943 / 1080 loss=1.902, trans_loss=3.332, nll_loss=1.383, w2v_ctc_loss=0.922, task_loss=0, contrastive_loss=0.142, total=7358.24, n_correct=4950, ppl=2.61, accuracy=67.272, wps=23452.5, ups=1.1, wpb=21321.8, bsz=736.8, num_updates=11600, lr=0.000131306, gnorm=0.301, clip=0, loss_scale=8, train_wall=90, gb_free=13.5, wall=7351
2023-08-21 19:49:03 | INFO | train_inner | epoch 012:   1043 / 1080 loss=1.895, trans_loss=3.336, nll_loss=1.386, w2v_ctc_loss=0.917, task_loss=0, contrastive_loss=0.103, total=7425, n_correct=4986.5, ppl=2.61, accuracy=67.158, wps=23643.5, ups=1.1, wpb=21506.6, bsz=746.4, num_updates=11700, lr=0.000130744, gnorm=0.299, clip=0, loss_scale=8, train_wall=90, gb_free=13.3, wall=7442
2023-08-21 19:49:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 19:50:17 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.086 | trans_loss 5.228 | nll_loss 2.442 | w2v_ctc_loss 1.241 | task_loss 0 | contrastive_loss 0.269 | total 6138.43 | n_correct 4113.43 | ppl 5.43 | accuracy 67.011 | uer 17.399 | wer 19.111 | raw_wer 19.111 | bleu 26.67 | wps 1288.1 | wpb 6138.4 | bsz 201.1 | num_updates 11737 | best_bleu 26.67
2023-08-21 19:50:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 11737 updates
2023-08-21 19:50:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 19:50:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 19:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 12 @ 11737 updates, score 26.67) (writing took 11.231676219031215 seconds)
2023-08-21 19:50:28 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-21 19:50:28 | INFO | train | epoch 012 | loss 1.904 | trans_loss 3.328 | nll_loss 1.376 | w2v_ctc_loss 0.915 | task_loss 0 | contrastive_loss 0.167 | total 7392.68 | n_correct 4977.27 | ppl 2.6 | accuracy 67.327 | wps 22247.4 | ups 1.04 | wpb 21418.9 | bsz 747.9 | num_updates 11737 | lr 0.000130538 | gnorm 0.3 | clip 0 | loss_scale 8 | train_wall 974 | gb_free 13.3 | wall 7527
2023-08-21 19:50:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 19:50:29 | INFO | fairseq.trainer | begin training epoch 13
2023-08-21 19:50:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 19:51:33 | INFO | train_inner | epoch 013:     63 / 1080 loss=1.881, trans_loss=3.312, nll_loss=1.357, w2v_ctc_loss=0.903, task_loss=0, contrastive_loss=0.149, total=7308.62, n_correct=4956.56, ppl=2.56, accuracy=67.818, wps=14206.7, ups=0.67, wpb=21189.3, bsz=724.1, num_updates=11800, lr=0.000130189, gnorm=0.301, clip=0, loss_scale=8, train_wall=90, gb_free=13.4, wall=7591
2023-08-21 19:53:04 | INFO | train_inner | epoch 013:    163 / 1080 loss=1.877, trans_loss=3.304, nll_loss=1.345, w2v_ctc_loss=0.873, task_loss=0, contrastive_loss=0.228, total=7574.63, n_correct=5156.89, ppl=2.54, accuracy=68.081, wps=24119.9, ups=1.1, wpb=21946.7, bsz=791.8, num_updates=11900, lr=0.000129641, gnorm=0.292, clip=0, loss_scale=8, train_wall=90, gb_free=12.2, wall=7682
2023-08-21 19:54:36 | INFO | train_inner | epoch 013:    263 / 1080 loss=1.854, trans_loss=3.308, nll_loss=1.352, w2v_ctc_loss=0.878, task_loss=0, contrastive_loss=0.103, total=7459.86, n_correct=5074.1, ppl=2.55, accuracy=68.019, wps=23292.1, ups=1.08, wpb=21616.8, bsz=756.2, num_updates=12000, lr=0.000129099, gnorm=0.297, clip=0, loss_scale=8, train_wall=92, gb_free=8.6, wall=7775
2023-08-21 19:54:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 19:55:18 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.102 | trans_loss 5.236 | nll_loss 2.449 | w2v_ctc_loss 1.275 | task_loss 0 | contrastive_loss 0.27 | total 6138.43 | n_correct 4118.14 | ppl 5.46 | accuracy 67.088 | uer 17.562 | wer 19.234 | raw_wer 19.234 | bleu 26.47 | wps 1230.2 | wpb 6138.4 | bsz 201.1 | num_updates 12000 | best_bleu 26.67
2023-08-21 19:55:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 12000 updates
2023-08-21 19:55:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_13_12000.pt
2023-08-21 19:55:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_13_12000.pt
2023-08-21 19:55:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_13_12000.pt (epoch 13 @ 12000 updates, score 26.47) (writing took 8.07177610101644 seconds)
2023-08-21 19:56:57 | INFO | train_inner | epoch 013:    363 / 1080 loss=1.881, trans_loss=3.313, nll_loss=1.357, w2v_ctc_loss=0.886, task_loss=0, contrastive_loss=0.184, total=7403.49, n_correct=5029.77, ppl=2.56, accuracy=67.938, wps=15241.7, ups=0.71, wpb=21445.7, bsz=753.1, num_updates=12100, lr=0.000128565, gnorm=0.3, clip=0, loss_scale=8, train_wall=90, gb_free=14, wall=7916
2023-08-21 19:58:28 | INFO | train_inner | epoch 013:    463 / 1080 loss=1.884, trans_loss=3.313, nll_loss=1.355, w2v_ctc_loss=0.885, task_loss=0, contrastive_loss=0.206, total=7431.31, n_correct=5045.55, ppl=2.56, accuracy=67.896, wps=23663.1, ups=1.1, wpb=21515.9, bsz=763, num_updates=12200, lr=0.000128037, gnorm=0.3, clip=0, loss_scale=8, train_wall=90, gb_free=11.8, wall=8007
2023-08-21 19:59:58 | INFO | train_inner | epoch 013:    563 / 1080 loss=1.863, trans_loss=3.318, nll_loss=1.364, w2v_ctc_loss=0.893, task_loss=0, contrastive_loss=0.097, total=7333.27, n_correct=4965.2, ppl=2.57, accuracy=67.708, wps=23617.3, ups=1.11, wpb=21243.9, bsz=709.9, num_updates=12300, lr=0.000127515, gnorm=0.301, clip=0, loss_scale=8, train_wall=89, gb_free=14.7, wall=8097
2023-08-21 20:01:28 | INFO | train_inner | epoch 013:    663 / 1080 loss=1.875, trans_loss=3.312, nll_loss=1.359, w2v_ctc_loss=0.895, task_loss=0, contrastive_loss=0.137, total=7354.21, n_correct=4991.22, ppl=2.57, accuracy=67.869, wps=23636.1, ups=1.11, wpb=21328.3, bsz=744, num_updates=12400, lr=0.000127, gnorm=0.3, clip=0, loss_scale=16, train_wall=90, gb_free=14, wall=8187
2023-08-21 20:03:00 | INFO | train_inner | epoch 013:    763 / 1080 loss=1.882, trans_loss=3.321, nll_loss=1.369, w2v_ctc_loss=0.902, task_loss=0, contrastive_loss=0.141, total=7237.6, n_correct=4891.68, ppl=2.58, accuracy=67.587, wps=22856.9, ups=1.09, wpb=20976.6, bsz=717.8, num_updates=12500, lr=0.000126491, gnorm=0.307, clip=0, loss_scale=16, train_wall=91, gb_free=11.5, wall=8279
2023-08-21 20:04:31 | INFO | train_inner | epoch 013:    863 / 1080 loss=1.867, trans_loss=3.318, nll_loss=1.362, w2v_ctc_loss=0.897, task_loss=0, contrastive_loss=0.091, total=7356.2, n_correct=4996.26, ppl=2.57, accuracy=67.919, wps=23336.6, ups=1.1, wpb=21297, bsz=743.5, num_updates=12600, lr=0.000125988, gnorm=0.299, clip=0, loss_scale=16, train_wall=91, gb_free=13.3, wall=8370
2023-08-21 20:06:02 | INFO | train_inner | epoch 013:    963 / 1080 loss=1.895, trans_loss=3.319, nll_loss=1.367, w2v_ctc_loss=0.893, task_loss=0, contrastive_loss=0.225, total=7395.5, n_correct=5007.74, ppl=2.58, accuracy=67.713, wps=23690.1, ups=1.11, wpb=21436.6, bsz=754.6, num_updates=12700, lr=0.000125491, gnorm=0.299, clip=0, loss_scale=16, train_wall=90, gb_free=14.9, wall=8460
2023-08-21 20:07:32 | INFO | train_inner | epoch 013:   1063 / 1080 loss=1.877, trans_loss=3.314, nll_loss=1.36, w2v_ctc_loss=0.882, task_loss=0, contrastive_loss=0.194, total=7483.66, n_correct=5086.47, ppl=2.57, accuracy=67.968, wps=24147.2, ups=1.11, wpb=21677.1, bsz=778.1, num_updates=12800, lr=0.000125, gnorm=0.297, clip=0, loss_scale=16, train_wall=89, gb_free=13.9, wall=8550
2023-08-21 20:07:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 20:08:25 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.096 | trans_loss 5.217 | nll_loss 2.426 | w2v_ctc_loss 1.292 | task_loss 0 | contrastive_loss 0.275 | total 6138.43 | n_correct 4116.14 | ppl 5.37 | accuracy 67.055 | uer 17.656 | wer 19.383 | raw_wer 19.383 | bleu 26.78 | wps 1330.7 | wpb 6138.4 | bsz 201.1 | num_updates 12817 | best_bleu 26.78
2023-08-21 20:08:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 12817 updates
2023-08-21 20:08:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 20:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 20:08:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 13 @ 12817 updates, score 26.78) (writing took 11.018939235946164 seconds)
2023-08-21 20:08:37 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-21 20:08:37 | INFO | train | epoch 013 | loss 1.875 | trans_loss 3.314 | nll_loss 1.359 | w2v_ctc_loss 0.888 | task_loss 0 | contrastive_loss 0.162 | total 7392.68 | n_correct 5017.68 | ppl 2.56 | accuracy 67.874 | wps 21251.3 | ups 0.99 | wpb 21418.9 | bsz 747.9 | num_updates 12817 | lr 0.000124917 | gnorm 0.299 | clip 0 | loss_scale 16 | train_wall 973 | gb_free 13.9 | wall 8616
2023-08-21 20:08:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 20:08:37 | INFO | fairseq.trainer | begin training epoch 14
2023-08-21 20:08:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 20:10:00 | INFO | train_inner | epoch 014:     83 / 1080 loss=1.833, trans_loss=3.303, nll_loss=1.344, w2v_ctc_loss=0.865, task_loss=0, contrastive_loss=0.083, total=7294.21, n_correct=4976.84, ppl=2.54, accuracy=68.23, wps=14224.5, ups=0.67, wpb=21127.8, bsz=709.2, num_updates=12900, lr=0.000124515, gnorm=0.299, clip=0, loss_scale=16, train_wall=90, gb_free=4.1, wall=8699
2023-08-21 20:11:31 | INFO | train_inner | epoch 014:    183 / 1080 loss=1.84, trans_loss=3.297, nll_loss=1.338, w2v_ctc_loss=0.862, task_loss=0, contrastive_loss=0.13, total=7431.17, n_correct=5082.31, ppl=2.53, accuracy=68.392, wps=23700.8, ups=1.1, wpb=21536.8, bsz=718.3, num_updates=13000, lr=0.000124035, gnorm=0.296, clip=0, loss_scale=16, train_wall=90, gb_free=10.1, wall=8790
2023-08-21 20:13:01 | INFO | train_inner | epoch 014:    283 / 1080 loss=1.855, trans_loss=3.291, nll_loss=1.331, w2v_ctc_loss=0.856, task_loss=0, contrastive_loss=0.222, total=7511.44, n_correct=5151.25, ppl=2.52, accuracy=68.579, wps=24184.1, ups=1.11, wpb=21768.5, bsz=786.5, num_updates=13100, lr=0.00012356, gnorm=0.295, clip=0, loss_scale=16, train_wall=89, gb_free=13.9, wall=8880
2023-08-21 20:14:32 | INFO | train_inner | epoch 014:    383 / 1080 loss=1.858, trans_loss=3.295, nll_loss=1.336, w2v_ctc_loss=0.859, task_loss=0, contrastive_loss=0.206, total=7418.87, n_correct=5077.34, ppl=2.53, accuracy=68.438, wps=23689.3, ups=1.1, wpb=21497.9, bsz=769, num_updates=13200, lr=0.000123091, gnorm=0.3, clip=0, loss_scale=16, train_wall=90, gb_free=11.7, wall=8970
2023-08-21 20:16:02 | INFO | train_inner | epoch 014:    483 / 1080 loss=1.837, trans_loss=3.299, nll_loss=1.341, w2v_ctc_loss=0.868, task_loss=0, contrastive_loss=0.086, total=7382.91, n_correct=5048.57, ppl=2.53, accuracy=68.382, wps=23782.2, ups=1.11, wpb=21393.2, bsz=740.2, num_updates=13300, lr=0.000122628, gnorm=0.297, clip=0, loss_scale=16, train_wall=89, gb_free=12, wall=9060
2023-08-21 20:17:33 | INFO | train_inner | epoch 014:    583 / 1080 loss=1.863, trans_loss=3.304, nll_loss=1.347, w2v_ctc_loss=0.865, task_loss=0, contrastive_loss=0.197, total=7481.28, n_correct=5111.23, ppl=2.54, accuracy=68.32, wps=23753.9, ups=1.1, wpb=21670.4, bsz=782.9, num_updates=13400, lr=0.000122169, gnorm=0.3, clip=0, loss_scale=16, train_wall=91, gb_free=11.7, wall=9151
2023-08-21 20:19:05 | INFO | train_inner | epoch 014:    683 / 1080 loss=1.881, trans_loss=3.307, nll_loss=1.351, w2v_ctc_loss=0.879, task_loss=0, contrastive_loss=0.251, total=7334.77, n_correct=4992.64, ppl=2.55, accuracy=68.068, wps=23183.1, ups=1.09, wpb=21250.9, bsz=754.3, num_updates=13500, lr=0.000121716, gnorm=0.307, clip=0, loss_scale=16, train_wall=91, gb_free=13.3, wall=9243
2023-08-21 20:20:36 | INFO | train_inner | epoch 014:    783 / 1080 loss=1.842, trans_loss=3.302, nll_loss=1.345, w2v_ctc_loss=0.869, task_loss=0, contrastive_loss=0.101, total=7429.54, n_correct=5078.52, ppl=2.54, accuracy=68.356, wps=23654.1, ups=1.1, wpb=21525.4, bsz=764.4, num_updates=13600, lr=0.000121268, gnorm=0.296, clip=0, loss_scale=16, train_wall=90, gb_free=10.3, wall=9334
2023-08-21 20:22:07 | INFO | train_inner | epoch 014:    883 / 1080 loss=1.844, trans_loss=3.308, nll_loss=1.35, w2v_ctc_loss=0.877, task_loss=0, contrastive_loss=0.087, total=7232.69, n_correct=4931.71, ppl=2.55, accuracy=68.186, wps=22948.7, ups=1.1, wpb=20946.8, bsz=681.1, num_updates=13700, lr=0.000120824, gnorm=0.303, clip=0, loss_scale=16, train_wall=91, gb_free=11.5, wall=9425
2023-08-21 20:23:37 | INFO | train_inner | epoch 014:    983 / 1080 loss=1.845, trans_loss=3.306, nll_loss=1.35, w2v_ctc_loss=0.86, task_loss=0, contrastive_loss=0.14, total=7376.77, n_correct=5042.88, ppl=2.55, accuracy=68.362, wps=23683.6, ups=1.11, wpb=21370, bsz=750.7, num_updates=13800, lr=0.000120386, gnorm=0.298, clip=0, loss_scale=16, train_wall=90, gb_free=13.5, wall=9516
2023-08-21 20:25:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 20:25:43 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.083 | trans_loss 5.215 | nll_loss 2.43 | w2v_ctc_loss 1.267 | task_loss 0 | contrastive_loss 0.262 | total 6138.43 | n_correct 4116.57 | ppl 5.39 | accuracy 67.062 | uer 17.268 | wer 19.171 | raw_wer 19.171 | bleu 26.79 | wps 1334 | wpb 6138.4 | bsz 201.1 | num_updates 13897 | best_bleu 26.79
2023-08-21 20:25:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 13897 updates
2023-08-21 20:25:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 20:25:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 20:25:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 14 @ 13897 updates, score 26.79) (writing took 11.312844209955074 seconds)
2023-08-21 20:25:55 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-21 20:25:55 | INFO | train | epoch 014 | loss 1.851 | trans_loss 3.301 | nll_loss 1.343 | w2v_ctc_loss 0.866 | task_loss 0 | contrastive_loss 0.157 | total 7392.68 | n_correct 5052.22 | ppl 2.54 | accuracy 68.341 | wps 22281.5 | ups 1.04 | wpb 21418.9 | bsz 747.9 | num_updates 13897 | lr 0.000119965 | gnorm 0.3 | clip 0 | loss_scale 16 | train_wall 973 | gb_free 13.1 | wall 9654
2023-08-21 20:25:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 20:25:55 | INFO | fairseq.trainer | begin training epoch 15
2023-08-21 20:25:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 20:26:06 | INFO | train_inner | epoch 015:      3 / 1080 loss=1.862, trans_loss=3.306, nll_loss=1.35, w2v_ctc_loss=0.864, task_loss=0, contrastive_loss=0.196, total=7371.96, n_correct=5034.95, ppl=2.55, accuracy=68.299, wps=14357.7, ups=0.67, wpb=21358.8, bsz=759.8, num_updates=13900, lr=0.000119952, gnorm=0.307, clip=0, loss_scale=16, train_wall=90, gb_free=13.8, wall=9664
2023-08-21 20:27:37 | INFO | train_inner | epoch 015:    103 / 1080 loss=1.827, trans_loss=3.28, nll_loss=1.316, w2v_ctc_loss=0.836, task_loss=0, contrastive_loss=0.183, total=7349.54, n_correct=5070.43, ppl=2.49, accuracy=68.99, wps=23373.7, ups=1.1, wpb=21287.3, bsz=755.5, num_updates=14000, lr=0.000119523, gnorm=0.296, clip=0, loss_scale=16, train_wall=90, gb_free=12.2, wall=9756
2023-08-21 20:27:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 20:28:15 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.08 | trans_loss 5.218 | nll_loss 2.425 | w2v_ctc_loss 1.246 | task_loss 0 | contrastive_loss 0.267 | total 6138.43 | n_correct 4128.29 | ppl 5.37 | accuracy 67.253 | uer 17.193 | wer 18.896 | raw_wer 18.896 | bleu 26.76 | wps 1338.3 | wpb 6138.4 | bsz 201.1 | num_updates 14000 | best_bleu 26.79
2023-08-21 20:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 14000 updates
2023-08-21 20:28:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_15_14000.pt
2023-08-21 20:28:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_15_14000.pt
2023-08-21 20:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_15_14000.pt (epoch 15 @ 14000 updates, score 26.76) (writing took 8.06883329199627 seconds)
2023-08-21 20:29:55 | INFO | train_inner | epoch 015:    203 / 1080 loss=1.825, trans_loss=3.283, nll_loss=1.321, w2v_ctc_loss=0.846, task_loss=0, contrastive_loss=0.137, total=7450.29, n_correct=5136.47, ppl=2.5, accuracy=68.943, wps=15647.5, ups=0.72, wpb=21592.4, bsz=756, num_updates=14100, lr=0.000119098, gnorm=0.294, clip=0, loss_scale=16, train_wall=90, gb_free=12.6, wall=9894
2023-08-21 20:31:25 | INFO | train_inner | epoch 015:    303 / 1080 loss=1.827, trans_loss=3.288, nll_loss=1.326, w2v_ctc_loss=0.843, task_loss=0, contrastive_loss=0.138, total=7496.11, n_correct=5159.52, ppl=2.51, accuracy=68.829, wps=24037.7, ups=1.11, wpb=21711.5, bsz=771.4, num_updates=14200, lr=0.000118678, gnorm=0.296, clip=0, loss_scale=16, train_wall=90, gb_free=14, wall=9984
2023-08-21 20:32:55 | INFO | train_inner | epoch 015:    403 / 1080 loss=1.833, trans_loss=3.289, nll_loss=1.328, w2v_ctc_loss=0.849, task_loss=0, contrastive_loss=0.152, total=7325.74, n_correct=5034.87, ppl=2.51, accuracy=68.728, wps=23653.5, ups=1.11, wpb=21221.7, bsz=752.2, num_updates=14300, lr=0.000118262, gnorm=0.299, clip=0, loss_scale=16, train_wall=89, gb_free=14, wall=10074
2023-08-21 20:34:25 | INFO | train_inner | epoch 015:    503 / 1080 loss=1.823, trans_loss=3.289, nll_loss=1.327, w2v_ctc_loss=0.847, task_loss=0, contrastive_loss=0.124, total=7236.35, n_correct=4974.41, ppl=2.51, accuracy=68.742, wps=23211.4, ups=1.11, wpb=20962.5, bsz=681.8, num_updates=14400, lr=0.000117851, gnorm=0.3, clip=0, loss_scale=16, train_wall=90, gb_free=14.2, wall=10164
2023-08-21 20:35:56 | INFO | train_inner | epoch 015:    603 / 1080 loss=1.852, trans_loss=3.294, nll_loss=1.336, w2v_ctc_loss=0.846, task_loss=0, contrastive_loss=0.257, total=7356.86, n_correct=5039.6, ppl=2.52, accuracy=68.502, wps=23449.7, ups=1.1, wpb=21322.1, bsz=745, num_updates=14500, lr=0.000117444, gnorm=0.298, clip=0, loss_scale=32, train_wall=90, gb_free=14.9, wall=10255
2023-08-21 20:37:27 | INFO | train_inner | epoch 015:    703 / 1080 loss=1.824, trans_loss=3.287, nll_loss=1.329, w2v_ctc_loss=0.839, task_loss=0, contrastive_loss=0.161, total=7414.96, n_correct=5099.45, ppl=2.51, accuracy=68.772, wps=23656.8, ups=1.1, wpb=21496.3, bsz=755.5, num_updates=14600, lr=0.000117041, gnorm=0.299, clip=0, loss_scale=32, train_wall=90, gb_free=15, wall=10346
2023-08-21 20:38:59 | INFO | train_inner | epoch 015:    803 / 1080 loss=1.828, trans_loss=3.294, nll_loss=1.336, w2v_ctc_loss=0.847, task_loss=0, contrastive_loss=0.137, total=7481.43, n_correct=5136.33, ppl=2.52, accuracy=68.654, wps=23692.3, ups=1.09, wpb=21677.2, bsz=775, num_updates=14700, lr=0.000116642, gnorm=0.295, clip=0, loss_scale=32, train_wall=91, gb_free=13.9, wall=10437
2023-08-21 20:40:30 | INFO | train_inner | epoch 015:    903 / 1080 loss=1.815, trans_loss=3.297, nll_loss=1.339, w2v_ctc_loss=0.841, task_loss=0, contrastive_loss=0.092, total=7368.47, n_correct=5060.64, ppl=2.53, accuracy=68.68, wps=23392, ups=1.1, wpb=21341.5, bsz=732.5, num_updates=14800, lr=0.000116248, gnorm=0.298, clip=0, loss_scale=32, train_wall=91, gb_free=14, wall=10528
2023-08-21 20:42:01 | INFO | train_inner | epoch 015:   1003 / 1080 loss=1.823, trans_loss=3.297, nll_loss=1.34, w2v_ctc_loss=0.845, task_loss=0, contrastive_loss=0.114, total=7412.59, n_correct=5086.43, ppl=2.53, accuracy=68.619, wps=23648, ups=1.1, wpb=21480, bsz=731, num_updates=14900, lr=0.000115857, gnorm=0.298, clip=0, loss_scale=32, train_wall=90, gb_free=13.7, wall=10619
2023-08-21 20:43:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 20:43:49 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.066 | trans_loss 5.204 | nll_loss 2.414 | w2v_ctc_loss 1.237 | task_loss 0 | contrastive_loss 0.258 | total 6138.43 | n_correct 4135.86 | ppl 5.33 | accuracy 67.376 | uer 16.966 | wer 18.769 | raw_wer 18.769 | bleu 27.16 | wps 1302.1 | wpb 6138.4 | bsz 201.1 | num_updates 14977 | best_bleu 27.16
2023-08-21 20:43:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 14977 updates
2023-08-21 20:43:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 20:43:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 20:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 15 @ 14977 updates, score 27.16) (writing took 11.496088744024746 seconds)
2023-08-21 20:44:01 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-21 20:44:01 | INFO | train | epoch 015 | loss 1.828 | trans_loss 3.29 | nll_loss 1.33 | w2v_ctc_loss 0.844 | task_loss 0 | contrastive_loss 0.152 | total 7392.68 | n_correct 5081.82 | ppl 2.51 | accuracy 68.741 | wps 21301.8 | ups 0.99 | wpb 21418.9 | bsz 747.9 | num_updates 14977 | lr 0.000115559 | gnorm 0.298 | clip 0 | loss_scale 32 | train_wall 973 | gb_free 12.8 | wall 10740
2023-08-21 20:44:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 20:44:01 | INFO | fairseq.trainer | begin training epoch 16
2023-08-21 20:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 20:44:29 | INFO | train_inner | epoch 016:     23 / 1080 loss=1.836, trans_loss=3.291, nll_loss=1.333, w2v_ctc_loss=0.843, task_loss=0, contrastive_loss=0.195, total=7282.6, n_correct=5004.01, ppl=2.52, accuracy=68.712, wps=14215.4, ups=0.67, wpb=21105.4, bsz=742.1, num_updates=15000, lr=0.00011547, gnorm=0.304, clip=0, loss_scale=32, train_wall=89, gb_free=13.7, wall=10768
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:0')
2023-08-21 20:45:28 | INFO | train_inner | epoch 016:    123 / 1080 loss=1.954, trans_loss=4.726, nll_loss=1.893, w2v_ctc_loss=0.609, task_loss=0, contrastive_loss=0.092, total=7314.44, n_correct=5056.46, ppl=3.71, accuracy=69.13, wps=25040.5, ups=1.7, wpb=14692.6, bsz=480, num_updates=15100, lr=0.000115087, gnorm=0.379, clip=0, loss_scale=32, train_wall=58, gb_free=13.3, wall=10826
2023-08-21 20:46:26 | INFO | train_inner | epoch 016:    223 / 1080 loss=1.963, trans_loss=4.754, nll_loss=1.911, w2v_ctc_loss=0.601, task_loss=0, contrastive_loss=0.147, total=7465.4, n_correct=5159.21, ppl=3.76, accuracy=69.108, wps=25572.9, ups=1.71, wpb=14930.8, bsz=518.6, num_updates=15200, lr=0.000114708, gnorm=0.377, clip=0, loss_scale=32, train_wall=58, gb_free=14.7, wall=10885
2023-08-21 20:47:25 | INFO | train_inner | epoch 016:    323 / 1080 loss=1.957, trans_loss=4.747, nll_loss=1.903, w2v_ctc_loss=0.602, task_loss=0, contrastive_loss=0.118, total=7438.41, n_correct=5147.99, ppl=3.74, accuracy=69.208, wps=25332.5, ups=1.7, wpb=14876.8, bsz=509.9, num_updates=15300, lr=0.000114332, gnorm=0.372, clip=0, loss_scale=32, train_wall=58, gb_free=13.7, wall=10944
2023-08-21 20:48:23 | INFO | train_inner | epoch 016:    423 / 1080 loss=1.956, trans_loss=4.75, nll_loss=1.906, w2v_ctc_loss=0.604, task_loss=0, contrastive_loss=0.091, total=7389.6, n_correct=5109.02, ppl=3.75, accuracy=69.138, wps=25366.1, ups=1.72, wpb=14779.2, bsz=494.7, num_updates=15400, lr=0.000113961, gnorm=0.374, clip=0, loss_scale=32, train_wall=58, gb_free=12.7, wall=11002
2023-08-21 20:49:23 | INFO | train_inner | epoch 016:    523 / 1080 loss=1.958, trans_loss=4.744, nll_loss=1.9, w2v_ctc_loss=0.61, task_loss=0, contrastive_loss=0.095, total=7516.98, n_correct=5207.77, ppl=3.73, accuracy=69.28, wps=25396.4, ups=1.69, wpb=15034, bsz=520, num_updates=15500, lr=0.000113592, gnorm=0.377, clip=0, loss_scale=32, train_wall=59, gb_free=13.2, wall=11061
2023-08-21 20:50:21 | INFO | train_inner | epoch 016:    623 / 1080 loss=1.969, trans_loss=4.762, nll_loss=1.922, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.126, total=7326.71, n_correct=5040.82, ppl=3.79, accuracy=68.801, wps=24956.8, ups=1.7, wpb=14653.4, bsz=483.7, num_updates=15600, lr=0.000113228, gnorm=0.38, clip=0, loss_scale=32, train_wall=58, gb_free=9.7, wall=11120
2023-08-21 20:51:20 | INFO | train_inner | epoch 016:    723 / 1080 loss=1.959, trans_loss=4.755, nll_loss=1.913, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.067, total=7391.31, n_correct=5095.96, ppl=3.77, accuracy=68.945, wps=25265.9, ups=1.71, wpb=14782.6, bsz=491, num_updates=15700, lr=0.000112867, gnorm=0.377, clip=0, loss_scale=32, train_wall=58, gb_free=11.9, wall=11178
2023-08-21 20:52:18 | INFO | train_inner | epoch 016:    823 / 1080 loss=1.967, trans_loss=4.761, nll_loss=1.923, w2v_ctc_loss=0.608, task_loss=0, contrastive_loss=0.129, total=7528.55, n_correct=5190.41, ppl=3.79, accuracy=68.943, wps=25813.3, ups=1.71, wpb=15057.1, bsz=527, num_updates=15800, lr=0.000112509, gnorm=0.377, clip=0, loss_scale=32, train_wall=58, gb_free=13.7, wall=11237
2023-08-21 20:53:16 | INFO | train_inner | epoch 016:    923 / 1080 loss=1.966, trans_loss=4.762, nll_loss=1.924, w2v_ctc_loss=0.615, task_loss=0, contrastive_loss=0.093, total=7375.91, n_correct=5085.16, ppl=3.79, accuracy=68.943, wps=25334, ups=1.72, wpb=14751.8, bsz=503.5, num_updates=15900, lr=0.000112154, gnorm=0.379, clip=0, loss_scale=32, train_wall=58, gb_free=15, wall=11295
2023-08-21 20:54:15 | INFO | train_inner | epoch 016:   1023 / 1080 loss=1.969, trans_loss=4.766, nll_loss=1.928, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.139, total=7370.36, n_correct=5073.08, ppl=3.81, accuracy=68.831, wps=24999.2, ups=1.7, wpb=14740.7, bsz=489.1, num_updates=16000, lr=0.000111803, gnorm=0.378, clip=0, loss_scale=32, train_wall=58, gb_free=11.9, wall=11354
2023-08-21 20:54:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:6')
2023-08-21 20:54:54 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.074 | trans_loss 5.203 | nll_loss 2.408 | w2v_ctc_loss 1.265 | task_loss 0 | contrastive_loss 0.262 | total 6138.43 | n_correct 4139.71 | ppl 5.31 | accuracy 67.439 | uer 16.952 | wer 18.717 | raw_wer 18.717 | bleu 26.99 | wps 1322.8 | wpb 6138.4 | bsz 201.1 | num_updates 16000 | best_bleu 27.16
2023-08-21 20:54:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 16000 updates
2023-08-21 20:54:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_16_16000.pt
2023-08-21 20:54:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_16_16000.pt
2023-08-21 20:55:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_16_16000.pt (epoch 16 @ 16000 updates, score 26.99) (writing took 7.421860740985721 seconds)
2023-08-21 20:55:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 20:56:14 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.081 | trans_loss 5.196 | nll_loss 2.402 | w2v_ctc_loss 1.293 | task_loss 0 | contrastive_loss 0.272 | total 6138.43 | n_correct 4147 | ppl 5.28 | accuracy 67.558 | uer 17.343 | wer 18.959 | raw_wer 18.959 | bleu 27.23 | wps 1332.1 | wpb 6138.4 | bsz 201.1 | num_updates 16057 | best_bleu 27.23
2023-08-21 20:56:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 16057 updates
2023-08-21 20:56:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 20:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 20:56:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 16 @ 16057 updates, score 27.23) (writing took 10.214039410930127 seconds)
2023-08-21 20:56:24 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-21 20:56:24 | INFO | train | epoch 016 | loss 1.958 | trans_loss 4.711 | nll_loss 1.896 | w2v_ctc_loss 0.615 | task_loss 0 | contrastive_loss 0.116 | total 7392.68 | n_correct 5102.23 | ppl 3.72 | accuracy 69.017 | wps 21681.6 | ups 1.45 | wpb 14923.4 | bsz 503.5 | num_updates 16057 | lr 0.000111605 | gnorm 0.376 | clip 0 | loss_scale 32 | train_wall 634 | gb_free 13.8 | wall 11483
2023-08-21 20:56:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 20:56:25 | INFO | fairseq.trainer | begin training epoch 17
2023-08-21 20:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 20:56:57 | INFO | train_inner | epoch 017:     43 / 1080 loss=1.96, trans_loss=4.752, nll_loss=1.909, w2v_ctc_loss=0.608, task_loss=0, contrastive_loss=0.135, total=7242.48, n_correct=5000.32, ppl=3.76, accuracy=69.042, wps=8940.9, ups=0.62, wpb=14485, bsz=468.3, num_updates=16100, lr=0.000111456, gnorm=0.381, clip=0, loss_scale=32, train_wall=57, gb_free=12.6, wall=11516
2023-08-21 20:57:56 | INFO | train_inner | epoch 017:    143 / 1080 loss=1.943, trans_loss=4.729, nll_loss=1.88, w2v_ctc_loss=0.601, task_loss=0, contrastive_loss=0.07, total=7460.01, n_correct=5189.04, ppl=3.68, accuracy=69.558, wps=25551, ups=1.71, wpb=14920, bsz=508.8, num_updates=16200, lr=0.000111111, gnorm=0.372, clip=0, loss_scale=32, train_wall=58, gb_free=12.2, wall=11574
2023-08-21 20:58:53 | INFO | train_inner | epoch 017:    243 / 1080 loss=1.946, trans_loss=4.729, nll_loss=1.881, w2v_ctc_loss=0.598, task_loss=0, contrastive_loss=0.1, total=7454.04, n_correct=5187.35, ppl=3.68, accuracy=69.591, wps=25873.8, ups=1.74, wpb=14908.1, bsz=511.4, num_updates=16300, lr=0.00011077, gnorm=0.374, clip=0, loss_scale=32, train_wall=57, gb_free=14.3, wall=11632
2023-08-21 20:59:52 | INFO | train_inner | epoch 017:    343 / 1080 loss=1.964, trans_loss=4.745, nll_loss=1.902, w2v_ctc_loss=0.607, task_loss=0, contrastive_loss=0.171, total=7422.79, n_correct=5137.63, ppl=3.74, accuracy=69.214, wps=25277, ups=1.7, wpb=14845.6, bsz=510.1, num_updates=16400, lr=0.000110432, gnorm=0.379, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=11691
2023-08-21 21:00:51 | INFO | train_inner | epoch 017:    443 / 1080 loss=1.952, trans_loss=4.741, nll_loss=1.896, w2v_ctc_loss=0.613, task_loss=0, contrastive_loss=0.065, total=7290.92, n_correct=5053.97, ppl=3.72, accuracy=69.319, wps=24617.3, ups=1.69, wpb=14581.8, bsz=477.8, num_updates=16500, lr=0.000110096, gnorm=0.377, clip=0, loss_scale=64, train_wall=59, gb_free=13.8, wall=11750
2023-08-21 21:01:50 | INFO | train_inner | epoch 017:    543 / 1080 loss=1.961, trans_loss=4.745, nll_loss=1.902, w2v_ctc_loss=0.612, task_loss=0, contrastive_loss=0.126, total=7499.14, n_correct=5195.05, ppl=3.74, accuracy=69.275, wps=25478.2, ups=1.7, wpb=14998.3, bsz=511, num_updates=16600, lr=0.000109764, gnorm=0.377, clip=0, loss_scale=64, train_wall=58, gb_free=14.2, wall=11809
2023-08-21 21:02:48 | INFO | train_inner | epoch 017:    643 / 1080 loss=1.954, trans_loss=4.746, nll_loss=1.903, w2v_ctc_loss=0.604, task_loss=0, contrastive_loss=0.109, total=7283.98, n_correct=5038.35, ppl=3.74, accuracy=69.17, wps=25048.9, ups=1.72, wpb=14568, bsz=473.8, num_updates=16700, lr=0.000109435, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=13.7, wall=11867
2023-08-21 21:03:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-21 21:03:47 | INFO | train_inner | epoch 017:    744 / 1080 loss=1.955, trans_loss=4.742, nll_loss=1.898, w2v_ctc_loss=0.605, task_loss=0, contrastive_loss=0.127, total=7450.35, n_correct=5166.19, ppl=3.73, accuracy=69.342, wps=25228.8, ups=1.69, wpb=14900.7, bsz=516.2, num_updates=16800, lr=0.000109109, gnorm=0.377, clip=0, loss_scale=32, train_wall=59, gb_free=12.7, wall=11926
2023-08-21 21:04:46 | INFO | train_inner | epoch 017:    844 / 1080 loss=1.962, trans_loss=4.749, nll_loss=1.908, w2v_ctc_loss=0.609, task_loss=0, contrastive_loss=0.152, total=7328.73, n_correct=5065.42, ppl=3.75, accuracy=69.117, wps=25064.9, ups=1.71, wpb=14657.5, bsz=495.5, num_updates=16900, lr=0.000108786, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=11984
2023-08-21 21:05:45 | INFO | train_inner | epoch 017:    944 / 1080 loss=1.958, trans_loss=4.745, nll_loss=1.902, w2v_ctc_loss=0.61, task_loss=0, contrastive_loss=0.12, total=7370.33, n_correct=5104.34, ppl=3.74, accuracy=69.255, wps=25024.3, ups=1.7, wpb=14740.7, bsz=489.3, num_updates=17000, lr=0.000108465, gnorm=0.38, clip=0, loss_scale=32, train_wall=58, gb_free=11.8, wall=12043
2023-08-21 21:06:44 | INFO | train_inner | epoch 017:   1044 / 1080 loss=1.947, trans_loss=4.741, nll_loss=1.897, w2v_ctc_loss=0.603, task_loss=0, contrastive_loss=0.063, total=7431.99, n_correct=5158.17, ppl=3.72, accuracy=69.405, wps=25153.1, ups=1.69, wpb=14864, bsz=499.5, num_updates=17100, lr=0.000108148, gnorm=0.376, clip=0, loss_scale=32, train_wall=59, gb_free=14.6, wall=12102
2023-08-21 21:07:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 21:07:43 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.065 | trans_loss 5.19 | nll_loss 2.394 | w2v_ctc_loss 1.261 | task_loss 0 | contrastive_loss 0.267 | total 6138.43 | n_correct 4150.14 | ppl 5.26 | accuracy 67.609 | uer 17.059 | wer 18.829 | raw_wer 18.829 | bleu 26.76 | wps 1332.2 | wpb 6138.4 | bsz 201.1 | num_updates 17136 | best_bleu 27.23
2023-08-21 21:07:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 17136 updates
2023-08-21 21:07:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_26.7601.pt
2023-08-21 21:07:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_26.7601.pt
2023-08-21 21:07:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_26.7601.pt (epoch 17 @ 17136 updates, score 26.76) (writing took 10.687055137008429 seconds)
2023-08-21 21:07:54 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-21 21:07:54 | INFO | train | epoch 017 | loss 1.954 | trans_loss 4.741 | nll_loss 1.897 | w2v_ctc_loss 0.606 | task_loss 0 | contrastive_loss 0.11 | total 7392.34 | n_correct 5125.17 | ppl 3.72 | accuracy 69.331 | wps 23121.7 | ups 1.56 | wpb 14784.7 | bsz 498.3 | num_updates 17136 | lr 0.000108034 | gnorm 0.377 | clip 0 | loss_scale 32 | train_wall 626 | gb_free 14.1 | wall 12173
2023-08-21 21:07:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 21:07:55 | INFO | fairseq.trainer | begin training epoch 18
2023-08-21 21:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 21:08:40 | INFO | train_inner | epoch 018:     64 / 1080 loss=1.947, trans_loss=4.724, nll_loss=1.875, w2v_ctc_loss=0.595, task_loss=0, contrastive_loss=0.141, total=7583.34, n_correct=5290.82, ppl=3.67, accuracy=69.769, wps=13112.4, ups=0.86, wpb=15166.7, bsz=544, num_updates=17200, lr=0.000107833, gnorm=0.376, clip=0, loss_scale=32, train_wall=57, gb_free=14.9, wall=12218
2023-08-21 21:09:38 | INFO | train_inner | epoch 018:    164 / 1080 loss=1.939, trans_loss=4.721, nll_loss=1.87, w2v_ctc_loss=0.591, task_loss=0, contrastive_loss=0.113, total=7334.39, n_correct=5121.55, ppl=3.66, accuracy=69.829, wps=25261.8, ups=1.72, wpb=14668.8, bsz=483, num_updates=17300, lr=0.000107521, gnorm=0.379, clip=0, loss_scale=32, train_wall=58, gb_free=13.8, wall=12276
2023-08-21 21:10:36 | INFO | train_inner | epoch 018:    264 / 1080 loss=1.943, trans_loss=4.722, nll_loss=1.872, w2v_ctc_loss=0.598, task_loss=0, contrastive_loss=0.127, total=7454.04, n_correct=5203.77, ppl=3.66, accuracy=69.811, wps=25448.3, ups=1.71, wpb=14908.1, bsz=505, num_updates=17400, lr=0.000107211, gnorm=0.375, clip=0, loss_scale=32, train_wall=58, gb_free=10.1, wall=12335
2023-08-21 21:11:35 | INFO | train_inner | epoch 018:    364 / 1080 loss=1.945, trans_loss=4.729, nll_loss=1.881, w2v_ctc_loss=0.599, task_loss=0, contrastive_loss=0.105, total=7323.09, n_correct=5093.25, ppl=3.68, accuracy=69.551, wps=24755.3, ups=1.69, wpb=14646.2, bsz=482.1, num_updates=17500, lr=0.000106904, gnorm=0.379, clip=0, loss_scale=32, train_wall=59, gb_free=13.6, wall=12394
2023-08-21 21:12:34 | INFO | train_inner | epoch 018:    464 / 1080 loss=1.937, trans_loss=4.727, nll_loss=1.878, w2v_ctc_loss=0.593, task_loss=0, contrastive_loss=0.062, total=7350.07, n_correct=5125.66, ppl=3.68, accuracy=69.736, wps=25088.3, ups=1.71, wpb=14700.1, bsz=489, num_updates=17600, lr=0.0001066, gnorm=0.376, clip=0, loss_scale=32, train_wall=58, gb_free=14, wall=12453
2023-08-21 21:13:32 | INFO | train_inner | epoch 018:    564 / 1080 loss=1.949, trans_loss=4.733, nll_loss=1.887, w2v_ctc_loss=0.609, task_loss=0, contrastive_loss=0.085, total=7229.09, n_correct=5021.87, ppl=3.7, accuracy=69.468, wps=24893.9, ups=1.72, wpb=14458.2, bsz=469.9, num_updates=17700, lr=0.000106299, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=14.4, wall=12511
2023-08-21 21:14:31 | INFO | train_inner | epoch 018:    664 / 1080 loss=1.952, trans_loss=4.734, nll_loss=1.89, w2v_ctc_loss=0.599, task_loss=0, contrastive_loss=0.148, total=7440.52, n_correct=5172.73, ppl=3.71, accuracy=69.521, wps=25385.6, ups=1.71, wpb=14881, bsz=523.7, num_updates=17800, lr=0.000106, gnorm=0.379, clip=0, loss_scale=32, train_wall=58, gb_free=10.6, wall=12569
2023-08-21 21:15:29 | INFO | train_inner | epoch 018:    764 / 1080 loss=1.936, trans_loss=4.723, nll_loss=1.875, w2v_ctc_loss=0.591, task_loss=0, contrastive_loss=0.068, total=7413.16, n_correct=5173.1, ppl=3.67, accuracy=69.783, wps=25452.6, ups=1.72, wpb=14826.3, bsz=498.6, num_updates=17900, lr=0.000105703, gnorm=0.374, clip=0, loss_scale=32, train_wall=58, gb_free=14.1, wall=12627
2023-08-21 21:16:27 | INFO | train_inner | epoch 018:    864 / 1080 loss=1.951, trans_loss=4.735, nll_loss=1.89, w2v_ctc_loss=0.606, task_loss=0, contrastive_loss=0.121, total=7425.55, n_correct=5161.29, ppl=3.71, accuracy=69.507, wps=25364.9, ups=1.71, wpb=14851.1, bsz=498.9, num_updates=18000, lr=0.000105409, gnorm=0.377, clip=0, loss_scale=32, train_wall=58, gb_free=12, wall=12686
2023-08-21 21:16:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 21:17:06 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.064 | trans_loss 5.192 | nll_loss 2.401 | w2v_ctc_loss 1.258 | task_loss 0 | contrastive_loss 0.26 | total 6138.43 | n_correct 4156.14 | ppl 5.28 | accuracy 67.707 | uer 16.918 | wer 18.669 | raw_wer 18.669 | bleu 27.25 | wps 1314.2 | wpb 6138.4 | bsz 201.1 | num_updates 18000 | best_bleu 27.25
2023-08-21 21:17:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 18000 updates
2023-08-21 21:17:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_18_18000.pt
2023-08-21 21:17:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_18_18000.pt
2023-08-21 21:17:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_18_18000.pt (epoch 18 @ 18000 updates, score 27.25) (writing took 11.906716987956315 seconds)
2023-08-21 21:18:17 | INFO | train_inner | epoch 018:    964 / 1080 loss=1.947, trans_loss=4.731, nll_loss=1.885, w2v_ctc_loss=0.603, task_loss=0, contrastive_loss=0.107, total=7444.68, n_correct=5183.58, ppl=3.69, accuracy=69.628, wps=13559.4, ups=0.91, wpb=14889.4, bsz=500.6, num_updates=18100, lr=0.000105118, gnorm=0.378, clip=0, loss_scale=32, train_wall=58, gb_free=13.4, wall=12796
2023-08-21 21:19:15 | INFO | train_inner | epoch 018:   1064 / 1080 loss=1.952, trans_loss=4.74, nll_loss=1.898, w2v_ctc_loss=0.604, task_loss=0, contrastive_loss=0.116, total=7386.3, n_correct=5129.84, ppl=3.73, accuracy=69.451, wps=25417.7, ups=1.72, wpb=14772.6, bsz=500.8, num_updates=18200, lr=0.000104828, gnorm=0.38, clip=0, loss_scale=32, train_wall=58, gb_free=11, wall=12854
2023-08-21 21:19:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 21:20:03 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.056 | trans_loss 5.186 | nll_loss 2.393 | w2v_ctc_loss 1.24 | task_loss 0 | contrastive_loss 0.267 | total 6138.43 | n_correct 4160.71 | ppl 5.25 | accuracy 67.781 | uer 17.027 | wer 18.762 | raw_wer 18.762 | bleu 26.85 | wps 1335.5 | wpb 6138.4 | bsz 201.1 | num_updates 18216 | best_bleu 27.25
2023-08-21 21:20:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 18216 updates
2023-08-21 21:20:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_26.8502.pt
2023-08-21 21:20:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_26.8502.pt
2023-08-21 21:20:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_26.8502.pt (epoch 18 @ 18216 updates, score 26.85) (writing took 6.76549616700504 seconds)
2023-08-21 21:20:10 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-21 21:20:10 | INFO | train | epoch 018 | loss 1.945 | trans_loss 4.729 | nll_loss 1.881 | w2v_ctc_loss 0.599 | task_loss 0 | contrastive_loss 0.112 | total 7392.68 | n_correct 5148.57 | ppl 3.68 | accuracy 69.644 | wps 21709.4 | ups 1.47 | wpb 14785.4 | bsz 498.6 | num_updates 18216 | lr 0.000104782 | gnorm 0.378 | clip 0 | loss_scale 32 | train_wall 625 | gb_free 13.8 | wall 12909
2023-08-21 21:20:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 21:20:10 | INFO | fairseq.trainer | begin training epoch 19
2023-08-21 21:20:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 21:21:07 | INFO | train_inner | epoch 019:     84 / 1080 loss=1.935, trans_loss=4.711, nll_loss=1.858, w2v_ctc_loss=0.59, task_loss=0, contrastive_loss=0.116, total=7334.5, n_correct=5135.82, ppl=3.63, accuracy=70.023, wps=13153.9, ups=0.9, wpb=14669, bsz=494.9, num_updates=18300, lr=0.000104542, gnorm=0.378, clip=0, loss_scale=32, train_wall=57, gb_free=13.7, wall=12965
2023-08-21 21:22:06 | INFO | train_inner | epoch 019:    184 / 1080 loss=1.924, trans_loss=4.702, nll_loss=1.846, w2v_ctc_loss=0.59, task_loss=0, contrastive_loss=0.055, total=7337.56, n_correct=5155.16, ppl=3.6, accuracy=70.257, wps=24818.2, ups=1.69, wpb=14675.1, bsz=473.8, num_updates=18400, lr=0.000104257, gnorm=0.379, clip=0, loss_scale=32, train_wall=58, gb_free=13.8, wall=13025
2023-08-21 21:23:05 | INFO | train_inner | epoch 019:    284 / 1080 loss=1.936, trans_loss=4.711, nll_loss=1.859, w2v_ctc_loss=0.591, task_loss=0, contrastive_loss=0.127, total=7404.31, n_correct=5186.77, ppl=3.63, accuracy=70.051, wps=25342.6, ups=1.71, wpb=14808.6, bsz=507.5, num_updates=18500, lr=0.000103975, gnorm=0.381, clip=0, loss_scale=32, train_wall=58, gb_free=13.7, wall=13083
2023-08-21 21:24:03 | INFO | train_inner | epoch 019:    384 / 1080 loss=1.939, trans_loss=4.714, nll_loss=1.863, w2v_ctc_loss=0.595, task_loss=0, contrastive_loss=0.12, total=7475.29, n_correct=5229.57, ppl=3.64, accuracy=69.958, wps=25456, ups=1.7, wpb=14950.6, bsz=525.8, num_updates=18600, lr=0.000103695, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=13142
2023-08-21 21:25:01 | INFO | train_inner | epoch 019:    484 / 1080 loss=1.93, trans_loss=4.716, nll_loss=1.865, w2v_ctc_loss=0.588, task_loss=0, contrastive_loss=0.076, total=7317.67, n_correct=5118.71, ppl=3.64, accuracy=69.95, wps=25218.2, ups=1.72, wpb=14635.3, bsz=475.4, num_updates=18700, lr=0.000103418, gnorm=0.376, clip=0, loss_scale=32, train_wall=57, gb_free=13.9, wall=13200
2023-08-21 21:25:59 | INFO | train_inner | epoch 019:    584 / 1080 loss=1.947, trans_loss=4.728, nll_loss=1.88, w2v_ctc_loss=0.596, task_loss=0, contrastive_loss=0.171, total=7337.24, n_correct=5115.29, ppl=3.68, accuracy=69.717, wps=25398.6, ups=1.73, wpb=14674.5, bsz=495.4, num_updates=18800, lr=0.000103142, gnorm=0.381, clip=0, loss_scale=64, train_wall=57, gb_free=12.2, wall=13258
2023-08-21 21:26:57 | INFO | train_inner | epoch 019:    684 / 1080 loss=1.94, trans_loss=4.711, nll_loss=1.86, w2v_ctc_loss=0.591, task_loss=0, contrastive_loss=0.157, total=7427.22, n_correct=5208.44, ppl=3.63, accuracy=70.126, wps=25544.4, ups=1.72, wpb=14854.4, bsz=516.8, num_updates=18900, lr=0.000102869, gnorm=0.379, clip=0, loss_scale=64, train_wall=58, gb_free=13.6, wall=13316
2023-08-21 21:27:56 | INFO | train_inner | epoch 019:    784 / 1080 loss=1.943, trans_loss=4.73, nll_loss=1.884, w2v_ctc_loss=0.597, task_loss=0, contrastive_loss=0.116, total=7269.79, n_correct=5068.55, ppl=3.69, accuracy=69.721, wps=24667.9, ups=1.7, wpb=14539.6, bsz=476, num_updates=19000, lr=0.000102598, gnorm=0.384, clip=0, loss_scale=64, train_wall=58, gb_free=13.9, wall=13375
2023-08-21 21:28:55 | INFO | train_inner | epoch 019:    884 / 1080 loss=1.942, trans_loss=4.721, nll_loss=1.873, w2v_ctc_loss=0.598, task_loss=0, contrastive_loss=0.117, total=7484.6, n_correct=5228.68, ppl=3.66, accuracy=69.859, wps=25588.2, ups=1.71, wpb=14969.2, bsz=514.1, num_updates=19100, lr=0.000102329, gnorm=0.377, clip=0, loss_scale=64, train_wall=58, gb_free=15.1, wall=13433
2023-08-21 21:29:53 | INFO | train_inner | epoch 019:    984 / 1080 loss=1.932, trans_loss=4.72, nll_loss=1.872, w2v_ctc_loss=0.593, task_loss=0, contrastive_loss=0.065, total=7486.61, n_correct=5238.64, ppl=3.66, accuracy=69.973, wps=25626.1, ups=1.71, wpb=14973.2, bsz=507, num_updates=19200, lr=0.000102062, gnorm=0.373, clip=0, loss_scale=64, train_wall=58, gb_free=13.8, wall=13492
2023-08-21 21:30:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 21:31:27 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.078 | trans_loss 5.18 | nll_loss 2.387 | w2v_ctc_loss 1.327 | task_loss 0 | contrastive_loss 0.266 | total 6138.43 | n_correct 4165.43 | ppl 5.23 | accuracy 67.858 | uer 17.099 | wer 18.843 | raw_wer 18.843 | bleu 27.44 | wps 1336.5 | wpb 6138.4 | bsz 201.1 | num_updates 19296 | best_bleu 27.44
2023-08-21 21:31:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 19296 updates
2023-08-21 21:31:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 21:31:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 21:31:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 19 @ 19296 updates, score 27.44) (writing took 14.278245769906789 seconds)
2023-08-21 21:31:42 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-21 21:31:42 | INFO | train | epoch 019 | loss 1.937 | trans_loss 4.718 | nll_loss 1.868 | w2v_ctc_loss 0.593 | task_loss 0 | contrastive_loss 0.111 | total 7392.68 | n_correct 5170.24 | ppl 3.65 | accuracy 69.937 | wps 23071.3 | ups 1.56 | wpb 14785.4 | bsz 498.6 | num_updates 19296 | lr 0.000101808 | gnorm 0.38 | clip 0 | loss_scale 64 | train_wall 625 | gb_free 13.5 | wall 13601
2023-08-21 21:31:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 21:31:42 | INFO | fairseq.trainer | begin training epoch 20
2023-08-21 21:31:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 21:31:52 | INFO | train_inner | epoch 020:      4 / 1080 loss=1.947, trans_loss=4.736, nll_loss=1.893, w2v_ctc_loss=0.602, task_loss=0, contrastive_loss=0.106, total=7393.52, n_correct=5138.86, ppl=3.71, accuracy=69.505, wps=12402.4, ups=0.84, wpb=14787, bsz=490.2, num_updates=19300, lr=0.000101797, gnorm=0.39, clip=0, loss_scale=64, train_wall=58, gb_free=13.8, wall=13611
2023-08-21 21:32:51 | INFO | train_inner | epoch 020:    104 / 1080 loss=1.932, trans_loss=4.703, nll_loss=1.849, w2v_ctc_loss=0.596, task_loss=0, contrastive_loss=0.106, total=7352.7, n_correct=5161.59, ppl=3.6, accuracy=70.2, wps=25056.2, ups=1.7, wpb=14705.4, bsz=496.6, num_updates=19400, lr=0.000101535, gnorm=0.383, clip=0, loss_scale=64, train_wall=58, gb_free=12.9, wall=13670
2023-08-21 21:33:49 | INFO | train_inner | epoch 020:    204 / 1080 loss=1.925, trans_loss=4.695, nll_loss=1.84, w2v_ctc_loss=0.584, task_loss=0, contrastive_loss=0.108, total=7440.09, n_correct=5238.04, ppl=3.58, accuracy=70.403, wps=25575.3, ups=1.72, wpb=14880.2, bsz=509.1, num_updates=19500, lr=0.000101274, gnorm=0.376, clip=0, loss_scale=64, train_wall=57, gb_free=14.2, wall=13728
2023-08-21 21:34:48 | INFO | train_inner | epoch 020:    304 / 1080 loss=1.926, trans_loss=4.702, nll_loss=1.848, w2v_ctc_loss=0.585, task_loss=0, contrastive_loss=0.107, total=7379.63, n_correct=5188.8, ppl=3.6, accuracy=70.312, wps=25287.2, ups=1.71, wpb=14759.3, bsz=500.3, num_updates=19600, lr=0.000101015, gnorm=0.379, clip=0, loss_scale=64, train_wall=58, gb_free=12.7, wall=13786
2023-08-21 21:35:46 | INFO | train_inner | epoch 020:    404 / 1080 loss=1.932, trans_loss=4.705, nll_loss=1.852, w2v_ctc_loss=0.583, task_loss=0, contrastive_loss=0.146, total=7397.87, n_correct=5195.1, ppl=3.61, accuracy=70.224, wps=25434.1, ups=1.72, wpb=14795.7, bsz=506.2, num_updates=19700, lr=0.000100759, gnorm=0.378, clip=0, loss_scale=64, train_wall=58, gb_free=14.4, wall=13844
2023-08-21 21:36:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-21 21:36:45 | INFO | train_inner | epoch 020:    505 / 1080 loss=1.931, trans_loss=4.708, nll_loss=1.855, w2v_ctc_loss=0.586, task_loss=0, contrastive_loss=0.127, total=7394.04, n_correct=5183.81, ppl=3.62, accuracy=70.108, wps=25022, ups=1.69, wpb=14788.1, bsz=483.8, num_updates=19800, lr=0.000100504, gnorm=0.375, clip=0, loss_scale=32, train_wall=59, gb_free=11.3, wall=13903
2023-08-21 21:37:44 | INFO | train_inner | epoch 020:    605 / 1080 loss=1.933, trans_loss=4.705, nll_loss=1.853, w2v_ctc_loss=0.583, task_loss=0, contrastive_loss=0.148, total=7485.04, n_correct=5252.81, ppl=3.61, accuracy=70.177, wps=25522, ups=1.7, wpb=14970.1, bsz=523.2, num_updates=19900, lr=0.000100251, gnorm=0.38, clip=0, loss_scale=32, train_wall=58, gb_free=8.8, wall=13962
2023-08-21 21:38:43 | INFO | train_inner | epoch 020:    705 / 1080 loss=1.926, trans_loss=4.714, nll_loss=1.863, w2v_ctc_loss=0.587, task_loss=0, contrastive_loss=0.06, total=7473.89, n_correct=5238.79, ppl=3.64, accuracy=70.095, wps=25263.7, ups=1.69, wpb=14947.8, bsz=499.4, num_updates=20000, lr=0.0001, gnorm=0.374, clip=0, loss_scale=32, train_wall=59, gb_free=14, wall=14021
2023-08-21 21:38:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 21:39:21 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.053 | trans_loss 5.181 | nll_loss 2.387 | w2v_ctc_loss 1.242 | task_loss 0 | contrastive_loss 0.264 | total 6138.43 | n_correct 4157.14 | ppl 5.23 | accuracy 67.723 | uer 16.682 | wer 18.323 | raw_wer 18.323 | bleu 27.24 | wps 1334 | wpb 6138.4 | bsz 201.1 | num_updates 20000 | best_bleu 27.44
2023-08-21 21:39:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 20000 updates
2023-08-21 21:39:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_20_20000.pt
2023-08-21 21:39:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_20_20000.pt
2023-08-21 21:39:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_20_20000.pt (epoch 20 @ 20000 updates, score 27.24) (writing took 13.753216149052605 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:0')
2023-08-21 21:40:35 | INFO | train_inner | epoch 020:    805 / 1080 loss=1.929, trans_loss=4.712, nll_loss=1.862, w2v_ctc_loss=0.592, task_loss=0, contrastive_loss=0.067, total=7311.19, n_correct=5123.32, ppl=3.63, accuracy=70.075, wps=13019.5, ups=0.89, wpb=14622.4, bsz=471.3, num_updates=20100, lr=9.97509e-05, gnorm=0.377, clip=0, loss_scale=32, train_wall=58, gb_free=13.9, wall=14134
2023-08-21 21:41:34 | INFO | train_inner | epoch 020:    905 / 1080 loss=1.931, trans_loss=4.716, nll_loss=1.867, w2v_ctc_loss=0.595, task_loss=0, contrastive_loss=0.061, total=7319.51, n_correct=5122.31, ppl=3.65, accuracy=69.982, wps=24966.8, ups=1.71, wpb=14639, bsz=482.4, num_updates=20200, lr=9.95037e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=58, gb_free=7.3, wall=14192
2023-08-21 21:42:32 | INFO | train_inner | epoch 020:   1005 / 1080 loss=1.933, trans_loss=4.714, nll_loss=1.864, w2v_ctc_loss=0.59, task_loss=0, contrastive_loss=0.116, total=7311.64, n_correct=5123.56, ppl=3.64, accuracy=70.074, wps=24969.2, ups=1.71, wpb=14623.3, bsz=487.2, num_updates=20300, lr=9.92583e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=58, gb_free=13.4, wall=14251
2023-08-21 21:43:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:5')
2023-08-21 21:43:54 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.055 | trans_loss 5.175 | nll_loss 2.376 | w2v_ctc_loss 1.264 | task_loss 0 | contrastive_loss 0.261 | total 6138.43 | n_correct 4171.86 | ppl 5.19 | accuracy 67.963 | uer 16.623 | wer 18.245 | raw_wer 18.245 | bleu 27.71 | wps 1342.2 | wpb 6138.4 | bsz 201.1 | num_updates 20375 | best_bleu 27.71
2023-08-21 21:43:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 20375 updates
2023-08-21 21:43:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 21:44:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 21:44:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 20 @ 20375 updates, score 27.71) (writing took 13.652043292066082 seconds)
2023-08-21 21:44:08 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-21 21:44:08 | INFO | train | epoch 020 | loss 1.93 | trans_loss 4.708 | nll_loss 1.855 | w2v_ctc_loss 0.587 | task_loss 0 | contrastive_loss 0.106 | total 7391.55 | n_correct 5186.42 | ppl 3.62 | accuracy 70.167 | wps 21388.4 | ups 1.45 | wpb 14783.1 | bsz 498.1 | num_updates 20375 | lr 9.90755e-05 | gnorm 0.378 | clip 0 | loss_scale 32 | train_wall 626 | gb_free 11.7 | wall 14346
2023-08-21 21:44:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 21:44:08 | INFO | fairseq.trainer | begin training epoch 21
2023-08-21 21:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 21:44:30 | INFO | train_inner | epoch 021:     25 / 1080 loss=1.927, trans_loss=4.704, nll_loss=1.852, w2v_ctc_loss=0.581, task_loss=0, contrastive_loss=0.112, total=7378.6, n_correct=5187.2, ppl=3.61, accuracy=70.301, wps=12486.7, ups=0.85, wpb=14757.2, bsz=512.5, num_updates=20400, lr=9.90148e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=57, gb_free=13.1, wall=14369
2023-08-21 21:45:29 | INFO | train_inner | epoch 021:    125 / 1080 loss=1.916, trans_loss=4.687, nll_loss=1.829, w2v_ctc_loss=0.576, task_loss=0, contrastive_loss=0.096, total=7379, n_correct=5213.6, ppl=3.55, accuracy=70.655, wps=25033, ups=1.7, wpb=14758, bsz=502.6, num_updates=20500, lr=9.8773e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=58, gb_free=12.7, wall=14428
2023-08-21 21:46:28 | INFO | train_inner | epoch 021:    225 / 1080 loss=1.924, trans_loss=4.688, nll_loss=1.83, w2v_ctc_loss=0.581, task_loss=0, contrastive_loss=0.151, total=7410.8, n_correct=5225.11, ppl=3.56, accuracy=70.507, wps=25287.8, ups=1.71, wpb=14821.6, bsz=508, num_updates=20600, lr=9.85329e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=58, gb_free=12.2, wall=14487
2023-08-21 21:47:26 | INFO | train_inner | epoch 021:    325 / 1080 loss=1.921, trans_loss=4.693, nll_loss=1.836, w2v_ctc_loss=0.579, task_loss=0, contrastive_loss=0.112, total=7344.51, n_correct=5169.01, ppl=3.57, accuracy=70.379, wps=25318.7, ups=1.72, wpb=14689, bsz=488.2, num_updates=20700, lr=9.82946e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=57, gb_free=13.8, wall=14545
2023-08-21 21:48:24 | INFO | train_inner | epoch 021:    425 / 1080 loss=1.918, trans_loss=4.69, nll_loss=1.833, w2v_ctc_loss=0.588, task_loss=0, contrastive_loss=0.062, total=7403.55, n_correct=5220.61, ppl=3.56, accuracy=70.515, wps=25469.7, ups=1.72, wpb=14807.1, bsz=480.5, num_updates=20800, lr=9.80581e-05, gnorm=0.379, clip=0, loss_scale=32, train_wall=57, gb_free=12.1, wall=14603
2023-08-21 21:49:22 | INFO | train_inner | epoch 021:    525 / 1080 loss=1.922, trans_loss=4.697, nll_loss=1.842, w2v_ctc_loss=0.579, task_loss=0, contrastive_loss=0.105, total=7418.52, n_correct=5227.23, ppl=3.59, accuracy=70.462, wps=25449.3, ups=1.72, wpb=14837, bsz=487.2, num_updates=20900, lr=9.78232e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=14661
2023-08-21 21:50:21 | INFO | train_inner | epoch 021:    625 / 1080 loss=1.937, trans_loss=4.709, nll_loss=1.859, w2v_ctc_loss=0.587, task_loss=0, contrastive_loss=0.17, total=7287.34, n_correct=5115.79, ppl=3.63, accuracy=70.201, wps=24729.7, ups=1.7, wpb=14574.7, bsz=500.2, num_updates=21000, lr=9.759e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=58, gb_free=13.9, wall=14720
2023-08-21 21:51:20 | INFO | train_inner | epoch 021:    725 / 1080 loss=1.924, trans_loss=4.704, nll_loss=1.852, w2v_ctc_loss=0.581, task_loss=0, contrastive_loss=0.1, total=7387.12, n_correct=5196.3, ppl=3.61, accuracy=70.343, wps=25235.2, ups=1.71, wpb=14774.2, bsz=507.4, num_updates=21100, lr=9.73585e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=58, gb_free=14.2, wall=14778
2023-08-21 21:52:18 | INFO | train_inner | epoch 021:    825 / 1080 loss=1.922, trans_loss=4.7, nll_loss=1.846, w2v_ctc_loss=0.575, task_loss=0, contrastive_loss=0.128, total=7485.43, n_correct=5267.73, ppl=3.6, accuracy=70.373, wps=25598.1, ups=1.71, wpb=14970.9, bsz=506.9, num_updates=21200, lr=9.71286e-05, gnorm=0.375, clip=0, loss_scale=32, train_wall=58, gb_free=12.8, wall=14837
2023-08-21 21:53:17 | INFO | train_inner | epoch 021:    925 / 1080 loss=1.925, trans_loss=4.705, nll_loss=1.853, w2v_ctc_loss=0.583, task_loss=0, contrastive_loss=0.095, total=7468.8, n_correct=5247.13, ppl=3.61, accuracy=70.254, wps=25522.7, ups=1.71, wpb=14937.6, bsz=513.3, num_updates=21300, lr=9.69003e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=58, gb_free=4, wall=14896
2023-08-21 21:54:16 | INFO | train_inner | epoch 021:   1025 / 1080 loss=1.928, trans_loss=4.709, nll_loss=1.859, w2v_ctc_loss=0.584, task_loss=0, contrastive_loss=0.103, total=7436.33, n_correct=5223.46, ppl=3.63, accuracy=70.242, wps=25216.1, ups=1.7, wpb=14872.7, bsz=501, num_updates=21400, lr=9.66736e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=14, wall=14955
2023-08-21 21:54:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 21:55:26 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.031 | trans_loss 5.169 | nll_loss 2.37 | w2v_ctc_loss 1.205 | task_loss 0 | contrastive_loss 0.257 | total 6138.43 | n_correct 4175.43 | ppl 5.17 | accuracy 68.021 | uer 16.297 | wer 18.111 | raw_wer 18.111 | bleu 27.37 | wps 1338.9 | wpb 6138.4 | bsz 201.1 | num_updates 21455 | best_bleu 27.71
2023-08-21 21:55:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 21455 updates
2023-08-21 21:55:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.3709.pt
2023-08-21 21:55:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.3709.pt
2023-08-21 21:55:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.3709.pt (epoch 21 @ 21455 updates, score 27.37) (writing took 9.373202602029778 seconds)
2023-08-21 21:55:36 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-21 21:55:36 | INFO | train | epoch 021 | loss 1.923 | trans_loss 4.698 | nll_loss 1.844 | w2v_ctc_loss 0.581 | task_loss 0 | contrastive_loss 0.109 | total 7392.68 | n_correct 5204.36 | ppl 3.59 | accuracy 70.399 | wps 23203.6 | ups 1.57 | wpb 14785.4 | bsz 498.6 | num_updates 21455 | lr 9.65497e-05 | gnorm 0.38 | clip 0 | loss_scale 32 | train_wall 625 | gb_free 5.9 | wall 15035
2023-08-21 21:55:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 21:55:36 | INFO | fairseq.trainer | begin training epoch 22
2023-08-21 21:55:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 21:56:10 | INFO | train_inner | epoch 022:     45 / 1080 loss=1.911, trans_loss=4.691, nll_loss=1.835, w2v_ctc_loss=0.573, task_loss=0, contrastive_loss=0.057, total=7300.1, n_correct=5152.95, ppl=3.57, accuracy=70.587, wps=12820.9, ups=0.88, wpb=14600.2, bsz=485.6, num_updates=21500, lr=9.64486e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=11.5, wall=15068
2023-08-21 21:57:08 | INFO | train_inner | epoch 022:    145 / 1080 loss=1.911, trans_loss=4.676, nll_loss=1.815, w2v_ctc_loss=0.563, task_loss=0, contrastive_loss=0.14, total=7428.39, n_correct=5266.36, ppl=3.52, accuracy=70.895, wps=25420.9, ups=1.71, wpb=14856.8, bsz=519.3, num_updates=21600, lr=9.6225e-05, gnorm=0.379, clip=0, loss_scale=32, train_wall=58, gb_free=10.1, wall=15127
2023-08-21 21:58:06 | INFO | train_inner | epoch 022:    245 / 1080 loss=1.907, trans_loss=4.677, nll_loss=1.816, w2v_ctc_loss=0.575, task_loss=0, contrastive_loss=0.061, total=7353.98, n_correct=5212.06, ppl=3.52, accuracy=70.874, wps=25353.4, ups=1.72, wpb=14708, bsz=490.7, num_updates=21700, lr=9.60031e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=57, gb_free=12.5, wall=15185
2023-08-21 21:59:04 | INFO | train_inner | epoch 022:    345 / 1080 loss=1.916, trans_loss=4.687, nll_loss=1.829, w2v_ctc_loss=0.579, task_loss=0, contrastive_loss=0.089, total=7374.31, n_correct=5208.87, ppl=3.55, accuracy=70.635, wps=25405.2, ups=1.72, wpb=14748.6, bsz=498.7, num_updates=21800, lr=9.57826e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=57, gb_free=10, wall=15243
2023-08-21 22:00:03 | INFO | train_inner | epoch 022:    445 / 1080 loss=1.909, trans_loss=4.679, nll_loss=1.82, w2v_ctc_loss=0.576, task_loss=0, contrastive_loss=0.073, total=7474.94, n_correct=5297.28, ppl=3.53, accuracy=70.867, wps=25477.2, ups=1.7, wpb=14949.9, bsz=500, num_updates=21900, lr=9.55637e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=58, gb_free=13.1, wall=15302
2023-08-21 22:01:02 | INFO | train_inner | epoch 022:    545 / 1080 loss=1.921, trans_loss=4.692, nll_loss=1.837, w2v_ctc_loss=0.575, task_loss=0, contrastive_loss=0.137, total=7497.24, n_correct=5294.06, ppl=3.57, accuracy=70.613, wps=25619, ups=1.71, wpb=14994.5, bsz=523.8, num_updates=22000, lr=9.53463e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=58, gb_free=13.5, wall=15360
2023-08-21 22:01:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 22:01:40 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.055 | trans_loss 5.179 | nll_loss 2.381 | w2v_ctc_loss 1.261 | task_loss 0 | contrastive_loss 0.257 | total 6138.43 | n_correct 4157.86 | ppl 5.21 | accuracy 67.735 | uer 16.514 | wer 18.04 | raw_wer 18.04 | bleu 27.36 | wps 1336.3 | wpb 6138.4 | bsz 201.1 | num_updates 22000 | best_bleu 27.71
2023-08-21 22:01:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 22000 updates
2023-08-21 22:01:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_22_22000.pt
2023-08-21 22:01:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_22_22000.pt
2023-08-21 22:01:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_22_22000.pt (epoch 22 @ 22000 updates, score 27.36) (writing took 8.982194382115267 seconds)
2023-08-21 22:02:48 | INFO | train_inner | epoch 022:    645 / 1080 loss=1.915, trans_loss=4.687, nll_loss=1.83, w2v_ctc_loss=0.571, task_loss=0, contrastive_loss=0.133, total=7452.96, n_correct=5269.2, ppl=3.56, accuracy=70.699, wps=13994.2, ups=0.94, wpb=14905.9, bsz=509.3, num_updates=22100, lr=9.51303e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=13.8, wall=15467
2023-08-21 22:03:47 | INFO | train_inner | epoch 022:    745 / 1080 loss=1.924, trans_loss=4.696, nll_loss=1.842, w2v_ctc_loss=0.573, task_loss=0, contrastive_loss=0.155, total=7386.18, n_correct=5204.67, ppl=3.59, accuracy=70.465, wps=25045.9, ups=1.7, wpb=14772.4, bsz=491.5, num_updates=22200, lr=9.49158e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=58, gb_free=13.8, wall=15526
2023-08-21 22:04:45 | INFO | train_inner | epoch 022:    845 / 1080 loss=1.91, trans_loss=4.693, nll_loss=1.838, w2v_ctc_loss=0.57, task_loss=0, contrastive_loss=0.063, total=7443.82, n_correct=5256.56, ppl=3.58, accuracy=70.616, wps=25628.1, ups=1.72, wpb=14887.6, bsz=503.4, num_updates=22300, lr=9.47027e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=57, gb_free=12.4, wall=15584
2023-08-21 22:05:43 | INFO | train_inner | epoch 022:    945 / 1080 loss=1.923, trans_loss=4.696, nll_loss=1.842, w2v_ctc_loss=0.578, task_loss=0, contrastive_loss=0.146, total=7314.17, n_correct=5154.76, ppl=3.59, accuracy=70.476, wps=25290.2, ups=1.73, wpb=14628.3, bsz=480.8, num_updates=22400, lr=9.44911e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=57, gb_free=10.2, wall=15642
2023-08-21 22:06:42 | INFO | train_inner | epoch 022:   1045 / 1080 loss=1.923, trans_loss=4.7, nll_loss=1.847, w2v_ctc_loss=0.578, task_loss=0, contrastive_loss=0.117, total=7396.66, n_correct=5208.22, ppl=3.6, accuracy=70.413, wps=25136.6, ups=1.7, wpb=14793.3, bsz=501, num_updates=22500, lr=9.42809e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=12.8, wall=15700
2023-08-21 22:07:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 22:07:41 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.057 | trans_loss 5.173 | nll_loss 2.374 | w2v_ctc_loss 1.274 | task_loss 0 | contrastive_loss 0.267 | total 6138.43 | n_correct 4165 | ppl 5.18 | accuracy 67.851 | uer 16.631 | wer 18.319 | raw_wer 18.319 | bleu 27.25 | wps 1326 | wpb 6138.4 | bsz 201.1 | num_updates 22535 | best_bleu 27.71
2023-08-21 22:07:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 22535 updates
2023-08-21 22:07:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.2503.pt
2023-08-21 22:07:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.2503.pt
2023-08-21 22:07:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.2503.pt (epoch 22 @ 22535 updates, score 27.25) (writing took 7.141766407992691 seconds)
2023-08-21 22:07:49 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-21 22:07:49 | INFO | train | epoch 022 | loss 1.916 | trans_loss 4.689 | nll_loss 1.832 | w2v_ctc_loss 0.574 | task_loss 0 | contrastive_loss 0.108 | total 7392.68 | n_correct 5222.6 | ppl 3.56 | accuracy 70.646 | wps 21785.1 | ups 1.47 | wpb 14785.4 | bsz 498.6 | num_updates 22535 | lr 9.42077e-05 | gnorm 0.379 | clip 0 | loss_scale 64 | train_wall 624 | gb_free 13.9 | wall 15768
2023-08-21 22:07:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 22:07:49 | INFO | fairseq.trainer | begin training epoch 23
2023-08-21 22:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 22:08:35 | INFO | train_inner | epoch 023:     65 / 1080 loss=1.906, trans_loss=4.678, nll_loss=1.819, w2v_ctc_loss=0.569, task_loss=0, contrastive_loss=0.067, total=7260.89, n_correct=5147.77, ppl=3.53, accuracy=70.897, wps=12787.6, ups=0.88, wpb=14521.8, bsz=485.4, num_updates=22600, lr=9.40721e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=58, gb_free=13.6, wall=15814
2023-08-21 22:09:34 | INFO | train_inner | epoch 023:    165 / 1080 loss=1.899, trans_loss=4.666, nll_loss=1.803, w2v_ctc_loss=0.567, task_loss=0, contrastive_loss=0.059, total=7336.34, n_correct=5217.77, ppl=3.49, accuracy=71.122, wps=25233.6, ups=1.72, wpb=14672.7, bsz=491, num_updates=22700, lr=9.38647e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=13.5, wall=15872
2023-08-21 22:10:32 | INFO | train_inner | epoch 023:    265 / 1080 loss=1.902, trans_loss=4.672, nll_loss=1.81, w2v_ctc_loss=0.564, task_loss=0, contrastive_loss=0.095, total=7369.4, n_correct=5240.42, ppl=3.51, accuracy=71.111, wps=25117.7, ups=1.7, wpb=14738.8, bsz=491, num_updates=22800, lr=9.36586e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=58, gb_free=12.9, wall=15931
2023-08-21 22:11:30 | INFO | train_inner | epoch 023:    365 / 1080 loss=1.912, trans_loss=4.678, nll_loss=1.818, w2v_ctc_loss=0.564, task_loss=0, contrastive_loss=0.148, total=7441.16, n_correct=5275.31, ppl=3.53, accuracy=70.894, wps=25606.6, ups=1.72, wpb=14882.3, bsz=513.3, num_updates=22900, lr=9.34539e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=57, gb_free=13.4, wall=15989
2023-08-21 22:12:29 | INFO | train_inner | epoch 023:    465 / 1080 loss=1.913, trans_loss=4.683, nll_loss=1.826, w2v_ctc_loss=0.572, task_loss=0, contrastive_loss=0.111, total=7478.5, n_correct=5297.17, ppl=3.54, accuracy=70.832, wps=25384.1, ups=1.7, wpb=14957, bsz=507.5, num_updates=23000, lr=9.32505e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=58, gb_free=14.7, wall=16048
2023-08-21 22:13:28 | INFO | train_inner | epoch 023:    565 / 1080 loss=1.916, trans_loss=4.682, nll_loss=1.824, w2v_ctc_loss=0.57, task_loss=0, contrastive_loss=0.164, total=7333.94, n_correct=5188.05, ppl=3.54, accuracy=70.74, wps=24999.9, ups=1.7, wpb=14667.9, bsz=480.9, num_updates=23100, lr=9.30484e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=58, gb_free=12.5, wall=16107
2023-08-21 22:14:27 | INFO | train_inner | epoch 023:    665 / 1080 loss=1.908, trans_loss=4.685, nll_loss=1.828, w2v_ctc_loss=0.572, task_loss=0, contrastive_loss=0.061, total=7399.36, n_correct=5236.95, ppl=3.55, accuracy=70.776, wps=25199.4, ups=1.7, wpb=14798.7, bsz=486.7, num_updates=23200, lr=9.28477e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=12.9, wall=16165
2023-08-21 22:15:25 | INFO | train_inner | epoch 023:    765 / 1080 loss=1.904, trans_loss=4.678, nll_loss=1.819, w2v_ctc_loss=0.565, task_loss=0, contrastive_loss=0.078, total=7439.9, n_correct=5281.21, ppl=3.53, accuracy=70.985, wps=25465, ups=1.71, wpb=14879.8, bsz=512.2, num_updates=23300, lr=9.26482e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=58, gb_free=10.3, wall=16224
2023-08-21 22:16:24 | INFO | train_inner | epoch 023:    865 / 1080 loss=1.913, trans_loss=4.689, nll_loss=1.834, w2v_ctc_loss=0.577, task_loss=0, contrastive_loss=0.073, total=7422.87, n_correct=5246.99, ppl=3.56, accuracy=70.687, wps=25336.5, ups=1.71, wpb=14845.7, bsz=511, num_updates=23400, lr=9.245e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=12.5, wall=16282
2023-08-21 22:17:22 | INFO | train_inner | epoch 023:    965 / 1080 loss=1.917, trans_loss=4.694, nll_loss=1.84, w2v_ctc_loss=0.567, task_loss=0, contrastive_loss=0.146, total=7461.13, n_correct=5264.3, ppl=3.58, accuracy=70.556, wps=25441.8, ups=1.7, wpb=14922.3, bsz=506.1, num_updates=23500, lr=9.22531e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=58, gb_free=13.3, wall=16341
2023-08-21 22:18:21 | INFO | train_inner | epoch 023:   1065 / 1080 loss=1.916, trans_loss=4.689, nll_loss=1.833, w2v_ctc_loss=0.564, task_loss=0, contrastive_loss=0.161, total=7335.52, n_correct=5183.47, ppl=3.56, accuracy=70.663, wps=24870.6, ups=1.7, wpb=14671, bsz=494.4, num_updates=23600, lr=9.20575e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=58, gb_free=9.5, wall=16400
2023-08-21 22:18:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 22:19:08 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.064 | trans_loss 5.172 | nll_loss 2.371 | w2v_ctc_loss 1.3 | task_loss 0 | contrastive_loss 0.263 | total 6138.43 | n_correct 4172.86 | ppl 5.17 | accuracy 67.979 | uer 16.677 | wer 18.386 | raw_wer 18.386 | bleu 27.3 | wps 1333.6 | wpb 6138.4 | bsz 201.1 | num_updates 23615 | best_bleu 27.71
2023-08-21 22:19:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 23615 updates
2023-08-21 22:19:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.3003.pt
2023-08-21 22:19:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.3003.pt
2023-08-21 22:19:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.3003.pt (epoch 23 @ 23615 updates, score 27.3) (writing took 7.244659180985764 seconds)
2023-08-21 22:19:16 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-21 22:19:16 | INFO | train | epoch 023 | loss 1.909 | trans_loss 4.681 | nll_loss 1.822 | w2v_ctc_loss 0.568 | task_loss 0 | contrastive_loss 0.107 | total 7392.68 | n_correct 5238.19 | ppl 3.54 | accuracy 70.856 | wps 23229.8 | ups 1.57 | wpb 14785.4 | bsz 498.6 | num_updates 23615 | lr 9.20282e-05 | gnorm 0.38 | clip 0 | loss_scale 64 | train_wall 627 | gb_free 6.2 | wall 16455
2023-08-21 22:19:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 22:19:17 | INFO | fairseq.trainer | begin training epoch 24
2023-08-21 22:19:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 22:20:14 | INFO | train_inner | epoch 024:     85 / 1080 loss=1.902, trans_loss=4.661, nll_loss=1.797, w2v_ctc_loss=0.556, task_loss=0, contrastive_loss=0.157, total=7352.09, n_correct=5243.18, ppl=3.47, accuracy=71.316, wps=13105.5, ups=0.89, wpb=14704.2, bsz=513.4, num_updates=23700, lr=9.1863e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=57, gb_free=13.5, wall=16512
2023-08-21 22:21:12 | INFO | train_inner | epoch 024:    185 / 1080 loss=1.905, trans_loss=4.667, nll_loss=1.804, w2v_ctc_loss=0.556, task_loss=0, contrastive_loss=0.172, total=7348.11, n_correct=5226.81, ppl=3.49, accuracy=71.131, wps=25147.7, ups=1.71, wpb=14696.2, bsz=497.1, num_updates=23800, lr=9.16698e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=58, gb_free=12.4, wall=16571
2023-08-21 22:22:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-21 22:22:11 | INFO | train_inner | epoch 024:    286 / 1080 loss=1.898, trans_loss=4.67, nll_loss=1.808, w2v_ctc_loss=0.565, task_loss=0, contrastive_loss=0.058, total=7372.52, n_correct=5245.5, ppl=3.5, accuracy=71.149, wps=24998.6, ups=1.7, wpb=14745, bsz=492.6, num_updates=23900, lr=9.14779e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=58, gb_free=12.8, wall=16630
2023-08-21 22:22:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-21 22:23:10 | INFO | train_inner | epoch 024:    387 / 1080 loss=1.904, trans_loss=4.664, nll_loss=1.801, w2v_ctc_loss=0.561, task_loss=0, contrastive_loss=0.146, total=7425.13, n_correct=5289.43, ppl=3.48, accuracy=71.237, wps=25096.8, ups=1.69, wpb=14850.3, bsz=513.6, num_updates=24000, lr=9.12871e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=59, gb_free=14.8, wall=16689
2023-08-21 22:23:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 22:23:49 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.059 | trans_loss 5.18 | nll_loss 2.382 | w2v_ctc_loss 1.267 | task_loss 0 | contrastive_loss 0.258 | total 6138.43 | n_correct 4176.86 | ppl 5.21 | accuracy 68.044 | uer 16.431 | wer 18.044 | raw_wer 18.044 | bleu 27.34 | wps 1337.7 | wpb 6138.4 | bsz 201.1 | num_updates 24000 | best_bleu 27.71
2023-08-21 22:23:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 24000 updates
2023-08-21 22:23:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_24_24000.pt
2023-08-21 22:23:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_24_24000.pt
2023-08-21 22:23:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_24_24000.pt (epoch 24 @ 24000 updates, score 27.34) (writing took 7.6092188589973375 seconds)
2023-08-21 22:24:55 | INFO | train_inner | epoch 024:    487 / 1080 loss=1.901, trans_loss=4.676, nll_loss=1.816, w2v_ctc_loss=0.565, task_loss=0, contrastive_loss=0.068, total=7215.4, n_correct=5123.46, ppl=3.52, accuracy=71.007, wps=13723, ups=0.95, wpb=14430.8, bsz=458.4, num_updates=24100, lr=9.10975e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=58, gb_free=14.1, wall=16794
2023-08-21 22:25:54 | INFO | train_inner | epoch 024:    587 / 1080 loss=1.899, trans_loss=4.669, nll_loss=1.809, w2v_ctc_loss=0.555, task_loss=0, contrastive_loss=0.102, total=7616.69, n_correct=5422.33, ppl=3.5, accuracy=71.19, wps=25829.3, ups=1.7, wpb=15233.4, bsz=540, num_updates=24200, lr=9.09091e-05, gnorm=0.372, clip=0, loss_scale=32, train_wall=58, gb_free=14, wall=16853
2023-08-21 22:26:52 | INFO | train_inner | epoch 024:    687 / 1080 loss=1.899, trans_loss=4.668, nll_loss=1.806, w2v_ctc_loss=0.568, task_loss=0, contrastive_loss=0.062, total=7437.55, n_correct=5294.17, ppl=3.5, accuracy=71.182, wps=25604.1, ups=1.72, wpb=14875.1, bsz=494.4, num_updates=24300, lr=9.07218e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=58, gb_free=14.3, wall=16911
2023-08-21 22:27:51 | INFO | train_inner | epoch 024:    787 / 1080 loss=1.902, trans_loss=4.674, nll_loss=1.815, w2v_ctc_loss=0.561, task_loss=0, contrastive_loss=0.098, total=7399.82, n_correct=5256.66, ppl=3.52, accuracy=71.038, wps=25106.2, ups=1.7, wpb=14799.6, bsz=500.5, num_updates=24400, lr=9.05357e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=58, gb_free=11.6, wall=16970
2023-08-21 22:28:50 | INFO | train_inner | epoch 024:    887 / 1080 loss=1.907, trans_loss=4.682, nll_loss=1.824, w2v_ctc_loss=0.565, task_loss=0, contrastive_loss=0.104, total=7321.4, n_correct=5186.87, ppl=3.54, accuracy=70.845, wps=25153.9, ups=1.72, wpb=14642.8, bsz=476.8, num_updates=24500, lr=9.03508e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=17028
2023-08-21 22:29:49 | INFO | train_inner | epoch 024:    987 / 1080 loss=1.903, trans_loss=4.681, nll_loss=1.824, w2v_ctc_loss=0.567, task_loss=0, contrastive_loss=0.057, total=7331.36, n_correct=5197.73, ppl=3.54, accuracy=70.897, wps=24744.6, ups=1.69, wpb=14662.7, bsz=474.7, num_updates=24600, lr=9.0167e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=59, gb_free=11.8, wall=17087
2023-08-21 22:30:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 22:31:21 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.049 | trans_loss 5.175 | nll_loss 2.374 | w2v_ctc_loss 1.246 | task_loss 0 | contrastive_loss 0.261 | total 6138.43 | n_correct 4176.71 | ppl 5.18 | accuracy 68.042 | uer 16.586 | wer 18.315 | raw_wer 18.315 | bleu 27.43 | wps 1335.4 | wpb 6138.4 | bsz 201.1 | num_updates 24693 | best_bleu 27.71
2023-08-21 22:31:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 24693 updates
2023-08-21 22:31:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.4302.pt
2023-08-21 22:31:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.4302.pt
2023-08-21 22:31:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.4302.pt (epoch 24 @ 24693 updates, score 27.43) (writing took 6.7445531010162085 seconds)
2023-08-21 22:31:29 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-21 22:31:29 | INFO | train | epoch 024 | loss 1.902 | trans_loss 4.671 | nll_loss 1.811 | w2v_ctc_loss 0.562 | task_loss 0 | contrastive_loss 0.102 | total 7392.05 | n_correct 5255.56 | ppl 3.51 | accuracy 71.097 | wps 21770.1 | ups 1.47 | wpb 14784.1 | bsz 498.2 | num_updates 24693 | lr 8.9997e-05 | gnorm 0.38 | clip 0 | loss_scale 32 | train_wall 626 | gb_free 15.1 | wall 17187
2023-08-21 22:31:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 22:31:29 | INFO | fairseq.trainer | begin training epoch 25
2023-08-21 22:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 22:31:41 | INFO | train_inner | epoch 025:      7 / 1080 loss=1.908, trans_loss=4.678, nll_loss=1.821, w2v_ctc_loss=0.566, task_loss=0, contrastive_loss=0.11, total=7403.93, n_correct=5252.87, ppl=3.53, accuracy=70.947, wps=13236.9, ups=0.89, wpb=14807.9, bsz=505.4, num_updates=24700, lr=8.99843e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=58, gb_free=13.4, wall=17199
2023-08-21 22:32:39 | INFO | train_inner | epoch 025:    107 / 1080 loss=1.887, trans_loss=4.653, nll_loss=1.786, w2v_ctc_loss=0.557, task_loss=0, contrastive_loss=0.055, total=7367.39, n_correct=5267.21, ppl=3.45, accuracy=71.494, wps=25162.1, ups=1.71, wpb=14734.8, bsz=489, num_updates=24800, lr=8.98027e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=58, gb_free=14.3, wall=17258
2023-08-21 22:33:38 | INFO | train_inner | epoch 025:    207 / 1080 loss=1.892, trans_loss=4.656, nll_loss=1.79, w2v_ctc_loss=0.556, task_loss=0, contrastive_loss=0.092, total=7409.42, n_correct=5294.67, ppl=3.46, accuracy=71.459, wps=25171.7, ups=1.7, wpb=14818.8, bsz=496.2, num_updates=24900, lr=8.96221e-05, gnorm=0.377, clip=0, loss_scale=32, train_wall=58, gb_free=13.8, wall=17317
2023-08-21 22:34:37 | INFO | train_inner | epoch 025:    307 / 1080 loss=1.888, trans_loss=4.657, nll_loss=1.792, w2v_ctc_loss=0.555, task_loss=0, contrastive_loss=0.054, total=7330.91, n_correct=5236.27, ppl=3.46, accuracy=71.427, wps=25047.8, ups=1.71, wpb=14661.8, bsz=475.5, num_updates=25000, lr=8.94427e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=58, gb_free=14.9, wall=17375
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:0')
2023-08-21 22:35:35 | INFO | train_inner | epoch 025:    407 / 1080 loss=1.899, trans_loss=4.662, nll_loss=1.798, w2v_ctc_loss=0.56, task_loss=0, contrastive_loss=0.105, total=7437.79, n_correct=5303.09, ppl=3.48, accuracy=71.299, wps=25369.3, ups=1.71, wpb=14875.6, bsz=511.7, num_updates=25100, lr=8.92644e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=17434
2023-08-21 22:36:34 | INFO | train_inner | epoch 025:    507 / 1080 loss=1.892, trans_loss=4.658, nll_loss=1.794, w2v_ctc_loss=0.555, task_loss=0, contrastive_loss=0.087, total=7466.64, n_correct=5330.51, ppl=3.47, accuracy=71.391, wps=25479.8, ups=1.71, wpb=14933.3, bsz=507.7, num_updates=25200, lr=8.90871e-05, gnorm=0.377, clip=0, loss_scale=32, train_wall=58, gb_free=14.3, wall=17493
2023-08-21 22:37:32 | INFO | train_inner | epoch 025:    607 / 1080 loss=1.902, trans_loss=4.664, nll_loss=1.801, w2v_ctc_loss=0.552, task_loss=0, contrastive_loss=0.176, total=7397.23, n_correct=5275.73, ppl=3.48, accuracy=71.32, wps=25342.4, ups=1.71, wpb=14794.5, bsz=511.7, num_updates=25300, lr=8.89108e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=58, gb_free=13.7, wall=17551
2023-08-21 22:38:31 | INFO | train_inner | epoch 025:    707 / 1080 loss=1.895, trans_loss=4.666, nll_loss=1.805, w2v_ctc_loss=0.546, task_loss=0, contrastive_loss=0.115, total=7440.65, n_correct=5303.65, ppl=3.49, accuracy=71.279, wps=25317.6, ups=1.7, wpb=14881.3, bsz=507.2, num_updates=25400, lr=8.87357e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=58, gb_free=12.7, wall=17610
2023-08-21 22:39:29 | INFO | train_inner | epoch 025:    807 / 1080 loss=1.902, trans_loss=4.673, nll_loss=1.814, w2v_ctc_loss=0.563, task_loss=0, contrastive_loss=0.1, total=7359.73, n_correct=5229.3, ppl=3.52, accuracy=71.053, wps=25324.7, ups=1.72, wpb=14719.5, bsz=490.1, num_updates=25500, lr=8.85615e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=58, gb_free=13.8, wall=17668
2023-08-21 22:40:28 | INFO | train_inner | epoch 025:    907 / 1080 loss=1.899, trans_loss=4.667, nll_loss=1.806, w2v_ctc_loss=0.558, task_loss=0, contrastive_loss=0.109, total=7417.43, n_correct=5288.58, ppl=3.5, accuracy=71.299, wps=25456.2, ups=1.72, wpb=14834.9, bsz=516.8, num_updates=25600, lr=8.83883e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=58, gb_free=11.7, wall=17726
2023-08-21 22:41:26 | INFO | train_inner | epoch 025:   1007 / 1080 loss=1.903, trans_loss=4.681, nll_loss=1.823, w2v_ctc_loss=0.566, task_loss=0, contrastive_loss=0.084, total=7241.32, n_correct=5135.85, ppl=3.54, accuracy=70.924, wps=24587.2, ups=1.7, wpb=14482.6, bsz=469.9, num_updates=25700, lr=8.82162e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=58, gb_free=12.4, wall=17785
2023-08-21 22:42:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:2')
2023-08-21 22:42:48 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.046 | trans_loss 5.167 | nll_loss 2.368 | w2v_ctc_loss 1.254 | task_loss 0 | contrastive_loss 0.264 | total 6138.43 | n_correct 4179 | ppl 5.16 | accuracy 68.079 | uer 16.487 | wer 18.23 | raw_wer 18.23 | bleu 27.41 | wps 1317.8 | wpb 6138.4 | bsz 201.1 | num_updates 25773 | best_bleu 27.71
2023-08-21 22:42:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 25773 updates
2023-08-21 22:42:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.4103.pt
2023-08-21 22:42:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.4103.pt
2023-08-21 22:42:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.4103.pt (epoch 25 @ 25773 updates, score 27.41) (writing took 6.395848887972534 seconds)
2023-08-21 22:42:55 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-21 22:42:55 | INFO | train | epoch 025 | loss 1.898 | trans_loss 4.665 | nll_loss 1.803 | w2v_ctc_loss 0.557 | task_loss 0 | contrastive_loss 0.105 | total 7392.68 | n_correct 5267.6 | ppl 3.49 | accuracy 71.254 | wps 23268.4 | ups 1.57 | wpb 14785.4 | bsz 498.6 | num_updates 25773 | lr 8.80912e-05 | gnorm 0.382 | clip 0 | loss_scale 32 | train_wall 627 | gb_free 11.8 | wall 17873
2023-08-21 22:42:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 22:42:55 | INFO | fairseq.trainer | begin training epoch 26
2023-08-21 22:42:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 22:43:18 | INFO | train_inner | epoch 026:     27 / 1080 loss=1.906, trans_loss=4.67, nll_loss=1.81, w2v_ctc_loss=0.556, task_loss=0, contrastive_loss=0.15, total=7459.39, n_correct=5302.13, ppl=3.51, accuracy=71.08, wps=13333.9, ups=0.89, wpb=14918.8, bsz=515.2, num_updates=25800, lr=8.80451e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=58, gb_free=14.1, wall=17897
2023-08-21 22:44:16 | INFO | train_inner | epoch 026:    127 / 1080 loss=1.878, trans_loss=4.63, nll_loss=1.759, w2v_ctc_loss=0.541, task_loss=0, contrastive_loss=0.112, total=7452.24, n_correct=5364.4, ppl=3.38, accuracy=71.984, wps=25856.5, ups=1.73, wpb=14904.5, bsz=525.3, num_updates=25900, lr=8.7875e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=57, gb_free=14.9, wall=17955
2023-08-21 22:45:15 | INFO | train_inner | epoch 026:    227 / 1080 loss=1.886, trans_loss=4.643, nll_loss=1.775, w2v_ctc_loss=0.548, task_loss=0, contrastive_loss=0.115, total=7461.57, n_correct=5352.23, ppl=3.42, accuracy=71.731, wps=25490.1, ups=1.71, wpb=14923.1, bsz=509.3, num_updates=26000, lr=8.77058e-05, gnorm=0.379, clip=0, loss_scale=32, train_wall=58, gb_free=13.7, wall=18013
2023-08-21 22:45:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 22:45:53 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.062 | trans_loss 5.175 | nll_loss 2.375 | w2v_ctc_loss 1.286 | task_loss 0 | contrastive_loss 0.262 | total 6138.43 | n_correct 4186 | ppl 5.19 | accuracy 68.193 | uer 16.367 | wer 18.115 | raw_wer 18.115 | bleu 27.59 | wps 1333.3 | wpb 6138.4 | bsz 201.1 | num_updates 26000 | best_bleu 27.71
2023-08-21 22:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 26000 updates
2023-08-21 22:45:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_26_26000.pt
2023-08-21 22:45:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_26_26000.pt
2023-08-21 22:46:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_26_26000.pt (epoch 26 @ 26000 updates, score 27.59) (writing took 8.585459062014706 seconds)
2023-08-21 22:47:01 | INFO | train_inner | epoch 026:    327 / 1080 loss=1.886, trans_loss=4.65, nll_loss=1.783, w2v_ctc_loss=0.547, task_loss=0, contrastive_loss=0.086, total=7365.52, n_correct=5273.78, ppl=3.44, accuracy=71.601, wps=13878, ups=0.94, wpb=14731, bsz=487.7, num_updates=26100, lr=8.75376e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=58, gb_free=13.3, wall=18119
2023-08-21 22:47:59 | INFO | train_inner | epoch 026:    427 / 1080 loss=1.898, trans_loss=4.659, nll_loss=1.795, w2v_ctc_loss=0.554, task_loss=0, contrastive_loss=0.139, total=7433.05, n_correct=5304.27, ppl=3.47, accuracy=71.361, wps=25426.4, ups=1.71, wpb=14866.1, bsz=498.2, num_updates=26200, lr=8.73704e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=58, gb_free=14.8, wall=18178
2023-08-21 22:48:58 | INFO | train_inner | epoch 026:    527 / 1080 loss=1.896, trans_loss=4.665, nll_loss=1.802, w2v_ctc_loss=0.55, task_loss=0, contrastive_loss=0.135, total=7352.51, n_correct=5240.67, ppl=3.49, accuracy=71.277, wps=25063.1, ups=1.7, wpb=14705, bsz=484, num_updates=26300, lr=8.72041e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=58, gb_free=13.3, wall=18236
2023-08-21 22:49:56 | INFO | train_inner | epoch 026:    627 / 1080 loss=1.89, trans_loss=4.661, nll_loss=1.797, w2v_ctc_loss=0.559, task_loss=0, contrastive_loss=0.058, total=7344.48, n_correct=5248.93, ppl=3.48, accuracy=71.468, wps=25195.2, ups=1.72, wpb=14689, bsz=484.5, num_updates=26400, lr=8.70388e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=12.6, wall=18295
2023-08-21 22:50:54 | INFO | train_inner | epoch 026:    727 / 1080 loss=1.902, trans_loss=4.668, nll_loss=1.808, w2v_ctc_loss=0.558, task_loss=0, contrastive_loss=0.127, total=7332.34, n_correct=5218.09, ppl=3.5, accuracy=71.165, wps=25150.2, ups=1.72, wpb=14664.7, bsz=494.1, num_updates=26500, lr=8.68744e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=58, gb_free=10.2, wall=18353
2023-08-21 22:51:53 | INFO | train_inner | epoch 026:    827 / 1080 loss=1.901, trans_loss=4.668, nll_loss=1.808, w2v_ctc_loss=0.555, task_loss=0, contrastive_loss=0.141, total=7417.07, n_correct=5283.21, ppl=3.5, accuracy=71.23, wps=25367.7, ups=1.71, wpb=14834.1, bsz=498.7, num_updates=26600, lr=8.6711e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=58, gb_free=13.6, wall=18412
2023-08-21 22:52:52 | INFO | train_inner | epoch 026:    927 / 1080 loss=1.891, trans_loss=4.668, nll_loss=1.806, w2v_ctc_loss=0.552, task_loss=0, contrastive_loss=0.061, total=7383.98, n_correct=5262.64, ppl=3.5, accuracy=71.271, wps=25112.2, ups=1.7, wpb=14768, bsz=490.6, num_updates=26700, lr=8.65485e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=58, gb_free=12.7, wall=18470
2023-08-21 22:53:50 | INFO | train_inner | epoch 026:   1027 / 1080 loss=1.894, trans_loss=4.667, nll_loss=1.807, w2v_ctc_loss=0.553, task_loss=0, contrastive_loss=0.075, total=7451.23, n_correct=5310.94, ppl=3.5, accuracy=71.276, wps=25412.4, ups=1.71, wpb=14902.5, bsz=509.4, num_updates=26800, lr=8.63868e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=58, gb_free=11.9, wall=18529
2023-08-21 22:54:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 22:54:59 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.051 | trans_loss 5.169 | nll_loss 2.368 | w2v_ctc_loss 1.268 | task_loss 0 | contrastive_loss 0.259 | total 6138.43 | n_correct 4191.43 | ppl 5.16 | accuracy 68.282 | uer 16.45 | wer 18.189 | raw_wer 18.189 | bleu 27.62 | wps 1340.3 | wpb 6138.4 | bsz 201.1 | num_updates 26853 | best_bleu 27.71
2023-08-21 22:54:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 26853 updates
2023-08-21 22:54:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.6201.pt
2023-08-21 22:55:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.6201.pt
2023-08-21 22:55:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.6201.pt (epoch 26 @ 26853 updates, score 27.62) (writing took 7.910580907948315 seconds)
2023-08-21 22:55:08 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-21 22:55:08 | INFO | train | epoch 026 | loss 1.892 | trans_loss 4.658 | nll_loss 1.794 | w2v_ctc_loss 0.552 | task_loss 0 | contrastive_loss 0.104 | total 7392.68 | n_correct 5281.65 | ppl 3.47 | accuracy 71.444 | wps 21785.7 | ups 1.47 | wpb 14785.4 | bsz 498.6 | num_updates 26853 | lr 8.63015e-05 | gnorm 0.382 | clip 0 | loss_scale 64 | train_wall 624 | gb_free 13.2 | wall 18606
2023-08-21 22:55:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 22:55:08 | INFO | fairseq.trainer | begin training epoch 27
2023-08-21 22:55:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 22:55:43 | INFO | train_inner | epoch 027:     47 / 1080 loss=1.88, trans_loss=4.649, nll_loss=1.783, w2v_ctc_loss=0.544, task_loss=0, contrastive_loss=0.059, total=7308.04, n_correct=5240.03, ppl=3.44, accuracy=71.702, wps=12988.4, ups=0.89, wpb=14616.1, bsz=502.2, num_updates=26900, lr=8.62261e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=57, gb_free=13.9, wall=18641
2023-08-21 22:56:41 | INFO | train_inner | epoch 027:    147 / 1080 loss=1.878, trans_loss=4.641, nll_loss=1.772, w2v_ctc_loss=0.545, task_loss=0, contrastive_loss=0.061, total=7407.93, n_correct=5319.49, ppl=3.42, accuracy=71.808, wps=25303.6, ups=1.71, wpb=14815.9, bsz=492, num_updates=27000, lr=8.60663e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=58, gb_free=12.5, wall=18700
2023-08-21 22:57:41 | INFO | train_inner | epoch 027:    247 / 1080 loss=1.885, trans_loss=4.644, nll_loss=1.776, w2v_ctc_loss=0.54, task_loss=0, contrastive_loss=0.134, total=7457.21, n_correct=5353.68, ppl=3.43, accuracy=71.792, wps=25208.7, ups=1.69, wpb=14914.4, bsz=513.8, num_updates=27100, lr=8.59074e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=59, gb_free=13.6, wall=18759
2023-08-21 22:58:39 | INFO | train_inner | epoch 027:    347 / 1080 loss=1.886, trans_loss=4.648, nll_loss=1.782, w2v_ctc_loss=0.542, task_loss=0, contrastive_loss=0.116, total=7441.51, n_correct=5333.97, ppl=3.44, accuracy=71.679, wps=25665.5, ups=1.72, wpb=14883, bsz=508.6, num_updates=27200, lr=8.57493e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=57, gb_free=14.2, wall=18817
2023-08-21 22:59:37 | INFO | train_inner | epoch 027:    447 / 1080 loss=1.881, trans_loss=4.643, nll_loss=1.776, w2v_ctc_loss=0.54, task_loss=0, contrastive_loss=0.095, total=7565.88, n_correct=5437.16, ppl=3.42, accuracy=71.864, wps=25883, ups=1.71, wpb=15131.8, bsz=524.5, num_updates=27300, lr=8.55921e-05, gnorm=0.374, clip=0, loss_scale=64, train_wall=58, gb_free=13.4, wall=18876
2023-08-21 22:59:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-21 23:00:36 | INFO | train_inner | epoch 027:    548 / 1080 loss=1.893, trans_loss=4.654, nll_loss=1.789, w2v_ctc_loss=0.548, task_loss=0, contrastive_loss=0.142, total=7426.3, n_correct=5307.6, ppl=3.46, accuracy=71.47, wps=25260.1, ups=1.7, wpb=14852.6, bsz=497.4, num_updates=27400, lr=8.54358e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=18934
2023-08-21 23:01:34 | INFO | train_inner | epoch 027:    648 / 1080 loss=1.884, trans_loss=4.647, nll_loss=1.78, w2v_ctc_loss=0.555, task_loss=0, contrastive_loss=0.064, total=7300.31, n_correct=5233.15, ppl=3.43, accuracy=71.684, wps=24927, ups=1.71, wpb=14600.6, bsz=495.5, num_updates=27500, lr=8.52803e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=58, gb_free=11.6, wall=18993
2023-08-21 23:02:33 | INFO | train_inner | epoch 027:    748 / 1080 loss=1.889, trans_loss=4.659, nll_loss=1.796, w2v_ctc_loss=0.551, task_loss=0, contrastive_loss=0.087, total=7324.44, n_correct=5233.98, ppl=3.47, accuracy=71.459, wps=24897.9, ups=1.7, wpb=14648.9, bsz=481.1, num_updates=27600, lr=8.51257e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=19052
2023-08-21 23:03:31 | INFO | train_inner | epoch 027:    848 / 1080 loss=1.886, trans_loss=4.65, nll_loss=1.785, w2v_ctc_loss=0.552, task_loss=0, contrastive_loss=0.092, total=7335.3, n_correct=5256.12, ppl=3.45, accuracy=71.655, wps=25228.1, ups=1.72, wpb=14670.6, bsz=490.2, num_updates=27700, lr=8.49719e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=58, gb_free=14.3, wall=19110
2023-08-21 23:04:30 | INFO | train_inner | epoch 027:    948 / 1080 loss=1.889, trans_loss=4.656, nll_loss=1.792, w2v_ctc_loss=0.548, task_loss=0, contrastive_loss=0.114, total=7310.75, n_correct=5227.89, ppl=3.46, accuracy=71.51, wps=24948.6, ups=1.71, wpb=14621.5, bsz=475.8, num_updates=27800, lr=8.48189e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=58, gb_free=14.1, wall=19169
2023-08-21 23:05:29 | INFO | train_inner | epoch 027:   1048 / 1080 loss=1.899, trans_loss=4.667, nll_loss=1.806, w2v_ctc_loss=0.555, task_loss=0, contrastive_loss=0.132, total=7372.35, n_correct=5249.66, ppl=3.5, accuracy=71.207, wps=25211.7, ups=1.71, wpb=14744.7, bsz=492.3, num_updates=27900, lr=8.46668e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=58, gb_free=15.2, wall=19227
2023-08-21 23:05:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 23:06:25 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.062 | trans_loss 5.168 | nll_loss 2.371 | w2v_ctc_loss 1.305 | task_loss 0 | contrastive_loss 0.261 | total 6138.43 | n_correct 4195.57 | ppl 5.17 | accuracy 68.349 | uer 16.482 | wer 18.148 | raw_wer 18.148 | bleu 27.88 | wps 1340.4 | wpb 6138.4 | bsz 201.1 | num_updates 27932 | best_bleu 27.88
2023-08-21 23:06:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 27932 updates
2023-08-21 23:06:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 23:06:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-21 23:06:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 27 @ 27932 updates, score 27.88) (writing took 11.414987839059904 seconds)
2023-08-21 23:06:37 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-21 23:06:37 | INFO | train | epoch 027 | loss 1.886 | trans_loss 4.65 | nll_loss 1.785 | w2v_ctc_loss 0.546 | task_loss 0 | contrastive_loss 0.1 | total 7391.91 | n_correct 5294.78 | ppl 3.45 | accuracy 71.629 | wps 23146.8 | ups 1.57 | wpb 14783.8 | bsz 498.2 | num_updates 27932 | lr 8.46182e-05 | gnorm 0.382 | clip 0 | loss_scale 32 | train_wall 625 | gb_free 11.1 | wall 19295
2023-08-21 23:06:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 23:06:37 | INFO | fairseq.trainer | begin training epoch 28
2023-08-21 23:06:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 23:07:24 | INFO | train_inner | epoch 028:     68 / 1080 loss=1.879, trans_loss=4.641, nll_loss=1.772, w2v_ctc_loss=0.54, task_loss=0, contrastive_loss=0.101, total=7323.51, n_correct=5259.26, ppl=3.41, accuracy=71.813, wps=12672.4, ups=0.87, wpb=14647, bsz=493, num_updates=28000, lr=8.45154e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=57, gb_free=14.1, wall=19343
2023-08-21 23:07:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 23:08:03 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.061 | trans_loss 5.176 | nll_loss 2.377 | w2v_ctc_loss 1.285 | task_loss 0 | contrastive_loss 0.257 | total 6138.43 | n_correct 4190.14 | ppl 5.19 | accuracy 68.261 | uer 16.426 | wer 18.189 | raw_wer 18.189 | bleu 27.51 | wps 1335.4 | wpb 6138.4 | bsz 201.1 | num_updates 28000 | best_bleu 27.88
2023-08-21 23:08:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 28000 updates
2023-08-21 23:08:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_28_28000.pt
2023-08-21 23:08:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_28_28000.pt
2023-08-21 23:08:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_28_28000.pt (epoch 28 @ 28000 updates, score 27.51) (writing took 9.165600498905405 seconds)
2023-08-21 23:09:11 | INFO | train_inner | epoch 028:    168 / 1080 loss=1.878, trans_loss=4.641, nll_loss=1.772, w2v_ctc_loss=0.547, task_loss=0, contrastive_loss=0.066, total=7465.69, n_correct=5366.5, ppl=3.41, accuracy=71.882, wps=13960.7, ups=0.93, wpb=14931.4, bsz=503.7, num_updates=28100, lr=8.43649e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=58, gb_free=14.5, wall=19450
2023-08-21 23:10:09 | INFO | train_inner | epoch 028:    268 / 1080 loss=1.896, trans_loss=4.642, nll_loss=1.773, w2v_ctc_loss=0.55, task_loss=0, contrastive_loss=0.203, total=7303.43, n_correct=5236.96, ppl=3.42, accuracy=71.705, wps=25038.5, ups=1.71, wpb=14606.9, bsz=502.9, num_updates=28200, lr=8.42152e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=19508
2023-08-21 23:11:08 | INFO | train_inner | epoch 028:    368 / 1080 loss=1.87, trans_loss=4.637, nll_loss=1.767, w2v_ctc_loss=0.536, task_loss=0, contrastive_loss=0.052, total=7374.55, n_correct=5308.8, ppl=3.4, accuracy=71.988, wps=24988.5, ups=1.69, wpb=14749.1, bsz=495, num_updates=28300, lr=8.40663e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=58, gb_free=13.2, wall=19567
2023-08-21 23:12:06 | INFO | train_inner | epoch 028:    468 / 1080 loss=1.875, trans_loss=4.634, nll_loss=1.764, w2v_ctc_loss=0.538, task_loss=0, contrastive_loss=0.091, total=7410.01, n_correct=5336.52, ppl=3.4, accuracy=72.018, wps=25579.4, ups=1.73, wpb=14820, bsz=504.2, num_updates=28400, lr=8.39181e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=57, gb_free=13.6, wall=19625
2023-08-21 23:13:05 | INFO | train_inner | epoch 028:    568 / 1080 loss=1.88, trans_loss=4.649, nll_loss=1.783, w2v_ctc_loss=0.541, task_loss=0, contrastive_loss=0.075, total=7467.62, n_correct=5353.2, ppl=3.44, accuracy=71.685, wps=25513.3, ups=1.71, wpb=14935.2, bsz=494.6, num_updates=28500, lr=8.37708e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=58, gb_free=14, wall=19684
2023-08-21 23:14:04 | INFO | train_inner | epoch 028:    668 / 1080 loss=1.876, trans_loss=4.639, nll_loss=1.77, w2v_ctc_loss=0.534, task_loss=0, contrastive_loss=0.088, total=7443.91, n_correct=5350.48, ppl=3.41, accuracy=71.877, wps=25334.9, ups=1.7, wpb=14887.8, bsz=513, num_updates=28600, lr=8.36242e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=58, gb_free=12.4, wall=19742
2023-08-21 23:15:03 | INFO | train_inner | epoch 028:    768 / 1080 loss=1.891, trans_loss=4.658, nll_loss=1.795, w2v_ctc_loss=0.547, task_loss=0, contrastive_loss=0.124, total=7319.25, n_correct=5228.55, ppl=3.47, accuracy=71.436, wps=24849.6, ups=1.7, wpb=14638.5, bsz=477.6, num_updates=28700, lr=8.34784e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=12.8, wall=19801
2023-08-21 23:16:01 | INFO | train_inner | epoch 028:    868 / 1080 loss=1.886, trans_loss=4.649, nll_loss=1.784, w2v_ctc_loss=0.544, task_loss=0, contrastive_loss=0.127, total=7361.7, n_correct=5278.6, ppl=3.44, accuracy=71.704, wps=25090.4, ups=1.7, wpb=14723.4, bsz=499.5, num_updates=28800, lr=8.33333e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=58, gb_free=11.9, wall=19860
2023-08-21 23:17:00 | INFO | train_inner | epoch 028:    968 / 1080 loss=1.884, trans_loss=4.654, nll_loss=1.789, w2v_ctc_loss=0.55, task_loss=0, contrastive_loss=0.062, total=7360.66, n_correct=5266.64, ppl=3.46, accuracy=71.551, wps=25189.6, ups=1.71, wpb=14721.3, bsz=483.5, num_updates=28900, lr=8.3189e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=58, gb_free=12.4, wall=19918
2023-08-21 23:17:58 | INFO | train_inner | epoch 028:   1068 / 1080 loss=1.888, trans_loss=4.655, nll_loss=1.792, w2v_ctc_loss=0.544, task_loss=0, contrastive_loss=0.12, total=7449.78, n_correct=5330.41, ppl=3.46, accuracy=71.551, wps=25590.8, ups=1.72, wpb=14899.6, bsz=512, num_updates=29000, lr=8.30455e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=10.6, wall=19977
2023-08-21 23:18:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 23:18:43 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.053 | trans_loss 5.165 | nll_loss 2.365 | w2v_ctc_loss 1.282 | task_loss 0 | contrastive_loss 0.262 | total 6138.43 | n_correct 4188.86 | ppl 5.15 | accuracy 68.24 | uer 16.319 | wer 18.01 | raw_wer 18.01 | bleu 27.59 | wps 1340.8 | wpb 6138.4 | bsz 201.1 | num_updates 29012 | best_bleu 27.88
2023-08-21 23:18:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 29012 updates
2023-08-21 23:18:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.5900.pt
2023-08-21 23:18:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.5900.pt
2023-08-21 23:18:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.5900.pt (epoch 28 @ 29012 updates, score 27.59) (writing took 7.229099339921959 seconds)
2023-08-21 23:18:51 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-21 23:18:51 | INFO | train | epoch 028 | loss 1.882 | trans_loss 4.645 | nll_loss 1.777 | w2v_ctc_loss 0.542 | task_loss 0 | contrastive_loss 0.102 | total 7392.68 | n_correct 5305.42 | ppl 3.43 | accuracy 71.766 | wps 21755 | ups 1.47 | wpb 14785.4 | bsz 498.6 | num_updates 29012 | lr 8.30283e-05 | gnorm 0.383 | clip 0 | loss_scale 32 | train_wall 625 | gb_free 10.1 | wall 20029
2023-08-21 23:18:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 23:18:51 | INFO | fairseq.trainer | begin training epoch 29
2023-08-21 23:18:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 23:19:51 | INFO | train_inner | epoch 029:     88 / 1080 loss=1.867, trans_loss=4.619, nll_loss=1.745, w2v_ctc_loss=0.531, task_loss=0, contrastive_loss=0.091, total=7545.75, n_correct=5457.13, ppl=3.35, accuracy=72.321, wps=13335.3, ups=0.88, wpb=15091.5, bsz=531.7, num_updates=29100, lr=8.29027e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=58, gb_free=9.5, wall=20090
2023-08-21 23:20:50 | INFO | train_inner | epoch 029:    188 / 1080 loss=1.874, trans_loss=4.63, nll_loss=1.758, w2v_ctc_loss=0.535, task_loss=0, contrastive_loss=0.106, total=7361.53, n_correct=5305.86, ppl=3.38, accuracy=72.076, wps=25082.3, ups=1.7, wpb=14723.1, bsz=486.2, num_updates=29200, lr=8.27606e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=58, gb_free=13.3, wall=20148
2023-08-21 23:21:49 | INFO | train_inner | epoch 029:    288 / 1080 loss=1.87, trans_loss=4.628, nll_loss=1.756, w2v_ctc_loss=0.529, task_loss=0, contrastive_loss=0.11, total=7324.67, n_correct=5282.66, ppl=3.38, accuracy=72.121, wps=24933, ups=1.7, wpb=14649.3, bsz=492.2, num_updates=29300, lr=8.26192e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=58, gb_free=14.1, wall=20207
2023-08-21 23:22:47 | INFO | train_inner | epoch 029:    388 / 1080 loss=1.878, trans_loss=4.64, nll_loss=1.771, w2v_ctc_loss=0.547, task_loss=0, contrastive_loss=0.071, total=7284.15, n_correct=5232.6, ppl=3.41, accuracy=71.835, wps=24902.1, ups=1.71, wpb=14568.3, bsz=474.7, num_updates=29400, lr=8.24786e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=58, gb_free=12.2, wall=20266
2023-08-21 23:23:45 | INFO | train_inner | epoch 029:    488 / 1080 loss=1.873, trans_loss=4.639, nll_loss=1.771, w2v_ctc_loss=0.538, task_loss=0, contrastive_loss=0.059, total=7461.06, n_correct=5361.75, ppl=3.41, accuracy=71.863, wps=25669.6, ups=1.72, wpb=14922.1, bsz=496.8, num_updates=29500, lr=8.23387e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=58, gb_free=12, wall=20324
2023-08-21 23:24:44 | INFO | train_inner | epoch 029:    588 / 1080 loss=1.879, trans_loss=4.644, nll_loss=1.776, w2v_ctc_loss=0.541, task_loss=0, contrastive_loss=0.089, total=7434, n_correct=5339.64, ppl=3.43, accuracy=71.827, wps=25231.1, ups=1.7, wpb=14868, bsz=506.1, num_updates=29600, lr=8.21995e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=58, gb_free=14.2, wall=20383
2023-08-21 23:25:43 | INFO | train_inner | epoch 029:    688 / 1080 loss=1.873, trans_loss=4.642, nll_loss=1.774, w2v_ctc_loss=0.538, task_loss=0, contrastive_loss=0.051, total=7411.32, n_correct=5323.43, ppl=3.42, accuracy=71.828, wps=25258.5, ups=1.7, wpb=14822.6, bsz=484.2, num_updates=29700, lr=8.2061e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=58, gb_free=12.8, wall=20441
2023-08-21 23:26:41 | INFO | train_inner | epoch 029:    788 / 1080 loss=1.887, trans_loss=4.645, nll_loss=1.779, w2v_ctc_loss=0.541, task_loss=0, contrastive_loss=0.151, total=7335.62, n_correct=5261.9, ppl=3.43, accuracy=71.731, wps=25101.7, ups=1.71, wpb=14671.2, bsz=497.1, num_updates=29800, lr=8.19232e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=58, gb_free=14, wall=20500
2023-08-21 23:27:39 | INFO | train_inner | epoch 029:    888 / 1080 loss=1.886, trans_loss=4.642, nll_loss=1.776, w2v_ctc_loss=0.532, task_loss=0, contrastive_loss=0.186, total=7469.49, n_correct=5369.89, ppl=3.42, accuracy=71.891, wps=25720.2, ups=1.72, wpb=14939, bsz=525.1, num_updates=29900, lr=8.17861e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=57, gb_free=13.8, wall=20558
2023-08-21 23:28:38 | INFO | train_inner | epoch 029:    988 / 1080 loss=1.884, trans_loss=4.65, nll_loss=1.785, w2v_ctc_loss=0.545, task_loss=0, contrastive_loss=0.113, total=7261.68, n_correct=5202.52, ppl=3.45, accuracy=71.643, wps=24806.8, ups=1.71, wpb=14523.4, bsz=478.7, num_updates=30000, lr=8.16497e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=58, gb_free=14.1, wall=20617
2023-08-21 23:28:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 23:29:16 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.042 | trans_loss 5.163 | nll_loss 2.363 | w2v_ctc_loss 1.249 | task_loss 0 | contrastive_loss 0.265 | total 6138.43 | n_correct 4200.57 | ppl 5.14 | accuracy 68.431 | uer 16.38 | wer 18.208 | raw_wer 18.208 | bleu 27.68 | wps 1344.5 | wpb 6138.4 | bsz 201.1 | num_updates 30000 | best_bleu 27.88
2023-08-21 23:29:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 30000 updates
2023-08-21 23:29:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_29_30000.pt
2023-08-21 23:29:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_29_30000.pt
2023-08-21 23:29:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_29_30000.pt (epoch 29 @ 30000 updates, score 27.68) (writing took 7.655528416973539 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:0')
2023-08-21 23:30:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:3')
2023-08-21 23:30:56 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.039 | trans_loss 5.158 | nll_loss 2.355 | w2v_ctc_loss 1.252 | task_loss 0 | contrastive_loss 0.265 | total 6138.43 | n_correct 4200 | ppl 5.12 | accuracy 68.421 | uer 16.369 | wer 18.178 | raw_wer 18.178 | bleu 27.59 | wps 1329.1 | wpb 6138.4 | bsz 201.1 | num_updates 30092 | best_bleu 27.88
2023-08-21 23:30:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 30092 updates
2023-08-21 23:30:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.5902.pt
2023-08-21 23:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.5902.pt
2023-08-21 23:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.5902.pt (epoch 29 @ 30092 updates, score 27.59) (writing took 7.152167033054866 seconds)
2023-08-21 23:31:04 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-21 23:31:04 | INFO | train | epoch 029 | loss 1.877 | trans_loss 4.638 | nll_loss 1.769 | w2v_ctc_loss 0.537 | task_loss 0 | contrastive_loss 0.102 | total 7392.68 | n_correct 5316.63 | ppl 3.41 | accuracy 71.917 | wps 21791.4 | ups 1.47 | wpb 14785.4 | bsz 498.6 | num_updates 30092 | lr 8.15247e-05 | gnorm 0.384 | clip 0 | loss_scale 64 | train_wall 626 | gb_free 11.1 | wall 20762
2023-08-21 23:31:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 23:31:04 | INFO | fairseq.trainer | begin training epoch 30
2023-08-21 23:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 23:31:16 | INFO | train_inner | epoch 030:      8 / 1080 loss=1.871, trans_loss=4.637, nll_loss=1.769, w2v_ctc_loss=0.531, task_loss=0, contrastive_loss=0.085, total=7450.29, n_correct=5364.46, ppl=3.41, accuracy=72.003, wps=9401.2, ups=0.63, wpb=14900.6, bsz=525.1, num_updates=30100, lr=8.15139e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=57, gb_free=13.5, wall=20775
2023-08-21 23:32:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-21 23:32:15 | INFO | train_inner | epoch 030:    109 / 1080 loss=1.86, trans_loss=4.611, nll_loss=1.734, w2v_ctc_loss=0.518, task_loss=0, contrastive_loss=0.115, total=7535.61, n_correct=5470.49, ppl=3.33, accuracy=72.595, wps=25732.1, ups=1.71, wpb=15071.2, bsz=529.9, num_updates=30200, lr=8.13788e-05, gnorm=0.369, clip=0, loss_scale=32, train_wall=58, gb_free=13.8, wall=20834
2023-08-21 23:33:13 | INFO | train_inner | epoch 030:    209 / 1080 loss=1.866, trans_loss=4.623, nll_loss=1.749, w2v_ctc_loss=0.54, task_loss=0, contrastive_loss=0.049, total=7310.46, n_correct=5278.1, ppl=3.36, accuracy=72.199, wps=25312.8, ups=1.73, wpb=14620.9, bsz=481, num_updates=30300, lr=8.12444e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=57, gb_free=12.7, wall=20891
2023-08-21 23:34:11 | INFO | train_inner | epoch 030:    309 / 1080 loss=1.866, trans_loss=4.621, nll_loss=1.747, w2v_ctc_loss=0.525, task_loss=0, contrastive_loss=0.115, total=7416.21, n_correct=5365.63, ppl=3.36, accuracy=72.35, wps=25542.9, ups=1.72, wpb=14832.4, bsz=514.9, num_updates=30400, lr=8.11107e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=58, gb_free=12.5, wall=20949
2023-08-21 23:35:10 | INFO | train_inner | epoch 030:    409 / 1080 loss=1.863, trans_loss=4.623, nll_loss=1.75, w2v_ctc_loss=0.533, task_loss=0, contrastive_loss=0.052, total=7318.85, n_correct=5291.77, ppl=3.36, accuracy=72.303, wps=24915.9, ups=1.7, wpb=14637.7, bsz=477.9, num_updates=30500, lr=8.09776e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=21008
2023-08-21 23:36:08 | INFO | train_inner | epoch 030:    509 / 1080 loss=1.876, trans_loss=4.633, nll_loss=1.763, w2v_ctc_loss=0.533, task_loss=0, contrastive_loss=0.121, total=7437.45, n_correct=5355.1, ppl=3.39, accuracy=72.002, wps=25533.4, ups=1.72, wpb=14874.9, bsz=519.8, num_updates=30600, lr=8.08452e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=58, gb_free=14.2, wall=21066
2023-08-21 23:37:07 | INFO | train_inner | epoch 030:    609 / 1080 loss=1.873, trans_loss=4.642, nll_loss=1.773, w2v_ctc_loss=0.537, task_loss=0, contrastive_loss=0.071, total=7249.76, n_correct=5213.96, ppl=3.42, accuracy=71.919, wps=24462.2, ups=1.69, wpb=14499.5, bsz=451.7, num_updates=30700, lr=8.07134e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=59, gb_free=13.8, wall=21126
2023-08-21 23:38:06 | INFO | train_inner | epoch 030:    709 / 1080 loss=1.881, trans_loss=4.643, nll_loss=1.776, w2v_ctc_loss=0.536, task_loss=0, contrastive_loss=0.125, total=7447.3, n_correct=5353.42, ppl=3.43, accuracy=71.884, wps=25529.7, ups=1.71, wpb=14894.6, bsz=506.2, num_updates=30800, lr=8.05823e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=21184
2023-08-21 23:39:04 | INFO | train_inner | epoch 030:    809 / 1080 loss=1.88, trans_loss=4.64, nll_loss=1.772, w2v_ctc_loss=0.54, task_loss=0, contrastive_loss=0.121, total=7330.27, n_correct=5271.65, ppl=3.42, accuracy=71.916, wps=25211.8, ups=1.72, wpb=14660.5, bsz=500.3, num_updates=30900, lr=8.04518e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=58, gb_free=13, wall=21242
2023-08-21 23:40:03 | INFO | train_inner | epoch 030:    909 / 1080 loss=1.875, trans_loss=4.644, nll_loss=1.777, w2v_ctc_loss=0.538, task_loss=0, contrastive_loss=0.061, total=7490.79, n_correct=5381.04, ppl=3.43, accuracy=71.835, wps=25437.3, ups=1.7, wpb=14981.6, bsz=495.8, num_updates=31000, lr=8.03219e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=58, gb_free=12.9, wall=21301
2023-08-21 23:41:02 | INFO | train_inner | epoch 030:   1009 / 1080 loss=1.883, trans_loss=4.639, nll_loss=1.771, w2v_ctc_loss=0.539, task_loss=0, contrastive_loss=0.149, total=7413.81, n_correct=5329.73, ppl=3.41, accuracy=71.889, wps=25100.2, ups=1.69, wpb=14827.6, bsz=502.4, num_updates=31100, lr=8.01927e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=59, gb_free=13.2, wall=21360
2023-08-21 23:41:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 23:42:22 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.05 | trans_loss 5.159 | nll_loss 2.358 | w2v_ctc_loss 1.286 | task_loss 0 | contrastive_loss 0.261 | total 6138.43 | n_correct 4191 | ppl 5.13 | accuracy 68.275 | uer 16.375 | wer 18.189 | raw_wer 18.189 | bleu 27.65 | wps 1335.2 | wpb 6138.4 | bsz 201.1 | num_updates 31171 | best_bleu 27.88
2023-08-21 23:42:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 31171 updates
2023-08-21 23:42:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.6507.pt
2023-08-21 23:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.6507.pt
2023-08-21 23:42:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.6507.pt (epoch 30 @ 31171 updates, score 27.65) (writing took 7.336697367951274 seconds)
2023-08-21 23:42:29 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-21 23:42:29 | INFO | train | epoch 030 | loss 1.872 | trans_loss 4.632 | nll_loss 1.762 | w2v_ctc_loss 0.534 | task_loss 0 | contrastive_loss 0.098 | total 7392.31 | n_correct 5328.54 | ppl 3.39 | accuracy 72.082 | wps 23261.7 | ups 1.57 | wpb 14784.6 | bsz 498.3 | num_updates 31171 | lr 8.01013e-05 | gnorm 0.382 | clip 0 | loss_scale 32 | train_wall 626 | gb_free 13.2 | wall 21448
2023-08-21 23:42:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 23:42:30 | INFO | fairseq.trainer | begin training epoch 31
2023-08-21 23:42:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 23:42:55 | INFO | train_inner | epoch 031:     29 / 1080 loss=1.868, trans_loss=4.628, nll_loss=1.756, w2v_ctc_loss=0.524, task_loss=0, contrastive_loss=0.111, total=7352.49, n_correct=5307.61, ppl=3.38, accuracy=72.188, wps=13019.1, ups=0.89, wpb=14705, bsz=500.6, num_updates=31200, lr=8.00641e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=21473
2023-08-21 23:43:53 | INFO | train_inner | epoch 031:    129 / 1080 loss=1.863, trans_loss=4.619, nll_loss=1.744, w2v_ctc_loss=0.527, task_loss=0, contrastive_loss=0.088, total=7371.82, n_correct=5334.22, ppl=3.35, accuracy=72.36, wps=25326.2, ups=1.72, wpb=14743.6, bsz=488.3, num_updates=31300, lr=7.99361e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=58, gb_free=11.4, wall=21531
2023-08-21 23:44:51 | INFO | train_inner | epoch 031:    229 / 1080 loss=1.86, trans_loss=4.622, nll_loss=1.749, w2v_ctc_loss=0.524, task_loss=0, contrastive_loss=0.058, total=7387.52, n_correct=5345, ppl=3.36, accuracy=72.352, wps=25452.3, ups=1.72, wpb=14775, bsz=492.5, num_updates=31400, lr=7.98087e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=57, gb_free=13, wall=21589
2023-08-21 23:45:50 | INFO | train_inner | epoch 031:    329 / 1080 loss=1.863, trans_loss=4.626, nll_loss=1.753, w2v_ctc_loss=0.53, task_loss=0, contrastive_loss=0.059, total=7375.82, n_correct=5326.81, ppl=3.37, accuracy=72.22, wps=25082, ups=1.7, wpb=14751.6, bsz=478.6, num_updates=31500, lr=7.96819e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=58, gb_free=12.3, wall=21648
2023-08-21 23:46:48 | INFO | train_inner | epoch 031:    429 / 1080 loss=1.875, trans_loss=4.632, nll_loss=1.762, w2v_ctc_loss=0.53, task_loss=0, contrastive_loss=0.137, total=7414.73, n_correct=5346.87, ppl=3.39, accuracy=72.111, wps=25366.2, ups=1.71, wpb=14829.5, bsz=503.2, num_updates=31600, lr=7.95557e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=58, gb_free=13.1, wall=21707
2023-08-21 23:47:48 | INFO | train_inner | epoch 031:    529 / 1080 loss=1.868, trans_loss=4.628, nll_loss=1.757, w2v_ctc_loss=0.526, task_loss=0, contrastive_loss=0.103, total=7399.07, n_correct=5346.71, ppl=3.38, accuracy=72.262, wps=24876.4, ups=1.68, wpb=14798.1, bsz=502.9, num_updates=31700, lr=7.94301e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=59, gb_free=10.9, wall=21766
2023-08-21 23:48:46 | INFO | train_inner | epoch 031:    629 / 1080 loss=1.869, trans_loss=4.624, nll_loss=1.753, w2v_ctc_loss=0.522, task_loss=0, contrastive_loss=0.128, total=7545.24, n_correct=5457.29, ppl=3.37, accuracy=72.328, wps=25839.7, ups=1.71, wpb=15090.5, bsz=542.6, num_updates=31800, lr=7.93052e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=21825
2023-08-21 23:49:45 | INFO | train_inner | epoch 031:    729 / 1080 loss=1.865, trans_loss=4.63, nll_loss=1.76, w2v_ctc_loss=0.522, task_loss=0, contrastive_loss=0.099, total=7378.01, n_correct=5328.35, ppl=3.39, accuracy=72.219, wps=25240.6, ups=1.71, wpb=14756, bsz=493.1, num_updates=31900, lr=7.91808e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=14.1, wall=21883
2023-08-21 23:50:43 | INFO | train_inner | epoch 031:    829 / 1080 loss=1.866, trans_loss=4.627, nll_loss=1.755, w2v_ctc_loss=0.527, task_loss=0, contrastive_loss=0.096, total=7359.29, n_correct=5317.99, ppl=3.38, accuracy=72.262, wps=25380.9, ups=1.72, wpb=14718.6, bsz=495, num_updates=32000, lr=7.90569e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=57, gb_free=11.8, wall=21941
2023-08-21 23:50:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 23:51:21 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.044 | trans_loss 5.162 | nll_loss 2.361 | w2v_ctc_loss 1.257 | task_loss 0 | contrastive_loss 0.264 | total 6138.43 | n_correct 4189.57 | ppl 5.14 | accuracy 68.252 | uer 16.294 | wer 18.07 | raw_wer 18.07 | bleu 27.53 | wps 1337.2 | wpb 6138.4 | bsz 201.1 | num_updates 32000 | best_bleu 27.88
2023-08-21 23:51:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 32000 updates
2023-08-21 23:51:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_31_32000.pt
2023-08-21 23:51:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_31_32000.pt
2023-08-21 23:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_31_32000.pt (epoch 31 @ 32000 updates, score 27.53) (writing took 9.715923364041373 seconds)
2023-08-21 23:52:30 | INFO | train_inner | epoch 031:    929 / 1080 loss=1.867, trans_loss=4.629, nll_loss=1.758, w2v_ctc_loss=0.529, task_loss=0, contrastive_loss=0.086, total=7501.3, n_correct=5415.62, ppl=3.38, accuracy=72.196, wps=13970.1, ups=0.93, wpb=15002.6, bsz=513.4, num_updates=32100, lr=7.89337e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=58, gb_free=13.8, wall=22048
2023-08-21 23:53:29 | INFO | train_inner | epoch 031:   1029 / 1080 loss=1.873, trans_loss=4.628, nll_loss=1.757, w2v_ctc_loss=0.532, task_loss=0, contrastive_loss=0.139, total=7318.8, n_correct=5281.35, ppl=3.38, accuracy=72.161, wps=24963.9, ups=1.71, wpb=14637.6, bsz=489.6, num_updates=32200, lr=7.8811e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=12.7, wall=22107
2023-08-21 23:53:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-21 23:54:37 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.034 | trans_loss 5.161 | nll_loss 2.36 | w2v_ctc_loss 1.229 | task_loss 0 | contrastive_loss 0.262 | total 6138.43 | n_correct 4192.14 | ppl 5.13 | accuracy 68.293 | uer 16.131 | wer 17.824 | raw_wer 17.824 | bleu 27.76 | wps 1334 | wpb 6138.4 | bsz 201.1 | num_updates 32251 | best_bleu 27.88
2023-08-21 23:54:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 32251 updates
2023-08-21 23:54:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7605.pt
2023-08-21 23:54:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7605.pt
2023-08-21 23:54:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7605.pt (epoch 31 @ 32251 updates, score 27.76) (writing took 7.029506057035178 seconds)
2023-08-21 23:54:44 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-21 23:54:44 | INFO | train | epoch 031 | loss 1.867 | trans_loss 4.626 | nll_loss 1.754 | w2v_ctc_loss 0.527 | task_loss 0 | contrastive_loss 0.1 | total 7392.68 | n_correct 5341.04 | ppl 3.37 | accuracy 72.248 | wps 21739.1 | ups 1.47 | wpb 14785.4 | bsz 498.6 | num_updates 32251 | lr 7.87487e-05 | gnorm 0.383 | clip 0 | loss_scale 64 | train_wall 625 | gb_free 13 | wall 22183
2023-08-21 23:54:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-21 23:54:44 | INFO | fairseq.trainer | begin training epoch 32
2023-08-21 23:54:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-21 23:55:20 | INFO | train_inner | epoch 032:     49 / 1080 loss=1.866, trans_loss=4.621, nll_loss=1.747, w2v_ctc_loss=0.535, task_loss=0, contrastive_loss=0.084, total=7176.62, n_correct=5189.48, ppl=3.36, accuracy=72.311, wps=12852.3, ups=0.9, wpb=14353.2, bsz=470.4, num_updates=32300, lr=7.86889e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=57, gb_free=12.2, wall=22219
2023-08-21 23:56:18 | INFO | train_inner | epoch 032:    149 / 1080 loss=1.86, trans_loss=4.61, nll_loss=1.734, w2v_ctc_loss=0.519, task_loss=0, contrastive_loss=0.123, total=7593.71, n_correct=5515.93, ppl=3.33, accuracy=72.638, wps=26132.4, ups=1.72, wpb=15187.4, bsz=542.1, num_updates=32400, lr=7.85674e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=57, gb_free=14.2, wall=22277
2023-08-21 23:57:17 | INFO | train_inner | epoch 032:    249 / 1080 loss=1.855, trans_loss=4.613, nll_loss=1.736, w2v_ctc_loss=0.517, task_loss=0, contrastive_loss=0.072, total=7351.14, n_correct=5333.83, ppl=3.33, accuracy=72.558, wps=25097.2, ups=1.71, wpb=14702.3, bsz=479.5, num_updates=32500, lr=7.84465e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=13.6, wall=22336
2023-08-21 23:58:16 | INFO | train_inner | epoch 032:    349 / 1080 loss=1.857, trans_loss=4.619, nll_loss=1.745, w2v_ctc_loss=0.523, task_loss=0, contrastive_loss=0.053, total=7408.64, n_correct=5367.44, ppl=3.35, accuracy=72.448, wps=25172.8, ups=1.7, wpb=14817.3, bsz=489.6, num_updates=32600, lr=7.8326e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=58, gb_free=13.9, wall=22394
2023-08-21 23:59:14 | INFO | train_inner | epoch 032:    449 / 1080 loss=1.864, trans_loss=4.619, nll_loss=1.745, w2v_ctc_loss=0.535, task_loss=0, contrastive_loss=0.063, total=7316.36, n_correct=5292.22, ppl=3.35, accuracy=72.334, wps=24976.9, ups=1.71, wpb=14632.7, bsz=485.9, num_updates=32700, lr=7.82062e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=58, gb_free=12.6, wall=22453
2023-08-22 00:00:13 | INFO | train_inner | epoch 032:    549 / 1080 loss=1.861, trans_loss=4.623, nll_loss=1.75, w2v_ctc_loss=0.525, task_loss=0, contrastive_loss=0.079, total=7386.96, n_correct=5349.93, ppl=3.36, accuracy=72.424, wps=25159.8, ups=1.7, wpb=14773.9, bsz=490.6, num_updates=32800, lr=7.80869e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=58, gb_free=13.7, wall=22512
2023-08-22 00:01:12 | INFO | train_inner | epoch 032:    649 / 1080 loss=1.865, trans_loss=4.625, nll_loss=1.754, w2v_ctc_loss=0.524, task_loss=0, contrastive_loss=0.091, total=7471.53, n_correct=5400.24, ppl=3.37, accuracy=72.278, wps=25496.6, ups=1.71, wpb=14943.1, bsz=513.3, num_updates=32900, lr=7.79681e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=58, gb_free=12.4, wall=22570
2023-08-22 00:01:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-22 00:02:11 | INFO | train_inner | epoch 032:    750 / 1080 loss=1.869, trans_loss=4.627, nll_loss=1.756, w2v_ctc_loss=0.524, task_loss=0, contrastive_loss=0.124, total=7386.35, n_correct=5333.52, ppl=3.38, accuracy=72.208, wps=25112.6, ups=1.7, wpb=14772.7, bsz=496.3, num_updates=33000, lr=7.78499e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=58, gb_free=9.7, wall=22629
2023-08-22 00:03:08 | INFO | train_inner | epoch 032:    850 / 1080 loss=1.858, trans_loss=4.618, nll_loss=1.744, w2v_ctc_loss=0.52, task_loss=0, contrastive_loss=0.081, total=7390.75, n_correct=5353.1, ppl=3.35, accuracy=72.43, wps=25765.2, ups=1.74, wpb=14781.5, bsz=505.1, num_updates=33100, lr=7.77322e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=57, gb_free=12.5, wall=22687
2023-08-22 00:04:07 | INFO | train_inner | epoch 032:    950 / 1080 loss=1.865, trans_loss=4.633, nll_loss=1.763, w2v_ctc_loss=0.533, task_loss=0, contrastive_loss=0.046, total=7341.23, n_correct=5293, ppl=3.39, accuracy=72.1, wps=24902.1, ups=1.7, wpb=14682.5, bsz=468.8, num_updates=33200, lr=7.76151e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=12.3, wall=22745
2023-08-22 00:05:06 | INFO | train_inner | epoch 032:   1050 / 1080 loss=1.874, trans_loss=4.627, nll_loss=1.756, w2v_ctc_loss=0.522, task_loss=0, contrastive_loss=0.193, total=7402.92, n_correct=5342.95, ppl=3.38, accuracy=72.174, wps=25260.2, ups=1.71, wpb=14805.8, bsz=512.5, num_updates=33300, lr=7.74984e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=58, gb_free=13.8, wall=22804
2023-08-22 00:05:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 00:06:01 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.044 | trans_loss 5.16 | nll_loss 2.357 | w2v_ctc_loss 1.268 | task_loss 0 | contrastive_loss 0.254 | total 6138.43 | n_correct 4197.43 | ppl 5.12 | accuracy 68.38 | uer 16.335 | wer 18.062 | raw_wer 18.062 | bleu 27.73 | wps 1332.8 | wpb 6138.4 | bsz 201.1 | num_updates 33330 | best_bleu 27.88
2023-08-22 00:06:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 33330 updates
2023-08-22 00:06:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7302.pt
2023-08-22 00:06:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7302.pt
2023-08-22 00:06:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7302.pt (epoch 32 @ 33330 updates, score 27.73) (writing took 7.0819232780486345 seconds)
2023-08-22 00:06:08 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-22 00:06:08 | INFO | train | epoch 032 | loss 1.863 | trans_loss 4.621 | nll_loss 1.748 | w2v_ctc_loss 0.524 | task_loss 0 | contrastive_loss 0.096 | total 7391.47 | n_correct 5349.28 | ppl 3.36 | accuracy 72.371 | wps 23308.1 | ups 1.58 | wpb 14782.9 | bsz 498.1 | num_updates 33330 | lr 7.74635e-05 | gnorm 0.384 | clip 0 | loss_scale 32 | train_wall 624 | gb_free 13.9 | wall 22867
2023-08-22 00:06:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 00:06:09 | INFO | fairseq.trainer | begin training epoch 33
2023-08-22 00:06:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 00:06:57 | INFO | train_inner | epoch 033:     70 / 1080 loss=1.859, trans_loss=4.61, nll_loss=1.734, w2v_ctc_loss=0.515, task_loss=0, contrastive_loss=0.119, total=7388.54, n_correct=5369.34, ppl=3.33, accuracy=72.671, wps=13222.9, ups=0.89, wpb=14777.1, bsz=529.3, num_updates=33400, lr=7.73823e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=57, gb_free=12.8, wall=22916
2023-08-22 00:07:56 | INFO | train_inner | epoch 033:    170 / 1080 loss=1.85, trans_loss=4.6, nll_loss=1.72, w2v_ctc_loss=0.515, task_loss=0, contrastive_loss=0.081, total=7392.04, n_correct=5379.59, ppl=3.29, accuracy=72.775, wps=25309, ups=1.71, wpb=14784.1, bsz=490.7, num_updates=33500, lr=7.72667e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=58, gb_free=12.8, wall=22974
2023-08-22 00:08:54 | INFO | train_inner | epoch 033:    270 / 1080 loss=1.861, trans_loss=4.615, nll_loss=1.739, w2v_ctc_loss=0.516, task_loss=0, contrastive_loss=0.137, total=7382.18, n_correct=5354.95, ppl=3.34, accuracy=72.539, wps=25411.5, ups=1.72, wpb=14764.4, bsz=487.7, num_updates=33600, lr=7.71517e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=58, gb_free=12.2, wall=23032
2023-08-22 00:09:53 | INFO | train_inner | epoch 033:    370 / 1080 loss=1.855, trans_loss=4.611, nll_loss=1.734, w2v_ctc_loss=0.516, task_loss=0, contrastive_loss=0.085, total=7410.42, n_correct=5377.85, ppl=3.33, accuracy=72.571, wps=25191.2, ups=1.7, wpb=14820.8, bsz=492, num_updates=33700, lr=7.70371e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=58, gb_free=12.2, wall=23091
2023-08-22 00:10:51 | INFO | train_inner | epoch 033:    470 / 1080 loss=1.861, trans_loss=4.618, nll_loss=1.743, w2v_ctc_loss=0.524, task_loss=0, contrastive_loss=0.09, total=7322.93, n_correct=5305.39, ppl=3.35, accuracy=72.449, wps=25011, ups=1.71, wpb=14645.9, bsz=485.1, num_updates=33800, lr=7.69231e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=58, gb_free=5.7, wall=23150
2023-08-22 00:11:50 | INFO | train_inner | epoch 033:    570 / 1080 loss=1.856, trans_loss=4.614, nll_loss=1.738, w2v_ctc_loss=0.516, task_loss=0, contrastive_loss=0.105, total=7304.9, n_correct=5297.64, ppl=3.34, accuracy=72.522, wps=24999.2, ups=1.71, wpb=14609.8, bsz=481, num_updates=33900, lr=7.68095e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=23208
2023-08-22 00:12:48 | INFO | train_inner | epoch 033:    670 / 1080 loss=1.857, trans_loss=4.613, nll_loss=1.739, w2v_ctc_loss=0.513, task_loss=0, contrastive_loss=0.125, total=7496.28, n_correct=5448.01, ppl=3.34, accuracy=72.676, wps=25734.9, ups=1.72, wpb=14992.6, bsz=516.6, num_updates=34000, lr=7.66965e-05, gnorm=0.384, clip=0, loss_scale=32, train_wall=58, gb_free=10.1, wall=23266
2023-08-22 00:12:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 00:13:26 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.067 | trans_loss 5.162 | nll_loss 2.363 | w2v_ctc_loss 1.334 | task_loss 0 | contrastive_loss 0.262 | total 6138.43 | n_correct 4196.29 | ppl 5.14 | accuracy 68.361 | uer 16.452 | wer 18.334 | raw_wer 18.334 | bleu 27.74 | wps 1336 | wpb 6138.4 | bsz 201.1 | num_updates 34000 | best_bleu 27.88
2023-08-22 00:13:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 34000 updates
2023-08-22 00:13:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_33_34000.pt
2023-08-22 00:13:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_33_34000.pt
2023-08-22 00:13:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_33_34000.pt (epoch 33 @ 34000 updates, score 27.74) (writing took 7.428555165999569 seconds)
2023-08-22 00:14:33 | INFO | train_inner | epoch 033:    770 / 1080 loss=1.869, trans_loss=4.628, nll_loss=1.758, w2v_ctc_loss=0.533, task_loss=0, contrastive_loss=0.089, total=7456.79, n_correct=5386.05, ppl=3.38, accuracy=72.23, wps=14168.8, ups=0.95, wpb=14913.6, bsz=514.4, num_updates=34100, lr=7.6584e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=58, gb_free=12.6, wall=23372
2023-08-22 00:15:31 | INFO | train_inner | epoch 033:    870 / 1080 loss=1.856, trans_loss=4.617, nll_loss=1.743, w2v_ctc_loss=0.518, task_loss=0, contrastive_loss=0.078, total=7402.44, n_correct=5367.44, ppl=3.35, accuracy=72.509, wps=25400.6, ups=1.72, wpb=14804.9, bsz=495.4, num_updates=34200, lr=7.64719e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=13.2, wall=23430
2023-08-22 00:16:30 | INFO | train_inner | epoch 033:    970 / 1080 loss=1.861, trans_loss=4.619, nll_loss=1.746, w2v_ctc_loss=0.52, task_loss=0, contrastive_loss=0.092, total=7458.99, n_correct=5405.82, ppl=3.35, accuracy=72.474, wps=25344.7, ups=1.7, wpb=14918, bsz=525.8, num_updates=34300, lr=7.63604e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=58, gb_free=10.2, wall=23489
2023-08-22 00:17:29 | INFO | train_inner | epoch 033:   1070 / 1080 loss=1.871, trans_loss=4.634, nll_loss=1.764, w2v_ctc_loss=0.532, task_loss=0, contrastive_loss=0.108, total=7303.64, n_correct=5264.04, ppl=3.4, accuracy=72.074, wps=25066.5, ups=1.72, wpb=14607.3, bsz=481.8, num_updates=34400, lr=7.62493e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=58, gb_free=13.8, wall=23547
2023-08-22 00:17:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 00:18:13 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.048 | trans_loss 5.158 | nll_loss 2.356 | w2v_ctc_loss 1.28 | task_loss 0 | contrastive_loss 0.263 | total 6138.43 | n_correct 4192.43 | ppl 5.12 | accuracy 68.298 | uer 16.196 | wer 17.813 | raw_wer 17.813 | bleu 27.47 | wps 1333.5 | wpb 6138.4 | bsz 201.1 | num_updates 34410 | best_bleu 27.88
2023-08-22 00:18:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 34410 updates
2023-08-22 00:18:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-22 00:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-22 00:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt (epoch 33 @ 34410 updates, score 27.47) (writing took 6.031633323989809 seconds)
2023-08-22 00:18:19 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-22 00:18:19 | INFO | train | epoch 033 | loss 1.859 | trans_loss 4.616 | nll_loss 1.741 | w2v_ctc_loss 0.52 | task_loss 0 | contrastive_loss 0.099 | total 7392.68 | n_correct 5360 | ppl 3.34 | accuracy 72.504 | wps 21856.1 | ups 1.48 | wpb 14785.4 | bsz 498.6 | num_updates 34410 | lr 7.62382e-05 | gnorm 0.385 | clip 0 | loss_scale 32 | train_wall 625 | gb_free 11.6 | wall 23598
2023-08-22 00:18:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 00:18:19 | INFO | fairseq.trainer | begin training epoch 34
2023-08-22 00:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 00:19:20 | INFO | train_inner | epoch 034:     90 / 1080 loss=1.855, trans_loss=4.604, nll_loss=1.724, w2v_ctc_loss=0.508, task_loss=0, contrastive_loss=0.16, total=7343.63, n_correct=5344.79, ppl=3.3, accuracy=72.781, wps=13210.2, ups=0.9, wpb=14687.3, bsz=494.1, num_updates=34500, lr=7.61387e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=58, gb_free=12.1, wall=23658
2023-08-22 00:20:19 | INFO | train_inner | epoch 034:    190 / 1080 loss=1.848, trans_loss=4.598, nll_loss=1.719, w2v_ctc_loss=0.504, task_loss=0, contrastive_loss=0.11, total=7458.77, n_correct=5440.13, ppl=3.29, accuracy=72.936, wps=25403.8, ups=1.7, wpb=14917.5, bsz=518.2, num_updates=34600, lr=7.60286e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=13.7, wall=23717
2023-08-22 00:21:18 | INFO | train_inner | epoch 034:    290 / 1080 loss=1.85, trans_loss=4.606, nll_loss=1.728, w2v_ctc_loss=0.521, task_loss=0, contrastive_loss=0.052, total=7484.26, n_correct=5451.41, ppl=3.31, accuracy=72.838, wps=25094.1, ups=1.68, wpb=14968.5, bsz=497.6, num_updates=34700, lr=7.5919e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=59, gb_free=14, wall=23777
2023-08-22 00:22:16 | INFO | train_inner | epoch 034:    390 / 1080 loss=1.857, trans_loss=4.611, nll_loss=1.735, w2v_ctc_loss=0.518, task_loss=0, contrastive_loss=0.105, total=7417.77, n_correct=5384.87, ppl=3.33, accuracy=72.594, wps=25438, ups=1.71, wpb=14835.5, bsz=502.9, num_updates=34800, lr=7.58098e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=23835
2023-08-22 00:23:15 | INFO | train_inner | epoch 034:    490 / 1080 loss=1.859, trans_loss=4.609, nll_loss=1.733, w2v_ctc_loss=0.515, task_loss=0, contrastive_loss=0.132, total=7476.9, n_correct=5434.96, ppl=3.32, accuracy=72.69, wps=25729.7, ups=1.72, wpb=14953.8, bsz=523.8, num_updates=34900, lr=7.57011e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=58, gb_free=12.1, wall=23893
2023-08-22 00:24:13 | INFO | train_inner | epoch 034:    590 / 1080 loss=1.852, trans_loss=4.612, nll_loss=1.736, w2v_ctc_loss=0.517, task_loss=0, contrastive_loss=0.054, total=7369.83, n_correct=5350.08, ppl=3.33, accuracy=72.594, wps=25265.4, ups=1.71, wpb=14739.7, bsz=478.9, num_updates=35000, lr=7.55929e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=13.7, wall=23952
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:0')
2023-08-22 00:25:11 | INFO | train_inner | epoch 034:    690 / 1080 loss=1.855, trans_loss=4.618, nll_loss=1.744, w2v_ctc_loss=0.52, task_loss=0, contrastive_loss=0.055, total=7399.97, n_correct=5363.58, ppl=3.35, accuracy=72.481, wps=25631.6, ups=1.73, wpb=14799.9, bsz=500, num_updates=35100, lr=7.54851e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=57, gb_free=13, wall=24009
2023-08-22 00:26:10 | INFO | train_inner | epoch 034:    790 / 1080 loss=1.853, trans_loss=4.613, nll_loss=1.737, w2v_ctc_loss=0.516, task_loss=0, contrastive_loss=0.066, total=7295.81, n_correct=5292.65, ppl=3.33, accuracy=72.544, wps=24719, ups=1.69, wpb=14591.6, bsz=468.5, num_updates=35200, lr=7.53778e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=58, gb_free=12.3, wall=24068
2023-08-22 00:27:08 | INFO | train_inner | epoch 034:    890 / 1080 loss=1.853, trans_loss=4.613, nll_loss=1.739, w2v_ctc_loss=0.513, task_loss=0, contrastive_loss=0.091, total=7365.18, n_correct=5348.93, ppl=3.34, accuracy=72.625, wps=25204.7, ups=1.71, wpb=14730.4, bsz=501.3, num_updates=35300, lr=7.5271e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=58, gb_free=10.4, wall=24127
2023-08-22 00:28:07 | INFO | train_inner | epoch 034:    990 / 1080 loss=1.86, trans_loss=4.619, nll_loss=1.746, w2v_ctc_loss=0.525, task_loss=0, contrastive_loss=0.08, total=7347.91, n_correct=5323.32, ppl=3.36, accuracy=72.447, wps=25115.2, ups=1.71, wpb=14695.8, bsz=493.4, num_updates=35400, lr=7.51646e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=58, gb_free=14.1, wall=24185
2023-08-22 00:28:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:1')
2023-08-22 00:29:37 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.042 | trans_loss 5.161 | nll_loss 2.359 | w2v_ctc_loss 1.253 | task_loss 0 | contrastive_loss 0.265 | total 6138.43 | n_correct 4198 | ppl 5.13 | accuracy 68.389 | uer 16.129 | wer 18.014 | raw_wer 18.014 | bleu 27.72 | wps 1339.8 | wpb 6138.4 | bsz 201.1 | num_updates 35490 | best_bleu 27.88
2023-08-22 00:29:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 35490 updates
2023-08-22 00:29:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7201.pt
2023-08-22 00:29:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7201.pt
2023-08-22 00:29:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7201.pt (epoch 34 @ 35490 updates, score 27.72) (writing took 6.643079879926518 seconds)
2023-08-22 00:29:44 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-22 00:29:44 | INFO | train | epoch 034 | loss 1.855 | trans_loss 4.611 | nll_loss 1.735 | w2v_ctc_loss 0.516 | task_loss 0 | contrastive_loss 0.098 | total 7392.68 | n_correct 5369.65 | ppl 3.33 | accuracy 72.635 | wps 23297.5 | ups 1.58 | wpb 14785.4 | bsz 498.6 | num_updates 35490 | lr 7.50692e-05 | gnorm 0.385 | clip 0 | loss_scale 64 | train_wall 625 | gb_free 13.7 | wall 24283
2023-08-22 00:29:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 00:29:45 | INFO | fairseq.trainer | begin training epoch 35
2023-08-22 00:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 00:29:58 | INFO | train_inner | epoch 035:     10 / 1080 loss=1.868, trans_loss=4.618, nll_loss=1.746, w2v_ctc_loss=0.516, task_loss=0, contrastive_loss=0.179, total=7373.78, n_correct=5344.77, ppl=3.35, accuracy=72.483, wps=13224.6, ups=0.9, wpb=14747.6, bsz=515, num_updates=35500, lr=7.50587e-05, gnorm=0.393, clip=0, loss_scale=64, train_wall=57, gb_free=14.6, wall=24297
2023-08-22 00:30:56 | INFO | train_inner | epoch 035:    110 / 1080 loss=1.847, trans_loss=4.596, nll_loss=1.715, w2v_ctc_loss=0.506, task_loss=0, contrastive_loss=0.129, total=7366.45, n_correct=5382.1, ppl=3.28, accuracy=73.062, wps=25367.8, ups=1.72, wpb=14732.9, bsz=493.6, num_updates=35600, lr=7.49532e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=58, gb_free=13.8, wall=24355
2023-08-22 00:31:55 | INFO | train_inner | epoch 035:    210 / 1080 loss=1.853, trans_loss=4.599, nll_loss=1.719, w2v_ctc_loss=0.516, task_loss=0, contrastive_loss=0.133, total=7410.42, n_correct=5401.85, ppl=3.29, accuracy=72.895, wps=25136.4, ups=1.7, wpb=14820.8, bsz=495.5, num_updates=35700, lr=7.48481e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=58, gb_free=13.5, wall=24414
2023-08-22 00:32:53 | INFO | train_inner | epoch 035:    310 / 1080 loss=1.842, trans_loss=4.598, nll_loss=1.717, w2v_ctc_loss=0.512, task_loss=0, contrastive_loss=0.043, total=7306.03, n_correct=5334.09, ppl=3.29, accuracy=73.009, wps=25205, ups=1.72, wpb=14612.1, bsz=471.4, num_updates=35800, lr=7.47435e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=57, gb_free=14.3, wall=24472
2023-08-22 00:33:51 | INFO | train_inner | epoch 035:    410 / 1080 loss=1.847, trans_loss=4.602, nll_loss=1.724, w2v_ctc_loss=0.515, task_loss=0, contrastive_loss=0.056, total=7392.86, n_correct=5383.44, ppl=3.3, accuracy=72.819, wps=25392.1, ups=1.72, wpb=14785.7, bsz=487.3, num_updates=35900, lr=7.46393e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=58, gb_free=11.1, wall=24530
2023-08-22 00:34:50 | INFO | train_inner | epoch 035:    510 / 1080 loss=1.857, trans_loss=4.61, nll_loss=1.734, w2v_ctc_loss=0.52, task_loss=0, contrastive_loss=0.102, total=7381.65, n_correct=5364.4, ppl=3.33, accuracy=72.672, wps=25368.8, ups=1.72, wpb=14763.3, bsz=516.5, num_updates=36000, lr=7.45356e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=58, gb_free=11.8, wall=24588
2023-08-22 00:34:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 00:35:28 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 4.058 | trans_loss 5.165 | nll_loss 2.362 | w2v_ctc_loss 1.297 | task_loss 0 | contrastive_loss 0.267 | total 6138.43 | n_correct 4191 | ppl 5.14 | accuracy 68.275 | uer 16.268 | wer 17.906 | raw_wer 17.906 | bleu 27.8 | wps 1335.8 | wpb 6138.4 | bsz 201.1 | num_updates 36000 | best_bleu 27.88
2023-08-22 00:35:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 36000 updates
2023-08-22 00:35:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_35_36000.pt
2023-08-22 00:35:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_35_36000.pt
2023-08-22 00:35:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_35_36000.pt (epoch 35 @ 36000 updates, score 27.8) (writing took 7.690598827903159 seconds)
2023-08-22 00:36:35 | INFO | train_inner | epoch 035:    610 / 1080 loss=1.851, trans_loss=4.606, nll_loss=1.729, w2v_ctc_loss=0.509, task_loss=0, contrastive_loss=0.1, total=7430.45, n_correct=5404.24, ppl=3.32, accuracy=72.731, wps=14097.2, ups=0.95, wpb=14860.9, bsz=499.5, num_updates=36100, lr=7.44323e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=58, gb_free=12, wall=24694
2023-08-22 00:37:34 | INFO | train_inner | epoch 035:    710 / 1080 loss=1.854, trans_loss=4.607, nll_loss=1.731, w2v_ctc_loss=0.513, task_loss=0, contrastive_loss=0.11, total=7478.62, n_correct=5440.39, ppl=3.32, accuracy=72.746, wps=25530.9, ups=1.71, wpb=14957.2, bsz=508.6, num_updates=36200, lr=7.43294e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=58, gb_free=11.3, wall=24752
2023-08-22 00:38:32 | INFO | train_inner | epoch 035:    810 / 1080 loss=1.853, trans_loss=4.61, nll_loss=1.734, w2v_ctc_loss=0.508, task_loss=0, contrastive_loss=0.109, total=7482.01, n_correct=5443.33, ppl=3.33, accuracy=72.752, wps=25453.1, ups=1.7, wpb=14964, bsz=513.9, num_updates=36300, lr=7.4227e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=11.4, wall=24811
2023-08-22 00:39:31 | INFO | train_inner | epoch 035:    910 / 1080 loss=1.848, trans_loss=4.612, nll_loss=1.737, w2v_ctc_loss=0.51, task_loss=0, contrastive_loss=0.058, total=7382.67, n_correct=5363.49, ppl=3.33, accuracy=72.65, wps=25351, ups=1.72, wpb=14765.3, bsz=498.4, num_updates=36400, lr=7.41249e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=58, gb_free=12.5, wall=24869
2023-08-22 00:40:29 | INFO | train_inner | epoch 035:   1010 / 1080 loss=1.857, trans_loss=4.612, nll_loss=1.737, w2v_ctc_loss=0.519, task_loss=0, contrastive_loss=0.097, total=7326.37, n_correct=5319.03, ppl=3.33, accuracy=72.601, wps=24987.3, ups=1.71, wpb=14652.7, bsz=487.8, num_updates=36500, lr=7.40233e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=58, gb_free=13.3, wall=24928
2023-08-22 00:41:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 00:41:48 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 4.051 | trans_loss 5.161 | nll_loss 2.361 | w2v_ctc_loss 1.285 | task_loss 0 | contrastive_loss 0.261 | total 6138.43 | n_correct 4194 | ppl 5.14 | accuracy 68.324 | uer 16.228 | wer 17.903 | raw_wer 17.903 | bleu 27.8 | wps 1343.5 | wpb 6138.4 | bsz 201.1 | num_updates 36570 | best_bleu 27.88
2023-08-22 00:41:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 36570 updates
2023-08-22 00:41:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8001.pt
2023-08-22 00:41:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8001.pt
2023-08-22 00:41:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8001.pt (epoch 35 @ 36570 updates, score 27.8) (writing took 7.142805777024478 seconds)
2023-08-22 00:41:56 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-08-22 00:41:56 | INFO | train | epoch 035 | loss 1.852 | trans_loss 4.606 | nll_loss 1.728 | w2v_ctc_loss 0.513 | task_loss 0 | contrastive_loss 0.098 | total 7392.68 | n_correct 5380.11 | ppl 3.31 | accuracy 72.776 | wps 21826.4 | ups 1.48 | wpb 14785.4 | bsz 498.6 | num_updates 36570 | lr 7.39524e-05 | gnorm 0.386 | clip 0 | loss_scale 64 | train_wall 625 | gb_free 12.5 | wall 25015
2023-08-22 00:41:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 00:41:56 | INFO | fairseq.trainer | begin training epoch 36
2023-08-22 00:41:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 00:42:21 | INFO | train_inner | epoch 036:     30 / 1080 loss=1.857, trans_loss=4.608, nll_loss=1.732, w2v_ctc_loss=0.515, task_loss=0, contrastive_loss=0.127, total=7329.33, n_correct=5322.07, ppl=3.32, accuracy=72.613, wps=13076.7, ups=0.89, wpb=14658.7, bsz=499.5, num_updates=36600, lr=7.39221e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=58, gb_free=13.8, wall=25040
2023-08-22 00:43:20 | INFO | train_inner | epoch 036:    130 / 1080 loss=1.847, trans_loss=4.591, nll_loss=1.709, w2v_ctc_loss=0.509, task_loss=0, contrastive_loss=0.127, total=7361.53, n_correct=5380.52, ppl=3.27, accuracy=73.09, wps=25006.2, ups=1.7, wpb=14723.1, bsz=499.7, num_updates=36700, lr=7.38213e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=58, gb_free=12.5, wall=25099
2023-08-22 00:44:18 | INFO | train_inner | epoch 036:    230 / 1080 loss=1.839, trans_loss=4.591, nll_loss=1.71, w2v_ctc_loss=0.506, task_loss=0, contrastive_loss=0.059, total=7486.59, n_correct=5478.03, ppl=3.27, accuracy=73.171, wps=25768.7, ups=1.72, wpb=14973.2, bsz=513.8, num_updates=36800, lr=7.3721e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=57, gb_free=13.7, wall=25157
2023-08-22 00:45:17 | INFO | train_inner | epoch 036:    330 / 1080 loss=1.843, trans_loss=4.594, nll_loss=1.714, w2v_ctc_loss=0.502, task_loss=0, contrastive_loss=0.086, total=7461.88, n_correct=5451.13, ppl=3.28, accuracy=73.053, wps=25570, ups=1.71, wpb=14923.8, bsz=523.7, num_updates=36900, lr=7.3621e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=58, gb_free=12, wall=25215
2023-08-22 00:46:15 | INFO | train_inner | epoch 036:    430 / 1080 loss=1.848, trans_loss=4.591, nll_loss=1.709, w2v_ctc_loss=0.497, task_loss=0, contrastive_loss=0.176, total=7511.29, n_correct=5490.74, ppl=3.27, accuracy=73.1, wps=25644.4, ups=1.71, wpb=15022.6, bsz=519.5, num_updates=37000, lr=7.35215e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=14.4, wall=25274
2023-08-22 00:46:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-22 00:47:14 | INFO | train_inner | epoch 036:    531 / 1080 loss=1.843, trans_loss=4.598, nll_loss=1.718, w2v_ctc_loss=0.508, task_loss=0, contrastive_loss=0.074, total=7378.95, n_correct=5383.74, ppl=3.29, accuracy=72.961, wps=25230.5, ups=1.71, wpb=14757.9, bsz=494.1, num_updates=37100, lr=7.34223e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=58, gb_free=12.5, wall=25332
2023-08-22 00:48:13 | INFO | train_inner | epoch 036:    631 / 1080 loss=1.853, trans_loss=4.607, nll_loss=1.73, w2v_ctc_loss=0.514, task_loss=0, contrastive_loss=0.108, total=7430.53, n_correct=5407.89, ppl=3.32, accuracy=72.779, wps=25207.5, ups=1.7, wpb=14861.1, bsz=504, num_updates=37200, lr=7.33236e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=58, gb_free=13.8, wall=25391
2023-08-22 00:49:12 | INFO | train_inner | epoch 036:    731 / 1080 loss=1.85, trans_loss=4.611, nll_loss=1.735, w2v_ctc_loss=0.51, task_loss=0, contrastive_loss=0.077, total=7348.33, n_correct=5341.92, ppl=3.33, accuracy=72.696, wps=25030.7, ups=1.7, wpb=14696.7, bsz=479.5, num_updates=37300, lr=7.32252e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=58, gb_free=13.4, wall=25450
2023-08-22 00:50:10 | INFO | train_inner | epoch 036:    831 / 1080 loss=1.853, trans_loss=4.605, nll_loss=1.728, w2v_ctc_loss=0.511, task_loss=0, contrastive_loss=0.112, total=7460.9, n_correct=5429.53, ppl=3.31, accuracy=72.773, wps=25713.2, ups=1.72, wpb=14921.8, bsz=515.5, num_updates=37400, lr=7.31272e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=57, gb_free=13.2, wall=25508
2023-08-22 00:51:08 | INFO | train_inner | epoch 036:    931 / 1080 loss=1.855, trans_loss=4.615, nll_loss=1.741, w2v_ctc_loss=0.519, task_loss=0, contrastive_loss=0.066, total=7323.8, n_correct=5310.51, ppl=3.34, accuracy=72.51, wps=24903.6, ups=1.7, wpb=14647.6, bsz=490.1, num_updates=37500, lr=7.30297e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=58, gb_free=12.4, wall=25567
2023-08-22 00:52:07 | INFO | train_inner | epoch 036:   1031 / 1080 loss=1.85, trans_loss=4.612, nll_loss=1.737, w2v_ctc_loss=0.514, task_loss=0, contrastive_loss=0.071, total=7205.53, n_correct=5234.51, ppl=3.33, accuracy=72.646, wps=24554.4, ups=1.7, wpb=14411.1, bsz=463.4, num_updates=37600, lr=7.29325e-05, gnorm=0.393, clip=0, loss_scale=64, train_wall=58, gb_free=12.9, wall=25626
2023-08-22 00:52:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 00:53:14 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 4.058 | trans_loss 5.163 | nll_loss 2.361 | w2v_ctc_loss 1.302 | task_loss 0 | contrastive_loss 0.265 | total 6138.43 | n_correct 4199.29 | ppl 5.14 | accuracy 68.41 | uer 16.297 | wer 17.958 | raw_wer 17.958 | bleu 27.86 | wps 1338.2 | wpb 6138.4 | bsz 201.1 | num_updates 37649 | best_bleu 27.88
2023-08-22 00:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 37649 updates
2023-08-22 00:53:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8603.pt
2023-08-22 00:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8603.pt
2023-08-22 00:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8603.pt (epoch 36 @ 37649 updates, score 27.86) (writing took 7.659852736978792 seconds)
2023-08-22 00:53:22 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-08-22 00:53:22 | INFO | train | epoch 036 | loss 1.848 | trans_loss 4.601 | nll_loss 1.723 | w2v_ctc_loss 0.51 | task_loss 0 | contrastive_loss 0.096 | total 7391.41 | n_correct 5386.85 | ppl 3.3 | accuracy 72.88 | wps 23251.6 | ups 1.57 | wpb 14782.8 | bsz 498.3 | num_updates 37649 | lr 7.2885e-05 | gnorm 0.387 | clip 0 | loss_scale 64 | train_wall 625 | gb_free 11.3 | wall 25701
2023-08-22 00:53:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 00:53:22 | INFO | fairseq.trainer | begin training epoch 37
2023-08-22 00:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 00:54:00 | INFO | train_inner | epoch 037:     51 / 1080 loss=1.842, trans_loss=4.594, nll_loss=1.713, w2v_ctc_loss=0.508, task_loss=0, contrastive_loss=0.076, total=7268.69, n_correct=5309.8, ppl=3.28, accuracy=73.05, wps=12884.3, ups=0.89, wpb=14537.4, bsz=470.9, num_updates=37700, lr=7.28357e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=58, gb_free=12.8, wall=25739
2023-08-22 00:54:58 | INFO | train_inner | epoch 037:    151 / 1080 loss=1.841, trans_loss=4.588, nll_loss=1.705, w2v_ctc_loss=0.498, task_loss=0, contrastive_loss=0.124, total=7464.92, n_correct=5468.79, ppl=3.26, accuracy=73.26, wps=25639.3, ups=1.72, wpb=14929.8, bsz=519, num_updates=37800, lr=7.27393e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=13.3, wall=25797
2023-08-22 00:55:57 | INFO | train_inner | epoch 037:    251 / 1080 loss=1.849, trans_loss=4.6, nll_loss=1.721, w2v_ctc_loss=0.508, task_loss=0, contrastive_loss=0.117, total=7443.65, n_correct=5431.19, ppl=3.3, accuracy=72.964, wps=25163.1, ups=1.69, wpb=14887.3, bsz=499.7, num_updates=37900, lr=7.26433e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=59, gb_free=13.5, wall=25856
2023-08-22 00:56:56 | INFO | train_inner | epoch 037:    351 / 1080 loss=1.845, trans_loss=4.595, nll_loss=1.716, w2v_ctc_loss=0.511, task_loss=0, contrastive_loss=0.093, total=7368.93, n_correct=5379.89, ppl=3.28, accuracy=73.008, wps=25148.7, ups=1.71, wpb=14737.9, bsz=493.8, num_updates=38000, lr=7.25476e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=58, gb_free=12.5, wall=25915
2023-08-22 00:56:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 00:57:34 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.072 | trans_loss 5.164 | nll_loss 2.361 | w2v_ctc_loss 1.343 | task_loss 0 | contrastive_loss 0.265 | total 6138.43 | n_correct 4196.86 | ppl 5.14 | accuracy 68.37 | uer 16.42 | wer 18.074 | raw_wer 18.074 | bleu 27.91 | wps 1338 | wpb 6138.4 | bsz 201.1 | num_updates 38000 | best_bleu 27.91
2023-08-22 00:57:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 38000 updates
2023-08-22 00:57:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_37_38000.pt
2023-08-22 00:57:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_37_38000.pt
2023-08-22 00:57:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_37_38000.pt (epoch 37 @ 38000 updates, score 27.91) (writing took 13.145869152038358 seconds)
2023-08-22 00:58:46 | INFO | train_inner | epoch 037:    451 / 1080 loss=1.844, trans_loss=4.587, nll_loss=1.705, w2v_ctc_loss=0.498, task_loss=0, contrastive_loss=0.139, total=7446.73, n_correct=5447.45, ppl=3.26, accuracy=73.152, wps=13518.6, ups=0.91, wpb=14893.5, bsz=520.2, num_updates=38100, lr=7.24524e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=57, gb_free=13.4, wall=26025
2023-08-22 00:59:45 | INFO | train_inner | epoch 037:    551 / 1080 loss=1.85, trans_loss=4.603, nll_loss=1.724, w2v_ctc_loss=0.514, task_loss=0, contrastive_loss=0.087, total=7347.09, n_correct=5351.61, ppl=3.3, accuracy=72.84, wps=24817.5, ups=1.69, wpb=14694.2, bsz=470.9, num_updates=38200, lr=7.23575e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=59, gb_free=13, wall=26084
2023-08-22 01:00:44 | INFO | train_inner | epoch 037:    651 / 1080 loss=1.846, trans_loss=4.595, nll_loss=1.716, w2v_ctc_loss=0.508, task_loss=0, contrastive_loss=0.11, total=7409.41, n_correct=5410.31, ppl=3.28, accuracy=73.019, wps=25375.7, ups=1.71, wpb=14818.8, bsz=512.5, num_updates=38300, lr=7.22629e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=58, gb_free=11.3, wall=26142
2023-08-22 01:01:42 | INFO | train_inner | epoch 037:    751 / 1080 loss=1.839, trans_loss=4.588, nll_loss=1.707, w2v_ctc_loss=0.497, task_loss=0, contrastive_loss=0.103, total=7535.17, n_correct=5517.82, ppl=3.27, accuracy=73.228, wps=25833, ups=1.71, wpb=15070.3, bsz=537.1, num_updates=38400, lr=7.21688e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=58, gb_free=13, wall=26201
2023-08-22 01:02:40 | INFO | train_inner | epoch 037:    851 / 1080 loss=1.84, trans_loss=4.595, nll_loss=1.716, w2v_ctc_loss=0.507, task_loss=0, contrastive_loss=0.052, total=7523.52, n_correct=5496.15, ppl=3.28, accuracy=73.053, wps=25826.2, ups=1.72, wpb=15047, bsz=520.2, num_updates=38500, lr=7.2075e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=58, gb_free=12.8, wall=26259
2023-08-22 01:03:39 | INFO | train_inner | epoch 037:    951 / 1080 loss=1.848, trans_loss=4.608, nll_loss=1.731, w2v_ctc_loss=0.519, task_loss=0, contrastive_loss=0.044, total=7183.81, n_correct=5224.54, ppl=3.32, accuracy=72.727, wps=24553.2, ups=1.71, wpb=14367.6, bsz=454.6, num_updates=38600, lr=7.19816e-05, gnorm=0.395, clip=0, loss_scale=64, train_wall=58, gb_free=10.5, wall=26317
2023-08-22 01:04:38 | INFO | train_inner | epoch 037:   1051 / 1080 loss=1.85, trans_loss=4.608, nll_loss=1.732, w2v_ctc_loss=0.508, task_loss=0, contrastive_loss=0.102, total=7338.43, n_correct=5336.5, ppl=3.32, accuracy=72.72, wps=24914.5, ups=1.7, wpb=14676.9, bsz=475, num_updates=38700, lr=7.18885e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=58, gb_free=13.3, wall=26376
2023-08-22 01:04:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 01:05:33 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.055 | trans_loss 5.163 | nll_loss 2.361 | w2v_ctc_loss 1.292 | task_loss 0 | contrastive_loss 0.263 | total 6138.43 | n_correct 4200.43 | ppl 5.14 | accuracy 68.428 | uer 16.188 | wer 17.932 | raw_wer 17.932 | bleu 27.82 | wps 1330.1 | wpb 6138.4 | bsz 201.1 | num_updates 38729 | best_bleu 27.91
2023-08-22 01:05:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 38729 updates
2023-08-22 01:05:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8201.pt
2023-08-22 01:05:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8201.pt
2023-08-22 01:05:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8201.pt (epoch 37 @ 38729 updates, score 27.82) (writing took 7.283202505088411 seconds)
2023-08-22 01:05:40 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-08-22 01:05:40 | INFO | train | epoch 037 | loss 1.845 | trans_loss 4.596 | nll_loss 1.717 | w2v_ctc_loss 0.506 | task_loss 0 | contrastive_loss 0.096 | total 7392.68 | n_correct 5397.38 | ppl 3.29 | accuracy 73.01 | wps 21623.2 | ups 1.46 | wpb 14785.4 | bsz 498.6 | num_updates 38729 | lr 7.18616e-05 | gnorm 0.387 | clip 0 | loss_scale 64 | train_wall 625 | gb_free 11.6 | wall 26439
2023-08-22 01:05:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 01:05:41 | INFO | fairseq.trainer | begin training epoch 38
2023-08-22 01:05:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 01:06:30 | INFO | train_inner | epoch 038:     71 / 1080 loss=1.839, trans_loss=4.586, nll_loss=1.703, w2v_ctc_loss=0.497, task_loss=0, contrastive_loss=0.107, total=7333.79, n_correct=5373.49, ppl=3.26, accuracy=73.27, wps=13047.8, ups=0.89, wpb=14667.6, bsz=505.1, num_updates=38800, lr=7.17958e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=57, gb_free=13.6, wall=26489
2023-08-22 01:07:29 | INFO | train_inner | epoch 038:    171 / 1080 loss=1.833, trans_loss=4.582, nll_loss=1.698, w2v_ctc_loss=0.493, task_loss=0, contrastive_loss=0.084, total=7432.71, n_correct=5454.17, ppl=3.24, accuracy=73.381, wps=25416.4, ups=1.71, wpb=14865.4, bsz=501.9, num_updates=38900, lr=7.17035e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=58, gb_free=11.3, wall=26547
2023-08-22 01:08:27 | INFO | train_inner | epoch 038:    271 / 1080 loss=1.839, trans_loss=4.581, nll_loss=1.696, w2v_ctc_loss=0.493, task_loss=0, contrastive_loss=0.152, total=7503.08, n_correct=5503.89, ppl=3.24, accuracy=73.355, wps=25571.3, ups=1.7, wpb=15006.2, bsz=504.2, num_updates=39000, lr=7.16115e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=58, gb_free=12.7, wall=26606
2023-08-22 01:08:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-22 01:09:27 | INFO | train_inner | epoch 038:    372 / 1080 loss=1.84, trans_loss=4.589, nll_loss=1.707, w2v_ctc_loss=0.504, task_loss=0, contrastive_loss=0.089, total=7422.18, n_correct=5436.89, ppl=3.27, accuracy=73.252, wps=25010.5, ups=1.68, wpb=14844.4, bsz=505.4, num_updates=39100, lr=7.15199e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=59, gb_free=13, wall=26665
2023-08-22 01:10:25 | INFO | train_inner | epoch 038:    472 / 1080 loss=1.838, trans_loss=4.59, nll_loss=1.709, w2v_ctc_loss=0.505, task_loss=0, contrastive_loss=0.059, total=7456.77, n_correct=5450.48, ppl=3.27, accuracy=73.094, wps=25409.9, ups=1.7, wpb=14913.5, bsz=506.6, num_updates=39200, lr=7.14286e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=26724
2023-08-22 01:11:24 | INFO | train_inner | epoch 038:    572 / 1080 loss=1.841, trans_loss=4.596, nll_loss=1.716, w2v_ctc_loss=0.497, task_loss=0, contrastive_loss=0.106, total=7424.74, n_correct=5421.63, ppl=3.28, accuracy=73.021, wps=25381, ups=1.71, wpb=14849.5, bsz=505.4, num_updates=39300, lr=7.13376e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=10.1, wall=26783
2023-08-22 01:12:22 | INFO | train_inner | epoch 038:    672 / 1080 loss=1.841, trans_loss=4.596, nll_loss=1.716, w2v_ctc_loss=0.5, task_loss=0, contrastive_loss=0.097, total=7305.71, n_correct=5340.04, ppl=3.29, accuracy=73.094, wps=25229.3, ups=1.73, wpb=14611.4, bsz=485.1, num_updates=39400, lr=7.1247e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=57, gb_free=13.1, wall=26840
2023-08-22 01:13:21 | INFO | train_inner | epoch 038:    772 / 1080 loss=1.84, trans_loss=4.594, nll_loss=1.714, w2v_ctc_loss=0.505, task_loss=0, contrastive_loss=0.064, total=7415.72, n_correct=5422.5, ppl=3.28, accuracy=73.122, wps=25061.5, ups=1.69, wpb=14831.4, bsz=496.2, num_updates=39500, lr=7.11568e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=59, gb_free=14.2, wall=26900
2023-08-22 01:14:19 | INFO | train_inner | epoch 038:    872 / 1080 loss=1.837, trans_loss=4.592, nll_loss=1.712, w2v_ctc_loss=0.505, task_loss=0, contrastive_loss=0.053, total=7218.89, n_correct=5278.47, ppl=3.28, accuracy=73.12, wps=25119.1, ups=1.74, wpb=14437.8, bsz=473.9, num_updates=39600, lr=7.10669e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=57, gb_free=14.2, wall=26957
2023-08-22 01:15:18 | INFO | train_inner | epoch 038:    972 / 1080 loss=1.848, trans_loss=4.6, nll_loss=1.722, w2v_ctc_loss=0.503, task_loss=0, contrastive_loss=0.13, total=7449.8, n_correct=5437.52, ppl=3.3, accuracy=72.989, wps=25260.5, ups=1.7, wpb=14899.6, bsz=507.7, num_updates=39700, lr=7.09773e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=58, gb_free=12.3, wall=27016
2023-08-22 01:16:16 | INFO | train_inner | epoch 038:   1072 / 1080 loss=1.841, trans_loss=4.598, nll_loss=1.718, w2v_ctc_loss=0.505, task_loss=0, contrastive_loss=0.081, total=7365.49, n_correct=5380.22, ppl=3.29, accuracy=73.046, wps=25096, ups=1.7, wpb=14731, bsz=490.9, num_updates=39800, lr=7.08881e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=58, gb_free=11.7, wall=27075
2023-08-22 01:16:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 01:16:59 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 4.06 | trans_loss 5.163 | nll_loss 2.362 | w2v_ctc_loss 1.312 | task_loss 0 | contrastive_loss 0.258 | total 6138.43 | n_correct 4202.71 | ppl 5.14 | accuracy 68.466 | uer 16.241 | wer 17.936 | raw_wer 17.936 | bleu 27.71 | wps 1335.7 | wpb 6138.4 | bsz 201.1 | num_updates 39808 | best_bleu 27.91
2023-08-22 01:16:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 39808 updates
2023-08-22 01:16:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-22 01:17:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-22 01:17:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt (epoch 38 @ 39808 updates, score 27.71) (writing took 5.893620949005708 seconds)
2023-08-22 01:17:05 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-08-22 01:17:05 | INFO | train | epoch 038 | loss 1.84 | trans_loss 4.591 | nll_loss 1.71 | w2v_ctc_loss 0.501 | task_loss 0 | contrastive_loss 0.094 | total 7391.67 | n_correct 5407.59 | ppl 3.27 | accuracy 73.158 | wps 23305.1 | ups 1.58 | wpb 14783.3 | bsz 498.2 | num_updates 39808 | lr 7.0881e-05 | gnorm 0.387 | clip 0 | loss_scale 32 | train_wall 626 | gb_free 14.1 | wall 27124
2023-08-22 01:17:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 01:17:05 | INFO | fairseq.trainer | begin training epoch 39
2023-08-22 01:17:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 01:18:06 | INFO | train_inner | epoch 039:     92 / 1080 loss=1.836, trans_loss=4.58, nll_loss=1.695, w2v_ctc_loss=0.498, task_loss=0, contrastive_loss=0.132, total=7142.09, n_correct=5242.82, ppl=3.24, accuracy=73.407, wps=13025.4, ups=0.91, wpb=14284.2, bsz=453.3, num_updates=39900, lr=7.07992e-05, gnorm=0.399, clip=0, loss_scale=32, train_wall=57, gb_free=9.3, wall=27184
2023-08-22 01:19:05 | INFO | train_inner | epoch 039:    192 / 1080 loss=1.834, trans_loss=4.585, nll_loss=1.702, w2v_ctc_loss=0.504, task_loss=0, contrastive_loss=0.056, total=7391.96, n_correct=5418.95, ppl=3.25, accuracy=73.309, wps=25151.3, ups=1.7, wpb=14783.9, bsz=489, num_updates=40000, lr=7.07107e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=58, gb_free=11.4, wall=27243
2023-08-22 01:19:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 01:19:43 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.067 | trans_loss 5.173 | nll_loss 2.374 | w2v_ctc_loss 1.312 | task_loss 0 | contrastive_loss 0.259 | total 6138.43 | n_correct 4193.57 | ppl 5.18 | accuracy 68.317 | uer 16.286 | wer 18.07 | raw_wer 18.07 | bleu 27.52 | wps 1340.6 | wpb 6138.4 | bsz 201.1 | num_updates 40000 | best_bleu 27.91
2023-08-22 01:19:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 40000 updates
2023-08-22 01:19:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_39_40000.pt
2023-08-22 01:19:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_39_40000.pt
2023-08-22 01:19:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_39_40000.pt (epoch 39 @ 40000 updates, score 27.52) (writing took 6.639505747007206 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:0')
2023-08-22 01:20:48 | INFO | train_inner | epoch 039:    292 / 1080 loss=1.845, trans_loss=4.587, nll_loss=1.704, w2v_ctc_loss=0.498, task_loss=0, contrastive_loss=0.165, total=7436.51, n_correct=5449.11, ppl=3.26, accuracy=73.275, wps=14352.7, ups=0.97, wpb=14873, bsz=511, num_updates=40100, lr=7.06225e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=58, gb_free=13, wall=27347
2023-08-22 01:21:47 | INFO | train_inner | epoch 039:    392 / 1080 loss=1.835, trans_loss=4.587, nll_loss=1.705, w2v_ctc_loss=0.5, task_loss=0, contrastive_loss=0.077, total=7381.12, n_correct=5407.32, ppl=3.26, accuracy=73.259, wps=25154.5, ups=1.7, wpb=14762.2, bsz=493.1, num_updates=40200, lr=7.05346e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=58, gb_free=12.2, wall=27406
2023-08-22 01:22:46 | INFO | train_inner | epoch 039:    492 / 1080 loss=1.842, trans_loss=4.6, nll_loss=1.721, w2v_ctc_loss=0.508, task_loss=0, contrastive_loss=0.058, total=7298.48, n_correct=5326.03, ppl=3.3, accuracy=72.975, wps=24868, ups=1.7, wpb=14597, bsz=472.5, num_updates=40300, lr=7.0447e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=58, gb_free=12.9, wall=27464
2023-08-22 01:23:44 | INFO | train_inner | epoch 039:    592 / 1080 loss=1.837, trans_loss=4.584, nll_loss=1.701, w2v_ctc_loss=0.498, task_loss=0, contrastive_loss=0.102, total=7414.36, n_correct=5430.48, ppl=3.25, accuracy=73.243, wps=25482.8, ups=1.72, wpb=14828.7, bsz=501.9, num_updates=40400, lr=7.03598e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=27522
2023-08-22 01:24:42 | INFO | train_inner | epoch 039:    692 / 1080 loss=1.836, trans_loss=4.587, nll_loss=1.705, w2v_ctc_loss=0.495, task_loss=0, contrastive_loss=0.097, total=7551.03, n_correct=5535.6, ppl=3.26, accuracy=73.309, wps=25869.5, ups=1.71, wpb=15102.1, bsz=529.8, num_updates=40500, lr=7.02728e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=58, gb_free=14, wall=27581
2023-08-22 01:25:41 | INFO | train_inner | epoch 039:    792 / 1080 loss=1.833, trans_loss=4.581, nll_loss=1.698, w2v_ctc_loss=0.487, task_loss=0, contrastive_loss=0.102, total=7523.64, n_correct=5519.39, ppl=3.25, accuracy=73.361, wps=25799.2, ups=1.71, wpb=15047.3, bsz=526.9, num_updates=40600, lr=7.01862e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=14.5, wall=27639
2023-08-22 01:26:40 | INFO | train_inner | epoch 039:    892 / 1080 loss=1.839, trans_loss=4.59, nll_loss=1.709, w2v_ctc_loss=0.499, task_loss=0, contrastive_loss=0.091, total=7365.11, n_correct=5387.03, ppl=3.27, accuracy=73.143, wps=24909.5, ups=1.69, wpb=14730.2, bsz=496.2, num_updates=40700, lr=7.01e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=59, gb_free=10.4, wall=27698
2023-08-22 01:27:38 | INFO | train_inner | epoch 039:    992 / 1080 loss=1.836, trans_loss=4.593, nll_loss=1.712, w2v_ctc_loss=0.499, task_loss=0, contrastive_loss=0.068, total=7342.01, n_correct=5365.78, ppl=3.28, accuracy=73.083, wps=25204.5, ups=1.72, wpb=14684, bsz=486.2, num_updates=40800, lr=7.0014e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=27757
2023-08-22 01:28:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:7')
2023-08-22 01:29:08 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.071 | trans_loss 5.165 | nll_loss 2.361 | w2v_ctc_loss 1.34 | task_loss 0 | contrastive_loss 0.266 | total 6138.43 | n_correct 4196 | ppl 5.14 | accuracy 68.356 | uer 16.238 | wer 17.888 | raw_wer 17.888 | bleu 27.87 | wps 1335.9 | wpb 6138.4 | bsz 201.1 | num_updates 40888 | best_bleu 27.91
2023-08-22 01:29:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 40888 updates
2023-08-22 01:29:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8701.pt
2023-08-22 01:29:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8701.pt
2023-08-22 01:29:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8701.pt (epoch 39 @ 40888 updates, score 27.87) (writing took 7.558971125050448 seconds)
2023-08-22 01:29:16 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-08-22 01:29:16 | INFO | train | epoch 039 | loss 1.837 | trans_loss 4.587 | nll_loss 1.705 | w2v_ctc_loss 0.499 | task_loss 0 | contrastive_loss 0.096 | total 7392.68 | n_correct 5414.25 | ppl 3.26 | accuracy 73.238 | wps 21856.2 | ups 1.48 | wpb 14785.4 | bsz 498.6 | num_updates 40888 | lr 6.99386e-05 | gnorm 0.389 | clip 0 | loss_scale 32 | train_wall 625 | gb_free 12.9 | wall 27854
2023-08-22 01:29:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 01:29:16 | INFO | fairseq.trainer | begin training epoch 40
2023-08-22 01:29:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 01:29:30 | INFO | train_inner | epoch 040:     12 / 1080 loss=1.838, trans_loss=4.588, nll_loss=1.706, w2v_ctc_loss=0.5, task_loss=0, contrastive_loss=0.094, total=7358.36, n_correct=5388.63, ppl=3.26, accuracy=73.231, wps=13102.2, ups=0.89, wpb=14716.7, bsz=513.4, num_updates=40900, lr=6.99284e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=58, gb_free=13.4, wall=27869
2023-08-22 01:30:29 | INFO | train_inner | epoch 040:    112 / 1080 loss=1.827, trans_loss=4.577, nll_loss=1.69, w2v_ctc_loss=0.489, task_loss=0, contrastive_loss=0.075, total=7377.04, n_correct=5425.34, ppl=3.23, accuracy=73.544, wps=25223.8, ups=1.71, wpb=14754.1, bsz=492, num_updates=41000, lr=6.9843e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=27927
2023-08-22 01:31:27 | INFO | train_inner | epoch 040:    212 / 1080 loss=1.829, trans_loss=4.572, nll_loss=1.685, w2v_ctc_loss=0.49, task_loss=0, contrastive_loss=0.1, total=7394.32, n_correct=5445.77, ppl=3.22, accuracy=73.648, wps=25253.4, ups=1.71, wpb=14788.6, bsz=504.8, num_updates=41100, lr=6.9758e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=58, gb_free=13.7, wall=27986
2023-08-22 01:32:26 | INFO | train_inner | epoch 040:    312 / 1080 loss=1.825, trans_loss=4.574, nll_loss=1.688, w2v_ctc_loss=0.494, task_loss=0, contrastive_loss=0.048, total=7367.83, n_correct=5417.16, ppl=3.22, accuracy=73.524, wps=25107.5, ups=1.7, wpb=14735.7, bsz=489.3, num_updates=41200, lr=6.96733e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=58, gb_free=13.8, wall=28045
2023-08-22 01:33:24 | INFO | train_inner | epoch 040:    412 / 1080 loss=1.833, trans_loss=4.581, nll_loss=1.697, w2v_ctc_loss=0.492, task_loss=0, contrastive_loss=0.111, total=7319.55, n_correct=5370.06, ppl=3.24, accuracy=73.366, wps=25328.6, ups=1.73, wpb=14639.1, bsz=483.7, num_updates=41300, lr=6.95889e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=57, gb_free=14.3, wall=28102
2023-08-22 01:34:22 | INFO | train_inner | epoch 040:    512 / 1080 loss=1.834, trans_loss=4.576, nll_loss=1.692, w2v_ctc_loss=0.49, task_loss=0, contrastive_loss=0.123, total=7533.91, n_correct=5539.29, ppl=3.23, accuracy=73.525, wps=25831.4, ups=1.71, wpb=15067.8, bsz=538.4, num_updates=41400, lr=6.95048e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=58, gb_free=12.1, wall=28161
2023-08-22 01:34:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-22 01:35:21 | INFO | train_inner | epoch 040:    613 / 1080 loss=1.833, trans_loss=4.585, nll_loss=1.702, w2v_ctc_loss=0.502, task_loss=0, contrastive_loss=0.054, total=7414.91, n_correct=5439.08, ppl=3.25, accuracy=73.353, wps=25061.7, ups=1.69, wpb=14829.8, bsz=486.5, num_updates=41500, lr=6.9421e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=59, gb_free=11.5, wall=28220
2023-08-22 01:36:20 | INFO | train_inner | epoch 040:    713 / 1080 loss=1.835, trans_loss=4.591, nll_loss=1.709, w2v_ctc_loss=0.504, task_loss=0, contrastive_loss=0.047, total=7323.25, n_correct=5358.87, ppl=3.27, accuracy=73.176, wps=24990.8, ups=1.71, wpb=14646.5, bsz=471.5, num_updates=41600, lr=6.93375e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=58, gb_free=5.9, wall=28279
2023-08-22 01:37:20 | INFO | train_inner | epoch 040:    813 / 1080 loss=1.844, trans_loss=4.591, nll_loss=1.71, w2v_ctc_loss=0.504, task_loss=0, contrastive_loss=0.131, total=7454.85, n_correct=5451.3, ppl=3.27, accuracy=73.124, wps=25014.5, ups=1.68, wpb=14909.7, bsz=501.1, num_updates=41700, lr=6.92543e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=59, gb_free=12.3, wall=28338
2023-08-22 01:38:18 | INFO | train_inner | epoch 040:    913 / 1080 loss=1.834, trans_loss=4.592, nll_loss=1.711, w2v_ctc_loss=0.5, task_loss=0, contrastive_loss=0.052, total=7424.32, n_correct=5435.39, ppl=3.27, accuracy=73.211, wps=25300.3, ups=1.7, wpb=14848.6, bsz=507.5, num_updates=41800, lr=6.91714e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=9.9, wall=28397
2023-08-22 01:39:16 | INFO | train_inner | epoch 040:   1013 / 1080 loss=1.842, trans_loss=4.59, nll_loss=1.711, w2v_ctc_loss=0.493, task_loss=0, contrastive_loss=0.145, total=7378.14, n_correct=5401.72, ppl=3.27, accuracy=73.212, wps=25434.7, ups=1.72, wpb=14756.3, bsz=513.9, num_updates=41900, lr=6.90889e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=58, gb_free=13.1, wall=28455
2023-08-22 01:39:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 01:40:34 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 4.063 | trans_loss 5.163 | nll_loss 2.359 | w2v_ctc_loss 1.32 | task_loss 0 | contrastive_loss 0.264 | total 6138.43 | n_correct 4206.43 | ppl 5.13 | accuracy 68.526 | uer 16.23 | wer 17.951 | raw_wer 17.951 | bleu 27.88 | wps 1330.8 | wpb 6138.4 | bsz 201.1 | num_updates 41967 | best_bleu 27.91
2023-08-22 01:40:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 41967 updates
2023-08-22 01:40:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8805.pt
2023-08-22 01:40:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8805.pt
2023-08-22 01:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8805.pt (epoch 40 @ 41967 updates, score 27.88) (writing took 7.969697143998928 seconds)
2023-08-22 01:40:43 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-08-22 01:40:43 | INFO | train | epoch 040 | loss 1.833 | trans_loss 4.583 | nll_loss 1.7 | w2v_ctc_loss 0.496 | task_loss 0 | contrastive_loss 0.089 | total 7392.01 | n_correct 5423.11 | ppl 3.25 | accuracy 73.364 | wps 23207.7 | ups 1.57 | wpb 14784 | bsz 498 | num_updates 41967 | lr 6.90337e-05 | gnorm 0.388 | clip 0 | loss_scale 32 | train_wall 626 | gb_free 13.4 | wall 28541
2023-08-22 01:40:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 01:40:43 | INFO | fairseq.trainer | begin training epoch 41
2023-08-22 01:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 01:41:10 | INFO | train_inner | epoch 041:     33 / 1080 loss=1.834, trans_loss=4.582, nll_loss=1.698, w2v_ctc_loss=0.493, task_loss=0, contrastive_loss=0.101, total=7422.81, n_correct=5446.8, ppl=3.25, accuracy=73.379, wps=13052.9, ups=0.88, wpb=14845.6, bsz=503.2, num_updates=42000, lr=6.90066e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=28569
2023-08-22 01:41:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 01:41:49 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 4.067 | trans_loss 5.167 | nll_loss 2.366 | w2v_ctc_loss 1.326 | task_loss 0 | contrastive_loss 0.261 | total 6138.43 | n_correct 4204.71 | ppl 5.16 | accuracy 68.498 | uer 16.238 | wer 17.973 | raw_wer 17.973 | bleu 27.66 | wps 1337.1 | wpb 6138.4 | bsz 201.1 | num_updates 42000 | best_bleu 27.91
2023-08-22 01:41:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 42000 updates
2023-08-22 01:41:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_41_42000.pt
2023-08-22 01:41:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_41_42000.pt
2023-08-22 01:41:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_41_42000.pt (epoch 41 @ 42000 updates, score 27.66) (writing took 7.735778236063197 seconds)
2023-08-22 01:42:55 | INFO | train_inner | epoch 041:    133 / 1080 loss=1.825, trans_loss=4.57, nll_loss=1.683, w2v_ctc_loss=0.484, task_loss=0, contrastive_loss=0.094, total=7567.96, n_correct=5575.32, ppl=3.21, accuracy=73.67, wps=14368.9, ups=0.95, wpb=15135.9, bsz=526.9, num_updates=42100, lr=6.89246e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=58, gb_free=13.7, wall=28674
2023-08-22 01:43:54 | INFO | train_inner | epoch 041:    233 / 1080 loss=1.821, trans_loss=4.573, nll_loss=1.686, w2v_ctc_loss=0.485, task_loss=0, contrastive_loss=0.054, total=7494.09, n_correct=5518.6, ppl=3.22, accuracy=73.639, wps=25457.5, ups=1.7, wpb=14988.2, bsz=512.2, num_updates=42200, lr=6.88428e-05, gnorm=0.383, clip=0, loss_scale=32, train_wall=58, gb_free=14.5, wall=28733
2023-08-22 01:44:52 | INFO | train_inner | epoch 041:    333 / 1080 loss=1.824, trans_loss=4.567, nll_loss=1.679, w2v_ctc_loss=0.492, task_loss=0, contrastive_loss=0.076, total=7391.3, n_correct=5448.49, ppl=3.2, accuracy=73.715, wps=25416, ups=1.72, wpb=14782.6, bsz=495, num_updates=42300, lr=6.87614e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=58, gb_free=11.5, wall=28791
2023-08-22 01:45:51 | INFO | train_inner | epoch 041:    433 / 1080 loss=1.826, trans_loss=4.576, nll_loss=1.69, w2v_ctc_loss=0.493, task_loss=0, contrastive_loss=0.057, total=7409.86, n_correct=5445, ppl=3.23, accuracy=73.483, wps=25317.9, ups=1.71, wpb=14819.7, bsz=497.9, num_updates=42400, lr=6.86803e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=58, gb_free=12.9, wall=28850
2023-08-22 01:46:49 | INFO | train_inner | epoch 041:    533 / 1080 loss=1.827, trans_loss=4.577, nll_loss=1.692, w2v_ctc_loss=0.491, task_loss=0, contrastive_loss=0.073, total=7392.73, n_correct=5433.94, ppl=3.23, accuracy=73.504, wps=25580.2, ups=1.73, wpb=14785.5, bsz=504, num_updates=42500, lr=6.85994e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=57, gb_free=13.7, wall=28907
2023-08-22 01:47:47 | INFO | train_inner | epoch 041:    633 / 1080 loss=1.833, trans_loss=4.588, nll_loss=1.706, w2v_ctc_loss=0.495, task_loss=0, contrastive_loss=0.073, total=7278.35, n_correct=5334.36, ppl=3.26, accuracy=73.291, wps=25024, ups=1.72, wpb=14556.7, bsz=473.6, num_updates=42600, lr=6.85189e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=58, gb_free=12.6, wall=28966
2023-08-22 01:48:46 | INFO | train_inner | epoch 041:    733 / 1080 loss=1.837, trans_loss=4.588, nll_loss=1.705, w2v_ctc_loss=0.498, task_loss=0, contrastive_loss=0.095, total=7249.97, n_correct=5307.97, ppl=3.26, accuracy=73.214, wps=24749.8, ups=1.71, wpb=14499.9, bsz=470.1, num_updates=42700, lr=6.84386e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=58, gb_free=10, wall=29024
2023-08-22 01:49:44 | INFO | train_inner | epoch 041:    833 / 1080 loss=1.846, trans_loss=4.591, nll_loss=1.71, w2v_ctc_loss=0.495, task_loss=0, contrastive_loss=0.183, total=7446.96, n_correct=5456.4, ppl=3.27, accuracy=73.27, wps=25338.2, ups=1.7, wpb=14893.9, bsz=520, num_updates=42800, lr=6.83586e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=58, gb_free=13.9, wall=29083
2023-08-22 01:50:43 | INFO | train_inner | epoch 041:    933 / 1080 loss=1.83, trans_loss=4.576, nll_loss=1.691, w2v_ctc_loss=0.488, task_loss=0, contrastive_loss=0.106, total=7465.51, n_correct=5488.51, ppl=3.23, accuracy=73.518, wps=25529, ups=1.71, wpb=14931, bsz=519.2, num_updates=42900, lr=6.82789e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=14.3, wall=29141
2023-08-22 01:51:41 | INFO | train_inner | epoch 041:   1033 / 1080 loss=1.835, trans_loss=4.583, nll_loss=1.7, w2v_ctc_loss=0.496, task_loss=0, contrastive_loss=0.118, total=7264.33, n_correct=5329.75, ppl=3.25, accuracy=73.369, wps=25143, ups=1.73, wpb=14528.7, bsz=469.9, num_updates=43000, lr=6.81994e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=57, gb_free=11.9, wall=29199
2023-08-22 01:52:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 01:52:48 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 4.056 | trans_loss 5.167 | nll_loss 2.365 | w2v_ctc_loss 1.289 | task_loss 0 | contrastive_loss 0.263 | total 6138.43 | n_correct 4206.57 | ppl 5.15 | accuracy 68.528 | uer 16.22 | wer 17.984 | raw_wer 17.984 | bleu 27.76 | wps 1258.3 | wpb 6138.4 | bsz 201.1 | num_updates 43047 | best_bleu 27.91
2023-08-22 01:52:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 43047 updates
2023-08-22 01:52:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7600.pt
2023-08-22 01:52:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7600.pt
2023-08-22 01:52:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.7600.pt (epoch 41 @ 43047 updates, score 27.76) (writing took 7.234790744027123 seconds)
2023-08-22 01:52:55 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-08-22 01:52:55 | INFO | train | epoch 041 | loss 1.831 | trans_loss 4.579 | nll_loss 1.695 | w2v_ctc_loss 0.492 | task_loss 0 | contrastive_loss 0.094 | total 7392.68 | n_correct 5430.7 | ppl 3.24 | accuracy 73.46 | wps 21808.6 | ups 1.48 | wpb 14785.4 | bsz 498.6 | num_updates 43047 | lr 6.81622e-05 | gnorm 0.39 | clip 0 | loss_scale 32 | train_wall 624 | gb_free 13.8 | wall 29274
2023-08-22 01:52:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 01:52:55 | INFO | fairseq.trainer | begin training epoch 42
2023-08-22 01:52:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 01:53:34 | INFO | train_inner | epoch 042:     53 / 1080 loss=1.835, trans_loss=4.58, nll_loss=1.695, w2v_ctc_loss=0.489, task_loss=0, contrastive_loss=0.149, total=7281.08, n_correct=5347.63, ppl=3.24, accuracy=73.446, wps=12836.1, ups=0.88, wpb=14562.2, bsz=496.2, num_updates=43100, lr=6.81203e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=57, gb_free=12.7, wall=29313
2023-08-22 01:54:33 | INFO | train_inner | epoch 042:    153 / 1080 loss=1.829, trans_loss=4.568, nll_loss=1.68, w2v_ctc_loss=0.494, task_loss=0, contrastive_loss=0.106, total=7318.74, n_correct=5390.21, ppl=3.2, accuracy=73.649, wps=24964.1, ups=1.71, wpb=14637.5, bsz=486.4, num_updates=43200, lr=6.80414e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=29371
2023-08-22 01:55:31 | INFO | train_inner | epoch 042:    253 / 1080 loss=1.82, trans_loss=4.565, nll_loss=1.676, w2v_ctc_loss=0.481, task_loss=0, contrastive_loss=0.088, total=7437.38, n_correct=5493.6, ppl=3.2, accuracy=73.865, wps=25601.6, ups=1.72, wpb=14874.8, bsz=515.8, num_updates=43300, lr=6.79628e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=57, gb_free=13.2, wall=29429
2023-08-22 01:56:30 | INFO | train_inner | epoch 042:    353 / 1080 loss=1.827, trans_loss=4.577, nll_loss=1.691, w2v_ctc_loss=0.498, task_loss=0, contrastive_loss=0.05, total=7189.32, n_correct=5282.33, ppl=3.23, accuracy=73.475, wps=24510.4, ups=1.7, wpb=14378.6, bsz=453.8, num_updates=43400, lr=6.78844e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=58, gb_free=9.1, wall=29488
2023-08-22 01:57:28 | INFO | train_inner | epoch 042:    453 / 1080 loss=1.832, trans_loss=4.576, nll_loss=1.691, w2v_ctc_loss=0.492, task_loss=0, contrastive_loss=0.112, total=7401.45, n_correct=5442.88, ppl=3.23, accuracy=73.538, wps=25130.6, ups=1.7, wpb=14802.9, bsz=505.6, num_updates=43500, lr=6.78064e-05, gnorm=0.392, clip=0, loss_scale=64, train_wall=58, gb_free=13.5, wall=29547
2023-08-22 01:58:26 | INFO | train_inner | epoch 042:    553 / 1080 loss=1.826, trans_loss=4.575, nll_loss=1.689, w2v_ctc_loss=0.486, task_loss=0, contrastive_loss=0.083, total=7392.61, n_correct=5434.75, ppl=3.22, accuracy=73.516, wps=25594.9, ups=1.73, wpb=14785.2, bsz=500.6, num_updates=43600, lr=6.77285e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=57, gb_free=12.5, wall=29605
2023-08-22 01:59:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-22 01:59:26 | INFO | train_inner | epoch 042:    654 / 1080 loss=1.824, trans_loss=4.573, nll_loss=1.687, w2v_ctc_loss=0.488, task_loss=0, contrastive_loss=0.06, total=7459.41, n_correct=5487.7, ppl=3.22, accuracy=73.567, wps=25021.3, ups=1.68, wpb=14918.8, bsz=516.2, num_updates=43700, lr=6.7651e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=59, gb_free=12.6, wall=29664
2023-08-22 02:00:24 | INFO | train_inner | epoch 042:    754 / 1080 loss=1.822, trans_loss=4.576, nll_loss=1.691, w2v_ctc_loss=0.488, task_loss=0, contrastive_loss=0.046, total=7347.96, n_correct=5407.34, ppl=3.23, accuracy=73.59, wps=25347.8, ups=1.72, wpb=14695.9, bsz=474.4, num_updates=43800, lr=6.75737e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=57, gb_free=10.6, wall=29722
2023-08-22 02:01:23 | INFO | train_inner | epoch 042:    854 / 1080 loss=1.83, trans_loss=4.577, nll_loss=1.693, w2v_ctc_loss=0.486, task_loss=0, contrastive_loss=0.12, total=7490.16, n_correct=5509.06, ppl=3.23, accuracy=73.551, wps=25380.1, ups=1.69, wpb=14980.3, bsz=514.1, num_updates=43900, lr=6.74967e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=14.2, wall=29781
2023-08-22 02:02:21 | INFO | train_inner | epoch 042:    954 / 1080 loss=1.829, trans_loss=4.578, nll_loss=1.694, w2v_ctc_loss=0.491, task_loss=0, contrastive_loss=0.096, total=7388.2, n_correct=5420.41, ppl=3.24, accuracy=73.366, wps=25274.5, ups=1.71, wpb=14776.4, bsz=489.3, num_updates=44000, lr=6.742e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=29840
2023-08-22 02:02:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 02:02:59 | INFO | dev_st | epoch 042 | valid on 'dev_st' subset | loss 4.057 | trans_loss 5.166 | nll_loss 2.364 | w2v_ctc_loss 1.293 | task_loss 0 | contrastive_loss 0.265 | total 6138.43 | n_correct 4203.14 | ppl 5.15 | accuracy 68.473 | uer 16.123 | wer 17.824 | raw_wer 17.824 | bleu 28 | wps 1352.1 | wpb 6138.4 | bsz 201.1 | num_updates 44000 | best_bleu 28
2023-08-22 02:02:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 44000 updates
2023-08-22 02:02:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_42_44000.pt
2023-08-22 02:03:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_42_44000.pt
2023-08-22 02:03:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_42_44000.pt (epoch 42 @ 44000 updates, score 28.0) (writing took 15.129452447057702 seconds)
2023-08-22 02:04:13 | INFO | train_inner | epoch 042:   1054 / 1080 loss=1.83, trans_loss=4.585, nll_loss=1.702, w2v_ctc_loss=0.485, task_loss=0, contrastive_loss=0.098, total=7525.75, n_correct=5520.85, ppl=3.25, accuracy=73.359, wps=13432.3, ups=0.89, wpb=15051.5, bsz=513.3, num_updates=44100, lr=6.73435e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=14, wall=29952
2023-08-22 02:04:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 02:05:08 | INFO | dev_st | epoch 042 | valid on 'dev_st' subset | loss 4.064 | trans_loss 5.166 | nll_loss 2.365 | w2v_ctc_loss 1.313 | task_loss 0 | contrastive_loss 0.269 | total 6138.43 | n_correct 4205.14 | ppl 5.15 | accuracy 68.505 | uer 16.139 | wer 17.958 | raw_wer 17.958 | bleu 27.87 | wps 1268.8 | wpb 6138.4 | bsz 201.1 | num_updates 44126 | best_bleu 28
2023-08-22 02:05:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 44126 updates
2023-08-22 02:05:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8702.pt
2023-08-22 02:05:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8702.pt
2023-08-22 02:05:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8702.pt (epoch 42 @ 44126 updates, score 27.87) (writing took 6.525605540024117 seconds)
2023-08-22 02:05:15 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-08-22 02:05:15 | INFO | train | epoch 042 | loss 1.827 | trans_loss 4.575 | nll_loss 1.689 | w2v_ctc_loss 0.488 | task_loss 0 | contrastive_loss 0.091 | total 7392.37 | n_correct 5437.59 | ppl 3.22 | accuracy 73.557 | wps 21552.3 | ups 1.46 | wpb 14784.7 | bsz 498.3 | num_updates 44126 | lr 6.73237e-05 | gnorm 0.39 | clip 0 | loss_scale 32 | train_wall 625 | gb_free 14.1 | wall 30014
2023-08-22 02:05:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 02:05:16 | INFO | fairseq.trainer | begin training epoch 43
2023-08-22 02:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 02:06:07 | INFO | train_inner | epoch 043:     74 / 1080 loss=1.822, trans_loss=4.567, nll_loss=1.679, w2v_ctc_loss=0.48, task_loss=0, contrastive_loss=0.099, total=7446.35, n_correct=5494.29, ppl=3.2, accuracy=73.785, wps=13145.8, ups=0.88, wpb=14892.7, bsz=507.5, num_updates=44200, lr=6.72673e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=58, gb_free=13, wall=30065
2023-08-22 02:07:05 | INFO | train_inner | epoch 043:    174 / 1080 loss=1.82, trans_loss=4.563, nll_loss=1.673, w2v_ctc_loss=0.484, task_loss=0, contrastive_loss=0.091, total=7348.7, n_correct=5427.29, ppl=3.19, accuracy=73.854, wps=25094.7, ups=1.71, wpb=14697.4, bsz=481.6, num_updates=44300, lr=6.71913e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=58, gb_free=14.2, wall=30124
2023-08-22 02:08:04 | INFO | train_inner | epoch 043:    274 / 1080 loss=1.825, trans_loss=4.57, nll_loss=1.683, w2v_ctc_loss=0.493, task_loss=0, contrastive_loss=0.076, total=7325.68, n_correct=5392.05, ppl=3.21, accuracy=73.605, wps=24995.9, ups=1.71, wpb=14651.4, bsz=491, num_updates=44400, lr=6.71156e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=58, gb_free=13.8, wall=30182
2023-08-22 02:09:02 | INFO | train_inner | epoch 043:    374 / 1080 loss=1.82, trans_loss=4.565, nll_loss=1.677, w2v_ctc_loss=0.485, task_loss=0, contrastive_loss=0.075, total=7335.05, n_correct=5412.2, ppl=3.2, accuracy=73.785, wps=25259.2, ups=1.72, wpb=14670.1, bsz=490.2, num_updates=44500, lr=6.70402e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=57, gb_free=12.2, wall=30240
2023-08-22 02:10:01 | INFO | train_inner | epoch 043:    474 / 1080 loss=1.819, trans_loss=4.569, nll_loss=1.681, w2v_ctc_loss=0.489, task_loss=0, contrastive_loss=0.043, total=7442.05, n_correct=5486.18, ppl=3.21, accuracy=73.719, wps=25382.6, ups=1.71, wpb=14884.1, bsz=491, num_updates=44600, lr=6.6965e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=58, gb_free=12.9, wall=30299
2023-08-22 02:10:59 | INFO | train_inner | epoch 043:    574 / 1080 loss=1.822, trans_loss=4.575, nll_loss=1.689, w2v_ctc_loss=0.488, task_loss=0, contrastive_loss=0.047, total=7338.3, n_correct=5396.96, ppl=3.22, accuracy=73.545, wps=25098.6, ups=1.71, wpb=14676.6, bsz=474.2, num_updates=44700, lr=6.689e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=13, wall=30358
2023-08-22 02:11:58 | INFO | train_inner | epoch 043:    674 / 1080 loss=1.818, trans_loss=4.568, nll_loss=1.681, w2v_ctc_loss=0.484, task_loss=0, contrastive_loss=0.05, total=7492.23, n_correct=5530.54, ppl=3.21, accuracy=73.817, wps=25394.4, ups=1.69, wpb=14984.5, bsz=517, num_updates=44800, lr=6.68153e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=58, gb_free=13.1, wall=30417
2023-08-22 02:12:56 | INFO | train_inner | epoch 043:    774 / 1080 loss=1.828, trans_loss=4.58, nll_loss=1.696, w2v_ctc_loss=0.49, task_loss=0, contrastive_loss=0.078, total=7352.75, n_correct=5403.7, ppl=3.24, accuracy=73.492, wps=25200.8, ups=1.71, wpb=14705.5, bsz=479.4, num_updates=44900, lr=6.67409e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=58, gb_free=13.2, wall=30475
2023-08-22 02:13:55 | INFO | train_inner | epoch 043:    874 / 1080 loss=1.839, trans_loss=4.583, nll_loss=1.7, w2v_ctc_loss=0.487, task_loss=0, contrastive_loss=0.166, total=7274.83, n_correct=5335.08, ppl=3.25, accuracy=73.336, wps=24941.2, ups=1.71, wpb=14549.7, bsz=489.3, num_updates=45000, lr=6.66667e-05, gnorm=0.401, clip=0, loss_scale=32, train_wall=58, gb_free=12.8, wall=30533
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:0')
2023-08-22 02:14:53 | INFO | train_inner | epoch 043:    974 / 1080 loss=1.846, trans_loss=4.585, nll_loss=1.703, w2v_ctc_loss=0.496, task_loss=0, contrastive_loss=0.2, total=7407.96, n_correct=5430.62, ppl=3.26, accuracy=73.308, wps=25262.7, ups=1.71, wpb=14815.9, bsz=522.2, num_updates=45100, lr=6.65927e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=30592
2023-08-22 02:15:52 | INFO | train_inner | epoch 043:   1074 / 1080 loss=1.822, trans_loss=4.57, nll_loss=1.684, w2v_ctc_loss=0.479, task_loss=0, contrastive_loss=0.088, total=7555.97, n_correct=5568.6, ppl=3.21, accuracy=73.698, wps=25636.8, ups=1.7, wpb=15111.9, bsz=540.8, num_updates=45200, lr=6.6519e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=58, gb_free=13.6, wall=30651
2023-08-22 02:15:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2568, device='cuda:4')
2023-08-22 02:16:35 | INFO | dev_st | epoch 043 | valid on 'dev_st' subset | loss 4.054 | trans_loss 5.165 | nll_loss 2.363 | w2v_ctc_loss 1.288 | task_loss 0 | contrastive_loss 0.259 | total 6138.43 | n_correct 4203.57 | ppl 5.15 | accuracy 68.48 | uer 16.118 | wer 17.847 | raw_wer 17.847 | bleu 27.62 | wps 1270.1 | wpb 6138.4 | bsz 201.1 | num_updates 45206 | best_bleu 28
2023-08-22 02:16:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 45206 updates
2023-08-22 02:16:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-22 02:16:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-22 02:16:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_last.pt (epoch 43 @ 45206 updates, score 27.62) (writing took 5.592674738960341 seconds)
2023-08-22 02:16:41 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-08-22 02:16:41 | INFO | train | epoch 043 | loss 1.826 | trans_loss 4.572 | nll_loss 1.686 | w2v_ctc_loss 0.487 | task_loss 0 | contrastive_loss 0.093 | total 7392.68 | n_correct 5443.53 | ppl 3.22 | accuracy 73.634 | wps 23291.7 | ups 1.58 | wpb 14785.4 | bsz 498.6 | num_updates 45206 | lr 6.65146e-05 | gnorm 0.391 | clip 0 | loss_scale 32 | train_wall 625 | gb_free 13.6 | wall 30699
2023-08-22 02:16:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 02:16:41 | INFO | fairseq.trainer | begin training epoch 44
2023-08-22 02:16:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 02:17:43 | INFO | train_inner | epoch 044:     94 / 1080 loss=1.815, trans_loss=4.552, nll_loss=1.659, w2v_ctc_loss=0.478, task_loss=0, contrastive_loss=0.092, total=7374.49, n_correct=5465.87, ppl=3.16, accuracy=74.119, wps=13274.6, ups=0.9, wpb=14749, bsz=500.6, num_updates=45300, lr=6.64455e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=57, gb_free=12.3, wall=30762
2023-08-22 02:18:42 | INFO | train_inner | epoch 044:    194 / 1080 loss=1.826, trans_loss=4.56, nll_loss=1.67, w2v_ctc_loss=0.484, task_loss=0, contrastive_loss=0.175, total=7287.05, n_correct=5389.33, ppl=3.18, accuracy=73.958, wps=24970.9, ups=1.71, wpb=14574.1, bsz=487.5, num_updates=45400, lr=6.63723e-05, gnorm=0.394, clip=0, loss_scale=32, train_wall=58, gb_free=11.1, wall=30820
2023-08-22 02:19:41 | INFO | train_inner | epoch 044:    294 / 1080 loss=1.823, trans_loss=4.561, nll_loss=1.672, w2v_ctc_loss=0.486, task_loss=0, contrastive_loss=0.122, total=7388.45, n_correct=5456.58, ppl=3.19, accuracy=73.853, wps=25136.4, ups=1.7, wpb=14776.9, bsz=507.8, num_updates=45500, lr=6.62994e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=58, gb_free=11.5, wall=30879
2023-08-22 02:20:39 | INFO | train_inner | epoch 044:    394 / 1080 loss=1.822, trans_loss=4.565, nll_loss=1.678, w2v_ctc_loss=0.481, task_loss=0, contrastive_loss=0.096, total=7507.16, n_correct=5540.83, ppl=3.2, accuracy=73.807, wps=25681.2, ups=1.71, wpb=15014.3, bsz=523, num_updates=45600, lr=6.62266e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=58, gb_free=12.8, wall=30938
2023-08-22 02:21:38 | INFO | train_inner | epoch 044:    494 / 1080 loss=1.813, trans_loss=4.561, nll_loss=1.671, w2v_ctc_loss=0.48, task_loss=0, contrastive_loss=0.046, total=7382.99, n_correct=5454.15, ppl=3.18, accuracy=73.875, wps=25140, ups=1.7, wpb=14766, bsz=493.4, num_updates=45700, lr=6.61541e-05, gnorm=0.388, clip=0, loss_scale=32, train_wall=58, gb_free=14.1, wall=30996
2023-08-22 02:22:36 | INFO | train_inner | epoch 044:    594 / 1080 loss=1.821, trans_loss=4.572, nll_loss=1.685, w2v_ctc_loss=0.48, task_loss=0, contrastive_loss=0.087, total=7314.32, n_correct=5392.23, ppl=3.22, accuracy=73.722, wps=25047.1, ups=1.71, wpb=14628.6, bsz=485.6, num_updates=45800, lr=6.60819e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=58, gb_free=9.4, wall=31055
2023-08-22 02:23:35 | INFO | train_inner | epoch 044:    694 / 1080 loss=1.822, trans_loss=4.57, nll_loss=1.683, w2v_ctc_loss=0.486, task_loss=0, contrastive_loss=0.075, total=7364.02, n_correct=5424.68, ppl=3.21, accuracy=73.665, wps=25118.2, ups=1.71, wpb=14728, bsz=488.1, num_updates=45900, lr=6.60098e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=58, gb_free=14.1, wall=31113
2023-08-22 02:24:33 | INFO | train_inner | epoch 044:    794 / 1080 loss=1.825, trans_loss=4.574, nll_loss=1.688, w2v_ctc_loss=0.485, task_loss=0, contrastive_loss=0.096, total=7545.17, n_correct=5555.98, ppl=3.22, accuracy=73.636, wps=25808.9, ups=1.71, wpb=15090.3, bsz=520.5, num_updates=46000, lr=6.5938e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=58, gb_free=13.7, wall=31172
2023-08-22 02:24:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 02:25:13 | INFO | dev_st | epoch 044 | valid on 'dev_st' subset | loss 4.068 | trans_loss 5.167 | nll_loss 2.366 | w2v_ctc_loss 1.328 | task_loss 0 | contrastive_loss 0.26 | total 6138.43 | n_correct 4204.86 | ppl 5.15 | accuracy 68.501 | uer 15.952 | wer 17.52 | raw_wer 17.52 | bleu 27.76 | wps 1278.1 | wpb 6138.4 | bsz 201.1 | num_updates 46000 | best_bleu 28
2023-08-22 02:25:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 46000 updates
2023-08-22 02:25:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_44_46000.pt
2023-08-22 02:25:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_44_46000.pt
2023-08-22 02:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_44_46000.pt (epoch 44 @ 46000 updates, score 27.76) (writing took 6.974709452013485 seconds)
2023-08-22 02:25:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-22 02:25:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 02:26:00 | INFO | dev_st | epoch 044 | valid on 'dev_st' subset | loss 4.068 | trans_loss 5.167 | nll_loss 2.366 | w2v_ctc_loss 1.328 | task_loss 0 | contrastive_loss 0.26 | total 6138.43 | n_correct 4204.86 | ppl 5.15 | accuracy 68.501 | uer 15.952 | wer 17.52 | raw_wer 17.52 | bleu 27.76 | wps 1289.6 | wpb 6138.4 | bsz 201.1 | num_updates 46000 | best_bleu 28
2023-08-22 02:26:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 46000 updates
2023-08-22 02:26:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_44_46000.pt
2023-08-22 02:26:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_44_46000.pt
2023-08-22 02:26:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_44_46000.pt (epoch 44 @ 46000 updates, score 27.76) (writing took 9.219680960057303 seconds)
2023-08-22 02:27:08 | INFO | train_inner | epoch 044:    895 / 1080 loss=1.83, trans_loss=4.582, nll_loss=1.698, w2v_ctc_loss=0.491, task_loss=0, contrastive_loss=0.083, total=7352.71, n_correct=5396.38, ppl=3.24, accuracy=73.393, wps=9514.1, ups=0.65, wpb=14705.4, bsz=475.2, num_updates=46100, lr=6.58665e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=58, gb_free=14.3, wall=31326
2023-08-22 02:28:07 | INFO | train_inner | epoch 044:    995 / 1080 loss=1.824, trans_loss=4.577, nll_loss=1.692, w2v_ctc_loss=0.49, task_loss=0, contrastive_loss=0.054, total=7409.45, n_correct=5453.11, ppl=3.23, accuracy=73.597, wps=25287.6, ups=1.71, wpb=14818.9, bsz=498.6, num_updates=46200, lr=6.57952e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=58, gb_free=13.3, wall=31385
2023-08-22 02:28:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 02:29:34 | INFO | dev_st | epoch 044 | valid on 'dev_st' subset | loss 4.05 | trans_loss 5.164 | nll_loss 2.362 | w2v_ctc_loss 1.272 | task_loss 0 | contrastive_loss 0.267 | total 6138.43 | n_correct 4203 | ppl 5.14 | accuracy 68.47 | uer 16.073 | wer 17.81 | raw_wer 17.81 | bleu 27.86 | wps 1328.4 | wpb 6138.4 | bsz 201.1 | num_updates 46285 | best_bleu 28
2023-08-22 02:29:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 46285 updates
2023-08-22 02:29:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8603.pt
2023-08-22 02:29:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8603.pt
2023-08-22 02:29:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8603.pt (epoch 44 @ 46285 updates, score 27.86) (writing took 9.62564639095217 seconds)
2023-08-22 02:29:44 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-08-22 02:29:44 | INFO | train | epoch 044 | loss 1.822 | trans_loss 4.568 | nll_loss 1.68 | w2v_ctc_loss 0.484 | task_loss 0 | contrastive_loss 0.089 | total 7391.57 | n_correct 5451.81 | ppl 3.21 | accuracy 73.757 | wps 20368.2 | ups 1.38 | wpb 14783.1 | bsz 498.1 | num_updates 46285 | lr 6.57347e-05 | gnorm 0.39 | clip 0 | loss_scale 32 | train_wall 625 | gb_free 9.3 | wall 31483
2023-08-22 02:29:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 02:29:44 | INFO | fairseq.trainer | begin training epoch 45
2023-08-22 02:29:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 02:30:01 | INFO | train_inner | epoch 045:     15 / 1080 loss=1.818, trans_loss=4.569, nll_loss=1.682, w2v_ctc_loss=0.486, task_loss=0, contrastive_loss=0.044, total=7318.16, n_correct=5399.33, ppl=3.21, accuracy=73.78, wps=12840.7, ups=0.88, wpb=14636.3, bsz=491.2, num_updates=46300, lr=6.57241e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=57, gb_free=13.5, wall=31499
2023-08-22 02:30:59 | INFO | train_inner | epoch 045:    115 / 1080 loss=1.815, trans_loss=4.549, nll_loss=1.656, w2v_ctc_loss=0.474, task_loss=0, contrastive_loss=0.117, total=7421.01, n_correct=5501.61, ppl=3.15, accuracy=74.136, wps=25574.1, ups=1.72, wpb=14842, bsz=513.4, num_updates=46400, lr=6.56532e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=58, gb_free=13.7, wall=31557
2023-08-22 02:31:57 | INFO | train_inner | epoch 045:    215 / 1080 loss=1.82, trans_loss=4.561, nll_loss=1.671, w2v_ctc_loss=0.484, task_loss=0, contrastive_loss=0.099, total=7382.95, n_correct=5457.45, ppl=3.18, accuracy=73.92, wps=25252, ups=1.71, wpb=14765.9, bsz=497.1, num_updates=46500, lr=6.55826e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=58, gb_free=12.7, wall=31616
2023-08-22 02:32:56 | INFO | train_inner | epoch 045:    315 / 1080 loss=1.813, trans_loss=4.564, nll_loss=1.674, w2v_ctc_loss=0.481, task_loss=0, contrastive_loss=0.039, total=7350.31, n_correct=5431.53, ppl=3.19, accuracy=73.895, wps=24844, ups=1.69, wpb=14700.6, bsz=469.3, num_updates=46600, lr=6.55122e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=59, gb_free=14.2, wall=31675
2023-08-22 02:33:55 | INFO | train_inner | epoch 045:    415 / 1080 loss=1.816, trans_loss=4.552, nll_loss=1.661, w2v_ctc_loss=0.475, task_loss=0, contrastive_loss=0.121, total=7484.95, n_correct=5550.93, ppl=3.16, accuracy=74.161, wps=25413.3, ups=1.7, wpb=14969.9, bsz=524.3, num_updates=46700, lr=6.5442e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=12.8, wall=31734
2023-08-22 02:34:54 | INFO | train_inner | epoch 045:    515 / 1080 loss=1.822, trans_loss=4.567, nll_loss=1.68, w2v_ctc_loss=0.482, task_loss=0, contrastive_loss=0.097, total=7457.81, n_correct=5504.83, ppl=3.2, accuracy=73.813, wps=25542.9, ups=1.71, wpb=14915.6, bsz=513.3, num_updates=46800, lr=6.5372e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=58, gb_free=11.9, wall=31792
2023-08-22 02:35:52 | INFO | train_inner | epoch 045:    615 / 1080 loss=1.814, trans_loss=4.565, nll_loss=1.677, w2v_ctc_loss=0.483, task_loss=0, contrastive_loss=0.042, total=7391.24, n_correct=5457.79, ppl=3.2, accuracy=73.841, wps=25310.6, ups=1.71, wpb=14782.5, bsz=492, num_updates=46900, lr=6.53023e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=31850
2023-08-22 02:36:50 | INFO | train_inner | epoch 045:    715 / 1080 loss=1.824, trans_loss=4.569, nll_loss=1.683, w2v_ctc_loss=0.484, task_loss=0, contrastive_loss=0.116, total=7354.03, n_correct=5426.87, ppl=3.21, accuracy=73.795, wps=25214.1, ups=1.71, wpb=14708.1, bsz=490.1, num_updates=47000, lr=6.52328e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=58, gb_free=13.8, wall=31909
2023-08-22 02:37:49 | INFO | train_inner | epoch 045:    815 / 1080 loss=1.823, trans_loss=4.57, nll_loss=1.684, w2v_ctc_loss=0.482, task_loss=0, contrastive_loss=0.105, total=7500.63, n_correct=5530.05, ppl=3.21, accuracy=73.728, wps=25600, ups=1.71, wpb=15001.3, bsz=522.2, num_updates=47100, lr=6.51635e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=58, gb_free=12.9, wall=31967
2023-08-22 02:38:48 | INFO | train_inner | epoch 045:    915 / 1080 loss=1.823, trans_loss=4.569, nll_loss=1.682, w2v_ctc_loss=0.48, task_loss=0, contrastive_loss=0.108, total=7385.08, n_correct=5446.37, ppl=3.21, accuracy=73.748, wps=25071.3, ups=1.7, wpb=14770.2, bsz=492.6, num_updates=47200, lr=6.50945e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=58, gb_free=13.9, wall=32026
2023-08-22 02:39:46 | INFO | train_inner | epoch 045:   1015 / 1080 loss=1.818, trans_loss=4.566, nll_loss=1.679, w2v_ctc_loss=0.474, task_loss=0, contrastive_loss=0.104, total=7376.48, n_correct=5445.9, ppl=3.2, accuracy=73.828, wps=25306.8, ups=1.72, wpb=14753, bsz=498.6, num_updates=47300, lr=6.50256e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=58, gb_free=13.9, wall=32085
2023-08-22 02:40:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 02:41:02 | INFO | dev_st | epoch 045 | valid on 'dev_st' subset | loss 4.075 | trans_loss 5.167 | nll_loss 2.364 | w2v_ctc_loss 1.351 | task_loss 0 | contrastive_loss 0.266 | total 6138.43 | n_correct 4204.86 | ppl 5.15 | accuracy 68.501 | uer 16.123 | wer 17.717 | raw_wer 17.717 | bleu 27.92 | wps 1326.3 | wpb 6138.4 | bsz 201.1 | num_updates 47365 | best_bleu 28
2023-08-22 02:41:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 47365 updates
2023-08-22 02:41:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.9207.pt
2023-08-22 02:41:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.9207.pt
2023-08-22 02:41:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.9207.pt (epoch 45 @ 47365 updates, score 27.92) (writing took 6.734251581947319 seconds)
2023-08-22 02:41:10 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-08-22 02:41:10 | INFO | train | epoch 045 | loss 1.819 | trans_loss 4.564 | nll_loss 1.675 | w2v_ctc_loss 0.48 | task_loss 0 | contrastive_loss 0.093 | total 7392.68 | n_correct 5460.94 | ppl 3.19 | accuracy 73.87 | wps 23285.8 | ups 1.57 | wpb 14785.4 | bsz 498.6 | num_updates 47365 | lr 6.4981e-05 | gnorm 0.392 | clip 0 | loss_scale 32 | train_wall 626 | gb_free 13.4 | wall 32168
2023-08-22 02:41:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 02:41:10 | INFO | fairseq.trainer | begin training epoch 46
2023-08-22 02:41:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 02:41:38 | INFO | train_inner | epoch 046:     35 / 1080 loss=1.817, trans_loss=4.562, nll_loss=1.674, w2v_ctc_loss=0.484, task_loss=0, contrastive_loss=0.052, total=7259.13, n_correct=5356.97, ppl=3.19, accuracy=73.796, wps=12973.3, ups=0.89, wpb=14518.3, bsz=479.4, num_updates=47400, lr=6.4957e-05, gnorm=0.405, clip=0, loss_scale=32, train_wall=57, gb_free=13.8, wall=32197
2023-08-22 02:42:36 | INFO | train_inner | epoch 046:    135 / 1080 loss=1.813, trans_loss=4.545, nll_loss=1.651, w2v_ctc_loss=0.47, task_loss=0, contrastive_loss=0.135, total=7449.35, n_correct=5531.04, ppl=3.14, accuracy=74.249, wps=25610.9, ups=1.72, wpb=14898.7, bsz=511, num_updates=47500, lr=6.48886e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=58, gb_free=14.1, wall=32255
2023-08-22 02:43:35 | INFO | train_inner | epoch 046:    235 / 1080 loss=1.81, trans_loss=4.552, nll_loss=1.661, w2v_ctc_loss=0.469, task_loss=0, contrastive_loss=0.098, total=7431.73, n_correct=5512.1, ppl=3.16, accuracy=74.17, wps=25458.7, ups=1.71, wpb=14863.5, bsz=507.8, num_updates=47600, lr=6.48204e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=58, gb_free=13.2, wall=32313
2023-08-22 02:44:34 | INFO | train_inner | epoch 046:    335 / 1080 loss=1.821, trans_loss=4.56, nll_loss=1.669, w2v_ctc_loss=0.482, task_loss=0, contrastive_loss=0.105, total=7492.33, n_correct=5538.21, ppl=3.18, accuracy=73.918, wps=25222.6, ups=1.68, wpb=14984.7, bsz=508.6, num_updates=47700, lr=6.47524e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=59, gb_free=14, wall=32373
2023-08-22 02:45:33 | INFO | train_inner | epoch 046:    435 / 1080 loss=1.819, trans_loss=4.557, nll_loss=1.668, w2v_ctc_loss=0.479, task_loss=0, contrastive_loss=0.127, total=7391.86, n_correct=5469, ppl=3.18, accuracy=73.987, wps=25053.4, ups=1.69, wpb=14783.7, bsz=512.5, num_updates=47800, lr=6.46846e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=59, gb_free=14.1, wall=32432
2023-08-22 02:46:32 | INFO | train_inner | epoch 046:    535 / 1080 loss=1.816, trans_loss=4.563, nll_loss=1.674, w2v_ctc_loss=0.478, task_loss=0, contrastive_loss=0.074, total=7449.81, n_correct=5508.42, ppl=3.19, accuracy=73.94, wps=25381.1, ups=1.7, wpb=14899.6, bsz=505.8, num_updates=47900, lr=6.46171e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=58, gb_free=3.2, wall=32490
2023-08-22 02:47:30 | INFO | train_inner | epoch 046:    635 / 1080 loss=1.813, trans_loss=4.556, nll_loss=1.666, w2v_ctc_loss=0.477, task_loss=0, contrastive_loss=0.081, total=7465.17, n_correct=5520.94, ppl=3.17, accuracy=73.956, wps=25513.2, ups=1.71, wpb=14930.3, bsz=506.1, num_updates=48000, lr=6.45497e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=58, gb_free=13, wall=32549
2023-08-22 02:47:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 02:48:09 | INFO | dev_st | epoch 046 | valid on 'dev_st' subset | loss 4.078 | trans_loss 5.174 | nll_loss 2.374 | w2v_ctc_loss 1.341 | task_loss 0 | contrastive_loss 0.266 | total 6138.43 | n_correct 4200.29 | ppl 5.18 | accuracy 68.426 | uer 16.393 | wer 18.062 | raw_wer 18.062 | bleu 27.77 | wps 1329.3 | wpb 6138.4 | bsz 201.1 | num_updates 48000 | best_bleu 28
2023-08-22 02:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 48000 updates
2023-08-22 02:48:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_46_48000.pt
2023-08-22 02:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_46_48000.pt
2023-08-22 02:48:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_46_48000.pt (epoch 46 @ 48000 updates, score 27.77) (writing took 6.9784943599952385 seconds)
2023-08-22 02:49:15 | INFO | train_inner | epoch 046:    735 / 1080 loss=1.821, trans_loss=4.571, nll_loss=1.684, w2v_ctc_loss=0.478, task_loss=0, contrastive_loss=0.106, total=7324.41, n_correct=5398.93, ppl=3.21, accuracy=73.711, wps=14031.8, ups=0.96, wpb=14648.8, bsz=488.6, num_updates=48100, lr=6.44826e-05, gnorm=0.395, clip=0, loss_scale=64, train_wall=58, gb_free=14.1, wall=32653
2023-08-22 02:50:14 | INFO | train_inner | epoch 046:    835 / 1080 loss=1.814, trans_loss=4.564, nll_loss=1.675, w2v_ctc_loss=0.48, task_loss=0, contrastive_loss=0.054, total=7395.13, n_correct=5468.58, ppl=3.19, accuracy=73.948, wps=25092.7, ups=1.7, wpb=14790.3, bsz=492.5, num_updates=48200, lr=6.44157e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=58, gb_free=13.1, wall=32712
2023-08-22 02:51:12 | INFO | train_inner | epoch 046:    935 / 1080 loss=1.817, trans_loss=4.568, nll_loss=1.681, w2v_ctc_loss=0.479, task_loss=0, contrastive_loss=0.071, total=7243.15, n_correct=5342.14, ppl=3.21, accuracy=73.754, wps=24969.7, ups=1.72, wpb=14486.3, bsz=473.8, num_updates=48300, lr=6.43489e-05, gnorm=0.396, clip=0, loss_scale=64, train_wall=57, gb_free=14, wall=32770
2023-08-22 02:52:10 | INFO | train_inner | epoch 046:   1035 / 1080 loss=1.821, trans_loss=4.572, nll_loss=1.686, w2v_ctc_loss=0.48, task_loss=0, contrastive_loss=0.086, total=7353.92, n_correct=5422.42, ppl=3.22, accuracy=73.735, wps=25127.5, ups=1.71, wpb=14707.8, bsz=486.2, num_updates=48400, lr=6.42824e-05, gnorm=0.396, clip=0, loss_scale=64, train_wall=58, gb_free=12.9, wall=32829
2023-08-22 02:52:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 02:53:15 | INFO | dev_st | epoch 046 | valid on 'dev_st' subset | loss 4.074 | trans_loss 5.169 | nll_loss 2.367 | w2v_ctc_loss 1.342 | task_loss 0 | contrastive_loss 0.266 | total 6138.43 | n_correct 4202.29 | ppl 5.16 | accuracy 68.459 | uer 16.377 | wer 18.122 | raw_wer 18.122 | bleu 27.88 | wps 1333.4 | wpb 6138.4 | bsz 201.1 | num_updates 48445 | best_bleu 28
2023-08-22 02:53:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 48445 updates
2023-08-22 02:53:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8803.pt
2023-08-22 02:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8803.pt
2023-08-22 02:53:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8803.pt (epoch 46 @ 48445 updates, score 27.88) (writing took 6.342978736036457 seconds)
2023-08-22 02:53:21 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-08-22 02:53:21 | INFO | train | epoch 046 | loss 1.816 | trans_loss 4.56 | nll_loss 1.671 | w2v_ctc_loss 0.477 | task_loss 0 | contrastive_loss 0.092 | total 7392.68 | n_correct 5466.57 | ppl 3.18 | accuracy 73.946 | wps 21826.6 | ups 1.48 | wpb 14785.4 | bsz 498.6 | num_updates 48445 | lr 6.42526e-05 | gnorm 0.392 | clip 0 | loss_scale 64 | train_wall 627 | gb_free 13.5 | wall 32900
2023-08-22 02:53:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 02:53:22 | INFO | fairseq.trainer | begin training epoch 47
2023-08-22 02:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 02:54:01 | INFO | train_inner | epoch 047:     55 / 1080 loss=1.81, trans_loss=4.551, nll_loss=1.659, w2v_ctc_loss=0.475, task_loss=0, contrastive_loss=0.069, total=7325.78, n_correct=5435.7, ppl=3.16, accuracy=74.2, wps=13207.7, ups=0.9, wpb=14651.6, bsz=489.6, num_updates=48500, lr=6.42161e-05, gnorm=0.398, clip=0, loss_scale=64, train_wall=58, gb_free=12.6, wall=32940
2023-08-22 02:54:59 | INFO | train_inner | epoch 047:    155 / 1080 loss=1.81, trans_loss=4.549, nll_loss=1.656, w2v_ctc_loss=0.471, task_loss=0, contrastive_loss=0.119, total=7364.29, n_correct=5463.68, ppl=3.15, accuracy=74.192, wps=25204.5, ups=1.71, wpb=14728.6, bsz=477.6, num_updates=48600, lr=6.415e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=58, gb_free=12.5, wall=32998
2023-08-22 02:55:59 | INFO | train_inner | epoch 047:    255 / 1080 loss=1.81, trans_loss=4.55, nll_loss=1.657, w2v_ctc_loss=0.47, task_loss=0, contrastive_loss=0.104, total=7342.97, n_correct=5447.61, ppl=3.15, accuracy=74.188, wps=24786.4, ups=1.69, wpb=14685.9, bsz=482.4, num_updates=48700, lr=6.40841e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=59, gb_free=14.3, wall=33057
2023-08-22 02:56:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-22 02:56:58 | INFO | train_inner | epoch 047:    356 / 1080 loss=1.812, trans_loss=4.557, nll_loss=1.667, w2v_ctc_loss=0.482, task_loss=0, contrastive_loss=0.049, total=7340.92, n_correct=5434.83, ppl=3.17, accuracy=74.035, wps=24757.7, ups=1.69, wpb=14681.8, bsz=487.2, num_updates=48800, lr=6.40184e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=59, gb_free=11.5, wall=33117
2023-08-22 02:57:57 | INFO | train_inner | epoch 047:    456 / 1080 loss=1.81, trans_loss=4.553, nll_loss=1.661, w2v_ctc_loss=0.473, task_loss=0, contrastive_loss=0.074, total=7333.55, n_correct=5441.08, ppl=3.16, accuracy=74.194, wps=25009.9, ups=1.71, wpb=14667.1, bsz=494.1, num_updates=48900, lr=6.39529e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=58, gb_free=13.1, wall=33175
2023-08-22 02:58:55 | INFO | train_inner | epoch 047:    556 / 1080 loss=1.811, trans_loss=4.553, nll_loss=1.663, w2v_ctc_loss=0.477, task_loss=0, contrastive_loss=0.062, total=7454.55, n_correct=5526.08, ppl=3.17, accuracy=74.13, wps=25675.4, ups=1.72, wpb=14909.1, bsz=522.9, num_updates=49000, lr=6.38877e-05, gnorm=0.395, clip=0, loss_scale=32, train_wall=58, gb_free=12.8, wall=33233
2023-08-22 02:59:54 | INFO | train_inner | epoch 047:    656 / 1080 loss=1.818, trans_loss=4.562, nll_loss=1.673, w2v_ctc_loss=0.476, task_loss=0, contrastive_loss=0.09, total=7401.07, n_correct=5468.62, ppl=3.19, accuracy=73.89, wps=25131.6, ups=1.7, wpb=14802.1, bsz=502.6, num_updates=49100, lr=6.38226e-05, gnorm=0.399, clip=0, loss_scale=32, train_wall=58, gb_free=13.8, wall=33292
2023-08-22 03:00:52 | INFO | train_inner | epoch 047:    756 / 1080 loss=1.815, trans_loss=4.561, nll_loss=1.672, w2v_ctc_loss=0.48, task_loss=0, contrastive_loss=0.064, total=7432.93, n_correct=5490.49, ppl=3.19, accuracy=73.867, wps=25499.7, ups=1.72, wpb=14865.9, bsz=497.8, num_updates=49200, lr=6.37577e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=58, gb_free=13, wall=33351
2023-08-22 03:01:50 | INFO | train_inner | epoch 047:    856 / 1080 loss=1.815, trans_loss=4.563, nll_loss=1.675, w2v_ctc_loss=0.475, task_loss=0, contrastive_loss=0.078, total=7353.74, n_correct=5438.53, ppl=3.19, accuracy=73.956, wps=25211.8, ups=1.71, wpb=14707.5, bsz=492.3, num_updates=49300, lr=6.3693e-05, gnorm=0.391, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=33409
2023-08-22 03:02:49 | INFO | train_inner | epoch 047:    956 / 1080 loss=1.826, trans_loss=4.567, nll_loss=1.681, w2v_ctc_loss=0.475, task_loss=0, contrastive_loss=0.163, total=7467.34, n_correct=5511.86, ppl=3.21, accuracy=73.813, wps=25575.4, ups=1.71, wpb=14934.7, bsz=527.2, num_updates=49400, lr=6.36285e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=58, gb_free=8.1, wall=33467
2023-08-22 03:03:47 | INFO | train_inner | epoch 047:   1056 / 1080 loss=1.816, trans_loss=4.558, nll_loss=1.668, w2v_ctc_loss=0.475, task_loss=0, contrastive_loss=0.11, total=7420.58, n_correct=5489.77, ppl=3.18, accuracy=73.98, wps=25499.9, ups=1.72, wpb=14841.2, bsz=501.4, num_updates=49500, lr=6.35642e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=58, gb_free=14.3, wall=33525
2023-08-22 03:04:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 03:04:39 | INFO | dev_st | epoch 047 | valid on 'dev_st' subset | loss 4.093 | trans_loss 5.173 | nll_loss 2.372 | w2v_ctc_loss 1.395 | task_loss 0 | contrastive_loss 0.267 | total 6138.43 | n_correct 4202.29 | ppl 5.18 | accuracy 68.459 | uer 16.27 | wer 18.014 | raw_wer 18.014 | bleu 27.84 | wps 1340.2 | wpb 6138.4 | bsz 201.1 | num_updates 49524 | best_bleu 28
2023-08-22 03:04:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 49524 updates
2023-08-22 03:04:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8407.pt
2023-08-22 03:04:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8407.pt
2023-08-22 03:04:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_27.8407.pt (epoch 47 @ 49524 updates, score 27.84) (writing took 6.979133257991634 seconds)
2023-08-22 03:04:46 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-08-22 03:04:46 | INFO | train | epoch 047 | loss 1.813 | trans_loss 4.557 | nll_loss 1.666 | w2v_ctc_loss 0.475 | task_loss 0 | contrastive_loss 0.089 | total 7392.31 | n_correct 5474.08 | ppl 3.17 | accuracy 74.051 | wps 23287.5 | ups 1.58 | wpb 14784.6 | bsz 498.2 | num_updates 49524 | lr 6.35488e-05 | gnorm 0.393 | clip 0 | loss_scale 32 | train_wall 626 | gb_free 14.3 | wall 33585
2023-08-22 03:04:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-22 03:04:47 | INFO | fairseq.trainer | begin training epoch 48
2023-08-22 03:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-22 03:05:38 | INFO | train_inner | epoch 048:     76 / 1080 loss=1.815, trans_loss=4.545, nll_loss=1.652, w2v_ctc_loss=0.467, task_loss=0, contrastive_loss=0.166, total=7427.08, n_correct=5513.11, ppl=3.14, accuracy=74.23, wps=13339.1, ups=0.9, wpb=14854.2, bsz=514.9, num_updates=49600, lr=6.35001e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=57, gb_free=13.6, wall=33637
2023-08-22 03:06:37 | INFO | train_inner | epoch 048:    176 / 1080 loss=1.807, trans_loss=4.545, nll_loss=1.65, w2v_ctc_loss=0.464, task_loss=0, contrastive_loss=0.11, total=7418.45, n_correct=5519.28, ppl=3.14, accuracy=74.399, wps=25371, ups=1.71, wpb=14836.9, bsz=506.7, num_updates=49700, lr=6.34361e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=58, gb_free=13.3, wall=33695
2023-08-22 03:07:36 | INFO | train_inner | epoch 048:    276 / 1080 loss=1.813, trans_loss=4.554, nll_loss=1.663, w2v_ctc_loss=0.479, task_loss=0, contrastive_loss=0.078, total=7308.42, n_correct=5413.68, ppl=3.17, accuracy=74.075, wps=24883.8, ups=1.7, wpb=14616.8, bsz=472, num_updates=49800, lr=6.33724e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=58, gb_free=13.7, wall=33754
2023-08-22 03:08:34 | INFO | train_inner | epoch 048:    376 / 1080 loss=1.805, trans_loss=4.543, nll_loss=1.649, w2v_ctc_loss=0.464, task_loss=0, contrastive_loss=0.103, total=7430.65, n_correct=5527.27, ppl=3.14, accuracy=74.385, wps=25606.5, ups=1.72, wpb=14861.3, bsz=518.2, num_updates=49900, lr=6.33089e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=58, gb_free=13.5, wall=33812
2023-08-22 03:09:33 | INFO | train_inner | epoch 048:    476 / 1080 loss=1.814, trans_loss=4.555, nll_loss=1.664, w2v_ctc_loss=0.479, task_loss=0, contrastive_loss=0.078, total=7390.54, n_correct=5469.49, ppl=3.17, accuracy=74.007, wps=25031.2, ups=1.69, wpb=14781.1, bsz=491.5, num_updates=50000, lr=6.32456e-05, gnorm=0.397, clip=0, loss_scale=32, train_wall=59, gb_free=11.5, wall=33871
2023-08-22 03:09:33 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-22 03:09:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-22 03:10:11 | INFO | dev_st | epoch 048 | valid on 'dev_st' subset | loss 4.084 | trans_loss 5.171 | nll_loss 2.368 | w2v_ctc_loss 1.368 | task_loss 0 | contrastive_loss 0.267 | total 6138.43 | n_correct 4201.14 | ppl 5.16 | accuracy 68.44 | uer 16.147 | wer 17.869 | raw_wer 17.869 | bleu 27.76 | wps 1319.9 | wpb 6138.4 | bsz 201.1 | num_updates 50000 | best_bleu 28
2023-08-22 03:10:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 50000 updates
2023-08-22 03:10:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_48_50000.pt
2023-08-22 03:10:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_48_50000.pt
2023-08-22 03:10:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0821_baseline_alpha1.5_mt0.5/checkpoint_48_50000.pt (epoch 48 @ 50000 updates, score 27.76) (writing took 6.612128194072284 seconds)
2023-08-22 03:10:18 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-08-22 03:10:18 | INFO | train | epoch 048 | loss 1.811 | trans_loss 4.548 | nll_loss 1.655 | w2v_ctc_loss 0.471 | task_loss 0 | contrastive_loss 0.111 | total 7397.91 | n_correct 5490.77 | ppl 3.15 | accuracy 74.221 | wps 21211.3 | ups 1.43 | wpb 14795.8 | bsz 501.1 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.394 | clip 0 | loss_scale 32 | train_wall 276 | gb_free 11.5 | wall 33917
2023-08-22 03:10:18 | INFO | fairseq_cli.train | done training in 33841.1 seconds
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    raise EOFError
EOFError
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1744 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
