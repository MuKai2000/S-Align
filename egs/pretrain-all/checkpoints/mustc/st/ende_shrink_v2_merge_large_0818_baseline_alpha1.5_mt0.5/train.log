2023-08-17 20:04:54 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11141
2023-08-17 20:04:54 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11141
2023-08-17 20:04:54 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11141
2023-08-17 20:04:54 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11141
2023-08-17 20:04:54 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11141
2023-08-17 20:04:54 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11141
2023-08-17 20:04:54 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11141
2023-08-17 20:04:54 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11141
2023-08-17 20:04:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-17 20:04:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:04:55 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:04:55 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:04:55 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:04:55 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:04:55 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:04:55 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:04:55 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-17 20:04:55 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:04:55 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-17 20:04:58 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11141', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-17 20:04:58 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-17 20:04:58 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-17 20:04:58 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-17 20:04:58 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-17 20:04:58 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-17 20:05:03 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-17 20:05:03 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-17 20:05:03 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-17 20:05:04 | INFO | root | load pretrained hubert
2023-08-17 20:05:12 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-17 20:05:16 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 3 terminated with the following error:
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/encoders/sentencepiece_bpe.py", line 38, in __init__
    import sentencepiece as spm
ModuleNotFoundError: No module named 'sentencepiece'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 133, in main
    task.load_dataset(valid_sub_split, combine=False, epoch=1)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining_merge.py", line 287, in load_dataset
    bpe_tokenizer = self.build_bpe(self.args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/tasks/speech_to_text.py", line 317, in build_bpe
    return encoders.build_bpe(Namespace(**self.data_cfg.bpe_tokenizer))
  File "/mnt/zhangyh/fairseq-AT/fairseq/registry.py", line 61, in build_x
    return builder(cfg, *extra_args, **extra_kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/encoders/sentencepiece_bpe.py", line 43, in __init__
    raise ImportError(
ImportError: Please install sentencepiece with: pip install sentencepiece

2023-08-17 20:05:48 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15752
2023-08-17 20:05:49 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15752
2023-08-17 20:05:49 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15752
2023-08-17 20:05:49 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15752
2023-08-17 20:05:49 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15752
2023-08-17 20:05:49 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15752
2023-08-17 20:05:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-17 20:05:49 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15752
2023-08-17 20:05:49 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15752
2023-08-17 20:05:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-17 20:05:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-17 20:05:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:05:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-17 20:05:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-17 20:05:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:05:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:05:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:05:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:05:50 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:05:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-17 20:05:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-17 20:05:53 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15752', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-17 20:05:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-17 20:05:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-17 20:05:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-17 20:05:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-17 20:05:53 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-17 20:05:57 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-17 20:05:57 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-17 20:05:57 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-17 20:05:59 | INFO | root | load pretrained hubert
2023-08-17 20:06:06 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-17 20:06:10 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-17 20:06:17 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-17 20:06:17 | INFO | root | share the sematic adapter and textual encoder
2023-08-17 20:06:17 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-17 20:06:17 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-17 20:06:17 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-17 20:06:17 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-17 20:06:17 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-17 20:06:17 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-17 20:06:17 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-17 20:06:17 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 20:06:17 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 20:06:17 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-17 20:06:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-17 20:06:32 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-17 20:06:32 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-17 20:06:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-17 20:06:33 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:06:33 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:06:33 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:06:33 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:06:33 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:06:33 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:06:33 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:06:33 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:06:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-17 20:06:33 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-17 20:06:33 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-17 20:06:33 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-17 20:06:33 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-17 20:06:33 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-17 20:06:33 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-17 20:06:33 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 20:06:33 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 20:06:34 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-17 20:06:36 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 6 terminated with the following error:
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/audio/audio_utils.py", line 101, in get_waveform
    import soundfile as sf
ModuleNotFoundError: No module named 'soundfile'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 328, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 164, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/mnt/zhangyh/fairseq-AT/fairseq/checkpoint_utils.py", line 272, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/mnt/zhangyh/fairseq-AT/fairseq/trainer.py", line 725, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/iterators.py", line 372, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/iterators.py", line 372, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/round_robin_zip_datasets.py", line 56, in __getitem__
    [
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/round_robin_zip_datasets.py", line 57, in <listcomp>
    (key, dataset[self._map_index(key, index)])
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/concat_dataset.py", line 39, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/audio/triple_dataset.py", line 184, in __getitem__
    source= get_features_or_waveform(
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/audio/audio_utils.py", line 188, in get_features_or_waveform
    return get_waveform(
  File "/mnt/zhangyh/fairseq-AT/fairseq/data/audio/audio_utils.py", line 103, in get_waveform
    raise ImportError("Please install soundfile: pip install soundfile")
ImportError: Please install soundfile: pip install soundfile

2023-08-17 20:07:43 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18611
2023-08-17 20:07:43 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18611
2023-08-17 20:07:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18611
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:18611
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:18611
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18611
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:18611
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:18611
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-17 20:07:44 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-17 20:07:44 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-17 20:07:47 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18611', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=True, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-17 20:07:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-17 20:07:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-17 20:07:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-17 20:07:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-17 20:07:47 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-17 20:07:51 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-17 20:07:51 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-17 20:07:51 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-17 20:07:53 | INFO | root | load pretrained hubert
2023-08-17 20:08:00 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-17 20:08:04 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-17 20:08:10 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-17 20:08:10 | INFO | root | share the sematic adapter and textual encoder
2023-08-17 20:08:10 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-17 20:08:10 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-17 20:08:10 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-17 20:08:10 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-17 20:08:10 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-17 20:08:10 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-17 20:08:10 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-17 20:08:10 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 20:08:10 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 20:08:10 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-17 20:08:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-17 20:08:26 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-17 20:08:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-17 20:08:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-17 20:08:26 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:08:26 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:08:26 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:08:26 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:08:26 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:08:26 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:08:26 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:08:26 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-17 20:08:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-17 20:08:26 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-17 20:08:26 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-17 20:08:26 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-17 20:08:26 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-17 20:08:26 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-17 20:08:26 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-17 20:08:26 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 20:08:26 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-17 20:08:28 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-17 20:08:30 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-17 20:09:12 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-17 20:09:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 20:09:12 | INFO | fairseq.trainer | begin training epoch 1
2023-08-17 20:09:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 20:09:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-17 20:10:21 | INFO | train_inner | epoch 001:    101 / 1474 loss=20.542, trans_loss=5.873, nll_loss=4.681, w2v_ctc_loss=22.92, task_loss=0, contrastive_loss=3.242, total=4212.33, n_correct=124.33, ppl=25.65, accuracy=2.952, wps=21084.5, ups=1.68, wpb=12566.1, bsz=472.9, num_updates=100, lr=4.098e-06, gnorm=2.767, clip=0, loss_scale=64, train_wall=62, gb_free=18.8, wall=115
2023-08-17 20:10:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-17 20:11:21 | INFO | train_inner | epoch 001:    202 / 1474 loss=17.071, trans_loss=5.849, nll_loss=4.679, w2v_ctc_loss=17.597, task_loss=0, contrastive_loss=3.258, total=4127.88, n_correct=125, ppl=25.62, accuracy=3.028, wps=20689.4, ups=1.68, wpb=12326, bsz=463, num_updates=200, lr=8.096e-06, gnorm=7.175, clip=19, loss_scale=32, train_wall=59, gb_free=18.8, wall=174
2023-08-17 20:12:20 | INFO | train_inner | epoch 001:    302 / 1474 loss=10.141, trans_loss=5.787, nll_loss=4.642, w2v_ctc_loss=7.044, task_loss=0, contrastive_loss=3.221, total=4077.62, n_correct=133.05, ppl=24.97, accuracy=3.263, wps=20423.2, ups=1.68, wpb=12179.5, bsz=437.4, num_updates=300, lr=1.2094e-05, gnorm=1.739, clip=0, loss_scale=32, train_wall=59, gb_free=19.3, wall=234
2023-08-17 20:13:19 | INFO | train_inner | epoch 001:    402 / 1474 loss=9.599, trans_loss=5.753, nll_loss=4.627, w2v_ctc_loss=6.163, task_loss=0, contrastive_loss=3.271, total=4177.45, n_correct=125.99, ppl=24.7, accuracy=3.016, wps=21274.6, ups=1.71, wpb=12474.2, bsz=462.8, num_updates=400, lr=1.6092e-05, gnorm=0.64, clip=0, loss_scale=32, train_wall=58, gb_free=18.8, wall=293
2023-08-17 20:14:18 | INFO | train_inner | epoch 001:    502 / 1474 loss=9.439, trans_loss=5.814, nll_loss=4.706, w2v_ctc_loss=5.827, task_loss=0, contrastive_loss=3.329, total=4202.06, n_correct=104.82, ppl=26.1, accuracy=2.494, wps=21293.6, ups=1.7, wpb=12556.3, bsz=490.7, num_updates=500, lr=2.009e-05, gnorm=0.465, clip=0, loss_scale=32, train_wall=58, gb_free=14, wall=352
2023-08-17 20:15:17 | INFO | train_inner | epoch 001:    602 / 1474 loss=9.255, trans_loss=5.883, nll_loss=4.786, w2v_ctc_loss=5.572, task_loss=0, contrastive_loss=3.247, total=4124.52, n_correct=89.34, ppl=27.59, accuracy=2.166, wps=20983.5, ups=1.71, wpb=12301.1, bsz=471, num_updates=600, lr=2.4088e-05, gnorm=0.434, clip=0, loss_scale=32, train_wall=58, gb_free=18.8, wall=410
2023-08-17 20:16:15 | INFO | train_inner | epoch 001:    702 / 1474 loss=8.978, trans_loss=5.906, nll_loss=4.817, w2v_ctc_loss=5.198, task_loss=0, contrastive_loss=3.134, total=4147.01, n_correct=75.44, ppl=28.18, accuracy=1.819, wps=21232.6, ups=1.71, wpb=12381.3, bsz=455.2, num_updates=700, lr=2.8086e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=58, gb_free=19.2, wall=469
2023-08-17 20:17:13 | INFO | train_inner | epoch 001:    802 / 1474 loss=8.683, trans_loss=5.908, nll_loss=4.82, w2v_ctc_loss=4.764, task_loss=0, contrastive_loss=3.154, total=4121.11, n_correct=82.91, ppl=28.25, accuracy=2.012, wps=21049.9, ups=1.71, wpb=12298.3, bsz=463.4, num_updates=800, lr=3.2084e-05, gnorm=0.773, clip=0, loss_scale=32, train_wall=58, gb_free=19.1, wall=527
2023-08-17 20:18:13 | INFO | train_inner | epoch 001:    902 / 1474 loss=8.377, trans_loss=5.814, nll_loss=4.71, w2v_ctc_loss=4.484, task_loss=0, contrastive_loss=3.044, total=4167.98, n_correct=113.55, ppl=26.17, accuracy=2.724, wps=20798.4, ups=1.67, wpb=12446.6, bsz=457.5, num_updates=900, lr=3.6082e-05, gnorm=0.867, clip=0, loss_scale=32, train_wall=59, gb_free=19, wall=587
2023-08-17 20:19:12 | INFO | train_inner | epoch 001:   1002 / 1474 loss=8.111, trans_loss=5.718, nll_loss=4.593, w2v_ctc_loss=4.287, task_loss=0, contrastive_loss=2.987, total=4136.38, n_correct=116.28, ppl=24.13, accuracy=2.811, wps=20905.7, ups=1.69, wpb=12354.6, bsz=458.8, num_updates=1000, lr=4.008e-05, gnorm=1.094, clip=0, loss_scale=32, train_wall=59, gb_free=19.2, wall=646
2023-08-17 20:20:11 | INFO | train_inner | epoch 001:   1102 / 1474 loss=7.933, trans_loss=5.735, nll_loss=4.611, w2v_ctc_loss=4.151, task_loss=0, contrastive_loss=2.859, total=4148.31, n_correct=117.86, ppl=24.44, accuracy=2.841, wps=21030, ups=1.7, wpb=12371.7, bsz=453.4, num_updates=1100, lr=4.4078e-05, gnorm=1.14, clip=0, loss_scale=32, train_wall=58, gb_free=18.6, wall=705
2023-08-17 20:21:10 | INFO | train_inner | epoch 001:   1202 / 1474 loss=7.781, trans_loss=5.725, nll_loss=4.603, w2v_ctc_loss=4.044, task_loss=0, contrastive_loss=2.747, total=4134.43, n_correct=120.83, ppl=24.3, accuracy=2.923, wps=21133.6, ups=1.71, wpb=12350.3, bsz=438.4, num_updates=1200, lr=4.8076e-05, gnorm=1.327, clip=0, loss_scale=32, train_wall=58, gb_free=19.4, wall=763
2023-08-17 20:22:08 | INFO | train_inner | epoch 001:   1302 / 1474 loss=7.668, trans_loss=5.731, nll_loss=4.609, w2v_ctc_loss=3.927, task_loss=0, contrastive_loss=2.671, total=4055.44, n_correct=118.97, ppl=24.4, accuracy=2.934, wps=20757.8, ups=1.71, wpb=12107.5, bsz=442.9, num_updates=1300, lr=5.2074e-05, gnorm=1.323, clip=0, loss_scale=32, train_wall=58, gb_free=19, wall=822
2023-08-17 20:23:07 | INFO | train_inner | epoch 001:   1402 / 1474 loss=7.553, trans_loss=5.712, nll_loss=4.589, w2v_ctc_loss=3.82, task_loss=0, contrastive_loss=2.772, total=4125.61, n_correct=124.27, ppl=24.06, accuracy=3.012, wps=21048.4, ups=1.71, wpb=12328.1, bsz=452, num_updates=1400, lr=5.6072e-05, gnorm=1.384, clip=0, loss_scale=32, train_wall=58, gb_free=18.6, wall=880
2023-08-17 20:23:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-17 20:24:35 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 11.435 | trans_loss 12.204 | nll_loss 11.608 | w2v_ctc_loss 4.935 | task_loss 0 | contrastive_loss 3.785 | total 4003.4 | n_correct 142.7 | ppl 3121.62 | accuracy 3.564 | uer 59.966 | wer 60.986 | raw_wer 60.986 | bleu 0 | wps 1084.6 | wpb 4003.4 | bsz 141.8 | num_updates 1472
2023-08-17 20:24:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1472 updates
2023-08-17 20:24:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 20:24:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 20:24:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1472 updates, score 0.0) (writing took 3.648236665991135 seconds)
2023-08-17 20:24:38 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-17 20:24:38 | INFO | train | epoch 001 | loss 9.967 | trans_loss 5.797 | nll_loss 4.673 | w2v_ctc_loss 6.982 | task_loss 0 | contrastive_loss 3.052 | total 4139.23 | n_correct 112.988 | ppl 25.51 | accuracy 2.73 | wps 19845.5 | ups 1.61 | wpb 12357.5 | bsz 458.7 | num_updates 1472 | lr 5.89506e-05 | gnorm 1.543 | clip 1.3 | loss_scale 32 | train_wall 862 | gb_free 18.9 | wall 972
2023-08-17 20:24:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 20:24:38 | INFO | fairseq.trainer | begin training epoch 2
2023-08-17 20:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 20:25:02 | INFO | train_inner | epoch 002:     28 / 1474 loss=7.473, trans_loss=5.725, nll_loss=4.601, w2v_ctc_loss=3.712, task_loss=0, contrastive_loss=2.706, total=4164.65, n_correct=125.31, ppl=24.27, accuracy=3.009, wps=10782.8, ups=0.87, wpb=12421.6, bsz=471.6, num_updates=1500, lr=6.007e-05, gnorm=1.468, clip=0, loss_scale=32, train_wall=59, gb_free=18.6, wall=996
2023-08-17 20:26:00 | INFO | train_inner | epoch 002:    128 / 1474 loss=7.342, trans_loss=5.713, nll_loss=4.587, w2v_ctc_loss=3.652, task_loss=0, contrastive_loss=2.578, total=4153.14, n_correct=127.73, ppl=24.03, accuracy=3.076, wps=21147.1, ups=1.71, wpb=12386.1, bsz=450.6, num_updates=1600, lr=6.4068e-05, gnorm=1.289, clip=0, loss_scale=32, train_wall=58, gb_free=19.5, wall=1054
2023-08-17 20:26:58 | INFO | train_inner | epoch 002:    228 / 1474 loss=7.33, trans_loss=5.733, nll_loss=4.615, w2v_ctc_loss=3.541, task_loss=0, contrastive_loss=2.657, total=4192.9, n_correct=124.21, ppl=24.51, accuracy=2.962, wps=21639.9, ups=1.73, wpb=12523.7, bsz=493, num_updates=1700, lr=6.8066e-05, gnorm=1.361, clip=0, loss_scale=32, train_wall=57, gb_free=19, wall=1112
2023-08-17 20:27:57 | INFO | train_inner | epoch 002:    328 / 1474 loss=7.147, trans_loss=5.709, nll_loss=4.584, w2v_ctc_loss=3.503, task_loss=0, contrastive_loss=2.426, total=4132.45, n_correct=126.79, ppl=23.98, accuracy=3.068, wps=21100.7, ups=1.71, wpb=12335.7, bsz=443.2, num_updates=1800, lr=7.2064e-05, gnorm=1.346, clip=0, loss_scale=32, train_wall=58, gb_free=19.2, wall=1170
2023-08-17 20:28:55 | INFO | train_inner | epoch 002:    428 / 1474 loss=7.022, trans_loss=5.69, nll_loss=4.563, w2v_ctc_loss=3.46, task_loss=0, contrastive_loss=2.293, total=4037.61, n_correct=129.71, ppl=23.65, accuracy=3.213, wps=20712.1, ups=1.72, wpb=12068.2, bsz=415.8, num_updates=1900, lr=7.6062e-05, gnorm=1.234, clip=0, loss_scale=32, train_wall=58, gb_free=19.6, wall=1229
2023-08-17 20:29:54 | INFO | train_inner | epoch 002:    528 / 1474 loss=6.999, trans_loss=5.704, nll_loss=4.579, w2v_ctc_loss=3.363, task_loss=0, contrastive_loss=2.399, total=4183.4, n_correct=127.78, ppl=23.9, accuracy=3.054, wps=21295.3, ups=1.71, wpb=12481.5, bsz=470.3, num_updates=2000, lr=8.006e-05, gnorm=1.189, clip=0, loss_scale=32, train_wall=58, gb_free=18.7, wall=1287
2023-08-17 20:29:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 20:30:38 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.016 | trans_loss 12.06 | nll_loss 11.438 | w2v_ctc_loss 4.479 | task_loss 0 | contrastive_loss 3.331 | total 4003.4 | n_correct 159.8 | ppl 2774.44 | accuracy 3.992 | uer 55.565 | wer 56.105 | raw_wer 56.105 | bleu 0 | wps 1113.3 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-17 20:30:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-17 20:30:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-17 20:30:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-17 20:30:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 11.038642247003736 seconds)
2023-08-17 20:31:47 | INFO | train_inner | epoch 002:    628 / 1474 loss=6.883, trans_loss=5.705, nll_loss=4.581, w2v_ctc_loss=3.304, task_loss=0, contrastive_loss=2.227, total=4126.46, n_correct=126.14, ppl=23.94, accuracy=3.057, wps=10834.3, ups=0.88, wpb=12316, bsz=446.7, num_updates=2100, lr=8.4058e-05, gnorm=1.3, clip=0, loss_scale=32, train_wall=58, gb_free=19, wall=1401
2023-08-17 20:32:46 | INFO | train_inner | epoch 002:    728 / 1474 loss=6.83, trans_loss=5.686, nll_loss=4.558, w2v_ctc_loss=3.273, task_loss=0, contrastive_loss=2.299, total=4148.66, n_correct=126.27, ppl=23.55, accuracy=3.044, wps=21295.2, ups=1.72, wpb=12384.1, bsz=462.9, num_updates=2200, lr=8.8056e-05, gnorm=1.305, clip=0, loss_scale=64, train_wall=58, gb_free=19.4, wall=1459
2023-08-17 20:33:44 | INFO | train_inner | epoch 002:    828 / 1474 loss=6.747, trans_loss=5.672, nll_loss=4.543, w2v_ctc_loss=3.239, task_loss=0, contrastive_loss=2.251, total=4164.61, n_correct=130.98, ppl=23.31, accuracy=3.145, wps=21268, ups=1.71, wpb=12439.5, bsz=459.2, num_updates=2300, lr=9.2054e-05, gnorm=1.186, clip=0, loss_scale=64, train_wall=58, gb_free=19.3, wall=1518
2023-08-17 20:34:42 | INFO | train_inner | epoch 002:    928 / 1474 loss=6.647, trans_loss=5.658, nll_loss=4.526, w2v_ctc_loss=3.178, task_loss=0, contrastive_loss=2.207, total=4109.63, n_correct=131.27, ppl=23.03, accuracy=3.194, wps=21007.3, ups=1.71, wpb=12270.1, bsz=447.9, num_updates=2400, lr=9.6052e-05, gnorm=1.346, clip=0, loss_scale=64, train_wall=58, gb_free=18.7, wall=1576
2023-08-17 20:35:41 | INFO | train_inner | epoch 002:   1028 / 1474 loss=6.567, trans_loss=5.66, nll_loss=4.528, w2v_ctc_loss=3.139, task_loss=0, contrastive_loss=2.091, total=4101.19, n_correct=126.62, ppl=23.07, accuracy=3.087, wps=20964.2, ups=1.71, wpb=12245.2, bsz=454.5, num_updates=2500, lr=0.00010005, gnorm=1.163, clip=0, loss_scale=64, train_wall=58, gb_free=18.8, wall=1634
2023-08-17 20:36:41 | INFO | train_inner | epoch 002:   1128 / 1474 loss=6.558, trans_loss=5.665, nll_loss=4.535, w2v_ctc_loss=3.088, task_loss=0, contrastive_loss=2.236, total=4192.73, n_correct=129.68, ppl=23.18, accuracy=3.093, wps=20903.5, ups=1.67, wpb=12513.6, bsz=488.9, num_updates=2600, lr=0.000104048, gnorm=1.161, clip=0, loss_scale=64, train_wall=59, gb_free=18.6, wall=1694
2023-08-17 20:37:39 | INFO | train_inner | epoch 002:   1228 / 1474 loss=6.492, trans_loss=5.661, nll_loss=4.529, w2v_ctc_loss=3.072, task_loss=0, contrastive_loss=2.157, total=4219.96, n_correct=128.51, ppl=23.09, accuracy=3.045, wps=21466.5, ups=1.7, wpb=12591.9, bsz=491.8, num_updates=2700, lr=0.000108046, gnorm=1.174, clip=0, loss_scale=64, train_wall=58, gb_free=18.7, wall=1753
2023-08-17 20:38:37 | INFO | train_inner | epoch 002:   1328 / 1474 loss=6.371, trans_loss=5.651, nll_loss=4.521, w2v_ctc_loss=3.047, task_loss=0, contrastive_loss=1.895, total=4163.26, n_correct=131.2, ppl=22.95, accuracy=3.151, wps=21466.1, ups=1.73, wpb=12441.6, bsz=463, num_updates=2800, lr=0.000112044, gnorm=1.107, clip=0, loss_scale=64, train_wall=57, gb_free=18.7, wall=1811
2023-08-17 20:39:36 | INFO | train_inner | epoch 002:   1428 / 1474 loss=6.253, trans_loss=5.622, nll_loss=4.484, w2v_ctc_loss=3.031, task_loss=0, contrastive_loss=1.917, total=4049.42, n_correct=130.08, ppl=22.38, accuracy=3.212, wps=20727.8, ups=1.71, wpb=12091.6, bsz=437.6, num_updates=2900, lr=0.000116042, gnorm=1.29, clip=0, loss_scale=64, train_wall=58, gb_free=18.9, wall=1869
2023-08-17 20:40:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 20:40:45 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.403 | trans_loss 11.847 | nll_loss 11.186 | w2v_ctc_loss 3.988 | task_loss 0 | contrastive_loss 2.555 | total 4003.4 | n_correct 153.1 | ppl 2329.83 | accuracy 3.824 | uer 50.569 | wer 50.442 | raw_wer 50.442 | bleu 0 | wps 1160.9 | wpb 4003.4 | bsz 141.8 | num_updates 2946 | best_bleu 0
2023-08-17 20:40:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2946 updates
2023-08-17 20:40:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 20:40:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 20:40:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2946 updates, score 0.0) (writing took 10.699859499989543 seconds)
2023-08-17 20:40:57 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-17 20:40:57 | INFO | train | epoch 002 | loss 6.795 | trans_loss 5.68 | nll_loss 4.552 | w2v_ctc_loss 3.277 | task_loss 0 | contrastive_loss 2.257 | total 4138.65 | n_correct 128.351 | ppl 23.45 | accuracy 3.101 | wps 18617 | ups 1.51 | wpb 12355.8 | bsz 458.5 | num_updates 2946 | lr 0.000117881 | gnorm 1.25 | clip 0 | loss_scale 64 | train_wall 853 | gb_free 19 | wall 1950
2023-08-17 20:40:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 20:40:57 | INFO | fairseq.trainer | begin training epoch 3
2023-08-17 20:40:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 20:41:35 | INFO | train_inner | epoch 003:     54 / 1474 loss=6.185, trans_loss=5.624, nll_loss=4.487, w2v_ctc_loss=2.985, task_loss=0, contrastive_loss=1.804, total=4067, n_correct=130.56, ppl=22.42, accuracy=3.21, wps=10199.4, ups=0.84, wpb=12142, bsz=441.4, num_updates=3000, lr=0.00012004, gnorm=1.156, clip=0, loss_scale=64, train_wall=58, gb_free=18.9, wall=1988
2023-08-17 20:41:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-17 20:41:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-17 20:41:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-17 20:41:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-17 20:41:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-17 20:41:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-17 20:42:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-08-17 20:42:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-08-17 20:42:56 | INFO | train_inner | epoch 003:    162 / 1474 loss=5.352, trans_loss=4.531, nll_loss=3.045, w2v_ctc_loss=3.049, task_loss=0, contrastive_loss=1.689, total=4165.02, n_correct=907.73, ppl=8.25, accuracy=21.794, wps=15242.1, ups=1.23, wpb=12439.2, bsz=466.7, num_updates=3100, lr=0.000124038, gnorm=9.883, clip=33, loss_scale=0.25, train_wall=81, gb_free=16.9, wall=2070
2023-08-17 20:44:13 | INFO | train_inner | epoch 003:    262 / 1474 loss=4.6, trans_loss=4.191, nll_loss=2.602, w2v_ctc_loss=2.76, task_loss=0, contrastive_loss=1.361, total=4149.55, n_correct=1268.78, ppl=6.07, accuracy=30.576, wps=16167.2, ups=1.3, wpb=12397.1, bsz=463.2, num_updates=3200, lr=0.000128036, gnorm=4.869, clip=10, loss_scale=0.25, train_wall=76, gb_free=16.6, wall=2147
2023-08-17 20:45:28 | INFO | train_inner | epoch 003:    362 / 1474 loss=4.429, trans_loss=4.17, nll_loss=2.576, w2v_ctc_loss=2.667, task_loss=0, contrastive_loss=1.338, total=4175.96, n_correct=1319.79, ppl=5.96, accuracy=31.604, wps=16587.6, ups=1.33, wpb=12461.5, bsz=474.2, num_updates=3300, lr=0.000132034, gnorm=4.378, clip=5, loss_scale=0.25, train_wall=74, gb_free=16.6, wall=2222
2023-08-17 20:46:44 | INFO | train_inner | epoch 003:    462 / 1474 loss=4.157, trans_loss=4.14, nll_loss=2.537, w2v_ctc_loss=2.553, task_loss=0, contrastive_loss=0.999, total=4187.52, n_correct=1366.1, ppl=5.81, accuracy=32.623, wps=16565.8, ups=1.33, wpb=12498.8, bsz=463.6, num_updates=3400, lr=0.000136032, gnorm=3.291, clip=1, loss_scale=0.25, train_wall=75, gb_free=14.5, wall=2297
2023-08-17 20:47:59 | INFO | train_inner | epoch 003:    562 / 1474 loss=3.952, trans_loss=4.129, nll_loss=2.527, w2v_ctc_loss=2.427, task_loss=0, contrastive_loss=0.91, total=4083.21, n_correct=1344.54, ppl=5.76, accuracy=32.929, wps=16179.6, ups=1.33, wpb=12199, bsz=437.9, num_updates=3500, lr=0.00014003, gnorm=2.411, clip=1, loss_scale=0.25, train_wall=75, gb_free=15.8, wall=2373
2023-08-17 20:49:15 | INFO | train_inner | epoch 003:    662 / 1474 loss=3.859, trans_loss=4.121, nll_loss=2.511, w2v_ctc_loss=2.336, task_loss=0, contrastive_loss=0.957, total=4232.39, n_correct=1426.93, ppl=5.7, accuracy=33.715, wps=16510.7, ups=1.31, wpb=12618.9, bsz=487.6, num_updates=3600, lr=0.000144028, gnorm=3.123, clip=2, loss_scale=0.25, train_wall=76, gb_free=16.3, wall=2449
2023-08-17 20:50:31 | INFO | train_inner | epoch 003:    762 / 1474 loss=3.709, trans_loss=4.101, nll_loss=2.49, w2v_ctc_loss=2.286, task_loss=0, contrastive_loss=0.667, total=4155.31, n_correct=1415.78, ppl=5.62, accuracy=34.072, wps=16398.5, ups=1.32, wpb=12412.9, bsz=465.8, num_updates=3700, lr=0.000148026, gnorm=2.417, clip=2, loss_scale=0.25, train_wall=75, gb_free=16.3, wall=2525
2023-08-17 20:51:46 | INFO | train_inner | epoch 003:    862 / 1474 loss=3.6, trans_loss=4.102, nll_loss=2.49, w2v_ctc_loss=2.217, task_loss=0, contrastive_loss=0.592, total=4170.95, n_correct=1432.38, ppl=5.62, accuracy=34.342, wps=16563.2, ups=1.33, wpb=12453.7, bsz=458.1, num_updates=3800, lr=0.000152024, gnorm=1.915, clip=1, loss_scale=0.25, train_wall=75, gb_free=17.3, wall=2600
2023-08-17 20:53:02 | INFO | train_inner | epoch 003:    962 / 1474 loss=3.538, trans_loss=4.09, nll_loss=2.472, w2v_ctc_loss=2.165, task_loss=0, contrastive_loss=0.6, total=4174.19, n_correct=1457.49, ppl=5.55, accuracy=34.917, wps=16564.5, ups=1.33, wpb=12449.2, bsz=475.7, num_updates=3900, lr=0.000156022, gnorm=1.975, clip=2, loss_scale=0.25, train_wall=74, gb_free=13.7, wall=2675
2023-08-17 20:54:16 | INFO | train_inner | epoch 003:   1062 / 1474 loss=3.45, trans_loss=4.084, nll_loss=2.468, w2v_ctc_loss=2.13, task_loss=0, contrastive_loss=0.495, total=4049.41, n_correct=1409.12, ppl=5.53, accuracy=34.798, wps=16287, ups=1.35, wpb=12096, bsz=436.3, num_updates=4000, lr=0.00016002, gnorm=1.771, clip=0, loss_scale=0.25, train_wall=74, gb_free=16.4, wall=2749
2023-08-17 20:54:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 20:54:52 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 6.046 | trans_loss 7.253 | nll_loss 5.137 | w2v_ctc_loss 2.619 | task_loss 0 | contrastive_loss 0.683 | total 4003.4 | n_correct 1451.2 | ppl 35.19 | accuracy 36.249 | uer 35.089 | wer 36.091 | raw_wer 36.091 | bleu 0.48 | wps 1370.8 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 0.48
2023-08-17 20:54:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-17 20:54:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-17 20:54:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-17 20:55:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 0.48) (writing took 12.133131290989695 seconds)
2023-08-17 20:56:18 | INFO | train_inner | epoch 003:   1162 / 1474 loss=3.383, trans_loss=4.082, nll_loss=2.463, w2v_ctc_loss=2.067, task_loss=0, contrastive_loss=0.464, total=4044.1, n_correct=1424.18, ppl=5.51, accuracy=35.216, wps=9846.2, ups=0.82, wpb=12070.2, bsz=433.6, num_updates=4100, lr=0.000164018, gnorm=1.695, clip=0, loss_scale=0.25, train_wall=74, gb_free=15.6, wall=2872
2023-08-17 20:57:34 | INFO | train_inner | epoch 003:   1262 / 1474 loss=3.331, trans_loss=4.072, nll_loss=2.452, w2v_ctc_loss=2.028, task_loss=0, contrastive_loss=0.433, total=4065.1, n_correct=1437.15, ppl=5.47, accuracy=35.353, wps=16055.9, ups=1.32, wpb=12140.5, bsz=432.3, num_updates=4200, lr=0.000168016, gnorm=1.885, clip=1, loss_scale=0.25, train_wall=75, gb_free=17, wall=2948
2023-08-17 20:58:49 | INFO | train_inner | epoch 003:   1362 / 1474 loss=3.293, trans_loss=4.06, nll_loss=2.435, w2v_ctc_loss=1.967, task_loss=0, contrastive_loss=0.522, total=4132.35, n_correct=1483.78, ppl=5.41, accuracy=35.906, wps=16366.9, ups=1.33, wpb=12335.6, bsz=462.1, num_updates=4300, lr=0.000172014, gnorm=1.564, clip=0, loss_scale=0.25, train_wall=75, gb_free=17.5, wall=3023
2023-08-17 21:00:04 | INFO | train_inner | epoch 003:   1462 / 1474 loss=3.247, trans_loss=4.051, nll_loss=2.425, w2v_ctc_loss=1.936, task_loss=0, contrastive_loss=0.48, total=4206.88, n_correct=1526.48, ppl=5.37, accuracy=36.285, wps=16735.3, ups=1.33, wpb=12566, bsz=476, num_updates=4400, lr=0.000176012, gnorm=1.466, clip=0, loss_scale=0.25, train_wall=74, gb_free=15, wall=3098
2023-08-17 21:00:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 21:00:48 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.834 | trans_loss 7.143 | nll_loss 4.995 | w2v_ctc_loss 2.309 | task_loss 0 | contrastive_loss 0.556 | total 4003.4 | n_correct 1516.1 | ppl 31.9 | accuracy 37.87 | uer 32.957 | wer 34.011 | raw_wer 34.011 | bleu 0.89 | wps 1466.5 | wpb 4003.4 | bsz 141.8 | num_updates 4412 | best_bleu 0.89
2023-08-17 21:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4412 updates
2023-08-17 21:00:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 21:00:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 21:01:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 3 @ 4412 updates, score 0.89) (writing took 11.843279147986323 seconds)
2023-08-17 21:01:00 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-17 21:01:00 | INFO | train | epoch 003 | loss 3.933 | trans_loss 4.192 | nll_loss 2.607 | w2v_ctc_loss 2.349 | task_loss 0 | contrastive_loss 0.862 | total 4140.16 | n_correct 1327.42 | ppl 6.09 | accuracy 32.062 | wps 15059.6 | ups 1.22 | wpb 12360.5 | bsz 459 | num_updates 4412 | lr 0.000176492 | gnorm 2.963 | clip 4 | loss_scale 0.25 | train_wall 1092 | gb_free 16.4 | wall 3153
2023-08-17 21:01:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 21:01:00 | INFO | fairseq.trainer | begin training epoch 4
2023-08-17 21:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 21:02:12 | INFO | train_inner | epoch 004:     88 / 1474 loss=3.147, trans_loss=4.037, nll_loss=2.403, w2v_ctc_loss=1.889, task_loss=0, contrastive_loss=0.32, total=4082.27, n_correct=1495.53, ppl=5.29, accuracy=36.635, wps=9566.5, ups=0.79, wpb=12182.1, bsz=434.2, num_updates=4500, lr=0.00018001, gnorm=1.492, clip=0, loss_scale=0.25, train_wall=73, gb_free=17.7, wall=3225
2023-08-17 21:03:26 | INFO | train_inner | epoch 004:    188 / 1474 loss=3.116, trans_loss=4.014, nll_loss=2.376, w2v_ctc_loss=1.853, task_loss=0, contrastive_loss=0.345, total=4184.92, n_correct=1562.77, ppl=5.19, accuracy=37.343, wps=16747, ups=1.34, wpb=12496.9, bsz=470.3, num_updates=4600, lr=0.000184008, gnorm=1.355, clip=0, loss_scale=0.25, train_wall=74, gb_free=13.2, wall=3300
2023-08-17 21:04:42 | INFO | train_inner | epoch 004:    288 / 1474 loss=3.154, trans_loss=4.018, nll_loss=2.382, w2v_ctc_loss=1.873, task_loss=0, contrastive_loss=0.471, total=4150, n_correct=1545.2, ppl=5.21, accuracy=37.234, wps=16381.5, ups=1.32, wpb=12397.9, bsz=465.2, num_updates=4700, lr=0.000188006, gnorm=1.862, clip=2, loss_scale=0.25, train_wall=75, gb_free=16.8, wall=3376
2023-08-17 21:05:57 | INFO | train_inner | epoch 004:    388 / 1474 loss=3.081, trans_loss=4.014, nll_loss=2.374, w2v_ctc_loss=1.843, task_loss=0, contrastive_loss=0.295, total=4114.32, n_correct=1544.92, ppl=5.18, accuracy=37.55, wps=16479.7, ups=1.34, wpb=12277.1, bsz=440, num_updates=4800, lr=0.000192004, gnorm=1.427, clip=0, loss_scale=0.25, train_wall=74, gb_free=12.2, wall=3450
2023-08-17 21:07:12 | INFO | train_inner | epoch 004:    488 / 1474 loss=3.142, trans_loss=3.996, nll_loss=2.351, w2v_ctc_loss=1.796, task_loss=0, contrastive_loss=0.709, total=4239.74, n_correct=1621.59, ppl=5.1, accuracy=38.247, wps=16746.1, ups=1.32, wpb=12652.2, bsz=506.4, num_updates=4900, lr=0.000196002, gnorm=1.474, clip=0, loss_scale=0.25, train_wall=75, gb_free=17, wall=3526
2023-08-17 21:08:28 | INFO | train_inner | epoch 004:    588 / 1474 loss=3.06, trans_loss=3.979, nll_loss=2.329, w2v_ctc_loss=1.815, task_loss=0, contrastive_loss=0.358, total=4219.26, n_correct=1637.11, ppl=5.02, accuracy=38.801, wps=16708.6, ups=1.33, wpb=12596.5, bsz=483.8, num_updates=5000, lr=0.0002, gnorm=1.684, clip=1, loss_scale=0.25, train_wall=75, gb_free=16, wall=3601
mt_weight tensor(0.5000)
asr_weight tensor(0.4093, device='cuda:0')
2023-08-17 21:09:44 | INFO | train_inner | epoch 004:    688 / 1474 loss=3.089, trans_loss=3.99, nll_loss=2.339, w2v_ctc_loss=1.855, task_loss=0, contrastive_loss=0.42, total=4171.93, n_correct=1617.32, ppl=5.06, accuracy=38.767, wps=16268.5, ups=1.31, wpb=12436.9, bsz=453.3, num_updates=5100, lr=0.00019803, gnorm=1.472, clip=1, loss_scale=0.25, train_wall=76, gb_free=15.6, wall=3678
2023-08-17 21:10:59 | INFO | train_inner | epoch 004:    788 / 1474 loss=3.069, trans_loss=3.976, nll_loss=2.325, w2v_ctc_loss=1.877, task_loss=0, contrastive_loss=0.301, total=4029.4, n_correct=1572.29, ppl=5.01, accuracy=39.02, wps=15966, ups=1.33, wpb=12032.2, bsz=423.7, num_updates=5200, lr=0.000196116, gnorm=1.225, clip=0, loss_scale=0.5, train_wall=75, gb_free=16.3, wall=3753
2023-08-17 21:12:15 | INFO | train_inner | epoch 004:    888 / 1474 loss=3.143, trans_loss=3.961, nll_loss=2.306, w2v_ctc_loss=1.911, task_loss=0, contrastive_loss=0.491, total=4175.28, n_correct=1647.31, ppl=4.95, accuracy=39.454, wps=16419.7, ups=1.32, wpb=12468.9, bsz=463.7, num_updates=5300, lr=0.000194257, gnorm=1.682, clip=0, loss_scale=0.5, train_wall=75, gb_free=15.6, wall=3829
2023-08-17 21:13:31 | INFO | train_inner | epoch 004:    988 / 1474 loss=3.097, trans_loss=3.951, nll_loss=2.293, w2v_ctc_loss=1.905, task_loss=0, contrastive_loss=0.367, total=4132.46, n_correct=1654.63, ppl=4.9, accuracy=40.04, wps=16406.9, ups=1.33, wpb=12343.2, bsz=455.3, num_updates=5400, lr=0.00019245, gnorm=1.394, clip=1, loss_scale=0.5, train_wall=75, gb_free=10.9, wall=3904
2023-08-17 21:14:45 | INFO | train_inner | epoch 004:   1088 / 1474 loss=3.097, trans_loss=3.955, nll_loss=2.297, w2v_ctc_loss=1.918, task_loss=0, contrastive_loss=0.347, total=4073.98, n_correct=1631.66, ppl=4.92, accuracy=40.051, wps=16257, ups=1.34, wpb=12161.7, bsz=437.9, num_updates=5500, lr=0.000190693, gnorm=1.723, clip=1, loss_scale=0.5, train_wall=74, gb_free=15.9, wall=3979
2023-08-17 21:16:00 | INFO | train_inner | epoch 004:   1188 / 1474 loss=3.181, trans_loss=3.947, nll_loss=2.288, w2v_ctc_loss=1.978, task_loss=0, contrastive_loss=0.473, total=4172.46, n_correct=1686.21, ppl=4.88, accuracy=40.413, wps=16675, ups=1.34, wpb=12459.8, bsz=487.1, num_updates=5600, lr=0.000188982, gnorm=2.091, clip=1, loss_scale=0.5, train_wall=74, gb_free=11.5, wall=4054
2023-08-17 21:17:15 | INFO | train_inner | epoch 004:   1288 / 1474 loss=3.199, trans_loss=3.936, nll_loss=2.274, w2v_ctc_loss=2.015, task_loss=0, contrastive_loss=0.451, total=4140.32, n_correct=1686.12, ppl=4.84, accuracy=40.724, wps=16467.2, ups=1.33, wpb=12365.2, bsz=467.7, num_updates=5700, lr=0.000187317, gnorm=2.134, clip=3, loss_scale=0.5, train_wall=75, gb_free=17, wall=4129
2023-08-17 21:18:31 | INFO | train_inner | epoch 004:   1388 / 1474 loss=3.069, trans_loss=3.912, nll_loss=2.243, w2v_ctc_loss=1.946, task_loss=0, contrastive_loss=0.283, total=4092.66, n_correct=1701.7, ppl=4.73, accuracy=41.579, wps=16226.3, ups=1.33, wpb=12224.9, bsz=436.3, num_updates=5800, lr=0.000185695, gnorm=1.64, clip=0, loss_scale=0.5, train_wall=75, gb_free=16.4, wall=4204
2023-08-17 21:19:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4093, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4093, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4093, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4093, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4093, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4093, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4093, device='cuda:7')
2023-08-17 21:20:08 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.372 | trans_loss 6.546 | nll_loss 4.211 | w2v_ctc_loss 2.236 | task_loss 0 | contrastive_loss 0.49 | total 4003.4 | n_correct 1834.1 | ppl 18.52 | accuracy 45.814 | uer 30.667 | wer 32.277 | raw_wer 32.277 | bleu 5.46 | wps 1490.1 | wpb 4003.4 | bsz 141.8 | num_updates 5886 | best_bleu 5.46
2023-08-17 21:20:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5886 updates
2023-08-17 21:20:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 21:20:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 21:20:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 4 @ 5886 updates, score 5.46) (writing took 10.547178154985886 seconds)
2023-08-17 21:20:19 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-17 21:20:19 | INFO | train | epoch 004 | loss 3.113 | trans_loss 3.973 | nll_loss 2.321 | w2v_ctc_loss 1.891 | task_loss 0 | contrastive_loss 0.403 | total 4138.65 | n_correct 1621.6 | ppl 5 | accuracy 39.182 | wps 15708.5 | ups 1.27 | wpb 12355.8 | bsz 458.5 | num_updates 5886 | lr 0.000184334 | gnorm 1.611 | clip 0.7 | loss_scale 0.5 | train_wall 1098 | gb_free 14.8 | wall 4313
2023-08-17 21:20:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 21:20:19 | INFO | fairseq.trainer | begin training epoch 5
2023-08-17 21:20:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 21:20:36 | INFO | train_inner | epoch 005:     14 / 1474 loss=3.044, trans_loss=3.901, nll_loss=2.226, w2v_ctc_loss=1.889, task_loss=0, contrastive_loss=0.348, total=4073.09, n_correct=1718.22, ppl=4.68, accuracy=42.185, wps=9663.4, ups=0.79, wpb=12158.4, bsz=451.4, num_updates=5900, lr=0.000184115, gnorm=1.782, clip=2, loss_scale=0.5, train_wall=73, gb_free=17.2, wall=4330
2023-08-17 21:21:51 | INFO | train_inner | epoch 005:    114 / 1474 loss=3.011, trans_loss=3.863, nll_loss=2.179, w2v_ctc_loss=1.867, task_loss=0, contrastive_loss=0.325, total=4233.69, n_correct=1831.04, ppl=4.53, accuracy=43.249, wps=17000.5, ups=1.34, wpb=12643.8, bsz=488.6, num_updates=6000, lr=0.000182574, gnorm=1.612, clip=1, loss_scale=0.5, train_wall=74, gb_free=15.7, wall=4404
2023-08-17 21:21:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 21:22:26 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.325 | trans_loss 6.51 | nll_loss 4.158 | w2v_ctc_loss 2.184 | task_loss 0 | contrastive_loss 0.47 | total 4003.4 | n_correct 1862.1 | ppl 17.85 | accuracy 46.513 | uer 30.927 | wer 32.214 | raw_wer 32.214 | bleu 5.93 | wps 1447.1 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 5.93
2023-08-17 21:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-17 21:22:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-17 21:22:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-17 21:22:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 5.93) (writing took 25.424842492997414 seconds)
2023-08-17 21:24:06 | INFO | train_inner | epoch 005:    214 / 1474 loss=3.019, trans_loss=3.858, nll_loss=2.169, w2v_ctc_loss=1.85, task_loss=0, contrastive_loss=0.527, total=4185.02, n_correct=1829.99, ppl=4.5, accuracy=43.727, wps=9257.9, ups=0.74, wpb=12486.5, bsz=485.7, num_updates=6100, lr=0.000181071, gnorm=1.44, clip=2, loss_scale=0.5, train_wall=74, gb_free=16.6, wall=4539
2023-08-17 21:25:20 | INFO | train_inner | epoch 005:    314 / 1474 loss=2.921, trans_loss=3.825, nll_loss=2.131, w2v_ctc_loss=1.81, task_loss=0, contrastive_loss=0.359, total=4097.42, n_correct=1824.38, ppl=4.38, accuracy=44.525, wps=16479.9, ups=1.35, wpb=12251.6, bsz=448, num_updates=6200, lr=0.000179605, gnorm=1.301, clip=0, loss_scale=0.5, train_wall=74, gb_free=14.3, wall=4614
2023-08-17 21:26:36 | INFO | train_inner | epoch 005:    414 / 1474 loss=2.934, trans_loss=3.812, nll_loss=2.113, w2v_ctc_loss=1.797, task_loss=0, contrastive_loss=0.443, total=4135.49, n_correct=1867.35, ppl=4.33, accuracy=45.154, wps=16280.3, ups=1.32, wpb=12359.1, bsz=465.9, num_updates=6300, lr=0.000178174, gnorm=1.285, clip=0, loss_scale=0.5, train_wall=75, gb_free=17.3, wall=4690
2023-08-17 21:27:51 | INFO | train_inner | epoch 005:    514 / 1474 loss=2.936, trans_loss=3.819, nll_loss=2.119, w2v_ctc_loss=1.831, task_loss=0, contrastive_loss=0.384, total=4035.21, n_correct=1815.67, ppl=4.35, accuracy=44.996, wps=16136.4, ups=1.34, wpb=12051.5, bsz=427.7, num_updates=6400, lr=0.000176777, gnorm=1.575, clip=1, loss_scale=0.5, train_wall=74, gb_free=17, wall=4764
2023-08-17 21:29:05 | INFO | train_inner | epoch 005:    614 / 1474 loss=2.879, trans_loss=3.802, nll_loss=2.095, w2v_ctc_loss=1.799, task_loss=0, contrastive_loss=0.286, total=4117.64, n_correct=1896.39, ppl=4.27, accuracy=46.055, wps=16449.4, ups=1.34, wpb=12284.8, bsz=443.7, num_updates=6500, lr=0.000175412, gnorm=1.238, clip=1, loss_scale=0.5, train_wall=74, gb_free=17.1, wall=4839
2023-08-17 21:30:20 | INFO | train_inner | epoch 005:    714 / 1474 loss=2.877, trans_loss=3.782, nll_loss=2.071, w2v_ctc_loss=1.775, task_loss=0, contrastive_loss=0.388, total=4153.99, n_correct=1949.08, ppl=4.2, accuracy=46.921, wps=16549.8, ups=1.33, wpb=12400.6, bsz=476.1, num_updates=6600, lr=0.000174078, gnorm=1.198, clip=1, loss_scale=0.5, train_wall=74, gb_free=17.5, wall=4914
2023-08-17 21:31:35 | INFO | train_inner | epoch 005:    814 / 1474 loss=2.823, trans_loss=3.762, nll_loss=2.045, w2v_ctc_loss=1.748, task_loss=0, contrastive_loss=0.312, total=4131.08, n_correct=1962.14, ppl=4.13, accuracy=47.497, wps=16396.4, ups=1.33, wpb=12332.3, bsz=455.1, num_updates=6700, lr=0.000172774, gnorm=0.996, clip=0, loss_scale=0.5, train_wall=75, gb_free=17.6, wall=4989
2023-08-17 21:32:51 | INFO | train_inner | epoch 005:    914 / 1474 loss=2.77, trans_loss=3.753, nll_loss=2.033, w2v_ctc_loss=1.714, task_loss=0, contrastive_loss=0.258, total=4109.29, n_correct=1971.34, ppl=4.09, accuracy=47.973, wps=16219.7, ups=1.32, wpb=12268.1, bsz=445.5, num_updates=6800, lr=0.000171499, gnorm=0.977, clip=0, loss_scale=0.5, train_wall=75, gb_free=12.1, wall=5065
2023-08-17 21:34:06 | INFO | train_inner | epoch 005:   1014 / 1474 loss=2.779, trans_loss=3.744, nll_loss=2.022, w2v_ctc_loss=1.713, task_loss=0, contrastive_loss=0.333, total=4163.73, n_correct=2015.76, ppl=4.06, accuracy=48.412, wps=16639.5, ups=1.34, wpb=12429.6, bsz=462.1, num_updates=6900, lr=0.000170251, gnorm=1.069, clip=1, loss_scale=0.5, train_wall=74, gb_free=16.3, wall=5139
2023-08-17 21:35:21 | INFO | train_inner | epoch 005:   1114 / 1474 loss=2.791, trans_loss=3.731, nll_loss=2.003, w2v_ctc_loss=1.731, task_loss=0, contrastive_loss=0.341, total=4172.75, n_correct=2043.23, ppl=4.01, accuracy=48.966, wps=16482.1, ups=1.32, wpb=12448.4, bsz=464, num_updates=7000, lr=0.000169031, gnorm=0.997, clip=0, loss_scale=0.5, train_wall=75, gb_free=12.9, wall=5215
2023-08-17 21:36:36 | INFO | train_inner | epoch 005:   1214 / 1474 loss=2.705, trans_loss=3.72, nll_loss=1.988, w2v_ctc_loss=1.666, task_loss=0, contrastive_loss=0.233, total=4164.91, n_correct=2065.35, ppl=3.97, accuracy=49.589, wps=16579.6, ups=1.33, wpb=12422.5, bsz=455.7, num_updates=7100, lr=0.000167836, gnorm=1.001, clip=1, loss_scale=0.5, train_wall=74, gb_free=14.9, wall=5290
2023-08-17 21:37:51 | INFO | train_inner | epoch 005:   1314 / 1474 loss=2.7, trans_loss=3.713, nll_loss=1.981, w2v_ctc_loss=1.678, task_loss=0, contrastive_loss=0.203, total=4127.88, n_correct=2054.48, ppl=3.95, accuracy=49.771, wps=16400.9, ups=1.33, wpb=12320.7, bsz=445.3, num_updates=7200, lr=0.000166667, gnorm=0.881, clip=0, loss_scale=1, train_wall=75, gb_free=16.3, wall=5365
2023-08-17 21:39:06 | INFO | train_inner | epoch 005:   1414 / 1474 loss=2.696, trans_loss=3.703, nll_loss=1.97, w2v_ctc_loss=1.661, task_loss=0, contrastive_loss=0.261, total=4135.9, n_correct=2076.42, ppl=3.92, accuracy=50.205, wps=16507.7, ups=1.34, wpb=12351.8, bsz=456.9, num_updates=7300, lr=0.000165521, gnorm=1.022, clip=1, loss_scale=1, train_wall=74, gb_free=16.8, wall=5440
2023-08-17 21:39:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 21:40:25 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.83 | trans_loss 5.917 | nll_loss 3.388 | w2v_ctc_loss 1.975 | task_loss 0 | contrastive_loss 0.414 | total 4003.4 | n_correct 2199.5 | ppl 10.47 | accuracy 54.941 | uer 28.591 | wer 29.835 | raw_wer 29.835 | bleu 11.96 | wps 1520.5 | wpb 4003.4 | bsz 141.8 | num_updates 7360 | best_bleu 11.96
2023-08-17 21:40:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7360 updates
2023-08-17 21:40:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 21:40:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 21:40:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7360 updates, score 11.96) (writing took 12.219097040011548 seconds)
2023-08-17 21:40:38 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-17 21:40:38 | INFO | train | epoch 005 | loss 2.843 | trans_loss 3.775 | nll_loss 2.062 | w2v_ctc_loss 1.758 | task_loss 0 | contrastive_loss 0.334 | total 4138.65 | n_correct 1946.38 | ppl 4.18 | accuracy 47.029 | wps 14947.8 | ups 1.21 | wpb 12355.8 | bsz 458.5 | num_updates 7360 | lr 0.000164845 | gnorm 1.202 | clip 0.7 | loss_scale 1 | train_wall 1097 | gb_free 16.2 | wall 5531
2023-08-17 21:40:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 21:40:38 | INFO | fairseq.trainer | begin training epoch 6
2023-08-17 21:40:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 21:41:14 | INFO | train_inner | epoch 006:     40 / 1474 loss=2.697, trans_loss=3.685, nll_loss=1.945, w2v_ctc_loss=1.675, task_loss=0, contrastive_loss=0.266, total=4114.92, n_correct=2082.24, ppl=3.85, accuracy=50.602, wps=9591.7, ups=0.78, wpb=12278.2, bsz=446.4, num_updates=7400, lr=0.000164399, gnorm=0.988, clip=0, loss_scale=1, train_wall=75, gb_free=16.5, wall=5568
2023-08-17 21:42:29 | INFO | train_inner | epoch 006:    140 / 1474 loss=2.641, trans_loss=3.654, nll_loss=1.906, w2v_ctc_loss=1.613, task_loss=0, contrastive_loss=0.299, total=4157.03, n_correct=2141.03, ppl=3.75, accuracy=51.504, wps=16657.4, ups=1.34, wpb=12418.5, bsz=455.9, num_updates=7500, lr=0.000163299, gnorm=0.883, clip=0, loss_scale=1, train_wall=74, gb_free=15, wall=5642
2023-08-17 21:43:44 | INFO | train_inner | epoch 006:    240 / 1474 loss=2.643, trans_loss=3.659, nll_loss=1.913, w2v_ctc_loss=1.641, task_loss=0, contrastive_loss=0.229, total=4121.73, n_correct=2121.14, ppl=3.77, accuracy=51.462, wps=16438.7, ups=1.34, wpb=12312.8, bsz=446.5, num_updates=7600, lr=0.000162221, gnorm=0.865, clip=0, loss_scale=1, train_wall=74, gb_free=16.2, wall=5717
2023-08-17 21:45:00 | INFO | train_inner | epoch 006:    340 / 1474 loss=2.652, trans_loss=3.639, nll_loss=1.886, w2v_ctc_loss=1.569, task_loss=0, contrastive_loss=0.501, total=4170.63, n_correct=2179.67, ppl=3.7, accuracy=52.262, wps=16388.9, ups=1.32, wpb=12451, bsz=486.5, num_updates=7700, lr=0.000161165, gnorm=0.86, clip=0, loss_scale=1, train_wall=75, gb_free=12.9, wall=5793
2023-08-17 21:46:14 | INFO | train_inner | epoch 006:    440 / 1474 loss=2.605, trans_loss=3.638, nll_loss=1.886, w2v_ctc_loss=1.599, task_loss=0, contrastive_loss=0.227, total=4147.89, n_correct=2173.98, ppl=3.69, accuracy=52.412, wps=16594.3, ups=1.34, wpb=12386.2, bsz=467, num_updates=7800, lr=0.000160128, gnorm=0.89, clip=0, loss_scale=1, train_wall=74, gb_free=16.9, wall=5868
2023-08-17 21:47:30 | INFO | train_inner | epoch 006:    540 / 1474 loss=2.565, trans_loss=3.632, nll_loss=1.876, w2v_ctc_loss=1.573, task_loss=0, contrastive_loss=0.2, total=4170.36, n_correct=2203.23, ppl=3.67, accuracy=52.831, wps=16520.5, ups=1.33, wpb=12447.9, bsz=455.9, num_updates=7900, lr=0.000159111, gnorm=0.736, clip=0, loss_scale=1, train_wall=75, gb_free=15.6, wall=5943
2023-08-17 21:48:44 | INFO | train_inner | epoch 006:    640 / 1474 loss=2.591, trans_loss=3.635, nll_loss=1.882, w2v_ctc_loss=1.574, task_loss=0, contrastive_loss=0.267, total=4144.5, n_correct=2183.38, ppl=3.68, accuracy=52.681, wps=16603.5, ups=1.34, wpb=12372.4, bsz=470, num_updates=8000, lr=0.000158114, gnorm=0.848, clip=0, loss_scale=1, train_wall=74, gb_free=17.2, wall=6018
2023-08-17 21:48:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 21:49:18 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.705 | trans_loss 5.773 | nll_loss 3.205 | w2v_ctc_loss 1.9 | task_loss 0 | contrastive_loss 0.412 | total 4003.4 | n_correct 2277.5 | ppl 9.22 | accuracy 56.889 | uer 27.126 | wer 28.31 | raw_wer 28.31 | bleu 13.75 | wps 1507.9 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 13.75
2023-08-17 21:49:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-17 21:49:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-17 21:49:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-17 21:49:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 13.75) (writing took 11.029634493985213 seconds)
2023-08-17 21:50:44 | INFO | train_inner | epoch 006:    740 / 1474 loss=2.561, trans_loss=3.627, nll_loss=1.871, w2v_ctc_loss=1.568, task_loss=0, contrastive_loss=0.212, total=4145.29, n_correct=2205.22, ppl=3.66, accuracy=53.198, wps=10293.7, ups=0.83, wpb=12375, bsz=454.7, num_updates=8100, lr=0.000157135, gnorm=0.697, clip=0, loss_scale=1, train_wall=75, gb_free=17.6, wall=6138
2023-08-17 21:51:59 | INFO | train_inner | epoch 006:    840 / 1474 loss=2.532, trans_loss=3.622, nll_loss=1.864, w2v_ctc_loss=1.541, task_loss=0, contrastive_loss=0.191, total=4131.83, n_correct=2205.63, ppl=3.64, accuracy=53.381, wps=16432.1, ups=1.33, wpb=12335.3, bsz=446.9, num_updates=8200, lr=0.000156174, gnorm=0.693, clip=0, loss_scale=1, train_wall=75, gb_free=16.6, wall=6213
2023-08-17 21:53:15 | INFO | train_inner | epoch 006:    940 / 1474 loss=2.562, trans_loss=3.622, nll_loss=1.865, w2v_ctc_loss=1.556, task_loss=0, contrastive_loss=0.285, total=4068.88, n_correct=2169.4, ppl=3.64, accuracy=53.317, wps=16070.2, ups=1.32, wpb=12145.6, bsz=436.9, num_updates=8300, lr=0.00015523, gnorm=0.689, clip=0, loss_scale=1, train_wall=75, gb_free=16.1, wall=6289
2023-08-17 21:54:30 | INFO | train_inner | epoch 006:   1040 / 1474 loss=2.546, trans_loss=3.603, nll_loss=1.84, w2v_ctc_loss=1.512, task_loss=0, contrastive_loss=0.36, total=4176.69, n_correct=2256.66, ppl=3.58, accuracy=54.03, wps=16674.7, ups=1.34, wpb=12465.8, bsz=480, num_updates=8400, lr=0.000154303, gnorm=0.663, clip=0, loss_scale=1, train_wall=74, gb_free=16.5, wall=6363
2023-08-17 21:55:45 | INFO | train_inner | epoch 006:   1140 / 1474 loss=2.522, trans_loss=3.604, nll_loss=1.842, w2v_ctc_loss=1.534, task_loss=0, contrastive_loss=0.218, total=4078.12, n_correct=2197.93, ppl=3.58, accuracy=53.896, wps=16237.8, ups=1.33, wpb=12175.4, bsz=435.5, num_updates=8500, lr=0.000153393, gnorm=0.707, clip=0, loss_scale=1, train_wall=74, gb_free=15, wall=6438
2023-08-17 21:57:00 | INFO | train_inner | epoch 006:   1240 / 1474 loss=2.551, trans_loss=3.589, nll_loss=1.824, w2v_ctc_loss=1.507, task_loss=0, contrastive_loss=0.482, total=4126.61, n_correct=2247.88, ppl=3.54, accuracy=54.473, wps=16426.2, ups=1.33, wpb=12325.4, bsz=463.4, num_updates=8600, lr=0.000152499, gnorm=0.693, clip=0, loss_scale=1, train_wall=74, gb_free=13.8, wall=6513
2023-08-17 21:58:14 | INFO | train_inner | epoch 006:   1340 / 1474 loss=2.473, trans_loss=3.589, nll_loss=1.82, w2v_ctc_loss=1.495, task_loss=0, contrastive_loss=0.17, total=4127.1, n_correct=2266.06, ppl=3.53, accuracy=54.907, wps=16585.7, ups=1.35, wpb=12313, bsz=454.8, num_updates=8700, lr=0.00015162, gnorm=0.664, clip=0, loss_scale=1, train_wall=74, gb_free=16.6, wall=6588
2023-08-17 21:59:29 | INFO | train_inner | epoch 006:   1440 / 1474 loss=2.516, trans_loss=3.594, nll_loss=1.829, w2v_ctc_loss=1.537, task_loss=0, contrastive_loss=0.191, total=4197.14, n_correct=2287.08, ppl=3.55, accuracy=54.491, wps=16667.9, ups=1.33, wpb=12529.7, bsz=463.5, num_updates=8800, lr=0.000150756, gnorm=0.96, clip=0, loss_scale=1, train_wall=74, gb_free=15.4, wall=6663
2023-08-17 21:59:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 22:00:29 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.587 | trans_loss 5.648 | nll_loss 3.045 | w2v_ctc_loss 1.827 | task_loss 0 | contrastive_loss 0.378 | total 4003.4 | n_correct 2364.1 | ppl 8.26 | accuracy 59.052 | uer 26.13 | wer 27.505 | raw_wer 27.505 | bleu 15.44 | wps 1460.2 | wpb 4003.4 | bsz 141.8 | num_updates 8834 | best_bleu 15.44
2023-08-17 22:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8834 updates
2023-08-17 22:00:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 22:00:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 22:00:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 6 @ 8834 updates, score 15.44) (writing took 11.95049637198099 seconds)
2023-08-17 22:00:41 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-17 22:00:41 | INFO | train | epoch 006 | loss 2.569 | trans_loss 3.622 | nll_loss 1.865 | w2v_ctc_loss 1.559 | task_loss 0 | contrastive_loss 0.272 | total 4138.65 | n_correct 2201.17 | ppl 3.64 | accuracy 53.186 | wps 15128.2 | ups 1.22 | wpb 12355.8 | bsz 458.5 | num_updates 8834 | lr 0.000150465 | gnorm 0.775 | clip 0 | loss_scale 1 | train_wall 1096 | gb_free 15.1 | wall 6735
2023-08-17 22:00:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 22:00:42 | INFO | fairseq.trainer | begin training epoch 7
2023-08-17 22:00:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 22:01:38 | INFO | train_inner | epoch 007:     66 / 1474 loss=2.459, trans_loss=3.572, nll_loss=1.8, w2v_ctc_loss=1.485, task_loss=0, contrastive_loss=0.194, total=4099.48, n_correct=2261.68, ppl=3.48, accuracy=55.17, wps=9468.4, ups=0.77, wpb=12236.9, bsz=460.3, num_updates=8900, lr=0.000149906, gnorm=0.767, clip=1, loss_scale=1, train_wall=75, gb_free=16.1, wall=6792
2023-08-17 22:02:53 | INFO | train_inner | epoch 007:    166 / 1474 loss=2.451, trans_loss=3.561, nll_loss=1.786, w2v_ctc_loss=1.462, task_loss=0, contrastive_loss=0.26, total=4107.4, n_correct=2279.62, ppl=3.45, accuracy=55.5, wps=16534.5, ups=1.35, wpb=12263.9, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.657, clip=0, loss_scale=1, train_wall=74, gb_free=16.9, wall=6866
2023-08-17 22:04:07 | INFO | train_inner | epoch 007:    266 / 1474 loss=2.418, trans_loss=3.552, nll_loss=1.773, w2v_ctc_loss=1.452, task_loss=0, contrastive_loss=0.17, total=4137.13, n_correct=2312.79, ppl=3.42, accuracy=55.903, wps=16526.8, ups=1.34, wpb=12346.5, bsz=454.9, num_updates=9100, lr=0.00014825, gnorm=0.62, clip=0, loss_scale=1, train_wall=74, gb_free=16.4, wall=6941
2023-08-17 22:05:23 | INFO | train_inner | epoch 007:    366 / 1474 loss=2.467, trans_loss=3.553, nll_loss=1.775, w2v_ctc_loss=1.44, task_loss=0, contrastive_loss=0.431, total=4199.72, n_correct=2345.61, ppl=3.42, accuracy=55.852, wps=16669.8, ups=1.33, wpb=12534, bsz=480.8, num_updates=9200, lr=0.000147442, gnorm=0.642, clip=0, loss_scale=1, train_wall=75, gb_free=17.4, wall=7016
2023-08-17 22:06:38 | INFO | train_inner | epoch 007:    466 / 1474 loss=2.437, trans_loss=3.55, nll_loss=1.773, w2v_ctc_loss=1.43, task_loss=0, contrastive_loss=0.343, total=4149.08, n_correct=2320.33, ppl=3.42, accuracy=55.924, wps=16462.6, ups=1.33, wpb=12391, bsz=459, num_updates=9300, lr=0.000146647, gnorm=0.561, clip=0, loss_scale=2, train_wall=75, gb_free=17, wall=7091
2023-08-17 22:07:53 | INFO | train_inner | epoch 007:    566 / 1474 loss=2.396, trans_loss=3.547, nll_loss=1.765, w2v_ctc_loss=1.427, task_loss=0, contrastive_loss=0.175, total=4168.84, n_correct=2349.24, ppl=3.4, accuracy=56.352, wps=16539.1, ups=1.33, wpb=12436.4, bsz=460, num_updates=9400, lr=0.000145865, gnorm=0.605, clip=0, loss_scale=2, train_wall=75, gb_free=16.3, wall=7167
2023-08-17 22:09:08 | INFO | train_inner | epoch 007:    666 / 1474 loss=2.386, trans_loss=3.541, nll_loss=1.76, w2v_ctc_loss=1.423, task_loss=0, contrastive_loss=0.16, total=4164.13, n_correct=2355.82, ppl=3.39, accuracy=56.574, wps=16560, ups=1.33, wpb=12427.2, bsz=458.5, num_updates=9500, lr=0.000145095, gnorm=0.624, clip=0, loss_scale=2, train_wall=74, gb_free=15.6, wall=7242
2023-08-17 22:10:23 | INFO | train_inner | epoch 007:    766 / 1474 loss=2.386, trans_loss=3.536, nll_loss=1.753, w2v_ctc_loss=1.423, task_loss=0, contrastive_loss=0.165, total=4126.5, n_correct=2328.13, ppl=3.37, accuracy=56.419, wps=16358.6, ups=1.33, wpb=12320.2, bsz=450.3, num_updates=9600, lr=0.000144338, gnorm=0.638, clip=0, loss_scale=2, train_wall=75, gb_free=15.3, wall=7317
2023-08-17 22:11:39 | INFO | train_inner | epoch 007:    866 / 1474 loss=2.39, trans_loss=3.544, nll_loss=1.762, w2v_ctc_loss=1.426, task_loss=0, contrastive_loss=0.172, total=4133.53, n_correct=2333.71, ppl=3.39, accuracy=56.458, wps=16387.8, ups=1.33, wpb=12333.5, bsz=453.5, num_updates=9700, lr=0.000143592, gnorm=0.701, clip=0, loss_scale=2, train_wall=75, gb_free=12.9, wall=7392
2023-08-17 22:12:54 | INFO | train_inner | epoch 007:    966 / 1474 loss=2.395, trans_loss=3.528, nll_loss=1.745, w2v_ctc_loss=1.401, task_loss=0, contrastive_loss=0.274, total=4144.45, n_correct=2360.88, ppl=3.35, accuracy=56.965, wps=16429.4, ups=1.33, wpb=12374.7, bsz=476.9, num_updates=9800, lr=0.000142857, gnorm=0.642, clip=0, loss_scale=2, train_wall=75, gb_free=16, wall=7468
2023-08-17 22:14:09 | INFO | train_inner | epoch 007:   1066 / 1474 loss=2.374, trans_loss=3.54, nll_loss=1.76, w2v_ctc_loss=1.423, task_loss=0, contrastive_loss=0.137, total=4100.65, n_correct=2320.75, ppl=3.39, accuracy=56.595, wps=16256.3, ups=1.33, wpb=12242.5, bsz=435.4, num_updates=9900, lr=0.000142134, gnorm=0.662, clip=0, loss_scale=2, train_wall=75, gb_free=15.8, wall=7543
2023-08-17 22:15:24 | INFO | train_inner | epoch 007:   1166 / 1474 loss=2.428, trans_loss=3.523, nll_loss=1.74, w2v_ctc_loss=1.407, task_loss=0, contrastive_loss=0.412, total=4138.96, n_correct=2361.09, ppl=3.34, accuracy=57.045, wps=16452.5, ups=1.33, wpb=12367.7, bsz=471.9, num_updates=10000, lr=0.000141421, gnorm=0.7, clip=0, loss_scale=2, train_wall=75, gb_free=16.6, wall=7618
2023-08-17 22:15:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 22:15:56 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.477 | trans_loss 5.531 | nll_loss 2.895 | w2v_ctc_loss 1.746 | task_loss 0 | contrastive_loss 0.36 | total 4003.4 | n_correct 2430.3 | ppl 7.44 | accuracy 60.706 | uer 25.042 | wer 26.509 | raw_wer 26.509 | bleu 17.18 | wps 1694.8 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 17.18
2023-08-17 22:15:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-17 22:15:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-17 22:15:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-17 22:16:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 17.18) (writing took 12.4188151069975 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:0')
2023-08-17 22:17:23 | INFO | train_inner | epoch 007:   1266 / 1474 loss=2.378, trans_loss=3.528, nll_loss=1.745, w2v_ctc_loss=1.421, task_loss=0, contrastive_loss=0.17, total=4120.42, n_correct=2346.38, ppl=3.35, accuracy=56.945, wps=10361.1, ups=0.84, wpb=12304.2, bsz=446.6, num_updates=10100, lr=0.00014072, gnorm=0.684, clip=0, loss_scale=2, train_wall=74, gb_free=15.5, wall=7737
2023-08-17 22:18:38 | INFO | train_inner | epoch 007:   1366 / 1474 loss=2.378, trans_loss=3.52, nll_loss=1.734, w2v_ctc_loss=1.41, task_loss=0, contrastive_loss=0.205, total=4186.45, n_correct=2403.03, ppl=3.33, accuracy=57.4, wps=16758.6, ups=1.34, wpb=12499.3, bsz=479.7, num_updates=10200, lr=0.000140028, gnorm=0.524, clip=0, loss_scale=2, train_wall=74, gb_free=12.3, wall=7811
2023-08-17 22:19:54 | INFO | train_inner | epoch 007:   1466 / 1474 loss=2.373, trans_loss=3.518, nll_loss=1.734, w2v_ctc_loss=1.395, task_loss=0, contrastive_loss=0.264, total=4117.01, n_correct=2361.08, ppl=3.33, accuracy=57.349, wps=16196.7, ups=1.32, wpb=12300.4, bsz=448.4, num_updates=10300, lr=0.000139347, gnorm=0.527, clip=0, loss_scale=2, train_wall=75, gb_free=16, wall=7887
2023-08-17 22:19:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:4')
2023-08-17 22:20:32 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.429 | trans_loss 5.486 | nll_loss 2.836 | w2v_ctc_loss 1.716 | task_loss 0 | contrastive_loss 0.338 | total 4003.4 | n_correct 2456.4 | ppl 7.14 | accuracy 61.358 | uer 24.309 | wer 25.801 | raw_wer 25.801 | bleu 17.81 | wps 1590.7 | wpb 4003.4 | bsz 141.8 | num_updates 10308 | best_bleu 17.81
2023-08-17 22:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10308 updates
2023-08-17 22:20:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 22:20:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 22:20:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 7 @ 10308 updates, score 17.81) (writing took 11.691874747019028 seconds)
2023-08-17 22:20:45 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-17 22:20:45 | INFO | train | epoch 007 | loss 2.406 | trans_loss 3.54 | nll_loss 1.759 | w2v_ctc_loss 1.427 | task_loss 0 | contrastive_loss 0.237 | total 4138.65 | n_correct 2337.06 | ppl 3.38 | accuracy 56.469 | wps 15136.7 | ups 1.23 | wpb 12355.8 | bsz 458.5 | num_updates 10308 | lr 0.000139293 | gnorm 0.635 | clip 0.1 | loss_scale 2 | train_wall 1098 | gb_free 13.3 | wall 7938
2023-08-17 22:20:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 22:20:45 | INFO | fairseq.trainer | begin training epoch 8
2023-08-17 22:20:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 22:22:01 | INFO | train_inner | epoch 008:     92 / 1474 loss=2.308, trans_loss=3.509, nll_loss=1.716, w2v_ctc_loss=1.353, task_loss=0, contrastive_loss=0.155, total=4097.76, n_correct=2373.35, ppl=3.28, accuracy=57.918, wps=9610.4, ups=0.79, wpb=12216.9, bsz=437, num_updates=10400, lr=0.000138675, gnorm=0.463, clip=0, loss_scale=2, train_wall=74, gb_free=15.8, wall=8014
2023-08-17 22:23:16 | INFO | train_inner | epoch 008:    192 / 1474 loss=2.311, trans_loss=3.498, nll_loss=1.702, w2v_ctc_loss=1.355, task_loss=0, contrastive_loss=0.177, total=4039, n_correct=2344.06, ppl=3.25, accuracy=58.036, wps=15935.8, ups=1.32, wpb=12046.3, bsz=428.9, num_updates=10500, lr=0.000138013, gnorm=0.518, clip=0, loss_scale=2, train_wall=75, gb_free=14.8, wall=8090
2023-08-17 22:24:31 | INFO | train_inner | epoch 008:    292 / 1474 loss=2.313, trans_loss=3.489, nll_loss=1.693, w2v_ctc_loss=1.355, task_loss=0, contrastive_loss=0.18, total=4210.6, n_correct=2457.97, ppl=3.23, accuracy=58.376, wps=16855.5, ups=1.34, wpb=12566.5, bsz=486.9, num_updates=10600, lr=0.000137361, gnorm=0.486, clip=0, loss_scale=2, train_wall=74, gb_free=15.9, wall=8165
2023-08-17 22:25:46 | INFO | train_inner | epoch 008:    392 / 1474 loss=2.319, trans_loss=3.495, nll_loss=1.699, w2v_ctc_loss=1.361, task_loss=0, contrastive_loss=0.198, total=4139.64, n_correct=2412.25, ppl=3.25, accuracy=58.272, wps=16393.1, ups=1.33, wpb=12350.6, bsz=447.4, num_updates=10700, lr=0.000136717, gnorm=0.525, clip=0, loss_scale=2, train_wall=75, gb_free=15, wall=8240
2023-08-17 22:27:02 | INFO | train_inner | epoch 008:    492 / 1474 loss=2.39, trans_loss=3.492, nll_loss=1.699, w2v_ctc_loss=1.354, task_loss=0, contrastive_loss=0.465, total=4189.5, n_correct=2440.7, ppl=3.25, accuracy=58.258, wps=16571.8, ups=1.32, wpb=12508.9, bsz=499.4, num_updates=10800, lr=0.000136083, gnorm=0.608, clip=0, loss_scale=2, train_wall=75, gb_free=12.8, wall=8315
2023-08-17 22:28:17 | INFO | train_inner | epoch 008:    592 / 1474 loss=2.306, trans_loss=3.491, nll_loss=1.7, w2v_ctc_loss=1.368, task_loss=0, contrastive_loss=0.132, total=4061.09, n_correct=2359.65, ppl=3.25, accuracy=58.104, wps=16206.7, ups=1.33, wpb=12140.1, bsz=427.7, num_updates=10900, lr=0.000135457, gnorm=0.503, clip=0, loss_scale=2, train_wall=74, gb_free=16.4, wall=8390
2023-08-17 22:29:32 | INFO | train_inner | epoch 008:    692 / 1474 loss=2.304, trans_loss=3.487, nll_loss=1.691, w2v_ctc_loss=1.363, task_loss=0, contrastive_loss=0.147, total=4144.17, n_correct=2424.11, ppl=3.23, accuracy=58.494, wps=16485.8, ups=1.33, wpb=12370.7, bsz=450.4, num_updates=11000, lr=0.00013484, gnorm=0.581, clip=0, loss_scale=2, train_wall=74, gb_free=13.4, wall=8465
2023-08-17 22:30:46 | INFO | train_inner | epoch 008:    792 / 1474 loss=2.306, trans_loss=3.48, nll_loss=1.686, w2v_ctc_loss=1.346, task_loss=0, contrastive_loss=0.227, total=4117.36, n_correct=2411.18, ppl=3.22, accuracy=58.561, wps=16497.9, ups=1.34, wpb=12305.6, bsz=448.1, num_updates=11100, lr=0.000134231, gnorm=0.517, clip=0, loss_scale=2, train_wall=74, gb_free=16.1, wall=8540
2023-08-17 22:32:01 | INFO | train_inner | epoch 008:    892 / 1474 loss=2.298, trans_loss=3.482, nll_loss=1.686, w2v_ctc_loss=1.322, task_loss=0, contrastive_loss=0.238, total=4182.5, n_correct=2461.09, ppl=3.22, accuracy=58.843, wps=16672.7, ups=1.33, wpb=12489.6, bsz=478.7, num_updates=11200, lr=0.000133631, gnorm=0.497, clip=0, loss_scale=2, train_wall=74, gb_free=17.3, wall=8615
2023-08-17 22:33:16 | INFO | train_inner | epoch 008:    992 / 1474 loss=2.264, trans_loss=3.477, nll_loss=1.679, w2v_ctc_loss=1.319, task_loss=0, contrastive_loss=0.138, total=4155.49, n_correct=2455.13, ppl=3.2, accuracy=59.082, wps=16603.5, ups=1.34, wpb=12408.4, bsz=464, num_updates=11300, lr=0.000133038, gnorm=0.447, clip=0, loss_scale=4, train_wall=74, gb_free=16.9, wall=8690
2023-08-17 22:34:32 | INFO | train_inner | epoch 008:   1092 / 1474 loss=2.319, trans_loss=3.483, nll_loss=1.685, w2v_ctc_loss=1.329, task_loss=0, contrastive_loss=0.359, total=4186.39, n_correct=2458.52, ppl=3.22, accuracy=58.726, wps=16546.7, ups=1.32, wpb=12493.6, bsz=461.7, num_updates=11400, lr=0.000132453, gnorm=0.556, clip=0, loss_scale=4, train_wall=75, gb_free=15.2, wall=8765
2023-08-17 22:35:47 | INFO | train_inner | epoch 008:   1192 / 1474 loss=2.281, trans_loss=3.474, nll_loss=1.677, w2v_ctc_loss=1.335, task_loss=0, contrastive_loss=0.148, total=4178.48, n_correct=2462.79, ppl=3.2, accuracy=58.94, wps=16581.5, ups=1.33, wpb=12482, bsz=472.1, num_updates=11500, lr=0.000131876, gnorm=0.506, clip=0, loss_scale=4, train_wall=75, gb_free=15.7, wall=8840
2023-08-17 22:37:02 | INFO | train_inner | epoch 008:   1292 / 1474 loss=2.277, trans_loss=3.477, nll_loss=1.68, w2v_ctc_loss=1.332, task_loss=0, contrastive_loss=0.166, total=4064.4, n_correct=2387.18, ppl=3.2, accuracy=58.734, wps=16237.5, ups=1.34, wpb=12140.7, bsz=436, num_updates=11600, lr=0.000131306, gnorm=0.501, clip=0, loss_scale=4, train_wall=74, gb_free=15.8, wall=8915
2023-08-17 22:38:16 | INFO | train_inner | epoch 008:   1392 / 1474 loss=2.295, trans_loss=3.477, nll_loss=1.68, w2v_ctc_loss=1.324, task_loss=0, contrastive_loss=0.238, total=4163.91, n_correct=2461.44, ppl=3.2, accuracy=59.114, wps=16772.4, ups=1.35, wpb=12433, bsz=472.8, num_updates=11700, lr=0.000130744, gnorm=0.521, clip=0, loss_scale=4, train_wall=74, gb_free=16.4, wall=8989
2023-08-17 22:39:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 22:39:50 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.349 | trans_loss 5.404 | nll_loss 2.725 | w2v_ctc_loss 1.663 | task_loss 0 | contrastive_loss 0.314 | total 4003.4 | n_correct 2506.8 | ppl 6.61 | accuracy 62.617 | uer 23.25 | wer 24.88 | raw_wer 24.88 | bleu 18.3 | wps 1611.3 | wpb 4003.4 | bsz 141.8 | num_updates 11782 | best_bleu 18.3
2023-08-17 22:39:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11782 updates
2023-08-17 22:39:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 22:39:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 22:40:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 11782 updates, score 18.3) (writing took 11.215316066984087 seconds)
2023-08-17 22:40:01 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-17 22:40:01 | INFO | train | epoch 008 | loss 2.305 | trans_loss 3.486 | nll_loss 1.69 | w2v_ctc_loss 1.342 | task_loss 0 | contrastive_loss 0.217 | total 4138.65 | n_correct 2424.13 | ppl 3.23 | accuracy 58.573 | wps 15747.7 | ups 1.27 | wpb 12355.8 | bsz 458.5 | num_updates 11782 | lr 0.000130288 | gnorm 0.514 | clip 0 | loss_scale 4 | train_wall 1096 | gb_free 16.9 | wall 9095
2023-08-17 22:40:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 22:40:01 | INFO | fairseq.trainer | begin training epoch 9
2023-08-17 22:40:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 22:40:22 | INFO | train_inner | epoch 009:     18 / 1474 loss=2.28, trans_loss=3.47, nll_loss=1.67, w2v_ctc_loss=1.298, task_loss=0, contrastive_loss=0.323, total=4111.15, n_correct=2434.97, ppl=3.18, accuracy=59.228, wps=9726.9, ups=0.79, wpb=12269.8, bsz=460.9, num_updates=11800, lr=0.000130189, gnorm=0.467, clip=0, loss_scale=4, train_wall=74, gb_free=16.9, wall=9116
2023-08-17 22:41:36 | INFO | train_inner | epoch 009:    118 / 1474 loss=2.231, trans_loss=3.446, nll_loss=1.64, w2v_ctc_loss=1.279, task_loss=0, contrastive_loss=0.165, total=4186.63, n_correct=2509.76, ppl=3.12, accuracy=59.947, wps=16843.6, ups=1.35, wpb=12503, bsz=481.5, num_updates=11900, lr=0.000129641, gnorm=0.44, clip=0, loss_scale=4, train_wall=73, gb_free=16.4, wall=9190
2023-08-17 22:42:51 | INFO | train_inner | epoch 009:    218 / 1474 loss=2.208, trans_loss=3.448, nll_loss=1.642, w2v_ctc_loss=1.271, task_loss=0, contrastive_loss=0.118, total=4071.82, n_correct=2439.69, ppl=3.12, accuracy=59.916, wps=16153.7, ups=1.33, wpb=12157.1, bsz=430.9, num_updates=12000, lr=0.000129099, gnorm=0.43, clip=0, loss_scale=4, train_wall=75, gb_free=16.6, wall=9265
2023-08-17 22:42:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 22:43:24 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.333 | trans_loss 5.406 | nll_loss 2.732 | w2v_ctc_loss 1.595 | task_loss 0 | contrastive_loss 0.324 | total 4003.4 | n_correct 2500.5 | ppl 6.64 | accuracy 62.459 | uer 23.064 | wer 24.712 | raw_wer 24.712 | bleu 18.52 | wps 1650.5 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.52
2023-08-17 22:43:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-17 22:43:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-17 22:43:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-17 22:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.52) (writing took 15.503351531020598 seconds)
2023-08-17 22:44:54 | INFO | train_inner | epoch 009:    318 / 1474 loss=2.217, trans_loss=3.438, nll_loss=1.631, w2v_ctc_loss=1.259, task_loss=0, contrastive_loss=0.176, total=4167.06, n_correct=2510.3, ppl=3.1, accuracy=60.242, wps=10180.6, ups=0.82, wpb=12450.2, bsz=485.4, num_updates=12100, lr=0.000128565, gnorm=0.46, clip=0, loss_scale=4, train_wall=73, gb_free=14.9, wall=9387
2023-08-17 22:46:09 | INFO | train_inner | epoch 009:    418 / 1474 loss=2.217, trans_loss=3.453, nll_loss=1.648, w2v_ctc_loss=1.275, task_loss=0, contrastive_loss=0.132, total=4175.09, n_correct=2495.82, ppl=3.13, accuracy=59.779, wps=16551.9, ups=1.33, wpb=12466.4, bsz=457.5, num_updates=12200, lr=0.000128037, gnorm=0.487, clip=0, loss_scale=4, train_wall=75, gb_free=17.2, wall=9463
2023-08-17 22:47:24 | INFO | train_inner | epoch 009:    518 / 1474 loss=2.238, trans_loss=3.45, nll_loss=1.644, w2v_ctc_loss=1.291, task_loss=0, contrastive_loss=0.184, total=4118.47, n_correct=2469.03, ppl=3.13, accuracy=59.95, wps=16486.8, ups=1.34, wpb=12292.7, bsz=439.7, num_updates=12300, lr=0.000127515, gnorm=0.484, clip=0, loss_scale=4, train_wall=74, gb_free=17.3, wall=9537
2023-08-17 22:48:39 | INFO | train_inner | epoch 009:    618 / 1474 loss=2.227, trans_loss=3.442, nll_loss=1.637, w2v_ctc_loss=1.264, task_loss=0, contrastive_loss=0.238, total=4141.76, n_correct=2488.28, ppl=3.11, accuracy=60.078, wps=16495, ups=1.33, wpb=12378.7, bsz=462.3, num_updates=12400, lr=0.000127, gnorm=0.487, clip=0, loss_scale=4, train_wall=74, gb_free=16.8, wall=9612
2023-08-17 22:49:54 | INFO | train_inner | epoch 009:    718 / 1474 loss=2.219, trans_loss=3.449, nll_loss=1.645, w2v_ctc_loss=1.285, task_loss=0, contrastive_loss=0.133, total=4075.02, n_correct=2441.74, ppl=3.13, accuracy=59.92, wps=16240.5, ups=1.33, wpb=12176, bsz=443.4, num_updates=12500, lr=0.000126491, gnorm=0.466, clip=0, loss_scale=4, train_wall=74, gb_free=17.3, wall=9687
2023-08-17 22:51:09 | INFO | train_inner | epoch 009:    818 / 1474 loss=2.276, trans_loss=3.44, nll_loss=1.635, w2v_ctc_loss=1.272, task_loss=0, contrastive_loss=0.375, total=4214.28, n_correct=2535.53, ppl=3.11, accuracy=60.165, wps=16750.1, ups=1.33, wpb=12593.1, bsz=499.2, num_updates=12600, lr=0.000125988, gnorm=0.463, clip=0, loss_scale=4, train_wall=75, gb_free=16.8, wall=9762
2023-08-17 22:52:24 | INFO | train_inner | epoch 009:    918 / 1474 loss=2.247, trans_loss=3.447, nll_loss=1.638, w2v_ctc_loss=1.269, task_loss=0, contrastive_loss=0.348, total=4157.54, n_correct=2499.2, ppl=3.11, accuracy=60.112, wps=16389.8, ups=1.32, wpb=12400.4, bsz=452, num_updates=12700, lr=0.000125491, gnorm=0.455, clip=0, loss_scale=4, train_wall=75, gb_free=16.3, wall=9838
2023-08-17 22:53:39 | INFO | train_inner | epoch 009:   1018 / 1474 loss=2.203, trans_loss=3.45, nll_loss=1.643, w2v_ctc_loss=1.267, task_loss=0, contrastive_loss=0.13, total=4093.77, n_correct=2457.36, ppl=3.12, accuracy=60.027, wps=16355.6, ups=1.34, wpb=12221, bsz=423.7, num_updates=12800, lr=0.000125, gnorm=0.457, clip=0, loss_scale=4, train_wall=74, gb_free=17.2, wall=9913
2023-08-17 22:54:54 | INFO | train_inner | epoch 009:   1118 / 1474 loss=2.206, trans_loss=3.447, nll_loss=1.637, w2v_ctc_loss=1.257, task_loss=0, contrastive_loss=0.156, total=4173.97, n_correct=2517.66, ppl=3.11, accuracy=60.318, wps=16617.1, ups=1.34, wpb=12442.6, bsz=471.4, num_updates=12900, lr=0.000124515, gnorm=0.435, clip=0, loss_scale=4, train_wall=74, gb_free=16.1, wall=9988
2023-08-17 22:56:10 | INFO | train_inner | epoch 009:   1218 / 1474 loss=2.208, trans_loss=3.444, nll_loss=1.638, w2v_ctc_loss=1.27, task_loss=0, contrastive_loss=0.139, total=4144.88, n_correct=2495.62, ppl=3.11, accuracy=60.21, wps=16245.4, ups=1.31, wpb=12376.1, bsz=450, num_updates=13000, lr=0.000124035, gnorm=0.447, clip=0, loss_scale=4, train_wall=76, gb_free=16.3, wall=10064
2023-08-17 22:57:25 | INFO | train_inner | epoch 009:   1318 / 1474 loss=2.236, trans_loss=3.436, nll_loss=1.626, w2v_ctc_loss=1.248, task_loss=0, contrastive_loss=0.331, total=4200.61, n_correct=2542.54, ppl=3.09, accuracy=60.528, wps=16829.9, ups=1.34, wpb=12534.4, bsz=490.7, num_updates=13100, lr=0.00012356, gnorm=0.447, clip=0, loss_scale=4, train_wall=74, gb_free=15.5, wall=10138
2023-08-17 22:58:39 | INFO | train_inner | epoch 009:   1418 / 1474 loss=2.196, trans_loss=3.45, nll_loss=1.643, w2v_ctc_loss=1.262, task_loss=0, contrastive_loss=0.115, total=4075.96, n_correct=2454.88, ppl=3.12, accuracy=60.228, wps=16417.1, ups=1.35, wpb=12161.1, bsz=430.6, num_updates=13200, lr=0.000123091, gnorm=0.475, clip=0, loss_scale=4, train_wall=73, gb_free=17.5, wall=10212
2023-08-17 22:59:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 22:59:52 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.279 | trans_loss 5.353 | nll_loss 2.67 | w2v_ctc_loss 1.553 | task_loss 0 | contrastive_loss 0.309 | total 4003.4 | n_correct 2532.5 | ppl 6.36 | accuracy 63.259 | uer 22.164 | wer 23.955 | raw_wer 23.955 | bleu 19.41 | wps 1633.8 | wpb 4003.4 | bsz 141.8 | num_updates 13256 | best_bleu 19.41
2023-08-17 22:59:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13256 updates
2023-08-17 22:59:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 22:59:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 23:00:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 9 @ 13256 updates, score 19.41) (writing took 12.209652338002343 seconds)
2023-08-17 23:00:05 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-17 23:00:05 | INFO | train | epoch 009 | loss 2.224 | trans_loss 3.445 | nll_loss 1.639 | w2v_ctc_loss 1.269 | task_loss 0 | contrastive_loss 0.201 | total 4138.65 | n_correct 2488.04 | ppl 3.11 | accuracy 60.117 | wps 15127.8 | ups 1.22 | wpb 12355.8 | bsz 458.5 | num_updates 13256 | lr 0.000122831 | gnorm 0.461 | clip 0 | loss_scale 4 | train_wall 1094 | gb_free 11.7 | wall 10299
2023-08-17 23:00:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 23:00:05 | INFO | fairseq.trainer | begin training epoch 10
2023-08-17 23:00:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 23:00:45 | INFO | train_inner | epoch 010:     44 / 1474 loss=2.197, trans_loss=3.429, nll_loss=1.618, w2v_ctc_loss=1.237, task_loss=0, contrastive_loss=0.214, total=4112.83, n_correct=2503.65, ppl=3.07, accuracy=60.874, wps=9740.9, ups=0.79, wpb=12275.4, bsz=475.1, num_updates=13300, lr=0.000122628, gnorm=0.459, clip=0, loss_scale=4, train_wall=73, gb_free=16.3, wall=10338
2023-08-17 23:02:00 | INFO | train_inner | epoch 010:    144 / 1474 loss=2.146, trans_loss=3.414, nll_loss=1.6, w2v_ctc_loss=1.208, task_loss=0, contrastive_loss=0.129, total=4230.29, n_correct=2590.64, ppl=3.03, accuracy=61.24, wps=16807.9, ups=1.33, wpb=12634.2, bsz=472.7, num_updates=13400, lr=0.000122169, gnorm=0.442, clip=0, loss_scale=8, train_wall=75, gb_free=16.5, wall=10414
2023-08-17 23:03:15 | INFO | train_inner | epoch 010:    244 / 1474 loss=2.177, trans_loss=3.411, nll_loss=1.594, w2v_ctc_loss=1.214, task_loss=0, contrastive_loss=0.254, total=4131.59, n_correct=2534.12, ppl=3.02, accuracy=61.335, wps=16465.3, ups=1.34, wpb=12331.3, bsz=463.6, num_updates=13500, lr=0.000121716, gnorm=0.462, clip=0, loss_scale=8, train_wall=74, gb_free=10.3, wall=10489
2023-08-17 23:04:30 | INFO | train_inner | epoch 010:    344 / 1474 loss=2.156, trans_loss=3.413, nll_loss=1.6, w2v_ctc_loss=1.21, task_loss=0, contrastive_loss=0.165, total=4135.23, n_correct=2528.14, ppl=3.03, accuracy=61.137, wps=16435, ups=1.33, wpb=12360.3, bsz=454.8, num_updates=13600, lr=0.000121268, gnorm=0.469, clip=0, loss_scale=8, train_wall=75, gb_free=17.2, wall=10564
2023-08-17 23:05:45 | INFO | train_inner | epoch 010:    444 / 1474 loss=2.183, trans_loss=3.417, nll_loss=1.602, w2v_ctc_loss=1.196, task_loss=0, contrastive_loss=0.342, total=4197.95, n_correct=2569.13, ppl=3.03, accuracy=61.2, wps=16636.6, ups=1.33, wpb=12531.8, bsz=481.2, num_updates=13700, lr=0.000120824, gnorm=0.469, clip=0, loss_scale=8, train_wall=75, gb_free=15.4, wall=10639
2023-08-17 23:07:00 | INFO | train_inner | epoch 010:    544 / 1474 loss=2.156, trans_loss=3.424, nll_loss=1.608, w2v_ctc_loss=1.224, task_loss=0, contrastive_loss=0.118, total=4097.61, n_correct=2502.34, ppl=3.05, accuracy=61.068, wps=16286.3, ups=1.33, wpb=12219.2, bsz=434.6, num_updates=13800, lr=0.000120386, gnorm=0.443, clip=0, loss_scale=8, train_wall=74, gb_free=17.7, wall=10714
2023-08-17 23:08:16 | INFO | train_inner | epoch 010:    644 / 1474 loss=2.179, trans_loss=3.418, nll_loss=1.603, w2v_ctc_loss=1.213, task_loss=0, contrastive_loss=0.237, total=4187.04, n_correct=2562.21, ppl=3.04, accuracy=61.194, wps=16648.9, ups=1.33, wpb=12494.9, bsz=483.5, num_updates=13900, lr=0.000119952, gnorm=0.42, clip=0, loss_scale=8, train_wall=75, gb_free=16.4, wall=10789
2023-08-17 23:09:30 | INFO | train_inner | epoch 010:    744 / 1474 loss=2.159, trans_loss=3.417, nll_loss=1.602, w2v_ctc_loss=1.231, task_loss=0, contrastive_loss=0.114, total=4112.31, n_correct=2515.65, ppl=3.04, accuracy=61.174, wps=16487.7, ups=1.34, wpb=12277.4, bsz=448.4, num_updates=14000, lr=0.000119523, gnorm=0.453, clip=0, loss_scale=8, train_wall=74, gb_free=12.4, wall=10864
2023-08-17 23:09:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 23:10:02 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.284 | trans_loss 5.334 | nll_loss 2.641 | w2v_ctc_loss 1.615 | task_loss 0 | contrastive_loss 0.311 | total 4003.4 | n_correct 2553.1 | ppl 6.24 | accuracy 63.773 | uer 22.382 | wer 24.205 | raw_wer 24.205 | bleu 19.48 | wps 1688.5 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.48
2023-08-17 23:10:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-17 23:10:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-17 23:10:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-17 23:10:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.48) (writing took 15.37989088500035 seconds)
2023-08-17 23:11:32 | INFO | train_inner | epoch 010:    844 / 1474 loss=2.141, trans_loss=3.415, nll_loss=1.6, w2v_ctc_loss=1.203, task_loss=0, contrastive_loss=0.122, total=4135.95, n_correct=2534.13, ppl=3.03, accuracy=61.271, wps=10085.8, ups=0.82, wpb=12346.8, bsz=456.9, num_updates=14100, lr=0.000119098, gnorm=0.445, clip=0, loss_scale=8, train_wall=74, gb_free=15.8, wall=10986
2023-08-17 23:12:46 | INFO | train_inner | epoch 010:    944 / 1474 loss=2.156, trans_loss=3.412, nll_loss=1.595, w2v_ctc_loss=1.208, task_loss=0, contrastive_loss=0.163, total=4169.57, n_correct=2560.41, ppl=3.02, accuracy=61.407, wps=16855.9, ups=1.36, wpb=12439, bsz=473.3, num_updates=14200, lr=0.000118678, gnorm=0.465, clip=0, loss_scale=8, train_wall=73, gb_free=13.6, wall=11060
2023-08-17 23:14:01 | INFO | train_inner | epoch 010:   1044 / 1474 loss=2.148, trans_loss=3.414, nll_loss=1.598, w2v_ctc_loss=1.214, task_loss=0, contrastive_loss=0.132, total=4058.1, n_correct=2484.89, ppl=3.03, accuracy=61.233, wps=16185.3, ups=1.34, wpb=12115.2, bsz=430.4, num_updates=14300, lr=0.000118262, gnorm=0.459, clip=0, loss_scale=8, train_wall=74, gb_free=16, wall=11135
2023-08-17 23:15:15 | INFO | train_inner | epoch 010:   1144 / 1474 loss=2.15, trans_loss=3.421, nll_loss=1.608, w2v_ctc_loss=1.225, task_loss=0, contrastive_loss=0.109, total=4034.12, n_correct=2464.11, ppl=3.05, accuracy=61.082, wps=16216.3, ups=1.35, wpb=12044.8, bsz=418.2, num_updates=14400, lr=0.000117851, gnorm=0.455, clip=0, loss_scale=8, train_wall=74, gb_free=15.5, wall=11209
2023-08-17 23:16:30 | INFO | train_inner | epoch 010:   1244 / 1474 loss=2.14, trans_loss=3.406, nll_loss=1.593, w2v_ctc_loss=1.216, task_loss=0, contrastive_loss=0.11, total=4107.11, n_correct=2517.55, ppl=3.02, accuracy=61.297, wps=16469.8, ups=1.34, wpb=12283.5, bsz=446.4, num_updates=14500, lr=0.000117444, gnorm=0.445, clip=0, loss_scale=8, train_wall=74, gb_free=15.1, wall=11284
2023-08-17 23:17:45 | INFO | train_inner | epoch 010:   1344 / 1474 loss=2.143, trans_loss=3.412, nll_loss=1.598, w2v_ctc_loss=1.211, task_loss=0, contrastive_loss=0.124, total=4143.63, n_correct=2546.24, ppl=3.03, accuracy=61.45, wps=16471.5, ups=1.33, wpb=12373.1, bsz=457, num_updates=14600, lr=0.000117041, gnorm=0.44, clip=0, loss_scale=8, train_wall=74, gb_free=16.6, wall=11359
2023-08-17 23:19:01 | INFO | train_inner | epoch 010:   1444 / 1474 loss=2.199, trans_loss=3.421, nll_loss=1.606, w2v_ctc_loss=1.191, task_loss=0, contrastive_loss=0.373, total=4183.87, n_correct=2561.82, ppl=3.04, accuracy=61.231, wps=16494, ups=1.32, wpb=12480.2, bsz=480.8, num_updates=14700, lr=0.000116642, gnorm=0.454, clip=0, loss_scale=8, train_wall=75, gb_free=13.3, wall=11434
2023-08-17 23:19:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 23:19:54 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.238 | trans_loss 5.32 | nll_loss 2.624 | w2v_ctc_loss 1.49 | task_loss 0 | contrastive_loss 0.312 | total 4003.4 | n_correct 2558 | ppl 6.16 | accuracy 63.896 | uer 21.458 | wer 23.217 | raw_wer 23.217 | bleu 19.67 | wps 1769.3 | wpb 4003.4 | bsz 141.8 | num_updates 14730 | best_bleu 19.67
2023-08-17 23:19:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14730 updates
2023-08-17 23:19:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 23:20:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 23:20:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 10 @ 14730 updates, score 19.67) (writing took 13.12787601799937 seconds)
2023-08-17 23:20:07 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-17 23:20:07 | INFO | train | epoch 010 | loss 2.161 | trans_loss 3.415 | nll_loss 1.6 | w2v_ctc_loss 1.211 | task_loss 0 | contrastive_loss 0.189 | total 4138.65 | n_correct 2534.56 | ppl 3.03 | accuracy 61.241 | wps 15151.7 | ups 1.23 | wpb 12355.8 | bsz 458.5 | num_updates 14730 | lr 0.000116524 | gnorm 0.457 | clip 0 | loss_scale 8 | train_wall 1094 | gb_free 17.1 | wall 11501
2023-08-17 23:20:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 23:20:07 | INFO | fairseq.trainer | begin training epoch 11
2023-08-17 23:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 23:21:06 | INFO | train_inner | epoch 011:     70 / 1474 loss=2.14, trans_loss=3.396, nll_loss=1.575, w2v_ctc_loss=1.191, task_loss=0, contrastive_loss=0.197, total=4162.14, n_correct=2576.88, ppl=2.98, accuracy=61.912, wps=9947.1, ups=0.8, wpb=12425.4, bsz=474.3, num_updates=14800, lr=0.000116248, gnorm=0.541, clip=0, loss_scale=8, train_wall=73, gb_free=16.4, wall=11559
2023-08-17 23:22:20 | INFO | train_inner | epoch 011:    170 / 1474 loss=2.107, trans_loss=3.393, nll_loss=1.573, w2v_ctc_loss=1.175, task_loss=0, contrastive_loss=0.122, total=4103.74, n_correct=2545.05, ppl=2.98, accuracy=62.018, wps=16445.2, ups=1.34, wpb=12261.3, bsz=450.5, num_updates=14900, lr=0.000115857, gnorm=0.46, clip=0, loss_scale=8, train_wall=74, gb_free=16.7, wall=11634
2023-08-17 23:23:35 | INFO | train_inner | epoch 011:    270 / 1474 loss=2.093, trans_loss=3.391, nll_loss=1.569, w2v_ctc_loss=1.166, task_loss=0, contrastive_loss=0.103, total=4114.56, n_correct=2552.87, ppl=2.97, accuracy=62.045, wps=16455.3, ups=1.34, wpb=12288.3, bsz=443.1, num_updates=15000, lr=0.00011547, gnorm=0.441, clip=0, loss_scale=8, train_wall=74, gb_free=15.5, wall=11709
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:0')
2023-08-17 23:24:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-17 23:24:27 | INFO | train_inner | epoch 011:    371 / 1474 loss=2.186, trans_loss=5.039, nll_loss=2.33, w2v_ctc_loss=0.879, task_loss=0, contrastive_loss=0.087, total=4105.43, n_correct=2552.41, ppl=5.03, accuracy=62.172, wps=15707, ups=1.91, wpb=8244.5, bsz=297.6, num_updates=15100, lr=0.000115087, gnorm=0.565, clip=0, loss_scale=4, train_wall=52, gb_free=14.4, wall=11761
2023-08-17 23:25:19 | INFO | train_inner | epoch 011:    471 / 1474 loss=2.218, trans_loss=5.079, nll_loss=2.364, w2v_ctc_loss=0.887, task_loss=0, contrastive_loss=0.21, total=4117.47, n_correct=2536.21, ppl=5.15, accuracy=61.596, wps=15867.9, ups=1.93, wpb=8234.9, bsz=303.7, num_updates=15200, lr=0.000114708, gnorm=0.64, clip=0, loss_scale=4, train_wall=51, gb_free=16.4, wall=11813
2023-08-17 23:26:11 | INFO | train_inner | epoch 011:    571 / 1474 loss=2.212, trans_loss=5.073, nll_loss=2.356, w2v_ctc_loss=0.893, task_loss=0, contrastive_loss=0.203, total=4070.21, n_correct=2513.54, ppl=5.12, accuracy=61.755, wps=15780.8, ups=1.94, wpb=8140.4, bsz=292.9, num_updates=15300, lr=0.000114332, gnorm=0.635, clip=0, loss_scale=4, train_wall=51, gb_free=13.5, wall=11865
2023-08-17 23:27:03 | INFO | train_inner | epoch 011:    671 / 1474 loss=2.215, trans_loss=5.063, nll_loss=2.344, w2v_ctc_loss=0.89, task_loss=0, contrastive_loss=0.261, total=4161.7, n_correct=2578.74, ppl=5.08, accuracy=61.964, wps=16011, ups=1.92, wpb=8323.4, bsz=311.8, num_updates=15400, lr=0.000113961, gnorm=0.612, clip=0, loss_scale=4, train_wall=51, gb_free=17.2, wall=11917
2023-08-17 23:27:55 | INFO | train_inner | epoch 011:    771 / 1474 loss=2.203, trans_loss=5.074, nll_loss=2.358, w2v_ctc_loss=0.902, task_loss=0, contrastive_loss=0.088, total=4151.24, n_correct=2569.48, ppl=5.13, accuracy=61.897, wps=16068.1, ups=1.94, wpb=8302.5, bsz=301, num_updates=15500, lr=0.000113592, gnorm=0.63, clip=0, loss_scale=4, train_wall=51, gb_free=16, wall=11968
2023-08-17 23:28:47 | INFO | train_inner | epoch 011:    871 / 1474 loss=2.196, trans_loss=5.07, nll_loss=2.353, w2v_ctc_loss=0.892, task_loss=0, contrastive_loss=0.076, total=4128.97, n_correct=2556.84, ppl=5.11, accuracy=61.924, wps=15732.9, ups=1.91, wpb=8257.9, bsz=294.6, num_updates=15600, lr=0.000113228, gnorm=0.589, clip=0, loss_scale=4, train_wall=52, gb_free=16.7, wall=12021
2023-08-17 23:29:39 | INFO | train_inner | epoch 011:    971 / 1474 loss=2.198, trans_loss=5.069, nll_loss=2.352, w2v_ctc_loss=0.895, task_loss=0, contrastive_loss=0.092, total=4144.6, n_correct=2568.83, ppl=5.11, accuracy=61.98, wps=15985.2, ups=1.93, wpb=8289.2, bsz=304.5, num_updates=15700, lr=0.000112867, gnorm=0.615, clip=0, loss_scale=4, train_wall=51, gb_free=17.9, wall=12073
2023-08-17 23:30:30 | INFO | train_inner | epoch 011:   1071 / 1474 loss=2.195, trans_loss=5.062, nll_loss=2.344, w2v_ctc_loss=0.889, task_loss=0, contrastive_loss=0.107, total=4153.33, n_correct=2581.01, ppl=5.08, accuracy=62.143, wps=16225.6, ups=1.95, wpb=8306.7, bsz=310.5, num_updates=15800, lr=0.000112509, gnorm=0.581, clip=0, loss_scale=4, train_wall=51, gb_free=15.9, wall=12124
2023-08-17 23:31:22 | INFO | train_inner | epoch 011:   1171 / 1474 loss=2.198, trans_loss=5.068, nll_loss=2.351, w2v_ctc_loss=0.893, task_loss=0, contrastive_loss=0.105, total=4177.49, n_correct=2590.43, ppl=5.1, accuracy=62.009, wps=16211.5, ups=1.94, wpb=8355, bsz=311.7, num_updates=15900, lr=0.000112154, gnorm=0.618, clip=0, loss_scale=4, train_wall=51, gb_free=17, wall=12175
2023-08-17 23:32:14 | INFO | train_inner | epoch 011:   1271 / 1474 loss=2.207, trans_loss=5.064, nll_loss=2.347, w2v_ctc_loss=0.899, task_loss=0, contrastive_loss=0.154, total=4150.45, n_correct=2572.65, ppl=5.09, accuracy=61.985, wps=15960.9, ups=1.92, wpb=8300.9, bsz=307.4, num_updates=16000, lr=0.000111803, gnorm=0.595, clip=0, loss_scale=4, train_wall=51, gb_free=16.7, wall=12227
2023-08-17 23:32:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:6')
2023-08-17 23:32:45 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.249 | trans_loss 5.297 | nll_loss 2.596 | w2v_ctc_loss 1.588 | task_loss 0 | contrastive_loss 0.304 | total 4003.4 | n_correct 2575.2 | ppl 6.05 | accuracy 64.325 | uer 21.488 | wer 23.351 | raw_wer 23.351 | bleu 20.02 | wps 1758.1 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 20.02
2023-08-17 23:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-17 23:32:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-17 23:32:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-17 23:32:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 20.02) (writing took 11.60607217400684 seconds)
2023-08-17 23:33:49 | INFO | train_inner | epoch 011:   1371 / 1474 loss=2.22, trans_loss=5.064, nll_loss=2.347, w2v_ctc_loss=0.886, task_loss=0, contrastive_loss=0.326, total=4191.95, n_correct=2599.37, ppl=5.09, accuracy=62.009, wps=8775.1, ups=1.05, wpb=8383.9, bsz=326.8, num_updates=16100, lr=0.000111456, gnorm=0.568, clip=0, loss_scale=4, train_wall=52, gb_free=15.8, wall=12323
2023-08-17 23:34:41 | INFO | train_inner | epoch 011:   1471 / 1474 loss=2.19, trans_loss=5.06, nll_loss=2.342, w2v_ctc_loss=0.885, task_loss=0, contrastive_loss=0.097, total=4172.29, n_correct=2596.43, ppl=5.07, accuracy=62.23, wps=16159.5, ups=1.94, wpb=8344.6, bsz=315.6, num_updates=16200, lr=0.000111111, gnorm=0.554, clip=0, loss_scale=4, train_wall=51, gb_free=16.4, wall=12374
2023-08-17 23:34:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 23:35:13 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.22 | trans_loss 5.287 | nll_loss 2.581 | w2v_ctc_loss 1.518 | task_loss 0 | contrastive_loss 0.304 | total 4003.4 | n_correct 2576.8 | ppl 5.98 | accuracy 64.365 | uer 21.511 | wer 23.601 | raw_wer 23.601 | bleu 19.89 | wps 1752.5 | wpb 4003.4 | bsz 141.8 | num_updates 16203 | best_bleu 20.02
2023-08-17 23:35:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16203 updates
2023-08-17 23:35:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_19.8900.pt
2023-08-17 23:35:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_19.8900.pt
2023-08-17 23:35:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_19.8900.pt (epoch 11 @ 16203 updates, score 19.89) (writing took 6.755298963020323 seconds)
2023-08-17 23:35:20 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-17 23:35:20 | INFO | train | epoch 011 | loss 2.179 | trans_loss 4.646 | nll_loss 2.154 | w2v_ctc_loss 0.962 | task_loss 0 | contrastive_loss 0.142 | total 4139.29 | n_correct 2565.8 | ppl 4.45 | accuracy 61.986 | wps 14562.1 | ups 1.61 | wpb 9027.7 | bsz 333.7 | num_updates 16203 | lr 0.000111101 | gnorm 0.572 | clip 0 | loss_scale 4 | train_wall 817 | gb_free 17.2 | wall 12414
2023-08-17 23:35:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 23:35:20 | INFO | fairseq.trainer | begin training epoch 12
2023-08-17 23:35:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 23:36:17 | INFO | train_inner | epoch 012:     97 / 1474 loss=2.171, trans_loss=5.022, nll_loss=2.291, w2v_ctc_loss=0.868, task_loss=0, contrastive_loss=0.127, total=4138.25, n_correct=2605.78, ppl=4.9, accuracy=62.968, wps=8631.5, ups=1.04, wpb=8276.5, bsz=312.6, num_updates=16300, lr=0.00011077, gnorm=0.558, clip=0, loss_scale=4, train_wall=50, gb_free=17, wall=12470
2023-08-17 23:37:08 | INFO | train_inner | epoch 012:    197 / 1474 loss=2.176, trans_loss=5.032, nll_loss=2.304, w2v_ctc_loss=0.881, task_loss=0, contrastive_loss=0.081, total=4126.75, n_correct=2585.13, ppl=4.94, accuracy=62.643, wps=16062.2, ups=1.95, wpb=8253.5, bsz=296.6, num_updates=16400, lr=0.000110432, gnorm=0.663, clip=0, loss_scale=4, train_wall=51, gb_free=16.6, wall=12522
2023-08-17 23:38:00 | INFO | train_inner | epoch 012:    297 / 1474 loss=2.177, trans_loss=5.033, nll_loss=2.306, w2v_ctc_loss=0.866, task_loss=0, contrastive_loss=0.12, total=4221.98, n_correct=2647.77, ppl=4.94, accuracy=62.714, wps=16399.6, ups=1.94, wpb=8444, bsz=326, num_updates=16500, lr=0.000110096, gnorm=0.616, clip=0, loss_scale=4, train_wall=51, gb_free=16.5, wall=12573
2023-08-17 23:38:52 | INFO | train_inner | epoch 012:    397 / 1474 loss=2.181, trans_loss=5.041, nll_loss=2.316, w2v_ctc_loss=0.882, task_loss=0, contrastive_loss=0.09, total=4136.43, n_correct=2584.42, ppl=4.98, accuracy=62.479, wps=15688, ups=1.9, wpb=8272.9, bsz=301.9, num_updates=16600, lr=0.000109764, gnorm=0.685, clip=0, loss_scale=4, train_wall=52, gb_free=15.9, wall=12626
2023-08-17 23:39:44 | INFO | train_inner | epoch 012:    497 / 1474 loss=2.188, trans_loss=5.05, nll_loss=2.328, w2v_ctc_loss=0.888, task_loss=0, contrastive_loss=0.104, total=4082.65, n_correct=2549.84, ppl=5.02, accuracy=62.456, wps=15789.7, ups=1.93, wpb=8165.3, bsz=297.7, num_updates=16700, lr=0.000109435, gnorm=0.814, clip=0, loss_scale=4, train_wall=51, gb_free=17.5, wall=12678
2023-08-17 23:40:36 | INFO | train_inner | epoch 012:    597 / 1474 loss=2.197, trans_loss=5.044, nll_loss=2.321, w2v_ctc_loss=0.894, task_loss=0, contrastive_loss=0.17, total=4217.4, n_correct=2631.17, ppl=5, accuracy=62.388, wps=16206.5, ups=1.92, wpb=8434.8, bsz=320.8, num_updates=16800, lr=0.000109109, gnorm=0.671, clip=0, loss_scale=4, train_wall=51, gb_free=16, wall=12730
2023-08-17 23:41:28 | INFO | train_inner | epoch 012:    697 / 1474 loss=2.183, trans_loss=5.029, nll_loss=2.301, w2v_ctc_loss=0.862, task_loss=0, contrastive_loss=0.252, total=4197.24, n_correct=2640.91, ppl=4.93, accuracy=62.92, wps=16319, ups=1.94, wpb=8394.5, bsz=323.6, num_updates=16900, lr=0.000108786, gnorm=0.573, clip=0, loss_scale=4, train_wall=51, gb_free=15.4, wall=12781
2023-08-17 23:42:19 | INFO | train_inner | epoch 012:    797 / 1474 loss=2.174, trans_loss=5.031, nll_loss=2.303, w2v_ctc_loss=0.879, task_loss=0, contrastive_loss=0.088, total=4083.9, n_correct=2561.92, ppl=4.94, accuracy=62.732, wps=15754.2, ups=1.93, wpb=8167.8, bsz=296.3, num_updates=17000, lr=0.000108465, gnorm=0.562, clip=0, loss_scale=4, train_wall=51, gb_free=13.1, wall=12833
2023-08-17 23:43:11 | INFO | train_inner | epoch 012:    897 / 1474 loss=2.179, trans_loss=5.032, nll_loss=2.305, w2v_ctc_loss=0.872, task_loss=0, contrastive_loss=0.142, total=4168.41, n_correct=2617.25, ppl=4.94, accuracy=62.788, wps=16143.2, ups=1.94, wpb=8336.8, bsz=306.2, num_updates=17100, lr=0.000108148, gnorm=0.578, clip=0, loss_scale=4, train_wall=51, gb_free=15.6, wall=12885
2023-08-17 23:44:03 | INFO | train_inner | epoch 012:    997 / 1474 loss=2.192, trans_loss=5.045, nll_loss=2.322, w2v_ctc_loss=0.893, task_loss=0, contrastive_loss=0.152, total=4121.91, n_correct=2571.8, ppl=5, accuracy=62.393, wps=15762.6, ups=1.91, wpb=8243.8, bsz=301.5, num_updates=17200, lr=0.000107833, gnorm=0.777, clip=1, loss_scale=8, train_wall=52, gb_free=16.2, wall=12937
2023-08-17 23:44:55 | INFO | train_inner | epoch 012:   1097 / 1474 loss=2.191, trans_loss=5.042, nll_loss=2.319, w2v_ctc_loss=0.882, task_loss=0, contrastive_loss=0.193, total=4055.97, n_correct=2536.84, ppl=4.99, accuracy=62.546, wps=15655.7, ups=1.93, wpb=8111.9, bsz=291.2, num_updates=17300, lr=0.000107521, gnorm=0.63, clip=0, loss_scale=8, train_wall=51, gb_free=12.5, wall=12989
2023-08-17 23:45:47 | INFO | train_inner | epoch 012:   1197 / 1474 loss=2.206, trans_loss=5.062, nll_loss=2.345, w2v_ctc_loss=0.906, task_loss=0, contrastive_loss=0.165, total=4187.55, n_correct=2603.8, ppl=5.08, accuracy=62.18, wps=16200.9, ups=1.93, wpb=8375.1, bsz=317.5, num_updates=17400, lr=0.000107211, gnorm=0.693, clip=0, loss_scale=8, train_wall=51, gb_free=16, wall=13041
2023-08-17 23:46:39 | INFO | train_inner | epoch 012:   1297 / 1474 loss=2.176, trans_loss=5.037, nll_loss=2.311, w2v_ctc_loss=0.886, task_loss=0, contrastive_loss=0.077, total=4075.32, n_correct=2553.88, ppl=4.96, accuracy=62.667, wps=15776, ups=1.94, wpb=8150.6, bsz=287, num_updates=17500, lr=0.000106904, gnorm=0.566, clip=0, loss_scale=8, train_wall=51, gb_free=17.2, wall=13092
2023-08-17 23:47:31 | INFO | train_inner | epoch 012:   1397 / 1474 loss=2.182, trans_loss=5.043, nll_loss=2.32, w2v_ctc_loss=0.869, task_loss=0, contrastive_loss=0.179, total=4137.07, n_correct=2591.65, ppl=4.99, accuracy=62.645, wps=15916.1, ups=1.92, wpb=8274.1, bsz=305.6, num_updates=17600, lr=0.0001066, gnorm=0.557, clip=0, loss_scale=8, train_wall=51, gb_free=17.2, wall=13144
2023-08-17 23:48:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 23:48:43 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.263 | nll_loss 2.55 | w2v_ctc_loss 1.529 | task_loss 0 | contrastive_loss 0.295 | total 4003.4 | n_correct 2591.7 | ppl 5.86 | accuracy 64.737 | uer 20.996 | wer 22.978 | raw_wer 22.978 | bleu 20.69 | wps 1670 | wpb 4003.4 | bsz 141.8 | num_updates 17677 | best_bleu 20.69
2023-08-17 23:48:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17677 updates
2023-08-17 23:48:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 23:48:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-17 23:48:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 12 @ 17677 updates, score 20.69) (writing took 11.960437494999496 seconds)
2023-08-17 23:48:55 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-17 23:48:55 | INFO | train | epoch 012 | loss 2.184 | trans_loss 5.039 | nll_loss 2.314 | w2v_ctc_loss 0.881 | task_loss 0 | contrastive_loss 0.137 | total 4138.65 | n_correct 2591.14 | ppl 4.97 | accuracy 62.608 | wps 14970.7 | ups 1.81 | wpb 8277.3 | bsz 305.7 | num_updates 17677 | lr 0.000106368 | gnorm 0.636 | clip 0.1 | loss_scale 8 | train_wall 755 | gb_free 13.1 | wall 13229
2023-08-17 23:48:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-17 23:48:55 | INFO | fairseq.trainer | begin training epoch 13
2023-08-17 23:48:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-17 23:49:14 | INFO | train_inner | epoch 013:     23 / 1474 loss=2.179, trans_loss=5.042, nll_loss=2.319, w2v_ctc_loss=0.886, task_loss=0, contrastive_loss=0.085, total=4092.72, n_correct=2564.79, ppl=4.99, accuracy=62.667, wps=7933.4, ups=0.97, wpb=8185.4, bsz=296.2, num_updates=17700, lr=0.000106299, gnorm=0.587, clip=0, loss_scale=8, train_wall=51, gb_free=16.4, wall=13247
2023-08-17 23:50:05 | INFO | train_inner | epoch 013:    123 / 1474 loss=2.163, trans_loss=5.012, nll_loss=2.279, w2v_ctc_loss=0.869, task_loss=0, contrastive_loss=0.099, total=4178.31, n_correct=2638.95, ppl=4.85, accuracy=63.158, wps=16290.9, ups=1.95, wpb=8356.6, bsz=304, num_updates=17800, lr=0.000106, gnorm=0.651, clip=0, loss_scale=8, train_wall=51, gb_free=16.8, wall=13299
2023-08-17 23:50:57 | INFO | train_inner | epoch 013:    223 / 1474 loss=2.189, trans_loss=5.022, nll_loss=2.293, w2v_ctc_loss=0.863, task_loss=0, contrastive_loss=0.317, total=4188.38, n_correct=2640.98, ppl=4.9, accuracy=63.055, wps=16167.6, ups=1.93, wpb=8376.8, bsz=326.5, num_updates=17900, lr=0.000105703, gnorm=0.695, clip=0, loss_scale=8, train_wall=51, gb_free=14.7, wall=13351
2023-08-17 23:51:49 | INFO | train_inner | epoch 013:    323 / 1474 loss=2.156, trans_loss=5.008, nll_loss=2.273, w2v_ctc_loss=0.862, task_loss=0, contrastive_loss=0.083, total=4101.73, n_correct=2598.19, ppl=4.83, accuracy=63.344, wps=15833.8, ups=1.93, wpb=8203.5, bsz=293.4, num_updates=18000, lr=0.000105409, gnorm=0.659, clip=0, loss_scale=8, train_wall=51, gb_free=17.7, wall=13402
2023-08-17 23:51:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-17 23:52:19 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.214 | trans_loss 5.279 | nll_loss 2.572 | w2v_ctc_loss 1.505 | task_loss 0 | contrastive_loss 0.313 | total 4003.4 | n_correct 2583 | ppl 5.95 | accuracy 64.52 | uer 21.233 | wer 23.157 | raw_wer 23.157 | bleu 20.27 | wps 1771.2 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 20.69
2023-08-17 23:52:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-17 23:52:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-17 23:52:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-17 23:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 20.27) (writing took 7.694376151019242 seconds)
2023-08-17 23:53:19 | INFO | train_inner | epoch 013:    423 / 1474 loss=2.164, trans_loss=5.011, nll_loss=2.278, w2v_ctc_loss=0.864, task_loss=0, contrastive_loss=0.132, total=4205.54, n_correct=2662.52, ppl=4.85, accuracy=63.31, wps=9325.4, ups=1.11, wpb=8411.1, bsz=323.5, num_updates=18100, lr=0.000105118, gnorm=0.569, clip=0, loss_scale=8, train_wall=51, gb_free=16.9, wall=13493
2023-08-17 23:54:12 | INFO | train_inner | epoch 013:    523 / 1474 loss=2.169, trans_loss=5.016, nll_loss=2.285, w2v_ctc_loss=0.864, task_loss=0, contrastive_loss=0.164, total=4185.31, n_correct=2641.35, ppl=4.87, accuracy=63.11, wps=15865.4, ups=1.9, wpb=8370.6, bsz=316.7, num_updates=18200, lr=0.000104828, gnorm=0.58, clip=0, loss_scale=8, train_wall=52, gb_free=17.1, wall=13545
2023-08-17 23:55:03 | INFO | train_inner | epoch 013:    623 / 1474 loss=2.155, trans_loss=5.011, nll_loss=2.279, w2v_ctc_loss=0.865, task_loss=0, contrastive_loss=0.079, total=4157.86, n_correct=2633.85, ppl=4.85, accuracy=63.346, wps=16180.4, ups=1.95, wpb=8315.7, bsz=306.4, num_updates=18300, lr=0.000104542, gnorm=0.62, clip=0, loss_scale=8, train_wall=51, gb_free=17.3, wall=13597
2023-08-17 23:55:54 | INFO | train_inner | epoch 013:    723 / 1474 loss=2.164, trans_loss=5.017, nll_loss=2.285, w2v_ctc_loss=0.876, task_loss=0, contrastive_loss=0.078, total=4099, n_correct=2585.29, ppl=4.87, accuracy=63.071, wps=15932.6, ups=1.94, wpb=8198, bsz=286.3, num_updates=18400, lr=0.000104257, gnorm=0.788, clip=1, loss_scale=8, train_wall=51, gb_free=16.2, wall=13648
2023-08-17 23:56:47 | INFO | train_inner | epoch 013:    823 / 1474 loss=2.174, trans_loss=5.024, nll_loss=2.295, w2v_ctc_loss=0.876, task_loss=0, contrastive_loss=0.128, total=4122.84, n_correct=2593.14, ppl=4.91, accuracy=62.897, wps=15793.7, ups=1.92, wpb=8245.7, bsz=305.7, num_updates=18500, lr=0.000103975, gnorm=0.602, clip=0, loss_scale=8, train_wall=52, gb_free=17.2, wall=13700
2023-08-17 23:57:38 | INFO | train_inner | epoch 013:    923 / 1474 loss=2.156, trans_loss=5.013, nll_loss=2.281, w2v_ctc_loss=0.86, task_loss=0, contrastive_loss=0.087, total=4100.74, n_correct=2592.38, ppl=4.86, accuracy=63.217, wps=15869.2, ups=1.93, wpb=8201.5, bsz=296.8, num_updates=18600, lr=0.000103695, gnorm=0.603, clip=0, loss_scale=8, train_wall=51, gb_free=16.1, wall=13752
2023-08-17 23:58:31 | INFO | train_inner | epoch 013:   1023 / 1474 loss=2.171, trans_loss=5.022, nll_loss=2.293, w2v_ctc_loss=0.873, task_loss=0, contrastive_loss=0.138, total=4080.72, n_correct=2567.19, ppl=4.9, accuracy=62.91, wps=15659.9, ups=1.92, wpb=8161.4, bsz=292.3, num_updates=18700, lr=0.000103418, gnorm=0.603, clip=0, loss_scale=8, train_wall=52, gb_free=17.5, wall=13804
2023-08-17 23:59:22 | INFO | train_inner | epoch 013:   1123 / 1474 loss=2.154, trans_loss=5.005, nll_loss=2.271, w2v_ctc_loss=0.854, task_loss=0, contrastive_loss=0.119, total=4103.17, n_correct=2601.34, ppl=4.83, accuracy=63.398, wps=15950.4, ups=1.94, wpb=8206.3, bsz=305.6, num_updates=18800, lr=0.000103142, gnorm=0.567, clip=0, loss_scale=8, train_wall=51, gb_free=17.7, wall=13856
2023-08-18 00:00:14 | INFO | train_inner | epoch 013:   1223 / 1474 loss=2.161, trans_loss=5.017, nll_loss=2.286, w2v_ctc_loss=0.87, task_loss=0, contrastive_loss=0.081, total=4124.88, n_correct=2607.92, ppl=4.88, accuracy=63.224, wps=16007.5, ups=1.94, wpb=8249.8, bsz=296.7, num_updates=18900, lr=0.000102869, gnorm=0.571, clip=0, loss_scale=8, train_wall=51, gb_free=17.7, wall=13907
2023-08-18 00:01:05 | INFO | train_inner | epoch 013:   1323 / 1474 loss=2.163, trans_loss=5.006, nll_loss=2.272, w2v_ctc_loss=0.861, task_loss=0, contrastive_loss=0.177, total=4108.18, n_correct=2607.53, ppl=4.83, accuracy=63.472, wps=15916.1, ups=1.94, wpb=8216.4, bsz=308.4, num_updates=19000, lr=0.000102598, gnorm=0.555, clip=0, loss_scale=8, train_wall=51, gb_free=16.4, wall=13959
2023-08-18 00:01:57 | INFO | train_inner | epoch 013:   1423 / 1474 loss=2.166, trans_loss=5.014, nll_loss=2.284, w2v_ctc_loss=0.853, task_loss=0, contrastive_loss=0.19, total=4171.47, n_correct=2637.31, ppl=4.87, accuracy=63.223, wps=16152.9, ups=1.94, wpb=8342.9, bsz=310.5, num_updates=19100, lr=0.000102329, gnorm=0.559, clip=0, loss_scale=8, train_wall=51, gb_free=15.4, wall=14010
2023-08-18 00:02:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 00:02:55 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.195 | trans_loss 5.262 | nll_loss 2.547 | w2v_ctc_loss 1.499 | task_loss 0 | contrastive_loss 0.292 | total 4003.4 | n_correct 2601.5 | ppl 5.84 | accuracy 64.982 | uer 21.004 | wer 23.023 | raw_wer 23.023 | bleu 20.44 | wps 1692.7 | wpb 4003.4 | bsz 141.8 | num_updates 19151 | best_bleu 20.69
2023-08-18 00:02:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19151 updates
2023-08-18 00:02:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_20.4402.pt
2023-08-18 00:02:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_20.4402.pt
2023-08-18 00:03:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_20.4402.pt (epoch 13 @ 19151 updates, score 20.44) (writing took 6.652470901986817 seconds)
2023-08-18 00:03:02 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-18 00:03:02 | INFO | train | epoch 013 | loss 2.164 | trans_loss 5.013 | nll_loss 2.281 | w2v_ctc_loss 0.865 | task_loss 0 | contrastive_loss 0.133 | total 4138.65 | n_correct 2616.39 | ppl 4.86 | accuracy 63.218 | wps 14408.3 | ups 1.74 | wpb 8277.3 | bsz 305.7 | num_updates 19151 | lr 0.000102193 | gnorm 0.612 | clip 0.1 | loss_scale 8 | train_wall 754 | gb_free 17.7 | wall 14076
2023-08-18 00:03:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 00:03:02 | INFO | fairseq.trainer | begin training epoch 14
2023-08-18 00:03:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 00:03:35 | INFO | train_inner | epoch 014:     49 / 1474 loss=2.137, trans_loss=4.981, nll_loss=2.241, w2v_ctc_loss=0.844, task_loss=0, contrastive_loss=0.091, total=4182.69, n_correct=2678.37, ppl=4.73, accuracy=64.035, wps=8496.6, ups=1.02, wpb=8365.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.521, clip=0, loss_scale=16, train_wall=52, gb_free=16.1, wall=14109
2023-08-18 00:04:27 | INFO | train_inner | epoch 014:    149 / 1474 loss=2.135, trans_loss=4.977, nll_loss=2.234, w2v_ctc_loss=0.848, task_loss=0, contrastive_loss=0.074, total=4086.4, n_correct=2611.9, ppl=4.71, accuracy=63.917, wps=15891.2, ups=1.94, wpb=8172.8, bsz=301.5, num_updates=19300, lr=0.000101797, gnorm=0.553, clip=0, loss_scale=16, train_wall=51, gb_free=17, wall=14160
2023-08-18 00:05:18 | INFO | train_inner | epoch 014:    249 / 1474 loss=2.146, trans_loss=4.989, nll_loss=2.249, w2v_ctc_loss=0.841, task_loss=0, contrastive_loss=0.177, total=4103.37, n_correct=2618.42, ppl=4.75, accuracy=63.811, wps=16016.6, ups=1.95, wpb=8206.7, bsz=294, num_updates=19400, lr=0.000101535, gnorm=0.56, clip=0, loss_scale=16, train_wall=51, gb_free=17.3, wall=14212
2023-08-18 00:06:10 | INFO | train_inner | epoch 014:    349 / 1474 loss=2.143, trans_loss=4.991, nll_loss=2.253, w2v_ctc_loss=0.84, task_loss=0, contrastive_loss=0.113, total=4168.35, n_correct=2658.14, ppl=4.77, accuracy=63.77, wps=16124.6, ups=1.93, wpb=8336.7, bsz=318.7, num_updates=19500, lr=0.000101274, gnorm=0.618, clip=0, loss_scale=16, train_wall=51, gb_free=16.3, wall=14263
2023-08-18 00:07:01 | INFO | train_inner | epoch 014:    449 / 1474 loss=2.141, trans_loss=4.993, nll_loss=2.255, w2v_ctc_loss=0.842, task_loss=0, contrastive_loss=0.093, total=4155.83, n_correct=2650.23, ppl=4.77, accuracy=63.771, wps=16121.6, ups=1.94, wpb=8311.7, bsz=306.7, num_updates=19600, lr=0.000101015, gnorm=0.6, clip=0, loss_scale=16, train_wall=51, gb_free=16, wall=14315
2023-08-18 00:07:53 | INFO | train_inner | epoch 014:    549 / 1474 loss=2.149, trans_loss=4.994, nll_loss=2.256, w2v_ctc_loss=0.864, task_loss=0, contrastive_loss=0.086, total=4064.87, n_correct=2582.12, ppl=4.78, accuracy=63.523, wps=15684.1, ups=1.93, wpb=8129.7, bsz=288.5, num_updates=19700, lr=0.000100759, gnorm=0.574, clip=0, loss_scale=16, train_wall=51, gb_free=17.8, wall=14367
2023-08-18 00:08:45 | INFO | train_inner | epoch 014:    649 / 1474 loss=2.156, trans_loss=5, nll_loss=2.264, w2v_ctc_loss=0.854, task_loss=0, contrastive_loss=0.151, total=4167.34, n_correct=2646.87, ppl=4.8, accuracy=63.515, wps=15963.1, ups=1.92, wpb=8334.7, bsz=307.8, num_updates=19800, lr=0.000100504, gnorm=0.697, clip=0, loss_scale=16, train_wall=52, gb_free=17.1, wall=14419
2023-08-18 00:09:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-18 00:09:37 | INFO | train_inner | epoch 014:    750 / 1474 loss=2.15, trans_loss=4.99, nll_loss=2.251, w2v_ctc_loss=0.865, task_loss=0, contrastive_loss=0.088, total=4125.55, n_correct=2624.81, ppl=4.76, accuracy=63.623, wps=15924.5, ups=1.93, wpb=8251.1, bsz=306.8, num_updates=19900, lr=0.000100251, gnorm=0.655, clip=0, loss_scale=8, train_wall=51, gb_free=16.9, wall=14471
2023-08-18 00:10:29 | INFO | train_inner | epoch 014:    850 / 1474 loss=2.159, trans_loss=4.987, nll_loss=2.248, w2v_ctc_loss=0.856, task_loss=0, contrastive_loss=0.199, total=4186.83, n_correct=2668.26, ppl=4.75, accuracy=63.73, wps=16192.6, ups=1.93, wpb=8373.7, bsz=321.3, num_updates=20000, lr=0.0001, gnorm=0.791, clip=0, loss_scale=8, train_wall=51, gb_free=16.2, wall=14522
2023-08-18 00:10:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 00:11:01 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.196 | trans_loss 5.254 | nll_loss 2.538 | w2v_ctc_loss 1.516 | task_loss 0 | contrastive_loss 0.298 | total 4003.4 | n_correct 2599.4 | ppl 5.81 | accuracy 64.93 | uer 20.325 | wer 22.091 | raw_wer 22.091 | bleu 21 | wps 1674 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21
2023-08-18 00:11:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-18 00:11:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-18 00:11:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-18 00:11:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.0) (writing took 14.299598543992033 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:0')
2023-08-18 00:12:07 | INFO | train_inner | epoch 014:    950 / 1474 loss=2.155, trans_loss=4.998, nll_loss=2.262, w2v_ctc_loss=0.856, task_loss=0, contrastive_loss=0.128, total=4166.07, n_correct=2643.45, ppl=4.8, accuracy=63.452, wps=8512.1, ups=1.02, wpb=8332.1, bsz=309.7, num_updates=20100, lr=9.97509e-05, gnorm=0.674, clip=0, loss_scale=8, train_wall=51, gb_free=16, wall=14620
2023-08-18 00:12:59 | INFO | train_inner | epoch 014:   1050 / 1474 loss=2.151, trans_loss=4.997, nll_loss=2.261, w2v_ctc_loss=0.857, task_loss=0, contrastive_loss=0.108, total=4137.97, n_correct=2631.49, ppl=4.79, accuracy=63.594, wps=15799.7, ups=1.91, wpb=8275.9, bsz=300.3, num_updates=20200, lr=9.95037e-05, gnorm=0.887, clip=1, loss_scale=8, train_wall=52, gb_free=17.6, wall=14673
2023-08-18 00:13:52 | INFO | train_inner | epoch 014:   1150 / 1474 loss=2.184, trans_loss=4.999, nll_loss=2.264, w2v_ctc_loss=0.865, task_loss=0, contrastive_loss=0.374, total=4232.08, n_correct=2687.79, ppl=4.8, accuracy=63.51, wps=15955.9, ups=1.89, wpb=8464.2, bsz=326.4, num_updates=20300, lr=9.92583e-05, gnorm=0.645, clip=0, loss_scale=8, train_wall=53, gb_free=15.8, wall=14726
2023-08-18 00:14:43 | INFO | train_inner | epoch 014:   1250 / 1474 loss=2.149, trans_loss=5.003, nll_loss=2.267, w2v_ctc_loss=0.864, task_loss=0, contrastive_loss=0.066, total=4022.82, n_correct=2549.46, ppl=4.81, accuracy=63.375, wps=15663.5, ups=1.95, wpb=8045.6, bsz=273.3, num_updates=20400, lr=9.90148e-05, gnorm=0.671, clip=0, loss_scale=8, train_wall=51, gb_free=16.1, wall=14777
2023-08-18 00:15:35 | INFO | train_inner | epoch 014:   1350 / 1474 loss=2.141, trans_loss=4.992, nll_loss=2.255, w2v_ctc_loss=0.847, task_loss=0, contrastive_loss=0.085, total=4198.44, n_correct=2677.89, ppl=4.77, accuracy=63.783, wps=16416.3, ups=1.96, wpb=8396.9, bsz=316.7, num_updates=20500, lr=9.8773e-05, gnorm=0.656, clip=0, loss_scale=8, train_wall=51, gb_free=17, wall=14828
2023-08-18 00:16:26 | INFO | train_inner | epoch 014:   1450 / 1474 loss=2.147, trans_loss=4.997, nll_loss=2.261, w2v_ctc_loss=0.845, task_loss=0, contrastive_loss=0.121, total=4138.32, n_correct=2632.82, ppl=4.79, accuracy=63.621, wps=15970.1, ups=1.93, wpb=8276.6, bsz=304.8, num_updates=20600, lr=9.85329e-05, gnorm=0.578, clip=0, loss_scale=8, train_wall=51, gb_free=11.1, wall=14880
2023-08-18 00:16:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:3')
2023-08-18 00:17:10 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.172 | trans_loss 5.24 | nll_loss 2.524 | w2v_ctc_loss 1.478 | task_loss 0 | contrastive_loss 0.289 | total 4003.4 | n_correct 2613.9 | ppl 5.75 | accuracy 65.292 | uer 20.208 | wer 21.998 | raw_wer 21.998 | bleu 21.04 | wps 1730.2 | wpb 4003.4 | bsz 141.8 | num_updates 20624 | best_bleu 21.04
2023-08-18 00:17:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20624 updates
2023-08-18 00:17:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 00:17:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 00:17:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 14 @ 20624 updates, score 21.04) (writing took 11.21679471101379 seconds)
2023-08-18 00:17:22 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-18 00:17:22 | INFO | train | epoch 014 | loss 2.15 | trans_loss 4.993 | nll_loss 2.256 | w2v_ctc_loss 0.853 | task_loss 0 | contrastive_loss 0.132 | total 4138.26 | n_correct 2634.06 | ppl 4.78 | accuracy 63.651 | wps 14179.1 | ups 1.71 | wpb 8276.5 | bsz 305.7 | num_updates 20624 | lr 9.84756e-05 | gnorm 0.649 | clip 0.1 | loss_scale 8 | train_wall 755 | gb_free 16.4 | wall 14936
2023-08-18 00:17:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 00:17:22 | INFO | fairseq.trainer | begin training epoch 15
2023-08-18 00:17:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 00:18:07 | INFO | train_inner | epoch 015:     76 / 1474 loss=2.139, trans_loss=4.977, nll_loss=2.236, w2v_ctc_loss=0.838, task_loss=0, contrastive_loss=0.168, total=4086.83, n_correct=2618.85, ppl=4.71, accuracy=64.08, wps=8096.7, ups=0.99, wpb=8173.7, bsz=301.6, num_updates=20700, lr=9.82946e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=51, gb_free=15.6, wall=14981
2023-08-18 00:19:00 | INFO | train_inner | epoch 015:    176 / 1474 loss=2.126, trans_loss=4.969, nll_loss=2.223, w2v_ctc_loss=0.836, task_loss=0, contrastive_loss=0.078, total=4115.38, n_correct=2645.76, ppl=4.67, accuracy=64.29, wps=15772.7, ups=1.92, wpb=8230.8, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.543, clip=0, loss_scale=8, train_wall=52, gb_free=16.6, wall=15033
2023-08-18 00:19:51 | INFO | train_inner | epoch 015:    276 / 1474 loss=2.125, trans_loss=4.97, nll_loss=2.225, w2v_ctc_loss=0.835, task_loss=0, contrastive_loss=0.072, total=4178.48, n_correct=2687.25, ppl=4.67, accuracy=64.312, wps=16266.2, ups=1.95, wpb=8357, bsz=309.5, num_updates=20900, lr=9.78232e-05, gnorm=0.562, clip=0, loss_scale=8, train_wall=51, gb_free=16.3, wall=15085
2023-08-18 00:20:42 | INFO | train_inner | epoch 015:    376 / 1474 loss=2.123, trans_loss=4.96, nll_loss=2.214, w2v_ctc_loss=0.829, task_loss=0, contrastive_loss=0.097, total=4176.34, n_correct=2687.86, ppl=4.64, accuracy=64.359, wps=16223.3, ups=1.94, wpb=8352.7, bsz=308.5, num_updates=21000, lr=9.759e-05, gnorm=0.568, clip=0, loss_scale=8, train_wall=51, gb_free=16.4, wall=15136
2023-08-18 00:20:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-18 00:21:35 | INFO | train_inner | epoch 015:    477 / 1474 loss=2.135, trans_loss=4.97, nll_loss=2.226, w2v_ctc_loss=0.827, task_loss=0, contrastive_loss=0.185, total=4074.68, n_correct=2613.36, ppl=4.68, accuracy=64.137, wps=15616.2, ups=1.92, wpb=8149.4, bsz=292.8, num_updates=21100, lr=9.73585e-05, gnorm=0.634, clip=0, loss_scale=4, train_wall=52, gb_free=16.7, wall=15188
2023-08-18 00:22:26 | INFO | train_inner | epoch 015:    577 / 1474 loss=2.128, trans_loss=4.969, nll_loss=2.224, w2v_ctc_loss=0.836, task_loss=0, contrastive_loss=0.099, total=4145.22, n_correct=2661.77, ppl=4.67, accuracy=64.213, wps=16114.7, ups=1.94, wpb=8290.4, bsz=300.4, num_updates=21200, lr=9.71286e-05, gnorm=0.559, clip=0, loss_scale=4, train_wall=51, gb_free=17, wall=15240
2023-08-18 00:23:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-18 00:23:19 | INFO | train_inner | epoch 015:    678 / 1474 loss=2.131, trans_loss=4.964, nll_loss=2.218, w2v_ctc_loss=0.835, task_loss=0, contrastive_loss=0.127, total=4122.03, n_correct=2648.13, ppl=4.65, accuracy=64.243, wps=15686.5, ups=1.9, wpb=8244.1, bsz=303.9, num_updates=21300, lr=9.69003e-05, gnorm=0.585, clip=0, loss_scale=2, train_wall=52, gb_free=17.3, wall=15292
2023-08-18 00:24:11 | INFO | train_inner | epoch 015:    778 / 1474 loss=2.136, trans_loss=4.979, nll_loss=2.237, w2v_ctc_loss=0.849, task_loss=0, contrastive_loss=0.086, total=4174.93, n_correct=2671.61, ppl=4.72, accuracy=63.992, wps=16103.5, ups=1.93, wpb=8349.9, bsz=304.2, num_updates=21400, lr=9.66736e-05, gnorm=0.674, clip=0, loss_scale=2, train_wall=51, gb_free=15.7, wall=15344
2023-08-18 00:25:02 | INFO | train_inner | epoch 015:    878 / 1474 loss=2.133, trans_loss=4.976, nll_loss=2.234, w2v_ctc_loss=0.849, task_loss=0, contrastive_loss=0.076, total=4050.9, n_correct=2596.06, ppl=4.7, accuracy=64.086, wps=15850.1, ups=1.96, wpb=8101.8, bsz=287.1, num_updates=21500, lr=9.64486e-05, gnorm=0.738, clip=1, loss_scale=2, train_wall=51, gb_free=15.8, wall=15395
2023-08-18 00:25:53 | INFO | train_inner | epoch 015:    978 / 1474 loss=2.138, trans_loss=4.978, nll_loss=2.237, w2v_ctc_loss=0.834, task_loss=0, contrastive_loss=0.159, total=4134.92, n_correct=2649.23, ppl=4.71, accuracy=64.07, wps=16029.9, ups=1.94, wpb=8269.8, bsz=304, num_updates=21600, lr=9.6225e-05, gnorm=0.615, clip=0, loss_scale=2, train_wall=51, gb_free=16.4, wall=15447
2023-08-18 00:26:46 | INFO | train_inner | epoch 015:   1078 / 1474 loss=2.158, trans_loss=4.979, nll_loss=2.239, w2v_ctc_loss=0.84, task_loss=0, contrastive_loss=0.319, total=4188.51, n_correct=2679.39, ppl=4.72, accuracy=63.97, wps=15987.7, ups=1.91, wpb=8377, bsz=326.1, num_updates=21700, lr=9.60031e-05, gnorm=0.655, clip=0, loss_scale=2, train_wall=52, gb_free=17.6, wall=15499
2023-08-18 00:27:37 | INFO | train_inner | epoch 015:   1178 / 1474 loss=2.122, trans_loss=4.965, nll_loss=2.222, w2v_ctc_loss=0.818, task_loss=0, contrastive_loss=0.123, total=4186.08, n_correct=2698.56, ppl=4.66, accuracy=64.465, wps=16249.1, ups=1.94, wpb=8372.2, bsz=328.3, num_updates=21800, lr=9.57826e-05, gnorm=0.564, clip=0, loss_scale=2, train_wall=51, gb_free=16.8, wall=15551
2023-08-18 00:28:29 | INFO | train_inner | epoch 015:   1278 / 1474 loss=2.132, trans_loss=4.968, nll_loss=2.223, w2v_ctc_loss=0.851, task_loss=0, contrastive_loss=0.079, total=4137.12, n_correct=2652.38, ppl=4.67, accuracy=64.112, wps=15852.2, ups=1.92, wpb=8274.2, bsz=300.7, num_updates=21900, lr=9.55637e-05, gnorm=0.656, clip=0, loss_scale=2, train_wall=52, gb_free=16.4, wall=15603
2023-08-18 00:29:21 | INFO | train_inner | epoch 015:   1378 / 1474 loss=2.121, trans_loss=4.967, nll_loss=2.222, w2v_ctc_loss=0.833, task_loss=0, contrastive_loss=0.067, total=4106.18, n_correct=2640.97, ppl=4.67, accuracy=64.317, wps=15932.1, ups=1.94, wpb=8212.4, bsz=294.9, num_updates=22000, lr=9.53463e-05, gnorm=0.597, clip=0, loss_scale=2, train_wall=51, gb_free=16.2, wall=15655
2023-08-18 00:29:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 00:29:52 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.162 | trans_loss 5.229 | nll_loss 2.506 | w2v_ctc_loss 1.473 | task_loss 0 | contrastive_loss 0.286 | total 4003.4 | n_correct 2617.6 | ppl 5.68 | accuracy 65.384 | uer 20.248 | wer 22.236 | raw_wer 22.236 | bleu 21.11 | wps 1713.8 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 21.11
2023-08-18 00:29:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-18 00:29:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-18 00:29:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-18 00:30:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 21.11) (writing took 12.887286019977182 seconds)
2023-08-18 00:30:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 00:31:27 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.16 | trans_loss 5.234 | nll_loss 2.516 | w2v_ctc_loss 1.445 | task_loss 0 | contrastive_loss 0.296 | total 4003.4 | n_correct 2613.9 | ppl 5.72 | accuracy 65.292 | uer 20.508 | wer 22.546 | raw_wer 22.546 | bleu 21.07 | wps 1761.4 | wpb 4003.4 | bsz 141.8 | num_updates 22096 | best_bleu 21.11
2023-08-18 00:31:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22096 updates
2023-08-18 00:31:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.0706.pt
2023-08-18 00:31:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.0706.pt
2023-08-18 00:31:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.0706.pt (epoch 15 @ 22096 updates, score 21.07) (writing took 8.484389157005353 seconds)
2023-08-18 00:31:36 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-18 00:31:36 | INFO | train | epoch 015 | loss 2.132 | trans_loss 4.971 | nll_loss 2.227 | w2v_ctc_loss 0.836 | task_loss 0 | contrastive_loss 0.128 | total 4137.5 | n_correct 2656.21 | ppl 4.68 | accuracy 64.199 | wps 14267.4 | ups 1.72 | wpb 8275 | bsz 305.4 | num_updates 22096 | lr 9.51389e-05 | gnorm 0.611 | clip 0.1 | loss_scale 2 | train_wall 754 | gb_free 16.9 | wall 15789
2023-08-18 00:31:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 00:31:36 | INFO | fairseq.trainer | begin training epoch 16
2023-08-18 00:31:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 00:31:44 | INFO | train_inner | epoch 016:      4 / 1474 loss=2.141, trans_loss=4.98, nll_loss=2.24, w2v_ctc_loss=0.838, task_loss=0, contrastive_loss=0.156, total=4144.75, n_correct=2655.82, ppl=4.73, accuracy=64.077, wps=5778.6, ups=0.7, wpb=8289.5, bsz=314.3, num_updates=22100, lr=9.51303e-05, gnorm=0.667, clip=0, loss_scale=2, train_wall=52, gb_free=16.3, wall=15798
2023-08-18 00:32:35 | INFO | train_inner | epoch 016:    104 / 1474 loss=2.117, trans_loss=4.951, nll_loss=2.202, w2v_ctc_loss=0.823, task_loss=0, contrastive_loss=0.099, total=4124.91, n_correct=2665.6, ppl=4.6, accuracy=64.622, wps=16145.1, ups=1.96, wpb=8249.8, bsz=315, num_updates=22200, lr=9.49158e-05, gnorm=0.644, clip=0, loss_scale=2, train_wall=51, gb_free=16.5, wall=15849
2023-08-18 00:33:27 | INFO | train_inner | epoch 016:    204 / 1474 loss=2.105, trans_loss=4.942, nll_loss=2.189, w2v_ctc_loss=0.815, task_loss=0, contrastive_loss=0.07, total=4109.75, n_correct=2665.02, ppl=4.56, accuracy=64.846, wps=15908.9, ups=1.94, wpb=8219.5, bsz=297.2, num_updates=22300, lr=9.47027e-05, gnorm=0.585, clip=0, loss_scale=2, train_wall=51, gb_free=17.2, wall=15901
2023-08-18 00:34:20 | INFO | train_inner | epoch 016:    304 / 1474 loss=2.128, trans_loss=4.957, nll_loss=2.209, w2v_ctc_loss=0.834, task_loss=0, contrastive_loss=0.146, total=4162.83, n_correct=2684.54, ppl=4.62, accuracy=64.488, wps=15891.2, ups=1.91, wpb=8325.7, bsz=308.6, num_updates=22400, lr=9.44911e-05, gnorm=0.68, clip=0, loss_scale=2, train_wall=52, gb_free=16.3, wall=15953
2023-08-18 00:35:11 | INFO | train_inner | epoch 016:    404 / 1474 loss=2.122, trans_loss=4.951, nll_loss=2.201, w2v_ctc_loss=0.829, task_loss=0, contrastive_loss=0.156, total=4064.71, n_correct=2623.97, ppl=4.6, accuracy=64.555, wps=15742.9, ups=1.94, wpb=8129.4, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.614, clip=0, loss_scale=2, train_wall=51, gb_free=15.6, wall=16005
2023-08-18 00:36:03 | INFO | train_inner | epoch 016:    504 / 1474 loss=2.114, trans_loss=4.953, nll_loss=2.204, w2v_ctc_loss=0.816, task_loss=0, contrastive_loss=0.105, total=4170.78, n_correct=2699.11, ppl=4.61, accuracy=64.715, wps=16066.3, ups=1.93, wpb=8341.6, bsz=319.1, num_updates=22600, lr=9.40721e-05, gnorm=0.546, clip=0, loss_scale=2, train_wall=51, gb_free=15.7, wall=16057
2023-08-18 00:36:54 | INFO | train_inner | epoch 016:    604 / 1474 loss=2.113, trans_loss=4.956, nll_loss=2.208, w2v_ctc_loss=0.823, task_loss=0, contrastive_loss=0.068, total=4128.84, n_correct=2668.5, ppl=4.62, accuracy=64.631, wps=16125, ups=1.95, wpb=8257.7, bsz=300.2, num_updates=22700, lr=9.38647e-05, gnorm=0.619, clip=0, loss_scale=2, train_wall=51, gb_free=12.1, wall=16108
2023-08-18 00:37:46 | INFO | train_inner | epoch 016:    704 / 1474 loss=2.111, trans_loss=4.952, nll_loss=2.202, w2v_ctc_loss=0.824, task_loss=0, contrastive_loss=0.069, total=4107.54, n_correct=2655.43, ppl=4.6, accuracy=64.648, wps=16007.6, ups=1.95, wpb=8215.1, bsz=299.6, num_updates=22800, lr=9.36586e-05, gnorm=0.579, clip=0, loss_scale=2, train_wall=51, gb_free=12.7, wall=16159
2023-08-18 00:38:38 | INFO | train_inner | epoch 016:    804 / 1474 loss=2.12, trans_loss=4.949, nll_loss=2.2, w2v_ctc_loss=0.813, task_loss=0, contrastive_loss=0.171, total=4180.18, n_correct=2700.74, ppl=4.59, accuracy=64.608, wps=16020.2, ups=1.92, wpb=8360.4, bsz=313, num_updates=22900, lr=9.34539e-05, gnorm=0.622, clip=0, loss_scale=2, train_wall=52, gb_free=16.3, wall=16211
2023-08-18 00:39:30 | INFO | train_inner | epoch 016:    904 / 1474 loss=2.109, trans_loss=4.95, nll_loss=2.2, w2v_ctc_loss=0.816, task_loss=0, contrastive_loss=0.079, total=4142.91, n_correct=2680.13, ppl=4.6, accuracy=64.692, wps=16019.4, ups=1.93, wpb=8285.8, bsz=304.1, num_updates=23000, lr=9.32505e-05, gnorm=0.574, clip=0, loss_scale=2, train_wall=51, gb_free=16.2, wall=16263
2023-08-18 00:40:21 | INFO | train_inner | epoch 016:   1004 / 1474 loss=2.127, trans_loss=4.959, nll_loss=2.212, w2v_ctc_loss=0.84, task_loss=0, contrastive_loss=0.119, total=4123.03, n_correct=2653.66, ppl=4.63, accuracy=64.362, wps=15980.8, ups=1.94, wpb=8246.1, bsz=301.2, num_updates=23100, lr=9.30484e-05, gnorm=0.676, clip=0, loss_scale=2, train_wall=51, gb_free=17.3, wall=16315
2023-08-18 00:41:13 | INFO | train_inner | epoch 016:   1104 / 1474 loss=2.126, trans_loss=4.966, nll_loss=2.222, w2v_ctc_loss=0.837, task_loss=0, contrastive_loss=0.098, total=4105.71, n_correct=2636.36, ppl=4.66, accuracy=64.212, wps=15872.5, ups=1.93, wpb=8211.4, bsz=294.9, num_updates=23200, lr=9.28477e-05, gnorm=0.639, clip=0, loss_scale=2, train_wall=51, gb_free=16.4, wall=16367
2023-08-18 00:42:05 | INFO | train_inner | epoch 016:   1204 / 1474 loss=2.127, trans_loss=4.959, nll_loss=2.213, w2v_ctc_loss=0.821, task_loss=0, contrastive_loss=0.189, total=4156.32, n_correct=2676.12, ppl=4.64, accuracy=64.387, wps=15913.2, ups=1.91, wpb=8312.6, bsz=305.8, num_updates=23300, lr=9.26482e-05, gnorm=0.566, clip=0, loss_scale=2, train_wall=52, gb_free=16.7, wall=16419
2023-08-18 00:42:58 | INFO | train_inner | epoch 016:   1304 / 1474 loss=2.13, trans_loss=4.957, nll_loss=2.21, w2v_ctc_loss=0.834, task_loss=0, contrastive_loss=0.169, total=4162.37, n_correct=2683.64, ppl=4.63, accuracy=64.474, wps=15856.3, ups=1.9, wpb=8324.7, bsz=315.3, num_updates=23400, lr=9.245e-05, gnorm=0.623, clip=0, loss_scale=4, train_wall=52, gb_free=16.7, wall=16471
2023-08-18 00:43:50 | INFO | train_inner | epoch 016:   1404 / 1474 loss=2.119, trans_loss=4.955, nll_loss=2.207, w2v_ctc_loss=0.829, task_loss=0, contrastive_loss=0.1, total=4193.81, n_correct=2709.73, ppl=4.62, accuracy=64.613, wps=16114.2, ups=1.92, wpb=8387.6, bsz=321.2, num_updates=23500, lr=9.22531e-05, gnorm=0.584, clip=0, loss_scale=4, train_wall=51, gb_free=16.9, wall=16523
2023-08-18 00:44:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 00:44:57 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.145 | trans_loss 5.217 | nll_loss 2.491 | w2v_ctc_loss 1.446 | task_loss 0 | contrastive_loss 0.287 | total 4003.4 | n_correct 2630 | ppl 5.62 | accuracy 65.694 | uer 20.261 | wer 22.065 | raw_wer 22.065 | bleu 21.15 | wps 1717.9 | wpb 4003.4 | bsz 141.8 | num_updates 23570 | best_bleu 21.15
2023-08-18 00:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23570 updates
2023-08-18 00:44:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 00:45:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 00:45:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 16 @ 23570 updates, score 21.15) (writing took 10.97987633899902 seconds)
2023-08-18 00:45:09 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-18 00:45:09 | INFO | train | epoch 016 | loss 2.12 | trans_loss 4.954 | nll_loss 2.205 | w2v_ctc_loss 0.825 | task_loss 0 | contrastive_loss 0.126 | total 4138.65 | n_correct 2672.03 | ppl 4.61 | accuracy 64.563 | wps 15008.2 | ups 1.81 | wpb 8277.3 | bsz 305.7 | num_updates 23570 | lr 9.2116e-05 | gnorm 0.609 | clip 0 | loss_scale 4 | train_wall 755 | gb_free 15.6 | wall 16602
2023-08-18 00:45:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 00:45:09 | INFO | fairseq.trainer | begin training epoch 17
2023-08-18 00:45:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 00:45:31 | INFO | train_inner | epoch 017:     30 / 1474 loss=2.116, trans_loss=4.938, nll_loss=2.185, w2v_ctc_loss=0.81, task_loss=0, contrastive_loss=0.233, total=4144.21, n_correct=2687.27, ppl=4.55, accuracy=64.844, wps=8168.3, ups=0.99, wpb=8288.4, bsz=301.1, num_updates=23600, lr=9.20575e-05, gnorm=0.558, clip=0, loss_scale=4, train_wall=51, gb_free=15.9, wall=16625
2023-08-18 00:46:22 | INFO | train_inner | epoch 017:    130 / 1474 loss=2.1, trans_loss=4.93, nll_loss=2.174, w2v_ctc_loss=0.817, task_loss=0, contrastive_loss=0.07, total=4109.25, n_correct=2673.42, ppl=4.51, accuracy=65.059, wps=16014.1, ups=1.95, wpb=8218.5, bsz=296.9, num_updates=23700, lr=9.1863e-05, gnorm=0.603, clip=0, loss_scale=4, train_wall=51, gb_free=16.8, wall=16676
2023-08-18 00:47:14 | INFO | train_inner | epoch 017:    230 / 1474 loss=2.114, trans_loss=4.927, nll_loss=2.171, w2v_ctc_loss=0.802, task_loss=0, contrastive_loss=0.233, total=4175, n_correct=2719.59, ppl=4.5, accuracy=65.14, wps=16132.7, ups=1.93, wpb=8350, bsz=319.3, num_updates=23800, lr=9.16698e-05, gnorm=0.532, clip=0, loss_scale=4, train_wall=51, gb_free=17.3, wall=16728
2023-08-18 00:48:07 | INFO | train_inner | epoch 017:    330 / 1474 loss=2.113, trans_loss=4.934, nll_loss=2.181, w2v_ctc_loss=0.806, task_loss=0, contrastive_loss=0.237, total=4159.09, n_correct=2702.3, ppl=4.53, accuracy=64.973, wps=15913, ups=1.91, wpb=8318.2, bsz=306, num_updates=23900, lr=9.14779e-05, gnorm=0.56, clip=0, loss_scale=4, train_wall=52, gb_free=16.9, wall=16780
2023-08-18 00:48:58 | INFO | train_inner | epoch 017:    430 / 1474 loss=2.098, trans_loss=4.933, nll_loss=2.178, w2v_ctc_loss=0.808, task_loss=0, contrastive_loss=0.07, total=4138.78, n_correct=2692.6, ppl=4.53, accuracy=65.058, wps=16004.2, ups=1.93, wpb=8277.6, bsz=305.3, num_updates=24000, lr=9.12871e-05, gnorm=0.672, clip=0, loss_scale=4, train_wall=51, gb_free=16.3, wall=16832
2023-08-18 00:48:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 00:49:29 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.161 | trans_loss 5.224 | nll_loss 2.5 | w2v_ctc_loss 1.481 | task_loss 0 | contrastive_loss 0.283 | total 4003.4 | n_correct 2626 | ppl 5.65 | accuracy 65.594 | uer 19.911 | wer 21.972 | raw_wer 21.972 | bleu 21.22 | wps 1747.5 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 21.22
2023-08-18 00:49:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-18 00:49:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-18 00:49:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-18 00:49:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 21.22) (writing took 11.754367935005575 seconds)
2023-08-18 00:50:34 | INFO | train_inner | epoch 017:    530 / 1474 loss=2.117, trans_loss=4.946, nll_loss=2.196, w2v_ctc_loss=0.826, task_loss=0, contrastive_loss=0.121, total=4189.98, n_correct=2708.65, ppl=4.58, accuracy=64.646, wps=8769.1, ups=1.05, wpb=8380, bsz=309.7, num_updates=24100, lr=9.10975e-05, gnorm=0.806, clip=0, loss_scale=4, train_wall=52, gb_free=16.5, wall=16927
2023-08-18 00:51:25 | INFO | train_inner | epoch 017:    630 / 1474 loss=2.102, trans_loss=4.94, nll_loss=2.188, w2v_ctc_loss=0.816, task_loss=0, contrastive_loss=0.066, total=4158.81, n_correct=2701.27, ppl=4.56, accuracy=64.953, wps=16099.8, ups=1.94, wpb=8317.6, bsz=300.1, num_updates=24200, lr=9.09091e-05, gnorm=0.613, clip=0, loss_scale=4, train_wall=51, gb_free=15.4, wall=16979
2023-08-18 00:52:17 | INFO | train_inner | epoch 017:    730 / 1474 loss=2.113, trans_loss=4.939, nll_loss=2.186, w2v_ctc_loss=0.825, task_loss=0, contrastive_loss=0.113, total=4174.65, n_correct=2707.72, ppl=4.55, accuracy=64.861, wps=16155.5, ups=1.93, wpb=8349.3, bsz=310.5, num_updates=24300, lr=9.07218e-05, gnorm=0.601, clip=0, loss_scale=4, train_wall=51, gb_free=12.1, wall=17031
2023-08-18 00:53:09 | INFO | train_inner | epoch 017:    830 / 1474 loss=2.113, trans_loss=4.946, nll_loss=2.195, w2v_ctc_loss=0.831, task_loss=0, contrastive_loss=0.081, total=4083.91, n_correct=2643.63, ppl=4.58, accuracy=64.733, wps=15867, ups=1.94, wpb=8167.8, bsz=294.5, num_updates=24400, lr=9.05357e-05, gnorm=0.772, clip=0, loss_scale=4, train_wall=51, gb_free=17, wall=17082
2023-08-18 00:54:00 | INFO | train_inner | epoch 017:    930 / 1474 loss=2.106, trans_loss=4.939, nll_loss=2.187, w2v_ctc_loss=0.82, task_loss=0, contrastive_loss=0.081, total=4114.87, n_correct=2669.15, ppl=4.55, accuracy=64.866, wps=15898.7, ups=1.93, wpb=8229.7, bsz=307.5, num_updates=24500, lr=9.03508e-05, gnorm=0.825, clip=1, loss_scale=4, train_wall=51, gb_free=17.8, wall=17134
2023-08-18 00:54:52 | INFO | train_inner | epoch 017:   1030 / 1474 loss=2.104, trans_loss=4.938, nll_loss=2.186, w2v_ctc_loss=0.82, task_loss=0, contrastive_loss=0.077, total=4091.03, n_correct=2657.72, ppl=4.55, accuracy=64.965, wps=15980.5, ups=1.95, wpb=8182.1, bsz=298.8, num_updates=24600, lr=9.0167e-05, gnorm=0.607, clip=0, loss_scale=4, train_wall=51, gb_free=15.8, wall=17185
2023-08-18 00:55:43 | INFO | train_inner | epoch 017:   1130 / 1474 loss=2.095, trans_loss=4.932, nll_loss=2.178, w2v_ctc_loss=0.801, task_loss=0, contrastive_loss=0.072, total=4112.54, n_correct=2679.54, ppl=4.52, accuracy=65.155, wps=16021.9, ups=1.95, wpb=8225.1, bsz=301.7, num_updates=24700, lr=8.99843e-05, gnorm=0.622, clip=0, loss_scale=4, train_wall=51, gb_free=15.8, wall=17237
2023-08-18 00:56:35 | INFO | train_inner | epoch 017:   1230 / 1474 loss=2.142, trans_loss=4.95, nll_loss=2.202, w2v_ctc_loss=0.811, task_loss=0, contrastive_loss=0.367, total=4171.58, n_correct=2691.24, ppl=4.6, accuracy=64.514, wps=15996.6, ups=1.92, wpb=8343.2, bsz=325.2, num_updates=24800, lr=8.98027e-05, gnorm=0.725, clip=1, loss_scale=4, train_wall=52, gb_free=16.6, wall=17289
2023-08-18 00:57:27 | INFO | train_inner | epoch 017:   1330 / 1474 loss=2.098, trans_loss=4.936, nll_loss=2.183, w2v_ctc_loss=0.803, task_loss=0, contrastive_loss=0.079, total=4138.5, n_correct=2689.51, ppl=4.54, accuracy=64.988, wps=15997.3, ups=1.93, wpb=8277, bsz=301.4, num_updates=24900, lr=8.96221e-05, gnorm=0.596, clip=0, loss_scale=4, train_wall=51, gb_free=15.9, wall=17341
2023-08-18 00:58:19 | INFO | train_inner | epoch 017:   1430 / 1474 loss=2.102, trans_loss=4.941, nll_loss=2.189, w2v_ctc_loss=0.813, task_loss=0, contrastive_loss=0.074, total=4118.28, n_correct=2674.22, ppl=4.56, accuracy=64.935, wps=15771.1, ups=1.91, wpb=8236.6, bsz=303.9, num_updates=25000, lr=8.94427e-05, gnorm=0.719, clip=1, loss_scale=4, train_wall=52, gb_free=16.1, wall=17393
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:0')
2023-08-18 00:58:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:3')
2023-08-18 00:59:13 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.145 | trans_loss 5.221 | nll_loss 2.496 | w2v_ctc_loss 1.434 | task_loss 0 | contrastive_loss 0.289 | total 4003.4 | n_correct 2623.2 | ppl 5.64 | accuracy 65.524 | uer 19.714 | wer 21.569 | raw_wer 21.569 | bleu 21.47 | wps 1752.8 | wpb 4003.4 | bsz 141.8 | num_updates 25044 | best_bleu 21.47
2023-08-18 00:59:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25044 updates
2023-08-18 00:59:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 00:59:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 00:59:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 17 @ 25044 updates, score 21.47) (writing took 11.595201338001061 seconds)
2023-08-18 00:59:25 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-18 00:59:25 | INFO | train | epoch 017 | loss 2.108 | trans_loss 4.937 | nll_loss 2.185 | w2v_ctc_loss 0.814 | task_loss 0 | contrastive_loss 0.124 | total 4138.65 | n_correct 2687.09 | ppl 4.55 | accuracy 64.927 | wps 14250.4 | ups 1.72 | wpb 8277.3 | bsz 305.7 | num_updates 25044 | lr 8.93641e-05 | gnorm 0.656 | clip 0.2 | loss_scale 4 | train_wall 755 | gb_free 16.3 | wall 17458
2023-08-18 00:59:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 00:59:25 | INFO | fairseq.trainer | begin training epoch 18
2023-08-18 00:59:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 01:00:01 | INFO | train_inner | epoch 018:     56 / 1474 loss=2.101, trans_loss=4.931, nll_loss=2.177, w2v_ctc_loss=0.818, task_loss=0, contrastive_loss=0.08, total=4131.1, n_correct=2685.9, ppl=4.52, accuracy=65.017, wps=8082.2, ups=0.98, wpb=8262.2, bsz=301.5, num_updates=25100, lr=8.92644e-05, gnorm=0.565, clip=0, loss_scale=4, train_wall=51, gb_free=16.9, wall=17495
2023-08-18 01:00:53 | INFO | train_inner | epoch 018:    156 / 1474 loss=2.094, trans_loss=4.908, nll_loss=2.147, w2v_ctc_loss=0.786, task_loss=0, contrastive_loss=0.199, total=4161.38, n_correct=2728.2, ppl=4.43, accuracy=65.56, wps=16169.1, ups=1.94, wpb=8322.8, bsz=315, num_updates=25200, lr=8.90871e-05, gnorm=0.552, clip=0, loss_scale=4, train_wall=51, gb_free=16.9, wall=17546
2023-08-18 01:01:45 | INFO | train_inner | epoch 018:    256 / 1474 loss=2.089, trans_loss=4.915, nll_loss=2.156, w2v_ctc_loss=0.804, task_loss=0, contrastive_loss=0.072, total=4153.17, n_correct=2715.71, ppl=4.46, accuracy=65.389, wps=16061.1, ups=1.93, wpb=8306.3, bsz=311.2, num_updates=25300, lr=8.89108e-05, gnorm=0.635, clip=0, loss_scale=4, train_wall=51, gb_free=17, wall=17598
2023-08-18 01:02:36 | INFO | train_inner | epoch 018:    356 / 1474 loss=2.09, trans_loss=4.921, nll_loss=2.162, w2v_ctc_loss=0.8, task_loss=0, contrastive_loss=0.086, total=4179.02, n_correct=2727.85, ppl=4.48, accuracy=65.275, wps=16195.7, ups=1.94, wpb=8358, bsz=302.1, num_updates=25400, lr=8.87357e-05, gnorm=0.551, clip=0, loss_scale=8, train_wall=51, gb_free=16.5, wall=17650
2023-08-18 01:03:29 | INFO | train_inner | epoch 018:    456 / 1474 loss=2.103, trans_loss=4.924, nll_loss=2.167, w2v_ctc_loss=0.804, task_loss=0, contrastive_loss=0.178, total=4069.37, n_correct=2652.47, ppl=4.49, accuracy=65.181, wps=15504.8, ups=1.91, wpb=8138.7, bsz=293.6, num_updates=25500, lr=8.85615e-05, gnorm=0.635, clip=0, loss_scale=8, train_wall=52, gb_free=15.7, wall=17702
2023-08-18 01:04:20 | INFO | train_inner | epoch 018:    556 / 1474 loss=2.084, trans_loss=4.908, nll_loss=2.147, w2v_ctc_loss=0.793, task_loss=0, contrastive_loss=0.087, total=4224.88, n_correct=2771.66, ppl=4.43, accuracy=65.603, wps=16485.7, ups=1.95, wpb=8449.8, bsz=330.4, num_updates=25600, lr=8.83883e-05, gnorm=0.629, clip=0, loss_scale=8, train_wall=51, gb_free=16.8, wall=17754
2023-08-18 01:05:11 | INFO | train_inner | epoch 018:    656 / 1474 loss=2.101, trans_loss=4.926, nll_loss=2.17, w2v_ctc_loss=0.807, task_loss=0, contrastive_loss=0.15, total=4087.72, n_correct=2666.49, ppl=4.5, accuracy=65.232, wps=15865.9, ups=1.94, wpb=8175.4, bsz=298.1, num_updates=25700, lr=8.82162e-05, gnorm=0.561, clip=0, loss_scale=8, train_wall=51, gb_free=16.6, wall=17805
2023-08-18 01:06:03 | INFO | train_inner | epoch 018:    756 / 1474 loss=2.11, trans_loss=4.924, nll_loss=2.168, w2v_ctc_loss=0.806, task_loss=0, contrastive_loss=0.244, total=4202.56, n_correct=2741.94, ppl=4.49, accuracy=65.245, wps=16182.9, ups=1.93, wpb=8405.1, bsz=322.9, num_updates=25800, lr=8.80451e-05, gnorm=0.554, clip=0, loss_scale=8, train_wall=51, gb_free=17.8, wall=17857
2023-08-18 01:06:55 | INFO | train_inner | epoch 018:    856 / 1474 loss=2.09, trans_loss=4.922, nll_loss=2.165, w2v_ctc_loss=0.802, task_loss=0, contrastive_loss=0.071, total=4181.64, n_correct=2728.72, ppl=4.48, accuracy=65.255, wps=16197.1, ups=1.94, wpb=8363.3, bsz=306.1, num_updates=25900, lr=8.7875e-05, gnorm=0.659, clip=1, loss_scale=8, train_wall=51, gb_free=15.8, wall=17909
2023-08-18 01:07:47 | INFO | train_inner | epoch 018:    956 / 1474 loss=2.086, trans_loss=4.918, nll_loss=2.159, w2v_ctc_loss=0.794, task_loss=0, contrastive_loss=0.076, total=4133.45, n_correct=2703.2, ppl=4.47, accuracy=65.398, wps=15971.7, ups=1.93, wpb=8266.9, bsz=312.7, num_updates=26000, lr=8.77058e-05, gnorm=0.562, clip=0, loss_scale=8, train_wall=51, gb_free=14.7, wall=17960
2023-08-18 01:07:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 01:08:18 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.13 | trans_loss 5.208 | nll_loss 2.478 | w2v_ctc_loss 1.411 | task_loss 0 | contrastive_loss 0.294 | total 4003.4 | n_correct 2638.4 | ppl 5.57 | accuracy 65.904 | uer 19.783 | wer 21.722 | raw_wer 21.722 | bleu 21.81 | wps 1744 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 21.81
2023-08-18 01:08:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-18 01:08:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-18 01:08:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-18 01:08:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 21.81) (writing took 12.633512567001162 seconds)
2023-08-18 01:09:23 | INFO | train_inner | epoch 018:   1056 / 1474 loss=2.086, trans_loss=4.918, nll_loss=2.16, w2v_ctc_loss=0.796, task_loss=0, contrastive_loss=0.072, total=4133.66, n_correct=2703.48, ppl=4.47, accuracy=65.402, wps=8592.3, ups=1.04, wpb=8267.3, bsz=298.3, num_updates=26100, lr=8.75376e-05, gnorm=0.574, clip=0, loss_scale=8, train_wall=51, gb_free=16.9, wall=18057
2023-08-18 01:10:15 | INFO | train_inner | epoch 018:   1156 / 1474 loss=2.102, trans_loss=4.916, nll_loss=2.157, w2v_ctc_loss=0.804, task_loss=0, contrastive_loss=0.182, total=4156.35, n_correct=2718.14, ppl=4.46, accuracy=65.397, wps=16069.9, ups=1.93, wpb=8312.7, bsz=315.8, num_updates=26200, lr=8.73704e-05, gnorm=0.651, clip=0, loss_scale=8, train_wall=51, gb_free=13.9, wall=18108
2023-08-18 01:11:06 | INFO | train_inner | epoch 018:   1256 / 1474 loss=2.09, trans_loss=4.929, nll_loss=2.174, w2v_ctc_loss=0.801, task_loss=0, contrastive_loss=0.067, total=4093.35, n_correct=2666.74, ppl=4.51, accuracy=65.148, wps=15952.7, ups=1.95, wpb=8186.7, bsz=288, num_updates=26300, lr=8.72041e-05, gnorm=0.598, clip=0, loss_scale=8, train_wall=51, gb_free=16.3, wall=18160
2023-08-18 01:11:58 | INFO | train_inner | epoch 018:   1356 / 1474 loss=2.102, trans_loss=4.929, nll_loss=2.174, w2v_ctc_loss=0.822, task_loss=0, contrastive_loss=0.091, total=4056.71, n_correct=2641.09, ppl=4.51, accuracy=65.104, wps=15762.7, ups=1.94, wpb=8113.4, bsz=289.2, num_updates=26400, lr=8.70388e-05, gnorm=0.566, clip=0, loss_scale=8, train_wall=51, gb_free=17.3, wall=18211
2023-08-18 01:12:50 | INFO | train_inner | epoch 018:   1456 / 1474 loss=2.093, trans_loss=4.924, nll_loss=2.168, w2v_ctc_loss=0.808, task_loss=0, contrastive_loss=0.077, total=4125.39, n_correct=2692.48, ppl=4.49, accuracy=65.266, wps=15783.9, ups=1.91, wpb=8250.8, bsz=299, num_updates=26500, lr=8.68744e-05, gnorm=0.568, clip=0, loss_scale=8, train_wall=52, gb_free=16.1, wall=18263
2023-08-18 01:12:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 01:13:30 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.14 | trans_loss 5.205 | nll_loss 2.477 | w2v_ctc_loss 1.46 | task_loss 0 | contrastive_loss 0.28 | total 4003.4 | n_correct 2640.6 | ppl 5.57 | accuracy 65.959 | uer 19.481 | wer 21.364 | raw_wer 21.364 | bleu 21.79 | wps 1741.1 | wpb 4003.4 | bsz 141.8 | num_updates 26518 | best_bleu 21.81
2023-08-18 01:13:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26518 updates
2023-08-18 01:13:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7905.pt
2023-08-18 01:13:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7905.pt
2023-08-18 01:13:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7905.pt (epoch 18 @ 26518 updates, score 21.79) (writing took 6.8747122090135235 seconds)
2023-08-18 01:13:38 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-18 01:13:38 | INFO | train | epoch 018 | loss 2.095 | trans_loss 4.92 | nll_loss 2.163 | w2v_ctc_loss 0.802 | task_loss 0 | contrastive_loss 0.121 | total 4138.65 | n_correct 2702.9 | ppl 4.48 | accuracy 65.309 | wps 14304.9 | ups 1.73 | wpb 8277.3 | bsz 305.7 | num_updates 26518 | lr 8.6845e-05 | gnorm 0.59 | clip 0.1 | loss_scale 8 | train_wall 755 | gb_free 16 | wall 18311
2023-08-18 01:13:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 01:13:38 | INFO | fairseq.trainer | begin training epoch 19
2023-08-18 01:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 01:14:27 | INFO | train_inner | epoch 019:     82 / 1474 loss=2.084, trans_loss=4.902, nll_loss=2.138, w2v_ctc_loss=0.794, task_loss=0, contrastive_loss=0.125, total=4098.8, n_correct=2691.38, ppl=4.4, accuracy=65.663, wps=8441.4, ups=1.03, wpb=8197.6, bsz=296.6, num_updates=26600, lr=8.6711e-05, gnorm=0.56, clip=0, loss_scale=8, train_wall=51, gb_free=17, wall=18361
2023-08-18 01:15:19 | INFO | train_inner | epoch 019:    182 / 1474 loss=2.089, trans_loss=4.902, nll_loss=2.138, w2v_ctc_loss=0.803, task_loss=0, contrastive_loss=0.122, total=4227.47, n_correct=2779.35, ppl=4.4, accuracy=65.745, wps=16308.6, ups=1.93, wpb=8454.9, bsz=325, num_updates=26700, lr=8.65485e-05, gnorm=0.659, clip=0, loss_scale=8, train_wall=51, gb_free=16.2, wall=18412
2023-08-18 01:16:10 | INFO | train_inner | epoch 019:    282 / 1474 loss=2.074, trans_loss=4.897, nll_loss=2.132, w2v_ctc_loss=0.794, task_loss=0, contrastive_loss=0.061, total=4188.96, n_correct=2755.96, ppl=4.38, accuracy=65.791, wps=16348.9, ups=1.95, wpb=8377.9, bsz=308.1, num_updates=26800, lr=8.63868e-05, gnorm=0.612, clip=0, loss_scale=8, train_wall=51, gb_free=17, wall=18464
2023-08-18 01:17:02 | INFO | train_inner | epoch 019:    382 / 1474 loss=2.085, trans_loss=4.898, nll_loss=2.134, w2v_ctc_loss=0.782, task_loss=0, contrastive_loss=0.17, total=4168.76, n_correct=2741.03, ppl=4.39, accuracy=65.752, wps=16164.3, ups=1.94, wpb=8337.5, bsz=310.6, num_updates=26900, lr=8.62261e-05, gnorm=0.559, clip=0, loss_scale=8, train_wall=51, gb_free=14.7, wall=18515
2023-08-18 01:17:54 | INFO | train_inner | epoch 019:    482 / 1474 loss=2.088, trans_loss=4.91, nll_loss=2.149, w2v_ctc_loss=0.808, task_loss=0, contrastive_loss=0.078, total=4107.91, n_correct=2690.11, ppl=4.44, accuracy=65.486, wps=15817.6, ups=1.93, wpb=8215.8, bsz=299.6, num_updates=27000, lr=8.60663e-05, gnorm=0.667, clip=0, loss_scale=8, train_wall=51, gb_free=12.2, wall=18567
2023-08-18 01:18:45 | INFO | train_inner | epoch 019:    582 / 1474 loss=2.079, trans_loss=4.9, nll_loss=2.137, w2v_ctc_loss=0.783, task_loss=0, contrastive_loss=0.138, total=4133.95, n_correct=2720.35, ppl=4.4, accuracy=65.805, wps=16040.5, ups=1.94, wpb=8267.9, bsz=306.3, num_updates=27100, lr=8.59074e-05, gnorm=0.552, clip=0, loss_scale=8, train_wall=51, gb_free=15.9, wall=18619
2023-08-18 01:19:37 | INFO | train_inner | epoch 019:    682 / 1474 loss=2.069, trans_loss=4.905, nll_loss=2.143, w2v_ctc_loss=0.771, task_loss=0, contrastive_loss=0.068, total=4199.37, n_correct=2766.26, ppl=4.42, accuracy=65.873, wps=16229.4, ups=1.93, wpb=8398.7, bsz=321.7, num_updates=27200, lr=8.57493e-05, gnorm=0.539, clip=0, loss_scale=8, train_wall=51, gb_free=17, wall=18670
2023-08-18 01:20:28 | INFO | train_inner | epoch 019:    782 / 1474 loss=2.081, trans_loss=4.904, nll_loss=2.141, w2v_ctc_loss=0.797, task_loss=0, contrastive_loss=0.082, total=4142.94, n_correct=2720.94, ppl=4.41, accuracy=65.677, wps=16070.5, ups=1.94, wpb=8285.9, bsz=305.4, num_updates=27300, lr=8.55921e-05, gnorm=0.638, clip=0, loss_scale=8, train_wall=51, gb_free=16.6, wall=18722
2023-08-18 01:21:20 | INFO | train_inner | epoch 019:    882 / 1474 loss=2.09, trans_loss=4.917, nll_loss=2.158, w2v_ctc_loss=0.806, task_loss=0, contrastive_loss=0.069, total=4153.23, n_correct=2713.95, ppl=4.46, accuracy=65.346, wps=16085.7, ups=1.94, wpb=8306.5, bsz=303.4, num_updates=27400, lr=8.54358e-05, gnorm=0.748, clip=1, loss_scale=8, train_wall=51, gb_free=16.9, wall=18774
2023-08-18 01:22:12 | INFO | train_inner | epoch 019:    982 / 1474 loss=2.101, trans_loss=4.915, nll_loss=2.156, w2v_ctc_loss=0.78, task_loss=0, contrastive_loss=0.296, total=4102.27, n_correct=2687.61, ppl=4.46, accuracy=65.515, wps=15707.5, ups=1.91, wpb=8204.5, bsz=308.7, num_updates=27500, lr=8.52803e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=52, gb_free=16, wall=18826
2023-08-18 01:22:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-18 01:23:05 | INFO | train_inner | epoch 019:   1083 / 1474 loss=2.083, trans_loss=4.913, nll_loss=2.153, w2v_ctc_loss=0.786, task_loss=0, contrastive_loss=0.109, total=4036.92, n_correct=2648.65, ppl=4.45, accuracy=65.611, wps=15302.2, ups=1.9, wpb=8073.8, bsz=291.7, num_updates=27600, lr=8.51257e-05, gnorm=0.559, clip=0, loss_scale=8, train_wall=52, gb_free=16.7, wall=18879
2023-08-18 01:23:57 | INFO | train_inner | epoch 019:   1183 / 1474 loss=2.099, trans_loss=4.914, nll_loss=2.155, w2v_ctc_loss=0.795, task_loss=0, contrastive_loss=0.191, total=4134.94, n_correct=2700.58, ppl=4.45, accuracy=65.311, wps=15831.3, ups=1.91, wpb=8269.9, bsz=305.9, num_updates=27700, lr=8.49719e-05, gnorm=0.608, clip=0, loss_scale=8, train_wall=52, gb_free=16.5, wall=18931
2023-08-18 01:24:49 | INFO | train_inner | epoch 019:   1283 / 1474 loss=2.082, trans_loss=4.914, nll_loss=2.154, w2v_ctc_loss=0.784, task_loss=0, contrastive_loss=0.089, total=4144.17, n_correct=2713.62, ppl=4.45, accuracy=65.48, wps=16104.2, ups=1.94, wpb=8288.3, bsz=301.4, num_updates=27800, lr=8.48189e-05, gnorm=0.568, clip=0, loss_scale=8, train_wall=51, gb_free=16.4, wall=18982
2023-08-18 01:25:41 | INFO | train_inner | epoch 019:   1383 / 1474 loss=2.083, trans_loss=4.911, nll_loss=2.151, w2v_ctc_loss=0.796, task_loss=0, contrastive_loss=0.076, total=4123.85, n_correct=2702.89, ppl=4.44, accuracy=65.543, wps=15921, ups=1.93, wpb=8247.7, bsz=300.7, num_updates=27900, lr=8.46668e-05, gnorm=0.582, clip=0, loss_scale=8, train_wall=51, gb_free=15.6, wall=19034
2023-08-18 01:26:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 01:26:58 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.134 | trans_loss 5.206 | nll_loss 2.476 | w2v_ctc_loss 1.441 | task_loss 0 | contrastive_loss 0.277 | total 4003.4 | n_correct 2641.8 | ppl 5.56 | accuracy 65.989 | uer 19.436 | wer 21.368 | raw_wer 21.368 | bleu 21.95 | wps 1770 | wpb 4003.4 | bsz 141.8 | num_updates 27991 | best_bleu 21.95
2023-08-18 01:26:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27991 updates
2023-08-18 01:26:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 01:27:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 01:27:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 19 @ 27991 updates, score 21.95) (writing took 12.943676904018503 seconds)
2023-08-18 01:27:12 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-18 01:27:12 | INFO | train | epoch 019 | loss 2.084 | trans_loss 4.907 | nll_loss 2.145 | w2v_ctc_loss 0.792 | task_loss 0 | contrastive_loss 0.119 | total 4138.63 | n_correct 2716 | ppl 4.42 | accuracy 65.626 | wps 14979.2 | ups 1.81 | wpb 8277.3 | bsz 305.6 | num_updates 27991 | lr 8.4529e-05 | gnorm 0.602 | clip 0.1 | loss_scale 8 | train_wall 754 | gb_free 17.4 | wall 19125
2023-08-18 01:27:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 01:27:12 | INFO | fairseq.trainer | begin training epoch 20
2023-08-18 01:27:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 01:27:23 | INFO | train_inner | epoch 020:      9 / 1474 loss=2.082, trans_loss=4.9, nll_loss=2.137, w2v_ctc_loss=0.784, task_loss=0, contrastive_loss=0.159, total=4119.95, n_correct=2708.81, ppl=4.4, accuracy=65.749, wps=8014.5, ups=0.97, wpb=8239.9, bsz=303.3, num_updates=28000, lr=8.45154e-05, gnorm=0.597, clip=0, loss_scale=8, train_wall=51, gb_free=17.1, wall=19137
2023-08-18 01:27:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 01:27:55 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.129 | trans_loss 5.208 | nll_loss 2.478 | w2v_ctc_loss 1.42 | task_loss 0 | contrastive_loss 0.279 | total 4003.4 | n_correct 2642.2 | ppl 5.57 | accuracy 65.999 | uer 19.322 | wer 21.297 | raw_wer 21.297 | bleu 21.74 | wps 1714.3 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 21.95
2023-08-18 01:27:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-18 01:27:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-18 01:27:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-18 01:28:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 21.74) (writing took 7.349768681015121 seconds)
2023-08-18 01:28:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-18 01:28:55 | INFO | train_inner | epoch 020:    110 / 1474 loss=2.057, trans_loss=4.879, nll_loss=2.11, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.082, total=4207.75, n_correct=2791.91, ppl=4.32, accuracy=66.352, wps=9176.9, ups=1.09, wpb=8415.5, bsz=316, num_updates=28100, lr=8.43649e-05, gnorm=0.537, clip=0, loss_scale=4, train_wall=52, gb_free=16.2, wall=19229
2023-08-18 01:29:47 | INFO | train_inner | epoch 020:    210 / 1474 loss=2.071, trans_loss=4.89, nll_loss=2.123, w2v_ctc_loss=0.776, task_loss=0, contrastive_loss=0.131, total=4155.61, n_correct=2739.03, ppl=4.36, accuracy=65.912, wps=16097.1, ups=1.94, wpb=8311.2, bsz=301.4, num_updates=28200, lr=8.42152e-05, gnorm=0.564, clip=0, loss_scale=4, train_wall=51, gb_free=16.9, wall=19280
2023-08-18 01:30:38 | INFO | train_inner | epoch 020:    310 / 1474 loss=2.064, trans_loss=4.884, nll_loss=2.115, w2v_ctc_loss=0.777, task_loss=0, contrastive_loss=0.071, total=4189.88, n_correct=2771.39, ppl=4.33, accuracy=66.145, wps=16304.6, ups=1.95, wpb=8379.8, bsz=324.9, num_updates=28300, lr=8.40663e-05, gnorm=0.576, clip=0, loss_scale=4, train_wall=51, gb_free=16.6, wall=19332
2023-08-18 01:31:30 | INFO | train_inner | epoch 020:    410 / 1474 loss=2.06, trans_loss=4.881, nll_loss=2.111, w2v_ctc_loss=0.771, task_loss=0, contrastive_loss=0.069, total=4101.46, n_correct=2715.38, ppl=4.32, accuracy=66.205, wps=15943.4, ups=1.94, wpb=8202.9, bsz=295.5, num_updates=28400, lr=8.39181e-05, gnorm=0.665, clip=0, loss_scale=4, train_wall=51, gb_free=15.9, wall=19383
2023-08-18 01:32:21 | INFO | train_inner | epoch 020:    510 / 1474 loss=2.076, trans_loss=4.897, nll_loss=2.133, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.156, total=4127.02, n_correct=2717.5, ppl=4.39, accuracy=65.847, wps=15976.2, ups=1.94, wpb=8254, bsz=303.8, num_updates=28500, lr=8.37708e-05, gnorm=0.628, clip=0, loss_scale=4, train_wall=51, gb_free=15.9, wall=19435
2023-08-18 01:33:13 | INFO | train_inner | epoch 020:    610 / 1474 loss=2.077, trans_loss=4.892, nll_loss=2.125, w2v_ctc_loss=0.778, task_loss=0, contrastive_loss=0.156, total=4079.57, n_correct=2688.07, ppl=4.36, accuracy=65.891, wps=15717.8, ups=1.93, wpb=8159.1, bsz=293.6, num_updates=28600, lr=8.36242e-05, gnorm=0.547, clip=0, loss_scale=4, train_wall=51, gb_free=17, wall=19487
2023-08-18 01:34:05 | INFO | train_inner | epoch 020:    710 / 1474 loss=2.073, trans_loss=4.897, nll_loss=2.132, w2v_ctc_loss=0.793, task_loss=0, contrastive_loss=0.063, total=4134.59, n_correct=2721.53, ppl=4.38, accuracy=65.823, wps=15978, ups=1.93, wpb=8269.2, bsz=299.7, num_updates=28700, lr=8.34784e-05, gnorm=0.736, clip=1, loss_scale=4, train_wall=51, gb_free=12, wall=19539
2023-08-18 01:34:56 | INFO | train_inner | epoch 020:    810 / 1474 loss=2.07, trans_loss=4.896, nll_loss=2.132, w2v_ctc_loss=0.783, task_loss=0, contrastive_loss=0.068, total=4157.39, n_correct=2738.03, ppl=4.38, accuracy=65.859, wps=16168.7, ups=1.94, wpb=8314.8, bsz=310.2, num_updates=28800, lr=8.33333e-05, gnorm=0.62, clip=0, loss_scale=4, train_wall=51, gb_free=13.5, wall=19590
2023-08-18 01:35:49 | INFO | train_inner | epoch 020:    910 / 1474 loss=2.103, trans_loss=4.899, nll_loss=2.136, w2v_ctc_loss=0.777, task_loss=0, contrastive_loss=0.355, total=4155.35, n_correct=2733.37, ppl=4.4, accuracy=65.78, wps=15848.8, ups=1.91, wpb=8310.7, bsz=322.5, num_updates=28900, lr=8.3189e-05, gnorm=0.632, clip=0, loss_scale=4, train_wall=52, gb_free=17.3, wall=19642
2023-08-18 01:36:41 | INFO | train_inner | epoch 020:   1010 / 1474 loss=2.077, trans_loss=4.899, nll_loss=2.135, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.141, total=4185.22, n_correct=2755.39, ppl=4.39, accuracy=65.836, wps=16078.4, ups=1.92, wpb=8370.4, bsz=311.8, num_updates=29000, lr=8.30455e-05, gnorm=0.681, clip=0, loss_scale=4, train_wall=52, gb_free=15.7, wall=19694
2023-08-18 01:37:33 | INFO | train_inner | epoch 020:   1110 / 1474 loss=2.091, trans_loss=4.9, nll_loss=2.137, w2v_ctc_loss=0.802, task_loss=0, contrastive_loss=0.149, total=4143.91, n_correct=2722.91, ppl=4.4, accuracy=65.709, wps=15881.6, ups=1.92, wpb=8287.8, bsz=308.6, num_updates=29100, lr=8.29027e-05, gnorm=0.778, clip=0, loss_scale=4, train_wall=52, gb_free=16.4, wall=19747
2023-08-18 01:38:25 | INFO | train_inner | epoch 020:   1210 / 1474 loss=2.081, trans_loss=4.897, nll_loss=2.132, w2v_ctc_loss=0.808, task_loss=0, contrastive_loss=0.063, total=4027.04, n_correct=2642.17, ppl=4.38, accuracy=65.611, wps=15638.5, ups=1.94, wpb=8054.1, bsz=282.7, num_updates=29200, lr=8.27606e-05, gnorm=0.837, clip=1, loss_scale=4, train_wall=51, gb_free=16.3, wall=19798
2023-08-18 01:39:16 | INFO | train_inner | epoch 020:   1310 / 1474 loss=2.071, trans_loss=4.899, nll_loss=2.135, w2v_ctc_loss=0.784, task_loss=0, contrastive_loss=0.066, total=4135.87, n_correct=2724.9, ppl=4.39, accuracy=65.885, wps=15968, ups=1.93, wpb=8271.7, bsz=300.8, num_updates=29300, lr=8.26192e-05, gnorm=0.602, clip=0, loss_scale=4, train_wall=51, gb_free=16.6, wall=19850
2023-08-18 01:40:08 | INFO | train_inner | epoch 020:   1410 / 1474 loss=2.069, trans_loss=4.895, nll_loss=2.13, w2v_ctc_loss=0.783, task_loss=0, contrastive_loss=0.063, total=4122.3, n_correct=2712.08, ppl=4.38, accuracy=65.79, wps=15998.7, ups=1.94, wpb=8244.6, bsz=294.5, num_updates=29400, lr=8.24786e-05, gnorm=0.589, clip=0, loss_scale=4, train_wall=51, gb_free=16.3, wall=19902
2023-08-18 01:40:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 01:41:13 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.115 | trans_loss 5.199 | nll_loss 2.468 | w2v_ctc_loss 1.393 | task_loss 0 | contrastive_loss 0.277 | total 4003.4 | n_correct 2636.8 | ppl 5.53 | accuracy 65.864 | uer 18.918 | wer 20.719 | raw_wer 20.719 | bleu 21.68 | wps 1683.6 | wpb 4003.4 | bsz 141.8 | num_updates 29464 | best_bleu 21.95
2023-08-18 01:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29464 updates
2023-08-18 01:41:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.6809.pt
2023-08-18 01:41:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.6809.pt
2023-08-18 01:41:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.6809.pt (epoch 20 @ 29464 updates, score 21.68) (writing took 6.481893753982149 seconds)
2023-08-18 01:41:19 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-18 01:41:19 | INFO | train | epoch 020 | loss 2.074 | trans_loss 4.893 | nll_loss 2.128 | w2v_ctc_loss 0.781 | task_loss 0 | contrastive_loss 0.117 | total 4139.04 | n_correct 2727.7 | ppl 4.37 | accuracy 65.902 | wps 14384.2 | ups 1.74 | wpb 8278.1 | bsz 305.7 | num_updates 29464 | lr 8.2389e-05 | gnorm 0.642 | clip 0.1 | loss_scale 4 | train_wall 754 | gb_free 16.1 | wall 19973
2023-08-18 01:41:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 01:41:20 | INFO | fairseq.trainer | begin training epoch 21
2023-08-18 01:41:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 01:41:45 | INFO | train_inner | epoch 021:     36 / 1474 loss=2.077, trans_loss=4.893, nll_loss=2.128, w2v_ctc_loss=0.769, task_loss=0, contrastive_loss=0.184, total=4143.81, n_correct=2731.74, ppl=4.37, accuracy=65.923, wps=8499.5, ups=1.03, wpb=8287.6, bsz=315, num_updates=29500, lr=8.23387e-05, gnorm=0.607, clip=0, loss_scale=4, train_wall=51, gb_free=15.6, wall=19999
2023-08-18 01:42:38 | INFO | train_inner | epoch 021:    136 / 1474 loss=2.073, trans_loss=4.875, nll_loss=2.104, w2v_ctc_loss=0.776, task_loss=0, contrastive_loss=0.178, total=4195.35, n_correct=2779.47, ppl=4.3, accuracy=66.251, wps=16097.2, ups=1.92, wpb=8390.7, bsz=319.8, num_updates=29600, lr=8.21995e-05, gnorm=0.662, clip=0, loss_scale=4, train_wall=52, gb_free=16.6, wall=20051
2023-08-18 01:43:29 | INFO | train_inner | epoch 021:    236 / 1474 loss=2.061, trans_loss=4.879, nll_loss=2.109, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.132, total=4148.29, n_correct=2749.76, ppl=4.31, accuracy=66.287, wps=16026, ups=1.93, wpb=8296.6, bsz=311.4, num_updates=29700, lr=8.2061e-05, gnorm=0.606, clip=0, loss_scale=4, train_wall=51, gb_free=12.8, wall=20103
2023-08-18 01:44:21 | INFO | train_inner | epoch 021:    336 / 1474 loss=2.072, trans_loss=4.883, nll_loss=2.115, w2v_ctc_loss=0.781, task_loss=0, contrastive_loss=0.135, total=4164.34, n_correct=2749.8, ppl=4.33, accuracy=66.032, wps=16037.6, ups=1.93, wpb=8328.7, bsz=312.6, num_updates=29800, lr=8.19232e-05, gnorm=0.575, clip=0, loss_scale=4, train_wall=51, gb_free=15.1, wall=20155
2023-08-18 01:45:12 | INFO | train_inner | epoch 021:    436 / 1474 loss=2.059, trans_loss=4.878, nll_loss=2.107, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.06, total=4170.15, n_correct=2764.16, ppl=4.31, accuracy=66.284, wps=16374, ups=1.96, wpb=8340.3, bsz=306.1, num_updates=29900, lr=8.17861e-05, gnorm=0.766, clip=1, loss_scale=4, train_wall=50, gb_free=16.7, wall=20206
2023-08-18 01:46:04 | INFO | train_inner | epoch 021:    536 / 1474 loss=2.055, trans_loss=4.872, nll_loss=2.1, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.056, total=4086.43, n_correct=2710.62, ppl=4.29, accuracy=66.332, wps=15819.5, ups=1.94, wpb=8172.9, bsz=295.4, num_updates=30000, lr=8.16497e-05, gnorm=0.585, clip=0, loss_scale=4, train_wall=51, gb_free=13.2, wall=20257
2023-08-18 01:46:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 01:46:35 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.148 | trans_loss 5.201 | nll_loss 2.469 | w2v_ctc_loss 1.503 | task_loss 0 | contrastive_loss 0.271 | total 4003.4 | n_correct 2639.7 | ppl 5.54 | accuracy 65.936 | uer 19.497 | wer 21.371 | raw_wer 21.371 | bleu 21.48 | wps 1750.2 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 21.95
2023-08-18 01:46:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-18 01:46:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-18 01:46:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-18 01:46:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 21.48) (writing took 7.349184536025859 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:0')
2023-08-18 01:47:35 | INFO | train_inner | epoch 021:    636 / 1474 loss=2.071, trans_loss=4.875, nll_loss=2.104, w2v_ctc_loss=0.764, task_loss=0, contrastive_loss=0.231, total=4214.93, n_correct=2791.16, ppl=4.3, accuracy=66.221, wps=9286.5, ups=1.1, wpb=8429.9, bsz=317.2, num_updates=30100, lr=8.15139e-05, gnorm=0.636, clip=0, loss_scale=4, train_wall=52, gb_free=17.1, wall=20348
2023-08-18 01:48:27 | INFO | train_inner | epoch 021:    736 / 1474 loss=2.063, trans_loss=4.884, nll_loss=2.116, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.092, total=4151.84, n_correct=2746.89, ppl=4.34, accuracy=66.161, wps=15884.5, ups=1.91, wpb=8303.7, bsz=307.5, num_updates=30200, lr=8.13788e-05, gnorm=0.601, clip=0, loss_scale=8, train_wall=52, gb_free=15.3, wall=20401
2023-08-18 01:49:19 | INFO | train_inner | epoch 021:    836 / 1474 loss=2.071, trans_loss=4.893, nll_loss=2.127, w2v_ctc_loss=0.776, task_loss=0, contrastive_loss=0.103, total=4075.02, n_correct=2689.15, ppl=4.37, accuracy=65.991, wps=15671.7, ups=1.92, wpb=8150, bsz=296.2, num_updates=30300, lr=8.12444e-05, gnorm=0.612, clip=0, loss_scale=8, train_wall=51, gb_free=16.8, wall=20453
2023-08-18 01:50:10 | INFO | train_inner | epoch 021:    936 / 1474 loss=2.062, trans_loss=4.88, nll_loss=2.111, w2v_ctc_loss=0.777, task_loss=0, contrastive_loss=0.079, total=4090.62, n_correct=2708.78, ppl=4.32, accuracy=66.219, wps=15940.1, ups=1.95, wpb=8181.2, bsz=300.5, num_updates=30400, lr=8.11107e-05, gnorm=0.619, clip=0, loss_scale=8, train_wall=51, gb_free=16, wall=20504
2023-08-18 01:51:02 | INFO | train_inner | epoch 021:   1036 / 1474 loss=2.063, trans_loss=4.888, nll_loss=2.121, w2v_ctc_loss=0.776, task_loss=0, contrastive_loss=0.073, total=4109.99, n_correct=2719.98, ppl=4.35, accuracy=66.18, wps=15974, ups=1.94, wpb=8220, bsz=298.5, num_updates=30500, lr=8.09776e-05, gnorm=0.595, clip=0, loss_scale=8, train_wall=51, gb_free=16.2, wall=20555
2023-08-18 01:51:53 | INFO | train_inner | epoch 021:   1136 / 1474 loss=2.068, trans_loss=4.884, nll_loss=2.116, w2v_ctc_loss=0.787, task_loss=0, contrastive_loss=0.078, total=4112.95, n_correct=2717.26, ppl=4.34, accuracy=66.066, wps=15981, ups=1.94, wpb=8225.9, bsz=293.6, num_updates=30600, lr=8.08452e-05, gnorm=0.723, clip=0, loss_scale=8, train_wall=51, gb_free=16.9, wall=20607
2023-08-18 01:52:45 | INFO | train_inner | epoch 021:   1236 / 1474 loss=2.067, trans_loss=4.882, nll_loss=2.114, w2v_ctc_loss=0.772, task_loss=0, contrastive_loss=0.127, total=4161.16, n_correct=2754.14, ppl=4.33, accuracy=66.187, wps=15944.3, ups=1.92, wpb=8322.3, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.626, clip=0, loss_scale=8, train_wall=52, gb_free=16.5, wall=20659
2023-08-18 01:53:37 | INFO | train_inner | epoch 021:   1336 / 1474 loss=2.061, trans_loss=4.88, nll_loss=2.112, w2v_ctc_loss=0.77, task_loss=0, contrastive_loss=0.089, total=4138.28, n_correct=2744.56, ppl=4.32, accuracy=66.321, wps=16138.9, ups=1.95, wpb=8276.6, bsz=309.9, num_updates=30800, lr=8.05823e-05, gnorm=0.636, clip=0, loss_scale=8, train_wall=51, gb_free=16.5, wall=20710
2023-08-18 01:53:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-18 01:54:29 | INFO | train_inner | epoch 021:   1437 / 1474 loss=2.084, trans_loss=4.894, nll_loss=2.129, w2v_ctc_loss=0.795, task_loss=0, contrastive_loss=0.139, total=4138.76, n_correct=2724.94, ppl=4.38, accuracy=65.84, wps=15743.8, ups=1.9, wpb=8277.5, bsz=305.8, num_updates=30900, lr=8.04518e-05, gnorm=0.629, clip=0, loss_scale=4, train_wall=52, gb_free=16.2, wall=20763
2023-08-18 01:54:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:1')
2023-08-18 01:55:20 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.122 | trans_loss 5.209 | nll_loss 2.479 | w2v_ctc_loss 1.392 | task_loss 0 | contrastive_loss 0.278 | total 4003.4 | n_correct 2632.9 | ppl 5.58 | accuracy 65.767 | uer 19.515 | wer 21.401 | raw_wer 21.401 | bleu 21.71 | wps 1690.2 | wpb 4003.4 | bsz 141.8 | num_updates 30937 | best_bleu 21.95
2023-08-18 01:55:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30937 updates
2023-08-18 01:55:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7103.pt
2023-08-18 01:55:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7103.pt
2023-08-18 01:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7103.pt (epoch 21 @ 30937 updates, score 21.71) (writing took 7.401129261997994 seconds)
2023-08-18 01:55:28 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-18 01:55:28 | INFO | train | epoch 021 | loss 2.067 | trans_loss 4.882 | nll_loss 2.113 | w2v_ctc_loss 0.775 | task_loss 0 | contrastive_loss 0.117 | total 4138.46 | n_correct 2738.28 | ppl 4.33 | accuracy 66.167 | wps 14358.6 | ups 1.73 | wpb 8276.9 | bsz 305.6 | num_updates 30937 | lr 8.04037e-05 | gnorm 0.631 | clip 0.1 | loss_scale 4 | train_wall 755 | gb_free 15.5 | wall 20822
2023-08-18 01:55:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 01:55:29 | INFO | fairseq.trainer | begin training epoch 22
2023-08-18 01:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 01:56:08 | INFO | train_inner | epoch 022:     63 / 1474 loss=2.056, trans_loss=4.87, nll_loss=2.098, w2v_ctc_loss=0.775, task_loss=0, contrastive_loss=0.059, total=4135.51, n_correct=2743.19, ppl=4.28, accuracy=66.333, wps=8379.2, ups=1.01, wpb=8271, bsz=299.9, num_updates=31000, lr=8.03219e-05, gnorm=0.65, clip=0, loss_scale=4, train_wall=51, gb_free=16.5, wall=20862
2023-08-18 01:57:00 | INFO | train_inner | epoch 022:    163 / 1474 loss=2.064, trans_loss=4.868, nll_loss=2.095, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.141, total=4107.71, n_correct=2727.98, ppl=4.27, accuracy=66.411, wps=15884.1, ups=1.93, wpb=8215.4, bsz=306.6, num_updates=31100, lr=8.01927e-05, gnorm=0.655, clip=0, loss_scale=4, train_wall=51, gb_free=14.9, wall=20913
2023-08-18 01:57:52 | INFO | train_inner | epoch 022:    263 / 1474 loss=2.044, trans_loss=4.857, nll_loss=2.081, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.081, total=4275.18, n_correct=2854.58, ppl=4.23, accuracy=66.771, wps=16481.6, ups=1.93, wpb=8550.4, bsz=330.4, num_updates=31200, lr=8.00641e-05, gnorm=0.548, clip=0, loss_scale=4, train_wall=51, gb_free=17, wall=20965
2023-08-18 01:58:44 | INFO | train_inner | epoch 022:    363 / 1474 loss=2.081, trans_loss=4.875, nll_loss=2.104, w2v_ctc_loss=0.778, task_loss=0, contrastive_loss=0.238, total=4180.65, n_correct=2767.65, ppl=4.3, accuracy=66.201, wps=16022.8, ups=1.92, wpb=8361.3, bsz=311.7, num_updates=31300, lr=7.99361e-05, gnorm=0.655, clip=0, loss_scale=4, train_wall=52, gb_free=17.2, wall=21017
2023-08-18 01:59:35 | INFO | train_inner | epoch 022:    463 / 1474 loss=2.063, trans_loss=4.873, nll_loss=2.101, w2v_ctc_loss=0.771, task_loss=0, contrastive_loss=0.121, total=4146.77, n_correct=2750.92, ppl=4.29, accuracy=66.339, wps=16028, ups=1.93, wpb=8293.5, bsz=300.2, num_updates=31400, lr=7.98087e-05, gnorm=0.546, clip=0, loss_scale=4, train_wall=51, gb_free=15.5, wall=21069
2023-08-18 02:00:27 | INFO | train_inner | epoch 022:    563 / 1474 loss=2.049, trans_loss=4.866, nll_loss=2.092, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.065, total=4136.18, n_correct=2753.55, ppl=4.26, accuracy=66.572, wps=16007.9, ups=1.94, wpb=8272.4, bsz=302.8, num_updates=31500, lr=7.96819e-05, gnorm=0.558, clip=0, loss_scale=4, train_wall=51, gb_free=16.6, wall=21121
2023-08-18 02:01:18 | INFO | train_inner | epoch 022:    663 / 1474 loss=2.05, trans_loss=4.859, nll_loss=2.083, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.153, total=4145.05, n_correct=2761.73, ppl=4.24, accuracy=66.627, wps=16262.3, ups=1.96, wpb=8290.1, bsz=311.7, num_updates=31600, lr=7.95557e-05, gnorm=0.571, clip=0, loss_scale=4, train_wall=50, gb_free=12.7, wall=21172
2023-08-18 02:02:11 | INFO | train_inner | epoch 022:    763 / 1474 loss=2.053, trans_loss=4.867, nll_loss=2.094, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.071, total=4170.48, n_correct=2771.93, ppl=4.27, accuracy=66.465, wps=15775.5, ups=1.89, wpb=8341, bsz=304.2, num_updates=31700, lr=7.94301e-05, gnorm=0.617, clip=0, loss_scale=4, train_wall=52, gb_free=13.5, wall=21225
2023-08-18 02:03:03 | INFO | train_inner | epoch 022:    863 / 1474 loss=2.053, trans_loss=4.875, nll_loss=2.104, w2v_ctc_loss=0.767, task_loss=0, contrastive_loss=0.057, total=4080.42, n_correct=2700.49, ppl=4.3, accuracy=66.182, wps=15820.5, ups=1.94, wpb=8160.8, bsz=291, num_updates=31800, lr=7.93052e-05, gnorm=0.59, clip=0, loss_scale=4, train_wall=51, gb_free=16.7, wall=21276
2023-08-18 02:03:54 | INFO | train_inner | epoch 022:    963 / 1474 loss=2.05, trans_loss=4.867, nll_loss=2.093, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.068, total=4131.43, n_correct=2746.24, ppl=4.27, accuracy=66.472, wps=16045.4, ups=1.94, wpb=8262.9, bsz=303.8, num_updates=31900, lr=7.91808e-05, gnorm=0.569, clip=0, loss_scale=4, train_wall=51, gb_free=16.8, wall=21328
2023-08-18 02:04:46 | INFO | train_inner | epoch 022:   1063 / 1474 loss=2.055, trans_loss=4.86, nll_loss=2.086, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.219, total=4157.6, n_correct=2774.45, ppl=4.25, accuracy=66.732, wps=16157.2, ups=1.94, wpb=8315.2, bsz=314.3, num_updates=32000, lr=7.90569e-05, gnorm=0.555, clip=0, loss_scale=4, train_wall=51, gb_free=17.1, wall=21379
2023-08-18 02:04:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 02:05:17 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.118 | trans_loss 5.197 | nll_loss 2.467 | w2v_ctc_loss 1.412 | task_loss 0 | contrastive_loss 0.274 | total 4003.4 | n_correct 2646.5 | ppl 5.53 | accuracy 66.106 | uer 19.138 | wer 20.957 | raw_wer 20.957 | bleu 21.91 | wps 1710.2 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 21.95
2023-08-18 02:05:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-18 02:05:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-18 02:05:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-18 02:05:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 21.91) (writing took 7.483072245988296 seconds)
2023-08-18 02:06:16 | INFO | train_inner | epoch 022:   1163 / 1474 loss=2.065, trans_loss=4.885, nll_loss=2.117, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.108, total=4100.88, n_correct=2713.84, ppl=4.34, accuracy=66.177, wps=9024.2, ups=1.1, wpb=8201.8, bsz=296.8, num_updates=32100, lr=7.89337e-05, gnorm=0.544, clip=0, loss_scale=4, train_wall=51, gb_free=17.3, wall=21470
2023-08-18 02:07:08 | INFO | train_inner | epoch 022:   1263 / 1474 loss=2.06, trans_loss=4.88, nll_loss=2.112, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.103, total=4171.08, n_correct=2767.32, ppl=4.32, accuracy=66.345, wps=16133.3, ups=1.93, wpb=8342.2, bsz=320.4, num_updates=32200, lr=7.8811e-05, gnorm=0.558, clip=0, loss_scale=4, train_wall=51, gb_free=12.5, wall=21522
2023-08-18 02:08:00 | INFO | train_inner | epoch 022:   1363 / 1474 loss=2.052, trans_loss=4.865, nll_loss=2.091, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.123, total=4069.83, n_correct=2706.75, ppl=4.26, accuracy=66.508, wps=15780, ups=1.94, wpb=8139.7, bsz=299.3, num_updates=32300, lr=7.86889e-05, gnorm=0.569, clip=0, loss_scale=4, train_wall=51, gb_free=15.6, wall=21573
2023-08-18 02:08:51 | INFO | train_inner | epoch 022:   1463 / 1474 loss=2.058, trans_loss=4.88, nll_loss=2.11, w2v_ctc_loss=0.772, task_loss=0, contrastive_loss=0.073, total=4087.39, n_correct=2709.89, ppl=4.32, accuracy=66.299, wps=15894, ups=1.94, wpb=8174.8, bsz=290.9, num_updates=32400, lr=7.85674e-05, gnorm=0.56, clip=0, loss_scale=4, train_wall=51, gb_free=15.6, wall=21625
2023-08-18 02:08:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 02:09:28 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.108 | trans_loss 5.192 | nll_loss 2.457 | w2v_ctc_loss 1.39 | task_loss 0 | contrastive_loss 0.274 | total 4003.4 | n_correct 2649.5 | ppl 5.49 | accuracy 66.181 | uer 18.95 | wer 20.849 | raw_wer 20.849 | bleu 21.52 | wps 1747.7 | wpb 4003.4 | bsz 141.8 | num_updates 32411 | best_bleu 21.95
2023-08-18 02:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32411 updates
2023-08-18 02:09:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.5205.pt
2023-08-18 02:09:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.5205.pt
2023-08-18 02:09:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.5205.pt (epoch 22 @ 32411 updates, score 21.52) (writing took 7.478804693004349 seconds)
2023-08-18 02:09:36 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-18 02:09:36 | INFO | train | epoch 022 | loss 2.057 | trans_loss 4.869 | nll_loss 2.097 | w2v_ctc_loss 0.764 | task_loss 0 | contrastive_loss 0.114 | total 4138.65 | n_correct 2749.66 | ppl 4.28 | accuracy 66.439 | wps 14399.8 | ups 1.74 | wpb 8277.3 | bsz 305.7 | num_updates 32411 | lr 7.85541e-05 | gnorm 0.582 | clip 0 | loss_scale 4 | train_wall 753 | gb_free 12 | wall 21669
2023-08-18 02:09:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 02:09:36 | INFO | fairseq.trainer | begin training epoch 23
2023-08-18 02:09:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 02:10:29 | INFO | train_inner | epoch 023:     89 / 1474 loss=2.04, trans_loss=4.85, nll_loss=2.072, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.064, total=4093.48, n_correct=2735.93, ppl=4.2, accuracy=66.836, wps=8365.1, ups=1.02, wpb=8187, bsz=300.7, num_updates=32500, lr=7.84465e-05, gnorm=0.593, clip=0, loss_scale=4, train_wall=51, gb_free=16.3, wall=21723
2023-08-18 02:11:21 | INFO | train_inner | epoch 023:    189 / 1474 loss=2.039, trans_loss=4.848, nll_loss=2.068, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.065, total=4117.93, n_correct=2751.67, ppl=4.19, accuracy=66.822, wps=15980, ups=1.94, wpb=8235.9, bsz=295.9, num_updates=32600, lr=7.8326e-05, gnorm=0.61, clip=0, loss_scale=4, train_wall=51, gb_free=15.9, wall=21774
2023-08-18 02:12:13 | INFO | train_inner | epoch 023:    289 / 1474 loss=2.051, trans_loss=4.861, nll_loss=2.086, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.136, total=4142.43, n_correct=2757.98, ppl=4.25, accuracy=66.579, wps=15784.2, ups=1.91, wpb=8284.9, bsz=303.4, num_updates=32700, lr=7.82062e-05, gnorm=0.578, clip=0, loss_scale=4, train_wall=52, gb_free=16.7, wall=21827
2023-08-18 02:13:05 | INFO | train_inner | epoch 023:    389 / 1474 loss=2.031, trans_loss=4.843, nll_loss=2.061, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.055, total=4115.12, n_correct=2757.66, ppl=4.17, accuracy=67.013, wps=15847.9, ups=1.93, wpb=8230.2, bsz=294.4, num_updates=32800, lr=7.80869e-05, gnorm=0.556, clip=0, loss_scale=4, train_wall=51, gb_free=13.5, wall=21879
2023-08-18 02:13:57 | INFO | train_inner | epoch 023:    489 / 1474 loss=2.046, trans_loss=4.856, nll_loss=2.08, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.112, total=4156.86, n_correct=2777.91, ppl=4.23, accuracy=66.827, wps=16087.9, ups=1.94, wpb=8313.7, bsz=312.1, num_updates=32900, lr=7.79681e-05, gnorm=0.6, clip=0, loss_scale=8, train_wall=51, gb_free=15.3, wall=21930
2023-08-18 02:14:48 | INFO | train_inner | epoch 023:    589 / 1474 loss=2.039, trans_loss=4.85, nll_loss=2.072, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.06, total=4172.99, n_correct=2795.83, ppl=4.2, accuracy=66.998, wps=16297.3, ups=1.95, wpb=8346, bsz=316.1, num_updates=33000, lr=7.78499e-05, gnorm=0.606, clip=0, loss_scale=8, train_wall=51, gb_free=16, wall=21982
2023-08-18 02:15:39 | INFO | train_inner | epoch 023:    689 / 1474 loss=2.045, trans_loss=4.858, nll_loss=2.083, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.097, total=4135.85, n_correct=2760.75, ppl=4.24, accuracy=66.752, wps=16073.8, ups=1.94, wpb=8271.7, bsz=301.9, num_updates=33100, lr=7.77322e-05, gnorm=0.584, clip=0, loss_scale=8, train_wall=51, gb_free=14.3, wall=22033
2023-08-18 02:16:32 | INFO | train_inner | epoch 023:    789 / 1474 loss=2.045, trans_loss=4.858, nll_loss=2.082, w2v_ctc_loss=0.758, task_loss=0, contrastive_loss=0.078, total=4155.54, n_correct=2772.25, ppl=4.23, accuracy=66.712, wps=15923.4, ups=1.92, wpb=8311.1, bsz=306.6, num_updates=33200, lr=7.76151e-05, gnorm=0.555, clip=0, loss_scale=8, train_wall=52, gb_free=16.8, wall=22085
2023-08-18 02:17:23 | INFO | train_inner | epoch 023:    889 / 1474 loss=2.049, trans_loss=4.852, nll_loss=2.075, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.155, total=4180.56, n_correct=2796.4, ppl=4.21, accuracy=66.891, wps=16139.9, ups=1.93, wpb=8361.1, bsz=324.5, num_updates=33300, lr=7.74984e-05, gnorm=0.628, clip=0, loss_scale=8, train_wall=51, gb_free=16.5, wall=22137
2023-08-18 02:18:15 | INFO | train_inner | epoch 023:    989 / 1474 loss=2.07, trans_loss=4.858, nll_loss=2.083, w2v_ctc_loss=0.761, task_loss=0, contrastive_loss=0.312, total=4163.63, n_correct=2773.25, ppl=4.24, accuracy=66.607, wps=16046.7, ups=1.93, wpb=8327.3, bsz=309.2, num_updates=33400, lr=7.73823e-05, gnorm=0.574, clip=0, loss_scale=8, train_wall=51, gb_free=12, wall=22189
2023-08-18 02:19:07 | INFO | train_inner | epoch 023:   1089 / 1474 loss=2.046, trans_loss=4.863, nll_loss=2.088, w2v_ctc_loss=0.761, task_loss=0, contrastive_loss=0.066, total=4094.62, n_correct=2726.8, ppl=4.25, accuracy=66.595, wps=15873.2, ups=1.94, wpb=8189.2, bsz=291.3, num_updates=33500, lr=7.72667e-05, gnorm=0.562, clip=0, loss_scale=8, train_wall=51, gb_free=17.5, wall=22241
2023-08-18 02:19:59 | INFO | train_inner | epoch 023:   1189 / 1474 loss=2.047, trans_loss=4.865, nll_loss=2.091, w2v_ctc_loss=0.764, task_loss=0, contrastive_loss=0.061, total=4161.7, n_correct=2769.66, ppl=4.26, accuracy=66.551, wps=16047.2, ups=1.93, wpb=8323.4, bsz=309.2, num_updates=33600, lr=7.71517e-05, gnorm=0.631, clip=0, loss_scale=8, train_wall=51, gb_free=16.9, wall=22292
2023-08-18 02:20:50 | INFO | train_inner | epoch 023:   1289 / 1474 loss=2.044, trans_loss=4.859, nll_loss=2.084, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.074, total=4133.96, n_correct=2757.95, ppl=4.24, accuracy=66.714, wps=16071.5, ups=1.94, wpb=8267.9, bsz=309.3, num_updates=33700, lr=7.70371e-05, gnorm=0.641, clip=0, loss_scale=8, train_wall=51, gb_free=16.8, wall=22344
2023-08-18 02:21:43 | INFO | train_inner | epoch 023:   1389 / 1474 loss=2.06, trans_loss=4.872, nll_loss=2.1, w2v_ctc_loss=0.76, task_loss=0, contrastive_loss=0.148, total=4159.95, n_correct=2763.61, ppl=4.29, accuracy=66.434, wps=15774.4, ups=1.9, wpb=8319.9, bsz=308.8, num_updates=33800, lr=7.69231e-05, gnorm=0.625, clip=0, loss_scale=8, train_wall=52, gb_free=11.2, wall=22397
2023-08-18 02:22:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 02:22:58 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.104 | trans_loss 5.19 | nll_loss 2.455 | w2v_ctc_loss 1.383 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2654.2 | ppl 5.48 | accuracy 66.299 | uer 18.286 | wer 19.906 | raw_wer 19.906 | bleu 22 | wps 1768.5 | wpb 4003.4 | bsz 141.8 | num_updates 33885 | best_bleu 22
2023-08-18 02:22:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33885 updates
2023-08-18 02:22:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 02:23:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 02:23:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 23 @ 33885 updates, score 22.0) (writing took 11.500843420013553 seconds)
2023-08-18 02:23:09 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-18 02:23:09 | INFO | train | epoch 023 | loss 2.047 | trans_loss 4.857 | nll_loss 2.081 | w2v_ctc_loss 0.755 | task_loss 0 | contrastive_loss 0.112 | total 4138.65 | n_correct 2761.92 | ppl 4.23 | accuracy 66.735 | wps 14997.1 | ups 1.81 | wpb 8277.3 | bsz 305.7 | num_updates 33885 | lr 7.68265e-05 | gnorm 0.596 | clip 0 | loss_scale 8 | train_wall 755 | gb_free 13.9 | wall 22483
2023-08-18 02:23:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 02:23:09 | INFO | fairseq.trainer | begin training epoch 24
2023-08-18 02:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 02:23:24 | INFO | train_inner | epoch 024:     15 / 1474 loss=2.064, trans_loss=4.865, nll_loss=2.091, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.247, total=4099.91, n_correct=2733.11, ppl=4.26, accuracy=66.663, wps=8080.1, ups=0.99, wpb=8199.8, bsz=308.7, num_updates=33900, lr=7.68095e-05, gnorm=0.596, clip=0, loss_scale=8, train_wall=51, gb_free=17, wall=22498
2023-08-18 02:24:16 | INFO | train_inner | epoch 024:    115 / 1474 loss=2.037, trans_loss=4.834, nll_loss=2.051, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.158, total=4147.74, n_correct=2786.64, ppl=4.14, accuracy=67.185, wps=16149.4, ups=1.95, wpb=8295.5, bsz=317.7, num_updates=34000, lr=7.66965e-05, gnorm=0.639, clip=0, loss_scale=8, train_wall=51, gb_free=15.8, wall=22549
2023-08-18 02:24:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 02:24:47 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.105 | trans_loss 5.192 | nll_loss 2.454 | w2v_ctc_loss 1.38 | task_loss 0 | contrastive_loss 0.275 | total 4003.4 | n_correct 2650.4 | ppl 5.48 | accuracy 66.204 | uer 18.78 | wer 20.682 | raw_wer 20.682 | bleu 21.71 | wps 1783.7 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22
2023-08-18 02:24:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-18 02:24:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-18 02:24:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-18 02:24:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 21.71) (writing took 6.995725243992638 seconds)
2023-08-18 02:25:46 | INFO | train_inner | epoch 024:    215 / 1474 loss=2.054, trans_loss=4.843, nll_loss=2.064, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.274, total=4244.96, n_correct=2843.86, ppl=4.18, accuracy=66.994, wps=9432.4, ups=1.11, wpb=8489.9, bsz=340, num_updates=34100, lr=7.6584e-05, gnorm=0.615, clip=0, loss_scale=8, train_wall=51, gb_free=15.7, wall=22639
2023-08-18 02:26:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-18 02:26:38 | INFO | train_inner | epoch 024:    316 / 1474 loss=2.03, trans_loss=4.842, nll_loss=2.061, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.056, total=4133.81, n_correct=2770.41, ppl=4.17, accuracy=67.018, wps=15716.6, ups=1.9, wpb=8267.6, bsz=306.9, num_updates=34200, lr=7.64719e-05, gnorm=0.631, clip=0, loss_scale=4, train_wall=52, gb_free=15.9, wall=22692
2023-08-18 02:27:31 | INFO | train_inner | epoch 024:    416 / 1474 loss=2.066, trans_loss=4.854, nll_loss=2.076, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.197, total=4152.16, n_correct=2763.99, ppl=4.22, accuracy=66.568, wps=15896.3, ups=1.91, wpb=8304.3, bsz=297.4, num_updates=34300, lr=7.63604e-05, gnorm=0.855, clip=0, loss_scale=4, train_wall=52, gb_free=17.3, wall=22744
2023-08-18 02:28:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-18 02:28:23 | INFO | train_inner | epoch 024:    517 / 1474 loss=2.045, trans_loss=4.85, nll_loss=2.072, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.077, total=4146.51, n_correct=2770.77, ppl=4.2, accuracy=66.822, wps=15815.9, ups=1.91, wpb=8293, bsz=302.4, num_updates=34400, lr=7.62493e-05, gnorm=0.666, clip=0, loss_scale=2, train_wall=52, gb_free=16.7, wall=22797
2023-08-18 02:29:15 | INFO | train_inner | epoch 024:    617 / 1474 loss=2.034, trans_loss=4.846, nll_loss=2.067, w2v_ctc_loss=0.744, task_loss=0, contrastive_loss=0.07, total=4148.8, n_correct=2777.21, ppl=4.19, accuracy=66.94, wps=16135.8, ups=1.94, wpb=8297.6, bsz=303.7, num_updates=34500, lr=7.61387e-05, gnorm=0.691, clip=0, loss_scale=2, train_wall=51, gb_free=16.8, wall=22848
2023-08-18 02:30:06 | INFO | train_inner | epoch 024:    717 / 1474 loss=2.045, trans_loss=4.855, nll_loss=2.078, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.102, total=4093.83, n_correct=2731.62, ppl=4.22, accuracy=66.725, wps=15954.1, ups=1.95, wpb=8187.7, bsz=295.4, num_updates=34600, lr=7.60286e-05, gnorm=0.638, clip=0, loss_scale=2, train_wall=51, gb_free=16.6, wall=22900
2023-08-18 02:30:58 | INFO | train_inner | epoch 024:    817 / 1474 loss=2.041, trans_loss=4.856, nll_loss=2.08, w2v_ctc_loss=0.752, task_loss=0, contrastive_loss=0.077, total=4127.86, n_correct=2756.51, ppl=4.23, accuracy=66.778, wps=15916.1, ups=1.93, wpb=8255.7, bsz=305.5, num_updates=34700, lr=7.5919e-05, gnorm=0.688, clip=0, loss_scale=2, train_wall=51, gb_free=13.7, wall=22951
2023-08-18 02:31:49 | INFO | train_inner | epoch 024:    917 / 1474 loss=2.047, trans_loss=4.859, nll_loss=2.082, w2v_ctc_loss=0.767, task_loss=0, contrastive_loss=0.053, total=4036.65, n_correct=2685.7, ppl=4.23, accuracy=66.533, wps=15637.9, ups=1.94, wpb=8073.3, bsz=279.6, num_updates=34800, lr=7.58098e-05, gnorm=0.905, clip=1, loss_scale=2, train_wall=51, gb_free=15.1, wall=23003
2023-08-18 02:32:41 | INFO | train_inner | epoch 024:   1017 / 1474 loss=2.042, trans_loss=4.858, nll_loss=2.081, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.059, total=4121.84, n_correct=2751.18, ppl=4.23, accuracy=66.746, wps=16046.1, ups=1.95, wpb=8243.7, bsz=297, num_updates=34900, lr=7.57011e-05, gnorm=0.704, clip=0, loss_scale=2, train_wall=51, gb_free=17.1, wall=23054
2023-08-18 02:33:32 | INFO | train_inner | epoch 024:   1117 / 1474 loss=2.042, trans_loss=4.841, nll_loss=2.06, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.101, total=4138.25, n_correct=2772.58, ppl=4.17, accuracy=66.999, wps=16008.2, ups=1.93, wpb=8276.5, bsz=310.3, num_updates=35000, lr=7.55929e-05, gnorm=0.784, clip=0, loss_scale=2, train_wall=51, gb_free=13.4, wall=23106
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:0')
2023-08-18 02:34:24 | INFO | train_inner | epoch 024:   1217 / 1474 loss=2.053, trans_loss=4.861, nll_loss=2.086, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.093, total=4160.84, n_correct=2771.57, ppl=4.24, accuracy=66.611, wps=16083.8, ups=1.93, wpb=8321.7, bsz=312, num_updates=35100, lr=7.54851e-05, gnorm=0.96, clip=0, loss_scale=2, train_wall=51, gb_free=14, wall=23158
2023-08-18 02:35:16 | INFO | train_inner | epoch 024:   1317 / 1474 loss=2.051, trans_loss=4.86, nll_loss=2.085, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.064, total=4105.25, n_correct=2733.12, ppl=4.24, accuracy=66.576, wps=15859.5, ups=1.93, wpb=8210.5, bsz=294.5, num_updates=35200, lr=7.53778e-05, gnorm=0.792, clip=0, loss_scale=2, train_wall=51, gb_free=15.9, wall=23210
2023-08-18 02:36:08 | INFO | train_inner | epoch 024:   1417 / 1474 loss=2.051, trans_loss=4.863, nll_loss=2.089, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.058, total=4090.3, n_correct=2723.4, ppl=4.25, accuracy=66.582, wps=15825, ups=1.93, wpb=8180.6, bsz=290.7, num_updates=35300, lr=7.5271e-05, gnorm=0.89, clip=1, loss_scale=2, train_wall=51, gb_free=17.3, wall=23261
2023-08-18 02:36:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:3')
2023-08-18 02:37:10 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.114 | trans_loss 5.194 | nll_loss 2.462 | w2v_ctc_loss 1.4 | task_loss 0 | contrastive_loss 0.277 | total 4003.4 | n_correct 2653.3 | ppl 5.51 | accuracy 66.276 | uer 18.565 | wer 20.413 | raw_wer 20.413 | bleu 21.63 | wps 1669.4 | wpb 4003.4 | bsz 141.8 | num_updates 35357 | best_bleu 22
2023-08-18 02:37:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35357 updates
2023-08-18 02:37:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.6300.pt
2023-08-18 02:37:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.6300.pt
2023-08-18 02:37:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.6300.pt (epoch 24 @ 35357 updates, score 21.63) (writing took 6.6917356380145065 seconds)
2023-08-18 02:37:16 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-18 02:37:16 | INFO | train | epoch 024 | loss 2.046 | trans_loss 4.851 | nll_loss 2.074 | w2v_ctc_loss 0.756 | task_loss 0 | contrastive_loss 0.108 | total 4137.28 | n_correct 2763.68 | ppl 4.21 | accuracy 66.799 | wps 14376.8 | ups 1.74 | wpb 8274.6 | bsz 305.2 | num_updates 35357 | lr 7.52103e-05 | gnorm 0.745 | clip 0.1 | loss_scale 2 | train_wall 754 | gb_free 16.1 | wall 23330
2023-08-18 02:37:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 02:37:17 | INFO | fairseq.trainer | begin training epoch 25
2023-08-18 02:37:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 02:37:46 | INFO | train_inner | epoch 025:     43 / 1474 loss=2.035, trans_loss=4.843, nll_loss=2.064, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.067, total=4160.53, n_correct=2791.15, ppl=4.18, accuracy=67.086, wps=8470.5, ups=1.02, wpb=8321.1, bsz=309.9, num_updates=35400, lr=7.51646e-05, gnorm=0.707, clip=0, loss_scale=2, train_wall=51, gb_free=16.4, wall=23360
2023-08-18 02:38:38 | INFO | train_inner | epoch 025:    143 / 1474 loss=2.024, trans_loss=4.827, nll_loss=2.043, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.067, total=4141.89, n_correct=2788.66, ppl=4.12, accuracy=67.328, wps=16024.1, ups=1.93, wpb=8283.8, bsz=311.9, num_updates=35500, lr=7.50587e-05, gnorm=0.697, clip=0, loss_scale=2, train_wall=51, gb_free=16.4, wall=23411
2023-08-18 02:39:29 | INFO | train_inner | epoch 025:    243 / 1474 loss=2.033, trans_loss=4.836, nll_loss=2.053, w2v_ctc_loss=0.753, task_loss=0, contrastive_loss=0.068, total=4120.99, n_correct=2764.06, ppl=4.15, accuracy=67.073, wps=15910.8, ups=1.93, wpb=8242, bsz=301.5, num_updates=35600, lr=7.49532e-05, gnorm=0.684, clip=0, loss_scale=2, train_wall=51, gb_free=15.7, wall=23463
2023-08-18 02:40:21 | INFO | train_inner | epoch 025:    343 / 1474 loss=2.036, trans_loss=4.837, nll_loss=2.054, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.098, total=4136.22, n_correct=2773.25, ppl=4.15, accuracy=67.048, wps=15978.9, ups=1.93, wpb=8272.4, bsz=294.5, num_updates=35700, lr=7.48481e-05, gnorm=0.757, clip=0, loss_scale=2, train_wall=51, gb_free=12.6, wall=23515
2023-08-18 02:41:13 | INFO | train_inner | epoch 025:    443 / 1474 loss=2.06, trans_loss=4.845, nll_loss=2.065, w2v_ctc_loss=0.778, task_loss=0, contrastive_loss=0.175, total=4163.26, n_correct=2783.54, ppl=4.18, accuracy=66.86, wps=15995.7, ups=1.92, wpb=8326.5, bsz=296.4, num_updates=35800, lr=7.47435e-05, gnorm=0.98, clip=2, loss_scale=2, train_wall=52, gb_free=15.8, wall=23567
2023-08-18 02:42:05 | INFO | train_inner | epoch 025:    543 / 1474 loss=2.04, trans_loss=4.848, nll_loss=2.069, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.074, total=4169.98, n_correct=2794.73, ppl=4.2, accuracy=67.02, wps=16185.4, ups=1.94, wpb=8340, bsz=316.3, num_updates=35900, lr=7.46393e-05, gnorm=0.786, clip=1, loss_scale=2, train_wall=51, gb_free=15, wall=23618
2023-08-18 02:42:56 | INFO | train_inner | epoch 025:    643 / 1474 loss=2.035, trans_loss=4.831, nll_loss=2.048, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.133, total=4151.24, n_correct=2791.44, ppl=4.13, accuracy=67.244, wps=16081.3, ups=1.94, wpb=8302.5, bsz=308.3, num_updates=36000, lr=7.45356e-05, gnorm=0.621, clip=0, loss_scale=2, train_wall=51, gb_free=16, wall=23670
2023-08-18 02:42:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 02:43:27 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.123 | trans_loss 5.187 | nll_loss 2.449 | w2v_ctc_loss 1.456 | task_loss 0 | contrastive_loss 0.267 | total 4003.4 | n_correct 2656.2 | ppl 5.46 | accuracy 66.349 | uer 18.791 | wer 20.704 | raw_wer 20.704 | bleu 22.1 | wps 1754.1 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.1
2023-08-18 02:43:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-18 02:43:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-18 02:43:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-18 02:43:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.1) (writing took 12.057736968999961 seconds)
2023-08-18 02:44:32 | INFO | train_inner | epoch 025:    743 / 1474 loss=2.037, trans_loss=4.832, nll_loss=2.049, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.129, total=4147.45, n_correct=2784.52, ppl=4.14, accuracy=67.138, wps=8703.3, ups=1.05, wpb=8294.9, bsz=307.3, num_updates=36100, lr=7.44323e-05, gnorm=0.63, clip=0, loss_scale=2, train_wall=51, gb_free=16.6, wall=23765
2023-08-18 02:45:23 | INFO | train_inner | epoch 025:    843 / 1474 loss=2.038, trans_loss=4.843, nll_loss=2.063, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.08, total=4156.98, n_correct=2784.54, ppl=4.18, accuracy=66.985, wps=16185.2, ups=1.95, wpb=8314, bsz=320.5, num_updates=36200, lr=7.43294e-05, gnorm=0.639, clip=0, loss_scale=2, train_wall=51, gb_free=17.1, wall=23817
2023-08-18 02:46:15 | INFO | train_inner | epoch 025:    943 / 1474 loss=2.039, trans_loss=4.841, nll_loss=2.061, w2v_ctc_loss=0.746, task_loss=0, contrastive_loss=0.135, total=4156.27, n_correct=2789.83, ppl=4.17, accuracy=67.123, wps=16026.5, ups=1.93, wpb=8312.5, bsz=315.4, num_updates=36300, lr=7.4227e-05, gnorm=0.585, clip=0, loss_scale=2, train_wall=51, gb_free=15.2, wall=23869
2023-08-18 02:47:07 | INFO | train_inner | epoch 025:   1043 / 1474 loss=2.052, trans_loss=4.849, nll_loss=2.07, w2v_ctc_loss=0.744, task_loss=0, contrastive_loss=0.242, total=4185.72, n_correct=2800.98, ppl=4.2, accuracy=66.918, wps=16022.7, ups=1.91, wpb=8371.4, bsz=313, num_updates=36400, lr=7.41249e-05, gnorm=0.647, clip=0, loss_scale=2, train_wall=52, gb_free=15, wall=23921
2023-08-18 02:47:59 | INFO | train_inner | epoch 025:   1143 / 1474 loss=2.033, trans_loss=4.844, nll_loss=2.064, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.051, total=4033.28, n_correct=2698.14, ppl=4.18, accuracy=66.897, wps=15673.3, ups=1.94, wpb=8066.6, bsz=283.5, num_updates=36500, lr=7.40233e-05, gnorm=0.628, clip=0, loss_scale=4, train_wall=51, gb_free=17.7, wall=23972
2023-08-18 02:48:50 | INFO | train_inner | epoch 025:   1243 / 1474 loss=2.029, trans_loss=4.844, nll_loss=2.063, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.063, total=4083.07, n_correct=2737.46, ppl=4.18, accuracy=67.044, wps=15934.1, ups=1.95, wpb=8166.1, bsz=294.5, num_updates=36600, lr=7.39221e-05, gnorm=0.652, clip=0, loss_scale=4, train_wall=51, gb_free=16.9, wall=24024
2023-08-18 02:49:42 | INFO | train_inner | epoch 025:   1343 / 1474 loss=2.041, trans_loss=4.84, nll_loss=2.059, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.154, total=4168.78, n_correct=2799.55, ppl=4.17, accuracy=67.155, wps=16059.4, ups=1.93, wpb=8337.6, bsz=308.9, num_updates=36700, lr=7.38213e-05, gnorm=0.626, clip=0, loss_scale=4, train_wall=51, gb_free=16.1, wall=24076
2023-08-18 02:50:34 | INFO | train_inner | epoch 025:   1443 / 1474 loss=2.047, trans_loss=4.854, nll_loss=2.078, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.122, total=4131.36, n_correct=2758.48, ppl=4.22, accuracy=66.769, wps=15855, ups=1.92, wpb=8262.7, bsz=309.3, num_updates=36800, lr=7.3721e-05, gnorm=0.663, clip=0, loss_scale=4, train_wall=52, gb_free=12.5, wall=24128
2023-08-18 02:50:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 02:51:22 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.095 | trans_loss 5.181 | nll_loss 2.441 | w2v_ctc_loss 1.374 | task_loss 0 | contrastive_loss 0.272 | total 4003.4 | n_correct 2658.9 | ppl 5.43 | accuracy 66.416 | uer 18.82 | wer 20.767 | raw_wer 20.767 | bleu 21.82 | wps 1730.1 | wpb 4003.4 | bsz 141.8 | num_updates 36831 | best_bleu 22.1
2023-08-18 02:51:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36831 updates
2023-08-18 02:51:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8204.pt
2023-08-18 02:51:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8204.pt
2023-08-18 02:51:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.8204.pt (epoch 25 @ 36831 updates, score 21.82) (writing took 7.125509268982569 seconds)
2023-08-18 02:51:29 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-18 02:51:29 | INFO | train | epoch 025 | loss 2.039 | trans_loss 4.841 | nll_loss 2.06 | w2v_ctc_loss 0.75 | task_loss 0 | contrastive_loss 0.111 | total 4138.65 | n_correct 2774.71 | ppl 4.17 | accuracy 67.044 | wps 14304.8 | ups 1.73 | wpb 8277.3 | bsz 305.7 | num_updates 36831 | lr 7.36899e-05 | gnorm 0.684 | clip 0.2 | loss_scale 4 | train_wall 754 | gb_free 14.5 | wall 24183
2023-08-18 02:51:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 02:51:30 | INFO | fairseq.trainer | begin training epoch 26
2023-08-18 02:51:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 02:52:13 | INFO | train_inner | epoch 026:     69 / 1474 loss=2.031, trans_loss=4.83, nll_loss=2.045, w2v_ctc_loss=0.744, task_loss=0, contrastive_loss=0.088, total=4157.89, n_correct=2793.26, ppl=4.13, accuracy=67.18, wps=8431.2, ups=1.01, wpb=8315.8, bsz=313.7, num_updates=36900, lr=7.3621e-05, gnorm=0.756, clip=1, loss_scale=4, train_wall=51, gb_free=12.3, wall=24226
2023-08-18 02:53:04 | INFO | train_inner | epoch 026:    169 / 1474 loss=2.033, trans_loss=4.82, nll_loss=2.034, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.259, total=4269.48, n_correct=2887.86, ppl=4.1, accuracy=67.64, wps=16475.8, ups=1.93, wpb=8539, bsz=338.4, num_updates=37000, lr=7.35215e-05, gnorm=0.558, clip=0, loss_scale=4, train_wall=51, gb_free=17.2, wall=24278
2023-08-18 02:53:56 | INFO | train_inner | epoch 026:    269 / 1474 loss=2.031, trans_loss=4.822, nll_loss=2.036, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.147, total=4124.11, n_correct=2778.82, ppl=4.1, accuracy=67.38, wps=15933.3, ups=1.93, wpb=8248.2, bsz=307.4, num_updates=37100, lr=7.34223e-05, gnorm=0.606, clip=0, loss_scale=4, train_wall=51, gb_free=15.2, wall=24330
2023-08-18 02:54:48 | INFO | train_inner | epoch 026:    369 / 1474 loss=2.028, trans_loss=4.827, nll_loss=2.042, w2v_ctc_loss=0.737, task_loss=0, contrastive_loss=0.107, total=4165.17, n_correct=2804.96, ppl=4.12, accuracy=67.343, wps=16201.7, ups=1.94, wpb=8330.3, bsz=314.8, num_updates=37200, lr=7.33236e-05, gnorm=0.602, clip=0, loss_scale=4, train_wall=51, gb_free=16.2, wall=24381
2023-08-18 02:55:39 | INFO | train_inner | epoch 026:    469 / 1474 loss=2.035, trans_loss=4.819, nll_loss=2.031, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.153, total=4159.48, n_correct=2803.37, ppl=4.09, accuracy=67.397, wps=16102.5, ups=1.94, wpb=8319, bsz=313, num_updates=37300, lr=7.32252e-05, gnorm=0.664, clip=0, loss_scale=4, train_wall=51, gb_free=13.4, wall=24433
2023-08-18 02:56:32 | INFO | train_inner | epoch 026:    569 / 1474 loss=2.029, trans_loss=4.829, nll_loss=2.044, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.072, total=4165.04, n_correct=2802.82, ppl=4.12, accuracy=67.294, wps=15862.7, ups=1.9, wpb=8330.1, bsz=305.4, num_updates=37400, lr=7.31272e-05, gnorm=0.594, clip=0, loss_scale=4, train_wall=52, gb_free=15.8, wall=24486
2023-08-18 02:57:23 | INFO | train_inner | epoch 026:    669 / 1474 loss=2.022, trans_loss=4.829, nll_loss=2.045, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.06, total=4129.35, n_correct=2777.74, ppl=4.13, accuracy=67.268, wps=16042.9, ups=1.94, wpb=8258.7, bsz=296.8, num_updates=37500, lr=7.30297e-05, gnorm=0.656, clip=0, loss_scale=4, train_wall=51, gb_free=17.4, wall=24537
2023-08-18 02:57:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-18 02:58:15 | INFO | train_inner | epoch 026:    770 / 1474 loss=2.039, trans_loss=4.835, nll_loss=2.053, w2v_ctc_loss=0.739, task_loss=0, contrastive_loss=0.17, total=4085.74, n_correct=2743.73, ppl=4.15, accuracy=67.154, wps=15739.9, ups=1.93, wpb=8171.5, bsz=297.7, num_updates=37600, lr=7.29325e-05, gnorm=0.595, clip=0, loss_scale=2, train_wall=51, gb_free=16.9, wall=24589
2023-08-18 02:59:07 | INFO | train_inner | epoch 026:    870 / 1474 loss=2.027, trans_loss=4.829, nll_loss=2.045, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.072, total=4177.9, n_correct=2811.33, ppl=4.13, accuracy=67.291, wps=16163.1, ups=1.93, wpb=8355.8, bsz=306.9, num_updates=37700, lr=7.28357e-05, gnorm=0.595, clip=0, loss_scale=2, train_wall=51, gb_free=16.1, wall=24641
2023-08-18 02:59:58 | INFO | train_inner | epoch 026:    970 / 1474 loss=2.023, trans_loss=4.829, nll_loss=2.044, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.123, total=4145.98, n_correct=2788.56, ppl=4.12, accuracy=67.259, wps=16096, ups=1.94, wpb=8292, bsz=302.5, num_updates=37800, lr=7.27393e-05, gnorm=0.572, clip=0, loss_scale=2, train_wall=51, gb_free=16.5, wall=24692
2023-08-18 03:00:51 | INFO | train_inner | epoch 026:   1070 / 1474 loss=2.023, trans_loss=4.831, nll_loss=2.047, w2v_ctc_loss=0.741, task_loss=0, contrastive_loss=0.055, total=4118.58, n_correct=2775.84, ppl=4.13, accuracy=67.398, wps=15820.1, ups=1.92, wpb=8237.2, bsz=293.8, num_updates=37900, lr=7.26433e-05, gnorm=0.652, clip=0, loss_scale=2, train_wall=52, gb_free=16.9, wall=24744
2023-08-18 03:01:42 | INFO | train_inner | epoch 026:   1170 / 1474 loss=2.034, trans_loss=4.84, nll_loss=2.059, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.097, total=4113.01, n_correct=2755.76, ppl=4.17, accuracy=67.001, wps=15863.9, ups=1.93, wpb=8226, bsz=298.1, num_updates=38000, lr=7.25476e-05, gnorm=0.641, clip=0, loss_scale=2, train_wall=51, gb_free=13.4, wall=24796
2023-08-18 03:01:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 03:02:14 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.096 | trans_loss 5.186 | nll_loss 2.45 | w2v_ctc_loss 1.369 | task_loss 0 | contrastive_loss 0.266 | total 4003.4 | n_correct 2657.2 | ppl 5.46 | accuracy 66.374 | uer 18.61 | wer 20.368 | raw_wer 20.368 | bleu 21.81 | wps 1673.2 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.1
2023-08-18 03:02:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-18 03:02:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-18 03:02:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-18 03:02:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 21.81) (writing took 7.005473636992974 seconds)
2023-08-18 03:03:14 | INFO | train_inner | epoch 026:   1270 / 1474 loss=2.032, trans_loss=4.844, nll_loss=2.063, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.059, total=4007.19, n_correct=2686.53, ppl=4.18, accuracy=67.043, wps=8780.2, ups=1.1, wpb=8014.4, bsz=281.1, num_updates=38100, lr=7.24524e-05, gnorm=0.609, clip=0, loss_scale=2, train_wall=51, gb_free=16.7, wall=24887
2023-08-18 03:04:06 | INFO | train_inner | epoch 026:   1370 / 1474 loss=2.022, trans_loss=4.834, nll_loss=2.051, w2v_ctc_loss=0.725, task_loss=0, contrastive_loss=0.073, total=4157.41, n_correct=2800.56, ppl=4.15, accuracy=67.363, wps=15978.4, ups=1.92, wpb=8314.8, bsz=312.4, num_updates=38200, lr=7.23575e-05, gnorm=0.627, clip=0, loss_scale=2, train_wall=51, gb_free=16.5, wall=24939
2023-08-18 03:04:57 | INFO | train_inner | epoch 026:   1470 / 1474 loss=2.02, trans_loss=4.829, nll_loss=2.046, w2v_ctc_loss=0.729, task_loss=0, contrastive_loss=0.067, total=4141.4, n_correct=2792.91, ppl=4.13, accuracy=67.439, wps=16116.8, ups=1.95, wpb=8282.8, bsz=311.3, num_updates=38300, lr=7.22629e-05, gnorm=0.592, clip=0, loss_scale=2, train_wall=51, gb_free=17.2, wall=24991
2023-08-18 03:04:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 03:05:30 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.094 | trans_loss 5.184 | nll_loss 2.446 | w2v_ctc_loss 1.364 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2651.5 | ppl 5.45 | accuracy 66.231 | uer 18.461 | wer 20.223 | raw_wer 20.223 | bleu 21.79 | wps 1757.3 | wpb 4003.4 | bsz 141.8 | num_updates 38304 | best_bleu 22.1
2023-08-18 03:05:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38304 updates
2023-08-18 03:05:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7909.pt
2023-08-18 03:05:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7909.pt
2023-08-18 03:05:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7909.pt (epoch 26 @ 38304 updates, score 21.79) (writing took 6.99885354199796 seconds)
2023-08-18 03:05:38 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-18 03:05:38 | INFO | train | epoch 026 | loss 2.028 | trans_loss 4.829 | nll_loss 2.045 | w2v_ctc_loss 0.737 | task_loss 0 | contrastive_loss 0.109 | total 4138.32 | n_correct 2785.38 | ppl 4.13 | accuracy 67.307 | wps 14374.6 | ups 1.74 | wpb 8276.6 | bsz 305.6 | num_updates 38304 | lr 7.22592e-05 | gnorm 0.62 | clip 0.1 | loss_scale 2 | train_wall 754 | gb_free 16 | wall 25031
2023-08-18 03:05:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 03:05:38 | INFO | fairseq.trainer | begin training epoch 27
2023-08-18 03:05:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 03:06:34 | INFO | train_inner | epoch 027:     96 / 1474 loss=2, trans_loss=4.795, nll_loss=2, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.046, total=4078.13, n_correct=2773.45, ppl=4, accuracy=68.008, wps=8400.9, ups=1.03, wpb=8156.3, bsz=285.1, num_updates=38400, lr=7.21688e-05, gnorm=0.632, clip=0, loss_scale=2, train_wall=51, gb_free=15.2, wall=25088
2023-08-18 03:07:26 | INFO | train_inner | epoch 027:    196 / 1474 loss=2.013, trans_loss=4.809, nll_loss=2.019, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.079, total=4185.69, n_correct=2838.1, ppl=4.05, accuracy=67.805, wps=16223.4, ups=1.94, wpb=8371.4, bsz=323.7, num_updates=38500, lr=7.2075e-05, gnorm=0.648, clip=0, loss_scale=2, train_wall=51, gb_free=17.1, wall=25139
2023-08-18 03:08:18 | INFO | train_inner | epoch 027:    296 / 1474 loss=2.018, trans_loss=4.817, nll_loss=2.03, w2v_ctc_loss=0.737, task_loss=0, contrastive_loss=0.059, total=4164.1, n_correct=2816.85, ppl=4.08, accuracy=67.646, wps=16105, ups=1.93, wpb=8328.2, bsz=305.7, num_updates=38600, lr=7.19816e-05, gnorm=0.694, clip=0, loss_scale=2, train_wall=51, gb_free=16.7, wall=25191
2023-08-18 03:09:10 | INFO | train_inner | epoch 027:    396 / 1474 loss=2.045, trans_loss=4.828, nll_loss=2.043, w2v_ctc_loss=0.742, task_loss=0, contrastive_loss=0.242, total=4080.38, n_correct=2747.3, ppl=4.12, accuracy=67.33, wps=15694, ups=1.92, wpb=8160.8, bsz=298.1, num_updates=38700, lr=7.18885e-05, gnorm=0.835, clip=1, loss_scale=2, train_wall=51, gb_free=16.1, wall=25243
2023-08-18 03:10:02 | INFO | train_inner | epoch 027:    496 / 1474 loss=2.034, trans_loss=4.826, nll_loss=2.041, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.178, total=4239.9, n_correct=2857.53, ppl=4.12, accuracy=67.396, wps=16269.4, ups=1.92, wpb=8479.8, bsz=329.3, num_updates=38800, lr=7.17958e-05, gnorm=0.617, clip=0, loss_scale=2, train_wall=52, gb_free=15, wall=25295
2023-08-18 03:10:53 | INFO | train_inner | epoch 027:    596 / 1474 loss=2.024, trans_loss=4.815, nll_loss=2.027, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.115, total=4144.77, n_correct=2799.66, ppl=4.08, accuracy=67.547, wps=16060.2, ups=1.94, wpb=8289.5, bsz=313.3, num_updates=38900, lr=7.17035e-05, gnorm=0.577, clip=0, loss_scale=2, train_wall=51, gb_free=17.6, wall=25347
2023-08-18 03:11:45 | INFO | train_inner | epoch 027:    696 / 1474 loss=2.025, trans_loss=4.822, nll_loss=2.036, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.094, total=4167.31, n_correct=2808.27, ppl=4.1, accuracy=67.388, wps=16061.9, ups=1.93, wpb=8334.6, bsz=306.9, num_updates=39000, lr=7.16115e-05, gnorm=0.69, clip=1, loss_scale=2, train_wall=51, gb_free=16.7, wall=25399
2023-08-18 03:12:37 | INFO | train_inner | epoch 027:    796 / 1474 loss=2.021, trans_loss=4.821, nll_loss=2.034, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.061, total=4106.27, n_correct=2766.61, ppl=4.1, accuracy=67.375, wps=15947.7, ups=1.94, wpb=8212.5, bsz=293.9, num_updates=39100, lr=7.15199e-05, gnorm=0.634, clip=0, loss_scale=2, train_wall=51, gb_free=16.7, wall=25450
2023-08-18 03:13:29 | INFO | train_inner | epoch 027:    896 / 1474 loss=2.016, trans_loss=4.826, nll_loss=2.04, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.053, total=4106.26, n_correct=2768.96, ppl=4.11, accuracy=67.433, wps=15796.3, ups=1.92, wpb=8212.5, bsz=293.2, num_updates=39200, lr=7.14286e-05, gnorm=0.675, clip=0, loss_scale=2, train_wall=51, gb_free=16.9, wall=25502
2023-08-18 03:13:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-18 03:14:21 | INFO | train_inner | epoch 027:    997 / 1474 loss=2.038, trans_loss=4.825, nll_loss=2.04, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.238, total=4181.56, n_correct=2817.31, ppl=4.11, accuracy=67.375, wps=15975, ups=1.91, wpb=8363.1, bsz=313.1, num_updates=39300, lr=7.13376e-05, gnorm=0.728, clip=0, loss_scale=1, train_wall=52, gb_free=15.9, wall=25555
2023-08-18 03:15:13 | INFO | train_inner | epoch 027:   1097 / 1474 loss=2.018, trans_loss=4.822, nll_loss=2.036, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.076, total=4165.48, n_correct=2809.06, ppl=4.1, accuracy=67.437, wps=16115.4, ups=1.93, wpb=8331, bsz=310.7, num_updates=39400, lr=7.1247e-05, gnorm=0.579, clip=0, loss_scale=1, train_wall=51, gb_free=17.2, wall=25606
2023-08-18 03:16:04 | INFO | train_inner | epoch 027:   1197 / 1474 loss=2.022, trans_loss=4.824, nll_loss=2.037, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.068, total=4091.68, n_correct=2757.9, ppl=4.1, accuracy=67.403, wps=15839.7, ups=1.94, wpb=8183.4, bsz=292.5, num_updates=39500, lr=7.11568e-05, gnorm=0.624, clip=0, loss_scale=1, train_wall=51, gb_free=17.5, wall=25658
2023-08-18 03:16:56 | INFO | train_inner | epoch 027:   1297 / 1474 loss=2.024, trans_loss=4.823, nll_loss=2.037, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.124, total=4057.13, n_correct=2736.93, ppl=4.1, accuracy=67.46, wps=15710.2, ups=1.94, wpb=8114.3, bsz=292.7, num_updates=39600, lr=7.10669e-05, gnorm=0.58, clip=0, loss_scale=1, train_wall=51, gb_free=15, wall=25710
2023-08-18 03:17:48 | INFO | train_inner | epoch 027:   1397 / 1474 loss=2.02, trans_loss=4.822, nll_loss=2.037, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.109, total=4158.28, n_correct=2805.41, ppl=4.1, accuracy=67.466, wps=16158.7, ups=1.94, wpb=8316.6, bsz=313.5, num_updates=39700, lr=7.09773e-05, gnorm=0.56, clip=0, loss_scale=1, train_wall=51, gb_free=16.3, wall=25761
2023-08-18 03:18:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 03:18:58 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.109 | trans_loss 5.187 | nll_loss 2.45 | w2v_ctc_loss 1.406 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2657.8 | ppl 5.46 | accuracy 66.389 | uer 18.939 | wer 20.95 | raw_wer 20.95 | bleu 21.79 | wps 1755.3 | wpb 4003.4 | bsz 141.8 | num_updates 39777 | best_bleu 22.1
2023-08-18 03:18:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39777 updates
2023-08-18 03:18:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7904.pt
2023-08-18 03:19:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7904.pt
2023-08-18 03:19:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.7904.pt (epoch 27 @ 39777 updates, score 21.79) (writing took 7.90651560400147 seconds)
2023-08-18 03:19:06 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-18 03:19:06 | INFO | train | epoch 027 | loss 2.022 | trans_loss 4.819 | nll_loss 2.032 | w2v_ctc_loss 0.731 | task_loss 0 | contrastive_loss 0.109 | total 4138.89 | n_correct 2794.42 | ppl 4.09 | accuracy 67.516 | wps 15080.2 | ups 1.82 | wpb 8277.8 | bsz 305.7 | num_updates 39777 | lr 7.09086e-05 | gnorm 0.644 | clip 0.1 | loss_scale 1 | train_wall 754 | gb_free 17.8 | wall 25840
2023-08-18 03:19:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 03:19:06 | INFO | fairseq.trainer | begin training epoch 28
2023-08-18 03:19:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 03:19:25 | INFO | train_inner | epoch 028:     23 / 1474 loss=2.006, trans_loss=4.811, nll_loss=2.022, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.06, total=4116.54, n_correct=2790.63, ppl=4.06, accuracy=67.791, wps=8444.2, ups=1.03, wpb=8233.1, bsz=307.5, num_updates=39800, lr=7.08881e-05, gnorm=0.597, clip=0, loss_scale=1, train_wall=51, gb_free=16.1, wall=25859
2023-08-18 03:20:17 | INFO | train_inner | epoch 028:    123 / 1474 loss=2, trans_loss=4.792, nll_loss=1.996, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.054, total=4115.01, n_correct=2802.83, ppl=3.99, accuracy=68.112, wps=15952.8, ups=1.94, wpb=8230, bsz=294, num_updates=39900, lr=7.07992e-05, gnorm=0.574, clip=0, loss_scale=1, train_wall=51, gb_free=17.3, wall=25910
2023-08-18 03:21:09 | INFO | train_inner | epoch 028:    223 / 1474 loss=2.009, trans_loss=4.808, nll_loss=2.018, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.066, total=4187.31, n_correct=2840.72, ppl=4.05, accuracy=67.841, wps=16142.1, ups=1.93, wpb=8374.6, bsz=314.5, num_updates=40000, lr=7.07107e-05, gnorm=0.659, clip=0, loss_scale=1, train_wall=51, gb_free=15.5, wall=25962
2023-08-18 03:21:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 03:21:39 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.108 | trans_loss 5.192 | nll_loss 2.456 | w2v_ctc_loss 1.391 | task_loss 0 | contrastive_loss 0.273 | total 4003.4 | n_correct 2658.4 | ppl 5.49 | accuracy 66.404 | uer 18.708 | wer 20.585 | raw_wer 20.585 | bleu 22.07 | wps 1753 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.1
2023-08-18 03:21:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-18 03:21:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-18 03:21:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-18 03:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.07) (writing took 7.914161352993688 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:0')
2023-08-18 03:22:40 | INFO | train_inner | epoch 028:    323 / 1474 loss=2.045, trans_loss=4.812, nll_loss=2.023, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.393, total=4136.97, n_correct=2791.75, ppl=4.06, accuracy=67.483, wps=9043, ups=1.09, wpb=8273.9, bsz=313.5, num_updates=40100, lr=7.06225e-05, gnorm=0.628, clip=0, loss_scale=1, train_wall=51, gb_free=17.5, wall=26054
2023-08-18 03:23:32 | INFO | train_inner | epoch 028:    423 / 1474 loss=2.009, trans_loss=4.805, nll_loss=2.014, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.05, total=4084.26, n_correct=2772.6, ppl=4.04, accuracy=67.885, wps=15819.9, ups=1.94, wpb=8168.5, bsz=294, num_updates=40200, lr=7.05346e-05, gnorm=0.577, clip=0, loss_scale=1, train_wall=51, gb_free=16.8, wall=26105
2023-08-18 03:24:23 | INFO | train_inner | epoch 028:    523 / 1474 loss=2.008, trans_loss=4.808, nll_loss=2.017, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.066, total=4118.66, n_correct=2792.25, ppl=4.05, accuracy=67.795, wps=16026.9, ups=1.95, wpb=8237.3, bsz=301, num_updates=40300, lr=7.0447e-05, gnorm=0.626, clip=0, loss_scale=1, train_wall=51, gb_free=17, wall=26157
2023-08-18 03:25:14 | INFO | train_inner | epoch 028:    623 / 1474 loss=2.01, trans_loss=4.815, nll_loss=2.026, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.056, total=4180.5, n_correct=2828.86, ppl=4.07, accuracy=67.668, wps=16325.1, ups=1.95, wpb=8361, bsz=305.7, num_updates=40400, lr=7.03598e-05, gnorm=0.569, clip=0, loss_scale=1, train_wall=51, gb_free=16.6, wall=26208
2023-08-18 03:26:07 | INFO | train_inner | epoch 028:    723 / 1474 loss=2.022, trans_loss=4.816, nll_loss=2.028, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.175, total=4175.56, n_correct=2828.09, ppl=4.08, accuracy=67.73, wps=15888.2, ups=1.9, wpb=8351.1, bsz=325.1, num_updates=40500, lr=7.02728e-05, gnorm=0.535, clip=0, loss_scale=1, train_wall=52, gb_free=16.6, wall=26260
2023-08-18 03:26:58 | INFO | train_inner | epoch 028:    823 / 1474 loss=2.003, trans_loss=4.807, nll_loss=2.016, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.053, total=4085.95, n_correct=2775.9, ppl=4.05, accuracy=67.938, wps=15883.5, ups=1.94, wpb=8171.9, bsz=305.3, num_updates=40600, lr=7.01862e-05, gnorm=0.58, clip=0, loss_scale=1, train_wall=51, gb_free=17.3, wall=26312
2023-08-18 03:27:51 | INFO | train_inner | epoch 028:    923 / 1474 loss=2.023, trans_loss=4.818, nll_loss=2.03, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.115, total=4129.1, n_correct=2787.3, ppl=4.08, accuracy=67.504, wps=15777.9, ups=1.91, wpb=8258.2, bsz=300.9, num_updates=40700, lr=7.01e-05, gnorm=0.565, clip=0, loss_scale=1, train_wall=52, gb_free=16.7, wall=26364
2023-08-18 03:28:42 | INFO | train_inner | epoch 028:   1023 / 1474 loss=2.028, trans_loss=4.816, nll_loss=2.027, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.166, total=4171.45, n_correct=2819.14, ppl=4.08, accuracy=67.582, wps=16129.5, ups=1.93, wpb=8342.9, bsz=308.8, num_updates=40800, lr=7.0014e-05, gnorm=0.576, clip=0, loss_scale=1, train_wall=51, gb_free=16.9, wall=26416
2023-08-18 03:29:34 | INFO | train_inner | epoch 028:   1123 / 1474 loss=2.011, trans_loss=4.807, nll_loss=2.018, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.076, total=4208.27, n_correct=2852.46, ppl=4.05, accuracy=67.782, wps=16400.7, ups=1.95, wpb=8416.5, bsz=320.2, num_updates=40900, lr=6.99284e-05, gnorm=0.59, clip=0, loss_scale=1, train_wall=51, gb_free=15.1, wall=26467
2023-08-18 03:30:25 | INFO | train_inner | epoch 028:   1223 / 1474 loss=2.006, trans_loss=4.814, nll_loss=2.025, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.061, total=4125.42, n_correct=2794.71, ppl=4.07, accuracy=67.744, wps=15939.1, ups=1.93, wpb=8250.8, bsz=308, num_updates=41000, lr=6.9843e-05, gnorm=0.571, clip=0, loss_scale=1, train_wall=51, gb_free=15, wall=26519
2023-08-18 03:31:18 | INFO | train_inner | epoch 028:   1323 / 1474 loss=2.021, trans_loss=4.819, nll_loss=2.031, w2v_ctc_loss=0.74, task_loss=0, contrastive_loss=0.077, total=4060.94, n_correct=2740.67, ppl=4.09, accuracy=67.489, wps=15602.6, ups=1.92, wpb=8121.9, bsz=281.1, num_updates=41100, lr=6.9758e-05, gnorm=0.955, clip=1, loss_scale=1, train_wall=51, gb_free=15.9, wall=26571
2023-08-18 03:32:09 | INFO | train_inner | epoch 028:   1423 / 1474 loss=2.01, trans_loss=4.81, nll_loss=2.019, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.097, total=4158.96, n_correct=2813.38, ppl=4.05, accuracy=67.646, wps=16004.2, ups=1.92, wpb=8317.9, bsz=300.3, num_updates=41200, lr=6.96733e-05, gnorm=0.56, clip=0, loss_scale=1, train_wall=51, gb_free=16.9, wall=26623
2023-08-18 03:32:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:5')
2023-08-18 03:33:07 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.095 | trans_loss 5.183 | nll_loss 2.443 | w2v_ctc_loss 1.37 | task_loss 0 | contrastive_loss 0.275 | total 4003.4 | n_correct 2656.7 | ppl 5.44 | accuracy 66.361 | uer 18.398 | wer 20.264 | raw_wer 20.264 | bleu 21.91 | wps 1727.5 | wpb 4003.4 | bsz 141.8 | num_updates 41251 | best_bleu 22.1
2023-08-18 03:33:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41251 updates
2023-08-18 03:33:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9108.pt
2023-08-18 03:33:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9108.pt
2023-08-18 03:33:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9108.pt (epoch 28 @ 41251 updates, score 21.91) (writing took 7.185389507008949 seconds)
2023-08-18 03:33:15 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-18 03:33:15 | INFO | train | epoch 028 | loss 2.014 | trans_loss 4.81 | nll_loss 2.02 | w2v_ctc_loss 0.722 | task_loss 0 | contrastive_loss 0.107 | total 4138.65 | n_correct 2803.56 | ppl 4.06 | accuracy 67.741 | wps 14380.3 | ups 1.74 | wpb 8277.3 | bsz 305.7 | num_updates 41251 | lr 6.96302e-05 | gnorm 0.612 | clip 0.1 | loss_scale 1 | train_wall 755 | gb_free 16.5 | wall 26688
2023-08-18 03:33:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 03:33:15 | INFO | fairseq.trainer | begin training epoch 29
2023-08-18 03:33:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 03:33:47 | INFO | train_inner | epoch 029:     49 / 1474 loss=2.005, trans_loss=4.799, nll_loss=2.006, w2v_ctc_loss=0.719, task_loss=0, contrastive_loss=0.073, total=4165.26, n_correct=2836.28, ppl=4.02, accuracy=68.094, wps=8549.7, ups=1.03, wpb=8330.5, bsz=316, num_updates=41300, lr=6.95889e-05, gnorm=0.564, clip=0, loss_scale=2, train_wall=51, gb_free=16.4, wall=26721
2023-08-18 03:34:39 | INFO | train_inner | epoch 029:    149 / 1474 loss=2.011, trans_loss=4.802, nll_loss=2.01, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.091, total=4118.11, n_correct=2797.79, ppl=4.03, accuracy=67.939, wps=15960.3, ups=1.94, wpb=8236.2, bsz=306.8, num_updates=41400, lr=6.95048e-05, gnorm=0.572, clip=0, loss_scale=2, train_wall=51, gb_free=15.4, wall=26772
2023-08-18 03:35:31 | INFO | train_inner | epoch 029:    249 / 1474 loss=2.008, trans_loss=4.792, nll_loss=1.997, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.173, total=4199.43, n_correct=2861.14, ppl=3.99, accuracy=68.132, wps=16098.5, ups=1.92, wpb=8398.9, bsz=329, num_updates=41500, lr=6.9421e-05, gnorm=0.553, clip=0, loss_scale=2, train_wall=52, gb_free=11.9, wall=26824
2023-08-18 03:36:23 | INFO | train_inner | epoch 029:    349 / 1474 loss=2.012, trans_loss=4.811, nll_loss=2.021, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.057, total=4088.08, n_correct=2769.82, ppl=4.06, accuracy=67.754, wps=15684.6, ups=1.92, wpb=8176.2, bsz=289.8, num_updates=41600, lr=6.93375e-05, gnorm=0.554, clip=0, loss_scale=2, train_wall=52, gb_free=15.3, wall=26876
2023-08-18 03:37:15 | INFO | train_inner | epoch 029:    449 / 1474 loss=1.993, trans_loss=4.783, nll_loss=1.985, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.05, total=4155.15, n_correct=2838.98, ppl=3.96, accuracy=68.324, wps=16022.2, ups=1.93, wpb=8310.3, bsz=307.8, num_updates=41700, lr=6.92543e-05, gnorm=0.529, clip=0, loss_scale=2, train_wall=51, gb_free=12.5, wall=26928
2023-08-18 03:38:07 | INFO | train_inner | epoch 029:    549 / 1474 loss=2.015, trans_loss=4.807, nll_loss=2.017, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.144, total=4166.22, n_correct=2822.25, ppl=4.05, accuracy=67.741, wps=15982.2, ups=1.92, wpb=8332.4, bsz=296.4, num_updates=41800, lr=6.91714e-05, gnorm=0.542, clip=0, loss_scale=2, train_wall=52, gb_free=15.6, wall=26980
2023-08-18 03:38:58 | INFO | train_inner | epoch 029:    649 / 1474 loss=2.014, trans_loss=4.795, nll_loss=2.001, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.213, total=4139.47, n_correct=2817.39, ppl=4, accuracy=68.062, wps=16043.2, ups=1.94, wpb=8278.9, bsz=319.4, num_updates=41900, lr=6.90889e-05, gnorm=0.561, clip=0, loss_scale=2, train_wall=51, gb_free=11.9, wall=27032
2023-08-18 03:39:51 | INFO | train_inner | epoch 029:    749 / 1474 loss=2.014, trans_loss=4.8, nll_loss=2.007, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.137, total=4231.88, n_correct=2874.64, ppl=4.02, accuracy=67.928, wps=16168.4, ups=1.91, wpb=8463.8, bsz=327.1, num_updates=42000, lr=6.90066e-05, gnorm=0.704, clip=1, loss_scale=2, train_wall=52, gb_free=17.6, wall=27084
2023-08-18 03:39:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 03:40:22 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.123 | trans_loss 5.195 | nll_loss 2.461 | w2v_ctc_loss 1.434 | task_loss 0 | contrastive_loss 0.269 | total 4003.4 | n_correct 2652.2 | ppl 5.51 | accuracy 66.249 | uer 18.56 | wer 20.391 | raw_wer 20.391 | bleu 21.59 | wps 1740.8 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.1
2023-08-18 03:40:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-18 03:40:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-18 03:40:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-18 03:40:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 21.59) (writing took 6.929335879016435 seconds)
2023-08-18 03:41:21 | INFO | train_inner | epoch 029:    849 / 1474 loss=2.005, trans_loss=4.815, nll_loss=2.026, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.05, total=4037.23, n_correct=2731.34, ppl=4.07, accuracy=67.654, wps=8990, ups=1.11, wpb=8074.5, bsz=283.7, num_updates=42100, lr=6.89246e-05, gnorm=0.584, clip=0, loss_scale=2, train_wall=51, gb_free=12.5, wall=27174
2023-08-18 03:42:12 | INFO | train_inner | epoch 029:    949 / 1474 loss=2.006, trans_loss=4.806, nll_loss=2.014, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.057, total=4079.11, n_correct=2767.34, ppl=4.04, accuracy=67.842, wps=15919, ups=1.95, wpb=8158.2, bsz=292.4, num_updates=42200, lr=6.88428e-05, gnorm=0.588, clip=0, loss_scale=2, train_wall=51, gb_free=14.3, wall=27226
2023-08-18 03:43:03 | INFO | train_inner | epoch 029:   1049 / 1474 loss=2.004, trans_loss=4.795, nll_loss=2.002, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.133, total=4141.41, n_correct=2818.71, ppl=4, accuracy=68.062, wps=16124.8, ups=1.95, wpb=8282.8, bsz=309.2, num_updates=42300, lr=6.87614e-05, gnorm=0.603, clip=0, loss_scale=2, train_wall=51, gb_free=16.6, wall=27277
2023-08-18 03:43:54 | INFO | train_inner | epoch 029:   1149 / 1474 loss=2.008, trans_loss=4.814, nll_loss=2.024, w2v_ctc_loss=0.724, task_loss=0, contrastive_loss=0.047, total=4079.37, n_correct=2762.05, ppl=4.07, accuracy=67.708, wps=15928.7, ups=1.95, wpb=8158.7, bsz=285.6, num_updates=42400, lr=6.86803e-05, gnorm=0.583, clip=0, loss_scale=2, train_wall=51, gb_free=16.1, wall=27328
2023-08-18 03:44:46 | INFO | train_inner | epoch 029:   1249 / 1474 loss=2.006, trans_loss=4.81, nll_loss=2.021, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.053, total=4156.24, n_correct=2817.15, ppl=4.06, accuracy=67.781, wps=16076.1, ups=1.93, wpb=8312.5, bsz=300.7, num_updates=42500, lr=6.85994e-05, gnorm=0.666, clip=0, loss_scale=2, train_wall=51, gb_free=17.2, wall=27380
2023-08-18 03:45:38 | INFO | train_inner | epoch 029:   1349 / 1474 loss=2.004, trans_loss=4.796, nll_loss=2.003, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.117, total=4160.63, n_correct=2831.31, ppl=4.01, accuracy=68.05, wps=15980.3, ups=1.92, wpb=8321.3, bsz=309, num_updates=42600, lr=6.85189e-05, gnorm=0.541, clip=0, loss_scale=2, train_wall=51, gb_free=14.5, wall=27432
2023-08-18 03:46:30 | INFO | train_inner | epoch 029:   1449 / 1474 loss=2.009, trans_loss=4.797, nll_loss=2.004, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.145, total=4167.72, n_correct=2833.25, ppl=4.01, accuracy=67.981, wps=16203.8, ups=1.94, wpb=8335.4, bsz=314.2, num_updates=42700, lr=6.84386e-05, gnorm=0.555, clip=0, loss_scale=2, train_wall=51, gb_free=17, wall=27483
2023-08-18 03:46:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 03:47:14 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.097 | trans_loss 5.183 | nll_loss 2.445 | w2v_ctc_loss 1.377 | task_loss 0 | contrastive_loss 0.272 | total 4003.4 | n_correct 2659.9 | ppl 5.44 | accuracy 66.441 | uer 18.185 | wer 20.104 | raw_wer 20.104 | bleu 21.76 | wps 1687.8 | wpb 4003.4 | bsz 141.8 | num_updates 42725 | best_bleu 22.1
2023-08-18 03:47:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42725 updates
2023-08-18 03:47:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-18 03:47:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-18 03:47:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_last.pt (epoch 29 @ 42725 updates, score 21.76) (writing took 6.3659600150131155 seconds)
2023-08-18 03:47:21 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-18 03:47:21 | INFO | train | epoch 029 | loss 2.008 | trans_loss 4.801 | nll_loss 2.009 | w2v_ctc_loss 0.715 | task_loss 0 | contrastive_loss 0.105 | total 4138.65 | n_correct 2811.81 | ppl 4.02 | accuracy 67.94 | wps 14419.4 | ups 1.74 | wpb 8277.3 | bsz 305.7 | num_updates 42725 | lr 6.84186e-05 | gnorm 0.58 | clip 0.1 | loss_scale 2 | train_wall 754 | gb_free 16.1 | wall 27534
2023-08-18 03:47:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 03:47:21 | INFO | fairseq.trainer | begin training epoch 30
2023-08-18 03:47:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 03:48:07 | INFO | train_inner | epoch 030:     75 / 1474 loss=2.005, trans_loss=4.79, nll_loss=1.995, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.161, total=4168.99, n_correct=2839.74, ppl=3.99, accuracy=68.116, wps=8586.2, ups=1.03, wpb=8338, bsz=316.7, num_updates=42800, lr=6.83586e-05, gnorm=0.665, clip=0, loss_scale=2, train_wall=51, gb_free=16.6, wall=27580
2023-08-18 03:48:58 | INFO | train_inner | epoch 030:    175 / 1474 loss=1.994, trans_loss=4.775, nll_loss=1.975, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.095, total=4215.08, n_correct=2886.7, ppl=3.93, accuracy=68.485, wps=16397.5, ups=1.95, wpb=8430.2, bsz=321, num_updates=42900, lr=6.82789e-05, gnorm=0.545, clip=0, loss_scale=2, train_wall=51, gb_free=17, wall=27632
2023-08-18 03:49:50 | INFO | train_inner | epoch 030:    275 / 1474 loss=1.998, trans_loss=4.795, nll_loss=2, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.049, total=4110.97, n_correct=2800.5, ppl=4, accuracy=68.123, wps=16005.4, ups=1.95, wpb=8221.9, bsz=292.3, num_updates=43000, lr=6.81994e-05, gnorm=0.665, clip=1, loss_scale=2, train_wall=51, gb_free=16.3, wall=27683
2023-08-18 03:50:42 | INFO | train_inner | epoch 030:    375 / 1474 loss=1.986, trans_loss=4.779, nll_loss=1.98, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.052, total=4191.07, n_correct=2870.41, ppl=3.95, accuracy=68.489, wps=16129.6, ups=1.92, wpb=8382.1, bsz=311, num_updates=43100, lr=6.81203e-05, gnorm=0.547, clip=0, loss_scale=2, train_wall=51, gb_free=16.6, wall=27735
2023-08-18 03:51:33 | INFO | train_inner | epoch 030:    475 / 1474 loss=1.998, trans_loss=4.789, nll_loss=1.992, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.117, total=4121.27, n_correct=2812.13, ppl=3.98, accuracy=68.235, wps=15978.1, ups=1.94, wpb=8242.5, bsz=311.3, num_updates=43200, lr=6.80414e-05, gnorm=0.628, clip=0, loss_scale=2, train_wall=51, gb_free=15.8, wall=27787
2023-08-18 03:52:25 | INFO | train_inner | epoch 030:    575 / 1474 loss=1.999, trans_loss=4.792, nll_loss=1.997, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.077, total=4157.58, n_correct=2836.23, ppl=3.99, accuracy=68.218, wps=16137.5, ups=1.94, wpb=8315.2, bsz=310, num_updates=43300, lr=6.79628e-05, gnorm=0.602, clip=0, loss_scale=2, train_wall=51, gb_free=16, wall=27838
2023-08-18 03:53:16 | INFO | train_inner | epoch 030:    675 / 1474 loss=2.006, trans_loss=4.794, nll_loss=1.999, w2v_ctc_loss=0.719, task_loss=0, contrastive_loss=0.092, total=4193.34, n_correct=2851.1, ppl=4, accuracy=67.991, wps=16242.3, ups=1.94, wpb=8386.7, bsz=316.4, num_updates=43400, lr=6.78844e-05, gnorm=0.562, clip=0, loss_scale=4, train_wall=51, gb_free=15.1, wall=27890
2023-08-18 03:54:08 | INFO | train_inner | epoch 030:    775 / 1474 loss=2.016, trans_loss=4.798, nll_loss=2.004, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.171, total=4101.46, n_correct=2787.99, ppl=4.01, accuracy=67.976, wps=15943.3, ups=1.94, wpb=8202.9, bsz=302.5, num_updates=43500, lr=6.78064e-05, gnorm=0.59, clip=0, loss_scale=4, train_wall=51, gb_free=16.7, wall=27941
2023-08-18 03:54:59 | INFO | train_inner | epoch 030:    875 / 1474 loss=2.001, trans_loss=4.797, nll_loss=2.003, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.065, total=4116.1, n_correct=2800.91, ppl=4.01, accuracy=68.048, wps=15975.8, ups=1.94, wpb=8232.2, bsz=298.9, num_updates=43600, lr=6.77285e-05, gnorm=0.547, clip=0, loss_scale=4, train_wall=51, gb_free=16.2, wall=27993
2023-08-18 03:55:52 | INFO | train_inner | epoch 030:    975 / 1474 loss=2.005, trans_loss=4.8, nll_loss=2.007, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.064, total=4121.44, n_correct=2798.77, ppl=4.02, accuracy=67.908, wps=15751.2, ups=1.91, wpb=8242.9, bsz=297.4, num_updates=43700, lr=6.7651e-05, gnorm=0.659, clip=0, loss_scale=4, train_wall=52, gb_free=16.1, wall=28045
2023-08-18 03:56:44 | INFO | train_inner | epoch 030:   1075 / 1474 loss=2.008, trans_loss=4.801, nll_loss=2.007, w2v_ctc_loss=0.711, task_loss=0, contrastive_loss=0.14, total=4092.65, n_correct=2777.91, ppl=4.02, accuracy=67.876, wps=15674.5, ups=1.91, wpb=8185.3, bsz=280.2, num_updates=43800, lr=6.75737e-05, gnorm=0.593, clip=0, loss_scale=4, train_wall=52, gb_free=14.5, wall=28098
2023-08-18 03:57:35 | INFO | train_inner | epoch 030:   1175 / 1474 loss=2.003, trans_loss=4.794, nll_loss=2, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.124, total=4174.4, n_correct=2843.96, ppl=4, accuracy=68.129, wps=16177.1, ups=1.94, wpb=8348.8, bsz=315.6, num_updates=43900, lr=6.74967e-05, gnorm=0.848, clip=0, loss_scale=4, train_wall=51, gb_free=16.9, wall=28149
2023-08-18 03:58:27 | INFO | train_inner | epoch 030:   1275 / 1474 loss=2.001, trans_loss=4.799, nll_loss=2.006, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.056, total=4039.35, n_correct=2747.76, ppl=4.02, accuracy=68.025, wps=15707.2, ups=1.94, wpb=8078.7, bsz=284.7, num_updates=44000, lr=6.742e-05, gnorm=0.586, clip=0, loss_scale=4, train_wall=51, gb_free=16.4, wall=28201
2023-08-18 03:58:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 03:58:59 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.101 | trans_loss 5.184 | nll_loss 2.443 | w2v_ctc_loss 1.39 | task_loss 0 | contrastive_loss 0.268 | total 4003.4 | n_correct 2663.3 | ppl 5.44 | accuracy 66.526 | uer 18.204 | wer 20.137 | raw_wer 20.137 | bleu 22.07 | wps 1700 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.1
2023-08-18 03:58:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-18 03:58:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-18 03:59:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-18 03:59:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.07) (writing took 7.184624193003401 seconds)
2023-08-18 03:59:58 | INFO | train_inner | epoch 030:   1375 / 1474 loss=1.996, trans_loss=4.791, nll_loss=1.997, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.07, total=4164.49, n_correct=2842.07, ppl=3.99, accuracy=68.245, wps=9168.1, ups=1.1, wpb=8329, bsz=321.7, num_updates=44100, lr=6.73435e-05, gnorm=0.611, clip=0, loss_scale=4, train_wall=51, gb_free=15.4, wall=28291
2023-08-18 04:00:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 04:01:20 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.096 | trans_loss 5.178 | nll_loss 2.437 | w2v_ctc_loss 1.388 | task_loss 0 | contrastive_loss 0.271 | total 4003.4 | n_correct 2668.2 | ppl 5.41 | accuracy 66.648 | uer 18.313 | wer 20.238 | raw_wer 20.238 | bleu 22.11 | wps 1756.7 | wpb 4003.4 | bsz 141.8 | num_updates 44199 | best_bleu 22.11
2023-08-18 04:01:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44199 updates
2023-08-18 04:01:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 04:01:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 04:01:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 30 @ 44199 updates, score 22.11) (writing took 12.838497502001701 seconds)
2023-08-18 04:01:34 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-18 04:01:34 | INFO | train | epoch 030 | loss 2.002 | trans_loss 4.793 | nll_loss 1.997 | w2v_ctc_loss 0.71 | task_loss 0 | contrastive_loss 0.104 | total 4138.65 | n_correct 2819.68 | ppl 3.99 | accuracy 68.13 | wps 14306 | ups 1.73 | wpb 8277.3 | bsz 305.7 | num_updates 44199 | lr 6.7268e-05 | gnorm 0.616 | clip 0.1 | loss_scale 4 | train_wall 753 | gb_free 17.2 | wall 28387
2023-08-18 04:01:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 04:01:34 | INFO | fairseq.trainer | begin training epoch 31
2023-08-18 04:01:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 04:01:41 | INFO | train_inner | epoch 031:      1 / 1474 loss=2.009, trans_loss=4.796, nll_loss=2.002, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.217, total=4125.07, n_correct=2807.63, ppl=4.01, accuracy=68.063, wps=7955.9, ups=0.96, wpb=8250.1, bsz=315.2, num_updates=44200, lr=6.72673e-05, gnorm=0.582, clip=0, loss_scale=4, train_wall=52, gb_free=15.7, wall=28395
2023-08-18 04:02:33 | INFO | train_inner | epoch 031:    101 / 1474 loss=1.992, trans_loss=4.781, nll_loss=1.982, w2v_ctc_loss=0.712, task_loss=0, contrastive_loss=0.055, total=4087.45, n_correct=2794.11, ppl=3.95, accuracy=68.358, wps=15912.4, ups=1.95, wpb=8174.9, bsz=291.9, num_updates=44300, lr=6.71913e-05, gnorm=0.611, clip=0, loss_scale=4, train_wall=51, gb_free=16.1, wall=28447
2023-08-18 04:03:25 | INFO | train_inner | epoch 031:    201 / 1474 loss=1.992, trans_loss=4.783, nll_loss=1.984, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.07, total=4137.8, n_correct=2827.1, ppl=3.96, accuracy=68.324, wps=15920, ups=1.92, wpb=8275.6, bsz=298.1, num_updates=44400, lr=6.71156e-05, gnorm=0.708, clip=1, loss_scale=4, train_wall=51, gb_free=15.4, wall=28498
2023-08-18 04:04:17 | INFO | train_inner | epoch 031:    301 / 1474 loss=1.999, trans_loss=4.781, nll_loss=1.982, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.119, total=4138.27, n_correct=2826.69, ppl=3.95, accuracy=68.306, wps=15978.2, ups=1.93, wpb=8276.5, bsz=300.1, num_updates=44500, lr=6.70402e-05, gnorm=0.587, clip=0, loss_scale=4, train_wall=51, gb_free=15.5, wall=28550
2023-08-18 04:05:08 | INFO | train_inner | epoch 031:    401 / 1474 loss=1.989, trans_loss=4.789, nll_loss=1.992, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.055, total=4098.88, n_correct=2797.9, ppl=3.98, accuracy=68.26, wps=15889.2, ups=1.94, wpb=8197.8, bsz=286.9, num_updates=44600, lr=6.6965e-05, gnorm=0.581, clip=0, loss_scale=4, train_wall=51, gb_free=17, wall=28602
2023-08-18 04:06:01 | INFO | train_inner | epoch 031:    501 / 1474 loss=1.991, trans_loss=4.78, nll_loss=1.981, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.063, total=4123.26, n_correct=2820.11, ppl=3.95, accuracy=68.395, wps=15733.9, ups=1.91, wpb=8246.5, bsz=302.9, num_updates=44700, lr=6.689e-05, gnorm=0.57, clip=0, loss_scale=4, train_wall=52, gb_free=16.8, wall=28654
2023-08-18 04:06:52 | INFO | train_inner | epoch 031:    601 / 1474 loss=1.989, trans_loss=4.782, nll_loss=1.983, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.054, total=4069.38, n_correct=2782.99, ppl=3.95, accuracy=68.389, wps=15802.2, ups=1.94, wpb=8138.8, bsz=291.2, num_updates=44800, lr=6.68153e-05, gnorm=0.574, clip=0, loss_scale=4, train_wall=51, gb_free=17.5, wall=28706
2023-08-18 04:07:44 | INFO | train_inner | epoch 031:    701 / 1474 loss=1.986, trans_loss=4.779, nll_loss=1.98, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.057, total=4211.5, n_correct=2883.04, ppl=3.94, accuracy=68.456, wps=16373.3, ups=1.94, wpb=8423, bsz=316.6, num_updates=44900, lr=6.67409e-05, gnorm=0.654, clip=0, loss_scale=4, train_wall=51, gb_free=16.8, wall=28757
2023-08-18 04:08:35 | INFO | train_inner | epoch 031:    801 / 1474 loss=1.997, trans_loss=4.786, nll_loss=1.988, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.123, total=4103.23, n_correct=2800.13, ppl=3.97, accuracy=68.242, wps=15851.1, ups=1.93, wpb=8206.5, bsz=296.8, num_updates=45000, lr=6.66667e-05, gnorm=0.57, clip=0, loss_scale=4, train_wall=51, gb_free=15.7, wall=28809
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:0')
2023-08-18 04:09:27 | INFO | train_inner | epoch 031:    901 / 1474 loss=1.99, trans_loss=4.778, nll_loss=1.977, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.07, total=4098.59, n_correct=2803, ppl=3.94, accuracy=68.389, wps=15831.1, ups=1.93, wpb=8197.2, bsz=293.9, num_updates=45100, lr=6.65927e-05, gnorm=0.667, clip=0, loss_scale=4, train_wall=51, gb_free=17.3, wall=28861
2023-08-18 04:10:19 | INFO | train_inner | epoch 031:   1001 / 1474 loss=2.003, trans_loss=4.792, nll_loss=1.997, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.152, total=4184.36, n_correct=2856.71, ppl=3.99, accuracy=68.271, wps=16043, ups=1.92, wpb=8368.7, bsz=320.3, num_updates=45200, lr=6.6519e-05, gnorm=0.602, clip=0, loss_scale=4, train_wall=52, gb_free=16.1, wall=28913
2023-08-18 04:11:11 | INFO | train_inner | epoch 031:   1101 / 1474 loss=1.993, trans_loss=4.784, nll_loss=1.987, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.099, total=4150.56, n_correct=2838.25, ppl=3.96, accuracy=68.382, wps=16165.3, ups=1.95, wpb=8301.1, bsz=315.1, num_updates=45300, lr=6.64455e-05, gnorm=0.551, clip=0, loss_scale=4, train_wall=51, gb_free=15.3, wall=28964
2023-08-18 04:12:02 | INFO | train_inner | epoch 031:   1201 / 1474 loss=2.003, trans_loss=4.785, nll_loss=1.989, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.214, total=4190.99, n_correct=2865.05, ppl=3.97, accuracy=68.362, wps=16262.3, ups=1.94, wpb=8382, bsz=323, num_updates=45400, lr=6.63723e-05, gnorm=0.561, clip=0, loss_scale=8, train_wall=51, gb_free=17.3, wall=29016
2023-08-18 04:12:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-18 04:12:54 | INFO | train_inner | epoch 031:   1302 / 1474 loss=1.996, trans_loss=4.794, nll_loss=1.999, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.061, total=4223.08, n_correct=2880.65, ppl=4, accuracy=68.212, wps=16247.3, ups=1.92, wpb=8446.2, bsz=324.5, num_updates=45500, lr=6.62994e-05, gnorm=0.577, clip=0, loss_scale=4, train_wall=51, gb_free=16.8, wall=29068
2023-08-18 04:13:47 | INFO | train_inner | epoch 031:   1402 / 1474 loss=2.019, trans_loss=4.789, nll_loss=1.994, w2v_ctc_loss=0.708, task_loss=0, contrastive_loss=0.262, total=4198.66, n_correct=2861, ppl=3.98, accuracy=68.141, wps=16048.7, ups=1.91, wpb=8397.3, bsz=327.4, num_updates=45600, lr=6.62266e-05, gnorm=0.705, clip=0, loss_scale=4, train_wall=52, gb_free=15.6, wall=29120
2023-08-18 04:14:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2508, device='cuda:7')
2023-08-18 04:14:56 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.094 | trans_loss 5.182 | nll_loss 2.441 | w2v_ctc_loss 1.373 | task_loss 0 | contrastive_loss 0.268 | total 4003.4 | n_correct 2663 | ppl 5.43 | accuracy 66.518 | uer 17.962 | wer 19.884 | raw_wer 19.884 | bleu 21.91 | wps 1640.1 | wpb 4003.4 | bsz 141.8 | num_updates 45672 | best_bleu 22.11
2023-08-18 04:14:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45672 updates
2023-08-18 04:14:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9107.pt
2023-08-18 04:14:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9107.pt
2023-08-18 04:15:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9107.pt (epoch 31 @ 45672 updates, score 21.91) (writing took 7.30583468900295 seconds)
2023-08-18 04:15:04 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-18 04:15:04 | INFO | train | epoch 031 | loss 1.996 | trans_loss 4.785 | nll_loss 1.987 | w2v_ctc_loss 0.703 | task_loss 0 | contrastive_loss 0.103 | total 4138.86 | n_correct 2827.45 | ppl 3.96 | accuracy 68.315 | wps 15045.4 | ups 1.82 | wpb 8277.7 | bsz 305.7 | num_updates 45672 | lr 6.61744e-05 | gnorm 0.606 | clip 0.1 | loss_scale 4 | train_wall 754 | gb_free 12.4 | wall 29198
2023-08-18 04:15:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 04:15:04 | INFO | fairseq.trainer | begin training epoch 32
2023-08-18 04:15:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 04:15:26 | INFO | train_inner | epoch 032:     28 / 1474 loss=1.989, trans_loss=4.781, nll_loss=1.983, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.051, total=4057.11, n_correct=2774.3, ppl=3.95, accuracy=68.381, wps=8157, ups=1.01, wpb=8114.2, bsz=294.1, num_updates=45700, lr=6.61541e-05, gnorm=0.575, clip=0, loss_scale=4, train_wall=51, gb_free=17.2, wall=29220
2023-08-18 04:16:18 | INFO | train_inner | epoch 032:    128 / 1474 loss=1.977, trans_loss=4.765, nll_loss=1.961, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.061, total=4197.14, n_correct=2885.67, ppl=3.89, accuracy=68.753, wps=16277.9, ups=1.94, wpb=8394.3, bsz=315.9, num_updates=45800, lr=6.60819e-05, gnorm=1.013, clip=1, loss_scale=4, train_wall=51, gb_free=13.5, wall=29271
2023-08-18 04:17:10 | INFO | train_inner | epoch 032:    228 / 1474 loss=1.99, trans_loss=4.78, nll_loss=1.981, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.071, total=4167.25, n_correct=2850.74, ppl=3.95, accuracy=68.408, wps=16034.5, ups=1.92, wpb=8334.5, bsz=323.2, num_updates=45900, lr=6.60098e-05, gnorm=0.604, clip=0, loss_scale=4, train_wall=51, gb_free=16.4, wall=29323
2023-08-18 04:18:01 | INFO | train_inner | epoch 032:    328 / 1474 loss=1.977, trans_loss=4.764, nll_loss=1.96, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.062, total=4172.57, n_correct=2871.77, ppl=3.89, accuracy=68.825, wps=16235.2, ups=1.95, wpb=8345.1, bsz=310.5, num_updates=46000, lr=6.5938e-05, gnorm=0.558, clip=0, loss_scale=4, train_wall=51, gb_free=13, wall=29375
2023-08-18 04:18:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 04:18:32 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.102 | trans_loss 5.182 | nll_loss 2.442 | w2v_ctc_loss 1.401 | task_loss 0 | contrastive_loss 0.267 | total 4003.4 | n_correct 2668.7 | ppl 5.43 | accuracy 66.661 | uer 18.228 | wer 20.115 | raw_wer 20.115 | bleu 22.14 | wps 1714.4 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.14
2023-08-18 04:18:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-18 04:18:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-18 04:18:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-18 04:18:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.14) (writing took 12.880235908000031 seconds)
2023-08-18 04:19:37 | INFO | train_inner | epoch 032:    428 / 1474 loss=1.982, trans_loss=4.768, nll_loss=1.965, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.062, total=4176.94, n_correct=2868.28, ppl=3.9, accuracy=68.669, wps=8680.4, ups=1.04, wpb=8353.9, bsz=312.9, num_updates=46100, lr=6.58665e-05, gnorm=0.615, clip=0, loss_scale=4, train_wall=51, gb_free=16.7, wall=29471
2023-08-18 04:20:30 | INFO | train_inner | epoch 032:    528 / 1474 loss=1.997, trans_loss=4.779, nll_loss=1.98, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.139, total=4198.65, n_correct=2874.14, ppl=3.94, accuracy=68.454, wps=15927.5, ups=1.9, wpb=8397.3, bsz=315.7, num_updates=46200, lr=6.57952e-05, gnorm=0.563, clip=0, loss_scale=4, train_wall=52, gb_free=17.1, wall=29524
2023-08-18 04:21:22 | INFO | train_inner | epoch 032:    628 / 1474 loss=1.992, trans_loss=4.782, nll_loss=1.984, w2v_ctc_loss=0.708, task_loss=0, contrastive_loss=0.068, total=4125.24, n_correct=2819.27, ppl=3.95, accuracy=68.342, wps=15834.9, ups=1.92, wpb=8250.5, bsz=296.8, num_updates=46300, lr=6.57241e-05, gnorm=0.684, clip=0, loss_scale=4, train_wall=52, gb_free=16.9, wall=29576
2023-08-18 04:22:14 | INFO | train_inner | epoch 032:    728 / 1474 loss=1.988, trans_loss=4.78, nll_loss=1.982, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.052, total=4163.48, n_correct=2850.06, ppl=3.95, accuracy=68.454, wps=16113.3, ups=1.94, wpb=8327, bsz=304.5, num_updates=46400, lr=6.56532e-05, gnorm=0.685, clip=0, loss_scale=4, train_wall=51, gb_free=16.3, wall=29627
2023-08-18 04:23:05 | INFO | train_inner | epoch 032:    828 / 1474 loss=1.983, trans_loss=4.777, nll_loss=1.977, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.049, total=4118.04, n_correct=2818.14, ppl=3.94, accuracy=68.434, wps=16086.3, ups=1.95, wpb=8236.1, bsz=294.4, num_updates=46500, lr=6.55826e-05, gnorm=0.669, clip=0, loss_scale=4, train_wall=51, gb_free=13.5, wall=29679
2023-08-18 04:23:57 | INFO | train_inner | epoch 032:    928 / 1474 loss=1.983, trans_loss=4.777, nll_loss=1.978, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.049, total=4138.73, n_correct=2834.56, ppl=3.94, accuracy=68.489, wps=16014.8, ups=1.93, wpb=8277.5, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.672, clip=0, loss_scale=4, train_wall=51, gb_free=16.6, wall=29730
2023-08-18 04:24:48 | INFO | train_inner | epoch 032:   1028 / 1474 loss=1.999, trans_loss=4.783, nll_loss=1.985, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.143, total=4105.63, n_correct=2807.57, ppl=3.96, accuracy=68.383, wps=15910.8, ups=1.94, wpb=8211.3, bsz=303.4, num_updates=46700, lr=6.5442e-05, gnorm=0.659, clip=0, loss_scale=4, train_wall=51, gb_free=11.6, wall=29782
2023-08-18 04:25:41 | INFO | train_inner | epoch 032:   1128 / 1474 loss=1.991, trans_loss=4.782, nll_loss=1.982, w2v_ctc_loss=0.7, task_loss=0, contrastive_loss=0.085, total=4018.68, n_correct=2743.76, ppl=3.95, accuracy=68.275, wps=15353.9, ups=1.91, wpb=8037.4, bsz=270.5, num_updates=46800, lr=6.5372e-05, gnorm=0.589, clip=0, loss_scale=4, train_wall=52, gb_free=12, wall=29834
2023-08-18 04:26:33 | INFO | train_inner | epoch 032:   1228 / 1474 loss=2.009, trans_loss=4.79, nll_loss=1.994, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.189, total=4165.54, n_correct=2840.53, ppl=3.98, accuracy=68.191, wps=16037.4, ups=1.93, wpb=8331.1, bsz=313.3, num_updates=46900, lr=6.53023e-05, gnorm=0.607, clip=0, loss_scale=4, train_wall=51, gb_free=15, wall=29886
2023-08-18 04:27:24 | INFO | train_inner | epoch 032:   1328 / 1474 loss=1.987, trans_loss=4.778, nll_loss=1.979, w2v_ctc_loss=0.703, task_loss=0, contrastive_loss=0.049, total=4074.77, n_correct=2788.35, ppl=3.94, accuracy=68.43, wps=15960.8, ups=1.96, wpb=8149.5, bsz=297.6, num_updates=47000, lr=6.52328e-05, gnorm=0.575, clip=0, loss_scale=4, train_wall=51, gb_free=17.8, wall=29937
2023-08-18 04:28:15 | INFO | train_inner | epoch 032:   1428 / 1474 loss=2.019, trans_loss=4.785, nll_loss=1.988, w2v_ctc_loss=0.708, task_loss=0, contrastive_loss=0.317, total=4115.52, n_correct=2808.05, ppl=3.97, accuracy=68.231, wps=15906.9, ups=1.93, wpb=8231, bsz=307.8, num_updates=47100, lr=6.51635e-05, gnorm=0.564, clip=0, loss_scale=4, train_wall=51, gb_free=17.6, wall=29989
2023-08-18 04:28:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 04:29:11 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.086 | trans_loss 5.178 | nll_loss 2.439 | w2v_ctc_loss 1.359 | task_loss 0 | contrastive_loss 0.262 | total 4003.4 | n_correct 2664.1 | ppl 5.42 | accuracy 66.546 | uer 18.021 | wer 19.858 | raw_wer 19.858 | bleu 21.98 | wps 1690.4 | wpb 4003.4 | bsz 141.8 | num_updates 47146 | best_bleu 22.14
2023-08-18 04:29:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47146 updates
2023-08-18 04:29:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9801.pt
2023-08-18 04:29:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9801.pt
2023-08-18 04:29:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint.best_bleu_21.9801.pt (epoch 32 @ 47146 updates, score 21.98) (writing took 7.168633093009703 seconds)
2023-08-18 04:29:19 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-18 04:29:19 | INFO | train | epoch 032 | loss 1.991 | trans_loss 4.778 | nll_loss 1.978 | w2v_ctc_loss 0.699 | task_loss 0 | contrastive_loss 0.102 | total 4138.65 | n_correct 2833.44 | ppl 3.94 | accuracy 68.463 | wps 14274.4 | ups 1.72 | wpb 8277.3 | bsz 305.7 | num_updates 47146 | lr 6.51317e-05 | gnorm 0.643 | clip 0.1 | loss_scale 4 | train_wall 755 | gb_free 16.5 | wall 30052
2023-08-18 04:29:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 04:29:19 | INFO | fairseq.trainer | begin training epoch 33
2023-08-18 04:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 04:29:54 | INFO | train_inner | epoch 033:     54 / 1474 loss=1.988, trans_loss=4.773, nll_loss=1.973, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.114, total=4143.17, n_correct=2843.89, ppl=3.93, accuracy=68.64, wps=8396.2, ups=1.01, wpb=8286.3, bsz=316.7, num_updates=47200, lr=6.50945e-05, gnorm=0.594, clip=0, loss_scale=4, train_wall=51, gb_free=16.9, wall=30088
2023-08-18 04:30:46 | INFO | train_inner | epoch 033:    154 / 1474 loss=1.972, trans_loss=4.762, nll_loss=1.957, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.04, total=4070.66, n_correct=2797.02, ppl=3.88, accuracy=68.712, wps=15696.7, ups=1.93, wpb=8141.3, bsz=283.8, num_updates=47300, lr=6.50256e-05, gnorm=0.761, clip=1, loss_scale=4, train_wall=51, gb_free=16.7, wall=30140
2023-08-18 04:31:38 | INFO | train_inner | epoch 033:    254 / 1474 loss=2.005, trans_loss=4.766, nll_loss=1.965, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.216, total=4279.52, n_correct=2939.24, ppl=3.9, accuracy=68.682, wps=16500.9, ups=1.93, wpb=8559, bsz=347.1, num_updates=47400, lr=6.4957e-05, gnorm=0.7, clip=0, loss_scale=4, train_wall=51, gb_free=16.7, wall=30192
2023-08-18 04:32:29 | INFO | train_inner | epoch 033:    354 / 1474 loss=1.985, trans_loss=4.77, nll_loss=1.968, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.07, total=4134.4, n_correct=2836.58, ppl=3.91, accuracy=68.609, wps=16098.8, ups=1.95, wpb=8268.8, bsz=303, num_updates=47500, lr=6.48886e-05, gnorm=0.565, clip=0, loss_scale=8, train_wall=51, gb_free=13, wall=30243
2023-08-18 04:32:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-18 04:33:21 | INFO | train_inner | epoch 033:    455 / 1474 loss=1.968, trans_loss=4.754, nll_loss=1.947, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.048, total=4127.73, n_correct=2850.97, ppl=3.86, accuracy=69.069, wps=16090.5, ups=1.95, wpb=8255.5, bsz=307.9, num_updates=47600, lr=6.48204e-05, gnorm=0.639, clip=0, loss_scale=4, train_wall=51, gb_free=16.9, wall=30294
2023-08-18 04:34:13 | INFO | train_inner | epoch 033:    555 / 1474 loss=1.986, trans_loss=4.774, nll_loss=1.973, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.069, total=4147.63, n_correct=2841.58, ppl=3.93, accuracy=68.511, wps=15887.6, ups=1.92, wpb=8295.3, bsz=296.9, num_updates=47700, lr=6.47524e-05, gnorm=0.608, clip=0, loss_scale=4, train_wall=52, gb_free=17.1, wall=30346
2023-08-18 04:35:05 | INFO | train_inner | epoch 033:    655 / 1474 loss=1.993, trans_loss=4.783, nll_loss=1.985, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.103, total=4142.79, n_correct=2829.51, ppl=3.96, accuracy=68.3, wps=15804.3, ups=1.91, wpb=8285.6, bsz=298.3, num_updates=47800, lr=6.46846e-05, gnorm=0.679, clip=0, loss_scale=4, train_wall=52, gb_free=16.4, wall=30399
2023-08-18 04:35:57 | INFO | train_inner | epoch 033:    755 / 1474 loss=1.991, trans_loss=4.778, nll_loss=1.978, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.05, total=4085.69, n_correct=2797.35, ppl=3.94, accuracy=68.467, wps=15926.2, ups=1.95, wpb=8171.4, bsz=291.8, num_updates=47900, lr=6.46171e-05, gnorm=0.57, clip=0, loss_scale=4, train_wall=51, gb_free=16.7, wall=30450
2023-08-18 04:36:48 | INFO | train_inner | epoch 033:    855 / 1474 loss=1.979, trans_loss=4.766, nll_loss=1.963, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.116, total=4118.38, n_correct=2834.39, ppl=3.9, accuracy=68.823, wps=16001.7, ups=1.94, wpb=8236.8, bsz=311.5, num_updates=48000, lr=6.45497e-05, gnorm=0.563, clip=0, loss_scale=4, train_wall=51, gb_free=16, wall=30502
2023-08-18 04:36:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 04:37:19 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.096 | trans_loss 5.183 | nll_loss 2.442 | w2v_ctc_loss 1.383 | task_loss 0 | contrastive_loss 0.259 | total 4003.4 | n_correct 2663.7 | ppl 5.43 | accuracy 66.536 | uer 17.912 | wer 19.876 | raw_wer 19.876 | bleu 21.99 | wps 1759.3 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.14
2023-08-18 04:37:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-18 04:37:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-18 04:37:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-18 04:37:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 21.99) (writing took 7.042169163993094 seconds)
2023-08-18 04:38:18 | INFO | train_inner | epoch 033:    955 / 1474 loss=1.986, trans_loss=4.772, nll_loss=1.97, w2v_ctc_loss=0.702, task_loss=0, contrastive_loss=0.065, total=4166.57, n_correct=2858.18, ppl=3.92, accuracy=68.598, wps=9267.2, ups=1.11, wpb=8333.1, bsz=313.4, num_updates=48100, lr=6.44826e-05, gnorm=0.608, clip=0, loss_scale=4, train_wall=51, gb_free=14.2, wall=30592
2023-08-18 04:39:10 | INFO | train_inner | epoch 033:   1055 / 1474 loss=1.994, trans_loss=4.769, nll_loss=1.966, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.162, total=4129.35, n_correct=2831.6, ppl=3.91, accuracy=68.573, wps=15836.7, ups=1.92, wpb=8258.7, bsz=303.2, num_updates=48200, lr=6.44157e-05, gnorm=0.597, clip=0, loss_scale=4, train_wall=52, gb_free=13.2, wall=30644
2023-08-18 04:40:03 | INFO | train_inner | epoch 033:   1155 / 1474 loss=1.99, trans_loss=4.778, nll_loss=1.979, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.151, total=4179.27, n_correct=2861.54, ppl=3.94, accuracy=68.47, wps=15934.4, ups=1.91, wpb=8358.5, bsz=310.1, num_updates=48300, lr=6.43489e-05, gnorm=0.619, clip=0, loss_scale=4, train_wall=52, gb_free=15.1, wall=30696
2023-08-18 04:40:54 | INFO | train_inner | epoch 033:   1255 / 1474 loss=1.982, trans_loss=4.77, nll_loss=1.968, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.053, total=4115.21, n_correct=2823.88, ppl=3.91, accuracy=68.621, wps=15909.8, ups=1.93, wpb=8230.4, bsz=294.9, num_updates=48400, lr=6.42824e-05, gnorm=0.562, clip=0, loss_scale=4, train_wall=51, gb_free=16.3, wall=30748
2023-08-18 04:41:46 | INFO | train_inner | epoch 033:   1355 / 1474 loss=1.983, trans_loss=4.771, nll_loss=1.97, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.074, total=4128.01, n_correct=2832.24, ppl=3.92, accuracy=68.61, wps=15886.5, ups=1.92, wpb=8256, bsz=312.3, num_updates=48500, lr=6.42161e-05, gnorm=0.596, clip=0, loss_scale=4, train_wall=51, gb_free=16.5, wall=30800
2023-08-18 04:42:38 | INFO | train_inner | epoch 033:   1455 / 1474 loss=1.997, trans_loss=4.773, nll_loss=1.973, w2v_ctc_loss=0.691, task_loss=0, contrastive_loss=0.215, total=4128.7, n_correct=2826.17, ppl=3.93, accuracy=68.452, wps=15950, ups=1.93, wpb=8257.4, bsz=309.9, num_updates=48600, lr=6.415e-05, gnorm=0.709, clip=0, loss_scale=4, train_wall=51, gb_free=16.6, wall=30852
2023-08-18 04:42:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 04:43:19 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.092 | trans_loss 5.182 | nll_loss 2.439 | w2v_ctc_loss 1.368 | task_loss 0 | contrastive_loss 0.266 | total 4003.4 | n_correct 2665.4 | ppl 5.42 | accuracy 66.578 | uer 17.909 | wer 19.928 | raw_wer 19.928 | bleu 22.23 | wps 1690.7 | wpb 4003.4 | bsz 141.8 | num_updates 48619 | best_bleu 22.23
2023-08-18 04:43:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48619 updates
2023-08-18 04:43:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 04:43:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-18 04:43:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_best.pt (epoch 33 @ 48619 updates, score 22.23) (writing took 12.55920435101143 seconds)
2023-08-18 04:43:32 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-18 04:43:32 | INFO | train | epoch 033 | loss 1.986 | trans_loss 4.77 | nll_loss 1.969 | w2v_ctc_loss 0.694 | task_loss 0 | contrastive_loss 0.102 | total 4138.57 | n_correct 2839.46 | ppl 3.91 | accuracy 68.61 | wps 14285.6 | ups 1.73 | wpb 8277.1 | bsz 305.6 | num_updates 48619 | lr 6.41375e-05 | gnorm 0.626 | clip 0.1 | loss_scale 4 | train_wall 755 | gb_free 17.9 | wall 30906
2023-08-18 04:43:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-18 04:43:32 | INFO | fairseq.trainer | begin training epoch 34
2023-08-18 04:43:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-18 04:44:21 | INFO | train_inner | epoch 034:     81 / 1474 loss=1.975, trans_loss=4.758, nll_loss=1.952, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.055, total=4113.07, n_correct=2830.99, ppl=3.87, accuracy=68.829, wps=7982.2, ups=0.97, wpb=8226.1, bsz=298.8, num_updates=48700, lr=6.40841e-05, gnorm=0.649, clip=0, loss_scale=4, train_wall=51, gb_free=16.6, wall=30955
2023-08-18 04:45:13 | INFO | train_inner | epoch 034:    181 / 1474 loss=1.969, trans_loss=4.749, nll_loss=1.941, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.056, total=4069.22, n_correct=2814.77, ppl=3.84, accuracy=69.172, wps=15778.7, ups=1.94, wpb=8138.4, bsz=295.5, num_updates=48800, lr=6.40184e-05, gnorm=0.556, clip=0, loss_scale=4, train_wall=51, gb_free=12.9, wall=31006
2023-08-18 04:46:05 | INFO | train_inner | epoch 034:    281 / 1474 loss=2.001, trans_loss=4.769, nll_loss=1.968, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.261, total=4252.78, n_correct=2919.55, ppl=3.91, accuracy=68.65, wps=16333.4, ups=1.92, wpb=8505.6, bsz=331.2, num_updates=48900, lr=6.39529e-05, gnorm=0.595, clip=0, loss_scale=4, train_wall=51, gb_free=16.8, wall=31058
2023-08-18 04:46:56 | INFO | train_inner | epoch 034:    381 / 1474 loss=1.983, trans_loss=4.754, nll_loss=1.947, w2v_ctc_loss=0.686, task_loss=0, contrastive_loss=0.154, total=4151.69, n_correct=2858.44, ppl=3.86, accuracy=68.85, wps=16045.7, ups=1.93, wpb=8303.4, bsz=316.4, num_updates=49000, lr=6.38877e-05, gnorm=0.682, clip=0, loss_scale=4, train_wall=51, gb_free=15.8, wall=31110
2023-08-18 04:47:48 | INFO | train_inner | epoch 034:    481 / 1474 loss=1.975, trans_loss=4.761, nll_loss=1.956, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.047, total=4078.14, n_correct=2805, ppl=3.88, accuracy=68.781, wps=15887.2, ups=1.95, wpb=8156.3, bsz=284.7, num_updates=49100, lr=6.38226e-05, gnorm=0.608, clip=0, loss_scale=4, train_wall=51, gb_free=16.3, wall=31161
2023-08-18 04:48:39 | INFO | train_inner | epoch 034:    581 / 1474 loss=1.966, trans_loss=4.75, nll_loss=1.942, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.05, total=4130.95, n_correct=2852.99, ppl=3.84, accuracy=69.064, wps=16010.8, ups=1.94, wpb=8261.9, bsz=302, num_updates=49200, lr=6.37577e-05, gnorm=0.582, clip=0, loss_scale=4, train_wall=51, gb_free=17.6, wall=31213
2023-08-18 04:49:31 | INFO | train_inner | epoch 034:    681 / 1474 loss=1.971, trans_loss=4.76, nll_loss=1.955, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.047, total=4110.04, n_correct=2830.17, ppl=3.88, accuracy=68.86, wps=15900.8, ups=1.93, wpb=8220.1, bsz=296.9, num_updates=49300, lr=6.3693e-05, gnorm=0.552, clip=0, loss_scale=4, train_wall=51, gb_free=17.3, wall=31265
2023-08-18 04:50:23 | INFO | train_inner | epoch 034:    781 / 1474 loss=1.986, trans_loss=4.777, nll_loss=1.977, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.116, total=4079.01, n_correct=2793.88, ppl=3.94, accuracy=68.494, wps=15740.5, ups=1.93, wpb=8158, bsz=295.7, num_updates=49400, lr=6.36285e-05, gnorm=0.654, clip=0, loss_scale=4, train_wall=51, gb_free=15.6, wall=31317
2023-08-18 04:51:15 | INFO | train_inner | epoch 034:    881 / 1474 loss=1.981, trans_loss=4.768, nll_loss=1.965, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.074, total=4092.48, n_correct=2810.73, ppl=3.91, accuracy=68.68, wps=15708.2, ups=1.92, wpb=8185, bsz=295.5, num_updates=49500, lr=6.35642e-05, gnorm=0.607, clip=0, loss_scale=4, train_wall=52, gb_free=16.6, wall=31369
2023-08-18 04:52:07 | INFO | train_inner | epoch 034:    981 / 1474 loss=1.984, trans_loss=4.767, nll_loss=1.964, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.072, total=4185.89, n_correct=2874.95, ppl=3.9, accuracy=68.682, wps=16230.6, ups=1.94, wpb=8371.8, bsz=315, num_updates=49600, lr=6.35001e-05, gnorm=0.651, clip=0, loss_scale=8, train_wall=51, gb_free=16.8, wall=31420
2023-08-18 04:52:58 | INFO | train_inner | epoch 034:   1081 / 1474 loss=1.976, trans_loss=4.764, nll_loss=1.959, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.052, total=4142.31, n_correct=2849.76, ppl=3.89, accuracy=68.796, wps=16203.6, ups=1.96, wpb=8284.6, bsz=306.1, num_updates=49700, lr=6.34361e-05, gnorm=0.598, clip=0, loss_scale=8, train_wall=51, gb_free=17.9, wall=31471
2023-08-18 04:53:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-18 04:53:50 | INFO | train_inner | epoch 034:   1182 / 1474 loss=1.977, trans_loss=4.765, nll_loss=1.962, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.064, total=4099.19, n_correct=2818.44, ppl=3.9, accuracy=68.756, wps=15566.9, ups=1.9, wpb=8198.4, bsz=296.1, num_updates=49800, lr=6.33724e-05, gnorm=0.599, clip=0, loss_scale=4, train_wall=52, gb_free=15.5, wall=31524
2023-08-18 04:54:42 | INFO | train_inner | epoch 034:   1282 / 1474 loss=1.977, trans_loss=4.762, nll_loss=1.958, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.05, total=4161.82, n_correct=2861.05, ppl=3.89, accuracy=68.745, wps=16079.9, ups=1.93, wpb=8323.6, bsz=303.8, num_updates=49900, lr=6.33089e-05, gnorm=0.738, clip=1, loss_scale=4, train_wall=51, gb_free=16.3, wall=31576
2023-08-18 04:55:34 | INFO | train_inner | epoch 034:   1382 / 1474 loss=1.993, trans_loss=4.773, nll_loss=1.972, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.113, total=4184.94, n_correct=2866.93, ppl=3.92, accuracy=68.506, wps=16126.3, ups=1.93, wpb=8369.9, bsz=318, num_updates=50000, lr=6.32456e-05, gnorm=0.561, clip=0, loss_scale=4, train_wall=51, gb_free=11.7, wall=31628
2023-08-18 04:55:34 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-18 04:55:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-18 04:56:06 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.088 | trans_loss 5.175 | nll_loss 2.432 | w2v_ctc_loss 1.368 | task_loss 0 | contrastive_loss 0.268 | total 4003.4 | n_correct 2672.1 | ppl 5.4 | accuracy 66.746 | uer 17.708 | wer 19.626 | raw_wer 19.626 | bleu 22.25 | wps 1709.5 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.25
2023-08-18 04:56:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-18 04:56:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-18 04:56:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-18 04:56:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v2_merge_large_0818_baseline_alpha1.5_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.25) (writing took 11.932921150990296 seconds)
2023-08-18 04:56:18 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-18 04:56:18 | INFO | train | epoch 034 | loss 1.98 | trans_loss 4.763 | nll_loss 1.958 | w2v_ctc_loss 0.689 | task_loss 0 | contrastive_loss 0.089 | total 4132.8 | n_correct 2842.53 | ppl 3.89 | accuracy 68.78 | wps 14900 | ups 1.8 | wpb 8265.6 | bsz 304.1 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.618 | clip 0.1 | loss_scale 4 | train_wall 707 | gb_free 11.7 | wall 31672
2023-08-18 04:56:18 | INFO | fairseq_cli.train | done training in 31626.6 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
