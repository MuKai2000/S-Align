2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12948
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12948
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12948
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12948
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12948
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12948
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12948
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12948
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-01 19:49:52 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-09-01 19:49:52 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-09-01 19:49:55 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12948', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-01 19:49:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-09-01 19:49:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-09-01 19:49:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-09-01 19:49:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-09-01 19:49:55 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-01 19:50:00 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-09-01 19:50:00 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-09-01 19:50:00 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-09-01 19:50:01 | INFO | root | load pretrained hubert
2023-09-01 19:50:09 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-09-01 19:50:13 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-01 19:50:19 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-09-01 19:50:20 | INFO | root | share the sematic adapter and textual encoder
2023-09-01 19:50:20 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-09-01 19:50:20 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-09-01 19:50:20 | INFO | fairseq_cli.train | model: S2TJoint
2023-09-01 19:50:20 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-09-01 19:50:20 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-09-01 19:50:20 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-01 19:50:20 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-01 19:50:20 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-01 19:50:20 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-01 19:50:20 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-01 19:50:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-01 19:50:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-09-01 19:50:35 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-09-01 19:50:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-01 19:50:35 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-01 19:50:35 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-01 19:50:35 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-01 19:50:35 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-01 19:50:35 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-01 19:50:35 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-01 19:50:35 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-01 19:50:35 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-01 19:50:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-01 19:50:35 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-09-01 19:50:35 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-09-01 19:50:35 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-01 19:50:35 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_last.pt
2023-09-01 19:50:35 | INFO | fairseq.trainer | loading train data for epoch 1
2023-09-01 19:50:35 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-01 19:50:35 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-01 19:50:35 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-09-01 19:50:37 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-01 19:50:39 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-01 19:51:19 | INFO | fairseq.optim.adam | using FusedAdam
2023-09-01 19:51:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-01 19:51:19 | INFO | fairseq.trainer | begin training epoch 1
2023-09-01 19:51:19 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
2023-09-01 19:51:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
2023-09-01 19:52:31 | INFO | train_inner | epoch 001:    101 / 1474 loss=17.39, trans_loss=5.881, nll_loss=4.692, w2v_ctc_loss=22.309, task_loss=4.959, task_loss_gen=4.891, contrastive_loss=0, total=4212.33, n_correct=124.46, ppl=25.85, accuracy=2.955, wps=20753.1, ups=1.66, wpb=12566.1, bsz=472.9, num_updates=100, lr=4.098e-06, gnorm=2.695, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=115
2023-09-01 19:52:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-01 19:53:31 | INFO | train_inner | epoch 001:    202 / 1474 loss=13.542, trans_loss=5.954, nll_loss=4.813, w2v_ctc_loss=16.303, task_loss=5.972, task_loss_gen=5.042, contrastive_loss=0, total=4127.88, n_correct=122.95, ppl=28.11, accuracy=2.979, wps=20455.1, ups=1.66, wpb=12326, bsz=463, num_updates=200, lr=8.096e-06, gnorm=7.325, clip=15, loss_scale=32, train_wall=60, gb_free=18.7, wall=176
2023-09-01 19:54:32 | INFO | train_inner | epoch 001:    302 / 1474 loss=7.362, trans_loss=5.986, nll_loss=4.888, w2v_ctc_loss=6.746, task_loss=7.781, task_loss_gen=5.673, contrastive_loss=0, total=4077.62, n_correct=136.72, ppl=29.62, accuracy=3.353, wps=20120.8, ups=1.65, wpb=12179.5, bsz=437.4, num_updates=300, lr=1.2094e-05, gnorm=1.409, clip=0, loss_scale=32, train_wall=60, gb_free=19.3, wall=236
2023-09-01 19:55:32 | INFO | train_inner | epoch 001:    402 / 1474 loss=6.846, trans_loss=5.932, nll_loss=4.847, w2v_ctc_loss=6.011, task_loss=6.475, task_loss_gen=5.075, contrastive_loss=0, total=4177.45, n_correct=99.42, ppl=28.78, accuracy=2.38, wps=20766.4, ups=1.66, wpb=12474.2, bsz=462.8, num_updates=400, lr=1.6092e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=59, gb_free=18.7, wall=296
2023-09-01 19:56:32 | INFO | train_inner | epoch 001:    502 / 1474 loss=6.808, trans_loss=6.18, nll_loss=5.168, w2v_ctc_loss=5.69, task_loss=5.598, task_loss_gen=4.811, contrastive_loss=0, total=4202.06, n_correct=25.66, ppl=35.94, accuracy=0.611, wps=20927.8, ups=1.67, wpb=12556.3, bsz=490.7, num_updates=500, lr=2.009e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=59, gb_free=14.6, wall=356
2023-09-01 19:57:31 | INFO | train_inner | epoch 001:    602 / 1474 loss=6.823, trans_loss=6.418, nll_loss=5.47, w2v_ctc_loss=5.465, task_loss=4.719, task_loss_gen=4.972, contrastive_loss=0, total=4124.52, n_correct=5.05, ppl=44.33, accuracy=0.122, wps=20660.9, ups=1.68, wpb=12301.1, bsz=471, num_updates=600, lr=2.4088e-05, gnorm=0.382, clip=0, loss_scale=32, train_wall=59, gb_free=18.8, wall=416
2023-09-01 19:58:31 | INFO | train_inner | epoch 001:    702 / 1474 loss=6.419, trans_loss=6.153, nll_loss=5.137, w2v_ctc_loss=5.116, task_loss=3.687, task_loss_gen=5.409, contrastive_loss=0, total=4147.01, n_correct=13.81, ppl=35.19, accuracy=0.333, wps=20837.7, ups=1.68, wpb=12381.3, bsz=455.2, num_updates=700, lr=2.8086e-05, gnorm=0.453, clip=0, loss_scale=32, train_wall=59, gb_free=19.1, wall=475
2023-09-01 19:59:31 | INFO | train_inner | epoch 001:    802 / 1474 loss=6.097, trans_loss=6.108, nll_loss=5.07, w2v_ctc_loss=4.668, task_loss=2.434, task_loss_gen=6.015, contrastive_loss=0, total=4121.11, n_correct=14.21, ppl=33.59, accuracy=0.345, wps=20573, ups=1.67, wpb=12298.3, bsz=463.4, num_updates=800, lr=3.2084e-05, gnorm=0.746, clip=0, loss_scale=32, train_wall=59, gb_free=19.1, wall=535
2023-09-01 20:00:50 | INFO | train_inner | epoch 001:    902 / 1474 loss=5.879, trans_loss=6.083, nll_loss=5.059, w2v_ctc_loss=4.359, task_loss=1.904, task_loss_gen=6.902, contrastive_loss=0, total=4167.98, n_correct=15.08, ppl=33.33, accuracy=0.362, wps=15601.8, ups=1.25, wpb=12446.6, bsz=457.5, num_updates=900, lr=3.6082e-05, gnorm=0.771, clip=0, loss_scale=32, train_wall=79, gb_free=19, wall=615
2023-09-01 20:02:14 | INFO | train_inner | epoch 001:   1002 / 1474 loss=5.673, trans_loss=6.022, nll_loss=4.98, w2v_ctc_loss=4.102, task_loss=0.827, task_loss_gen=9.154, contrastive_loss=0, total=4136.38, n_correct=20.42, ppl=31.56, accuracy=0.494, wps=14838.9, ups=1.2, wpb=12354.6, bsz=458.8, num_updates=1000, lr=4.008e-05, gnorm=0.964, clip=0, loss_scale=32, train_wall=83, gb_free=19.2, wall=698
2023-09-01 20:03:34 | INFO | train_inner | epoch 001:   1102 / 1474 loss=5.673, trans_loss=6.191, nll_loss=5.194, w2v_ctc_loss=3.928, task_loss=4.892, task_loss_gen=5.547, contrastive_loss=0, total=4148.31, n_correct=3.23, ppl=36.61, accuracy=0.078, wps=15352.3, ups=1.24, wpb=12371.7, bsz=453.4, num_updates=1100, lr=4.4078e-05, gnorm=0.969, clip=0, loss_scale=32, train_wall=79, gb_free=18.6, wall=779
2023-09-01 20:03:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-01 20:04:53 | INFO | train_inner | epoch 001:   1203 / 1474 loss=5.485, trans_loss=6.028, nll_loss=4.975, w2v_ctc_loss=3.801, task_loss=5.53, task_loss_gen=5.664, contrastive_loss=0, total=4116.39, n_correct=15.41, ppl=31.45, accuracy=0.374, wps=15515.1, ups=1.26, wpb=12295.1, bsz=430, num_updates=1200, lr=4.8076e-05, gnorm=1.028, clip=0, loss_scale=16, train_wall=68, gb_free=18.8, wall=858
2023-09-01 20:06:12 | INFO | train_inner | epoch 001:   1303 / 1474 loss=5.432, trans_loss=6.095, nll_loss=5.079, w2v_ctc_loss=3.655, task_loss=4.754, task_loss_gen=5.585, contrastive_loss=0, total=4055.88, n_correct=4.96, ppl=33.81, accuracy=0.122, wps=15354.7, ups=1.27, wpb=12109.1, bsz=443.9, num_updates=1300, lr=5.2074e-05, gnorm=1.025, clip=0, loss_scale=16, train_wall=75, gb_free=19.2, wall=937
2023-09-01 20:07:31 | INFO | train_inner | epoch 001:   1403 / 1474 loss=5.356, trans_loss=6.105, nll_loss=5.106, w2v_ctc_loss=3.53, task_loss=3.581, task_loss_gen=6.061, contrastive_loss=0, total=4127.47, n_correct=44.79, ppl=34.44, accuracy=1.085, wps=15656.7, ups=1.27, wpb=12332.8, bsz=452, num_updates=1400, lr=5.6072e-05, gnorm=1.043, clip=0, loss_scale=16, train_wall=78, gb_free=19.1, wall=1016
2023-09-01 20:08:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-01 20:09:15 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 10.546 | trans_loss 13.612 | nll_loss 13.449 | w2v_ctc_loss 4.478 | task_loss 25.615 | task_loss_gen 26.48 | contrastive_loss 0 | total 4003.4 | n_correct 18.4 | ppl 11186.2 | accuracy 0.46 | uer 60.152 | wer 58.726 | raw_wer 58.726 | bleu 0 | wps 951 | wpb 4003.4 | bsz 141.8 | num_updates 1471
2023-09-01 20:09:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1471 updates
2023-09-01 20:09:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 20:09:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 20:09:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1471 updates, score 0.0) (writing took 4.4389753630093765 seconds)
2023-09-01 20:09:19 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-09-01 20:09:19 | INFO | train | epoch 001 | loss 7.395 | trans_loss 6.085 | nll_loss 5.04 | w2v_ctc_loss 6.692 | task_loss 4.421 | task_loss_gen 5.762 | contrastive_loss 0 | total 4138.13 | n_correct 44.2271 | ppl 32.9 | accuracy 1.069 | wps 16998.1 | ups 1.38 | wpb 12354.2 | bsz 458.2 | num_updates 1471 | lr 5.89106e-05 | gnorm 1.409 | clip 1 | loss_scale 16 | train_wall 996 | gb_free 18.9 | wall 1124
2023-09-01 20:09:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-01 20:09:20 | INFO | fairseq.trainer | begin training epoch 2
2023-09-01 20:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 20:09:46 | INFO | train_inner | epoch 002:     29 / 1474 loss=5.294, trans_loss=6.119, nll_loss=5.11, w2v_ctc_loss=3.418, task_loss=2.888, task_loss_gen=5.669, contrastive_loss=0, total=4165.52, n_correct=8.02, ppl=34.54, accuracy=0.193, wps=9240.5, ups=0.74, wpb=12425.3, bsz=471.4, num_updates=1500, lr=6.007e-05, gnorm=1.265, clip=0, loss_scale=16, train_wall=73, gb_free=18.7, wall=1150
2023-09-01 20:10:45 | INFO | train_inner | epoch 002:    129 / 1474 loss=5.204, trans_loss=6.055, nll_loss=5.009, w2v_ctc_loss=3.345, task_loss=2.86, task_loss_gen=6.441, contrastive_loss=0, total=4149.27, n_correct=13.12, ppl=32.2, accuracy=0.316, wps=20939.1, ups=1.69, wpb=12375.1, bsz=451.7, num_updates=1600, lr=6.4068e-05, gnorm=1.036, clip=0, loss_scale=16, train_wall=58, gb_free=18.7, wall=1209
2023-09-01 20:11:43 | INFO | train_inner | epoch 002:    229 / 1474 loss=5.142, trans_loss=6.08, nll_loss=5.06, w2v_ctc_loss=3.228, task_loss=1.794, task_loss_gen=5.673, contrastive_loss=0, total=4199.2, n_correct=3.5, ppl=33.37, accuracy=0.083, wps=21327.1, ups=1.7, wpb=12541.6, bsz=494.4, num_updates=1700, lr=6.8066e-05, gnorm=1.055, clip=0, loss_scale=16, train_wall=58, gb_free=18.8, wall=1268
2023-09-01 20:12:43 | INFO | train_inner | epoch 002:    329 / 1474 loss=5.199, trans_loss=6.189, nll_loss=5.192, w2v_ctc_loss=3.191, task_loss=2.078, task_loss_gen=6.769, contrastive_loss=0, total=4130.92, n_correct=11.82, ppl=36.55, accuracy=0.286, wps=20689.1, ups=1.68, wpb=12331.6, bsz=442.3, num_updates=1800, lr=7.2064e-05, gnorm=1.072, clip=0, loss_scale=16, train_wall=59, gb_free=18.6, wall=1328
2023-09-01 20:13:42 | INFO | train_inner | epoch 002:    429 / 1474 loss=5.087, trans_loss=6.071, nll_loss=5.064, w2v_ctc_loss=3.141, task_loss=2.508, task_loss_gen=7.244, contrastive_loss=0, total=4036.18, n_correct=20.16, ppl=33.45, accuracy=0.499, wps=20442.7, ups=1.69, wpb=12064.4, bsz=416.3, num_updates=1900, lr=7.6062e-05, gnorm=0.932, clip=0, loss_scale=16, train_wall=58, gb_free=18.9, wall=1387
2023-09-01 20:14:42 | INFO | train_inner | epoch 002:    529 / 1474 loss=5.119, trans_loss=6.224, nll_loss=5.223, w2v_ctc_loss=3.036, task_loss=2.093, task_loss_gen=6.612, contrastive_loss=0, total=4185.63, n_correct=5.88, ppl=37.35, accuracy=0.14, wps=20737.9, ups=1.66, wpb=12487.7, bsz=470.3, num_updates=2000, lr=8.006e-05, gnorm=0.937, clip=0, loss_scale=16, train_wall=60, gb_free=18.7, wall=1447
2023-09-01 20:14:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 20:15:29 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.483 | trans_loss 13.773 | nll_loss 13.638 | w2v_ctc_loss 3.906 | task_loss 9.454 | task_loss_gen 33.669 | contrastive_loss 0 | total 4003.4 | n_correct 3.2 | ppl 12751.1 | accuracy 0.08 | uer 54.341 | wer 53.622 | raw_wer 53.622 | bleu 0 | wps 1040.9 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-09-01 20:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-09-01 20:15:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-09-01 20:15:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-09-01 20:15:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 11.686931726988405 seconds)
--------------------
Before gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0371, -0.0875, -0.0684,  ..., -0.0234, -0.0322, -0.0319],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0900, -0.0496,  0.0390,  ..., -0.0460,  0.0370, -0.0465]],
       device='cuda:0', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.9697, -0.7886,  0.1220, -0.2915,  1.6748], device='cuda:0',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0525, -0.1375, -0.0911,  ..., -0.0320, -0.0469, -0.0469],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1351, -0.1294,  0.0096,  ..., -0.0678,  0.0553, -0.0692]],
       device='cuda:0', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.9697, -0.7886,  0.1220, -0.2915,  1.6748], device='cuda:0',
       dtype=torch.float16)
--------------------
2023-09-01 20:16:40 | INFO | train_inner | epoch 002:    629 / 1474 loss=4.968, trans_loss=6.062, nll_loss=5.044, w2v_ctc_loss=2.971, task_loss=1.623, task_loss_gen=7.323, contrastive_loss=0, total=4116.05, n_correct=9.32, ppl=33, accuracy=0.226, wps=10480.7, ups=0.85, wpb=12285, bsz=443.4, num_updates=2100, lr=8.4058e-05, gnorm=0.985, clip=0, loss_scale=16, train_wall=58, gb_free=19.5, wall=1564
2023-09-01 20:17:38 | INFO | train_inner | epoch 002:    729 / 1474 loss=5.036, trans_loss=6.202, nll_loss=5.21, w2v_ctc_loss=2.933, task_loss=1.063, task_loss_gen=8.122, contrastive_loss=0, total=4152.4, n_correct=4.25, ppl=37.02, accuracy=0.102, wps=21086.8, ups=1.7, wpb=12393.8, bsz=463.6, num_updates=2200, lr=8.8056e-05, gnorm=0.888, clip=0, loss_scale=16, train_wall=58, gb_free=18.8, wall=1623
2023-09-01 20:18:37 | INFO | train_inner | epoch 002:    829 / 1474 loss=4.981, trans_loss=6.155, nll_loss=5.161, w2v_ctc_loss=2.897, task_loss=1.236, task_loss_gen=7.933, contrastive_loss=0, total=4168.87, n_correct=12.2, ppl=35.78, accuracy=0.293, wps=21077.3, ups=1.69, wpb=12453.5, bsz=461.2, num_updates=2300, lr=9.2054e-05, gnorm=0.819, clip=0, loss_scale=16, train_wall=58, gb_free=18.6, wall=1682
2023-09-01 20:19:37 | INFO | train_inner | epoch 002:    929 / 1474 loss=4.919, trans_loss=6.123, nll_loss=5.111, w2v_ctc_loss=2.833, task_loss=1.042, task_loss_gen=8.823, contrastive_loss=0, total=4104.79, n_correct=8.93, ppl=34.56, accuracy=0.218, wps=20720.4, ups=1.69, wpb=12254.8, bsz=445.6, num_updates=2400, lr=9.6052e-05, gnorm=0.826, clip=0, loss_scale=16, train_wall=59, gb_free=18.8, wall=1741
2023-09-01 20:20:37 | INFO | train_inner | epoch 002:   1029 / 1474 loss=4.917, trans_loss=6.157, nll_loss=5.158, w2v_ctc_loss=2.793, task_loss=0.736, task_loss_gen=9.549, contrastive_loss=0, total=4100.85, n_correct=8.42, ppl=35.7, accuracy=0.205, wps=20365, ups=1.66, wpb=12245.2, bsz=455.2, num_updates=2500, lr=0.00010005, gnorm=0.762, clip=0, loss_scale=16, train_wall=60, gb_free=19.2, wall=1801
2023-09-01 20:21:36 | INFO | train_inner | epoch 002:   1129 / 1474 loss=4.803, trans_loss=6.061, nll_loss=5.042, w2v_ctc_loss=2.728, task_loss=0.445, task_loss_gen=9.618, contrastive_loss=0, total=4195.47, n_correct=11.8, ppl=32.96, accuracy=0.281, wps=21057.1, ups=1.68, wpb=12522.7, bsz=489.6, num_updates=2600, lr=0.000104048, gnorm=0.71, clip=0, loss_scale=16, train_wall=59, gb_free=18.8, wall=1861
2023-09-01 20:22:36 | INFO | train_inner | epoch 002:   1229 / 1474 loss=4.843, trans_loss=6.14, nll_loss=5.128, w2v_ctc_loss=2.707, task_loss=0.401, task_loss_gen=10.238, contrastive_loss=0, total=4220.45, n_correct=8.61, ppl=34.97, accuracy=0.204, wps=21130.2, ups=1.68, wpb=12591.7, bsz=492, num_updates=2700, lr=0.000108046, gnorm=0.662, clip=0, loss_scale=16, train_wall=59, gb_free=19.6, wall=1920
2023-09-01 20:23:35 | INFO | train_inner | epoch 002:   1329 / 1474 loss=4.897, trans_loss=6.233, nll_loss=5.25, w2v_ctc_loss=2.682, task_loss=0.324, task_loss_gen=11.659, contrastive_loss=0, total=4159.97, n_correct=8.93, ppl=38.07, accuracy=0.215, wps=21148.7, ups=1.7, wpb=12433.6, bsz=462.1, num_updates=2800, lr=0.000112044, gnorm=0.639, clip=0, loss_scale=16, train_wall=58, gb_free=19.4, wall=1979
2023-09-01 20:24:34 | INFO | train_inner | epoch 002:   1429 / 1474 loss=4.763, trans_loss=6.059, nll_loss=5.031, w2v_ctc_loss=2.662, task_loss=0.214, task_loss_gen=15.194, contrastive_loss=0, total=4050.6, n_correct=26.14, ppl=32.68, accuracy=0.645, wps=20424.6, ups=1.69, wpb=12095, bsz=438.3, num_updates=2900, lr=0.000116042, gnorm=0.712, clip=0, loss_scale=16, train_wall=59, gb_free=19.5, wall=2038
2023-09-01 20:25:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--------------------
Before gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0059, -0.0818, -0.0525,  ..., -0.0289, -0.0202, -0.0169],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0076,  0.0411, -0.0582,  ..., -0.0293,  0.0158, -0.0120]],
       device='cuda:7', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.2808, -0.2120,  0.0468, -0.1526,  0.6270], device='cuda:7',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0087, -0.1198, -0.0685,  ..., -0.0422, -0.0288, -0.0254],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0104,  0.0606, -0.1093,  ..., -0.0459,  0.0283, -0.0204]],
       device='cuda:7', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.2808, -0.2120,  0.0468, -0.1526,  0.6270], device='cuda:7',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0673,  0.0011,  0.1260,  ..., -0.0049, -0.0199, -0.0074],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1129,  0.1907,  0.0420,  ..., -0.0313,  0.0289, -0.0422]],
       device='cuda:5', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.7427, -0.6177,  0.0900, -0.2959,  1.3555], device='cuda:5',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0939,  0.0079,  0.1792,  ..., -0.0045, -0.0257, -0.0083],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1617,  0.2998,  0.0902,  ..., -0.0465,  0.0419, -0.0631]],
       device='cuda:5', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.7427, -0.6177,  0.0900, -0.2959,  1.3555], device='cuda:5',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0538, -0.0308, -0.1014,  ..., -0.0173, -0.0210,  0.0119],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1549, -0.3757, -0.0803,  ...,  0.0327,  0.1378, -0.0477]],
       device='cuda:4', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.9062, -0.9688,  0.1370, -0.2651,  1.9854], device='cuda:4',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0794, -0.0286, -0.1663,  ..., -0.0258, -0.0307,  0.0144],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.2317, -0.5898, -0.1293,  ...,  0.0592,  0.2096, -0.0743]],
       device='cuda:4', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.9062, -0.9688,  0.1370, -0.2651,  1.9854], device='cuda:4',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0370, -0.0665, -0.0097,  ..., -0.0181, -0.0177, -0.0218],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0218,  0.1228,  0.0439,  ..., -0.0316,  0.0198, -0.0138]],
       device='cuda:6', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.3069, -0.1819,  0.0333, -0.1418,  0.5381], device='cuda:6',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0598, -0.1008, -0.0134,  ..., -0.0260, -0.0251, -0.0298],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0363,  0.1744,  0.0693,  ..., -0.0464,  0.0266, -0.0219]],
       device='cuda:6', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.3069, -0.1819,  0.0333, -0.1418,  0.5381], device='cuda:6',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0860, -0.0455, -0.2277,  ..., -0.0246, -0.0019, -0.0305],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0184, -0.1230, -0.4358,  ...,  0.0014,  0.0658, -0.0740]],
       device='cuda:1', dtype=torch.float16)
task_net layer_norm.weight True tensor([-2.4590, -2.1484,  0.2866, -0.4324,  3.0664], device='cuda:1',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.3086e-01, -6.5491e-02, -3.3887e-01,  ..., -3.6224e-02,
         -1.9836e-04, -4.5898e-02],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.3300e-02, -2.1899e-01, -6.9043e-01,  ..., -4.2572e-03,
          9.7656e-02, -1.1389e-01]], device='cuda:1', dtype=torch.float16)
task_net layer_norm.weight True tensor([-2.4590, -2.1484,  0.2866, -0.4324,  3.0664], device='cuda:1',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0517, -0.0754, -0.0388,  ..., -0.0234, -0.0168, -0.0159],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0737, -0.1426, -0.0426,  ..., -0.0351,  0.0388, -0.0214]],
       device='cuda:3', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.2795, -0.3459,  0.0253, -0.1969,  0.7305], device='cuda:3',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0762, -0.1141, -0.0444,  ..., -0.0359, -0.0238, -0.0186],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1060, -0.1927, -0.0664,  ..., -0.0473,  0.0503, -0.0318]],
       device='cuda:3', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.2795, -0.3459,  0.0253, -0.1969,  0.7305], device='cuda:3',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0522, -0.1348, -0.0104,  ..., -0.0167, -0.0093, -0.0469],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0154, -0.2479, -0.4033,  ..., -0.0423,  0.0854, -0.0518]],
       device='cuda:2', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.5278, -0.2139,  0.0511, -0.2490,  0.8354], device='cuda:2',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0801, -0.1862,  0.0077,  ..., -0.0195, -0.0217, -0.0667],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0248, -0.4001, -0.6650,  ..., -0.0643,  0.1294, -0.0814]],
       device='cuda:2', dtype=torch.float16)
task_net layer_norm.weight True tensor([-0.5278, -0.2139,  0.0511, -0.2490,  0.8354], device='cuda:2',
       dtype=torch.float16)
--------------------
2023-09-01 20:25:47 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.377 | trans_loss 13.843 | nll_loss 13.693 | w2v_ctc_loss 3.394 | task_loss 0.874 | task_loss_gen 74.21 | contrastive_loss 0 | total 4003.4 | n_correct 0.2 | ppl 13244.4 | accuracy 0.005 | uer 48.483 | wer 47.302 | raw_wer 47.302 | bleu 0 | wps 1031.6 | wpb 4003.4 | bsz 141.8 | num_updates 2945 | best_bleu 0
2023-09-01 20:25:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2945 updates
2023-09-01 20:25:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 20:25:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 20:25:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2945 updates, score 0.0) (writing took 11.758677337988047 seconds)
2023-09-01 20:25:59 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-09-01 20:25:59 | INFO | train | epoch 002 | loss 4.991 | trans_loss 6.129 | nll_loss 5.12 | w2v_ctc_loss 2.939 | task_loss 1.305 | task_loss_gen 8.773 | contrastive_loss 0 | total 4138.65 | n_correct 10.8847 | ppl 34.78 | accuracy 0.263 | wps 18211.6 | ups 1.47 | wpb 12355.8 | bsz 458.5 | num_updates 2945 | lr 0.000117841 | gnorm 0.86 | clip 0 | loss_scale 16 | train_wall 864 | gb_free 19 | wall 2124
2023-09-01 20:26:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-01 20:26:00 | INFO | fairseq.trainer | begin training epoch 3
2023-09-01 20:26:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 20:26:40 | INFO | train_inner | epoch 003:     55 / 1474 loss=4.829, trans_loss=6.196, nll_loss=5.204, w2v_ctc_loss=2.612, task_loss=0.131, task_loss_gen=15.754, contrastive_loss=0, total=4066.57, n_correct=7.98, ppl=36.86, accuracy=0.196, wps=9605, ups=0.79, wpb=12139.2, bsz=441.1, num_updates=3000, lr=0.00012004, gnorm=0.653, clip=0, loss_scale=16, train_wall=60, gb_free=18.7, wall=2165
2023-09-01 20:28:15 | INFO | train_inner | epoch 003:    155 / 1474 loss=3.978, trans_loss=5.274, nll_loss=4.045, w2v_ctc_loss=2.274, task_loss=0.021, task_loss_gen=16.089, contrastive_loss=0, total=4134.66, n_correct=305.03, ppl=16.51, accuracy=7.377, wps=12971.3, ups=1.05, wpb=12344.9, bsz=452.5, num_updates=3100, lr=0.000124038, gnorm=1.408, clip=0, loss_scale=16, train_wall=95, gb_free=14.7, wall=2260
2023-09-01 20:29:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-01 20:29:53 | INFO | train_inner | epoch 003:    256 / 1474 loss=3.419, trans_loss=4.696, nll_loss=3.268, w2v_ctc_loss=2.022, task_loss=0.005, task_loss_gen=21.57, contrastive_loss=0, total=4133.56, n_correct=717.58, ppl=9.63, accuracy=17.36, wps=12670.1, ups=1.03, wpb=12351.3, bsz=456.3, num_updates=3200, lr=0.000128036, gnorm=0.988, clip=0, loss_scale=8, train_wall=97, gb_free=16.3, wall=2357
2023-09-01 20:31:28 | INFO | train_inner | epoch 003:    356 / 1474 loss=3.084, trans_loss=4.303, nll_loss=2.742, w2v_ctc_loss=1.93, task_loss=0.001, task_loss_gen=24.684, contrastive_loss=0, total=4171.73, n_correct=1136, ppl=6.69, accuracy=27.231, wps=13122.1, ups=1.05, wpb=12449.7, bsz=468.2, num_updates=3300, lr=0.000132034, gnorm=1.06, clip=0, loss_scale=8, train_wall=94, gb_free=15.2, wall=2452
2023-09-01 20:32:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-01 20:33:05 | INFO | train_inner | epoch 003:    457 / 1474 loss=3.045, trans_loss=4.266, nll_loss=2.695, w2v_ctc_loss=1.911, task_loss=0.003, task_loss_gen=22.394, contrastive_loss=0, total=4204.59, n_correct=1203.92, ppl=6.47, accuracy=28.633, wps=12890.5, ups=1.03, wpb=12549.5, bsz=476, num_updates=3400, lr=0.000136032, gnorm=1.47, clip=0, loss_scale=4, train_wall=97, gb_free=12, wall=2550
2023-09-01 20:34:41 | INFO | train_inner | epoch 003:    557 / 1474 loss=3.009, trans_loss=4.259, nll_loss=2.69, w2v_ctc_loss=1.87, task_loss=0.027, task_loss_gen=18.168, contrastive_loss=0, total=4093.13, n_correct=1192.21, ppl=6.45, accuracy=29.127, wps=12759.8, ups=1.04, wpb=12228.7, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.275, clip=0, loss_scale=4, train_wall=95, gb_free=17.3, wall=2645
2023-09-01 20:36:18 | INFO | train_inner | epoch 003:    657 / 1474 loss=2.947, trans_loss=4.249, nll_loss=2.672, w2v_ctc_loss=1.794, task_loss=0.11, task_loss_gen=11.878, contrastive_loss=0, total=4222.97, n_correct=1256.51, ppl=6.37, accuracy=29.754, wps=12977.6, ups=1.03, wpb=12591.9, bsz=483.6, num_updates=3600, lr=0.000144028, gnorm=1.199, clip=0, loss_scale=4, train_wall=96, gb_free=16.6, wall=2742
2023-09-01 20:37:53 | INFO | train_inner | epoch 003:    757 / 1474 loss=2.938, trans_loss=4.221, nll_loss=2.641, w2v_ctc_loss=1.812, task_loss=0.144, task_loss_gen=10.876, contrastive_loss=0, total=4164.5, n_correct=1275.47, ppl=6.24, accuracy=30.627, wps=13050.3, ups=1.05, wpb=12438.4, bsz=470.6, num_updates=3700, lr=0.000148026, gnorm=1.44, clip=1, loss_scale=4, train_wall=94, gb_free=16.4, wall=2838
2023-09-01 20:39:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-01 20:39:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-09-01 20:39:31 | INFO | train_inner | epoch 003:    859 / 1474 loss=2.922, trans_loss=4.222, nll_loss=2.642, w2v_ctc_loss=1.789, task_loss=0.142, task_loss_gen=11.49, contrastive_loss=0, total=4167.66, n_correct=1283.04, ppl=6.24, accuracy=30.786, wps=12740.8, ups=1.02, wpb=12445.5, bsz=455.6, num_updates=3800, lr=0.000152024, gnorm=1.405, clip=0, loss_scale=1, train_wall=97, gb_free=16, wall=2935
2023-09-01 20:40:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-01 20:41:08 | INFO | train_inner | epoch 003:    960 / 1474 loss=2.952, trans_loss=4.297, nll_loss=2.729, w2v_ctc_loss=1.81, task_loss=0.236, task_loss_gen=8.961, contrastive_loss=0, total=4178.12, n_correct=1262.6, ppl=6.63, accuracy=30.219, wps=12803.8, ups=1.03, wpb=12461.4, bsz=475.7, num_updates=3900, lr=0.000156022, gnorm=2.026, clip=1, loss_scale=0.5, train_wall=97, gb_free=15.9, wall=3033
2023-09-01 20:42:44 | INFO | train_inner | epoch 003:   1060 / 1474 loss=3.004, trans_loss=4.363, nll_loss=2.812, w2v_ctc_loss=1.873, task_loss=0.559, task_loss_gen=8.233, contrastive_loss=0, total=4051.14, n_correct=1201.54, ppl=7.02, accuracy=29.659, wps=12648.5, ups=1.05, wpb=12099.4, bsz=436.8, num_updates=4000, lr=0.00016002, gnorm=2.774, clip=0, loss_scale=0.5, train_wall=95, gb_free=16.4, wall=3128
2023-09-01 20:42:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 20:43:24 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.757 | trans_loss 7.551 | nll_loss 5.494 | w2v_ctc_loss 2.174 | task_loss 5.712 | task_loss_gen 21.022 | contrastive_loss 0 | total 4003.4 | n_correct 1283.3 | ppl 45.07 | accuracy 32.055 | uer 32.318 | wer 33.008 | raw_wer 33.008 | bleu 0.18 | wps 1214.6 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 0.18
2023-09-01 20:43:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-09-01 20:43:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-09-01 20:43:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-09-01 20:43:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 0.18) (writing took 14.578013217978878 seconds)
2023-09-01 20:45:13 | INFO | train_inner | epoch 003:   1160 / 1474 loss=3.01, trans_loss=4.379, nll_loss=2.832, w2v_ctc_loss=1.879, task_loss=0.627, task_loss_gen=7.402, contrastive_loss=0, total=4050.25, n_correct=1192.51, ppl=7.12, accuracy=29.443, wps=8101.6, ups=0.67, wpb=12088.6, bsz=435.7, num_updates=4100, lr=0.000164018, gnorm=3.066, clip=3, loss_scale=0.5, train_wall=94, gb_free=16, wall=3278
2023-09-01 20:46:48 | INFO | train_inner | epoch 003:   1260 / 1474 loss=2.969, trans_loss=4.343, nll_loss=2.79, w2v_ctc_loss=1.847, task_loss=0.725, task_loss_gen=7.128, contrastive_loss=0, total=4058.28, n_correct=1223.61, ppl=6.91, accuracy=30.151, wps=12761.6, ups=1.05, wpb=12119.7, bsz=431.2, num_updates=4200, lr=0.000168016, gnorm=2.52, clip=0, loss_scale=0.5, train_wall=94, gb_free=16.1, wall=3373
2023-09-01 20:47:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-01 20:47:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2023-09-01 20:48:26 | INFO | train_inner | epoch 003:   1362 / 1474 loss=3.287, trans_loss=4.551, nll_loss=3.055, w2v_ctc_loss=2.259, task_loss=2.632, task_loss_gen=4.867, contrastive_loss=0, total=4133.85, n_correct=1174.12, ppl=8.31, accuracy=28.403, wps=12571.9, ups=1.02, wpb=12339.7, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=19.203, clip=77, loss_scale=0.125, train_wall=97, gb_free=17.4, wall=3471
2023-09-01 20:50:02 | INFO | train_inner | epoch 003:   1462 / 1474 loss=3.349, trans_loss=4.82, nll_loss=3.398, w2v_ctc_loss=2.342, task_loss=4.48, task_loss_gen=4.254, contrastive_loss=0, total=4206.88, n_correct=1174.53, ppl=10.54, accuracy=27.919, wps=13085, ups=1.04, wpb=12566, bsz=476, num_updates=4400, lr=0.000176012, gnorm=24.711, clip=96, loss_scale=0.125, train_wall=95, gb_free=14.7, wall=3567
2023-09-01 20:50:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 20:50:54 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.911 | trans_loss 7.624 | nll_loss 5.575 | w2v_ctc_loss 2.521 | task_loss 61.824 | task_loss_gen 32.891 | contrastive_loss 0 | total 4003.4 | n_correct 1261.9 | ppl 47.67 | accuracy 31.521 | uer 37.356 | wer 38.474 | raw_wer 38.474 | bleu 0.12 | wps 1168.9 | wpb 4003.4 | bsz 141.8 | num_updates 4412 | best_bleu 0.18
2023-09-01 20:50:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4412 updates
2023-09-01 20:50:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.1208.pt
2023-09-01 20:50:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.1208.pt
2023-09-01 20:51:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.1208.pt (epoch 3 @ 4412 updates, score 0.12) (writing took 6.624869368009968 seconds)
2023-09-01 20:51:01 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-09-01 20:51:01 | INFO | train | epoch 003 | loss 3.201 | trans_loss 4.517 | nll_loss 3.021 | w2v_ctc_loss 1.985 | task_loss 0.765 | task_loss_gen 12.833 | contrastive_loss 0 | total 4138.48 | n_correct 1072.71 | ppl 8.12 | accuracy 25.92 | wps 12068.7 | ups 0.98 | wpb 12355.3 | bsz 458 | num_updates 4412 | lr 0.000176492 | gnorm 4.821 | clip 13 | loss_scale 0.125 | train_wall 1382 | gb_free 16.2 | wall 3626
2023-09-01 20:51:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-01 20:51:01 | INFO | fairseq.trainer | begin training epoch 4
2023-09-01 20:51:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 20:52:32 | INFO | train_inner | epoch 004:     88 / 1474 loss=3.292, trans_loss=5.146, nll_loss=3.82, w2v_ctc_loss=2.307, task_loss=47.258, task_loss_gen=24.92, contrastive_loss=0, total=4082.27, n_correct=1199.68, ppl=14.13, accuracy=29.388, wps=8113.5, ups=0.67, wpb=12182.1, bsz=434.2, num_updates=4500, lr=0.00018001, gnorm=40.29, clip=100, loss_scale=0.125, train_wall=94, gb_free=17.5, wall=3717
2023-09-01 20:54:08 | INFO | train_inner | epoch 004:    188 / 1474 loss=3.184, trans_loss=5.174, nll_loss=3.869, w2v_ctc_loss=2.13, task_loss=35.106, task_loss_gen=18.748, contrastive_loss=0, total=4184.92, n_correct=1209.63, ppl=14.62, accuracy=28.904, wps=13092.9, ups=1.05, wpb=12496.9, bsz=470.3, num_updates=4600, lr=0.000184008, gnorm=39.476, clip=100, loss_scale=0.125, train_wall=95, gb_free=12.8, wall=3812
2023-09-01 20:55:43 | INFO | train_inner | epoch 004:    288 / 1474 loss=3.144, trans_loss=5.156, nll_loss=3.849, w2v_ctc_loss=2.08, task_loss=31.76, task_loss_gen=16.833, contrastive_loss=0, total=4150, n_correct=1218.05, ppl=14.41, accuracy=29.351, wps=12978.2, ups=1.05, wpb=12397.9, bsz=465.2, num_updates=4700, lr=0.000188006, gnorm=33.593, clip=100, loss_scale=0.125, train_wall=95, gb_free=16.6, wall=3908
2023-09-01 20:57:18 | INFO | train_inner | epoch 004:    388 / 1474 loss=3.107, trans_loss=5.116, nll_loss=3.796, w2v_ctc_loss=2.059, task_loss=18.59, task_loss_gen=10.03, contrastive_loss=0, total=4114.32, n_correct=1249.31, ppl=13.89, accuracy=30.365, wps=12929.9, ups=1.05, wpb=12277.1, bsz=440, num_updates=4800, lr=0.000192004, gnorm=28.368, clip=100, loss_scale=0.125, train_wall=94, gb_free=11.7, wall=4003
2023-09-01 20:58:54 | INFO | train_inner | epoch 004:    488 / 1474 loss=3.032, trans_loss=5.073, nll_loss=3.741, w2v_ctc_loss=1.981, task_loss=11.386, task_loss_gen=6.442, contrastive_loss=0, total=4239.74, n_correct=1318.72, ppl=13.37, accuracy=31.104, wps=13214, ups=1.04, wpb=12652.2, bsz=506.4, num_updates=4900, lr=0.000196002, gnorm=22.466, clip=98, loss_scale=0.125, train_wall=95, gb_free=16.7, wall=4099
2023-09-01 21:00:30 | INFO | train_inner | epoch 004:    588 / 1474 loss=2.976, trans_loss=5.054, nll_loss=3.72, w2v_ctc_loss=1.906, task_loss=12.106, task_loss_gen=6.899, contrastive_loss=0, total=4219.26, n_correct=1330.41, ppl=13.18, accuracy=31.532, wps=13183.8, ups=1.05, wpb=12596.5, bsz=483.8, num_updates=5000, lr=0.0002, gnorm=17.552, clip=94, loss_scale=0.125, train_wall=95, gb_free=15.8, wall=4194
mt_weight tensor(0.5000)
asr_weight tensor(0.4979, device='cuda:0')
2023-09-01 21:02:07 | INFO | train_inner | epoch 004:    688 / 1474 loss=3.018, trans_loss=5.059, nll_loss=3.722, w2v_ctc_loss=1.971, task_loss=11.241, task_loss_gen=6.816, contrastive_loss=0, total=4171.93, n_correct=1324.83, ppl=13.19, accuracy=31.756, wps=12725.5, ups=1.02, wpb=12436.9, bsz=453.3, num_updates=5100, lr=0.00019803, gnorm=13.882, clip=84, loss_scale=0.125, train_wall=97, gb_free=15.3, wall=4292
2023-09-01 21:03:43 | INFO | train_inner | epoch 004:    788 / 1474 loss=3.005, trans_loss=5.038, nll_loss=3.699, w2v_ctc_loss=1.962, task_loss=7.913, task_loss_gen=5.238, contrastive_loss=0, total=4029.4, n_correct=1293.26, ppl=12.99, accuracy=32.096, wps=12584.5, ups=1.05, wpb=12032.2, bsz=423.7, num_updates=5200, lr=0.000196116, gnorm=9.929, clip=37, loss_scale=0.125, train_wall=95, gb_free=16, wall=4388
2023-09-01 21:05:19 | INFO | train_inner | epoch 004:    888 / 1474 loss=2.937, trans_loss=5.024, nll_loss=3.683, w2v_ctc_loss=1.867, task_loss=6.768, task_loss_gen=4.855, contrastive_loss=0, total=4175.28, n_correct=1349.12, ppl=12.84, accuracy=32.312, wps=13017.8, ups=1.04, wpb=12468.9, bsz=463.7, num_updates=5300, lr=0.000194257, gnorm=8.046, clip=15, loss_scale=0.125, train_wall=95, gb_free=15.3, wall=4483
2023-09-01 21:06:55 | INFO | train_inner | epoch 004:    988 / 1474 loss=2.944, trans_loss=5.008, nll_loss=3.661, w2v_ctc_loss=1.888, task_loss=6.492, task_loss_gen=4.717, contrastive_loss=0, total=4132.46, n_correct=1350.91, ppl=12.65, accuracy=32.69, wps=12834.7, ups=1.04, wpb=12343.2, bsz=455.3, num_updates=5400, lr=0.00019245, gnorm=7.261, clip=8, loss_scale=0.125, train_wall=95, gb_free=10.2, wall=4580
2023-09-01 21:08:31 | INFO | train_inner | epoch 004:   1088 / 1474 loss=2.892, trans_loss=5.013, nll_loss=3.667, w2v_ctc_loss=1.804, task_loss=6.502, task_loss_gen=4.832, contrastive_loss=0, total=4073.98, n_correct=1327.73, ppl=12.71, accuracy=32.59, wps=12684.5, ups=1.04, wpb=12161.7, bsz=437.9, num_updates=5500, lr=0.000190693, gnorm=6.303, clip=2, loss_scale=0.125, train_wall=95, gb_free=15.6, wall=4675
2023-09-01 21:10:06 | INFO | train_inner | epoch 004:   1188 / 1474 loss=2.863, trans_loss=4.999, nll_loss=3.652, w2v_ctc_loss=1.775, task_loss=4.852, task_loss_gen=3.991, contrastive_loss=0, total=4172.46, n_correct=1378.14, ppl=12.57, accuracy=33.029, wps=13073, ups=1.05, wpb=12459.8, bsz=487.1, num_updates=5600, lr=0.000188982, gnorm=5.103, clip=0, loss_scale=0.125, train_wall=94, gb_free=10.9, wall=4771
2023-09-01 21:11:42 | INFO | train_inner | epoch 004:   1288 / 1474 loss=2.822, trans_loss=4.992, nll_loss=3.642, w2v_ctc_loss=1.716, task_loss=5.165, task_loss_gen=4.22, contrastive_loss=0, total=4140.32, n_correct=1373.9, ppl=12.48, accuracy=33.183, wps=12905.9, ups=1.04, wpb=12365.2, bsz=467.7, num_updates=5700, lr=0.000187317, gnorm=4.912, clip=1, loss_scale=0.125, train_wall=95, gb_free=16.8, wall=4867
2023-09-01 21:13:16 | INFO | train_inner | epoch 004:   1388 / 1474 loss=2.823, trans_loss=4.991, nll_loss=3.641, w2v_ctc_loss=1.716, task_loss=5.544, task_loss_gen=4.461, contrastive_loss=0, total=4092.66, n_correct=1358, ppl=12.47, accuracy=33.181, wps=12995.3, ups=1.06, wpb=12224.9, bsz=436.3, num_updates=5800, lr=0.000185695, gnorm=4.753, clip=0, loss_scale=0.125, train_wall=93, gb_free=16.2, wall=4961
2023-09-01 21:14:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4979, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4979, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4979, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4979, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4979, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4979, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4979, device='cuda:2')
2023-09-01 21:15:07 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.544 | trans_loss 7.345 | nll_loss 5.26 | w2v_ctc_loss 1.929 | task_loss 14.228 | task_loss_gen 15.2 | contrastive_loss 0 | total 4003.4 | n_correct 1379.9 | ppl 38.33 | accuracy 34.468 | uer 28.585 | wer 29.719 | raw_wer 29.719 | bleu 0.12 | wps 1903.4 | wpb 4003.4 | bsz 141.8 | num_updates 5886 | best_bleu 0.18
2023-09-01 21:15:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5886 updates
2023-09-01 21:15:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.1207.pt
2023-09-01 21:15:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.1207.pt
2023-09-01 21:15:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.1207.pt (epoch 4 @ 5886 updates, score 0.12) (writing took 7.874067431985168 seconds)
2023-09-01 21:15:15 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-09-01 21:15:15 | INFO | train | epoch 004 | loss 2.989 | trans_loss 5.056 | nll_loss 3.721 | w2v_ctc_loss 1.923 | task_loss 14.422 | task_loss_gen 8.502 | contrastive_loss 0 | total 4138.65 | n_correct 1310.16 | ppl 13.18 | accuracy 31.657 | wps 12531.9 | ups 1.01 | wpb 12355.8 | bsz 458.5 | num_updates 5886 | lr 0.000184334 | gnorm 16.256 | clip 49.3 | loss_scale 0.125 | train_wall 1397 | gb_free 14.5 | wall 5079
2023-09-01 21:15:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-01 21:15:15 | INFO | fairseq.trainer | begin training epoch 5
2023-09-01 21:15:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 21:15:35 | INFO | train_inner | epoch 005:     14 / 1474 loss=2.795, trans_loss=4.987, nll_loss=3.635, w2v_ctc_loss=1.676, task_loss=4.821, task_loss_gen=4.192, contrastive_loss=0, total=4073.09, n_correct=1359.25, ppl=12.42, accuracy=33.371, wps=8747.5, ups=0.72, wpb=12158.4, bsz=451.4, num_updates=5900, lr=0.000184115, gnorm=4.024, clip=0, loss_scale=0.125, train_wall=93, gb_free=17, wall=5100
2023-09-01 21:17:11 | INFO | train_inner | epoch 005:    114 / 1474 loss=2.72, trans_loss=4.955, nll_loss=3.594, w2v_ctc_loss=1.579, task_loss=4.356, task_loss_gen=3.811, contrastive_loss=0, total=4233.69, n_correct=1437.24, ppl=12.08, accuracy=33.948, wps=13256, ups=1.05, wpb=12643.8, bsz=488.6, num_updates=6000, lr=0.000182574, gnorm=3.63, clip=0, loss_scale=0.125, train_wall=95, gb_free=15.5, wall=5195
2023-09-01 21:17:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 21:17:40 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.509 | trans_loss 7.346 | nll_loss 5.26 | w2v_ctc_loss 1.807 | task_loss 11.49 | task_loss_gen 15.624 | contrastive_loss 0 | total 4003.4 | n_correct 1375 | ppl 38.31 | accuracy 34.346 | uer 28.453 | wer 29.641 | raw_wer 29.641 | bleu 0.2 | wps 1910.2 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 0.2
2023-09-01 21:17:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-09-01 21:17:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-09-01 21:17:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-09-01 21:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 0.2) (writing took 12.058129654993536 seconds)
2023-09-01 21:19:26 | INFO | train_inner | epoch 005:    214 / 1474 loss=2.702, trans_loss=4.948, nll_loss=3.583, w2v_ctc_loss=1.558, task_loss=3.822, task_loss_gen=3.854, contrastive_loss=0, total=4185.02, n_correct=1429.36, ppl=11.98, accuracy=34.154, wps=9206.3, ups=0.74, wpb=12486.5, bsz=485.7, num_updates=6100, lr=0.000181071, gnorm=3.097, clip=1, loss_scale=0.125, train_wall=93, gb_free=16.4, wall=5331
2023-09-01 21:21:01 | INFO | train_inner | epoch 005:    314 / 1474 loss=2.736, trans_loss=4.948, nll_loss=3.587, w2v_ctc_loss=1.609, task_loss=4.148, task_loss_gen=4.155, contrastive_loss=0, total=4097.42, n_correct=1391.93, ppl=12.02, accuracy=33.971, wps=12957.7, ups=1.06, wpb=12251.6, bsz=448, num_updates=6200, lr=0.000179605, gnorm=3.037, clip=1, loss_scale=0.125, train_wall=94, gb_free=13.8, wall=5425
2023-09-01 21:22:36 | INFO | train_inner | epoch 005:    414 / 1474 loss=2.672, trans_loss=4.943, nll_loss=3.581, w2v_ctc_loss=1.511, task_loss=4.13, task_loss_gen=4.036, contrastive_loss=0, total=4135.49, n_correct=1406.32, ppl=11.97, accuracy=34.006, wps=12943.6, ups=1.05, wpb=12359.1, bsz=465.9, num_updates=6300, lr=0.000178174, gnorm=2.423, clip=0, loss_scale=0.25, train_wall=95, gb_free=17.1, wall=5521
2023-09-01 21:24:11 | INFO | train_inner | epoch 005:    514 / 1474 loss=2.661, trans_loss=4.943, nll_loss=3.579, w2v_ctc_loss=1.493, task_loss=4.438, task_loss_gen=4.446, contrastive_loss=0, total=4035.21, n_correct=1376.65, ppl=11.95, accuracy=34.116, wps=12673.8, ups=1.05, wpb=12051.5, bsz=427.7, num_updates=6400, lr=0.000176777, gnorm=1.498, clip=1, loss_scale=0.25, train_wall=94, gb_free=16.8, wall=5616
2023-09-01 21:25:46 | INFO | train_inner | epoch 005:    614 / 1474 loss=2.664, trans_loss=4.948, nll_loss=3.582, w2v_ctc_loss=1.494, task_loss=4.151, task_loss_gen=4.306, contrastive_loss=0, total=4117.64, n_correct=1404.79, ppl=11.98, accuracy=34.116, wps=12915.3, ups=1.05, wpb=12284.8, bsz=443.7, num_updates=6500, lr=0.000175412, gnorm=1.175, clip=0, loss_scale=0.25, train_wall=94, gb_free=16.9, wall=5711
2023-09-01 21:27:22 | INFO | train_inner | epoch 005:    714 / 1474 loss=2.709, trans_loss=4.94, nll_loss=3.575, w2v_ctc_loss=1.568, task_loss=3.625, task_loss_gen=3.938, contrastive_loss=0, total=4153.99, n_correct=1414.14, ppl=11.92, accuracy=34.043, wps=12982.5, ups=1.05, wpb=12400.6, bsz=476.1, num_updates=6600, lr=0.000174078, gnorm=2.492, clip=5, loss_scale=0.25, train_wall=95, gb_free=17.4, wall=5806
2023-09-01 21:27:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2023-09-01 21:28:59 | INFO | train_inner | epoch 005:    815 / 1474 loss=2.707, trans_loss=4.943, nll_loss=3.577, w2v_ctc_loss=1.562, task_loss=3.524, task_loss_gen=4.089, contrastive_loss=0, total=4131.79, n_correct=1405.41, ppl=11.94, accuracy=34.015, wps=12693.5, ups=1.03, wpb=12334.9, bsz=455.1, num_updates=6700, lr=0.000172774, gnorm=2.264, clip=1, loss_scale=0.125, train_wall=96, gb_free=17.4, wall=5904
2023-09-01 21:30:35 | INFO | train_inner | epoch 005:    915 / 1474 loss=2.751, trans_loss=4.942, nll_loss=3.577, w2v_ctc_loss=1.631, task_loss=4.264, task_loss_gen=4.278, contrastive_loss=0, total=4109.79, n_correct=1394.38, ppl=11.93, accuracy=33.928, wps=12847.7, ups=1.05, wpb=12270.6, bsz=446, num_updates=6800, lr=0.000171499, gnorm=4.631, clip=7, loss_scale=0.125, train_wall=95, gb_free=16.3, wall=5999
2023-09-01 21:32:10 | INFO | train_inner | epoch 005:   1015 / 1474 loss=2.674, trans_loss=4.935, nll_loss=3.568, w2v_ctc_loss=1.519, task_loss=3.699, task_loss_gen=4.01, contrastive_loss=0, total=4169.45, n_correct=1428.12, ppl=11.86, accuracy=34.252, wps=13114, ups=1.05, wpb=12445, bsz=463.3, num_updates=6900, lr=0.000170251, gnorm=1.806, clip=0, loss_scale=0.125, train_wall=94, gb_free=12, wall=6094
2023-09-01 21:33:46 | INFO | train_inner | epoch 005:   1115 / 1474 loss=2.708, trans_loss=4.931, nll_loss=3.559, w2v_ctc_loss=1.571, task_loss=3.677, task_loss_gen=4.06, contrastive_loss=0, total=4168.98, n_correct=1426.69, ppl=11.79, accuracy=34.222, wps=12902.1, ups=1.04, wpb=12437.1, bsz=464, num_updates=7000, lr=0.000169031, gnorm=2.47, clip=3, loss_scale=0.125, train_wall=96, gb_free=15.8, wall=6190
2023-09-01 21:33:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
2023-09-01 21:35:22 | INFO | train_inner | epoch 005:   1216 / 1474 loss=2.774, trans_loss=4.941, nll_loss=3.572, w2v_ctc_loss=1.667, task_loss=3.776, task_loss_gen=4.115, contrastive_loss=0, total=4161.5, n_correct=1426.11, ppl=11.89, accuracy=34.269, wps=12861.4, ups=1.04, wpb=12412.2, bsz=454.7, num_updates=7100, lr=0.000167836, gnorm=5.049, clip=6, loss_scale=0.0625, train_wall=96, gb_free=15.5, wall=6287
2023-09-01 21:36:59 | INFO | train_inner | epoch 005:   1316 / 1474 loss=2.652, trans_loss=4.932, nll_loss=3.564, w2v_ctc_loss=1.483, task_loss=3.624, task_loss_gen=4.132, contrastive_loss=0, total=4133.01, n_correct=1424.17, ppl=11.83, accuracy=34.458, wps=12827, ups=1.04, wpb=12337.1, bsz=445.7, num_updates=7200, lr=0.000166667, gnorm=2.727, clip=0, loss_scale=0.0625, train_wall=95, gb_free=14.6, wall=6383
2023-09-01 21:38:34 | INFO | train_inner | epoch 005:   1416 / 1474 loss=2.656, trans_loss=4.926, nll_loss=3.558, w2v_ctc_loss=1.493, task_loss=3.619, task_loss_gen=4.114, contrastive_loss=0, total=4133.51, n_correct=1423.99, ppl=11.77, accuracy=34.45, wps=12998.8, ups=1.05, wpb=12344.9, bsz=457.2, num_updates=7300, lr=0.000165521, gnorm=3.277, clip=2, loss_scale=0.0625, train_wall=94, gb_free=15.5, wall=6478
2023-09-01 21:39:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 21:40:00 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.456 | trans_loss 7.298 | nll_loss 5.208 | w2v_ctc_loss 1.741 | task_loss 9.293 | task_loss_gen 16.576 | contrastive_loss 0 | total 4003.4 | n_correct 1404.5 | ppl 36.95 | accuracy 35.083 | uer 27.136 | wer 28.444 | raw_wer 28.444 | bleu 0.2 | wps 1755 | wpb 4003.4 | bsz 141.8 | num_updates 7358 | best_bleu 0.2
2023-09-01 21:40:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7358 updates
2023-09-01 21:40:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 21:40:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 21:40:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7358 updates, score 0.2) (writing took 13.237379669008078 seconds)
2023-09-01 21:40:13 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-09-01 21:40:13 | INFO | train | epoch 005 | loss 2.701 | trans_loss 4.94 | nll_loss 3.575 | w2v_ctc_loss 1.556 | task_loss 3.905 | task_loss_gen 4.088 | contrastive_loss 0 | total 4138.94 | n_correct 1413.35 | ppl 11.91 | accuracy 34.148 | wps 12136.1 | ups 0.98 | wpb 12356.7 | bsz 458.6 | num_updates 7358 | lr 0.000164868 | gnorm 2.844 | clip 1.8 | loss_scale 0.0625 | train_wall 1394 | gb_free 15.9 | wall 6578
2023-09-01 21:40:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-01 21:40:13 | INFO | fairseq.trainer | begin training epoch 6
2023-09-01 21:40:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 21:41:01 | INFO | train_inner | epoch 006:     42 / 1474 loss=2.718, trans_loss=4.913, nll_loss=3.538, w2v_ctc_loss=1.596, task_loss=3.569, task_loss_gen=4.149, contrastive_loss=0, total=4117.69, n_correct=1422.32, ppl=11.61, accuracy=34.542, wps=8332.4, ups=0.68, wpb=12286.9, bsz=446.6, num_updates=7400, lr=0.000164399, gnorm=2.973, clip=1, loss_scale=0.0625, train_wall=95, gb_free=16.4, wall=6626
2023-09-01 21:42:37 | INFO | train_inner | epoch 006:    142 / 1474 loss=2.722, trans_loss=4.899, nll_loss=3.523, w2v_ctc_loss=1.607, task_loss=3.444, task_loss_gen=4.095, contrastive_loss=0, total=4162.89, n_correct=1445.99, ppl=11.49, accuracy=34.735, wps=13016.4, ups=1.05, wpb=12435.5, bsz=456.6, num_updates=7500, lr=0.000163299, gnorm=2.509, clip=2, loss_scale=0.0625, train_wall=95, gb_free=9.9, wall=6721
2023-09-01 21:44:12 | INFO | train_inner | epoch 006:    242 / 1474 loss=2.624, trans_loss=4.899, nll_loss=3.522, w2v_ctc_loss=1.457, task_loss=3.729, task_loss_gen=4.212, contrastive_loss=0, total=4127, n_correct=1440.81, ppl=11.49, accuracy=34.912, wps=12976.4, ups=1.05, wpb=12325.9, bsz=451, num_updates=7600, lr=0.000162221, gnorm=2.878, clip=0, loss_scale=0.0625, train_wall=94, gb_free=16.6, wall=6816
2023-09-01 21:45:49 | INFO | train_inner | epoch 006:    342 / 1474 loss=2.582, trans_loss=4.89, nll_loss=3.51, w2v_ctc_loss=1.401, task_loss=3.353, task_loss_gen=3.887, contrastive_loss=0, total=4151.56, n_correct=1450.94, ppl=11.39, accuracy=34.949, wps=12763.5, ups=1.03, wpb=12396.9, bsz=479.6, num_updates=7700, lr=0.000161165, gnorm=2.504, clip=1, loss_scale=0.0625, train_wall=96, gb_free=16.2, wall=6913
2023-09-01 21:47:23 | INFO | train_inner | epoch 006:    442 / 1474 loss=2.571, trans_loss=4.888, nll_loss=3.508, w2v_ctc_loss=1.385, task_loss=3.359, task_loss_gen=3.91, contrastive_loss=0, total=4163.13, n_correct=1467.13, ppl=11.38, accuracy=35.241, wps=13242.6, ups=1.07, wpb=12431, bsz=469.5, num_updates=7800, lr=0.000160128, gnorm=2.151, clip=0, loss_scale=0.0625, train_wall=93, gb_free=16.6, wall=7007
2023-09-01 21:48:58 | INFO | train_inner | epoch 006:    542 / 1474 loss=2.579, trans_loss=4.892, nll_loss=3.512, w2v_ctc_loss=1.393, task_loss=3.57, task_loss_gen=4.1, contrastive_loss=0, total=4157.56, n_correct=1465.43, ppl=11.41, accuracy=35.247, wps=13063.2, ups=1.05, wpb=12410.3, bsz=453.4, num_updates=7900, lr=0.000159111, gnorm=2.561, clip=0, loss_scale=0.0625, train_wall=94, gb_free=12.2, wall=7102
2023-09-01 21:50:32 | INFO | train_inner | epoch 006:    642 / 1474 loss=2.573, trans_loss=4.89, nll_loss=3.51, w2v_ctc_loss=1.387, task_loss=3.298, task_loss_gen=3.832, contrastive_loss=0, total=4156.54, n_correct=1462.68, ppl=11.4, accuracy=35.19, wps=13143.9, ups=1.06, wpb=12409.1, bsz=473.4, num_updates=8000, lr=0.000158114, gnorm=2.453, clip=0, loss_scale=0.0625, train_wall=94, gb_free=12.9, wall=7197
2023-09-01 21:50:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 21:51:04 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 5.402 | trans_loss 7.274 | nll_loss 5.172 | w2v_ctc_loss 1.613 | task_loss 8.983 | task_loss_gen 17.525 | contrastive_loss 0 | total 4003.4 | n_correct 1420.7 | ppl 36.06 | accuracy 35.487 | uer 24.41 | wer 25.857 | raw_wer 25.857 | bleu 0.2 | wps 1706.8 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 0.2
2023-09-01 21:51:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-09-01 21:51:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-09-01 21:51:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-09-01 21:51:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 0.2) (writing took 16.243801978009287 seconds)
2023-09-01 21:52:56 | INFO | train_inner | epoch 006:    742 / 1474 loss=2.562, trans_loss=4.89, nll_loss=3.509, w2v_ctc_loss=1.371, task_loss=3.473, task_loss_gen=4.113, contrastive_loss=0, total=4144.04, n_correct=1458.79, ppl=11.39, accuracy=35.202, wps=8572.2, ups=0.69, wpb=12371, bsz=455.4, num_updates=8100, lr=0.000157135, gnorm=2.147, clip=0, loss_scale=0.0625, train_wall=95, gb_free=15.9, wall=7341
2023-09-01 21:54:32 | INFO | train_inner | epoch 006:    842 / 1474 loss=2.564, trans_loss=4.897, nll_loss=3.518, w2v_ctc_loss=1.366, task_loss=3.665, task_loss_gen=4.243, contrastive_loss=0, total=4128.68, n_correct=1449.08, ppl=11.46, accuracy=35.098, wps=12826.7, ups=1.04, wpb=12323.5, bsz=444.8, num_updates=8200, lr=0.000156174, gnorm=2.293, clip=0, loss_scale=0.0625, train_wall=95, gb_free=16.9, wall=7437
2023-09-01 21:56:08 | INFO | train_inner | epoch 006:    942 / 1474 loss=2.568, trans_loss=4.894, nll_loss=3.515, w2v_ctc_loss=1.375, task_loss=3.796, task_loss_gen=4.42, contrastive_loss=0, total=4056.99, n_correct=1422.13, ppl=11.43, accuracy=35.054, wps=12655.9, ups=1.04, wpb=12112.2, bsz=434.5, num_updates=8300, lr=0.00015523, gnorm=2.262, clip=0, loss_scale=0.0625, train_wall=95, gb_free=16.8, wall=7533
2023-09-01 21:57:43 | INFO | train_inner | epoch 006:   1042 / 1474 loss=2.541, trans_loss=4.882, nll_loss=3.498, w2v_ctc_loss=1.343, task_loss=3.248, task_loss_gen=3.812, contrastive_loss=0, total=4190.44, n_correct=1485.6, ppl=11.3, accuracy=35.452, wps=13223.4, ups=1.06, wpb=12505, bsz=481.7, num_updates=8400, lr=0.000154303, gnorm=1.998, clip=0, loss_scale=0.0625, train_wall=94, gb_free=12.3, wall=7627
2023-09-01 21:59:18 | INFO | train_inner | epoch 006:   1142 / 1474 loss=2.553, trans_loss=4.894, nll_loss=3.515, w2v_ctc_loss=1.349, task_loss=3.786, task_loss_gen=4.427, contrastive_loss=0, total=4067.19, n_correct=1429.28, ppl=11.43, accuracy=35.142, wps=12780, ups=1.05, wpb=12142.6, bsz=434.8, num_updates=8500, lr=0.000153393, gnorm=2.316, clip=0, loss_scale=0.0625, train_wall=94, gb_free=16.5, wall=7722
2023-09-01 22:00:54 | INFO | train_inner | epoch 006:   1242 / 1474 loss=2.527, trans_loss=4.872, nll_loss=3.488, w2v_ctc_loss=1.324, task_loss=3.477, task_loss_gen=4.087, contrastive_loss=0, total=4130.01, n_correct=1463.13, ppl=11.22, accuracy=35.427, wps=12868.2, ups=1.04, wpb=12336.7, bsz=462.5, num_updates=8600, lr=0.000152499, gnorm=1.994, clip=0, loss_scale=0.0625, train_wall=95, gb_free=16.2, wall=7818
2023-09-01 22:02:28 | INFO | train_inner | epoch 006:   1342 / 1474 loss=2.524, trans_loss=4.887, nll_loss=3.504, w2v_ctc_loss=1.312, task_loss=3.383, task_loss_gen=4.005, contrastive_loss=0, total=4130.33, n_correct=1461.38, ppl=11.35, accuracy=35.382, wps=13071.1, ups=1.06, wpb=12323.4, bsz=456.7, num_updates=8700, lr=0.00015162, gnorm=1.754, clip=0, loss_scale=0.0625, train_wall=94, gb_free=17.2, wall=7912
2023-09-01 22:04:04 | INFO | train_inner | epoch 006:   1442 / 1474 loss=2.523, trans_loss=4.879, nll_loss=3.496, w2v_ctc_loss=1.313, task_loss=3.43, task_loss_gen=4.052, contrastive_loss=0, total=4200.52, n_correct=1491.37, ppl=11.28, accuracy=35.504, wps=13096.5, ups=1.04, wpb=12538.8, bsz=465.2, num_updates=8800, lr=0.000150756, gnorm=1.814, clip=0, loss_scale=0.0625, train_wall=95, gb_free=15.7, wall=8008
2023-09-01 22:04:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 22:05:05 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 5.364 | trans_loss 7.252 | nll_loss 5.143 | w2v_ctc_loss 1.538 | task_loss 8.798 | task_loss_gen 17.29 | contrastive_loss 0 | total 4003.4 | n_correct 1435.1 | ppl 35.32 | accuracy 35.847 | uer 23.054 | wer 24.85 | raw_wer 24.85 | bleu 0.19 | wps 1746.2 | wpb 4003.4 | bsz 141.8 | num_updates 8832 | best_bleu 0.2
2023-09-01 22:05:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8832 updates
2023-09-01 22:05:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.1908.pt
2023-09-01 22:05:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.1908.pt
2023-09-01 22:05:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.1908.pt (epoch 6 @ 8832 updates, score 0.19) (writing took 10.033741505001672 seconds)
2023-09-01 22:05:15 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-09-01 22:05:15 | INFO | train | epoch 006 | loss 2.574 | trans_loss 4.889 | nll_loss 3.509 | w2v_ctc_loss 1.387 | task_loss 3.489 | task_loss_gen 4.075 | contrastive_loss 0 | total 4138.65 | n_correct 1455.85 | ppl 11.38 | accuracy 35.177 | wps 12127.8 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 8832 | lr 0.000150482 | gnorm 2.265 | clip 0.3 | loss_scale 0.0625 | train_wall 1393 | gb_free 14.8 | wall 8080
2023-09-01 22:05:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-01 22:05:15 | INFO | fairseq.trainer | begin training epoch 7
2023-09-01 22:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 22:06:28 | INFO | train_inner | epoch 007:     68 / 1474 loss=2.49, trans_loss=4.861, nll_loss=3.472, w2v_ctc_loss=1.276, task_loss=3.405, task_loss_gen=4.047, contrastive_loss=0, total=4091.75, n_correct=1467.33, ppl=11.1, accuracy=35.861, wps=8479.2, ups=0.69, wpb=12213.6, bsz=456.9, num_updates=8900, lr=0.000149906, gnorm=1.725, clip=0, loss_scale=0.0625, train_wall=94, gb_free=17.1, wall=8152
2023-09-01 22:08:02 | INFO | train_inner | epoch 007:    168 / 1474 loss=2.484, trans_loss=4.861, nll_loss=3.471, w2v_ctc_loss=1.266, task_loss=3.375, task_loss_gen=4.006, contrastive_loss=0, total=4133.39, n_correct=1478.11, ppl=11.09, accuracy=35.76, wps=13070.9, ups=1.06, wpb=12340.1, bsz=466.9, num_updates=9000, lr=0.000149071, gnorm=1.624, clip=0, loss_scale=0.0625, train_wall=94, gb_free=11.6, wall=8247
2023-09-01 22:09:37 | INFO | train_inner | epoch 007:    268 / 1474 loss=2.486, trans_loss=4.856, nll_loss=3.464, w2v_ctc_loss=1.271, task_loss=3.534, task_loss_gen=4.179, contrastive_loss=0, total=4123.72, n_correct=1479.88, ppl=11.03, accuracy=35.887, wps=12946.7, ups=1.05, wpb=12308.1, bsz=447.9, num_updates=9100, lr=0.00014825, gnorm=1.416, clip=0, loss_scale=0.125, train_wall=94, gb_free=12.7, wall=8342
2023-09-01 22:11:13 | INFO | train_inner | epoch 007:    368 / 1474 loss=2.469, trans_loss=4.851, nll_loss=3.458, w2v_ctc_loss=1.25, task_loss=3.355, task_loss_gen=4.013, contrastive_loss=0, total=4179.78, n_correct=1505.9, ppl=10.99, accuracy=36.028, wps=13058.7, ups=1.05, wpb=12474.1, bsz=473.8, num_updates=9200, lr=0.000147442, gnorm=0.88, clip=0, loss_scale=0.125, train_wall=95, gb_free=15.8, wall=8437
2023-09-01 22:12:48 | INFO | train_inner | epoch 007:    468 / 1474 loss=2.478, trans_loss=4.853, nll_loss=3.461, w2v_ctc_loss=1.262, task_loss=3.385, task_loss_gen=3.999, contrastive_loss=0, total=4165.95, n_correct=1497.86, ppl=11.01, accuracy=35.955, wps=13087.2, ups=1.05, wpb=12439.7, bsz=465, num_updates=9300, lr=0.000146647, gnorm=1.058, clip=1, loss_scale=0.125, train_wall=94, gb_free=16.4, wall=8532
2023-09-01 22:14:23 | INFO | train_inner | epoch 007:    568 / 1474 loss=2.464, trans_loss=4.856, nll_loss=3.464, w2v_ctc_loss=1.238, task_loss=3.338, task_loss_gen=4.009, contrastive_loss=0, total=4163.63, n_correct=1501.28, ppl=11.03, accuracy=36.057, wps=13093.4, ups=1.05, wpb=12422.2, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.699, clip=0, loss_scale=0.125, train_wall=94, gb_free=17.4, wall=8627
2023-09-01 22:15:59 | INFO | train_inner | epoch 007:    668 / 1474 loss=2.478, trans_loss=4.852, nll_loss=3.459, w2v_ctc_loss=1.263, task_loss=3.357, task_loss_gen=4.017, contrastive_loss=0, total=4177.64, n_correct=1513.25, ppl=10.99, accuracy=36.223, wps=12993.5, ups=1.04, wpb=12467.9, bsz=461.8, num_updates=9500, lr=0.000145095, gnorm=0.982, clip=0, loss_scale=0.125, train_wall=95, gb_free=13.7, wall=8723
2023-09-01 22:17:34 | INFO | train_inner | epoch 007:    768 / 1474 loss=2.481, trans_loss=4.851, nll_loss=3.459, w2v_ctc_loss=1.265, task_loss=3.619, task_loss_gen=4.308, contrastive_loss=0, total=4107.56, n_correct=1480.76, ppl=10.99, accuracy=36.05, wps=12820.6, ups=1.05, wpb=12265.3, bsz=443.6, num_updates=9600, lr=0.000144338, gnorm=0.854, clip=0, loss_scale=0.125, train_wall=95, gb_free=12.3, wall=8819
2023-09-01 22:19:11 | INFO | train_inner | epoch 007:    868 / 1474 loss=2.458, trans_loss=4.854, nll_loss=3.461, w2v_ctc_loss=1.231, task_loss=3.447, task_loss_gen=4.134, contrastive_loss=0, total=4139.64, n_correct=1495.41, ppl=11.01, accuracy=36.124, wps=12798.3, ups=1.04, wpb=12349.4, bsz=458.1, num_updates=9700, lr=0.000143592, gnorm=0.693, clip=0, loss_scale=0.125, train_wall=96, gb_free=15.9, wall=8915
2023-09-01 22:20:47 | INFO | train_inner | epoch 007:    968 / 1474 loss=2.443, trans_loss=4.84, nll_loss=3.445, w2v_ctc_loss=1.217, task_loss=3.262, task_loss_gen=3.932, contrastive_loss=0, total=4142.26, n_correct=1503.24, ppl=10.89, accuracy=36.29, wps=12855.9, ups=1.04, wpb=12370.1, bsz=473.2, num_updates=9800, lr=0.000142857, gnorm=0.641, clip=0, loss_scale=0.125, train_wall=96, gb_free=16.2, wall=9012
2023-09-01 22:22:22 | INFO | train_inner | epoch 007:   1068 / 1474 loss=2.47, trans_loss=4.854, nll_loss=3.462, w2v_ctc_loss=1.249, task_loss=3.521, task_loss_gen=4.277, contrastive_loss=0, total=4109.77, n_correct=1485.16, ppl=11.02, accuracy=36.137, wps=12925.2, ups=1.05, wpb=12269.3, bsz=438.4, num_updates=9900, lr=0.000142134, gnorm=0.653, clip=0, loss_scale=0.125, train_wall=94, gb_free=15.9, wall=9106
2023-09-01 22:23:57 | INFO | train_inner | epoch 007:   1168 / 1474 loss=2.446, trans_loss=4.834, nll_loss=3.439, w2v_ctc_loss=1.224, task_loss=3.369, task_loss_gen=4.039, contrastive_loss=0, total=4125.49, n_correct=1497.34, ppl=10.85, accuracy=36.295, wps=13013.4, ups=1.06, wpb=12325.5, bsz=467.3, num_updates=10000, lr=0.000141421, gnorm=0.768, clip=0, loss_scale=0.125, train_wall=94, gb_free=15.5, wall=9201
2023-09-01 22:23:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 22:24:34 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 5.305 | trans_loss 7.219 | nll_loss 5.099 | w2v_ctc_loss 1.418 | task_loss 8.462 | task_loss_gen 17.721 | contrastive_loss 0 | total 4003.4 | n_correct 1454.8 | ppl 34.26 | accuracy 36.339 | uer 21.803 | wer 23.452 | raw_wer 23.452 | bleu 0.23 | wps 1330.1 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 0.23
2023-09-01 22:24:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-09-01 22:24:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-09-01 22:24:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-09-01 22:24:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 0.23) (writing took 12.409175028995378 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:0')
2023-09-01 22:26:21 | INFO | train_inner | epoch 007:   1268 / 1474 loss=2.434, trans_loss=4.845, nll_loss=3.451, w2v_ctc_loss=1.201, task_loss=3.469, task_loss_gen=4.155, contrastive_loss=0, total=4127.75, n_correct=1494.1, ppl=10.94, accuracy=36.196, wps=8547.7, ups=0.69, wpb=12328.2, bsz=451.1, num_updates=10100, lr=0.00014072, gnorm=0.72, clip=0, loss_scale=0.125, train_wall=94, gb_free=15.6, wall=9345
2023-09-01 22:27:56 | INFO | train_inner | epoch 007:   1368 / 1474 loss=2.442, trans_loss=4.832, nll_loss=3.434, w2v_ctc_loss=1.223, task_loss=3.253, task_loss_gen=3.878, contrastive_loss=0, total=4180.86, n_correct=1531.02, ppl=10.81, accuracy=36.62, wps=13108.5, ups=1.05, wpb=12481.5, bsz=476.8, num_updates=10200, lr=0.000140028, gnorm=0.759, clip=0, loss_scale=0.125, train_wall=94, gb_free=16.4, wall=9441
2023-09-01 22:29:33 | INFO | train_inner | epoch 007:   1468 / 1474 loss=2.439, trans_loss=4.833, nll_loss=3.437, w2v_ctc_loss=1.213, task_loss=3.58, task_loss_gen=4.322, contrastive_loss=0, total=4121.26, n_correct=1504.61, ppl=10.83, accuracy=36.508, wps=12731.7, ups=1.03, wpb=12314.3, bsz=448.8, num_updates=10300, lr=0.000139347, gnorm=0.578, clip=0, loss_scale=0.125, train_wall=96, gb_free=16.7, wall=9537
2023-09-01 22:29:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:3')
2023-09-01 22:30:14 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 5.302 | trans_loss 7.199 | nll_loss 5.071 | w2v_ctc_loss 1.451 | task_loss 8.357 | task_loss_gen 17.729 | contrastive_loss 0 | total 4003.4 | n_correct 1465.3 | ppl 33.61 | accuracy 36.601 | uer 22.032 | wer 23.597 | raw_wer 23.597 | bleu 0.21 | wps 1430.5 | wpb 4003.4 | bsz 141.8 | num_updates 10306 | best_bleu 0.23
2023-09-01 22:30:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10306 updates
2023-09-01 22:30:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.2105.pt
2023-09-01 22:30:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.2105.pt
2023-09-01 22:30:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_0.2105.pt (epoch 7 @ 10306 updates, score 0.21) (writing took 8.709328736003954 seconds)
2023-09-01 22:30:23 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-09-01 22:30:23 | INFO | train | epoch 007 | loss 2.463 | trans_loss 4.848 | nll_loss 3.455 | w2v_ctc_loss 1.242 | task_loss 3.423 | task_loss_gen 4.095 | contrastive_loss 0 | total 4138.65 | n_correct 1495.89 | ppl 10.97 | accuracy 36.144 | wps 12079.3 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 10306 | lr 0.000139306 | gnorm 0.918 | clip 0.1 | loss_scale 0.125 | train_wall 1395 | gb_free 12.8 | wall 9587
2023-09-01 22:30:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-01 22:30:23 | INFO | fairseq.trainer | begin training epoch 8
2023-09-01 22:30:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 22:32:00 | INFO | train_inner | epoch 008:     94 / 1474 loss=2.415, trans_loss=4.825, nll_loss=3.42, w2v_ctc_loss=1.181, task_loss=3.615, task_loss_gen=4.357, contrastive_loss=0, total=4105.83, n_correct=1513.04, ppl=10.7, accuracy=36.851, wps=8317.9, ups=0.68, wpb=12240.4, bsz=439.6, num_updates=10400, lr=0.000138675, gnorm=0.644, clip=0, loss_scale=0.125, train_wall=94, gb_free=17.5, wall=9685
2023-09-01 22:33:35 | INFO | train_inner | epoch 008:    194 / 1474 loss=2.422, trans_loss=4.825, nll_loss=3.421, w2v_ctc_loss=1.191, task_loss=3.74, task_loss_gen=4.512, contrastive_loss=0, total=4020.77, n_correct=1477.78, ppl=10.71, accuracy=36.754, wps=12664.9, ups=1.06, wpb=11991.3, bsz=425.1, num_updates=10500, lr=0.000138013, gnorm=0.612, clip=0, loss_scale=0.125, train_wall=94, gb_free=16.5, wall=9779
2023-09-01 22:35:10 | INFO | train_inner | epoch 008:    294 / 1474 loss=2.405, trans_loss=4.803, nll_loss=3.395, w2v_ctc_loss=1.184, task_loss=3.152, task_loss_gen=3.862, contrastive_loss=0, total=4215.76, n_correct=1569.32, ppl=10.52, accuracy=37.225, wps=13255.6, ups=1.05, wpb=12584.1, bsz=488.4, num_updates=10600, lr=0.000137361, gnorm=0.352, clip=0, loss_scale=0.125, train_wall=94, gb_free=16, wall=9874
2023-09-01 22:36:46 | INFO | train_inner | epoch 008:    394 / 1474 loss=2.414, trans_loss=4.816, nll_loss=3.409, w2v_ctc_loss=1.185, task_loss=3.525, task_loss_gen=4.258, contrastive_loss=0, total=4139.28, n_correct=1528, ppl=10.62, accuracy=36.915, wps=12763.2, ups=1.03, wpb=12347.9, bsz=448.2, num_updates=10700, lr=0.000136717, gnorm=0.623, clip=0, loss_scale=0.125, train_wall=96, gb_free=16.9, wall=9971
2023-09-01 22:38:23 | INFO | train_inner | epoch 008:    494 / 1474 loss=2.394, trans_loss=4.794, nll_loss=3.384, w2v_ctc_loss=1.17, task_loss=3.084, task_loss_gen=3.755, contrastive_loss=0, total=4191.9, n_correct=1563.6, ppl=10.44, accuracy=37.301, wps=13005.8, ups=1.04, wpb=12516.4, bsz=497.9, num_updates=10800, lr=0.000136083, gnorm=0.418, clip=0, loss_scale=0.125, train_wall=95, gb_free=16.7, wall=10067
2023-09-01 22:39:58 | INFO | train_inner | epoch 008:    594 / 1474 loss=2.422, trans_loss=4.815, nll_loss=3.413, w2v_ctc_loss=1.194, task_loss=3.711, task_loss_gen=4.372, contrastive_loss=0, total=4075.21, n_correct=1493.77, ppl=10.65, accuracy=36.655, wps=12752.1, ups=1.05, wpb=12181.8, bsz=434.6, num_updates=10900, lr=0.000135457, gnorm=1.01, clip=0, loss_scale=0.125, train_wall=95, gb_free=17.5, wall=10163
2023-09-01 22:41:33 | INFO | train_inner | epoch 008:    694 / 1474 loss=2.41, trans_loss=4.809, nll_loss=3.402, w2v_ctc_loss=1.18, task_loss=3.559, task_loss_gen=4.238, contrastive_loss=0, total=4138.17, n_correct=1528.29, ppl=10.57, accuracy=36.932, wps=12984.5, ups=1.05, wpb=12352.9, bsz=446.3, num_updates=11000, lr=0.00013484, gnorm=0.842, clip=0, loss_scale=0.125, train_wall=94, gb_free=15.6, wall=10258
2023-09-01 22:43:08 | INFO | train_inner | epoch 008:    794 / 1474 loss=2.398, trans_loss=4.794, nll_loss=3.386, w2v_ctc_loss=1.172, task_loss=3.466, task_loss_gen=4.183, contrastive_loss=0, total=4120.58, n_correct=1530.91, ppl=10.46, accuracy=37.153, wps=13044.1, ups=1.06, wpb=12316.7, bsz=450.3, num_updates=11100, lr=0.000134231, gnorm=0.722, clip=0, loss_scale=0.25, train_wall=94, gb_free=12.9, wall=10352
2023-09-01 22:44:43 | INFO | train_inner | epoch 008:    894 / 1474 loss=2.39, trans_loss=4.793, nll_loss=3.381, w2v_ctc_loss=1.163, task_loss=3.262, task_loss_gen=3.928, contrastive_loss=0, total=4172.66, n_correct=1557.87, ppl=10.42, accuracy=37.335, wps=13077.2, ups=1.05, wpb=12458.1, bsz=473.6, num_updates=11200, lr=0.000133631, gnorm=0.369, clip=0, loss_scale=0.25, train_wall=95, gb_free=16.7, wall=10448
2023-09-01 22:46:18 | INFO | train_inner | epoch 008:    994 / 1474 loss=2.388, trans_loss=4.786, nll_loss=3.373, w2v_ctc_loss=1.162, task_loss=3.233, task_loss_gen=3.925, contrastive_loss=0, total=4163.42, n_correct=1557.21, ppl=10.36, accuracy=37.402, wps=13095.5, ups=1.05, wpb=12433.5, bsz=467.1, num_updates=11300, lr=0.000133038, gnorm=0.372, clip=0, loss_scale=0.25, train_wall=94, gb_free=16.7, wall=10542
2023-09-01 22:47:55 | INFO | train_inner | epoch 008:   1094 / 1474 loss=2.385, trans_loss=4.78, nll_loss=3.363, w2v_ctc_loss=1.159, task_loss=3.461, task_loss_gen=4.16, contrastive_loss=0, total=4175.4, n_correct=1568.43, ppl=10.29, accuracy=37.564, wps=12888.2, ups=1.03, wpb=12461.7, bsz=458.2, num_updates=11400, lr=0.000132453, gnorm=0.376, clip=0, loss_scale=0.25, train_wall=96, gb_free=17.2, wall=10639
2023-09-01 22:49:29 | INFO | train_inner | epoch 008:   1194 / 1474 loss=2.384, trans_loss=4.771, nll_loss=3.353, w2v_ctc_loss=1.159, task_loss=3.206, task_loss_gen=3.902, contrastive_loss=0, total=4174.4, n_correct=1569.18, ppl=10.21, accuracy=37.591, wps=13206.5, ups=1.06, wpb=12468.1, bsz=471.6, num_updates=11500, lr=0.000131876, gnorm=0.319, clip=0, loss_scale=0.25, train_wall=94, gb_free=15.3, wall=10734
2023-09-01 22:51:04 | INFO | train_inner | epoch 008:   1294 / 1474 loss=2.388, trans_loss=4.765, nll_loss=3.345, w2v_ctc_loss=1.163, task_loss=3.494, task_loss_gen=4.262, contrastive_loss=0, total=4081.78, n_correct=1529.69, ppl=10.16, accuracy=37.476, wps=12849.1, ups=1.05, wpb=12192.8, bsz=442.3, num_updates=11600, lr=0.000131306, gnorm=0.316, clip=0, loss_scale=0.25, train_wall=94, gb_free=15.5, wall=10828
2023-09-01 22:52:38 | INFO | train_inner | epoch 008:   1394 / 1474 loss=2.381, trans_loss=4.75, nll_loss=3.324, w2v_ctc_loss=1.16, task_loss=3.283, task_loss_gen=4.004, contrastive_loss=0, total=4153.08, n_correct=1572.35, ppl=10.02, accuracy=37.86, wps=13232.9, ups=1.07, wpb=12401.3, bsz=467.2, num_updates=11700, lr=0.000130744, gnorm=0.328, clip=0, loss_scale=0.25, train_wall=93, gb_free=15.1, wall=10922
2023-09-01 22:53:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 22:54:30 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 5.222 | trans_loss 7.106 | nll_loss 4.94 | w2v_ctc_loss 1.394 | task_loss 8.443 | task_loss_gen 17.975 | contrastive_loss 0 | total 4003.4 | n_correct 1518 | ppl 30.7 | accuracy 37.918 | uer 20.426 | wer 22.121 | raw_wer 22.121 | bleu 0.52 | wps 1420.6 | wpb 4003.4 | bsz 141.8 | num_updates 11780 | best_bleu 0.52
2023-09-01 22:54:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11780 updates
2023-09-01 22:54:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 22:54:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 22:54:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 11780 updates, score 0.52) (writing took 13.550398027000483 seconds)
2023-09-01 22:54:43 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-09-01 22:54:43 | INFO | train | epoch 008 | loss 2.398 | trans_loss 4.791 | nll_loss 3.379 | w2v_ctc_loss 1.171 | task_loss 3.398 | task_loss_gen 4.107 | contrastive_loss 0 | total 4138.65 | n_correct 1541.92 | ppl 10.4 | accuracy 37.257 | wps 12469 | ups 1.01 | wpb 12355.8 | bsz 458.5 | num_updates 11780 | lr 0.000130299 | gnorm 0.512 | clip 0 | loss_scale 0.25 | train_wall 1392 | gb_free 16.6 | wall 11048
2023-09-01 22:54:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-01 22:54:44 | INFO | fairseq.trainer | begin training epoch 9
2023-09-01 22:54:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 22:55:12 | INFO | train_inner | epoch 009:     20 / 1474 loss=2.362, trans_loss=4.718, nll_loss=3.28, w2v_ctc_loss=1.136, task_loss=3.322, task_loss_gen=4.063, contrastive_loss=0, total=4111.18, n_correct=1562.76, ppl=9.71, accuracy=38.012, wps=7936.3, ups=0.65, wpb=12270.5, bsz=462.1, num_updates=11800, lr=0.000130189, gnorm=0.356, clip=0, loss_scale=0.25, train_wall=95, gb_free=16.2, wall=11077
2023-09-01 22:56:47 | INFO | train_inner | epoch 009:    120 / 1474 loss=2.347, trans_loss=4.496, nll_loss=2.985, w2v_ctc_loss=1.118, task_loss=3.193, task_loss_gen=3.802, contrastive_loss=0, total=4190.48, n_correct=1596.32, ppl=7.92, accuracy=38.094, wps=13192.8, ups=1.05, wpb=12512.7, bsz=483.8, num_updates=11900, lr=0.000129641, gnorm=0.585, clip=0, loss_scale=0.25, train_wall=94, gb_free=15.6, wall=11172
2023-09-01 22:58:23 | INFO | train_inner | epoch 009:    220 / 1474 loss=2.352, trans_loss=4.207, nll_loss=2.611, w2v_ctc_loss=1.111, task_loss=3.703, task_loss_gen=4.489, contrastive_loss=0, total=4065.17, n_correct=1541.07, ppl=6.11, accuracy=37.909, wps=12687.2, ups=1.05, wpb=12137.5, bsz=427.1, num_updates=12000, lr=0.000129099, gnorm=0.378, clip=0, loss_scale=0.25, train_wall=95, gb_free=15.7, wall=11267
2023-09-01 22:58:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 22:58:57 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 5.23 | trans_loss 7.114 | nll_loss 4.952 | w2v_ctc_loss 1.401 | task_loss 8.625 | task_loss_gen 17.824 | contrastive_loss 0 | total 4003.4 | n_correct 1506.5 | ppl 30.95 | accuracy 37.631 | uer 20.192 | wer 21.89 | raw_wer 21.89 | bleu 0.3 | wps 1545.9 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 0.52
2023-09-01 22:58:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-09-01 22:58:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-09-01 22:59:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-09-01 22:59:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 0.3) (writing took 8.656475746014621 seconds)
2023-09-01 23:00:40 | INFO | train_inner | epoch 009:    320 / 1474 loss=2.328, trans_loss=4.107, nll_loss=2.487, w2v_ctc_loss=1.097, task_loss=3.114, task_loss_gen=3.768, contrastive_loss=0, total=4172.96, n_correct=1604, ppl=5.6, accuracy=38.438, wps=9055.8, ups=0.73, wpb=12467.1, bsz=486.5, num_updates=12100, lr=0.000128565, gnorm=0.347, clip=0, loss_scale=0.25, train_wall=93, gb_free=10.4, wall=11405
2023-09-01 23:02:16 | INFO | train_inner | epoch 009:    420 / 1474 loss=2.342, trans_loss=4.086, nll_loss=2.46, w2v_ctc_loss=1.111, task_loss=3.38, task_loss_gen=4.096, contrastive_loss=0, total=4182.58, n_correct=1595.44, ppl=5.5, accuracy=38.145, wps=13032.6, ups=1.04, wpb=12488.5, bsz=461.4, num_updates=12200, lr=0.000128037, gnorm=0.319, clip=0, loss_scale=0.25, train_wall=95, gb_free=17.3, wall=11501
2023-09-01 23:03:51 | INFO | train_inner | epoch 009:    520 / 1474 loss=2.359, trans_loss=4.068, nll_loss=2.437, w2v_ctc_loss=1.13, task_loss=3.557, task_loss_gen=4.344, contrastive_loss=0, total=4112.02, n_correct=1570.74, ppl=5.42, accuracy=38.199, wps=12919.1, ups=1.05, wpb=12275, bsz=437.1, num_updates=12300, lr=0.000127515, gnorm=0.311, clip=0, loss_scale=0.25, train_wall=94, gb_free=17.4, wall=11596
2023-09-01 23:05:27 | INFO | train_inner | epoch 009:    620 / 1474 loss=2.33, trans_loss=4.044, nll_loss=2.411, w2v_ctc_loss=1.102, task_loss=3.373, task_loss_gen=4.119, contrastive_loss=0, total=4140.3, n_correct=1592.6, ppl=5.32, accuracy=38.466, wps=12961.9, ups=1.05, wpb=12373, bsz=462, num_updates=12400, lr=0.000127, gnorm=0.304, clip=0, loss_scale=0.25, train_wall=95, gb_free=15.3, wall=11691
2023-09-01 23:07:01 | INFO | train_inner | epoch 009:    720 / 1474 loss=2.349, trans_loss=4.041, nll_loss=2.407, w2v_ctc_loss=1.127, task_loss=3.503, task_loss_gen=4.304, contrastive_loss=0, total=4074.09, n_correct=1559.12, ppl=5.3, accuracy=38.269, wps=12889.3, ups=1.06, wpb=12175.5, bsz=442.4, num_updates=12500, lr=0.000126491, gnorm=0.293, clip=0, loss_scale=0.25, train_wall=94, gb_free=16.3, wall=11786
2023-09-01 23:08:37 | INFO | train_inner | epoch 009:    820 / 1474 loss=2.332, trans_loss=4.021, nll_loss=2.382, w2v_ctc_loss=1.113, task_loss=3.087, task_loss_gen=3.771, contrastive_loss=0, total=4200.53, n_correct=1626.34, ppl=5.21, accuracy=38.717, wps=13167.1, ups=1.05, wpb=12551.2, bsz=495.6, num_updates=12600, lr=0.000125988, gnorm=0.299, clip=0, loss_scale=0.25, train_wall=95, gb_free=11.7, wall=11881
2023-09-01 23:10:13 | INFO | train_inner | epoch 009:    920 / 1474 loss=2.34, trans_loss=4.029, nll_loss=2.387, w2v_ctc_loss=1.114, task_loss=3.402, task_loss_gen=4.181, contrastive_loss=0, total=4168.08, n_correct=1608.34, ppl=5.23, accuracy=38.587, wps=12861.3, ups=1.03, wpb=12433.4, bsz=454.9, num_updates=12700, lr=0.000125491, gnorm=0.289, clip=0, loss_scale=0.25, train_wall=96, gb_free=16.8, wall=11978
2023-09-01 23:11:49 | INFO | train_inner | epoch 009:   1020 / 1474 loss=2.348, trans_loss=4.034, nll_loss=2.396, w2v_ctc_loss=1.114, task_loss=3.746, task_loss_gen=4.614, contrastive_loss=0, total=4098.18, n_correct=1567.93, ppl=5.26, accuracy=38.259, wps=12819.5, ups=1.05, wpb=12233.3, bsz=424.7, num_updates=12800, lr=0.000125, gnorm=0.306, clip=0, loss_scale=0.25, train_wall=95, gb_free=16.4, wall=12073
2023-09-01 23:13:24 | INFO | train_inner | epoch 009:   1120 / 1474 loss=2.334, trans_loss=4.022, nll_loss=2.377, w2v_ctc_loss=1.108, task_loss=3.182, task_loss_gen=3.944, contrastive_loss=0, total=4164.24, n_correct=1610.46, ppl=5.19, accuracy=38.674, wps=13057.6, ups=1.05, wpb=12412.9, bsz=468.7, num_updates=12900, lr=0.000124515, gnorm=0.278, clip=0, loss_scale=0.25, train_wall=94, gb_free=14.2, wall=12168
2023-09-01 23:15:00 | INFO | train_inner | epoch 009:   1220 / 1474 loss=2.347, trans_loss=4.022, nll_loss=2.381, w2v_ctc_loss=1.122, task_loss=3.494, task_loss_gen=4.296, contrastive_loss=0, total=4152.13, n_correct=1599.04, ppl=5.21, accuracy=38.511, wps=12894.2, ups=1.04, wpb=12395.5, bsz=451.3, num_updates=13000, lr=0.000124035, gnorm=0.317, clip=0, loss_scale=0.25, train_wall=95, gb_free=17.3, wall=12264
2023-09-01 23:16:34 | INFO | train_inner | epoch 009:   1320 / 1474 loss=2.317, trans_loss=4.003, nll_loss=2.356, w2v_ctc_loss=1.095, task_loss=3.034, task_loss_gen=3.76, contrastive_loss=0, total=4199.35, n_correct=1638.4, ppl=5.12, accuracy=39.016, wps=13264.8, ups=1.06, wpb=12531.8, bsz=491.2, num_updates=13100, lr=0.00012356, gnorm=0.278, clip=0, loss_scale=0.25, train_wall=94, gb_free=16.2, wall=12359
2023-09-01 23:18:09 | INFO | train_inner | epoch 009:   1420 / 1474 loss=2.342, trans_loss=4.018, nll_loss=2.375, w2v_ctc_loss=1.114, task_loss=3.542, task_loss_gen=4.411, contrastive_loss=0, total=4073.83, n_correct=1566.29, ppl=5.19, accuracy=38.448, wps=12824.5, ups=1.06, wpb=12155.9, bsz=431.5, num_updates=13200, lr=0.000123091, gnorm=0.271, clip=0, loss_scale=0.5, train_wall=94, gb_free=12.4, wall=12454
2023-09-01 23:18:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 23:19:35 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 5.157 | trans_loss 7.042 | nll_loss 4.863 | w2v_ctc_loss 1.323 | task_loss 8.067 | task_loss_gen 18.259 | contrastive_loss 0 | total 4003.4 | n_correct 1546.6 | ppl 29.1 | accuracy 38.632 | uer 19.282 | wer 21.017 | raw_wer 21.017 | bleu 0.63 | wps 1391.9 | wpb 4003.4 | bsz 141.8 | num_updates 13254 | best_bleu 0.63
2023-09-01 23:19:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13254 updates
2023-09-01 23:19:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 23:19:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 23:19:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 9 @ 13254 updates, score 0.63) (writing took 13.916869321023114 seconds)
2023-09-01 23:19:50 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-09-01 23:19:50 | INFO | train | epoch 009 | loss 2.34 | trans_loss 4.091 | nll_loss 2.467 | w2v_ctc_loss 1.112 | task_loss 3.361 | task_loss_gen 4.117 | contrastive_loss 0 | total 4138.65 | n_correct 1590.67 | ppl 5.53 | accuracy 38.434 | wps 12091.4 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 13254 | lr 0.00012284 | gnorm 0.326 | clip 0 | loss_scale 0.5 | train_wall 1391 | gb_free 11.2 | wall 12554
2023-09-01 23:19:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-01 23:19:50 | INFO | fairseq.trainer | begin training epoch 10
2023-09-01 23:19:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 23:20:41 | INFO | train_inner | epoch 010:     46 / 1474 loss=2.301, trans_loss=3.99, nll_loss=2.34, w2v_ctc_loss=1.078, task_loss=3.052, task_loss_gen=3.828, contrastive_loss=0, total=4122.64, n_correct=1620.78, ppl=5.06, accuracy=39.314, wps=8100.3, ups=0.66, wpb=12305.9, bsz=477, num_updates=13300, lr=0.000122628, gnorm=0.25, clip=0, loss_scale=0.5, train_wall=93, gb_free=15.7, wall=12606
2023-09-01 23:22:17 | INFO | train_inner | epoch 010:    146 / 1474 loss=2.284, trans_loss=3.98, nll_loss=2.327, w2v_ctc_loss=1.052, task_loss=3.12, task_loss_gen=3.958, contrastive_loss=0, total=4236.72, n_correct=1670.24, ppl=5.02, accuracy=39.423, wps=13248, ups=1.05, wpb=12652.8, bsz=475.1, num_updates=13400, lr=0.000122169, gnorm=0.243, clip=0, loss_scale=0.5, train_wall=95, gb_free=16.3, wall=12701
2023-09-01 23:23:51 | INFO | train_inner | epoch 010:    246 / 1474 loss=2.289, trans_loss=3.975, nll_loss=2.32, w2v_ctc_loss=1.06, task_loss=3.241, task_loss_gen=4.076, contrastive_loss=0, total=4127.77, n_correct=1628.94, ppl=4.99, accuracy=39.463, wps=12982.1, ups=1.05, wpb=12319.2, bsz=461.1, num_updates=13500, lr=0.000121716, gnorm=0.255, clip=0, loss_scale=0.5, train_wall=94, gb_free=14.6, wall=12796
2023-09-01 23:25:27 | INFO | train_inner | epoch 010:    346 / 1474 loss=2.285, trans_loss=3.973, nll_loss=2.321, w2v_ctc_loss=1.056, task_loss=3.301, task_loss_gen=4.171, contrastive_loss=0, total=4129.43, n_correct=1627.34, ppl=5, accuracy=39.408, wps=12904.6, ups=1.05, wpb=12340.9, bsz=453.1, num_updates=13600, lr=0.000121268, gnorm=0.248, clip=0, loss_scale=0.5, train_wall=95, gb_free=15.9, wall=12892
2023-09-01 23:27:03 | INFO | train_inner | epoch 010:    446 / 1474 loss=2.275, trans_loss=3.968, nll_loss=2.312, w2v_ctc_loss=1.049, task_loss=3.122, task_loss_gen=4.003, contrastive_loss=0, total=4185.96, n_correct=1670.53, ppl=4.97, accuracy=39.908, wps=13006.8, ups=1.04, wpb=12499.4, bsz=478.6, num_updates=13700, lr=0.000120824, gnorm=0.249, clip=0, loss_scale=0.5, train_wall=95, gb_free=16.4, wall=12988
2023-09-01 23:28:39 | INFO | train_inner | epoch 010:    546 / 1474 loss=2.3, trans_loss=3.977, nll_loss=2.319, w2v_ctc_loss=1.078, task_loss=3.587, task_loss_gen=4.494, contrastive_loss=0, total=4092.73, n_correct=1627.53, ppl=4.99, accuracy=39.766, wps=12735.9, ups=1.04, wpb=12202.1, bsz=433.1, num_updates=13800, lr=0.000120386, gnorm=0.262, clip=0, loss_scale=0.5, train_wall=95, gb_free=16.4, wall=13084
2023-09-01 23:30:14 | INFO | train_inner | epoch 010:    646 / 1474 loss=2.279, trans_loss=3.959, nll_loss=2.299, w2v_ctc_loss=1.066, task_loss=2.949, task_loss_gen=3.787, contrastive_loss=0, total=4209.71, n_correct=1697.47, ppl=4.92, accuracy=40.323, wps=13221.4, ups=1.05, wpb=12562, bsz=489, num_updates=13900, lr=0.000119952, gnorm=0.253, clip=0, loss_scale=0.5, train_wall=94, gb_free=13.6, wall=13179
2023-09-01 23:31:49 | INFO | train_inner | epoch 010:    746 / 1474 loss=2.294, trans_loss=3.955, nll_loss=2.295, w2v_ctc_loss=1.086, task_loss=3.263, task_loss_gen=4.224, contrastive_loss=0, total=4100.84, n_correct=1650.45, ppl=4.91, accuracy=40.247, wps=12860.4, ups=1.05, wpb=12244.9, bsz=445, num_updates=14000, lr=0.000119523, gnorm=0.256, clip=0, loss_scale=0.5, train_wall=95, gb_free=16.8, wall=13274
2023-09-01 23:31:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 23:32:24 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 5.094 | trans_loss 6.931 | nll_loss 4.709 | w2v_ctc_loss 1.363 | task_loss 7.306 | task_loss_gen 18.899 | contrastive_loss 0 | total 4003.4 | n_correct 1619.6 | ppl 26.16 | accuracy 40.456 | uer 19.619 | wer 21.543 | raw_wer 21.543 | bleu 1.5 | wps 1468.8 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 1.5
2023-09-01 23:32:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-09-01 23:32:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-09-01 23:32:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-09-01 23:32:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 1.5) (writing took 13.133925152011216 seconds)
2023-09-01 23:34:13 | INFO | train_inner | epoch 010:    846 / 1474 loss=2.27, trans_loss=3.95, nll_loss=2.288, w2v_ctc_loss=1.059, task_loss=3.126, task_loss_gen=4.076, contrastive_loss=0, total=4138.46, n_correct=1679.87, ppl=4.88, accuracy=40.592, wps=8574, ups=0.69, wpb=12354.3, bsz=456.5, num_updates=14100, lr=0.000119098, gnorm=0.254, clip=0, loss_scale=0.5, train_wall=94, gb_free=17, wall=13418
2023-09-01 23:35:47 | INFO | train_inner | epoch 010:    946 / 1474 loss=2.268, trans_loss=3.937, nll_loss=2.269, w2v_ctc_loss=1.065, task_loss=3.024, task_loss_gen=3.913, contrastive_loss=0, total=4159.81, n_correct=1709.21, ppl=4.82, accuracy=41.089, wps=13239.2, ups=1.07, wpb=12407.1, bsz=472.6, num_updates=14200, lr=0.000118678, gnorm=0.262, clip=0, loss_scale=0.5, train_wall=93, gb_free=16, wall=13512
2023-09-01 23:37:23 | INFO | train_inner | epoch 010:   1046 / 1474 loss=2.274, trans_loss=3.934, nll_loss=2.267, w2v_ctc_loss=1.075, task_loss=3.435, task_loss_gen=4.467, contrastive_loss=0, total=4064.74, n_correct=1668.06, ppl=4.81, accuracy=41.037, wps=12702.9, ups=1.05, wpb=12137.8, bsz=432.1, num_updates=14300, lr=0.000118262, gnorm=0.263, clip=0, loss_scale=0.5, train_wall=95, gb_free=16, wall=13607
2023-09-01 23:38:57 | INFO | train_inner | epoch 010:   1146 / 1474 loss=2.283, trans_loss=3.941, nll_loss=2.275, w2v_ctc_loss=1.091, task_loss=3.63, task_loss_gen=4.62, contrastive_loss=0, total=4032.56, n_correct=1658.18, ppl=4.84, accuracy=41.12, wps=12702.5, ups=1.06, wpb=12038.7, bsz=419.7, num_updates=14400, lr=0.000117851, gnorm=0.281, clip=0, loss_scale=0.5, train_wall=94, gb_free=12.8, wall=13702
2023-09-01 23:40:33 | INFO | train_inner | epoch 010:   1246 / 1474 loss=2.25, trans_loss=3.89, nll_loss=2.213, w2v_ctc_loss=1.089, task_loss=3.439, task_loss_gen=4.188, contrastive_loss=0, total=4108.65, n_correct=1757.88, ppl=4.64, accuracy=42.785, wps=12895.8, ups=1.05, wpb=12288.9, bsz=445.7, num_updates=14500, lr=0.000117444, gnorm=0.291, clip=0, loss_scale=0.5, train_wall=95, gb_free=15.3, wall=13797
2023-09-01 23:42:08 | INFO | train_inner | epoch 010:   1346 / 1474 loss=2.2, trans_loss=3.807, nll_loss=2.1, w2v_ctc_loss=1.109, task_loss=3.379, task_loss_gen=4.138, contrastive_loss=0, total=4147.4, n_correct=1943.13, ppl=4.29, accuracy=46.852, wps=12949, ups=1.05, wpb=12385, bsz=456.3, num_updates=14600, lr=0.000117041, gnorm=0.332, clip=0, loss_scale=0.5, train_wall=95, gb_free=15.2, wall=13893
2023-09-01 23:43:44 | INFO | train_inner | epoch 010:   1446 / 1474 loss=2.142, trans_loss=3.74, nll_loss=2.011, w2v_ctc_loss=1.092, task_loss=3.174, task_loss_gen=3.854, contrastive_loss=0, total=4189.02, n_correct=2088.53, ppl=4.03, accuracy=49.857, wps=13051.7, ups=1.04, wpb=12494.2, bsz=483.2, num_updates=14700, lr=0.000116642, gnorm=0.332, clip=0, loss_scale=0.5, train_wall=95, gb_free=14.9, wall=13989
2023-09-01 23:44:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-01 23:44:48 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.418 | trans_loss 5.893 | nll_loss 3.365 | w2v_ctc_loss 1.447 | task_loss 6.781 | task_loss_gen 19.029 | contrastive_loss 0 | total 4003.4 | n_correct 2203.9 | ppl 10.3 | accuracy 55.051 | uer 20.166 | wer 22.18 | raw_wer 22.18 | bleu 11.33 | wps 1358.9 | wpb 4003.4 | bsz 141.8 | num_updates 14728 | best_bleu 11.33
2023-09-01 23:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14728 updates
2023-09-01 23:44:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 23:44:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-01 23:45:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 10 @ 14728 updates, score 11.33) (writing took 12.716315244004363 seconds)
2023-09-01 23:45:01 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-09-01 23:45:01 | INFO | train | epoch 010 | loss 2.261 | trans_loss 3.925 | nll_loss 2.255 | w2v_ctc_loss 1.072 | task_loss 3.255 | task_loss_gen 4.115 | contrastive_loss 0 | total 4138.65 | n_correct 1725.31 | ppl 4.77 | accuracy 41.688 | wps 12052.1 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 14728 | lr 0.000116531 | gnorm 0.271 | clip 0 | loss_scale 0.5 | train_wall 1393 | gb_free 16.9 | wall 14065
2023-09-01 23:45:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-01 23:45:01 | INFO | fairseq.trainer | begin training epoch 11
2023-09-01 23:45:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-01 23:46:16 | INFO | train_inner | epoch 011:     72 / 1474 loss=2.098, trans_loss=3.672, nll_loss=1.925, w2v_ctc_loss=1.083, task_loss=3.159, task_loss_gen=3.841, contrastive_loss=0, total=4151.84, n_correct=2165.61, ppl=3.8, accuracy=52.16, wps=8141.7, ups=0.66, wpb=12396.2, bsz=472.4, num_updates=14800, lr=0.000116248, gnorm=0.334, clip=0, loss_scale=0.5, train_wall=93, gb_free=17.1, wall=14141
2023-09-01 23:47:52 | INFO | train_inner | epoch 011:    172 / 1474 loss=2.082, trans_loss=3.649, nll_loss=1.897, w2v_ctc_loss=1.082, task_loss=3.45, task_loss_gen=4.176, contrastive_loss=0, total=4112.36, n_correct=2190.57, ppl=3.72, accuracy=53.268, wps=12829.8, ups=1.04, wpb=12285.1, bsz=453.4, num_updates=14900, lr=0.000115857, gnorm=0.336, clip=0, loss_scale=0.5, train_wall=95, gb_free=16.3, wall=14237
2023-09-01 23:49:27 | INFO | train_inner | epoch 011:    272 / 1474 loss=2.063, trans_loss=3.624, nll_loss=1.864, w2v_ctc_loss=1.074, task_loss=3.529, task_loss_gen=4.287, contrastive_loss=0, total=4108.86, n_correct=2226.98, ppl=3.64, accuracy=54.199, wps=12881.5, ups=1.05, wpb=12272.6, bsz=441, num_updates=15000, lr=0.00011547, gnorm=0.34, clip=0, loss_scale=0.5, train_wall=95, gb_free=15.9, wall=14332
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:0')
2023-09-01 23:50:39 | INFO | train_inner | epoch 011:    372 / 1474 loss=2.235, trans_loss=5.36, nll_loss=2.737, w2v_ctc_loss=0.811, task_loss=5.201, task_loss_gen=6.308, contrastive_loss=0, total=4099.47, n_correct=2254.06, ppl=6.67, accuracy=54.984, wps=11534.7, ups=1.4, wpb=8238.3, bsz=296.2, num_updates=15100, lr=0.000115087, gnorm=0.486, clip=0, loss_scale=0.5, train_wall=70, gb_free=16.7, wall=14403
2023-09-01 23:51:52 | INFO | train_inner | epoch 011:    472 / 1474 loss=2.226, trans_loss=5.371, nll_loss=2.733, w2v_ctc_loss=0.8, task_loss=5.263, task_loss_gen=6.395, contrastive_loss=0, total=4112.57, n_correct=2277.98, ppl=6.65, accuracy=55.391, wps=11310.9, ups=1.38, wpb=8225.1, bsz=302.7, num_updates=15200, lr=0.000114708, gnorm=0.497, clip=0, loss_scale=1, train_wall=72, gb_free=11.7, wall=14476
2023-09-01 23:53:04 | INFO | train_inner | epoch 011:    572 / 1474 loss=2.216, trans_loss=5.346, nll_loss=2.701, w2v_ctc_loss=0.816, task_loss=5.32, task_loss_gen=6.566, contrastive_loss=0, total=4068.45, n_correct=2281.03, ppl=6.5, accuracy=56.066, wps=11237.5, ups=1.38, wpb=8136.9, bsz=292.8, num_updates=15300, lr=0.000114332, gnorm=0.491, clip=0, loss_scale=1, train_wall=72, gb_free=17.6, wall=14549
2023-09-01 23:54:16 | INFO | train_inner | epoch 011:    672 / 1474 loss=2.199, trans_loss=5.324, nll_loss=2.672, w2v_ctc_loss=0.804, task_loss=4.864, task_loss_gen=6, contrastive_loss=0, total=4161.97, n_correct=2355.83, ppl=6.37, accuracy=56.604, wps=11523.7, ups=1.38, wpb=8323.9, bsz=311.9, num_updates=15400, lr=0.000113961, gnorm=0.482, clip=0, loss_scale=1, train_wall=72, gb_free=17.4, wall=14621
2023-09-01 23:55:29 | INFO | train_inner | epoch 011:    772 / 1474 loss=2.205, trans_loss=5.329, nll_loss=2.679, w2v_ctc_loss=0.824, task_loss=5.173, task_loss_gen=6.303, contrastive_loss=0, total=4155.4, n_correct=2360.88, ppl=6.4, accuracy=56.815, wps=11467.6, ups=1.38, wpb=8310.8, bsz=301.7, num_updates=15500, lr=0.000113592, gnorm=0.495, clip=0, loss_scale=1, train_wall=72, gb_free=16.4, wall=14693
2023-09-01 23:56:41 | INFO | train_inner | epoch 011:    872 / 1474 loss=2.199, trans_loss=5.317, nll_loss=2.664, w2v_ctc_loss=0.819, task_loss=5.271, task_loss_gen=6.416, contrastive_loss=0, total=4128.59, n_correct=2347.89, ppl=6.34, accuracy=56.869, wps=11368.9, ups=1.38, wpb=8257.2, bsz=295.2, num_updates=15600, lr=0.000113228, gnorm=0.489, clip=0, loss_scale=1, train_wall=72, gb_free=14.8, wall=14766
2023-09-01 23:57:53 | INFO | train_inner | epoch 011:    972 / 1474 loss=2.188, trans_loss=5.305, nll_loss=2.649, w2v_ctc_loss=0.818, task_loss=5.054, task_loss_gen=6.211, contrastive_loss=0, total=4151.98, n_correct=2377.82, ppl=6.27, accuracy=57.27, wps=11548.8, ups=1.39, wpb=8304, bsz=305, num_updates=15700, lr=0.000112867, gnorm=0.492, clip=0, loss_scale=1, train_wall=71, gb_free=14.6, wall=14838
2023-09-01 23:59:05 | INFO | train_inner | epoch 011:   1072 / 1474 loss=2.182, trans_loss=5.293, nll_loss=2.634, w2v_ctc_loss=0.82, task_loss=4.914, task_loss_gen=5.973, contrastive_loss=0, total=4152.41, n_correct=2387.37, ppl=6.21, accuracy=57.494, wps=11537.3, ups=1.39, wpb=8304.8, bsz=311, num_updates=15800, lr=0.000112509, gnorm=0.495, clip=0, loss_scale=1, train_wall=71, gb_free=15.7, wall=14910
2023-09-02 00:00:17 | INFO | train_inner | epoch 011:   1172 / 1474 loss=2.183, trans_loss=5.295, nll_loss=2.636, w2v_ctc_loss=0.822, task_loss=5.063, task_loss_gen=6.119, contrastive_loss=0, total=4173.64, n_correct=2403.54, ppl=6.22, accuracy=57.589, wps=11571.2, ups=1.39, wpb=8347.3, bsz=310.3, num_updates=15900, lr=0.000112154, gnorm=0.493, clip=0, loss_scale=1, train_wall=71, gb_free=16.7, wall=14982
2023-09-02 00:01:30 | INFO | train_inner | epoch 011:   1272 / 1474 loss=2.182, trans_loss=5.285, nll_loss=2.625, w2v_ctc_loss=0.828, task_loss=5.016, task_loss_gen=6.08, contrastive_loss=0, total=4156.85, n_correct=2398.19, ppl=6.17, accuracy=57.692, wps=11437.4, ups=1.38, wpb=8313.7, bsz=310.3, num_updates=16000, lr=0.000111803, gnorm=0.496, clip=0, loss_scale=1, train_wall=72, gb_free=15.4, wall=15055
2023-09-02 00:01:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:1')
2023-09-02 00:02:03 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.141 | trans_loss 5.473 | nll_loss 2.827 | w2v_ctc_loss 1.47 | task_loss 6.962 | task_loss_gen 19.417 | contrastive_loss 0 | total 4003.4 | n_correct 2462.4 | ppl 7.1 | accuracy 61.508 | uer 19.465 | wer 21.181 | raw_wer 21.181 | bleu 17.39 | wps 1635.2 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 17.39
2023-09-02 00:02:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-09-02 00:02:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-09-02 00:02:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-09-02 00:02:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 17.39) (writing took 14.103147914021974 seconds)
2023-09-02 00:03:30 | INFO | train_inner | epoch 011:   1372 / 1474 loss=2.164, trans_loss=5.273, nll_loss=2.609, w2v_ctc_loss=0.804, task_loss=4.784, task_loss_gen=5.783, contrastive_loss=0, total=4184.47, n_correct=2429.08, ppl=6.1, accuracy=58.05, wps=6983, ups=0.83, wpb=8368.9, bsz=324.1, num_updates=16100, lr=0.000111456, gnorm=0.492, clip=0, loss_scale=1, train_wall=72, gb_free=17.6, wall=15175
2023-09-02 00:04:42 | INFO | train_inner | epoch 011:   1472 / 1474 loss=2.164, trans_loss=5.27, nll_loss=2.606, w2v_ctc_loss=0.814, task_loss=4.88, task_loss_gen=5.867, contrastive_loss=0, total=4171.68, n_correct=2432.06, ppl=6.09, accuracy=58.299, wps=11578.3, ups=1.39, wpb=8343.4, bsz=315.1, num_updates=16200, lr=0.000111111, gnorm=0.489, clip=0, loss_scale=1, train_wall=71, gb_free=15.1, wall=15247
2023-09-02 00:04:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 00:05:18 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.108 | trans_loss 5.445 | nll_loss 2.787 | w2v_ctc_loss 1.422 | task_loss 7.413 | task_loss_gen 18.912 | contrastive_loss 0 | total 4003.4 | n_correct 2477.2 | ppl 6.9 | accuracy 61.877 | uer 19.651 | wer 21.584 | raw_wer 21.584 | bleu 17.49 | wps 1496.8 | wpb 4003.4 | bsz 141.8 | num_updates 16202 | best_bleu 17.49
2023-09-02 00:05:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16202 updates
2023-09-02 00:05:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 00:05:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 00:05:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 11 @ 16202 updates, score 17.49) (writing took 13.78154252099921 seconds)
2023-09-02 00:05:32 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-09-02 00:05:32 | INFO | train | epoch 011 | loss 2.166 | trans_loss 4.893 | nll_loss 2.467 | w2v_ctc_loss 0.881 | task_loss 4.637 | task_loss_gen 5.641 | contrastive_loss 0 | total 4138.65 | n_correct 2329.45 | ppl 5.53 | accuracy 56.285 | wps 10812.5 | ups 1.2 | wpb 9031.7 | bsz 333.8 | num_updates 16202 | lr 0.000111104 | gnorm 0.463 | clip 0 | loss_scale 1 | train_wall 1115 | gb_free 16.9 | wall 15297
2023-09-02 00:05:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 00:05:32 | INFO | fairseq.trainer | begin training epoch 12
2023-09-02 00:05:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 00:06:49 | INFO | train_inner | epoch 012:     98 / 1474 loss=2.136, trans_loss=5.223, nll_loss=2.543, w2v_ctc_loss=0.792, task_loss=4.901, task_loss_gen=5.919, contrastive_loss=0, total=4136.78, n_correct=2448.92, ppl=5.83, accuracy=59.199, wps=6502.6, ups=0.79, wpb=8273.6, bsz=313, num_updates=16300, lr=0.00011077, gnorm=0.501, clip=0, loss_scale=1, train_wall=70, gb_free=16.4, wall=15374
2023-09-02 00:08:01 | INFO | train_inner | epoch 012:    198 / 1474 loss=2.139, trans_loss=5.223, nll_loss=2.545, w2v_ctc_loss=0.793, task_loss=4.997, task_loss_gen=6.177, contrastive_loss=0, total=4147.1, n_correct=2453.32, ppl=5.84, accuracy=59.157, wps=11532.9, ups=1.39, wpb=8294.2, bsz=301.9, num_updates=16400, lr=0.000110432, gnorm=0.49, clip=0, loss_scale=1, train_wall=71, gb_free=13.8, wall=15446
2023-09-02 00:09:13 | INFO | train_inner | epoch 012:    298 / 1474 loss=2.13, trans_loss=5.221, nll_loss=2.542, w2v_ctc_loss=0.782, task_loss=4.776, task_loss_gen=5.776, contrastive_loss=0, total=4207.23, n_correct=2499.63, ppl=5.82, accuracy=59.413, wps=11649.4, ups=1.38, wpb=8414.5, bsz=321.1, num_updates=16500, lr=0.000110096, gnorm=0.487, clip=0, loss_scale=1, train_wall=71, gb_free=14.7, wall=15518
2023-09-02 00:10:26 | INFO | train_inner | epoch 012:    398 / 1474 loss=2.141, trans_loss=5.224, nll_loss=2.546, w2v_ctc_loss=0.801, task_loss=5.154, task_loss_gen=6.223, contrastive_loss=0, total=4129, n_correct=2444.96, ppl=5.84, accuracy=59.214, wps=11419.1, ups=1.38, wpb=8258, bsz=300.7, num_updates=16600, lr=0.000109764, gnorm=0.497, clip=0, loss_scale=1, train_wall=71, gb_free=16.7, wall=15590
2023-09-02 00:11:37 | INFO | train_inner | epoch 012:    498 / 1474 loss=2.145, trans_loss=5.233, nll_loss=2.557, w2v_ctc_loss=0.807, task_loss=5.232, task_loss_gen=6.272, contrastive_loss=0, total=4089.63, n_correct=2426.35, ppl=5.89, accuracy=59.329, wps=11424.6, ups=1.4, wpb=8179.3, bsz=299.3, num_updates=16700, lr=0.000109435, gnorm=0.507, clip=0, loss_scale=1, train_wall=71, gb_free=13.8, wall=15662
2023-09-02 00:12:50 | INFO | train_inner | epoch 012:    598 / 1474 loss=2.133, trans_loss=5.219, nll_loss=2.539, w2v_ctc_loss=0.798, task_loss=4.866, task_loss_gen=5.849, contrastive_loss=0, total=4208.01, n_correct=2499.97, ppl=5.81, accuracy=59.41, wps=11540.9, ups=1.37, wpb=8416, bsz=319, num_updates=16800, lr=0.000109109, gnorm=0.485, clip=0, loss_scale=1, train_wall=72, gb_free=16.7, wall=15735
2023-09-02 00:14:02 | INFO | train_inner | epoch 012:    698 / 1474 loss=2.118, trans_loss=5.199, nll_loss=2.516, w2v_ctc_loss=0.785, task_loss=4.584, task_loss_gen=5.664, contrastive_loss=0, total=4201.87, n_correct=2520.33, ppl=5.72, accuracy=59.981, wps=11720.3, ups=1.39, wpb=8403.7, bsz=324.3, num_updates=16900, lr=0.000108786, gnorm=0.49, clip=0, loss_scale=1, train_wall=71, gb_free=11.6, wall=15807
2023-09-02 00:15:14 | INFO | train_inner | epoch 012:    798 / 1474 loss=2.125, trans_loss=5.201, nll_loss=2.517, w2v_ctc_loss=0.793, task_loss=5.159, task_loss_gen=6.286, contrastive_loss=0, total=4085.33, n_correct=2442.82, ppl=5.72, accuracy=59.795, wps=11293, ups=1.38, wpb=8170.7, bsz=296.8, num_updates=17000, lr=0.000108465, gnorm=0.501, clip=0, loss_scale=1, train_wall=71, gb_free=17.1, wall=15879
2023-09-02 00:16:27 | INFO | train_inner | epoch 012:    898 / 1474 loss=2.128, trans_loss=5.205, nll_loss=2.523, w2v_ctc_loss=0.798, task_loss=5.179, task_loss_gen=6.34, contrastive_loss=0, total=4168.55, n_correct=2491.93, ppl=5.75, accuracy=59.779, wps=11470.9, ups=1.38, wpb=8337.1, bsz=305.7, num_updates=17100, lr=0.000108148, gnorm=0.494, clip=0, loss_scale=1, train_wall=72, gb_free=9.3, wall=15952
2023-09-02 00:17:39 | INFO | train_inner | epoch 012:    998 / 1474 loss=2.13, trans_loss=5.209, nll_loss=2.528, w2v_ctc_loss=0.802, task_loss=5.177, task_loss_gen=6.287, contrastive_loss=0, total=4118.45, n_correct=2462.68, ppl=5.77, accuracy=59.796, wps=11417.5, ups=1.39, wpb=8236.9, bsz=301.4, num_updates=17200, lr=0.000107833, gnorm=0.496, clip=0, loss_scale=1, train_wall=71, gb_free=11.3, wall=16024
2023-09-02 00:18:51 | INFO | train_inner | epoch 012:   1098 / 1474 loss=2.13, trans_loss=5.206, nll_loss=2.524, w2v_ctc_loss=0.804, task_loss=5.268, task_loss_gen=6.384, contrastive_loss=0, total=4068.9, n_correct=2437.01, ppl=5.75, accuracy=59.894, wps=11345.7, ups=1.39, wpb=8137.8, bsz=293, num_updates=17300, lr=0.000107521, gnorm=0.501, clip=0, loss_scale=2, train_wall=71, gb_free=15.7, wall=16095
2023-09-02 00:20:03 | INFO | train_inner | epoch 012:   1198 / 1474 loss=2.133, trans_loss=5.214, nll_loss=2.536, w2v_ctc_loss=0.817, task_loss=4.782, task_loss_gen=6.043, contrastive_loss=0, total=4184.7, n_correct=2498.61, ppl=5.8, accuracy=59.708, wps=11547.6, ups=1.38, wpb=8369.4, bsz=317.6, num_updates=17400, lr=0.000107211, gnorm=0.486, clip=0, loss_scale=2, train_wall=71, gb_free=13.2, wall=16168
2023-09-02 00:21:16 | INFO | train_inner | epoch 012:   1298 / 1474 loss=2.125, trans_loss=5.194, nll_loss=2.51, w2v_ctc_loss=0.805, task_loss=5.527, task_loss_gen=6.907, contrastive_loss=0, total=4070.11, n_correct=2443.36, ppl=5.69, accuracy=60.032, wps=11254.9, ups=1.38, wpb=8140.2, bsz=285.4, num_updates=17500, lr=0.000106904, gnorm=0.502, clip=0, loss_scale=2, train_wall=72, gb_free=14, wall=16240
2023-09-02 00:22:28 | INFO | train_inner | epoch 012:   1398 / 1474 loss=2.12, trans_loss=5.2, nll_loss=2.518, w2v_ctc_loss=0.796, task_loss=5.045, task_loss_gen=6.246, contrastive_loss=0, total=4135.31, n_correct=2483.16, ppl=5.73, accuracy=60.048, wps=11372.4, ups=1.38, wpb=8270.6, bsz=305.4, num_updates=17600, lr=0.0001066, gnorm=0.494, clip=0, loss_scale=2, train_wall=72, gb_free=15.9, wall=16313
2023-09-02 00:23:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 00:23:58 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.033 | trans_loss 5.346 | nll_loss 2.663 | w2v_ctc_loss 1.397 | task_loss 6.935 | task_loss_gen 19.315 | contrastive_loss 0 | total 4003.4 | n_correct 2540.9 | ppl 6.34 | accuracy 63.469 | uer 18.735 | wer 20.551 | raw_wer 20.551 | bleu 19.21 | wps 1487.8 | wpb 4003.4 | bsz 141.8 | num_updates 17676 | best_bleu 19.21
2023-09-02 00:23:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17676 updates
2023-09-02 00:23:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 00:24:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 00:24:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 12 @ 17676 updates, score 19.21) (writing took 13.36426096901414 seconds)
2023-09-02 00:24:12 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-09-02 00:24:12 | INFO | train | epoch 012 | loss 2.13 | trans_loss 5.211 | nll_loss 2.53 | w2v_ctc_loss 0.798 | task_loss 5.04 | task_loss_gen 6.169 | contrastive_loss 0 | total 4138.65 | n_correct 2468.86 | ppl 5.78 | accuracy 59.654 | wps 10892.5 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 17676 | lr 0.000106371 | gnorm 0.495 | clip 0 | loss_scale 2 | train_wall 1052 | gb_free 12.4 | wall 16417
2023-09-02 00:24:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 00:24:12 | INFO | fairseq.trainer | begin training epoch 13
2023-09-02 00:24:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 00:24:37 | INFO | train_inner | epoch 013:     24 / 1474 loss=2.118, trans_loss=5.19, nll_loss=2.505, w2v_ctc_loss=0.801, task_loss=5.047, task_loss_gen=6.313, contrastive_loss=0, total=4097.19, n_correct=2469.66, ppl=5.68, accuracy=60.277, wps=6393.9, ups=0.78, wpb=8194.4, bsz=297.7, num_updates=17700, lr=0.000106299, gnorm=0.499, clip=0, loss_scale=2, train_wall=71, gb_free=15.8, wall=16441
2023-09-02 00:25:49 | INFO | train_inner | epoch 013:    124 / 1474 loss=2.099, trans_loss=5.162, nll_loss=2.467, w2v_ctc_loss=0.778, task_loss=5.151, task_loss_gen=6.165, contrastive_loss=0, total=4172.67, n_correct=2535.9, ppl=5.53, accuracy=60.774, wps=11600.2, ups=1.39, wpb=8345.3, bsz=303.7, num_updates=17800, lr=0.000106, gnorm=0.493, clip=0, loss_scale=2, train_wall=71, gb_free=15.8, wall=16513
2023-09-02 00:27:01 | INFO | train_inner | epoch 013:    224 / 1474 loss=2.098, trans_loss=5.169, nll_loss=2.478, w2v_ctc_loss=0.775, task_loss=4.925, task_loss_gen=5.804, contrastive_loss=0, total=4191.23, n_correct=2546.06, ppl=5.57, accuracy=60.747, wps=11527.3, ups=1.38, wpb=8382.5, bsz=326.3, num_updates=17900, lr=0.000105703, gnorm=0.492, clip=0, loss_scale=2, train_wall=72, gb_free=16.6, wall=16586
2023-09-02 00:28:13 | INFO | train_inner | epoch 013:    324 / 1474 loss=2.094, trans_loss=5.151, nll_loss=2.453, w2v_ctc_loss=0.773, task_loss=5.302, task_loss_gen=6.474, contrastive_loss=0, total=4102.25, n_correct=2508.92, ppl=5.48, accuracy=61.16, wps=11371.8, ups=1.39, wpb=8204.5, bsz=292.6, num_updates=18000, lr=0.000105409, gnorm=0.496, clip=0, loss_scale=2, train_wall=71, gb_free=16.1, wall=16658
2023-09-02 00:28:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 00:28:47 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.026 | trans_loss 5.354 | nll_loss 2.668 | w2v_ctc_loss 1.355 | task_loss 7.577 | task_loss_gen 18.743 | contrastive_loss 0 | total 4003.4 | n_correct 2539.6 | ppl 6.36 | accuracy 63.436 | uer 18.605 | wer 20.376 | raw_wer 20.376 | bleu 19.32 | wps 1595.9 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.32
2023-09-02 00:28:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-09-02 00:28:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-09-02 00:28:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-09-02 00:29:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.32) (writing took 14.335224556998583 seconds)
2023-09-02 00:30:13 | INFO | train_inner | epoch 013:    424 / 1474 loss=2.09, trans_loss=5.151, nll_loss=2.456, w2v_ctc_loss=0.779, task_loss=4.639, task_loss_gen=5.674, contrastive_loss=0, total=4205.83, n_correct=2573.34, ppl=5.49, accuracy=61.185, wps=7011.6, ups=0.83, wpb=8411.7, bsz=324.4, num_updates=18100, lr=0.000105118, gnorm=0.49, clip=0, loss_scale=2, train_wall=71, gb_free=16.2, wall=16778
2023-09-02 00:31:26 | INFO | train_inner | epoch 013:    524 / 1474 loss=2.093, trans_loss=5.157, nll_loss=2.461, w2v_ctc_loss=0.775, task_loss=4.895, task_loss_gen=5.967, contrastive_loss=0, total=4186.08, n_correct=2548.41, ppl=5.51, accuracy=60.878, wps=11543.5, ups=1.38, wpb=8372.2, bsz=317, num_updates=18200, lr=0.000104828, gnorm=0.492, clip=0, loss_scale=2, train_wall=72, gb_free=16.7, wall=16850
2023-09-02 00:32:38 | INFO | train_inner | epoch 013:    624 / 1474 loss=2.09, trans_loss=5.149, nll_loss=2.453, w2v_ctc_loss=0.78, task_loss=4.994, task_loss_gen=6.115, contrastive_loss=0, total=4152.83, n_correct=2539.34, ppl=5.47, accuracy=61.147, wps=11444.7, ups=1.38, wpb=8305.7, bsz=304.5, num_updates=18300, lr=0.000104542, gnorm=0.493, clip=0, loss_scale=2, train_wall=72, gb_free=15.7, wall=16923
2023-09-02 00:33:51 | INFO | train_inner | epoch 013:    724 / 1474 loss=2.107, trans_loss=5.161, nll_loss=2.466, w2v_ctc_loss=0.799, task_loss=5.633, task_loss_gen=6.694, contrastive_loss=0, total=4109.56, n_correct=2498.98, ppl=5.52, accuracy=60.809, wps=11396, ups=1.39, wpb=8219.1, bsz=289.8, num_updates=18400, lr=0.000104257, gnorm=0.508, clip=0, loss_scale=2, train_wall=71, gb_free=14.6, wall=16995
2023-09-02 00:35:04 | INFO | train_inner | epoch 013:    824 / 1474 loss=2.098, trans_loss=5.157, nll_loss=2.464, w2v_ctc_loss=0.786, task_loss=5.52, task_loss_gen=6.392, contrastive_loss=0, total=4114.63, n_correct=2506.86, ppl=5.52, accuracy=60.926, wps=11247, ups=1.37, wpb=8229.3, bsz=302.5, num_updates=18500, lr=0.000103975, gnorm=0.505, clip=0, loss_scale=2, train_wall=72, gb_free=16.6, wall=17068
2023-09-02 00:36:15 | INFO | train_inner | epoch 013:    924 / 1474 loss=2.09, trans_loss=5.146, nll_loss=2.45, w2v_ctc_loss=0.782, task_loss=5.1, task_loss_gen=6.242, contrastive_loss=0, total=4102.25, n_correct=2518.48, ppl=5.46, accuracy=61.393, wps=11478.2, ups=1.4, wpb=8204.5, bsz=297.5, num_updates=18600, lr=0.000103695, gnorm=0.486, clip=0, loss_scale=2, train_wall=71, gb_free=15.5, wall=17140
2023-09-02 00:37:27 | INFO | train_inner | epoch 013:   1024 / 1474 loss=2.099, trans_loss=5.152, nll_loss=2.457, w2v_ctc_loss=0.795, task_loss=5.334, task_loss_gen=6.467, contrastive_loss=0, total=4097.02, n_correct=2498.15, ppl=5.49, accuracy=60.975, wps=11373.3, ups=1.39, wpb=8194, bsz=297.1, num_updates=18700, lr=0.000103418, gnorm=0.498, clip=0, loss_scale=2, train_wall=71, gb_free=16.4, wall=17212
2023-09-02 00:38:39 | INFO | train_inner | epoch 013:   1124 / 1474 loss=2.082, trans_loss=5.135, nll_loss=2.434, w2v_ctc_loss=0.774, task_loss=5.048, task_loss_gen=6.225, contrastive_loss=0, total=4082.89, n_correct=2513.54, ppl=5.41, accuracy=61.563, wps=11412.8, ups=1.4, wpb=8165.8, bsz=300.3, num_updates=18800, lr=0.000103142, gnorm=0.494, clip=0, loss_scale=2, train_wall=71, gb_free=15.1, wall=17283
2023-09-02 00:39:51 | INFO | train_inner | epoch 013:   1224 / 1474 loss=2.091, trans_loss=5.145, nll_loss=2.448, w2v_ctc_loss=0.785, task_loss=5.31, task_loss_gen=6.513, contrastive_loss=0, total=4122.93, n_correct=2528.98, ppl=5.46, accuracy=61.339, wps=11443.1, ups=1.39, wpb=8245.9, bsz=296.7, num_updates=18900, lr=0.000102869, gnorm=0.512, clip=0, loss_scale=2, train_wall=71, gb_free=16.2, wall=17356
2023-09-02 00:41:03 | INFO | train_inner | epoch 013:   1324 / 1474 loss=2.08, trans_loss=5.132, nll_loss=2.432, w2v_ctc_loss=0.772, task_loss=4.989, task_loss_gen=6.06, contrastive_loss=0, total=4113.08, n_correct=2534.57, ppl=5.4, accuracy=61.622, wps=11385.2, ups=1.38, wpb=8226.2, bsz=309.2, num_updates=19000, lr=0.000102598, gnorm=0.498, clip=0, loss_scale=2, train_wall=71, gb_free=16.6, wall=17428
2023-09-02 00:42:16 | INFO | train_inner | epoch 013:   1424 / 1474 loss=2.084, trans_loss=5.14, nll_loss=2.442, w2v_ctc_loss=0.774, task_loss=4.935, task_loss_gen=6.09, contrastive_loss=0, total=4174.18, n_correct=2564.14, ppl=5.43, accuracy=61.429, wps=11490.1, ups=1.38, wpb=8348.4, bsz=310.4, num_updates=19100, lr=0.000102329, gnorm=0.489, clip=0, loss_scale=2, train_wall=72, gb_free=16.2, wall=17500
2023-09-02 00:42:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 00:43:25 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.99 | trans_loss 5.308 | nll_loss 2.615 | w2v_ctc_loss 1.338 | task_loss 7.38 | task_loss_gen 18.906 | contrastive_loss 0 | total 4003.4 | n_correct 2564.5 | ppl 6.13 | accuracy 64.058 | uer 18.865 | wer 20.581 | raw_wer 20.581 | bleu 20.09 | wps 1641.1 | wpb 4003.4 | bsz 141.8 | num_updates 19150 | best_bleu 20.09
2023-09-02 00:43:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19150 updates
2023-09-02 00:43:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 00:43:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 00:43:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 13 @ 19150 updates, score 20.09) (writing took 11.970843119022902 seconds)
2023-09-02 00:43:37 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-09-02 00:43:37 | INFO | train | epoch 013 | loss 2.092 | trans_loss 5.149 | nll_loss 2.453 | w2v_ctc_loss 0.78 | task_loss 5.092 | task_loss_gen 6.175 | contrastive_loss 0 | total 4138.65 | n_correct 2531.28 | ppl 5.48 | accuracy 61.162 | wps 10472.8 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 19150 | lr 0.000102195 | gnorm 0.496 | clip 0 | loss_scale 2 | train_wall 1052 | gb_free 17.4 | wall 17582
2023-09-02 00:43:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 00:43:37 | INFO | fairseq.trainer | begin training epoch 14
2023-09-02 00:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 00:44:20 | INFO | train_inner | epoch 014:     50 / 1474 loss=2.062, trans_loss=5.105, nll_loss=2.399, w2v_ctc_loss=0.76, task_loss=4.543, task_loss_gen=5.667, contrastive_loss=0, total=4177.38, n_correct=2595.88, ppl=5.27, accuracy=62.141, wps=6729.5, ups=0.81, wpb=8354.8, bsz=321.6, num_updates=19200, lr=0.000102062, gnorm=0.484, clip=0, loss_scale=2, train_wall=71, gb_free=16.9, wall=17625
2023-09-02 00:45:32 | INFO | train_inner | epoch 014:    150 / 1474 loss=2.059, trans_loss=5.096, nll_loss=2.385, w2v_ctc_loss=0.756, task_loss=5.055, task_loss_gen=6.14, contrastive_loss=0, total=4098.74, n_correct=2553.93, ppl=5.22, accuracy=62.31, wps=11445.9, ups=1.4, wpb=8197.5, bsz=303.4, num_updates=19300, lr=0.000101797, gnorm=0.494, clip=0, loss_scale=4, train_wall=71, gb_free=16.3, wall=17696
2023-09-02 00:46:44 | INFO | train_inner | epoch 014:    250 / 1474 loss=2.067, trans_loss=5.108, nll_loss=2.4, w2v_ctc_loss=0.763, task_loss=4.956, task_loss_gen=6.437, contrastive_loss=0, total=4099.27, n_correct=2546.73, ppl=5.28, accuracy=62.126, wps=11382.3, ups=1.39, wpb=8198.5, bsz=294.5, num_updates=19400, lr=0.000101535, gnorm=0.496, clip=0, loss_scale=4, train_wall=71, gb_free=16.1, wall=17768
2023-09-02 00:47:56 | INFO | train_inner | epoch 014:    350 / 1474 loss=2.064, trans_loss=5.108, nll_loss=2.402, w2v_ctc_loss=0.767, task_loss=4.63, task_loss_gen=5.874, contrastive_loss=0, total=4161.31, n_correct=2587.45, ppl=5.28, accuracy=62.179, wps=11522.8, ups=1.38, wpb=8322.6, bsz=316.7, num_updates=19500, lr=0.000101274, gnorm=0.491, clip=0, loss_scale=4, train_wall=71, gb_free=16.4, wall=17840
2023-09-02 00:49:08 | INFO | train_inner | epoch 014:    450 / 1474 loss=2.065, trans_loss=5.109, nll_loss=2.402, w2v_ctc_loss=0.763, task_loss=4.84, task_loss_gen=6.105, contrastive_loss=0, total=4153.74, n_correct=2581.78, ppl=5.29, accuracy=62.156, wps=11562, ups=1.39, wpb=8307.5, bsz=305.8, num_updates=19600, lr=0.000101015, gnorm=0.496, clip=0, loss_scale=4, train_wall=71, gb_free=15.3, wall=17912
2023-09-02 00:50:21 | INFO | train_inner | epoch 014:    550 / 1474 loss=2.075, trans_loss=5.11, nll_loss=2.404, w2v_ctc_loss=0.777, task_loss=5.311, task_loss_gen=6.708, contrastive_loss=0, total=4064.6, n_correct=2515.1, ppl=5.29, accuracy=61.878, wps=11129.8, ups=1.37, wpb=8129.2, bsz=288.5, num_updates=19700, lr=0.000100759, gnorm=0.506, clip=0, loss_scale=4, train_wall=72, gb_free=15.7, wall=17985
2023-09-02 00:51:33 | INFO | train_inner | epoch 014:    650 / 1474 loss=2.073, trans_loss=5.117, nll_loss=2.413, w2v_ctc_loss=0.77, task_loss=4.802, task_loss_gen=6.123, contrastive_loss=0, total=4170.44, n_correct=2574.94, ppl=5.32, accuracy=61.743, wps=11543.3, ups=1.38, wpb=8340.9, bsz=308.9, num_updates=19800, lr=0.000100504, gnorm=0.5, clip=0, loss_scale=4, train_wall=72, gb_free=14.3, wall=18058
2023-09-02 00:52:45 | INFO | train_inner | epoch 014:    750 / 1474 loss=2.064, trans_loss=5.099, nll_loss=2.39, w2v_ctc_loss=0.767, task_loss=5.014, task_loss_gen=6.132, contrastive_loss=0, total=4131.24, n_correct=2570.33, ppl=5.24, accuracy=62.217, wps=11466.6, ups=1.39, wpb=8262.5, bsz=306.7, num_updates=19900, lr=0.000100251, gnorm=0.498, clip=0, loss_scale=4, train_wall=71, gb_free=16.6, wall=18130
2023-09-02 00:53:57 | INFO | train_inner | epoch 014:    850 / 1474 loss=2.059, trans_loss=5.097, nll_loss=2.387, w2v_ctc_loss=0.763, task_loss=4.787, task_loss_gen=5.894, contrastive_loss=0, total=4186.83, n_correct=2605.25, ppl=5.23, accuracy=62.225, wps=11642.3, ups=1.39, wpb=8373.7, bsz=321.3, num_updates=20000, lr=0.0001, gnorm=0.494, clip=0, loss_scale=4, train_wall=71, gb_free=15.9, wall=18202
2023-09-02 00:53:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 00:54:30 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.991 | trans_loss 5.287 | nll_loss 2.579 | w2v_ctc_loss 1.389 | task_loss 8.442 | task_loss_gen 18.272 | contrastive_loss 0 | total 4003.4 | n_correct 2579.1 | ppl 5.98 | accuracy 64.423 | uer 18.552 | wer 20.327 | raw_wer 20.327 | bleu 20.28 | wps 1603 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 20.28
2023-09-02 00:54:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-09-02 00:54:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-09-02 00:54:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-09-02 00:54:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 20.28) (writing took 13.779738899000222 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:0')
2023-09-02 00:55:57 | INFO | train_inner | epoch 014:    950 / 1474 loss=2.067, trans_loss=5.108, nll_loss=2.402, w2v_ctc_loss=0.767, task_loss=5.14, task_loss_gen=6.211, contrastive_loss=0, total=4166.07, n_correct=2583.28, ppl=5.28, accuracy=62.008, wps=6942.9, ups=0.83, wpb=8332.1, bsz=309.7, num_updates=20100, lr=9.97509e-05, gnorm=0.493, clip=0, loss_scale=4, train_wall=72, gb_free=15.6, wall=18322
2023-09-02 00:57:11 | INFO | train_inner | epoch 014:   1050 / 1474 loss=2.066, trans_loss=5.104, nll_loss=2.397, w2v_ctc_loss=0.766, task_loss=5.164, task_loss_gen=6.321, contrastive_loss=0, total=4137.97, n_correct=2572.19, ppl=5.27, accuracy=62.161, wps=11245.4, ups=1.36, wpb=8275.9, bsz=300.3, num_updates=20200, lr=9.95037e-05, gnorm=0.5, clip=0, loss_scale=4, train_wall=73, gb_free=17.3, wall=18395
2023-09-02 00:58:23 | INFO | train_inner | epoch 014:   1150 / 1474 loss=2.064, trans_loss=5.102, nll_loss=2.395, w2v_ctc_loss=0.77, task_loss=4.591, task_loss_gen=5.833, contrastive_loss=0, total=4232.08, n_correct=2628.87, ppl=5.26, accuracy=62.118, wps=11643.6, ups=1.38, wpb=8464.2, bsz=326.4, num_updates=20300, lr=9.92583e-05, gnorm=0.492, clip=0, loss_scale=4, train_wall=72, gb_free=15.5, wall=18468
2023-09-02 00:59:36 | INFO | train_inner | epoch 014:   1250 / 1474 loss=2.078, trans_loss=5.114, nll_loss=2.409, w2v_ctc_loss=0.779, task_loss=5.785, task_loss_gen=7.234, contrastive_loss=0, total=4022.82, n_correct=2495.17, ppl=5.31, accuracy=62.025, wps=11171.7, ups=1.39, wpb=8045.6, bsz=273.3, num_updates=20400, lr=9.90148e-05, gnorm=0.508, clip=0, loss_scale=4, train_wall=71, gb_free=15.8, wall=18540
2023-09-02 01:00:48 | INFO | train_inner | epoch 014:   1350 / 1474 loss=2.057, trans_loss=5.101, nll_loss=2.393, w2v_ctc_loss=0.758, task_loss=4.878, task_loss_gen=5.919, contrastive_loss=0, total=4198.44, n_correct=2616.77, ppl=5.25, accuracy=62.327, wps=11638.7, ups=1.39, wpb=8396.9, bsz=316.7, num_updates=20500, lr=9.8773e-05, gnorm=0.492, clip=0, loss_scale=4, train_wall=71, gb_free=16.7, wall=18612
2023-09-02 01:01:59 | INFO | train_inner | epoch 014:   1450 / 1474 loss=2.06, trans_loss=5.103, nll_loss=2.396, w2v_ctc_loss=0.756, task_loss=4.769, task_loss_gen=6.191, contrastive_loss=0, total=4138.32, n_correct=2576.39, ppl=5.26, accuracy=62.257, wps=11532.3, ups=1.39, wpb=8276.6, bsz=304.8, num_updates=20600, lr=9.85329e-05, gnorm=0.499, clip=0, loss_scale=4, train_wall=71, gb_free=10.3, wall=18684
2023-09-02 01:02:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:1')
2023-09-02 01:02:51 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.973 | trans_loss 5.28 | nll_loss 2.582 | w2v_ctc_loss 1.344 | task_loss 8.891 | task_loss_gen 18.029 | contrastive_loss 0 | total 4003.4 | n_correct 2583.8 | ppl 5.99 | accuracy 64.54 | uer 18.4 | wer 20.156 | raw_wer 20.156 | bleu 20.27 | wps 1565.4 | wpb 4003.4 | bsz 141.8 | num_updates 20624 | best_bleu 20.28
2023-09-02 01:02:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20624 updates
2023-09-02 01:02:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_20.2702.pt
2023-09-02 01:02:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_20.2702.pt
2023-09-02 01:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_20.2702.pt (epoch 14 @ 20624 updates, score 20.27) (writing took 8.082442164013628 seconds)
2023-09-02 01:02:59 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-09-02 01:02:59 | INFO | train | epoch 014 | loss 2.066 | trans_loss 5.106 | nll_loss 2.398 | w2v_ctc_loss 0.766 | task_loss 4.963 | task_loss_gen 6.199 | contrastive_loss 0 | total 4138.65 | n_correct 2570.99 | ppl 5.27 | accuracy 62.122 | wps 10496.9 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 20624 | lr 9.84756e-05 | gnorm 0.497 | clip 0 | loss_scale 4 | train_wall 1053 | gb_free 16.1 | wall 18744
2023-09-02 01:03:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 01:03:00 | INFO | fairseq.trainer | begin training epoch 15
2023-09-02 01:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 01:04:01 | INFO | train_inner | epoch 015:     76 / 1474 loss=2.054, trans_loss=5.087, nll_loss=2.374, w2v_ctc_loss=0.755, task_loss=5.034, task_loss_gen=6.179, contrastive_loss=0, total=4086.83, n_correct=2555.96, ppl=5.18, accuracy=62.541, wps=6713.1, ups=0.82, wpb=8173.7, bsz=301.6, num_updates=20700, lr=9.82946e-05, gnorm=0.501, clip=0, loss_scale=4, train_wall=71, gb_free=15.2, wall=18806
2023-09-02 01:05:14 | INFO | train_inner | epoch 015:    176 / 1474 loss=2.052, trans_loss=5.079, nll_loss=2.364, w2v_ctc_loss=0.76, task_loss=5.172, task_loss_gen=6.425, contrastive_loss=0, total=4115.38, n_correct=2580.65, ppl=5.15, accuracy=62.707, wps=11375.4, ups=1.38, wpb=8230.8, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.5, clip=0, loss_scale=4, train_wall=71, gb_free=16.3, wall=18878
2023-09-02 01:06:26 | INFO | train_inner | epoch 015:    276 / 1474 loss=2.047, trans_loss=5.077, nll_loss=2.361, w2v_ctc_loss=0.752, task_loss=4.876, task_loss_gen=6.075, contrastive_loss=0, total=4178.48, n_correct=2625.44, ppl=5.14, accuracy=62.832, wps=11607.3, ups=1.39, wpb=8357, bsz=309.5, num_updates=20900, lr=9.78232e-05, gnorm=0.496, clip=0, loss_scale=4, train_wall=71, gb_free=15.9, wall=18950
2023-09-02 01:07:38 | INFO | train_inner | epoch 015:    376 / 1474 loss=2.044, trans_loss=5.068, nll_loss=2.35, w2v_ctc_loss=0.748, task_loss=4.865, task_loss_gen=6.191, contrastive_loss=0, total=4176.34, n_correct=2628.23, ppl=5.1, accuracy=62.931, wps=11609.2, ups=1.39, wpb=8352.7, bsz=308.5, num_updates=21000, lr=9.759e-05, gnorm=0.492, clip=0, loss_scale=4, train_wall=71, gb_free=16.1, wall=19022
2023-09-02 01:08:50 | INFO | train_inner | epoch 015:    476 / 1474 loss=2.052, trans_loss=5.08, nll_loss=2.365, w2v_ctc_loss=0.753, task_loss=5.228, task_loss_gen=6.545, contrastive_loss=0, total=4076.17, n_correct=2553, ppl=5.15, accuracy=62.632, wps=11258.7, ups=1.38, wpb=8152.3, bsz=293.1, num_updates=21100, lr=9.73585e-05, gnorm=0.502, clip=0, loss_scale=4, train_wall=72, gb_free=16.4, wall=19094
2023-09-02 01:10:02 | INFO | train_inner | epoch 015:    576 / 1474 loss=2.05, trans_loss=5.079, nll_loss=2.363, w2v_ctc_loss=0.754, task_loss=5.715, task_loss_gen=6.439, contrastive_loss=0, total=4151.89, n_correct=2604.43, ppl=5.14, accuracy=62.729, wps=11473.2, ups=1.38, wpb=8303.8, bsz=302, num_updates=21200, lr=9.71286e-05, gnorm=0.495, clip=0, loss_scale=4, train_wall=72, gb_free=13.2, wall=19167
2023-09-02 01:11:14 | INFO | train_inner | epoch 015:    676 / 1474 loss=2.046, trans_loss=5.069, nll_loss=2.352, w2v_ctc_loss=0.753, task_loss=5.181, task_loss_gen=6.303, contrastive_loss=0, total=4122.17, n_correct=2589.95, ppl=5.1, accuracy=62.83, wps=11427.1, ups=1.39, wpb=8244.3, bsz=304, num_updates=21300, lr=9.69003e-05, gnorm=0.494, clip=0, loss_scale=4, train_wall=71, gb_free=17, wall=19239
2023-09-02 01:12:27 | INFO | train_inner | epoch 015:    776 / 1474 loss=2.045, trans_loss=5.073, nll_loss=2.356, w2v_ctc_loss=0.753, task_loss=4.883, task_loss_gen=6.221, contrastive_loss=0, total=4181.07, n_correct=2627.72, ppl=5.12, accuracy=62.848, wps=11518.2, ups=1.38, wpb=8362.1, bsz=307.1, num_updates=21400, lr=9.66736e-05, gnorm=0.489, clip=0, loss_scale=8, train_wall=72, gb_free=16.2, wall=19312
2023-09-02 01:13:39 | INFO | train_inner | epoch 015:    876 / 1474 loss=2.049, trans_loss=5.071, nll_loss=2.356, w2v_ctc_loss=0.758, task_loss=4.797, task_loss_gen=6.799, contrastive_loss=0, total=4052.17, n_correct=2553.03, ppl=5.12, accuracy=63.004, wps=11345.5, ups=1.4, wpb=8104.3, bsz=286.4, num_updates=21500, lr=9.64486e-05, gnorm=0.495, clip=0, loss_scale=8, train_wall=71, gb_free=16.7, wall=19383
2023-09-02 01:14:50 | INFO | train_inner | epoch 015:    976 / 1474 loss=2.046, trans_loss=5.073, nll_loss=2.358, w2v_ctc_loss=0.754, task_loss=4.621, task_loss_gen=6.261, contrastive_loss=0, total=4135.95, n_correct=2600.89, ppl=5.13, accuracy=62.885, wps=11528.6, ups=1.39, wpb=8271.9, bsz=304.3, num_updates=21600, lr=9.6225e-05, gnorm=0.494, clip=0, loss_scale=8, train_wall=71, gb_free=16.3, wall=19455
2023-09-02 01:16:03 | INFO | train_inner | epoch 015:   1076 / 1474 loss=2.04, trans_loss=5.072, nll_loss=2.356, w2v_ctc_loss=0.75, task_loss=4.399, task_loss_gen=5.879, contrastive_loss=0, total=4187.18, n_correct=2634.84, ppl=5.12, accuracy=62.926, wps=11445.3, ups=1.37, wpb=8374.4, bsz=324.7, num_updates=21700, lr=9.60031e-05, gnorm=0.485, clip=0, loss_scale=8, train_wall=72, gb_free=13.6, wall=19528
2023-09-02 01:17:15 | INFO | train_inner | epoch 015:   1176 / 1474 loss=2.026, trans_loss=5.059, nll_loss=2.342, w2v_ctc_loss=0.731, task_loss=4.025, task_loss_gen=5.668, contrastive_loss=0, total=4184.18, n_correct=2651, ppl=5.07, accuracy=63.358, wps=11676.2, ups=1.4, wpb=8368.4, bsz=328.4, num_updates=21800, lr=9.57826e-05, gnorm=0.491, clip=0, loss_scale=8, train_wall=71, gb_free=15.4, wall=19600
2023-09-02 01:18:27 | INFO | train_inner | epoch 015:   1276 / 1474 loss=2.047, trans_loss=5.065, nll_loss=2.346, w2v_ctc_loss=0.763, task_loss=4.61, task_loss_gen=6.493, contrastive_loss=0, total=4141.39, n_correct=2606.87, ppl=5.09, accuracy=62.947, wps=11464, ups=1.38, wpb=8282.8, bsz=302.1, num_updates=21900, lr=9.55637e-05, gnorm=0.499, clip=0, loss_scale=8, train_wall=71, gb_free=16.1, wall=19672
2023-09-02 01:19:40 | INFO | train_inner | epoch 015:   1376 / 1474 loss=2.044, trans_loss=5.067, nll_loss=2.349, w2v_ctc_loss=0.755, task_loss=4.967, task_loss_gen=6.502, contrastive_loss=0, total=4106.11, n_correct=2587.82, ppl=5.1, accuracy=63.024, wps=11351.7, ups=1.38, wpb=8212.2, bsz=294.2, num_updates=22000, lr=9.53463e-05, gnorm=0.503, clip=0, loss_scale=8, train_wall=72, gb_free=16.5, wall=19744
2023-09-02 01:19:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 01:20:13 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.953 | trans_loss 5.265 | nll_loss 2.555 | w2v_ctc_loss 1.314 | task_loss 8.068 | task_loss_gen 19.036 | contrastive_loss 0 | total 4003.4 | n_correct 2594.3 | ppl 5.88 | accuracy 64.802 | uer 18.244 | wer 19.858 | raw_wer 19.858 | bleu 20.6 | wps 1586 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 20.6
2023-09-02 01:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-09-02 01:20:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-09-02 01:20:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-09-02 01:20:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 20.6) (writing took 13.496561312989797 seconds)
2023-09-02 01:21:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 01:22:11 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.25 | nll_loss 2.537 | w2v_ctc_loss 1.354 | task_loss 10.524 | task_loss_gen 18.061 | contrastive_loss 0 | total 4003.4 | n_correct 2600.5 | ppl 5.81 | accuracy 64.957 | uer 18.339 | wer 20.055 | raw_wer 20.055 | bleu 20.65 | wps 1648 | wpb 4003.4 | bsz 141.8 | num_updates 22098 | best_bleu 20.65
2023-09-02 01:22:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22098 updates
2023-09-02 01:22:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 01:22:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 01:22:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 15 @ 22098 updates, score 20.65) (writing took 12.92260286200326 seconds)
2023-09-02 01:22:24 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-09-02 01:22:24 | INFO | train | epoch 015 | loss 2.045 | trans_loss 5.072 | nll_loss 2.356 | w2v_ctc_loss 0.752 | task_loss 4.869 | task_loss_gen 6.255 | contrastive_loss 0 | total 4138.65 | n_correct 2602.79 | ppl 5.12 | accuracy 62.89 | wps 10472.6 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 22098 | lr 9.51346e-05 | gnorm 0.495 | clip 0 | loss_scale 8 | train_wall 1053 | gb_free 16.6 | wall 19909
2023-09-02 01:22:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 01:22:25 | INFO | fairseq.trainer | begin training epoch 16
2023-09-02 01:22:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 01:22:33 | INFO | train_inner | epoch 016:      2 / 1474 loss=2.044, trans_loss=5.076, nll_loss=2.362, w2v_ctc_loss=0.752, task_loss=4.856, task_loss_gen=6.042, contrastive_loss=0, total=4152.6, n_correct=2612.52, ppl=5.14, accuracy=62.913, wps=4790.4, ups=0.58, wpb=8305.2, bsz=316.4, num_updates=22100, lr=9.51303e-05, gnorm=0.49, clip=0, loss_scale=8, train_wall=72, gb_free=16.3, wall=19918
2023-09-02 01:23:45 | INFO | train_inner | epoch 016:    102 / 1474 loss=2.022, trans_loss=5.044, nll_loss=2.32, w2v_ctc_loss=0.732, task_loss=5.072, task_loss_gen=6.026, contrastive_loss=0, total=4115.14, n_correct=2613.64, ppl=4.99, accuracy=63.513, wps=11526.7, ups=1.4, wpb=8230.3, bsz=313.9, num_updates=22200, lr=9.49158e-05, gnorm=0.497, clip=0, loss_scale=8, train_wall=71, gb_free=12.1, wall=19989
2023-09-02 01:24:57 | INFO | train_inner | epoch 016:    202 / 1474 loss=2.023, trans_loss=5.037, nll_loss=2.309, w2v_ctc_loss=0.729, task_loss=5.013, task_loss_gen=6.429, contrastive_loss=0, total=4109.58, n_correct=2614.65, ppl=4.95, accuracy=63.623, wps=11324, ups=1.38, wpb=8219.2, bsz=297.3, num_updates=22300, lr=9.47027e-05, gnorm=0.497, clip=0, loss_scale=8, train_wall=72, gb_free=14.7, wall=20062
2023-09-02 01:26:10 | INFO | train_inner | epoch 016:    302 / 1474 loss=2.033, trans_loss=5.049, nll_loss=2.327, w2v_ctc_loss=0.744, task_loss=4.973, task_loss_gen=6.228, contrastive_loss=0, total=4164.1, n_correct=2638.24, ppl=5.02, accuracy=63.357, wps=11491.8, ups=1.38, wpb=8328.2, bsz=308.6, num_updates=22400, lr=9.44911e-05, gnorm=0.5, clip=0, loss_scale=8, train_wall=72, gb_free=16.9, wall=20134
2023-09-02 01:27:21 | INFO | train_inner | epoch 016:    402 / 1474 loss=2.035, trans_loss=5.046, nll_loss=2.321, w2v_ctc_loss=0.746, task_loss=5.391, task_loss_gen=6.733, contrastive_loss=0, total=4065.22, n_correct=2578.48, ppl=5, accuracy=63.428, wps=11342.8, ups=1.4, wpb=8130.4, bsz=286.4, num_updates=22500, lr=9.42809e-05, gnorm=0.508, clip=0, loss_scale=8, train_wall=71, gb_free=15.9, wall=20206
2023-09-02 01:28:34 | INFO | train_inner | epoch 016:    502 / 1474 loss=2.023, trans_loss=5.045, nll_loss=2.322, w2v_ctc_loss=0.733, task_loss=4.673, task_loss_gen=5.968, contrastive_loss=0, total=4181.93, n_correct=2660.89, ppl=5, accuracy=63.628, wps=11503.6, ups=1.38, wpb=8363.9, bsz=320.3, num_updates=22600, lr=9.40721e-05, gnorm=0.487, clip=0, loss_scale=8, train_wall=72, gb_free=15.5, wall=20279
2023-09-02 01:29:45 | INFO | train_inner | epoch 016:    602 / 1474 loss=2.022, trans_loss=5.04, nll_loss=2.315, w2v_ctc_loss=0.729, task_loss=4.578, task_loss_gen=6.278, contrastive_loss=0, total=4122.97, n_correct=2624.84, ppl=4.98, accuracy=63.664, wps=11554.4, ups=1.4, wpb=8245.9, bsz=299, num_updates=22700, lr=9.38647e-05, gnorm=0.498, clip=0, loss_scale=8, train_wall=70, gb_free=15.8, wall=20350
2023-09-02 01:30:57 | INFO | train_inner | epoch 016:    702 / 1474 loss=2.031, trans_loss=5.046, nll_loss=2.322, w2v_ctc_loss=0.742, task_loss=5.042, task_loss_gen=6.539, contrastive_loss=0, total=4093.15, n_correct=2595.1, ppl=5, accuracy=63.401, wps=11482.3, ups=1.4, wpb=8186.3, bsz=296.5, num_updates=22800, lr=9.36586e-05, gnorm=0.498, clip=0, loss_scale=8, train_wall=70, gb_free=17.5, wall=20421
2023-09-02 01:32:09 | INFO | train_inner | epoch 016:    802 / 1474 loss=2.022, trans_loss=5.041, nll_loss=2.317, w2v_ctc_loss=0.73, task_loss=4.863, task_loss_gen=6.014, contrastive_loss=0, total=4183.24, n_correct=2658.04, ppl=4.98, accuracy=63.54, wps=11588.3, ups=1.39, wpb=8366.5, bsz=312.1, num_updates=22900, lr=9.34539e-05, gnorm=0.492, clip=0, loss_scale=8, train_wall=71, gb_free=17.5, wall=20493
2023-09-02 01:33:21 | INFO | train_inner | epoch 016:    902 / 1474 loss=2.025, trans_loss=5.041, nll_loss=2.317, w2v_ctc_loss=0.735, task_loss=5.103, task_loss_gen=6.162, contrastive_loss=0, total=4150.23, n_correct=2638.55, ppl=4.98, accuracy=63.576, wps=11547.1, ups=1.39, wpb=8300.5, bsz=306.5, num_updates=23000, lr=9.32505e-05, gnorm=0.493, clip=0, loss_scale=8, train_wall=71, gb_free=11.7, wall=20565
2023-09-02 01:34:33 | INFO | train_inner | epoch 016:   1002 / 1474 loss=2.031, trans_loss=5.047, nll_loss=2.324, w2v_ctc_loss=0.745, task_loss=4.922, task_loss_gen=6.492, contrastive_loss=0, total=4116.59, n_correct=2609.16, ppl=5.01, accuracy=63.382, wps=11348.2, ups=1.38, wpb=8233.2, bsz=300.6, num_updates=23100, lr=9.30484e-05, gnorm=0.491, clip=0, loss_scale=8, train_wall=72, gb_free=16.5, wall=20638
2023-09-02 01:35:46 | INFO | train_inner | epoch 016:   1102 / 1474 loss=2.036, trans_loss=5.054, nll_loss=2.334, w2v_ctc_loss=0.747, task_loss=5.177, task_loss_gen=6.702, contrastive_loss=0, total=4112.71, n_correct=2599.84, ppl=5.04, accuracy=63.215, wps=11292.3, ups=1.37, wpb=8225.4, bsz=295.7, num_updates=23200, lr=9.28477e-05, gnorm=0.505, clip=0, loss_scale=8, train_wall=72, gb_free=11.8, wall=20711
2023-09-02 01:36:59 | INFO | train_inner | epoch 016:   1202 / 1474 loss=2.03, trans_loss=5.05, nll_loss=2.329, w2v_ctc_loss=0.735, task_loss=5.206, task_loss_gen=6.376, contrastive_loss=0, total=4161.11, n_correct=2635.86, ppl=5.02, accuracy=63.345, wps=11441.5, ups=1.37, wpb=8322.2, bsz=308.2, num_updates=23300, lr=9.26482e-05, gnorm=0.502, clip=0, loss_scale=8, train_wall=72, gb_free=15.5, wall=20783
2023-09-02 01:38:12 | INFO | train_inner | epoch 016:   1302 / 1474 loss=2.03, trans_loss=5.044, nll_loss=2.322, w2v_ctc_loss=0.747, task_loss=4.844, task_loss_gen=6.188, contrastive_loss=0, total=4149.14, n_correct=2634.49, ppl=5, accuracy=63.495, wps=11390.3, ups=1.37, wpb=8298.3, bsz=311.9, num_updates=23400, lr=9.245e-05, gnorm=0.492, clip=0, loss_scale=16, train_wall=72, gb_free=10.9, wall=20856
2023-09-02 01:39:25 | INFO | train_inner | epoch 016:   1402 / 1474 loss=2.023, trans_loss=5.039, nll_loss=2.315, w2v_ctc_loss=0.741, task_loss=3.658, task_loss_gen=6.142, contrastive_loss=0, total=4200.01, n_correct=2672.68, ppl=4.98, accuracy=63.635, wps=11529.6, ups=1.37, wpb=8400, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.486, clip=0, loss_scale=16, train_wall=72, gb_free=16.7, wall=20929
2023-09-02 01:40:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 01:40:49 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.941 | trans_loss 5.233 | nll_loss 2.518 | w2v_ctc_loss 1.344 | task_loss 7.423 | task_loss_gen 19.789 | contrastive_loss 0 | total 4003.4 | n_correct 2607.8 | ppl 5.73 | accuracy 65.14 | uer 18.055 | wer 19.757 | raw_wer 19.757 | bleu 21.19 | wps 1620 | wpb 4003.4 | bsz 141.8 | num_updates 23572 | best_bleu 21.19
2023-09-02 01:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23572 updates
2023-09-02 01:40:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 01:40:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 01:41:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 16 @ 23572 updates, score 21.19) (writing took 13.657922577986028 seconds)
2023-09-02 01:41:03 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-09-02 01:41:03 | INFO | train | epoch 016 | loss 2.027 | trans_loss 5.044 | nll_loss 2.321 | w2v_ctc_loss 0.738 | task_loss 4.841 | task_loss_gen 6.305 | contrastive_loss 0 | total 4138.65 | n_correct 2627.88 | ppl 5 | accuracy 63.496 | wps 10903.3 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 23572 | lr 9.21121e-05 | gnorm 0.496 | clip 0 | loss_scale 16 | train_wall 1053 | gb_free 15.1 | wall 21028
2023-09-02 01:41:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 01:41:04 | INFO | fairseq.trainer | begin training epoch 17
2023-09-02 01:41:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 01:41:32 | INFO | train_inner | epoch 017:     28 / 1474 loss=2.018, trans_loss=5.026, nll_loss=2.297, w2v_ctc_loss=0.728, task_loss=4.202, task_loss_gen=6.619, contrastive_loss=0, total=4141.79, n_correct=2643.4, ppl=4.92, accuracy=63.823, wps=6519.6, ups=0.79, wpb=8283.6, bsz=301.5, num_updates=23600, lr=9.20575e-05, gnorm=0.496, clip=0, loss_scale=16, train_wall=72, gb_free=15.8, wall=21056
2023-09-02 01:42:44 | INFO | train_inner | epoch 017:    128 / 1474 loss=2.013, trans_loss=5.013, nll_loss=2.28, w2v_ctc_loss=0.731, task_loss=4.178, task_loss_gen=6.837, contrastive_loss=0, total=4110.88, n_correct=2637.83, ppl=4.86, accuracy=64.167, wps=11350.8, ups=1.38, wpb=8221.8, bsz=295.4, num_updates=23700, lr=9.1863e-05, gnorm=0.497, clip=0, loss_scale=16, train_wall=72, gb_free=16, wall=21129
2023-09-02 01:43:56 | INFO | train_inner | epoch 017:    228 / 1474 loss=2.006, trans_loss=5.013, nll_loss=2.28, w2v_ctc_loss=0.718, task_loss=3.71, task_loss_gen=6.279, contrastive_loss=0, total=4171.95, n_correct=2672.78, ppl=4.86, accuracy=64.065, wps=11659.7, ups=1.4, wpb=8343.9, bsz=320.4, num_updates=23800, lr=9.16698e-05, gnorm=0.503, clip=0, loss_scale=16, train_wall=71, gb_free=15.7, wall=21200
2023-09-02 01:45:08 | INFO | train_inner | epoch 017:    328 / 1474 loss=2.009, trans_loss=5.016, nll_loss=2.285, w2v_ctc_loss=0.72, task_loss=4.57, task_loss_gen=6.526, contrastive_loss=0, total=4157.94, n_correct=2665.57, ppl=4.87, accuracy=64.108, wps=11544.6, ups=1.39, wpb=8315.9, bsz=305, num_updates=23900, lr=9.14779e-05, gnorm=0.498, clip=0, loss_scale=16, train_wall=71, gb_free=14.2, wall=21272
2023-09-02 01:46:21 | INFO | train_inner | epoch 017:    428 / 1474 loss=2.015, trans_loss=5.022, nll_loss=2.292, w2v_ctc_loss=0.732, task_loss=4.233, task_loss_gen=6.762, contrastive_loss=0, total=4141.8, n_correct=2649.55, ppl=4.9, accuracy=63.971, wps=11382.2, ups=1.37, wpb=8283.6, bsz=306.7, num_updates=24000, lr=9.12871e-05, gnorm=0.505, clip=0, loss_scale=16, train_wall=72, gb_free=17, wall=21345
2023-09-02 01:46:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 01:46:53 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.965 | trans_loss 5.248 | nll_loss 2.532 | w2v_ctc_loss 1.39 | task_loss 9.102 | task_loss_gen 19.271 | contrastive_loss 0 | total 4003.4 | n_correct 2600.1 | ppl 5.79 | accuracy 64.947 | uer 18.374 | wer 20.022 | raw_wer 20.022 | bleu 20.56 | wps 1643.3 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 21.19
2023-09-02 01:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-09-02 01:46:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-09-02 01:46:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-09-02 01:47:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 20.56) (writing took 9.55763249800657 seconds)
2023-09-02 01:48:17 | INFO | train_inner | epoch 017:    528 / 1474 loss=2.015, trans_loss=5.022, nll_loss=2.293, w2v_ctc_loss=0.732, task_loss=4.204, task_loss_gen=6.905, contrastive_loss=0, total=4180.09, n_correct=2675.02, ppl=4.9, accuracy=63.994, wps=7204.4, ups=0.86, wpb=8360.2, bsz=307.5, num_updates=24100, lr=9.10975e-05, gnorm=0.496, clip=0, loss_scale=16, train_wall=72, gb_free=16.8, wall=21461
2023-09-02 01:49:29 | INFO | train_inner | epoch 017:    628 / 1474 loss=2.014, trans_loss=5.024, nll_loss=2.295, w2v_ctc_loss=0.726, task_loss=3.711, task_loss_gen=7.064, contrastive_loss=0, total=4166.6, n_correct=2666.2, ppl=4.91, accuracy=63.99, wps=11515.2, ups=1.38, wpb=8333.2, bsz=302.3, num_updates=24200, lr=9.09091e-05, gnorm=0.496, clip=0, loss_scale=16, train_wall=72, gb_free=15.3, wall=21534
2023-09-02 01:50:41 | INFO | train_inner | epoch 017:    728 / 1474 loss=2.023, trans_loss=5.028, nll_loss=2.3, w2v_ctc_loss=0.743, task_loss=3.773, task_loss_gen=6.856, contrastive_loss=0, total=4168.97, n_correct=2656.28, ppl=4.93, accuracy=63.715, wps=11577.2, ups=1.39, wpb=8337.9, bsz=308.4, num_updates=24300, lr=9.07218e-05, gnorm=0.503, clip=0, loss_scale=16, train_wall=71, gb_free=16.7, wall=21606
2023-09-02 01:51:53 | INFO | train_inner | epoch 017:    828 / 1474 loss=2.018, trans_loss=5.025, nll_loss=2.296, w2v_ctc_loss=0.735, task_loss=4.247, task_loss_gen=6.892, contrastive_loss=0, total=4097.38, n_correct=2619.3, ppl=4.91, accuracy=63.926, wps=11392.5, ups=1.39, wpb=8194.8, bsz=297.3, num_updates=24400, lr=9.05357e-05, gnorm=0.506, clip=0, loss_scale=16, train_wall=71, gb_free=10.1, wall=21677
2023-09-02 01:53:04 | INFO | train_inner | epoch 017:    928 / 1474 loss=2.012, trans_loss=5.023, nll_loss=2.293, w2v_ctc_loss=0.721, task_loss=4.94, task_loss_gen=6.63, contrastive_loss=0, total=4105.01, n_correct=2621.01, ppl=4.9, accuracy=63.849, wps=11628.6, ups=1.42, wpb=8210, bsz=304.1, num_updates=24500, lr=9.03508e-05, gnorm=0.508, clip=0, loss_scale=16, train_wall=70, gb_free=16.3, wall=21748
2023-09-02 01:54:15 | INFO | train_inner | epoch 017:   1028 / 1474 loss=2.016, trans_loss=5.024, nll_loss=2.296, w2v_ctc_loss=0.73, task_loss=4.739, task_loss_gen=6.704, contrastive_loss=0, total=4105.88, n_correct=2620.64, ppl=4.91, accuracy=63.827, wps=11413.5, ups=1.39, wpb=8211.8, bsz=303.4, num_updates=24600, lr=9.0167e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=71, gb_free=15.6, wall=21820
2023-09-02 01:55:27 | INFO | train_inner | epoch 017:   1128 / 1474 loss=2.007, trans_loss=5.016, nll_loss=2.285, w2v_ctc_loss=0.715, task_loss=6.467, task_loss_gen=6.875, contrastive_loss=0, total=4095.58, n_correct=2628.84, ppl=4.87, accuracy=64.187, wps=11444.7, ups=1.4, wpb=8191.2, bsz=298.5, num_updates=24700, lr=8.99843e-05, gnorm=0.502, clip=0, loss_scale=16, train_wall=71, gb_free=15.4, wall=21892
2023-09-02 01:56:40 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2.017, trans_loss=5.031, nll_loss=2.304, w2v_ctc_loss=0.724, task_loss=5.263, task_loss_gen=6.371, contrastive_loss=0, total=4162.14, n_correct=2648.89, ppl=4.94, accuracy=63.643, wps=11347.3, ups=1.36, wpb=8324.3, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.501, clip=0, loss_scale=16, train_wall=73, gb_free=15.8, wall=21965
2023-09-02 01:57:53 | INFO | train_inner | epoch 017:   1328 / 1474 loss=2.012, trans_loss=5.024, nll_loss=2.295, w2v_ctc_loss=0.72, task_loss=4.903, task_loss_gen=6.474, contrastive_loss=0, total=4149.03, n_correct=2654.62, ppl=4.91, accuracy=63.982, wps=11406.4, ups=1.37, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.498, clip=0, loss_scale=16, train_wall=72, gb_free=16.5, wall=22038
2023-09-02 01:59:06 | INFO | train_inner | epoch 017:   1428 / 1474 loss=2.006, trans_loss=5.017, nll_loss=2.287, w2v_ctc_loss=0.716, task_loss=4.319, task_loss_gen=6.644, contrastive_loss=0, total=4117.13, n_correct=2641.55, ppl=4.88, accuracy=64.16, wps=11337.8, ups=1.38, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.49, clip=0, loss_scale=16, train_wall=72, gb_free=17.2, wall=22110
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:0')
2023-09-02 01:59:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:5')
2023-09-02 02:00:12 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.945 | trans_loss 5.226 | nll_loss 2.505 | w2v_ctc_loss 1.373 | task_loss 9.928 | task_loss_gen 18.13 | contrastive_loss 0 | total 4003.4 | n_correct 2611.9 | ppl 5.68 | accuracy 65.242 | uer 17.702 | wer 19.339 | raw_wer 19.339 | bleu 20.81 | wps 1647.2 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 21.19
2023-09-02 02:00:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-09-02 02:00:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_20.8109.pt
2023-09-02 02:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_20.8109.pt
2023-09-02 02:00:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_20.8109.pt (epoch 17 @ 25046 updates, score 20.81) (writing took 8.647216882003704 seconds)
2023-09-02 02:00:21 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-09-02 02:00:21 | INFO | train | epoch 017 | loss 2.013 | trans_loss 5.021 | nll_loss 2.291 | w2v_ctc_loss 0.726 | task_loss 4.55 | task_loss_gen 6.694 | contrastive_loss 0 | total 4138.65 | n_correct 2647.95 | ppl 4.89 | accuracy 63.981 | wps 10540.2 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.501 | clip 0 | loss_scale 16 | train_wall 1053 | gb_free 16 | wall 22186
2023-09-02 02:00:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 02:00:21 | INFO | fairseq.trainer | begin training epoch 18
2023-09-02 02:00:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 02:01:08 | INFO | train_inner | epoch 018:     54 / 1474 loss=2.009, trans_loss=5.012, nll_loss=2.281, w2v_ctc_loss=0.729, task_loss=5.298, task_loss_gen=6.621, contrastive_loss=0, total=4138.21, n_correct=2656.84, ppl=4.86, accuracy=64.203, wps=6782.2, ups=0.82, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.497, clip=0, loss_scale=16, train_wall=72, gb_free=17.5, wall=22232
2023-09-02 02:02:20 | INFO | train_inner | epoch 018:    154 / 1474 loss=1.992, trans_loss=4.991, nll_loss=2.252, w2v_ctc_loss=0.706, task_loss=4.325, task_loss_gen=6.152, contrastive_loss=0, total=4158.88, n_correct=2685.96, ppl=4.76, accuracy=64.584, wps=11509.6, ups=1.38, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.499, clip=0, loss_scale=16, train_wall=71, gb_free=16.5, wall=22305
2023-09-02 02:03:33 | INFO | train_inner | epoch 018:    254 / 1474 loss=1.992, trans_loss=4.991, nll_loss=2.252, w2v_ctc_loss=0.708, task_loss=3.969, task_loss_gen=6.507, contrastive_loss=0, total=4164.11, n_correct=2692.95, ppl=4.76, accuracy=64.67, wps=11470, ups=1.38, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.499, clip=0, loss_scale=16, train_wall=72, gb_free=14.6, wall=22377
2023-09-02 02:04:45 | INFO | train_inner | epoch 018:    354 / 1474 loss=1.997, trans_loss=4.998, nll_loss=2.261, w2v_ctc_loss=0.707, task_loss=4.796, task_loss_gen=6.682, contrastive_loss=0, total=4163.13, n_correct=2686.11, ppl=4.79, accuracy=64.521, wps=11452, ups=1.38, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.5, clip=0, loss_scale=16, train_wall=72, gb_free=17.3, wall=22450
2023-09-02 02:05:59 | INFO | train_inner | epoch 018:    454 / 1474 loss=2.007, trans_loss=5.004, nll_loss=2.27, w2v_ctc_loss=0.724, task_loss=4.664, task_loss_gen=7.251, contrastive_loss=0, total=4087.83, n_correct=2627.49, ppl=4.82, accuracy=64.276, wps=11157.1, ups=1.36, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.509, clip=0, loss_scale=32, train_wall=73, gb_free=16, wall=22523
2023-09-02 02:07:11 | INFO | train_inner | epoch 018:    554 / 1474 loss=1.988, trans_loss=4.987, nll_loss=2.249, w2v_ctc_loss=0.707, task_loss=3.042, task_loss_gen=6.459, contrastive_loss=0, total=4204.41, n_correct=2722.87, ppl=4.75, accuracy=64.762, wps=11649.8, ups=1.39, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.488, clip=0, loss_scale=32, train_wall=71, gb_free=17.1, wall=22596
2023-09-02 02:08:23 | INFO | train_inner | epoch 018:    654 / 1474 loss=2.006, trans_loss=5.005, nll_loss=2.271, w2v_ctc_loss=0.725, task_loss=2.974, task_loss_gen=7.777, contrastive_loss=0, total=4096.81, n_correct=2636.62, ppl=4.83, accuracy=64.358, wps=11420.6, ups=1.39, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.503, clip=0, loss_scale=32, train_wall=71, gb_free=16.3, wall=22667
2023-09-02 02:09:35 | INFO | train_inner | epoch 018:    754 / 1474 loss=2.002, trans_loss=5.003, nll_loss=2.269, w2v_ctc_loss=0.722, task_loss=3.3, task_loss_gen=7.149, contrastive_loss=0, total=4208.29, n_correct=2707.53, ppl=4.82, accuracy=64.338, wps=11628.9, ups=1.38, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.496, clip=0, loss_scale=32, train_wall=72, gb_free=17.5, wall=22740
2023-09-02 02:10:47 | INFO | train_inner | epoch 018:    854 / 1474 loss=2.001, trans_loss=5, nll_loss=2.264, w2v_ctc_loss=0.719, task_loss=3.62, task_loss_gen=7.669, contrastive_loss=0, total=4166.81, n_correct=2685.56, ppl=4.8, accuracy=64.451, wps=11523.7, ups=1.38, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=72, gb_free=12.3, wall=22812
2023-09-02 02:11:59 | INFO | train_inner | epoch 018:    954 / 1474 loss=1.988, trans_loss=4.99, nll_loss=2.252, w2v_ctc_loss=0.703, task_loss=2.806, task_loss_gen=7.239, contrastive_loss=0, total=4142.65, n_correct=2680.91, ppl=4.76, accuracy=64.715, wps=11603.2, ups=1.4, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.493, clip=0, loss_scale=32, train_wall=71, gb_free=14.5, wall=22883
2023-09-02 02:11:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 02:12:32 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.937 | trans_loss 5.224 | nll_loss 2.506 | w2v_ctc_loss 1.351 | task_loss 10.92 | task_loss_gen 21.387 | contrastive_loss 0 | total 4003.4 | n_correct 2620.7 | ppl 5.68 | accuracy 65.462 | uer 18.124 | wer 19.921 | raw_wer 19.921 | bleu 21.29 | wps 1636.6 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 21.29
2023-09-02 02:12:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-09-02 02:12:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-09-02 02:12:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-09-02 02:12:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 21.29) (writing took 13.989445057988632 seconds)
2023-09-02 02:13:59 | INFO | train_inner | epoch 018:   1054 / 1474 loss=1.999, trans_loss=4.997, nll_loss=2.261, w2v_ctc_loss=0.714, task_loss=3.748, task_loss_gen=7.907, contrastive_loss=0, total=4137.77, n_correct=2667.51, ppl=4.79, accuracy=64.467, wps=6894.4, ups=0.83, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=72, gb_free=17, wall=23003
2023-09-02 02:15:11 | INFO | train_inner | epoch 018:   1154 / 1474 loss=1.997, trans_loss=4.992, nll_loss=2.254, w2v_ctc_loss=0.718, task_loss=3.548, task_loss_gen=7.323, contrastive_loss=0, total=4153.69, n_correct=2680.73, ppl=4.77, accuracy=64.539, wps=11509.6, ups=1.39, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.496, clip=0, loss_scale=32, train_wall=72, gb_free=14.8, wall=23076
2023-09-02 02:16:23 | INFO | train_inner | epoch 018:   1254 / 1474 loss=2.003, trans_loss=5.006, nll_loss=2.273, w2v_ctc_loss=0.716, task_loss=3.806, task_loss_gen=8.147, contrastive_loss=0, total=4087.62, n_correct=2633.43, ppl=4.83, accuracy=64.425, wps=11348.8, ups=1.39, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.502, clip=0, loss_scale=32, train_wall=71, gb_free=16.3, wall=23148
2023-09-02 02:17:35 | INFO | train_inner | epoch 018:   1354 / 1474 loss=2.012, trans_loss=5.008, nll_loss=2.275, w2v_ctc_loss=0.737, task_loss=3.566, task_loss_gen=8.297, contrastive_loss=0, total=4070.69, n_correct=2616.08, ppl=4.84, accuracy=64.266, wps=11372.4, ups=1.4, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=71, gb_free=17.1, wall=23219
2023-09-02 02:18:48 | INFO | train_inner | epoch 018:   1454 / 1474 loss=2.005, trans_loss=5.004, nll_loss=2.27, w2v_ctc_loss=0.724, task_loss=3.934, task_loss_gen=7.899, contrastive_loss=0, total=4113.2, n_correct=2646.01, ppl=4.82, accuracy=64.33, wps=11274.5, ups=1.37, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.502, clip=0, loss_scale=32, train_wall=72, gb_free=16.1, wall=23292
2023-09-02 02:19:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 02:19:35 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.932 | trans_loss 5.222 | nll_loss 2.502 | w2v_ctc_loss 1.339 | task_loss 10.681 | task_loss_gen 20.164 | contrastive_loss 0 | total 4003.4 | n_correct 2620.8 | ppl 5.66 | accuracy 65.464 | uer 17.801 | wer 19.522 | raw_wer 19.522 | bleu 21.49 | wps 1642.6 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 21.49
2023-09-02 02:19:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-09-02 02:19:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 02:19:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 02:19:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 18 @ 26520 updates, score 21.49) (writing took 14.237462555000093 seconds)
2023-09-02 02:19:49 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-09-02 02:19:49 | INFO | train | epoch 018 | loss 1.999 | trans_loss 4.998 | nll_loss 2.263 | w2v_ctc_loss 0.717 | task_loss 3.745 | task_loss_gen 7.283 | contrastive_loss 0 | total 4138.65 | n_correct 2668.12 | ppl 4.8 | accuracy 64.468 | wps 10442.9 | ups 1.26 | wpb 8277.3 | bsz 305.7 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.5 | clip 0 | loss_scale 32 | train_wall 1055 | gb_free 15.6 | wall 23354
2023-09-02 02:19:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 02:19:50 | INFO | fairseq.trainer | begin training epoch 19
2023-09-02 02:19:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 02:20:54 | INFO | train_inner | epoch 019:     80 / 1474 loss=1.992, trans_loss=4.981, nll_loss=2.241, w2v_ctc_loss=0.712, task_loss=2.996, task_loss_gen=7.995, contrastive_loss=0, total=4102.06, n_correct=2658.65, ppl=4.73, accuracy=64.813, wps=6504.8, ups=0.79, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.508, clip=0, loss_scale=32, train_wall=71, gb_free=17.2, wall=23418
2023-09-02 02:22:07 | INFO | train_inner | epoch 019:    180 / 1474 loss=1.989, trans_loss=4.979, nll_loss=2.238, w2v_ctc_loss=0.714, task_loss=3.827, task_loss_gen=7.312, contrastive_loss=0, total=4227.7, n_correct=2740.57, ppl=4.72, accuracy=64.824, wps=11623.2, ups=1.37, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.497, clip=0, loss_scale=32, train_wall=72, gb_free=16.7, wall=23491
2023-09-02 02:23:19 | INFO | train_inner | epoch 019:    280 / 1474 loss=1.989, trans_loss=4.975, nll_loss=2.231, w2v_ctc_loss=0.711, task_loss=5.372, task_loss_gen=7.021, contrastive_loss=0, total=4187.34, n_correct=2717.49, ppl=4.7, accuracy=64.898, wps=11601.6, ups=1.39, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=71, gb_free=15.6, wall=23563
2023-09-02 02:24:31 | INFO | train_inner | epoch 019:    380 / 1474 loss=1.982, trans_loss=4.973, nll_loss=2.23, w2v_ctc_loss=0.699, task_loss=4.568, task_loss_gen=7.149, contrastive_loss=0, total=4170.52, n_correct=2707.06, ppl=4.69, accuracy=64.909, wps=11580.8, ups=1.39, wpb=8341, bsz=311, num_updates=26900, lr=8.62261e-05, gnorm=0.506, clip=0, loss_scale=32, train_wall=71, gb_free=16, wall=23635
2023-09-02 02:25:43 | INFO | train_inner | epoch 019:    480 / 1474 loss=1.989, trans_loss=4.98, nll_loss=2.239, w2v_ctc_loss=0.707, task_loss=3.589, task_loss_gen=7.711, contrastive_loss=0, total=4113.89, n_correct=2667.31, ppl=4.72, accuracy=64.837, wps=11447.4, ups=1.39, wpb=8227.8, bsz=301.5, num_updates=27000, lr=8.60663e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=71, gb_free=16.9, wall=23707
2023-09-02 02:26:54 | INFO | train_inner | epoch 019:    580 / 1474 loss=1.986, trans_loss=4.978, nll_loss=2.237, w2v_ctc_loss=0.702, task_loss=4.576, task_loss_gen=6.823, contrastive_loss=0, total=4128.58, n_correct=2676.87, ppl=4.71, accuracy=64.838, wps=11523.3, ups=1.4, wpb=8257.2, bsz=306.2, num_updates=27100, lr=8.59074e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=71, gb_free=16.3, wall=23779
2023-09-02 02:28:06 | INFO | train_inner | epoch 019:    680 / 1474 loss=1.975, trans_loss=4.978, nll_loss=2.238, w2v_ctc_loss=0.684, task_loss=2.985, task_loss_gen=6.832, contrastive_loss=0, total=4201.56, n_correct=2732.75, ppl=4.72, accuracy=65.041, wps=11659.2, ups=1.39, wpb=8403.1, bsz=321.5, num_updates=27200, lr=8.57493e-05, gnorm=0.491, clip=0, loss_scale=32, train_wall=71, gb_free=17.5, wall=23851
2023-09-02 02:29:19 | INFO | train_inner | epoch 019:    780 / 1474 loss=1.991, trans_loss=4.979, nll_loss=2.238, w2v_ctc_loss=0.712, task_loss=3.325, task_loss_gen=8.17, contrastive_loss=0, total=4124.03, n_correct=2673.37, ppl=4.72, accuracy=64.824, wps=11374.6, ups=1.38, wpb=8248.1, bsz=299, num_updates=27300, lr=8.55921e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=72, gb_free=17.2, wall=23923
2023-09-02 02:30:31 | INFO | train_inner | epoch 019:    880 / 1474 loss=1.988, trans_loss=4.983, nll_loss=2.243, w2v_ctc_loss=0.705, task_loss=3.245, task_loss_gen=7.944, contrastive_loss=0, total=4177.8, n_correct=2709.15, ppl=4.73, accuracy=64.846, wps=11569.5, ups=1.38, wpb=8355.6, bsz=309.6, num_updates=27400, lr=8.54358e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=23996
2023-09-02 02:31:44 | INFO | train_inner | epoch 019:    980 / 1474 loss=1.992, trans_loss=4.991, nll_loss=2.254, w2v_ctc_loss=0.703, task_loss=4.025, task_loss_gen=7.569, contrastive_loss=0, total=4084.26, n_correct=2640.41, ppl=4.77, accuracy=64.648, wps=11169.1, ups=1.37, wpb=8168.5, bsz=305.8, num_updates=27500, lr=8.52803e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=72, gb_free=15.8, wall=24069
2023-09-02 02:32:56 | INFO | train_inner | epoch 019:   1080 / 1474 loss=1.99, trans_loss=4.987, nll_loss=2.248, w2v_ctc_loss=0.703, task_loss=3.196, task_loss_gen=8.968, contrastive_loss=0, total=4042.73, n_correct=2619.84, ppl=4.75, accuracy=64.804, wps=11278.5, ups=1.39, wpb=8085.5, bsz=294, num_updates=27600, lr=8.51257e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=71, gb_free=16.9, wall=24141
2023-09-02 02:34:09 | INFO | train_inner | epoch 019:   1180 / 1474 loss=1.988, trans_loss=4.981, nll_loss=2.242, w2v_ctc_loss=0.706, task_loss=2.244, task_loss_gen=9.551, contrastive_loss=0, total=4140.95, n_correct=2681.69, ppl=4.73, accuracy=64.76, wps=11366.4, ups=1.37, wpb=8281.9, bsz=307.9, num_updates=27700, lr=8.49719e-05, gnorm=0.502, clip=0, loss_scale=64, train_wall=72, gb_free=12.4, wall=24213
2023-09-02 02:35:21 | INFO | train_inner | epoch 019:   1280 / 1474 loss=1.987, trans_loss=4.983, nll_loss=2.245, w2v_ctc_loss=0.699, task_loss=2.276, task_loss_gen=9.54, contrastive_loss=0, total=4135.79, n_correct=2681.78, ppl=4.74, accuracy=64.843, wps=11525.5, ups=1.39, wpb=8271.6, bsz=299.5, num_updates=27800, lr=8.48189e-05, gnorm=0.499, clip=0, loss_scale=64, train_wall=71, gb_free=17.6, wall=24285
2023-09-02 02:36:33 | INFO | train_inner | epoch 019:   1380 / 1474 loss=1.988, trans_loss=4.979, nll_loss=2.239, w2v_ctc_loss=0.708, task_loss=1.813, task_loss_gen=10.273, contrastive_loss=0, total=4138.67, n_correct=2683.61, ppl=4.72, accuracy=64.842, wps=11413.4, ups=1.38, wpb=8277.3, bsz=301.6, num_updates=27900, lr=8.46668e-05, gnorm=0.502, clip=0, loss_scale=64, train_wall=72, gb_free=16.2, wall=24358
2023-09-02 02:37:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 02:38:14 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.911 | trans_loss 5.204 | nll_loss 2.477 | w2v_ctc_loss 1.308 | task_loss 10.956 | task_loss_gen 23.935 | contrastive_loss 0 | total 4003.4 | n_correct 2627.3 | ppl 5.57 | accuracy 65.627 | uer 17.758 | wer 19.47 | raw_wer 19.47 | bleu 20.99 | wps 1644.9 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 21.49
2023-09-02 02:38:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-09-02 02:38:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_20.9902.pt
2023-09-02 02:38:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_20.9902.pt
2023-09-02 02:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_20.9902.pt (epoch 19 @ 27994 updates, score 20.99) (writing took 8.457821122021414 seconds)
2023-09-02 02:38:23 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-09-02 02:38:23 | INFO | train | epoch 019 | loss 1.987 | trans_loss 4.98 | nll_loss 2.239 | w2v_ctc_loss 0.705 | task_loss 3.363 | task_loss_gen 8.193 | contrastive_loss 0 | total 4138.65 | n_correct 2684.08 | ppl 4.72 | accuracy 64.854 | wps 10954.4 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 27994 | lr 8.45245e-05 | gnorm 0.503 | clip 0 | loss_scale 64 | train_wall 1053 | gb_free 17.1 | wall 24468
2023-09-02 02:38:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 02:38:23 | INFO | fairseq.trainer | begin training epoch 20
2023-09-02 02:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 02:38:35 | INFO | train_inner | epoch 020:      6 / 1474 loss=1.984, trans_loss=4.972, nll_loss=2.23, w2v_ctc_loss=0.705, task_loss=2.012, task_loss_gen=10.18, contrastive_loss=0, total=4117.61, n_correct=2676.27, ppl=4.69, accuracy=64.996, wps=6754.1, ups=0.82, wpb=8235.2, bsz=303, num_updates=28000, lr=8.45154e-05, gnorm=0.503, clip=0, loss_scale=64, train_wall=71, gb_free=16.1, wall=24480
2023-09-02 02:38:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 02:39:08 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.918 | trans_loss 5.208 | nll_loss 2.481 | w2v_ctc_loss 1.322 | task_loss 12.271 | task_loss_gen 23.286 | contrastive_loss 0 | total 4003.4 | n_correct 2630.7 | ppl 5.58 | accuracy 65.712 | uer 17.668 | wer 19.406 | raw_wer 19.406 | bleu 21.08 | wps 1656.6 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 21.49
2023-09-02 02:39:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-09-02 02:39:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-09-02 02:39:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-09-02 02:39:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 21.08) (writing took 9.059029386990005 seconds)
2023-09-02 02:40:29 | INFO | train_inner | epoch 020:    106 / 1474 loss=1.968, trans_loss=4.951, nll_loss=2.203, w2v_ctc_loss=0.687, task_loss=1.864, task_loss_gen=10.12, contrastive_loss=0, total=4192.82, n_correct=2744.55, ppl=4.6, accuracy=65.458, wps=7358.8, ups=0.88, wpb=8385.6, bsz=312.8, num_updates=28100, lr=8.43649e-05, gnorm=0.49, clip=0, loss_scale=64, train_wall=71, gb_free=15.9, wall=24594
2023-09-02 02:41:42 | INFO | train_inner | epoch 020:    206 / 1474 loss=1.974, trans_loss=4.958, nll_loss=2.211, w2v_ctc_loss=0.691, task_loss=2.051, task_loss_gen=10.515, contrastive_loss=0, total=4155.9, n_correct=2713.02, ppl=4.63, accuracy=65.281, wps=11441.6, ups=1.38, wpb=8311.8, bsz=302.3, num_updates=28200, lr=8.42152e-05, gnorm=0.5, clip=0, loss_scale=64, train_wall=72, gb_free=11.3, wall=24666
2023-09-02 02:42:54 | INFO | train_inner | epoch 020:    306 / 1474 loss=1.964, trans_loss=4.95, nll_loss=2.201, w2v_ctc_loss=0.689, task_loss=2.506, task_loss_gen=8.64, contrastive_loss=0, total=4192.69, n_correct=2745.96, ppl=4.6, accuracy=65.494, wps=11658.7, ups=1.39, wpb=8385.4, bsz=327.6, num_updates=28300, lr=8.40663e-05, gnorm=0.494, clip=0, loss_scale=64, train_wall=71, gb_free=16.7, wall=24738
2023-09-02 02:44:06 | INFO | train_inner | epoch 020:    406 / 1474 loss=1.972, trans_loss=4.951, nll_loss=2.201, w2v_ctc_loss=0.693, task_loss=2.107, task_loss_gen=10.808, contrastive_loss=0, total=4116.96, n_correct=2699.16, ppl=4.6, accuracy=65.562, wps=11380.7, ups=1.38, wpb=8233.9, bsz=296.8, num_updates=28400, lr=8.39181e-05, gnorm=0.503, clip=0, loss_scale=64, train_wall=71, gb_free=12.3, wall=24811
2023-09-02 02:45:19 | INFO | train_inner | epoch 020:    506 / 1474 loss=1.976, trans_loss=4.964, nll_loss=2.22, w2v_ctc_loss=0.689, task_loss=2.391, task_loss_gen=10.048, contrastive_loss=0, total=4100.73, n_correct=2673.08, ppl=4.66, accuracy=65.185, wps=11305.1, ups=1.38, wpb=8201.5, bsz=298.4, num_updates=28500, lr=8.37708e-05, gnorm=0.502, clip=0, loss_scale=64, train_wall=72, gb_free=16, wall=24883
2023-09-02 02:46:30 | INFO | train_inner | epoch 020:    606 / 1474 loss=1.98, trans_loss=4.963, nll_loss=2.217, w2v_ctc_loss=0.698, task_loss=2.497, task_loss_gen=10.042, contrastive_loss=0, total=4101.99, n_correct=2672.54, ppl=4.65, accuracy=65.152, wps=11465.5, ups=1.4, wpb=8204, bsz=298.3, num_updates=28600, lr=8.36242e-05, gnorm=0.5, clip=0, loss_scale=64, train_wall=71, gb_free=13.2, wall=24955
2023-09-02 02:47:42 | INFO | train_inner | epoch 020:    706 / 1474 loss=1.983, trans_loss=4.967, nll_loss=2.222, w2v_ctc_loss=0.707, task_loss=3.067, task_loss_gen=9.903, contrastive_loss=0, total=4124.25, n_correct=2684.68, ppl=4.66, accuracy=65.095, wps=11472.1, ups=1.39, wpb=8248.5, bsz=297.2, num_updates=28700, lr=8.34784e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=71, gb_free=16.4, wall=25027
2023-09-02 02:48:54 | INFO | train_inner | epoch 020:    806 / 1474 loss=1.977, trans_loss=4.963, nll_loss=2.219, w2v_ctc_loss=0.699, task_loss=2.869, task_loss_gen=9.693, contrastive_loss=0, total=4153.23, n_correct=2707.49, ppl=4.66, accuracy=65.19, wps=11537.7, ups=1.39, wpb=8306.5, bsz=308.5, num_updates=28800, lr=8.33333e-05, gnorm=0.5, clip=0, loss_scale=64, train_wall=71, gb_free=17.4, wall=25099
2023-09-02 02:50:07 | INFO | train_inner | epoch 020:    906 / 1474 loss=1.982, trans_loss=4.971, nll_loss=2.229, w2v_ctc_loss=0.702, task_loss=2.17, task_loss_gen=9.453, contrastive_loss=0, total=4153.72, n_correct=2696.79, ppl=4.69, accuracy=64.925, wps=11352, ups=1.37, wpb=8307.4, bsz=320.7, num_updates=28900, lr=8.3189e-05, gnorm=0.504, clip=0, loss_scale=64, train_wall=72, gb_free=15.8, wall=25172
2023-09-02 02:51:21 | INFO | train_inner | epoch 020:   1006 / 1474 loss=1.974, trans_loss=4.963, nll_loss=2.217, w2v_ctc_loss=0.691, task_loss=2.161, task_loss_gen=10.512, contrastive_loss=0, total=4156.05, n_correct=2709.67, ppl=4.65, accuracy=65.198, wps=11337.1, ups=1.36, wpb=8312.1, bsz=305.3, num_updates=29000, lr=8.30455e-05, gnorm=0.496, clip=0, loss_scale=64, train_wall=73, gb_free=14.7, wall=25245
2023-09-02 02:52:33 | INFO | train_inner | epoch 020:   1106 / 1474 loss=1.98, trans_loss=4.967, nll_loss=2.223, w2v_ctc_loss=0.702, task_loss=2.3, task_loss_gen=9.716, contrastive_loss=0, total=4181.53, n_correct=2722.07, ppl=4.67, accuracy=65.097, wps=11610.5, ups=1.39, wpb=8363.1, bsz=320.2, num_updates=29100, lr=8.29027e-05, gnorm=0.502, clip=0, loss_scale=64, train_wall=71, gb_free=16.8, wall=25317
2023-09-02 02:53:45 | INFO | train_inner | epoch 020:   1206 / 1474 loss=1.983, trans_loss=4.956, nll_loss=2.209, w2v_ctc_loss=0.713, task_loss=2.403, task_loss_gen=11.643, contrastive_loss=0, total=4029.26, n_correct=2627.5, ppl=4.62, accuracy=65.21, wps=11150.7, ups=1.38, wpb=8058.5, bsz=282.4, num_updates=29200, lr=8.27606e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=71, gb_free=16.3, wall=25389
2023-09-02 02:54:58 | INFO | train_inner | epoch 020:   1306 / 1474 loss=1.979, trans_loss=4.966, nll_loss=2.221, w2v_ctc_loss=0.699, task_loss=2.488, task_loss_gen=10.329, contrastive_loss=0, total=4127.21, n_correct=2692.45, ppl=4.66, accuracy=65.237, wps=11348.8, ups=1.37, wpb=8254.4, bsz=299.9, num_updates=29300, lr=8.26192e-05, gnorm=0.497, clip=0, loss_scale=64, train_wall=72, gb_free=14.5, wall=25462
2023-09-02 02:56:10 | INFO | train_inner | epoch 020:   1406 / 1474 loss=1.982, trans_loss=4.966, nll_loss=2.222, w2v_ctc_loss=0.703, task_loss=1.875, task_loss_gen=11.482, contrastive_loss=0, total=4110.89, n_correct=2677.21, ppl=4.66, accuracy=65.125, wps=11368.3, ups=1.38, wpb=8221.8, bsz=291.6, num_updates=29400, lr=8.24786e-05, gnorm=0.508, clip=0, loss_scale=64, train_wall=72, gb_free=12.9, wall=25534
2023-09-02 02:56:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 02:57:32 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.896 | trans_loss 5.195 | nll_loss 2.465 | w2v_ctc_loss 1.279 | task_loss 16.784 | task_loss_gen 21.072 | contrastive_loss 0 | total 4003.4 | n_correct 2635.5 | ppl 5.52 | accuracy 65.832 | uer 17.503 | wer 19.354 | raw_wer 19.354 | bleu 21.41 | wps 1633.2 | wpb 4003.4 | bsz 141.8 | num_updates 29468 | best_bleu 21.49
2023-09-02 02:57:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29468 updates
2023-09-02 02:57:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4105.pt
2023-09-02 02:57:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4105.pt
2023-09-02 02:57:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4105.pt (epoch 20 @ 29468 updates, score 21.41) (writing took 7.720133876980981 seconds)
2023-09-02 02:57:40 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-09-02 02:57:40 | INFO | train | epoch 020 | loss 1.976 | trans_loss 4.961 | nll_loss 2.215 | w2v_ctc_loss 0.697 | task_loss 2.278 | task_loss_gen 10.209 | contrastive_loss 0 | total 4138.65 | n_correct 2699.79 | ppl 4.64 | accuracy 65.234 | wps 10545.8 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 29468 | lr 8.23834e-05 | gnorm 0.5 | clip 0 | loss_scale 64 | train_wall 1054 | gb_free 15.9 | wall 25625
2023-09-02 02:57:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 02:57:40 | INFO | fairseq.trainer | begin training epoch 21
2023-09-02 02:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 02:58:11 | INFO | train_inner | epoch 021:     32 / 1474 loss=1.971, trans_loss=4.959, nll_loss=2.213, w2v_ctc_loss=0.69, task_loss=1.291, task_loss_gen=11.074, contrastive_loss=0, total=4166.35, n_correct=2720.54, ppl=4.63, accuracy=65.298, wps=6859.1, ups=0.82, wpb=8332.7, bsz=319.4, num_updates=29500, lr=8.23387e-05, gnorm=0.492, clip=0, loss_scale=64, train_wall=71, gb_free=10.7, wall=25656
2023-09-02 02:58:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-09-02 02:59:24 | INFO | train_inner | epoch 021:    133 / 1474 loss=1.96, trans_loss=4.938, nll_loss=2.185, w2v_ctc_loss=0.681, task_loss=1.463, task_loss_gen=11.069, contrastive_loss=0, total=4179.97, n_correct=2744.32, ppl=4.55, accuracy=65.654, wps=11491.7, ups=1.37, wpb=8359.9, bsz=317.6, num_updates=29600, lr=8.21995e-05, gnorm=0.494, clip=0, loss_scale=64, train_wall=72, gb_free=12.6, wall=25729
2023-09-02 03:00:36 | INFO | train_inner | epoch 021:    233 / 1474 loss=1.961, trans_loss=4.944, nll_loss=2.194, w2v_ctc_loss=0.678, task_loss=2.014, task_loss_gen=10.863, contrastive_loss=0, total=4166.37, n_correct=2733.44, ppl=4.57, accuracy=65.607, wps=11632.7, ups=1.4, wpb=8332.7, bsz=315.2, num_updates=29700, lr=8.2061e-05, gnorm=0.501, clip=0, loss_scale=64, train_wall=71, gb_free=13.7, wall=25800
2023-09-02 03:01:49 | INFO | train_inner | epoch 021:    333 / 1474 loss=1.97, trans_loss=4.948, nll_loss=2.198, w2v_ctc_loss=0.694, task_loss=3.705, task_loss_gen=9.417, contrastive_loss=0, total=4132.25, n_correct=2704.79, ppl=4.59, accuracy=65.456, wps=11299.3, ups=1.37, wpb=8264.5, bsz=305, num_updates=29800, lr=8.19232e-05, gnorm=0.499, clip=0, loss_scale=64, train_wall=72, gb_free=16.3, wall=25873
2023-09-02 03:02:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-02 03:03:01 | INFO | train_inner | epoch 021:    434 / 1474 loss=1.961, trans_loss=4.942, nll_loss=2.19, w2v_ctc_loss=0.68, task_loss=2.862, task_loss_gen=9.321, contrastive_loss=0, total=4195.82, n_correct=2757.42, ppl=4.56, accuracy=65.718, wps=11609.5, ups=1.38, wpb=8391.6, bsz=311.7, num_updates=29900, lr=8.17861e-05, gnorm=0.503, clip=0, loss_scale=32, train_wall=71, gb_free=15.5, wall=25946
2023-09-02 03:04:13 | INFO | train_inner | epoch 021:    534 / 1474 loss=1.971, trans_loss=4.947, nll_loss=2.197, w2v_ctc_loss=0.694, task_loss=5.319, task_loss_gen=8.432, contrastive_loss=0, total=4083.98, n_correct=2675.09, ppl=4.58, accuracy=65.502, wps=11300.6, ups=1.38, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=72, gb_free=12.6, wall=26018
2023-09-02 03:04:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 03:04:46 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.92 | trans_loss 5.226 | nll_loss 2.508 | w2v_ctc_loss 1.289 | task_loss 24.54 | task_loss_gen 21.94 | contrastive_loss 0 | total 4003.4 | n_correct 2622.3 | ppl 5.69 | accuracy 65.502 | uer 17.617 | wer 19.429 | raw_wer 19.429 | bleu 21.05 | wps 1627.6 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 21.49
2023-09-02 03:04:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-09-02 03:04:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-09-02 03:04:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-09-02 03:04:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 21.05) (writing took 9.055904776992975 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:0')
2023-09-02 03:06:09 | INFO | train_inner | epoch 021:    634 / 1474 loss=1.968, trans_loss=4.949, nll_loss=2.199, w2v_ctc_loss=0.684, task_loss=6.371, task_loss_gen=7.6, contrastive_loss=0, total=4215.41, n_correct=2761.51, ppl=4.59, accuracy=65.51, wps=7311.4, ups=0.87, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.509, clip=0, loss_scale=32, train_wall=72, gb_free=10.9, wall=26133
2023-09-02 03:07:21 | INFO | train_inner | epoch 021:    734 / 1474 loss=1.972, trans_loss=4.958, nll_loss=2.212, w2v_ctc_loss=0.689, task_loss=7.44, task_loss_gen=7.913, contrastive_loss=0, total=4152.97, n_correct=2714.24, ppl=4.63, accuracy=65.357, wps=11539.3, ups=1.39, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.504, clip=0, loss_scale=32, train_wall=71, gb_free=16, wall=26205
2023-09-02 03:08:33 | INFO | train_inner | epoch 021:    834 / 1474 loss=1.977, trans_loss=4.962, nll_loss=2.217, w2v_ctc_loss=0.693, task_loss=8.498, task_loss_gen=8.247, contrastive_loss=0, total=4066.93, n_correct=2654.4, ppl=4.65, accuracy=65.268, wps=11198, ups=1.38, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=72, gb_free=16.6, wall=26278
2023-09-02 03:09:45 | INFO | train_inner | epoch 021:    934 / 1474 loss=1.969, trans_loss=4.95, nll_loss=2.2, w2v_ctc_loss=0.69, task_loss=7.991, task_loss_gen=7.465, contrastive_loss=0, total=4103.34, n_correct=2685.33, ppl=4.6, accuracy=65.443, wps=11461.9, ups=1.4, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=26350
2023-09-02 03:10:57 | INFO | train_inner | epoch 021:   1034 / 1474 loss=1.975, trans_loss=4.961, nll_loss=2.215, w2v_ctc_loss=0.695, task_loss=5.846, task_loss_gen=7.251, contrastive_loss=0, total=4099.86, n_correct=2676.25, ppl=4.64, accuracy=65.277, wps=11382.6, ups=1.39, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=71, gb_free=10.9, wall=26422
2023-09-02 03:12:09 | INFO | train_inner | epoch 021:   1134 / 1474 loss=1.972, trans_loss=4.947, nll_loss=2.197, w2v_ctc_loss=0.693, task_loss=6.451, task_loss_gen=7.52, contrastive_loss=0, total=4120.75, n_correct=2702.55, ppl=4.58, accuracy=65.584, wps=11415.4, ups=1.39, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=71, gb_free=15.5, wall=26494
2023-09-02 03:13:21 | INFO | train_inner | epoch 021:   1234 / 1474 loss=1.965, trans_loss=4.949, nll_loss=2.2, w2v_ctc_loss=0.683, task_loss=5.365, task_loss_gen=6.533, contrastive_loss=0, total=4154.73, n_correct=2722.76, ppl=4.6, accuracy=65.534, wps=11634.9, ups=1.4, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.5, clip=0, loss_scale=32, train_wall=71, gb_free=12.2, wall=26565
2023-09-02 03:14:33 | INFO | train_inner | epoch 021:   1334 / 1474 loss=1.966, trans_loss=4.948, nll_loss=2.198, w2v_ctc_loss=0.687, task_loss=5.097, task_loss_gen=6.661, contrastive_loss=0, total=4147.17, n_correct=2721.57, ppl=4.59, accuracy=65.625, wps=11425.6, ups=1.38, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.496, clip=0, loss_scale=32, train_wall=72, gb_free=15.9, wall=26638
2023-09-02 03:15:46 | INFO | train_inner | epoch 021:   1434 / 1474 loss=1.982, trans_loss=4.96, nll_loss=2.214, w2v_ctc_loss=0.711, task_loss=5.311, task_loss_gen=7.024, contrastive_loss=0, total=4133.93, n_correct=2692.98, ppl=4.64, accuracy=65.143, wps=11318.7, ups=1.37, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=72, gb_free=15.2, wall=26711
2023-09-02 03:16:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:1')
2023-09-02 03:16:48 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.906 | trans_loss 5.205 | nll_loss 2.474 | w2v_ctc_loss 1.291 | task_loss 18.301 | task_loss_gen 19.099 | contrastive_loss 0 | total 4003.4 | n_correct 2638.1 | ppl 5.56 | accuracy 65.896 | uer 17.49 | wer 19.362 | raw_wer 19.362 | bleu 21.46 | wps 1645.2 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 21.49
2023-09-02 03:16:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-09-02 03:16:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4604.pt
2023-09-02 03:16:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4604.pt
2023-09-02 03:16:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4604.pt (epoch 21 @ 30940 updates, score 21.46) (writing took 8.679044901015004 seconds)
2023-09-02 03:16:57 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-09-02 03:16:57 | INFO | train | epoch 021 | loss 1.969 | trans_loss 4.95 | nll_loss 2.201 | w2v_ctc_loss 0.689 | task_loss 5.157 | task_loss_gen 8.286 | contrastive_loss 0 | total 4138.83 | n_correct 2710.11 | ppl 4.6 | accuracy 65.48 | wps 10531.3 | ups 1.27 | wpb 8277.7 | bsz 305.8 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.506 | clip 0 | loss_scale 32 | train_wall 1054 | gb_free 15.1 | wall 26782
2023-09-02 03:16:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 03:16:57 | INFO | fairseq.trainer | begin training epoch 22
2023-09-02 03:16:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 03:17:48 | INFO | train_inner | epoch 022:     60 / 1474 loss=1.96, trans_loss=4.931, nll_loss=2.177, w2v_ctc_loss=0.684, task_loss=5.303, task_loss_gen=7.005, contrastive_loss=0, total=4128.84, n_correct=2723.76, ppl=4.52, accuracy=65.969, wps=6801.4, ups=0.82, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=26832
2023-09-02 03:19:01 | INFO | train_inner | epoch 022:    160 / 1474 loss=1.956, trans_loss=4.927, nll_loss=2.172, w2v_ctc_loss=0.68, task_loss=4.539, task_loss_gen=7.046, contrastive_loss=0, total=4123.35, n_correct=2718.41, ppl=4.51, accuracy=65.927, wps=11328.9, ups=1.37, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.5, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=26905
2023-09-02 03:20:12 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.943, trans_loss=4.92, nll_loss=2.163, w2v_ctc_loss=0.663, task_loss=3.273, task_loss_gen=6.299, contrastive_loss=0, total=4267.16, n_correct=2829.3, ppl=4.48, accuracy=66.304, wps=11869.4, ups=1.39, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.485, clip=0, loss_scale=32, train_wall=71, gb_free=16.4, wall=26977
2023-09-02 03:21:26 | INFO | train_inner | epoch 022:    360 / 1474 loss=1.965, trans_loss=4.937, nll_loss=2.185, w2v_ctc_loss=0.688, task_loss=4.518, task_loss_gen=7.038, contrastive_loss=0, total=4180.09, n_correct=2743.9, ppl=4.55, accuracy=65.642, wps=11360.9, ups=1.36, wpb=8360.2, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=73, gb_free=17.2, wall=27051
2023-09-02 03:22:38 | INFO | train_inner | epoch 022:    460 / 1474 loss=1.965, trans_loss=4.936, nll_loss=2.183, w2v_ctc_loss=0.688, task_loss=4.098, task_loss_gen=7.56, contrastive_loss=0, total=4132.62, n_correct=2715.78, ppl=4.54, accuracy=65.716, wps=11420.9, ups=1.38, wpb=8265.2, bsz=297.2, num_updates=31400, lr=7.98087e-05, gnorm=0.503, clip=0, loss_scale=32, train_wall=72, gb_free=16.2, wall=27123
2023-09-02 03:23:52 | INFO | train_inner | epoch 022:    560 / 1474 loss=1.955, trans_loss=4.927, nll_loss=2.171, w2v_ctc_loss=0.679, task_loss=4.28, task_loss_gen=7.107, contrastive_loss=0, total=4155.5, n_correct=2742.6, ppl=4.5, accuracy=65.999, wps=11303.9, ups=1.36, wpb=8311, bsz=307.3, num_updates=31500, lr=7.96819e-05, gnorm=0.497, clip=0, loss_scale=32, train_wall=73, gb_free=16.1, wall=27197
2023-09-02 03:25:03 | INFO | train_inner | epoch 022:    660 / 1474 loss=1.949, trans_loss=4.923, nll_loss=2.167, w2v_ctc_loss=0.667, task_loss=3.468, task_loss_gen=7.092, contrastive_loss=0, total=4147.84, n_correct=2741.58, ppl=4.49, accuracy=66.097, wps=11625.1, ups=1.4, wpb=8295.7, bsz=313.1, num_updates=31600, lr=7.95557e-05, gnorm=0.496, clip=0, loss_scale=32, train_wall=71, gb_free=12.6, wall=27268
2023-09-02 03:26:16 | INFO | train_inner | epoch 022:    760 / 1474 loss=1.96, trans_loss=4.93, nll_loss=2.175, w2v_ctc_loss=0.684, task_loss=3.555, task_loss_gen=7.716, contrastive_loss=0, total=4166.89, n_correct=2743.93, ppl=4.52, accuracy=65.851, wps=11539.8, ups=1.38, wpb=8333.8, bsz=304.3, num_updates=31700, lr=7.94301e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=71, gb_free=15.6, wall=27340
2023-09-02 03:27:29 | INFO | train_inner | epoch 022:    860 / 1474 loss=1.965, trans_loss=4.942, nll_loss=2.191, w2v_ctc_loss=0.682, task_loss=4.662, task_loss_gen=7.91, contrastive_loss=0, total=4074.75, n_correct=2671.1, ppl=4.57, accuracy=65.552, wps=11150.5, ups=1.37, wpb=8149.5, bsz=288.4, num_updates=31800, lr=7.93052e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=72, gb_free=17.2, wall=27413
2023-09-02 03:28:41 | INFO | train_inner | epoch 022:    960 / 1474 loss=1.954, trans_loss=4.929, nll_loss=2.174, w2v_ctc_loss=0.673, task_loss=4.596, task_loss_gen=7.272, contrastive_loss=0, total=4136.34, n_correct=2729.84, ppl=4.51, accuracy=65.997, wps=11439.7, ups=1.38, wpb=8272.7, bsz=303.7, num_updates=31900, lr=7.91808e-05, gnorm=0.505, clip=0, loss_scale=64, train_wall=72, gb_free=16.3, wall=27486
2023-09-02 03:29:53 | INFO | train_inner | epoch 022:   1060 / 1474 loss=1.947, trans_loss=4.921, nll_loss=2.165, w2v_ctc_loss=0.665, task_loss=3.126, task_loss_gen=7.494, contrastive_loss=0, total=4157.21, n_correct=2748.66, ppl=4.49, accuracy=66.118, wps=11574.1, ups=1.39, wpb=8314.4, bsz=315.4, num_updates=32000, lr=7.90569e-05, gnorm=0.494, clip=0, loss_scale=64, train_wall=71, gb_free=11.7, wall=27557
2023-09-02 03:29:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 03:30:25 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.9 | trans_loss 5.199 | nll_loss 2.471 | w2v_ctc_loss 1.282 | task_loss 10.152 | task_loss_gen 22.281 | contrastive_loss 0 | total 4003.4 | n_correct 2639.2 | ppl 5.55 | accuracy 65.924 | uer 17.381 | wer 18.974 | raw_wer 18.974 | bleu 21.46 | wps 1664.3 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 21.49
2023-09-02 03:30:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-09-02 03:30:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-09-02 03:30:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-09-02 03:30:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 21.46) (writing took 9.838183589017717 seconds)
2023-09-02 03:31:47 | INFO | train_inner | epoch 022:   1160 / 1474 loss=1.97, trans_loss=4.948, nll_loss=2.199, w2v_ctc_loss=0.693, task_loss=2.333, task_loss_gen=9.717, contrastive_loss=0, total=4092.91, n_correct=2681.86, ppl=4.59, accuracy=65.525, wps=7176.2, ups=0.88, wpb=8185.8, bsz=294.3, num_updates=32100, lr=7.89337e-05, gnorm=0.508, clip=0, loss_scale=64, train_wall=71, gb_free=15.7, wall=27671
2023-09-02 03:32:59 | INFO | train_inner | epoch 022:   1260 / 1474 loss=1.956, trans_loss=4.939, nll_loss=2.189, w2v_ctc_loss=0.681, task_loss=1.83, task_loss_gen=9.11, contrastive_loss=0, total=4182.65, n_correct=2751.09, ppl=4.56, accuracy=65.774, wps=11613.4, ups=1.39, wpb=8365.3, bsz=323.6, num_updates=32200, lr=7.8811e-05, gnorm=0.494, clip=0, loss_scale=64, train_wall=71, gb_free=16, wall=27743
2023-09-02 03:34:10 | INFO | train_inner | epoch 022:   1360 / 1474 loss=1.953, trans_loss=4.925, nll_loss=2.17, w2v_ctc_loss=0.673, task_loss=2.059, task_loss_gen=9.967, contrastive_loss=0, total=4071.58, n_correct=2688.71, ppl=4.5, accuracy=66.036, wps=11435.3, ups=1.4, wpb=8143.2, bsz=300.6, num_updates=32300, lr=7.86889e-05, gnorm=0.504, clip=0, loss_scale=64, train_wall=71, gb_free=16.4, wall=27815
2023-09-02 03:35:22 | INFO | train_inner | epoch 022:   1460 / 1474 loss=1.964, trans_loss=4.939, nll_loss=2.187, w2v_ctc_loss=0.687, task_loss=2.194, task_loss_gen=10.821, contrastive_loss=0, total=4077.83, n_correct=2681.82, ppl=4.55, accuracy=65.766, wps=11278.1, ups=1.38, wpb=8155.7, bsz=288, num_updates=32400, lr=7.85674e-05, gnorm=0.504, clip=0, loss_scale=64, train_wall=72, gb_free=15.8, wall=27887
2023-09-02 03:35:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 03:36:06 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.896 | trans_loss 5.188 | nll_loss 2.459 | w2v_ctc_loss 1.295 | task_loss 11.555 | task_loss_gen 26.24 | contrastive_loss 0 | total 4003.4 | n_correct 2642.4 | ppl 5.5 | accuracy 66.004 | uer 17.471 | wer 19.16 | raw_wer 19.16 | bleu 21.3 | wps 1649.6 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 21.49
2023-09-02 03:36:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-09-02 03:36:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.3006.pt
2023-09-02 03:36:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.3006.pt
2023-09-02 03:36:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.3006.pt (epoch 22 @ 32414 updates, score 21.3) (writing took 7.546230331994593 seconds)
2023-09-02 03:36:14 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-09-02 03:36:14 | INFO | train | epoch 022 | loss 1.957 | trans_loss 4.931 | nll_loss 2.177 | w2v_ctc_loss 0.679 | task_loss 3.525 | task_loss_gen 7.977 | contrastive_loss 0 | total 4138.65 | n_correct 2726.93 | ppl 4.52 | accuracy 65.889 | wps 10549.5 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.501 | clip 0 | loss_scale 64 | train_wall 1054 | gb_free 11.3 | wall 27938
2023-09-02 03:36:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 03:36:14 | INFO | fairseq.trainer | begin training epoch 23
2023-09-02 03:36:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 03:36:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-02 03:37:25 | INFO | train_inner | epoch 023:     87 / 1474 loss=1.952, trans_loss=4.916, nll_loss=2.157, w2v_ctc_loss=0.68, task_loss=2.378, task_loss_gen=10.393, contrastive_loss=0, total=4099.63, n_correct=2713.4, ppl=4.46, accuracy=66.186, wps=6694.3, ups=0.82, wpb=8199.3, bsz=301.8, num_updates=32500, lr=7.84465e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=73, gb_free=16.1, wall=28009
2023-09-02 03:38:37 | INFO | train_inner | epoch 023:    187 / 1474 loss=1.95, trans_loss=4.911, nll_loss=2.151, w2v_ctc_loss=0.672, task_loss=6.462, task_loss_gen=8.468, contrastive_loss=0, total=4107.77, n_correct=2720.36, ppl=4.44, accuracy=66.225, wps=11372.3, ups=1.38, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.504, clip=0, loss_scale=32, train_wall=72, gb_free=16.1, wall=28082
2023-09-02 03:39:50 | INFO | train_inner | epoch 023:    287 / 1474 loss=1.952, trans_loss=4.926, nll_loss=2.17, w2v_ctc_loss=0.668, task_loss=5.233, task_loss_gen=7.829, contrastive_loss=0, total=4153.12, n_correct=2739.36, ppl=4.5, accuracy=65.959, wps=11428.8, ups=1.38, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.503, clip=0, loss_scale=32, train_wall=72, gb_free=16.7, wall=28154
2023-09-02 03:41:02 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.947, trans_loss=4.912, nll_loss=2.152, w2v_ctc_loss=0.665, task_loss=8.499, task_loss_gen=8.04, contrastive_loss=0, total=4116.7, n_correct=2734.08, ppl=4.44, accuracy=66.414, wps=11433.8, ups=1.39, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=71, gb_free=14.9, wall=28226
2023-09-02 03:42:14 | INFO | train_inner | epoch 023:    487 / 1474 loss=1.945, trans_loss=4.917, nll_loss=2.159, w2v_ctc_loss=0.665, task_loss=5.925, task_loss_gen=6.967, contrastive_loss=0, total=4157.6, n_correct=2754.6, ppl=4.47, accuracy=66.255, wps=11542.8, ups=1.39, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=71, gb_free=17, wall=28298
2023-09-02 03:43:26 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.942, trans_loss=4.91, nll_loss=2.15, w2v_ctc_loss=0.665, task_loss=5.46, task_loss_gen=7.026, contrastive_loss=0, total=4173.42, n_correct=2769.44, ppl=4.44, accuracy=66.359, wps=11615.2, ups=1.39, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.5, clip=0, loss_scale=32, train_wall=71, gb_free=12.3, wall=28370
2023-09-02 03:44:38 | INFO | train_inner | epoch 023:    687 / 1474 loss=1.955, trans_loss=4.923, nll_loss=2.167, w2v_ctc_loss=0.68, task_loss=6.956, task_loss_gen=7.179, contrastive_loss=0, total=4137.82, n_correct=2731.76, ppl=4.49, accuracy=66.019, wps=11524.7, ups=1.39, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.506, clip=0, loss_scale=32, train_wall=71, gb_free=16.8, wall=28442
2023-09-02 03:45:50 | INFO | train_inner | epoch 023:    787 / 1474 loss=1.953, trans_loss=4.922, nll_loss=2.165, w2v_ctc_loss=0.677, task_loss=7.294, task_loss_gen=7.456, contrastive_loss=0, total=4150.99, n_correct=2743.2, ppl=4.48, accuracy=66.085, wps=11488.6, ups=1.38, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.504, clip=0, loss_scale=32, train_wall=71, gb_free=16, wall=28514
2023-09-02 03:47:02 | INFO | train_inner | epoch 023:    887 / 1474 loss=1.944, trans_loss=4.914, nll_loss=2.155, w2v_ctc_loss=0.67, task_loss=6.689, task_loss_gen=6.562, contrastive_loss=0, total=4181.99, n_correct=2771.47, ppl=4.45, accuracy=66.272, wps=11647.9, ups=1.39, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.491, clip=0, loss_scale=32, train_wall=71, gb_free=16.2, wall=28586
2023-09-02 03:48:14 | INFO | train_inner | epoch 023:    987 / 1474 loss=1.951, trans_loss=4.92, nll_loss=2.163, w2v_ctc_loss=0.672, task_loss=5.808, task_loss_gen=6.729, contrastive_loss=0, total=4168.73, n_correct=2751.8, ppl=4.48, accuracy=66.011, wps=11501.2, ups=1.38, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=72, gb_free=10.4, wall=28659
2023-09-02 03:49:27 | INFO | train_inner | epoch 023:   1087 / 1474 loss=1.956, trans_loss=4.923, nll_loss=2.167, w2v_ctc_loss=0.679, task_loss=5.544, task_loss_gen=7.357, contrastive_loss=0, total=4088.49, n_correct=2701.08, ppl=4.49, accuracy=66.065, wps=11208.1, ups=1.37, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.499, clip=0, loss_scale=32, train_wall=72, gb_free=15.6, wall=28732
2023-09-02 03:50:40 | INFO | train_inner | epoch 023:   1187 / 1474 loss=1.952, trans_loss=4.925, nll_loss=2.17, w2v_ctc_loss=0.678, task_loss=4.812, task_loss_gen=6.83, contrastive_loss=0, total=4162.7, n_correct=2749.77, ppl=4.5, accuracy=66.057, wps=11472, ups=1.38, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=72, gb_free=15.8, wall=28804
2023-09-02 03:51:52 | INFO | train_inner | epoch 023:   1287 / 1474 loss=1.944, trans_loss=4.917, nll_loss=2.159, w2v_ctc_loss=0.666, task_loss=3.507, task_loss_gen=6.96, contrastive_loss=0, total=4135.53, n_correct=2740.02, ppl=4.47, accuracy=66.256, wps=11499.6, ups=1.39, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.499, clip=0, loss_scale=32, train_wall=71, gb_free=16.5, wall=28876
2023-09-02 03:53:04 | INFO | train_inner | epoch 023:   1387 / 1474 loss=1.958, trans_loss=4.933, nll_loss=2.18, w2v_ctc_loss=0.679, task_loss=4.576, task_loss_gen=7.079, contrastive_loss=0, total=4143.98, n_correct=2728.84, ppl=4.53, accuracy=65.851, wps=11480.6, ups=1.39, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.498, clip=0, loss_scale=32, train_wall=71, gb_free=15.6, wall=28948
2023-09-02 03:54:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 03:54:40 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.908 | trans_loss 5.187 | nll_loss 2.451 | w2v_ctc_loss 1.338 | task_loss 9.174 | task_loss_gen 20.847 | contrastive_loss 0 | total 4003.4 | n_correct 2642.7 | ppl 5.47 | accuracy 66.011 | uer 17.681 | wer 19.477 | raw_wer 19.477 | bleu 21.46 | wps 1623.4 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 21.49
2023-09-02 03:54:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-09-02 03:54:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4609.pt
2023-09-02 03:54:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4609.pt
2023-09-02 03:54:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.4609.pt (epoch 23 @ 33887 updates, score 21.46) (writing took 7.771838602988282 seconds)
2023-09-02 03:54:48 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-09-02 03:54:48 | INFO | train | epoch 023 | loss 1.95 | trans_loss 4.92 | nll_loss 2.163 | w2v_ctc_loss 0.672 | task_loss 5.612 | task_loss_gen 7.418 | contrastive_loss 0 | total 4138.89 | n_correct 2737.1 | ppl 4.48 | accuracy 66.131 | wps 10942.7 | ups 1.32 | wpb 8277.8 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.503 | clip 0 | loss_scale 32 | train_wall 1054 | gb_free 13.3 | wall 29052
2023-09-02 03:54:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 03:54:48 | INFO | fairseq.trainer | begin training epoch 24
2023-09-02 03:54:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 03:55:06 | INFO | train_inner | epoch 024:     13 / 1474 loss=1.954, trans_loss=4.93, nll_loss=2.176, w2v_ctc_loss=0.67, task_loss=4.388, task_loss_gen=6.963, contrastive_loss=0, total=4085.11, n_correct=2692.7, ppl=4.52, accuracy=65.915, wps=6698.1, ups=0.82, wpb=8170.2, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.502, clip=0, loss_scale=32, train_wall=72, gb_free=12.2, wall=29070
2023-09-02 03:56:18 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.933, trans_loss=4.896, nll_loss=2.132, w2v_ctc_loss=0.658, task_loss=3.114, task_loss_gen=6.888, contrastive_loss=0, total=4171.44, n_correct=2776.64, ppl=4.38, accuracy=66.563, wps=11541.3, ups=1.38, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.494, clip=0, loss_scale=32, train_wall=71, gb_free=16.1, wall=29143
2023-09-02 03:56:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 03:56:51 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.921 | trans_loss 5.191 | nll_loss 2.458 | w2v_ctc_loss 1.372 | task_loss 9.34 | task_loss_gen 22.118 | contrastive_loss 0 | total 4003.4 | n_correct 2641.1 | ppl 5.49 | accuracy 65.971 | uer 17.678 | wer 19.365 | raw_wer 19.365 | bleu 21.53 | wps 1655.2 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 21.53
2023-09-02 03:56:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-09-02 03:56:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-09-02 03:56:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-09-02 03:57:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 21.53) (writing took 14.172669563995441 seconds)
2023-09-02 03:58:18 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.929, trans_loss=4.899, nll_loss=2.137, w2v_ctc_loss=0.647, task_loss=2.882, task_loss_gen=6.781, contrastive_loss=0, total=4251.29, n_correct=2831.52, ppl=4.4, accuracy=66.604, wps=7120.9, ups=0.84, wpb=8502.6, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.488, clip=0, loss_scale=32, train_wall=71, gb_free=16.4, wall=29262
2023-09-02 03:59:29 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.935, trans_loss=4.898, nll_loss=2.134, w2v_ctc_loss=0.658, task_loss=3.245, task_loss_gen=7.486, contrastive_loss=0, total=4128.18, n_correct=2748.28, ppl=4.39, accuracy=66.574, wps=11472.6, ups=1.39, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.5, clip=0, loss_scale=32, train_wall=71, gb_free=15.9, wall=29334
2023-09-02 04:00:42 | INFO | train_inner | epoch 024:    413 / 1474 loss=1.952, trans_loss=4.907, nll_loss=2.146, w2v_ctc_loss=0.679, task_loss=4.29, task_loss_gen=7.955, contrastive_loss=0, total=4158.92, n_correct=2751.99, ppl=4.43, accuracy=66.171, wps=11511.5, ups=1.38, wpb=8317.8, bsz=299.7, num_updates=34300, lr=7.63604e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=72, gb_free=16.3, wall=29406
2023-09-02 04:01:55 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.942, trans_loss=4.902, nll_loss=2.14, w2v_ctc_loss=0.667, task_loss=4.394, task_loss_gen=7.516, contrastive_loss=0, total=4144.91, n_correct=2754.66, ppl=4.41, accuracy=66.459, wps=11377.1, ups=1.37, wpb=8289.8, bsz=303.3, num_updates=34400, lr=7.62493e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=72, gb_free=16.7, wall=29479
2023-09-02 04:03:07 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.937, trans_loss=4.902, nll_loss=2.14, w2v_ctc_loss=0.656, task_loss=5.378, task_loss_gen=7.304, contrastive_loss=0, total=4165.3, n_correct=2768.31, ppl=4.41, accuracy=66.461, wps=11565.3, ups=1.39, wpb=8330.6, bsz=307.7, num_updates=34500, lr=7.61387e-05, gnorm=0.496, clip=0, loss_scale=32, train_wall=71, gb_free=15.3, wall=29551
2023-09-02 04:04:19 | INFO | train_inner | epoch 024:    713 / 1474 loss=1.945, trans_loss=4.911, nll_loss=2.15, w2v_ctc_loss=0.666, task_loss=4.831, task_loss_gen=7.595, contrastive_loss=0, total=4102.21, n_correct=2719.9, ppl=4.44, accuracy=66.303, wps=11350.9, ups=1.38, wpb=8204.4, bsz=295.1, num_updates=34600, lr=7.60286e-05, gnorm=0.501, clip=0, loss_scale=64, train_wall=72, gb_free=16.6, wall=29623
2023-09-02 04:05:31 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.939, trans_loss=4.908, nll_loss=2.149, w2v_ctc_loss=0.659, task_loss=2.866, task_loss_gen=8.078, contrastive_loss=0, total=4110.6, n_correct=2731.73, ppl=4.43, accuracy=66.456, wps=11361.3, ups=1.38, wpb=8221.2, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.504, clip=0, loss_scale=64, train_wall=72, gb_free=16.2, wall=29696
2023-09-02 04:06:43 | INFO | train_inner | epoch 024:    913 / 1474 loss=1.95, trans_loss=4.909, nll_loss=2.148, w2v_ctc_loss=0.676, task_loss=2.514, task_loss_gen=9.865, contrastive_loss=0, total=4043.03, n_correct=2679.54, ppl=4.43, accuracy=66.276, wps=11241.3, ups=1.39, wpb=8086.1, bsz=281, num_updates=34800, lr=7.58098e-05, gnorm=0.508, clip=0, loss_scale=64, train_wall=71, gb_free=10.8, wall=29768
2023-09-02 04:07:56 | INFO | train_inner | epoch 024:   1013 / 1474 loss=1.942, trans_loss=4.909, nll_loss=2.148, w2v_ctc_loss=0.662, task_loss=2.235, task_loss_gen=9.66, contrastive_loss=0, total=4136.81, n_correct=2749.69, ppl=4.43, accuracy=66.469, wps=11440.3, ups=1.38, wpb=8273.6, bsz=298.4, num_updates=34900, lr=7.57011e-05, gnorm=0.501, clip=0, loss_scale=64, train_wall=71, gb_free=16.6, wall=29840
2023-09-02 04:09:08 | INFO | train_inner | epoch 024:   1113 / 1474 loss=1.937, trans_loss=4.893, nll_loss=2.129, w2v_ctc_loss=0.668, task_loss=2.057, task_loss_gen=9.52, contrastive_loss=0, total=4135.73, n_correct=2754.99, ppl=4.37, accuracy=66.614, wps=11438.9, ups=1.38, wpb=8271.5, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.496, clip=0, loss_scale=64, train_wall=71, gb_free=16.7, wall=29912
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:0')
2023-09-02 04:10:20 | INFO | train_inner | epoch 024:   1213 / 1474 loss=1.938, trans_loss=4.905, nll_loss=2.144, w2v_ctc_loss=0.66, task_loss=2.175, task_loss_gen=9.946, contrastive_loss=0, total=4148.3, n_correct=2755.7, ppl=4.42, accuracy=66.43, wps=11483.9, ups=1.38, wpb=8296.6, bsz=310.8, num_updates=35100, lr=7.54851e-05, gnorm=0.502, clip=0, loss_scale=64, train_wall=72, gb_free=16.3, wall=29985
2023-09-02 04:11:33 | INFO | train_inner | epoch 024:   1313 / 1474 loss=1.948, trans_loss=4.91, nll_loss=2.149, w2v_ctc_loss=0.674, task_loss=2.53, task_loss_gen=10.366, contrastive_loss=0, total=4110.05, n_correct=2726.2, ppl=4.44, accuracy=66.33, wps=11341.1, ups=1.38, wpb=8220.1, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=72, gb_free=16.9, wall=30057
2023-09-02 04:12:45 | INFO | train_inner | epoch 024:   1413 / 1474 loss=1.945, trans_loss=4.907, nll_loss=2.147, w2v_ctc_loss=0.672, task_loss=2.13, task_loss_gen=10.443, contrastive_loss=0, total=4090.91, n_correct=2721.34, ppl=4.43, accuracy=66.522, wps=11353.3, ups=1.39, wpb=8181.8, bsz=292.7, num_updates=35300, lr=7.5271e-05, gnorm=0.504, clip=0, loss_scale=64, train_wall=71, gb_free=15.8, wall=30129
2023-09-02 04:13:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:3')
2023-09-02 04:14:01 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.903 | trans_loss 5.178 | nll_loss 2.445 | w2v_ctc_loss 1.339 | task_loss 7.022 | task_loss_gen 30.876 | contrastive_loss 0 | total 4003.4 | n_correct 2650.2 | ppl 5.45 | accuracy 66.199 | uer 17.219 | wer 18.899 | raw_wer 18.899 | bleu 21.85 | wps 1646.9 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 21.85
2023-09-02 04:14:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-09-02 04:14:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 04:14:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 04:14:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 24 @ 35361 updates, score 21.85) (writing took 13.48430181198637 seconds)
2023-09-02 04:14:15 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-09-02 04:14:15 | INFO | train | epoch 024 | loss 1.94 | trans_loss 4.904 | nll_loss 2.142 | w2v_ctc_loss 0.664 | task_loss 3.114 | task_loss_gen 8.574 | contrastive_loss 0 | total 4138.65 | n_correct 2750.31 | ppl 4.42 | accuracy 66.454 | wps 10449.9 | ups 1.26 | wpb 8277.3 | bsz 305.7 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.501 | clip 0 | loss_scale 64 | train_wall 1054 | gb_free 15.8 | wall 30220
2023-09-02 04:14:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 04:14:16 | INFO | fairseq.trainer | begin training epoch 25
2023-09-02 04:14:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 04:14:51 | INFO | train_inner | epoch 025:     39 / 1474 loss=1.932, trans_loss=4.895, nll_loss=2.132, w2v_ctc_loss=0.658, task_loss=1.455, task_loss_gen=11.032, contrastive_loss=0, total=4166.95, n_correct=2782.89, ppl=4.38, accuracy=66.785, wps=6603.1, ups=0.79, wpb=8333.9, bsz=312, num_updates=35400, lr=7.51646e-05, gnorm=0.502, clip=0, loss_scale=64, train_wall=71, gb_free=16.1, wall=30255
2023-09-02 04:16:03 | INFO | train_inner | epoch 025:    139 / 1474 loss=1.926, trans_loss=4.881, nll_loss=2.112, w2v_ctc_loss=0.652, task_loss=2.376, task_loss_gen=9.919, contrastive_loss=0, total=4133.64, n_correct=2770.34, ppl=4.32, accuracy=67.019, wps=11514.1, ups=1.39, wpb=8267.3, bsz=307.7, num_updates=35500, lr=7.50587e-05, gnorm=0.496, clip=0, loss_scale=64, train_wall=71, gb_free=15.5, wall=30327
2023-09-02 04:17:16 | INFO | train_inner | epoch 025:    239 / 1474 loss=1.928, trans_loss=4.887, nll_loss=2.119, w2v_ctc_loss=0.65, task_loss=2.439, task_loss_gen=10.575, contrastive_loss=0, total=4114.53, n_correct=2747.38, ppl=4.34, accuracy=66.773, wps=11297.9, ups=1.37, wpb=8229.1, bsz=302.7, num_updates=35600, lr=7.49532e-05, gnorm=0.501, clip=0, loss_scale=64, train_wall=72, gb_free=16.7, wall=30400
2023-09-02 04:18:28 | INFO | train_inner | epoch 025:    339 / 1474 loss=1.933, trans_loss=4.887, nll_loss=2.118, w2v_ctc_loss=0.655, task_loss=2.795, task_loss_gen=10.834, contrastive_loss=0, total=4148.7, n_correct=2768.43, ppl=4.34, accuracy=66.73, wps=11433.2, ups=1.38, wpb=8297.4, bsz=295.1, num_updates=35700, lr=7.48481e-05, gnorm=0.506, clip=0, loss_scale=64, train_wall=72, gb_free=16, wall=30473
2023-09-02 04:19:41 | INFO | train_inner | epoch 025:    439 / 1474 loss=1.941, trans_loss=4.89, nll_loss=2.124, w2v_ctc_loss=0.669, task_loss=2.412, task_loss_gen=10.415, contrastive_loss=0, total=4167.03, n_correct=2775.82, ppl=4.36, accuracy=66.614, wps=11405.9, ups=1.37, wpb=8334.1, bsz=298.3, num_updates=35800, lr=7.47435e-05, gnorm=0.508, clip=0, loss_scale=64, train_wall=72, gb_free=11.9, wall=30546
2023-09-02 04:20:53 | INFO | train_inner | epoch 025:    539 / 1474 loss=1.938, trans_loss=4.901, nll_loss=2.139, w2v_ctc_loss=0.663, task_loss=2.43, task_loss_gen=9.9, contrastive_loss=0, total=4156.93, n_correct=2768.54, ppl=4.4, accuracy=66.601, wps=11575.7, ups=1.39, wpb=8313.9, bsz=312.8, num_updates=35900, lr=7.46393e-05, gnorm=0.505, clip=0, loss_scale=64, train_wall=71, gb_free=16.7, wall=30618
2023-09-02 04:22:05 | INFO | train_inner | epoch 025:    639 / 1474 loss=1.931, trans_loss=4.885, nll_loss=2.118, w2v_ctc_loss=0.659, task_loss=2.887, task_loss_gen=9.392, contrastive_loss=0, total=4153.23, n_correct=2775.18, ppl=4.34, accuracy=66.82, wps=11505.2, ups=1.39, wpb=8306.5, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=71, gb_free=14.5, wall=30690
2023-09-02 04:22:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 04:22:38 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.89 | trans_loss 5.182 | nll_loss 2.45 | w2v_ctc_loss 1.29 | task_loss 27.382 | task_loss_gen 21.987 | contrastive_loss 0 | total 4003.4 | n_correct 2651 | ppl 5.46 | accuracy 66.219 | uer 17.408 | wer 19.078 | raw_wer 19.078 | bleu 21.64 | wps 1643.5 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 21.85
2023-09-02 04:22:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-09-02 04:22:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-09-02 04:22:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-09-02 04:22:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 21.64) (writing took 9.350617396004964 seconds)
2023-09-02 04:24:00 | INFO | train_inner | epoch 025:    739 / 1474 loss=1.934, trans_loss=4.887, nll_loss=2.121, w2v_ctc_loss=0.658, task_loss=2.491, task_loss_gen=10.579, contrastive_loss=0, total=4123.21, n_correct=2748.56, ppl=4.35, accuracy=66.661, wps=7203.7, ups=0.87, wpb=8246.4, bsz=300.7, num_updates=36100, lr=7.44323e-05, gnorm=0.51, clip=0, loss_scale=64, train_wall=71, gb_free=14.3, wall=30804
2023-09-02 04:25:11 | INFO | train_inner | epoch 025:    839 / 1474 loss=1.928, trans_loss=4.891, nll_loss=2.126, w2v_ctc_loss=0.652, task_loss=1.979, task_loss_gen=9.654, contrastive_loss=0, total=4197.27, n_correct=2803.54, ppl=4.37, accuracy=66.794, wps=11706.4, ups=1.39, wpb=8394.5, bsz=328.2, num_updates=36200, lr=7.43294e-05, gnorm=0.498, clip=0, loss_scale=64, train_wall=71, gb_free=15.8, wall=30876
2023-09-02 04:26:24 | INFO | train_inner | epoch 025:    939 / 1474 loss=1.934, trans_loss=4.894, nll_loss=2.13, w2v_ctc_loss=0.663, task_loss=1.873, task_loss_gen=10.887, contrastive_loss=0, total=4137.23, n_correct=2756.63, ppl=4.38, accuracy=66.63, wps=11433.8, ups=1.38, wpb=8274.5, bsz=313.3, num_updates=36300, lr=7.4227e-05, gnorm=0.503, clip=0, loss_scale=64, train_wall=72, gb_free=16.2, wall=30948
2023-09-02 04:27:37 | INFO | train_inner | epoch 025:   1039 / 1474 loss=1.933, trans_loss=4.9, nll_loss=2.137, w2v_ctc_loss=0.649, task_loss=2.436, task_loss_gen=10.151, contrastive_loss=0, total=4183.45, n_correct=2786.28, ppl=4.4, accuracy=66.602, wps=11501.6, ups=1.37, wpb=8366.9, bsz=311, num_updates=36400, lr=7.41249e-05, gnorm=0.501, clip=0, loss_scale=64, train_wall=72, gb_free=16.3, wall=31021
2023-09-02 04:28:49 | INFO | train_inner | epoch 025:   1139 / 1474 loss=1.936, trans_loss=4.895, nll_loss=2.13, w2v_ctc_loss=0.658, task_loss=3.296, task_loss_gen=10.357, contrastive_loss=0, total=4045.24, n_correct=2694.07, ppl=4.38, accuracy=66.599, wps=11166.4, ups=1.38, wpb=8090.5, bsz=287, num_updates=36500, lr=7.40233e-05, gnorm=0.508, clip=0, loss_scale=64, train_wall=72, gb_free=16.1, wall=31094
2023-09-02 04:30:00 | INFO | train_inner | epoch 025:   1239 / 1474 loss=1.935, trans_loss=4.899, nll_loss=2.135, w2v_ctc_loss=0.655, task_loss=4.387, task_loss_gen=9.628, contrastive_loss=0, total=4079.17, n_correct=2719.74, ppl=4.39, accuracy=66.674, wps=11505.3, ups=1.41, wpb=8158.3, bsz=292.3, num_updates=36600, lr=7.39221e-05, gnorm=0.507, clip=0, loss_scale=128, train_wall=70, gb_free=16.6, wall=31164
2023-09-02 04:31:12 | INFO | train_inner | epoch 025:   1339 / 1474 loss=1.931, trans_loss=4.89, nll_loss=2.125, w2v_ctc_loss=0.656, task_loss=2.029, task_loss_gen=11.053, contrastive_loss=0, total=4173.55, n_correct=2788.91, ppl=4.36, accuracy=66.823, wps=11599.7, ups=1.39, wpb=8347.1, bsz=312.7, num_updates=36700, lr=7.38213e-05, gnorm=0.5, clip=0, loss_scale=128, train_wall=71, gb_free=16.5, wall=31236
2023-09-02 04:32:25 | INFO | train_inner | epoch 025:   1439 / 1474 loss=1.94, trans_loss=4.905, nll_loss=2.143, w2v_ctc_loss=0.662, task_loss=1.773, task_loss_gen=12.73, contrastive_loss=0, total=4102.27, n_correct=2725.02, ppl=4.42, accuracy=66.427, wps=11252.5, ups=1.37, wpb=8204.5, bsz=299.9, num_updates=36800, lr=7.3721e-05, gnorm=0.5, clip=0, loss_scale=128, train_wall=72, gb_free=15.6, wall=31309
2023-09-02 04:32:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 04:33:23 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.879 | trans_loss 5.176 | nll_loss 2.438 | w2v_ctc_loss 1.267 | task_loss 11.051 | task_loss_gen 29.236 | contrastive_loss 0 | total 4003.4 | n_correct 2660.3 | ppl 5.42 | accuracy 66.451 | uer 17.163 | wer 18.974 | raw_wer 18.974 | bleu 22 | wps 1653.5 | wpb 4003.4 | bsz 141.8 | num_updates 36835 | best_bleu 22
2023-09-02 04:33:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36835 updates
2023-09-02 04:33:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 04:33:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 04:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 25 @ 36835 updates, score 22.0) (writing took 13.582196601986652 seconds)
2023-09-02 04:33:37 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-09-02 04:33:37 | INFO | train | epoch 025 | loss 1.933 | trans_loss 4.892 | nll_loss 2.127 | w2v_ctc_loss 0.657 | task_loss 2.478 | task_loss_gen 10.453 | contrastive_loss 0 | total 4138.65 | n_correct 2760.48 | ppl 4.37 | accuracy 66.7 | wps 10502.9 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 36835 | lr 7.36859e-05 | gnorm 0.504 | clip 0 | loss_scale 128 | train_wall 1053 | gb_free 13.9 | wall 31382
2023-09-02 04:33:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 04:33:37 | INFO | fairseq.trainer | begin training epoch 26
2023-09-02 04:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 04:34:31 | INFO | train_inner | epoch 026:     65 / 1474 loss=1.921, trans_loss=4.877, nll_loss=2.107, w2v_ctc_loss=0.646, task_loss=1.19, task_loss_gen=12.578, contrastive_loss=0, total=4178.19, n_correct=2801.44, ppl=4.31, accuracy=67.049, wps=6596.9, ups=0.79, wpb=8356.4, bsz=317.5, num_updates=36900, lr=7.3621e-05, gnorm=0.496, clip=0, loss_scale=128, train_wall=71, gb_free=13.9, wall=31436
2023-09-02 04:35:44 | INFO | train_inner | epoch 026:    165 / 1474 loss=1.912, trans_loss=4.874, nll_loss=2.105, w2v_ctc_loss=0.63, task_loss=0.801, task_loss_gen=12.828, contrastive_loss=0, total=4269.55, n_correct=2868.82, ppl=4.3, accuracy=67.193, wps=11755.7, ups=1.38, wpb=8539.1, bsz=341.4, num_updates=37000, lr=7.35215e-05, gnorm=0.482, clip=0, loss_scale=128, train_wall=72, gb_free=15, wall=31509
2023-09-02 04:36:56 | INFO | train_inner | epoch 026:    265 / 1474 loss=1.924, trans_loss=4.87, nll_loss=2.099, w2v_ctc_loss=0.654, task_loss=1.543, task_loss_gen=12.637, contrastive_loss=0, total=4128.39, n_correct=2768.26, ppl=4.28, accuracy=67.054, wps=11409.3, ups=1.38, wpb=8256.8, bsz=306.8, num_updates=37100, lr=7.34223e-05, gnorm=0.5, clip=0, loss_scale=128, train_wall=72, gb_free=9.5, wall=31581
2023-09-02 04:38:08 | INFO | train_inner | epoch 026:    365 / 1474 loss=1.921, trans_loss=4.873, nll_loss=2.102, w2v_ctc_loss=0.649, task_loss=1.201, task_loss_gen=13.36, contrastive_loss=0, total=4166.22, n_correct=2797.19, ppl=4.29, accuracy=67.14, wps=11599.6, ups=1.39, wpb=8332.4, bsz=315, num_updates=37200, lr=7.33236e-05, gnorm=0.492, clip=0, loss_scale=128, train_wall=71, gb_free=16.4, wall=31653
2023-09-02 04:39:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-09-02 04:39:21 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.92, trans_loss=4.865, nll_loss=2.092, w2v_ctc_loss=0.651, task_loss=1.222, task_loss_gen=13.116, contrastive_loss=0, total=4165.73, n_correct=2800.4, ppl=4.26, accuracy=67.225, wps=11496.3, ups=1.38, wpb=8331.5, bsz=315.2, num_updates=37300, lr=7.32252e-05, gnorm=0.496, clip=0, loss_scale=64, train_wall=72, gb_free=17.5, wall=31725
2023-09-02 04:40:33 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.932, trans_loss=4.883, nll_loss=2.116, w2v_ctc_loss=0.664, task_loss=2.367, task_loss_gen=11.719, contrastive_loss=0, total=4155.02, n_correct=2777.18, ppl=4.33, accuracy=66.839, wps=11438.3, ups=1.38, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=72, gb_free=17.5, wall=31798
2023-09-02 04:41:46 | INFO | train_inner | epoch 026:    666 / 1474 loss=1.928, trans_loss=4.88, nll_loss=2.112, w2v_ctc_loss=0.652, task_loss=2.848, task_loss_gen=10.901, contrastive_loss=0, total=4136.96, n_correct=2769.18, ppl=4.32, accuracy=66.938, wps=11367.1, ups=1.37, wpb=8273.9, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=72, gb_free=15, wall=31871
2023-09-02 04:42:58 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.929, trans_loss=4.883, nll_loss=2.115, w2v_ctc_loss=0.65, task_loss=5.265, task_loss_gen=9.851, contrastive_loss=0, total=4086.28, n_correct=2730.6, ppl=4.33, accuracy=66.824, wps=11379.3, ups=1.39, wpb=8172.6, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.506, clip=0, loss_scale=64, train_wall=71, gb_free=14.7, wall=31943
2023-09-02 04:44:10 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.932, trans_loss=4.885, nll_loss=2.118, w2v_ctc_loss=0.658, task_loss=9.518, task_loss_gen=10.086, contrastive_loss=0, total=4183.26, n_correct=2793.22, ppl=4.34, accuracy=66.771, wps=11633.9, ups=1.39, wpb=8366.5, bsz=308.1, num_updates=37700, lr=7.28357e-05, gnorm=0.505, clip=0, loss_scale=64, train_wall=71, gb_free=17, wall=32015
2023-09-02 04:45:22 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.928, trans_loss=4.888, nll_loss=2.122, w2v_ctc_loss=0.643, task_loss=9.591, task_loss_gen=9.438, contrastive_loss=0, total=4137.96, n_correct=2763.24, ppl=4.35, accuracy=66.778, wps=11450.1, ups=1.38, wpb=8275.9, bsz=299, num_updates=37800, lr=7.27393e-05, gnorm=0.502, clip=0, loss_scale=64, train_wall=71, gb_free=16.6, wall=32087
2023-09-02 04:46:35 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.929, trans_loss=4.883, nll_loss=2.115, w2v_ctc_loss=0.654, task_loss=6.58, task_loss_gen=8.54, contrastive_loss=0, total=4120.53, n_correct=2759.03, ppl=4.33, accuracy=66.958, wps=11318.1, ups=1.37, wpb=8241.1, bsz=294.3, num_updates=37900, lr=7.26433e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=72, gb_free=16.3, wall=32160
2023-09-02 04:47:48 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.934, trans_loss=4.893, nll_loss=2.128, w2v_ctc_loss=0.657, task_loss=5.015, task_loss_gen=8.55, contrastive_loss=0, total=4113.86, n_correct=2744.25, ppl=4.37, accuracy=66.707, wps=11267.9, ups=1.37, wpb=8227.7, bsz=298.5, num_updates=38000, lr=7.25476e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=72, gb_free=16.2, wall=32233
2023-09-02 04:47:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 04:48:21 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.907 | trans_loss 5.182 | nll_loss 2.448 | w2v_ctc_loss 1.346 | task_loss 26.06 | task_loss_gen 22.879 | contrastive_loss 0 | total 4003.4 | n_correct 2646.6 | ppl 5.46 | accuracy 66.109 | uer 17.23 | wer 19.049 | raw_wer 19.049 | bleu 21.37 | wps 1659.9 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22
2023-09-02 04:48:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-09-02 04:48:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-09-02 04:48:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-09-02 04:48:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 21.37) (writing took 9.15237690898357 seconds)
2023-09-02 04:49:42 | INFO | train_inner | epoch 026:   1266 / 1474 loss=1.944, trans_loss=4.901, nll_loss=2.138, w2v_ctc_loss=0.669, task_loss=4.541, task_loss_gen=9.459, contrastive_loss=0, total=3996.19, n_correct=2658.08, ppl=4.4, accuracy=66.515, wps=7002.6, ups=0.88, wpb=7992.4, bsz=279.3, num_updates=38100, lr=7.24524e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=71, gb_free=17.4, wall=32347
2023-09-02 04:50:56 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.927, trans_loss=4.889, nll_loss=2.124, w2v_ctc_loss=0.648, task_loss=3.303, task_loss_gen=8.835, contrastive_loss=0, total=4159.74, n_correct=2782.15, ppl=4.36, accuracy=66.883, wps=11334.7, ups=1.36, wpb=8319.5, bsz=311.4, num_updates=38200, lr=7.23575e-05, gnorm=0.498, clip=0, loss_scale=64, train_wall=73, gb_free=16.9, wall=32420
2023-09-02 04:52:08 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.917, trans_loss=4.879, nll_loss=2.112, w2v_ctc_loss=0.637, task_loss=3.604, task_loss_gen=8.054, contrastive_loss=0, total=4165.66, n_correct=2796.46, ppl=4.32, accuracy=67.131, wps=11566.5, ups=1.39, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.5, clip=0, loss_scale=64, train_wall=71, gb_free=16, wall=32492
2023-09-02 04:52:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 04:52:46 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.886 | trans_loss 5.178 | nll_loss 2.442 | w2v_ctc_loss 1.285 | task_loss 14.65 | task_loss_gen 22.051 | contrastive_loss 0 | total 4003.4 | n_correct 2647.9 | ppl 5.43 | accuracy 66.141 | uer 17.158 | wer 18.944 | raw_wer 18.944 | bleu 21.66 | wps 1610.5 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 22
2023-09-02 04:52:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-09-02 04:52:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.6600.pt
2023-09-02 04:52:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.6600.pt
2023-09-02 04:52:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.6600.pt (epoch 26 @ 38308 updates, score 21.66) (writing took 7.288511060003657 seconds)
2023-09-02 04:52:54 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-09-02 04:52:54 | INFO | train | epoch 026 | loss 1.927 | trans_loss 4.881 | nll_loss 2.113 | w2v_ctc_loss 0.651 | task_loss 3.914 | task_loss_gen 10.721 | contrastive_loss 0 | total 4138.68 | n_correct 2770.61 | ppl 4.33 | accuracy 66.944 | wps 10538.9 | ups 1.27 | wpb 8277.4 | bsz 305.7 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.502 | clip 0 | loss_scale 64 | train_wall 1054 | gb_free 15.7 | wall 32539
2023-09-02 04:52:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 04:52:54 | INFO | fairseq.trainer | begin training epoch 27
2023-09-02 04:52:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 04:54:07 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.912, trans_loss=4.849, nll_loss=2.07, w2v_ctc_loss=0.637, task_loss=3.323, task_loss_gen=9.743, contrastive_loss=0, total=4054.57, n_correct=2740.28, ppl=4.2, accuracy=67.585, wps=6768.7, ups=0.83, wpb=8109.1, bsz=282.4, num_updates=38400, lr=7.21688e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=70, gb_free=16, wall=32612
2023-09-02 04:55:20 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.913, trans_loss=4.861, nll_loss=2.087, w2v_ctc_loss=0.642, task_loss=2.967, task_loss_gen=8.744, contrastive_loss=0, total=4195.2, n_correct=2824.48, ppl=4.25, accuracy=67.326, wps=11620.4, ups=1.38, wpb=8390.4, bsz=323.2, num_updates=38500, lr=7.2075e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=72, gb_free=16.8, wall=32684
2023-09-02 04:56:32 | INFO | train_inner | epoch 027:    292 / 1474 loss=1.923, trans_loss=4.871, nll_loss=2.099, w2v_ctc_loss=0.65, task_loss=3.214, task_loss_gen=9.225, contrastive_loss=0, total=4162.23, n_correct=2798.41, ppl=4.28, accuracy=67.233, wps=11492.6, ups=1.38, wpb=8324.5, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.508, clip=0, loss_scale=64, train_wall=72, gb_free=16.9, wall=32757
2023-09-02 04:57:45 | INFO | train_inner | epoch 027:    392 / 1474 loss=1.926, trans_loss=4.874, nll_loss=2.104, w2v_ctc_loss=0.649, task_loss=2.942, task_loss_gen=10.364, contrastive_loss=0, total=4079.05, n_correct=2730.23, ppl=4.3, accuracy=66.933, wps=11153.8, ups=1.37, wpb=8158.1, bsz=297.1, num_updates=38700, lr=7.18885e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=73, gb_free=16.6, wall=32830
2023-09-02 04:58:58 | INFO | train_inner | epoch 027:    492 / 1474 loss=1.92, trans_loss=4.878, nll_loss=2.109, w2v_ctc_loss=0.647, task_loss=2.215, task_loss_gen=9.191, contrastive_loss=0, total=4243.25, n_correct=2844.87, ppl=4.31, accuracy=67.045, wps=11704.2, ups=1.38, wpb=8486.5, bsz=331, num_updates=38800, lr=7.17958e-05, gnorm=0.498, clip=0, loss_scale=64, train_wall=72, gb_free=15.4, wall=32902
2023-09-02 05:00:10 | INFO | train_inner | epoch 027:    592 / 1474 loss=1.919, trans_loss=4.868, nll_loss=2.096, w2v_ctc_loss=0.649, task_loss=1.978, task_loss_gen=10.485, contrastive_loss=0, total=4137.92, n_correct=2780.2, ppl=4.28, accuracy=67.188, wps=11495.7, ups=1.39, wpb=8275.8, bsz=313.5, num_updates=38900, lr=7.17035e-05, gnorm=0.508, clip=0, loss_scale=64, train_wall=71, gb_free=15.6, wall=32974
2023-09-02 05:01:22 | INFO | train_inner | epoch 027:    692 / 1474 loss=1.925, trans_loss=4.874, nll_loss=2.103, w2v_ctc_loss=0.654, task_loss=2.239, task_loss_gen=10.638, contrastive_loss=0, total=4158.48, n_correct=2788.2, ppl=4.3, accuracy=67.049, wps=11497.3, ups=1.38, wpb=8317, bsz=304.1, num_updates=39000, lr=7.16115e-05, gnorm=0.5, clip=0, loss_scale=64, train_wall=72, gb_free=15.4, wall=33047
2023-09-02 05:02:34 | INFO | train_inner | epoch 027:    792 / 1474 loss=1.922, trans_loss=4.868, nll_loss=2.095, w2v_ctc_loss=0.649, task_loss=2.601, task_loss_gen=11.042, contrastive_loss=0, total=4100.88, n_correct=2755.62, ppl=4.27, accuracy=67.196, wps=11443.9, ups=1.4, wpb=8201.8, bsz=292.2, num_updates=39100, lr=7.15199e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=71, gb_free=15.4, wall=33118
2023-09-02 05:03:46 | INFO | train_inner | epoch 027:    892 / 1474 loss=1.922, trans_loss=4.878, nll_loss=2.107, w2v_ctc_loss=0.64, task_loss=2.536, task_loss_gen=10.571, contrastive_loss=0, total=4111.94, n_correct=2761.83, ppl=4.31, accuracy=67.166, wps=11434.3, ups=1.39, wpb=8223.9, bsz=294.9, num_updates=39200, lr=7.14286e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=71, gb_free=15.8, wall=33190
2023-09-02 05:04:58 | INFO | train_inner | epoch 027:    992 / 1474 loss=1.921, trans_loss=4.874, nll_loss=2.105, w2v_ctc_loss=0.643, task_loss=2.657, task_loss_gen=10.15, contrastive_loss=0, total=4189.27, n_correct=2810.03, ppl=4.3, accuracy=67.077, wps=11520.1, ups=1.37, wpb=8378.5, bsz=314.9, num_updates=39300, lr=7.13376e-05, gnorm=0.503, clip=0, loss_scale=64, train_wall=72, gb_free=14, wall=33263
2023-09-02 05:06:11 | INFO | train_inner | epoch 027:   1092 / 1474 loss=1.918, trans_loss=4.871, nll_loss=2.099, w2v_ctc_loss=0.64, task_loss=2.932, task_loss_gen=10.325, contrastive_loss=0, total=4160.42, n_correct=2795.99, ppl=4.29, accuracy=67.205, wps=11543.7, ups=1.39, wpb=8320.8, bsz=307.3, num_updates=39400, lr=7.1247e-05, gnorm=0.507, clip=0, loss_scale=128, train_wall=71, gb_free=16.7, wall=33335
2023-09-02 05:07:23 | INFO | train_inner | epoch 027:   1192 / 1474 loss=1.924, trans_loss=4.873, nll_loss=2.103, w2v_ctc_loss=0.65, task_loss=2.051, task_loss_gen=12.276, contrastive_loss=0, total=4103.72, n_correct=2754.67, ppl=4.3, accuracy=67.126, wps=11354.8, ups=1.38, wpb=8207.4, bsz=297.1, num_updates=39500, lr=7.11568e-05, gnorm=0.502, clip=0, loss_scale=128, train_wall=71, gb_free=17.3, wall=33407
2023-09-02 05:07:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-09-02 05:08:36 | INFO | train_inner | epoch 027:   1293 / 1474 loss=1.924, trans_loss=4.874, nll_loss=2.104, w2v_ctc_loss=0.648, task_loss=2.141, task_loss_gen=12.042, contrastive_loss=0, total=4062.32, n_correct=2725.27, ppl=4.3, accuracy=67.087, wps=11135.7, ups=1.37, wpb=8124.6, bsz=292.9, num_updates=39600, lr=7.10669e-05, gnorm=0.512, clip=0, loss_scale=64, train_wall=72, gb_free=16.3, wall=33480
2023-09-02 05:09:47 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.92, trans_loss=4.876, nll_loss=2.107, w2v_ctc_loss=0.644, task_loss=4.384, task_loss_gen=8.829, contrastive_loss=0, total=4152, n_correct=2785.58, ppl=4.31, accuracy=67.09, wps=11635.7, ups=1.4, wpb=8304, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.504, clip=0, loss_scale=64, train_wall=71, gb_free=16.3, wall=33552
2023-09-02 05:10:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 05:11:19 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.884 | trans_loss 5.174 | nll_loss 2.44 | w2v_ctc_loss 1.287 | task_loss 34.172 | task_loss_gen 26.552 | contrastive_loss 0 | total 4003.4 | n_correct 2651.1 | ppl 5.43 | accuracy 66.221 | uer 17.179 | wer 19.045 | raw_wer 19.045 | bleu 22.03 | wps 1529.6 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 22.03
2023-09-02 05:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-09-02 05:11:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 05:11:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 05:11:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 27 @ 39781 updates, score 22.03) (writing took 13.007230131013785 seconds)
2023-09-02 05:11:33 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-09-02 05:11:33 | INFO | train | epoch 027 | loss 1.92 | trans_loss 4.871 | nll_loss 2.099 | w2v_ctc_loss 0.646 | task_loss 2.9 | task_loss_gen 10.131 | contrastive_loss 0 | total 4138.83 | n_correct 2779.88 | ppl 4.29 | accuracy 67.166 | wps 10898.7 | ups 1.32 | wpb 8277.7 | bsz 305.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.507 | clip 0 | loss_scale 64 | train_wall 1052 | gb_free 17.5 | wall 33657
2023-09-02 05:11:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 05:11:33 | INFO | fairseq.trainer | begin training epoch 28
2023-09-02 05:11:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 05:11:54 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.916, trans_loss=4.869, nll_loss=2.097, w2v_ctc_loss=0.64, task_loss=5.997, task_loss_gen=8.606, contrastive_loss=0, total=4108.43, n_correct=2765.9, ppl=4.28, accuracy=67.323, wps=6463.4, ups=0.79, wpb=8216.9, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.508, clip=0, loss_scale=64, train_wall=71, gb_free=16, wall=33679
2023-09-02 05:13:07 | INFO | train_inner | epoch 028:    119 / 1474 loss=1.909, trans_loss=4.844, nll_loss=2.064, w2v_ctc_loss=0.637, task_loss=5.518, task_loss_gen=8.774, contrastive_loss=0, total=4113.41, n_correct=2785.26, ppl=4.18, accuracy=67.712, wps=11399.6, ups=1.39, wpb=8226.8, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.505, clip=0, loss_scale=64, train_wall=72, gb_free=16.6, wall=33751
2023-09-02 05:14:19 | INFO | train_inner | epoch 028:    219 / 1474 loss=1.908, trans_loss=4.854, nll_loss=2.078, w2v_ctc_loss=0.635, task_loss=3.452, task_loss_gen=8.16, contrastive_loss=0, total=4191.56, n_correct=2832.32, ppl=4.22, accuracy=67.572, wps=11641.5, ups=1.39, wpb=8383.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.502, clip=0, loss_scale=64, train_wall=71, gb_free=14.8, wall=33823
2023-09-02 05:14:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 05:14:51 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.896 | trans_loss 5.179 | nll_loss 2.442 | w2v_ctc_loss 1.317 | task_loss 18.537 | task_loss_gen 23.207 | contrastive_loss 0 | total 4003.4 | n_correct 2653.2 | ppl 5.44 | accuracy 66.274 | uer 17.134 | wer 18.881 | raw_wer 18.881 | bleu 21.73 | wps 1641 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.03
2023-09-02 05:14:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-09-02 05:14:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-09-02 05:14:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-09-02 05:15:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 21.73) (writing took 10.579153760016197 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:0')
2023-09-02 05:16:15 | INFO | train_inner | epoch 028:    319 / 1474 loss=1.912, trans_loss=4.863, nll_loss=2.089, w2v_ctc_loss=0.628, task_loss=3.149, task_loss_gen=9.302, contrastive_loss=0, total=4145.32, n_correct=2787.82, ppl=4.26, accuracy=67.252, wps=7145.6, ups=0.86, wpb=8290.6, bsz=316.1, num_updates=40100, lr=7.06225e-05, gnorm=0.512, clip=0, loss_scale=64, train_wall=71, gb_free=15.4, wall=33939
2023-09-02 05:17:26 | INFO | train_inner | epoch 028:    419 / 1474 loss=1.916, trans_loss=4.857, nll_loss=2.081, w2v_ctc_loss=0.645, task_loss=3.276, task_loss_gen=9.753, contrastive_loss=0, total=4092.14, n_correct=2760.21, ppl=4.23, accuracy=67.452, wps=11386.5, ups=1.39, wpb=8184.3, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=71, gb_free=16, wall=34011
2023-09-02 05:18:38 | INFO | train_inner | epoch 028:    519 / 1474 loss=1.912, trans_loss=4.858, nll_loss=2.083, w2v_ctc_loss=0.633, task_loss=5.834, task_loss_gen=8.971, contrastive_loss=0, total=4096.35, n_correct=2762.95, ppl=4.24, accuracy=67.449, wps=11402.4, ups=1.39, wpb=8192.7, bsz=295.5, num_updates=40300, lr=7.0447e-05, gnorm=0.51, clip=0, loss_scale=64, train_wall=71, gb_free=15.7, wall=34083
2023-09-02 05:19:50 | INFO | train_inner | epoch 028:    619 / 1474 loss=1.916, trans_loss=4.866, nll_loss=2.094, w2v_ctc_loss=0.643, task_loss=5.97, task_loss_gen=8.1, contrastive_loss=0, total=4178.12, n_correct=2811.01, ppl=4.27, accuracy=67.279, wps=11576.3, ups=1.39, wpb=8356.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.5, clip=0, loss_scale=64, train_wall=72, gb_free=15.5, wall=34155
2023-09-02 05:21:03 | INFO | train_inner | epoch 028:    719 / 1474 loss=1.911, trans_loss=4.867, nll_loss=2.095, w2v_ctc_loss=0.635, task_loss=3.316, task_loss_gen=7.362, contrastive_loss=0, total=4185.82, n_correct=2816.23, ppl=4.27, accuracy=67.28, wps=11612.4, ups=1.39, wpb=8371.6, bsz=326.4, num_updates=40500, lr=7.02728e-05, gnorm=0.501, clip=0, loss_scale=64, train_wall=71, gb_free=15.6, wall=34227
2023-09-02 05:22:14 | INFO | train_inner | epoch 028:    819 / 1474 loss=1.91, trans_loss=4.859, nll_loss=2.085, w2v_ctc_loss=0.636, task_loss=2.782, task_loss_gen=9.004, contrastive_loss=0, total=4096.2, n_correct=2764.67, ppl=4.24, accuracy=67.494, wps=11414.9, ups=1.39, wpb=8192.4, bsz=307, num_updates=40600, lr=7.01862e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=71, gb_free=15.4, wall=34299
2023-09-02 05:23:27 | INFO | train_inner | epoch 028:    919 / 1474 loss=1.92, trans_loss=4.867, nll_loss=2.095, w2v_ctc_loss=0.646, task_loss=2.033, task_loss_gen=10.326, contrastive_loss=0, total=4120.27, n_correct=2768.16, ppl=4.27, accuracy=67.184, wps=11301, ups=1.37, wpb=8240.5, bsz=300.8, num_updates=40700, lr=7.01e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=72, gb_free=17.1, wall=34372
2023-09-02 05:24:39 | INFO | train_inner | epoch 028:   1019 / 1474 loss=1.921, trans_loss=4.867, nll_loss=2.095, w2v_ctc_loss=0.649, task_loss=2.247, task_loss_gen=9.494, contrastive_loss=0, total=4177.86, n_correct=2806.47, ppl=4.27, accuracy=67.175, wps=11615, ups=1.39, wpb=8355.7, bsz=311.1, num_updates=40800, lr=7.0014e-05, gnorm=0.503, clip=0, loss_scale=64, train_wall=71, gb_free=16.1, wall=34444
2023-09-02 05:25:51 | INFO | train_inner | epoch 028:   1119 / 1474 loss=1.913, trans_loss=4.859, nll_loss=2.085, w2v_ctc_loss=0.642, task_loss=2.819, task_loss_gen=9.402, contrastive_loss=0, total=4210.86, n_correct=2836.4, ppl=4.24, accuracy=67.359, wps=11652.9, ups=1.38, wpb=8421.7, bsz=318.9, num_updates=40900, lr=6.99284e-05, gnorm=0.498, clip=0, loss_scale=64, train_wall=71, gb_free=17.2, wall=34516
2023-09-02 05:27:03 | INFO | train_inner | epoch 028:   1219 / 1474 loss=1.909, trans_loss=4.862, nll_loss=2.088, w2v_ctc_loss=0.628, task_loss=2.957, task_loss_gen=9.051, contrastive_loss=0, total=4104.61, n_correct=2767.52, ppl=4.25, accuracy=67.425, wps=11417, ups=1.39, wpb=8209.2, bsz=305.6, num_updates=41000, lr=6.9843e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=71, gb_free=16.2, wall=34588
2023-09-02 05:28:16 | INFO | train_inner | epoch 028:   1319 / 1474 loss=1.921, trans_loss=4.864, nll_loss=2.091, w2v_ctc_loss=0.647, task_loss=2.883, task_loss_gen=10.481, contrastive_loss=0, total=4087.78, n_correct=2748.14, ppl=4.26, accuracy=67.228, wps=11186.3, ups=1.37, wpb=8175.6, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=72, gb_free=14.7, wall=34661
2023-09-02 05:29:29 | INFO | train_inner | epoch 028:   1419 / 1474 loss=1.916, trans_loss=4.863, nll_loss=2.089, w2v_ctc_loss=0.637, task_loss=3.797, task_loss_gen=9.852, contrastive_loss=0, total=4145.03, n_correct=2789.27, ppl=4.26, accuracy=67.292, wps=11388, ups=1.37, wpb=8290.1, bsz=297.6, num_updates=41200, lr=6.96733e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=72, gb_free=17.3, wall=34734
2023-09-02 05:30:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:3')
2023-09-02 05:30:43 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.899 | trans_loss 5.183 | nll_loss 2.45 | w2v_ctc_loss 1.317 | task_loss 29 | task_loss_gen 23.306 | contrastive_loss 0 | total 4003.4 | n_correct 2644.8 | ppl 5.46 | accuracy 66.064 | uer 17.259 | wer 18.929 | raw_wer 18.929 | bleu 21.91 | wps 1521.7 | wpb 4003.4 | bsz 141.8 | num_updates 41255 | best_bleu 22.03
2023-09-02 05:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41255 updates
2023-09-02 05:30:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.9103.pt
2023-09-02 05:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.9103.pt
2023-09-02 05:30:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.9103.pt (epoch 28 @ 41255 updates, score 21.91) (writing took 7.949301974993432 seconds)
2023-09-02 05:30:51 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-09-02 05:30:51 | INFO | train | epoch 028 | loss 1.914 | trans_loss 4.86 | nll_loss 2.086 | w2v_ctc_loss 0.638 | task_loss 3.607 | task_loss_gen 9.09 | contrastive_loss 0 | total 4138.65 | n_correct 2788.83 | ppl 4.25 | accuracy 67.385 | wps 10531.9 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 41255 | lr 6.96268e-05 | gnorm 0.506 | clip 0 | loss_scale 64 | train_wall 1054 | gb_free 16.2 | wall 34816
2023-09-02 05:30:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 05:30:51 | INFO | fairseq.trainer | begin training epoch 29
2023-09-02 05:30:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 05:31:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-02 05:31:32 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.909, trans_loss=4.851, nll_loss=2.076, w2v_ctc_loss=0.641, task_loss=5.145, task_loss_gen=8.278, contrastive_loss=0, total=4172.67, n_correct=2818.97, ppl=4.22, accuracy=67.558, wps=6773.4, ups=0.81, wpb=8345.3, bsz=317.3, num_updates=41300, lr=6.95889e-05, gnorm=0.508, clip=0, loss_scale=32, train_wall=72, gb_free=16.1, wall=34857
2023-09-02 05:32:44 | INFO | train_inner | epoch 029:    146 / 1474 loss=1.91, trans_loss=4.855, nll_loss=2.079, w2v_ctc_loss=0.633, task_loss=9.404, task_loss_gen=8.596, contrastive_loss=0, total=4105.72, n_correct=2776.58, ppl=4.22, accuracy=67.627, wps=11414.6, ups=1.39, wpb=8211.4, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=71, gb_free=15.7, wall=34929
2023-09-02 05:33:57 | INFO | train_inner | epoch 029:    246 / 1474 loss=1.902, trans_loss=4.849, nll_loss=2.072, w2v_ctc_loss=0.624, task_loss=7.813, task_loss_gen=7.241, contrastive_loss=0, total=4199.67, n_correct=2836.59, ppl=4.21, accuracy=67.543, wps=11515.5, ups=1.37, wpb=8399.3, bsz=330.5, num_updates=41500, lr=6.9421e-05, gnorm=0.506, clip=0, loss_scale=32, train_wall=72, gb_free=15.3, wall=35002
2023-09-02 05:35:10 | INFO | train_inner | epoch 029:    346 / 1474 loss=1.921, trans_loss=4.864, nll_loss=2.092, w2v_ctc_loss=0.648, task_loss=8.148, task_loss_gen=8.292, contrastive_loss=0, total=4095.17, n_correct=2759.22, ppl=4.26, accuracy=67.377, wps=11260, ups=1.37, wpb=8190.3, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=72, gb_free=16.4, wall=35075
2023-09-02 05:36:22 | INFO | train_inner | epoch 029:    446 / 1474 loss=1.9, trans_loss=4.833, nll_loss=2.051, w2v_ctc_loss=0.627, task_loss=5.158, task_loss_gen=6.805, contrastive_loss=0, total=4157.44, n_correct=2822.57, ppl=4.15, accuracy=67.892, wps=11602.6, ups=1.4, wpb=8314.9, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=71, gb_free=16.2, wall=35146
2023-09-02 05:37:34 | INFO | train_inner | epoch 029:    546 / 1474 loss=1.917, trans_loss=4.863, nll_loss=2.088, w2v_ctc_loss=0.635, task_loss=6.564, task_loss_gen=7.868, contrastive_loss=0, total=4150.87, n_correct=2793.04, ppl=4.25, accuracy=67.288, wps=11435.9, ups=1.38, wpb=8301.7, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=72, gb_free=15.4, wall=35219
2023-09-02 05:38:46 | INFO | train_inner | epoch 029:    646 / 1474 loss=1.904, trans_loss=4.849, nll_loss=2.071, w2v_ctc_loss=0.631, task_loss=7.905, task_loss_gen=7.341, contrastive_loss=0, total=4143.02, n_correct=2801.57, ppl=4.2, accuracy=67.621, wps=11523.5, ups=1.39, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=71, gb_free=16.7, wall=35291
2023-09-02 05:39:59 | INFO | train_inner | epoch 029:    746 / 1474 loss=1.902, trans_loss=4.847, nll_loss=2.07, w2v_ctc_loss=0.628, task_loss=5.345, task_loss_gen=6.039, contrastive_loss=0, total=4249.79, n_correct=2876.53, ppl=4.2, accuracy=67.686, wps=11652.3, ups=1.37, wpb=8499.6, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.493, clip=0, loss_scale=32, train_wall=72, gb_free=16.3, wall=35364
2023-09-02 05:39:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 05:40:33 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.906 | trans_loss 5.178 | nll_loss 2.44 | w2v_ctc_loss 1.35 | task_loss 8.939 | task_loss_gen 19.216 | contrastive_loss 0 | total 4003.4 | n_correct 2654.9 | ppl 5.43 | accuracy 66.316 | uer 17.235 | wer 18.877 | raw_wer 18.877 | bleu 22.13 | wps 1539.6 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.13
2023-09-02 05:40:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-09-02 05:40:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-09-02 05:40:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-09-02 05:40:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.13) (writing took 13.981723326985957 seconds)
2023-09-02 05:41:59 | INFO | train_inner | epoch 029:    846 / 1474 loss=1.916, trans_loss=4.862, nll_loss=2.089, w2v_ctc_loss=0.635, task_loss=5.125, task_loss_gen=7.429, contrastive_loss=0, total=4027.19, n_correct=2710.12, ppl=4.25, accuracy=67.296, wps=6703.6, ups=0.83, wpb=8054.4, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=71, gb_free=16.9, wall=35484
2023-09-02 05:43:11 | INFO | train_inner | epoch 029:    946 / 1474 loss=1.913, trans_loss=4.857, nll_loss=2.081, w2v_ctc_loss=0.638, task_loss=4.456, task_loss_gen=6.917, contrastive_loss=0, total=4082.14, n_correct=2757.72, ppl=4.23, accuracy=67.556, wps=11389.9, ups=1.4, wpb=8164.3, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.511, clip=0, loss_scale=32, train_wall=71, gb_free=15, wall=35556
2023-09-02 05:44:23 | INFO | train_inner | epoch 029:   1046 / 1474 loss=1.906, trans_loss=4.848, nll_loss=2.07, w2v_ctc_loss=0.633, task_loss=3.53, task_loss_gen=6.997, contrastive_loss=0, total=4148.18, n_correct=2807.74, ppl=4.2, accuracy=67.686, wps=11474.9, ups=1.38, wpb=8296.4, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=71, gb_free=15.6, wall=35628
2023-09-02 05:45:35 | INFO | train_inner | epoch 029:   1146 / 1474 loss=1.921, trans_loss=4.864, nll_loss=2.09, w2v_ctc_loss=0.649, task_loss=4.134, task_loss_gen=7.878, contrastive_loss=0, total=4063.95, n_correct=2736.38, ppl=4.26, accuracy=67.333, wps=11293.9, ups=1.39, wpb=8127.9, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=71, gb_free=12.9, wall=35700
2023-09-02 05:46:48 | INFO | train_inner | epoch 029:   1246 / 1474 loss=1.914, trans_loss=4.862, nll_loss=2.089, w2v_ctc_loss=0.637, task_loss=4.161, task_loss_gen=7.239, contrastive_loss=0, total=4158.81, n_correct=2800.84, ppl=4.26, accuracy=67.347, wps=11447, ups=1.38, wpb=8317.6, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=72, gb_free=15.4, wall=35773
2023-09-02 05:48:01 | INFO | train_inner | epoch 029:   1346 / 1474 loss=1.905, trans_loss=4.846, nll_loss=2.069, w2v_ctc_loss=0.628, task_loss=4.313, task_loss_gen=7.007, contrastive_loss=0, total=4166.34, n_correct=2816.31, ppl=4.19, accuracy=67.597, wps=11477.8, ups=1.38, wpb=8332.7, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.502, clip=0, loss_scale=32, train_wall=72, gb_free=17.5, wall=35845
2023-09-02 05:49:13 | INFO | train_inner | epoch 029:   1446 / 1474 loss=1.907, trans_loss=4.849, nll_loss=2.072, w2v_ctc_loss=0.635, task_loss=3.597, task_loss_gen=7.17, contrastive_loss=0, total=4162.2, n_correct=2812.37, ppl=4.2, accuracy=67.569, wps=11557.9, ups=1.39, wpb=8324.4, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.506, clip=0, loss_scale=32, train_wall=71, gb_free=17, wall=35917
2023-09-02 05:49:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 05:50:05 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.896 | trans_loss 5.164 | nll_loss 2.423 | w2v_ctc_loss 1.35 | task_loss 9.42 | task_loss_gen 20.042 | contrastive_loss 0 | total 4003.4 | n_correct 2659.7 | ppl 5.36 | accuracy 66.436 | uer 17.012 | wer 18.765 | raw_wer 18.765 | bleu 21.97 | wps 1642.6 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 22.13
2023-09-02 05:50:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-09-02 05:50:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.9709.pt
2023-09-02 05:50:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.9709.pt
2023-09-02 05:50:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.9709.pt (epoch 29 @ 42728 updates, score 21.97) (writing took 8.738831413997104 seconds)
2023-09-02 05:50:14 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-09-02 05:50:14 | INFO | train | epoch 029 | loss 1.909 | trans_loss 4.853 | nll_loss 2.077 | w2v_ctc_loss 0.634 | task_loss 5.678 | task_loss_gen 7.336 | contrastive_loss 0 | total 4138.66 | n_correct 2795.04 | ppl 4.22 | accuracy 67.535 | wps 10481.9 | ups 1.27 | wpb 8277.3 | bsz 305.6 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.51 | clip 0 | loss_scale 32 | train_wall 1053 | gb_free 15.8 | wall 35979
2023-09-02 05:50:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 05:50:15 | INFO | fairseq.trainer | begin training epoch 30
2023-09-02 05:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 05:51:14 | INFO | train_inner | epoch 030:     72 / 1474 loss=1.895, trans_loss=4.837, nll_loss=2.056, w2v_ctc_loss=0.617, task_loss=3.442, task_loss_gen=6.685, contrastive_loss=0, total=4182.65, n_correct=2839.25, ppl=4.16, accuracy=67.882, wps=6887.4, ups=0.82, wpb=8365.3, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=71, gb_free=13.1, wall=36039
2023-09-02 05:52:26 | INFO | train_inner | epoch 030:    172 / 1474 loss=1.893, trans_loss=4.824, nll_loss=2.04, w2v_ctc_loss=0.624, task_loss=4.268, task_loss_gen=6.38, contrastive_loss=0, total=4203.05, n_correct=2862.69, ppl=4.11, accuracy=68.11, wps=11697.1, ups=1.39, wpb=8406.1, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.502, clip=0, loss_scale=32, train_wall=71, gb_free=17.1, wall=36111
2023-09-02 05:53:38 | INFO | train_inner | epoch 030:    272 / 1474 loss=1.907, trans_loss=4.844, nll_loss=2.064, w2v_ctc_loss=0.637, task_loss=3.763, task_loss_gen=7.45, contrastive_loss=0, total=4116.93, n_correct=2791.22, ppl=4.18, accuracy=67.799, wps=11389.3, ups=1.38, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=72, gb_free=16.7, wall=36183
2023-09-02 05:54:51 | INFO | train_inner | epoch 030:    372 / 1474 loss=1.897, trans_loss=4.832, nll_loss=2.048, w2v_ctc_loss=0.622, task_loss=2.821, task_loss_gen=8.141, contrastive_loss=0, total=4173.13, n_correct=2837.52, ppl=4.14, accuracy=67.995, wps=11439.1, ups=1.37, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.507, clip=0, loss_scale=32, train_wall=72, gb_free=11.4, wall=36256
2023-09-02 05:56:03 | INFO | train_inner | epoch 030:    472 / 1474 loss=1.895, trans_loss=4.837, nll_loss=2.056, w2v_ctc_loss=0.618, task_loss=2.25, task_loss_gen=8.944, contrastive_loss=0, total=4135.2, n_correct=2809.51, ppl=4.16, accuracy=67.941, wps=11572.3, ups=1.4, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.508, clip=0, loss_scale=32, train_wall=71, gb_free=16.6, wall=36327
2023-09-02 05:57:15 | INFO | train_inner | epoch 030:    572 / 1474 loss=1.899, trans_loss=4.839, nll_loss=2.058, w2v_ctc_loss=0.627, task_loss=2.584, task_loss_gen=8.39, contrastive_loss=0, total=4168.65, n_correct=2827.62, ppl=4.17, accuracy=67.831, wps=11592.3, ups=1.39, wpb=8337.3, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.503, clip=0, loss_scale=32, train_wall=71, gb_free=15.6, wall=36399
2023-09-02 05:58:27 | INFO | train_inner | epoch 030:    672 / 1474 loss=1.902, trans_loss=4.84, nll_loss=2.06, w2v_ctc_loss=0.632, task_loss=3.679, task_loss_gen=7.891, contrastive_loss=0, total=4183.65, n_correct=2833.81, ppl=4.17, accuracy=67.735, wps=11538.5, ups=1.38, wpb=8367.3, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.503, clip=0, loss_scale=64, train_wall=72, gb_free=16.5, wall=36472
2023-09-02 05:59:39 | INFO | train_inner | epoch 030:    772 / 1474 loss=1.909, trans_loss=4.846, nll_loss=2.068, w2v_ctc_loss=0.639, task_loss=3.028, task_loss_gen=8.336, contrastive_loss=0, total=4106.9, n_correct=2776.02, ppl=4.19, accuracy=67.594, wps=11419, ups=1.39, wpb=8213.8, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.508, clip=0, loss_scale=64, train_wall=71, gb_free=11.5, wall=36544
2023-09-02 06:00:52 | INFO | train_inner | epoch 030:    872 / 1474 loss=1.909, trans_loss=4.846, nll_loss=2.068, w2v_ctc_loss=0.637, task_loss=3.414, task_loss_gen=8.894, contrastive_loss=0, total=4089.18, n_correct=2770.81, ppl=4.19, accuracy=67.76, wps=11254.8, ups=1.38, wpb=8178.4, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.512, clip=0, loss_scale=64, train_wall=72, gb_free=16.2, wall=36616
2023-09-02 06:02:04 | INFO | train_inner | epoch 030:    972 / 1474 loss=1.907, trans_loss=4.847, nll_loss=2.069, w2v_ctc_loss=0.636, task_loss=2.821, task_loss_gen=9.377, contrastive_loss=0, total=4140.03, n_correct=2802.98, ppl=4.2, accuracy=67.704, wps=11449, ups=1.38, wpb=8280.1, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.501, clip=0, loss_scale=64, train_wall=72, gb_free=13.5, wall=36689
2023-09-02 06:03:17 | INFO | train_inner | epoch 030:   1072 / 1474 loss=1.91, trans_loss=4.85, nll_loss=2.071, w2v_ctc_loss=0.629, task_loss=2.768, task_loss_gen=10.287, contrastive_loss=0, total=4101.12, n_correct=2769.29, ppl=4.2, accuracy=67.525, wps=11254.5, ups=1.37, wpb=8202.2, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.512, clip=0, loss_scale=64, train_wall=72, gb_free=16.3, wall=36762
2023-09-02 06:04:30 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.894, trans_loss=4.837, nll_loss=2.057, w2v_ctc_loss=0.616, task_loss=2.489, task_loss_gen=8.842, contrastive_loss=0, total=4168.22, n_correct=2834.26, ppl=4.16, accuracy=67.997, wps=11490.5, ups=1.38, wpb=8336.4, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.499, clip=0, loss_scale=64, train_wall=72, gb_free=16.4, wall=36834
2023-09-02 06:05:43 | INFO | train_inner | epoch 030:   1272 / 1474 loss=1.913, trans_loss=4.849, nll_loss=2.072, w2v_ctc_loss=0.64, task_loss=3.594, task_loss_gen=10.199, contrastive_loss=0, total=4032.74, n_correct=2727.19, ppl=4.2, accuracy=67.626, wps=11049.5, ups=1.37, wpb=8065.5, bsz=281.8, num_updates=44000, lr=6.742e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=72, gb_free=16.5, wall=36907
2023-09-02 06:05:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 06:06:17 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.918 | trans_loss 5.171 | nll_loss 2.429 | w2v_ctc_loss 1.408 | task_loss 19.758 | task_loss_gen 21.918 | contrastive_loss 0 | total 4003.4 | n_correct 2658.7 | ppl 5.39 | accuracy 66.411 | uer 17.185 | wer 18.97 | raw_wer 18.97 | bleu 22.35 | wps 1550.2 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.35
2023-09-02 06:06:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-09-02 06:06:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-09-02 06:06:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-09-02 06:06:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.35) (writing took 13.263881299004424 seconds)
2023-09-02 06:07:42 | INFO | train_inner | epoch 030:   1372 / 1474 loss=1.897, trans_loss=4.842, nll_loss=2.063, w2v_ctc_loss=0.623, task_loss=3.405, task_loss_gen=8.346, contrastive_loss=0, total=4166.96, n_correct=2828.35, ppl=4.18, accuracy=67.876, wps=6969.6, ups=0.84, wpb=8333.9, bsz=322.3, num_updates=44100, lr=6.73435e-05, gnorm=0.505, clip=0, loss_scale=64, train_wall=71, gb_free=15, wall=37027
2023-09-02 06:08:54 | INFO | train_inner | epoch 030:   1472 / 1474 loss=1.902, trans_loss=4.846, nll_loss=2.069, w2v_ctc_loss=0.624, task_loss=3.605, task_loss_gen=8.278, contrastive_loss=0, total=4125.17, n_correct=2791.12, ppl=4.2, accuracy=67.661, wps=11494.6, ups=1.39, wpb=8250.3, bsz=310, num_updates=44200, lr=6.72673e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=71, gb_free=16.7, wall=37098
2023-09-02 06:08:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 06:09:28 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.879 | trans_loss 5.162 | nll_loss 2.42 | w2v_ctc_loss 1.297 | task_loss 29.441 | task_loss_gen 27.957 | contrastive_loss 0 | total 4003.4 | n_correct 2663.7 | ppl 5.35 | accuracy 66.536 | uer 16.832 | wer 18.568 | raw_wer 18.568 | bleu 22.12 | wps 1646.2 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 22.35
2023-09-02 06:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-09-02 06:09:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1205.pt
2023-09-02 06:09:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1205.pt
2023-09-02 06:09:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1205.pt (epoch 30 @ 44202 updates, score 22.12) (writing took 8.52438638699823 seconds)
2023-09-02 06:09:37 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-09-02 06:09:37 | INFO | train | epoch 030 | loss 1.902 | trans_loss 4.841 | nll_loss 2.061 | w2v_ctc_loss 0.628 | task_loss 3.195 | task_loss_gen 8.437 | contrastive_loss 0 | total 4138.65 | n_correct 2806.18 | ppl 4.17 | accuracy 67.804 | wps 10495 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.507 | clip 0 | loss_scale 64 | train_wall 1054 | gb_free 16.8 | wall 37142
2023-09-02 06:09:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 06:09:37 | INFO | fairseq.trainer | begin training epoch 31
2023-09-02 06:09:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 06:10:55 | INFO | train_inner | epoch 031:     98 / 1474 loss=1.899, trans_loss=4.83, nll_loss=2.046, w2v_ctc_loss=0.628, task_loss=4.554, task_loss_gen=8.708, contrastive_loss=0, total=4081.34, n_correct=2778.32, ppl=4.13, accuracy=68.074, wps=6724.7, ups=0.82, wpb=8162.7, bsz=294.7, num_updates=44300, lr=6.71913e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=71, gb_free=16.1, wall=37220
2023-09-02 06:12:07 | INFO | train_inner | epoch 031:    198 / 1474 loss=1.899, trans_loss=4.833, nll_loss=2.05, w2v_ctc_loss=0.624, task_loss=3.222, task_loss_gen=9.089, contrastive_loss=0, total=4146.03, n_correct=2814.86, ppl=4.14, accuracy=67.893, wps=11488.4, ups=1.39, wpb=8292.1, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=71, gb_free=13, wall=37292
2023-09-02 06:13:21 | INFO | train_inner | epoch 031:    298 / 1474 loss=1.896, trans_loss=4.826, nll_loss=2.04, w2v_ctc_loss=0.624, task_loss=3.015, task_loss_gen=9.14, contrastive_loss=0, total=4146.75, n_correct=2822.78, ppl=4.11, accuracy=68.072, wps=11313.4, ups=1.36, wpb=8293.5, bsz=300.7, num_updates=44500, lr=6.70402e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=73, gb_free=17.3, wall=37365
2023-09-02 06:14:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-02 06:14:34 | INFO | train_inner | epoch 031:    399 / 1474 loss=1.9, trans_loss=4.836, nll_loss=2.054, w2v_ctc_loss=0.621, task_loss=4.246, task_loss_gen=10.335, contrastive_loss=0, total=4088.82, n_correct=2778.43, ppl=4.15, accuracy=67.952, wps=11183.9, ups=1.37, wpb=8177.6, bsz=285.7, num_updates=44600, lr=6.6965e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=72, gb_free=16.9, wall=37438
2023-09-02 06:15:47 | INFO | train_inner | epoch 031:    499 / 1474 loss=1.904, trans_loss=4.835, nll_loss=2.052, w2v_ctc_loss=0.635, task_loss=18.55, task_loss_gen=13.717, contrastive_loss=0, total=4111.85, n_correct=2789.97, ppl=4.15, accuracy=67.852, wps=11308.6, ups=1.38, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=72, gb_free=10.6, wall=37511
2023-09-02 06:16:59 | INFO | train_inner | epoch 031:    599 / 1474 loss=1.898, trans_loss=4.834, nll_loss=2.051, w2v_ctc_loss=0.62, task_loss=9.767, task_loss_gen=8.527, contrastive_loss=0, total=4083.44, n_correct=2774.75, ppl=4.15, accuracy=67.951, wps=11304.4, ups=1.38, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=72, gb_free=16.5, wall=37583
2023-09-02 06:18:11 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.891, trans_loss=4.829, nll_loss=2.046, w2v_ctc_loss=0.613, task_loss=5.439, task_loss_gen=6.756, contrastive_loss=0, total=4213.98, n_correct=2866.98, ppl=4.13, accuracy=68.035, wps=11709.2, ups=1.39, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.501, clip=0, loss_scale=32, train_wall=71, gb_free=16, wall=37655
2023-09-02 06:19:23 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.901, trans_loss=4.84, nll_loss=2.059, w2v_ctc_loss=0.622, task_loss=4.877, task_loss_gen=7.466, contrastive_loss=0, total=4097.37, n_correct=2775.1, ppl=4.17, accuracy=67.729, wps=11302.6, ups=1.38, wpb=8194.7, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=72, gb_free=12.6, wall=37728
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:0')
2023-09-02 06:20:35 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.897, trans_loss=4.827, nll_loss=2.042, w2v_ctc_loss=0.623, task_loss=4.702, task_loss_gen=7.706, contrastive_loss=0, total=4096.72, n_correct=2785.82, ppl=4.12, accuracy=68.001, wps=11367.4, ups=1.39, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=71, gb_free=16.9, wall=37800
2023-09-02 06:21:48 | INFO | train_inner | epoch 031:    999 / 1474 loss=1.895, trans_loss=4.84, nll_loss=2.06, w2v_ctc_loss=0.617, task_loss=4.071, task_loss_gen=7.055, contrastive_loss=0, total=4187.84, n_correct=2846.51, ppl=4.17, accuracy=67.971, wps=11621.9, ups=1.39, wpb=8375.7, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.503, clip=0, loss_scale=32, train_wall=71, gb_free=16.9, wall=37872
2023-09-02 06:23:00 | INFO | train_inner | epoch 031:   1099 / 1474 loss=1.895, trans_loss=4.835, nll_loss=2.054, w2v_ctc_loss=0.618, task_loss=4.339, task_loss_gen=6.672, contrastive_loss=0, total=4149.44, n_correct=2819.67, ppl=4.15, accuracy=67.953, wps=11530.5, ups=1.39, wpb=8298.9, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.508, clip=0, loss_scale=32, train_wall=71, gb_free=17.3, wall=37944
2023-09-02 06:24:11 | INFO | train_inner | epoch 031:   1199 / 1474 loss=1.894, trans_loss=4.835, nll_loss=2.055, w2v_ctc_loss=0.62, task_loss=2.748, task_loss_gen=7.454, contrastive_loss=0, total=4189.76, n_correct=2847.49, ppl=4.15, accuracy=67.963, wps=11744.4, ups=1.4, wpb=8379.5, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.503, clip=0, loss_scale=32, train_wall=71, gb_free=12.9, wall=38015
2023-09-02 06:25:23 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.894, trans_loss=4.837, nll_loss=2.057, w2v_ctc_loss=0.621, task_loss=2.313, task_loss_gen=8.068, contrastive_loss=0, total=4227.44, n_correct=2874.32, ppl=4.16, accuracy=67.992, wps=11742.6, ups=1.39, wpb=8454.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.506, clip=0, loss_scale=32, train_wall=71, gb_free=16.1, wall=38087
2023-09-02 06:26:35 | INFO | train_inner | epoch 031:   1399 / 1474 loss=1.897, trans_loss=4.836, nll_loss=2.056, w2v_ctc_loss=0.622, task_loss=2.294, task_loss_gen=9.249, contrastive_loss=0, total=4186.05, n_correct=2841.25, ppl=4.16, accuracy=67.874, wps=11585.8, ups=1.38, wpb=8372.1, bsz=326.6, num_updates=45600, lr=6.62266e-05, gnorm=0.508, clip=0, loss_scale=32, train_wall=72, gb_free=17.2, wall=38160
2023-09-02 06:27:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1299, device='cuda:7')
2023-09-02 06:28:02 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.909 | trans_loss 5.173 | nll_loss 2.434 | w2v_ctc_loss 1.37 | task_loss 24.318 | task_loss_gen 21.792 | contrastive_loss 0 | total 4003.4 | n_correct 2660 | ppl 5.41 | accuracy 66.444 | uer 16.821 | wer 18.679 | raw_wer 18.679 | bleu 22.18 | wps 1627 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 22.35
2023-09-02 06:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-09-02 06:28:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1801.pt
2023-09-02 06:28:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1801.pt
2023-09-02 06:28:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_22.1801.pt (epoch 31 @ 45675 updates, score 22.18) (writing took 8.02851753399591 seconds)
2023-09-02 06:28:10 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-09-02 06:28:10 | INFO | train | epoch 031 | loss 1.898 | trans_loss 4.834 | nll_loss 2.052 | w2v_ctc_loss 0.623 | task_loss 5.142 | task_loss_gen 8.638 | contrastive_loss 0 | total 4138.66 | n_correct 2811.94 | ppl 4.15 | accuracy 67.943 | wps 10950.5 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.513 | clip 0 | loss_scale 32 | train_wall 1052 | gb_free 11.7 | wall 38255
2023-09-02 06:28:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 06:28:11 | INFO | fairseq.trainer | begin training epoch 32
2023-09-02 06:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 06:28:36 | INFO | train_inner | epoch 032:     25 / 1474 loss=1.903, trans_loss=4.834, nll_loss=2.052, w2v_ctc_loss=0.631, task_loss=3.578, task_loss_gen=9.759, contrastive_loss=0, total=4042.6, n_correct=2744.41, ppl=4.15, accuracy=67.887, wps=6703.5, ups=0.83, wpb=8085.2, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=71, gb_free=16, wall=38280
2023-09-02 06:29:48 | INFO | train_inner | epoch 032:    125 / 1474 loss=1.877, trans_loss=4.808, nll_loss=2.019, w2v_ctc_loss=0.6, task_loss=5.173, task_loss_gen=6.624, contrastive_loss=0, total=4227.68, n_correct=2895.29, ppl=4.05, accuracy=68.484, wps=11683.4, ups=1.38, wpb=8455.4, bsz=323.3, num_updates=45800, lr=6.60819e-05, gnorm=0.496, clip=0, loss_scale=32, train_wall=72, gb_free=15.9, wall=38353
2023-09-02 06:31:01 | INFO | train_inner | epoch 032:    225 / 1474 loss=1.89, trans_loss=4.828, nll_loss=2.044, w2v_ctc_loss=0.618, task_loss=4.382, task_loss_gen=6.867, contrastive_loss=0, total=4157.32, n_correct=2832.89, ppl=4.12, accuracy=68.142, wps=11486.5, ups=1.38, wpb=8314.6, bsz=320.6, num_updates=45900, lr=6.60098e-05, gnorm=0.509, clip=0, loss_scale=32, train_wall=72, gb_free=16.9, wall=38425
2023-09-02 06:32:12 | INFO | train_inner | epoch 032:    325 / 1474 loss=1.878, trans_loss=4.808, nll_loss=2.018, w2v_ctc_loss=0.603, task_loss=3.623, task_loss_gen=6.99, contrastive_loss=0, total=4183.45, n_correct=2868.79, ppl=4.05, accuracy=68.575, wps=11685.3, ups=1.4, wpb=8366.9, bsz=314.4, num_updates=46000, lr=6.5938e-05, gnorm=0.504, clip=0, loss_scale=32, train_wall=71, gb_free=17.2, wall=38497
2023-09-02 06:32:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 06:32:45 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.904 | trans_loss 5.174 | nll_loss 2.434 | w2v_ctc_loss 1.355 | task_loss 6.088 | task_loss_gen 25.292 | contrastive_loss 0 | total 4003.4 | n_correct 2665.7 | ppl 5.4 | accuracy 66.586 | uer 16.89 | wer 18.579 | raw_wer 18.579 | bleu 22.46 | wps 1613.4 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.46
2023-09-02 06:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-09-02 06:32:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-09-02 06:32:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-09-02 06:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.46) (writing took 16.25451696300297 seconds)
2023-09-02 06:34:14 | INFO | train_inner | epoch 032:    425 / 1474 loss=1.887, trans_loss=4.817, nll_loss=2.03, w2v_ctc_loss=0.612, task_loss=6.213, task_loss_gen=7.568, contrastive_loss=0, total=4157.28, n_correct=2836.18, ppl=4.08, accuracy=68.222, wps=6796.2, ups=0.82, wpb=8314.6, bsz=305.9, num_updates=46100, lr=6.58665e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=71, gb_free=14.5, wall=38619
2023-09-02 06:35:28 | INFO | train_inner | epoch 032:    525 / 1474 loss=1.899, trans_loss=4.833, nll_loss=2.05, w2v_ctc_loss=0.629, task_loss=4.905, task_loss_gen=7.025, contrastive_loss=0, total=4198.93, n_correct=2852.02, ppl=4.14, accuracy=67.923, wps=11458.6, ups=1.36, wpb=8397.9, bsz=317.6, num_updates=46200, lr=6.57952e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=73, gb_free=17, wall=38692
2023-09-02 06:36:41 | INFO | train_inner | epoch 032:    625 / 1474 loss=1.897, trans_loss=4.831, nll_loss=2.048, w2v_ctc_loss=0.623, task_loss=4.646, task_loss_gen=7.394, contrastive_loss=0, total=4142.69, n_correct=2813.18, ppl=4.13, accuracy=67.907, wps=11386.1, ups=1.37, wpb=8285.4, bsz=301.6, num_updates=46300, lr=6.57241e-05, gnorm=0.51, clip=0, loss_scale=32, train_wall=72, gb_free=17, wall=38765
2023-09-02 06:37:54 | INFO | train_inner | epoch 032:    725 / 1474 loss=1.896, trans_loss=4.829, nll_loss=2.046, w2v_ctc_loss=0.624, task_loss=4.125, task_loss_gen=7.373, contrastive_loss=0, total=4154.59, n_correct=2829.85, ppl=4.13, accuracy=68.114, wps=11381.5, ups=1.37, wpb=8309.2, bsz=301.8, num_updates=46400, lr=6.56532e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=72, gb_free=15.6, wall=38838
2023-09-02 06:39:06 | INFO | train_inner | epoch 032:    825 / 1474 loss=1.891, trans_loss=4.823, nll_loss=2.038, w2v_ctc_loss=0.614, task_loss=3.835, task_loss_gen=7.498, contrastive_loss=0, total=4114.54, n_correct=2806.26, ppl=4.11, accuracy=68.203, wps=11435.4, ups=1.39, wpb=8229.1, bsz=294.9, num_updates=46500, lr=6.55826e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=71, gb_free=16.8, wall=38910
2023-09-02 06:40:18 | INFO | train_inner | epoch 032:    925 / 1474 loss=1.894, trans_loss=4.826, nll_loss=2.043, w2v_ctc_loss=0.617, task_loss=3.852, task_loss_gen=7.67, contrastive_loss=0, total=4139.67, n_correct=2819.09, ppl=4.12, accuracy=68.099, wps=11474.9, ups=1.39, wpb=8279.3, bsz=298.3, num_updates=46600, lr=6.55122e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=72, gb_free=16.6, wall=38982
2023-09-02 06:41:30 | INFO | train_inner | epoch 032:   1025 / 1474 loss=1.894, trans_loss=4.829, nll_loss=2.046, w2v_ctc_loss=0.62, task_loss=3.323, task_loss_gen=7.917, contrastive_loss=0, total=4119.15, n_correct=2805.48, ppl=4.13, accuracy=68.108, wps=11403.5, ups=1.38, wpb=8238.3, bsz=304.5, num_updates=46700, lr=6.5442e-05, gnorm=0.504, clip=0, loss_scale=64, train_wall=72, gb_free=16.2, wall=39054
2023-09-02 06:42:43 | INFO | train_inner | epoch 032:   1125 / 1474 loss=1.901, trans_loss=4.829, nll_loss=2.044, w2v_ctc_loss=0.624, task_loss=3.24, task_loss_gen=10.52, contrastive_loss=0, total=4019.61, n_correct=2733.41, ppl=4.12, accuracy=68.002, wps=11052.9, ups=1.37, wpb=8039.2, bsz=271.4, num_updates=46800, lr=6.5372e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=72, gb_free=17.4, wall=39127
2023-09-02 06:43:55 | INFO | train_inner | epoch 032:   1225 / 1474 loss=1.898, trans_loss=4.836, nll_loss=2.056, w2v_ctc_loss=0.622, task_loss=2.771, task_loss_gen=8.134, contrastive_loss=0, total=4149.28, n_correct=2814.07, ppl=4.16, accuracy=67.821, wps=11454.2, ups=1.38, wpb=8298.6, bsz=310.3, num_updates=46900, lr=6.53023e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=72, gb_free=15.6, wall=39200
2023-09-02 06:45:07 | INFO | train_inner | epoch 032:   1325 / 1474 loss=1.893, trans_loss=4.824, nll_loss=2.04, w2v_ctc_loss=0.62, task_loss=2.39, task_loss_gen=9.755, contrastive_loss=0, total=4079.22, n_correct=2780.02, ppl=4.11, accuracy=68.151, wps=11401.6, ups=1.4, wpb=8158.4, bsz=296.2, num_updates=47000, lr=6.52328e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=71, gb_free=14.8, wall=39271
2023-09-02 06:46:19 | INFO | train_inner | epoch 032:   1425 / 1474 loss=1.896, trans_loss=4.826, nll_loss=2.042, w2v_ctc_loss=0.625, task_loss=1.874, task_loss_gen=11.265, contrastive_loss=0, total=4111.41, n_correct=2797.76, ppl=4.12, accuracy=68.049, wps=11444.4, ups=1.39, wpb=8222.8, bsz=306.1, num_updates=47100, lr=6.51635e-05, gnorm=0.512, clip=0, loss_scale=64, train_wall=71, gb_free=15.7, wall=39343
2023-09-02 06:46:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 06:47:27 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.895 | trans_loss 5.169 | nll_loss 2.429 | w2v_ctc_loss 1.336 | task_loss 6.649 | task_loss_gen 38.837 | contrastive_loss 0 | total 4003.4 | n_correct 2663.3 | ppl 5.38 | accuracy 66.526 | uer 16.893 | wer 18.709 | raw_wer 18.709 | bleu 21.96 | wps 1567.2 | wpb 4003.4 | bsz 141.8 | num_updates 47149 | best_bleu 22.46
2023-09-02 06:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47149 updates
2023-09-02 06:47:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.9609.pt
2023-09-02 06:47:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.9609.pt
2023-09-02 06:47:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint.best_bleu_21.9609.pt (epoch 32 @ 47149 updates, score 21.96) (writing took 8.413777334004408 seconds)
2023-09-02 06:47:36 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-09-02 06:47:36 | INFO | train | epoch 032 | loss 1.892 | trans_loss 4.825 | nll_loss 2.04 | w2v_ctc_loss 0.618 | task_loss 3.82 | task_loss_gen 8.113 | contrastive_loss 0 | total 4138.65 | n_correct 2819.83 | ppl 4.11 | accuracy 68.134 | wps 10470.5 | ups 1.26 | wpb 8277.3 | bsz 305.7 | num_updates 47149 | lr 6.51297e-05 | gnorm 0.51 | clip 0 | loss_scale 64 | train_wall 1054 | gb_free 16.2 | wall 39420
2023-09-02 06:47:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 06:47:36 | INFO | fairseq.trainer | begin training epoch 33
2023-09-02 06:47:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 06:48:21 | INFO | train_inner | epoch 033:     51 / 1474 loss=1.883, trans_loss=4.82, nll_loss=2.034, w2v_ctc_loss=0.608, task_loss=1.438, task_loss_gen=12.346, contrastive_loss=0, total=4156.71, n_correct=2838.88, ppl=4.1, accuracy=68.296, wps=6786.7, ups=0.82, wpb=8313.4, bsz=322.5, num_updates=47200, lr=6.50945e-05, gnorm=0.501, clip=0, loss_scale=64, train_wall=71, gb_free=16.2, wall=39466
2023-09-02 06:49:33 | INFO | train_inner | epoch 033:    151 / 1474 loss=1.879, trans_loss=4.803, nll_loss=2.012, w2v_ctc_loss=0.598, task_loss=1.533, task_loss_gen=15.824, contrastive_loss=0, total=4071.44, n_correct=2794.14, ppl=4.03, accuracy=68.628, wps=11279.8, ups=1.39, wpb=8142.9, bsz=284.1, num_updates=47300, lr=6.50256e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=72, gb_free=15.9, wall=39538
2023-09-02 06:50:45 | INFO | train_inner | epoch 033:    251 / 1474 loss=1.876, trans_loss=4.806, nll_loss=2.017, w2v_ctc_loss=0.605, task_loss=1.027, task_loss_gen=13.384, contrastive_loss=0, total=4281.28, n_correct=2932.14, ppl=4.05, accuracy=68.487, wps=11859.1, ups=1.38, wpb=8562.6, bsz=346.3, num_updates=47400, lr=6.4957e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=72, gb_free=16.2, wall=39610
2023-09-02 06:51:58 | INFO | train_inner | epoch 033:    351 / 1474 loss=1.889, trans_loss=4.815, nll_loss=2.027, w2v_ctc_loss=0.618, task_loss=2.054, task_loss_gen=10.905, contrastive_loss=0, total=4111.69, n_correct=2809.83, ppl=4.08, accuracy=68.338, wps=11384.4, ups=1.38, wpb=8223.4, bsz=298.4, num_updates=47500, lr=6.48886e-05, gnorm=0.515, clip=0, loss_scale=64, train_wall=71, gb_free=16.6, wall=39682
2023-09-02 06:53:09 | INFO | train_inner | epoch 033:    451 / 1474 loss=1.874, trans_loss=4.802, nll_loss=2.011, w2v_ctc_loss=0.602, task_loss=1.915, task_loss_gen=10.374, contrastive_loss=0, total=4147.28, n_correct=2849.54, ppl=4.03, accuracy=68.709, wps=11664, ups=1.41, wpb=8294.6, bsz=313.5, num_updates=47600, lr=6.48204e-05, gnorm=0.503, clip=0, loss_scale=64, train_wall=70, gb_free=16.3, wall=39753
2023-09-02 06:54:21 | INFO | train_inner | epoch 033:    551 / 1474 loss=1.89, trans_loss=4.816, nll_loss=2.027, w2v_ctc_loss=0.616, task_loss=2.363, task_loss_gen=11.452, contrastive_loss=0, total=4127.68, n_correct=2815.19, ppl=4.08, accuracy=68.203, wps=11399.8, ups=1.38, wpb=8255.4, bsz=292.6, num_updates=47700, lr=6.47524e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=72, gb_free=15.3, wall=39826
2023-09-02 06:55:34 | INFO | train_inner | epoch 033:    651 / 1474 loss=1.892, trans_loss=4.828, nll_loss=2.044, w2v_ctc_loss=0.612, task_loss=2.691, task_loss_gen=10.386, contrastive_loss=0, total=4164.1, n_correct=2834.5, ppl=4.12, accuracy=68.07, wps=11485.6, ups=1.38, wpb=8328.2, bsz=302.4, num_updates=47800, lr=6.46846e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=72, gb_free=15.1, wall=39898
2023-09-02 06:56:46 | INFO | train_inner | epoch 033:    751 / 1474 loss=1.901, trans_loss=4.825, nll_loss=2.04, w2v_ctc_loss=0.633, task_loss=2.259, task_loss_gen=11.71, contrastive_loss=0, total=4064.29, n_correct=2766.68, ppl=4.11, accuracy=68.073, wps=11285, ups=1.39, wpb=8128.6, bsz=285.8, num_updates=47900, lr=6.46171e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=71, gb_free=16.3, wall=39970
2023-09-02 06:57:58 | INFO | train_inner | epoch 033:    851 / 1474 loss=1.88, trans_loss=4.813, nll_loss=2.026, w2v_ctc_loss=0.605, task_loss=1.728, task_loss_gen=10.974, contrastive_loss=0, total=4141.12, n_correct=2835.55, ppl=4.07, accuracy=68.473, wps=11499.6, ups=1.39, wpb=8282.2, bsz=318.5, num_updates=48000, lr=6.45497e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=71, gb_free=16.4, wall=40042
2023-09-02 06:57:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 06:58:31 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.896 | trans_loss 5.176 | nll_loss 2.436 | w2v_ctc_loss 1.324 | task_loss 11.155 | task_loss_gen 26.976 | contrastive_loss 0 | total 4003.4 | n_correct 2657.3 | ppl 5.41 | accuracy 66.376 | uer 16.776 | wer 18.433 | raw_wer 18.433 | bleu 21.84 | wps 1641.9 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.46
2023-09-02 06:58:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-09-02 06:58:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-09-02 06:58:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-09-02 06:58:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 21.84) (writing took 7.953749536012765 seconds)
2023-09-02 06:59:51 | INFO | train_inner | epoch 033:    951 / 1474 loss=1.888, trans_loss=4.816, nll_loss=2.029, w2v_ctc_loss=0.618, task_loss=2.168, task_loss_gen=11.369, contrastive_loss=0, total=4147.76, n_correct=2834.11, ppl=4.08, accuracy=68.329, wps=7329, ups=0.88, wpb=8295.5, bsz=308.2, num_updates=48100, lr=6.44826e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=71, gb_free=17.3, wall=40156
2023-09-02 07:01:04 | INFO | train_inner | epoch 033:   1051 / 1474 loss=1.891, trans_loss=4.817, nll_loss=2.03, w2v_ctc_loss=0.618, task_loss=6.017, task_loss_gen=9.906, contrastive_loss=0, total=4137.41, n_correct=2819.35, ppl=4.08, accuracy=68.143, wps=11359.8, ups=1.37, wpb=8274.8, bsz=307.9, num_updates=48200, lr=6.44157e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=72, gb_free=15.6, wall=40228
2023-09-02 07:02:17 | INFO | train_inner | epoch 033:   1151 / 1474 loss=1.89, trans_loss=4.827, nll_loss=2.044, w2v_ctc_loss=0.61, task_loss=5.682, task_loss_gen=8.337, contrastive_loss=0, total=4182.88, n_correct=2847.14, ppl=4.12, accuracy=68.066, wps=11473.2, ups=1.37, wpb=8365.8, bsz=308.6, num_updates=48300, lr=6.43489e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=72, gb_free=16, wall=40301
2023-09-02 07:03:29 | INFO | train_inner | epoch 033:   1251 / 1474 loss=1.892, trans_loss=4.819, nll_loss=2.032, w2v_ctc_loss=0.618, task_loss=5.844, task_loss_gen=9.015, contrastive_loss=0, total=4102.27, n_correct=2799.48, ppl=4.09, accuracy=68.242, wps=11363.9, ups=1.39, wpb=8204.5, bsz=291.8, num_updates=48400, lr=6.42824e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=71, gb_free=15.4, wall=40374
2023-09-02 07:04:42 | INFO | train_inner | epoch 033:   1351 / 1474 loss=1.886, trans_loss=4.82, nll_loss=2.034, w2v_ctc_loss=0.616, task_loss=4.731, task_loss_gen=8.112, contrastive_loss=0, total=4131.08, n_correct=2824.58, ppl=4.09, accuracy=68.374, wps=11334.1, ups=1.37, wpb=8262.2, bsz=313.9, num_updates=48500, lr=6.42161e-05, gnorm=0.508, clip=0, loss_scale=64, train_wall=72, gb_free=16.9, wall=40446
2023-09-02 07:05:54 | INFO | train_inner | epoch 033:   1451 / 1474 loss=1.886, trans_loss=4.819, nll_loss=2.034, w2v_ctc_loss=0.608, task_loss=3.014, task_loss_gen=8.782, contrastive_loss=0, total=4135.49, n_correct=2819.08, ppl=4.09, accuracy=68.168, wps=11460.8, ups=1.39, wpb=8271, bsz=310.7, num_updates=48600, lr=6.415e-05, gnorm=0.515, clip=0, loss_scale=64, train_wall=71, gb_free=15.8, wall=40519
2023-09-02 07:06:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 07:06:45 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.885 | trans_loss 5.168 | nll_loss 2.422 | w2v_ctc_loss 1.304 | task_loss 13.537 | task_loss_gen 22.335 | contrastive_loss 0 | total 4003.4 | n_correct 2665.2 | ppl 5.36 | accuracy 66.573 | uer 16.67 | wer 18.34 | raw_wer 18.34 | bleu 22.47 | wps 1507.6 | wpb 4003.4 | bsz 141.8 | num_updates 48623 | best_bleu 22.47
2023-09-02 07:06:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48623 updates
2023-09-02 07:06:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 07:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt
2023-09-02 07:06:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_best.pt (epoch 33 @ 48623 updates, score 22.47) (writing took 13.988713886996266 seconds)
2023-09-02 07:06:59 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-09-02 07:06:59 | INFO | train | epoch 033 | loss 1.887 | trans_loss 4.816 | nll_loss 2.029 | w2v_ctc_loss 0.613 | task_loss 2.997 | task_loss_gen 10.824 | contrastive_loss 0 | total 4138.65 | n_correct 2827.04 | ppl 4.08 | accuracy 68.308 | wps 10488.7 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 48623 | lr 6.41349e-05 | gnorm 0.512 | clip 0 | loss_scale 64 | train_wall 1054 | gb_free 17.6 | wall 40583
2023-09-02 07:06:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-09-02 07:06:59 | INFO | fairseq.trainer | begin training epoch 34
2023-09-02 07:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-02 07:07:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-09-02 07:08:03 | INFO | train_inner | epoch 034:     78 / 1474 loss=1.881, trans_loss=4.806, nll_loss=2.017, w2v_ctc_loss=0.608, task_loss=2.752, task_loss_gen=9.237, contrastive_loss=0, total=4117.19, n_correct=2819.74, ppl=4.05, accuracy=68.487, wps=6392.5, ups=0.78, wpb=8234.4, bsz=300.4, num_updates=48700, lr=6.40841e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=72, gb_free=14.9, wall=40647
2023-09-02 07:09:15 | INFO | train_inner | epoch 034:    178 / 1474 loss=1.876, trans_loss=4.794, nll_loss=2, w2v_ctc_loss=0.605, task_loss=3.287, task_loss_gen=9.56, contrastive_loss=0, total=4071.22, n_correct=2802.68, ppl=4, accuracy=68.841, wps=11228.9, ups=1.38, wpb=8142.4, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=72, gb_free=15.2, wall=40720
2023-09-02 07:10:28 | INFO | train_inner | epoch 034:    278 / 1474 loss=1.883, trans_loss=4.814, nll_loss=2.026, w2v_ctc_loss=0.607, task_loss=3.887, task_loss_gen=7.76, contrastive_loss=0, total=4237.89, n_correct=2895.39, ppl=4.07, accuracy=68.321, wps=11710.7, ups=1.38, wpb=8475.8, bsz=326.9, num_updates=48900, lr=6.39529e-05, gnorm=0.507, clip=0, loss_scale=64, train_wall=72, gb_free=10, wall=40792
2023-09-02 07:11:40 | INFO | train_inner | epoch 034:    378 / 1474 loss=1.871, trans_loss=4.795, nll_loss=2.002, w2v_ctc_loss=0.597, task_loss=2.764, task_loss_gen=8.622, contrastive_loss=0, total=4167, n_correct=2866.25, ppl=4, accuracy=68.784, wps=11528, ups=1.38, wpb=8334, bsz=319, num_updates=49000, lr=6.38877e-05, gnorm=0.509, clip=0, loss_scale=64, train_wall=72, gb_free=17, wall=40865
2023-09-02 07:12:52 | INFO | train_inner | epoch 034:    478 / 1474 loss=1.884, trans_loss=4.806, nll_loss=2.015, w2v_ctc_loss=0.611, task_loss=1.874, task_loss_gen=12.332, contrastive_loss=0, total=4071.65, n_correct=2787.1, ppl=4.04, accuracy=68.451, wps=11280.8, ups=1.39, wpb=8143.3, bsz=284.8, num_updates=49100, lr=6.38226e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=72, gb_free=11.1, wall=40937
2023-09-02 07:14:04 | INFO | train_inner | epoch 034:    578 / 1474 loss=1.875, trans_loss=4.794, nll_loss=1.999, w2v_ctc_loss=0.602, task_loss=1.406, task_loss_gen=13.655, contrastive_loss=0, total=4110.13, n_correct=2825.27, ppl=4, accuracy=68.739, wps=11499.4, ups=1.4, wpb=8220.3, bsz=299, num_updates=49200, lr=6.37577e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=71, gb_free=16.4, wall=41008
2023-09-02 07:15:15 | INFO | train_inner | epoch 034:    678 / 1474 loss=1.879, trans_loss=4.804, nll_loss=2.014, w2v_ctc_loss=0.604, task_loss=1.504, task_loss_gen=14.862, contrastive_loss=0, total=4128.65, n_correct=2832.85, ppl=4.04, accuracy=68.614, wps=11525.3, ups=1.4, wpb=8257.3, bsz=300.7, num_updates=49300, lr=6.3693e-05, gnorm=0.511, clip=0, loss_scale=64, train_wall=71, gb_free=17.5, wall=41080
2023-09-02 07:16:28 | INFO | train_inner | epoch 034:    778 / 1474 loss=1.885, trans_loss=4.821, nll_loss=2.034, w2v_ctc_loss=0.601, task_loss=1.44, task_loss_gen=17.042, contrastive_loss=0, total=4075.69, n_correct=2781.93, ppl=4.1, accuracy=68.257, wps=11293.2, ups=1.39, wpb=8151.4, bsz=294.5, num_updates=49400, lr=6.36285e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=71, gb_free=17, wall=41152
2023-09-02 07:17:40 | INFO | train_inner | epoch 034:    878 / 1474 loss=1.886, trans_loss=4.813, nll_loss=2.025, w2v_ctc_loss=0.611, task_loss=1.621, task_loss_gen=16.673, contrastive_loss=0, total=4104.97, n_correct=2808.19, ppl=4.07, accuracy=68.41, wps=11287.9, ups=1.37, wpb=8209.9, bsz=296.3, num_updates=49500, lr=6.35642e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=72, gb_free=17.5, wall=41225
2023-09-02 07:18:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-02 07:18:53 | INFO | train_inner | epoch 034:    979 / 1474 loss=1.885, trans_loss=4.812, nll_loss=2.024, w2v_ctc_loss=0.615, task_loss=2.367, task_loss_gen=10.481, contrastive_loss=0, total=4166.27, n_correct=2847.99, ppl=4.07, accuracy=68.358, wps=11416.6, ups=1.37, wpb=8332.5, bsz=312.4, num_updates=49600, lr=6.35001e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=72, gb_free=15.6, wall=41298
2023-09-02 07:20:05 | INFO | train_inner | epoch 034:   1079 / 1474 loss=1.885, trans_loss=4.814, nll_loss=2.026, w2v_ctc_loss=0.61, task_loss=5.859, task_loss_gen=8.565, contrastive_loss=0, total=4150.57, n_correct=2839.69, ppl=4.07, accuracy=68.417, wps=11640, ups=1.4, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=71, gb_free=16.5, wall=41369
2023-09-02 07:21:17 | INFO | train_inner | epoch 034:   1179 / 1474 loss=1.89, trans_loss=4.821, nll_loss=2.034, w2v_ctc_loss=0.611, task_loss=7.743, task_loss_gen=8.624, contrastive_loss=0, total=4098.77, n_correct=2796.31, ppl=4.1, accuracy=68.223, wps=11300.6, ups=1.38, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=72, gb_free=16.6, wall=41442
2023-09-02 07:22:29 | INFO | train_inner | epoch 034:   1279 / 1474 loss=1.889, trans_loss=4.816, nll_loss=2.028, w2v_ctc_loss=0.614, task_loss=11.649, task_loss_gen=9.9, contrastive_loss=0, total=4150.54, n_correct=2831.83, ppl=4.08, accuracy=68.228, wps=11533, ups=1.39, wpb=8301.1, bsz=301, num_updates=49900, lr=6.33089e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=71, gb_free=16.9, wall=41514
2023-09-02 07:23:42 | INFO | train_inner | epoch 034:   1379 / 1474 loss=1.891, trans_loss=4.824, nll_loss=2.039, w2v_ctc_loss=0.619, task_loss=12.148, task_loss_gen=9.527, contrastive_loss=0, total=4196.91, n_correct=2858.45, ppl=4.11, accuracy=68.108, wps=11488.6, ups=1.37, wpb=8393.8, bsz=321.4, num_updates=50000, lr=6.32456e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=72, gb_free=15.8, wall=41587
2023-09-02 07:23:42 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-09-02 07:23:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-02 07:24:15 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.885 | trans_loss 5.17 | nll_loss 2.426 | w2v_ctc_loss 1.298 | task_loss 40.522 | task_loss_gen 30.747 | contrastive_loss 0 | total 4003.4 | n_correct 2661.7 | ppl 5.37 | accuracy 66.486 | uer 16.664 | wer 18.571 | raw_wer 18.571 | bleu 21.88 | wps 1647.3 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.47
2023-09-02 07:24:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-09-02 07:24:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-09-02 07:24:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-09-02 07:24:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_v3_merge_wmt_0901_shrink_soft_noCL_AT_sentence_scale3.5_alpha1.5_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 21.88) (writing took 8.15108339197468 seconds)
2023-09-02 07:24:23 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-09-02 07:24:23 | INFO | train | epoch 034 | loss 1.883 | trans_loss 4.81 | nll_loss 2.02 | w2v_ctc_loss 0.608 | task_loss 4.382 | task_loss_gen 11.176 | contrastive_loss 0 | total 4132.5 | n_correct 2828.61 | ppl 4.06 | accuracy 68.448 | wps 10896.8 | ups 1.32 | wpb 8265 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.518 | clip 0 | loss_scale 32 | train_wall 985 | gb_free 15.8 | wall 41628
2023-09-02 07:24:23 | INFO | fairseq_cli.train | done training in 41583.8 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
