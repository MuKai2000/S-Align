2023-08-23 13:24:06 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:14689
2023-08-23 13:24:06 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:14689
2023-08-23 13:24:06 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:14689
2023-08-23 13:24:06 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:14689
2023-08-23 13:24:06 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:14689
2023-08-23 13:24:06 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:14689
2023-08-23 13:24:06 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:14689
2023-08-23 13:24:06 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:14689
2023-08-23 13:24:06 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 13:24:07 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 13:24:07 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-23 13:24:07 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 13:24:07 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-23 13:24:07 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 13:24:07 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 13:24:07 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-23 13:24:07 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 13:24:07 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-23 13:24:10 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14689', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 12000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 12000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=12000, max_tokens_valid=12000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=12000, max_tokens_valid=12000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=12000, max_tokens_valid=12000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-23 13:24:10 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-23 13:24:10 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-23 13:24:10 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-23 13:24:10 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-23 13:24:10 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-23 13:24:15 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-23 13:24:15 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-23 13:24:15 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-23 13:24:16 | INFO | root | load pretrained hubert
2023-08-23 13:24:24 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-23 13:24:27 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-23 13:24:34 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-23 13:24:34 | INFO | root | share the sematic adapter and textual encoder
2023-08-23 13:24:34 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-23 13:24:34 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-23 13:24:34 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-23 13:24:34 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-23 13:24:34 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-23 13:24:34 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-23 13:24:34 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-23 13:24:34 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 13:24:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 13:24:34 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-23 13:24:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-23 13:24:50 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-23 13:24:50 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-23 13:24:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-23 13:24:50 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 13:24:50 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 13:24:50 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 13:24:50 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 13:24:50 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 13:24:50 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 13:24:50 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 13:24:50 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 13:24:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-23 13:24:50 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-23 13:24:50 | INFO | fairseq_cli.train | max tokens per device = 12000 and max sentences per device = None
2023-08-23 13:24:50 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-23 13:24:50 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-23 13:24:50 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-23 13:24:50 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-23 13:24:50 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 13:24:50 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 13:24:52 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-23 13:24:54 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-23 13:25:44 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-23 13:25:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-23 13:25:45 | INFO | fairseq.trainer | begin training epoch 1
2023-08-23 13:25:45 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
2023-08-23 13:25:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
2023-08-23 13:27:06 | INFO | train_inner | epoch 001:    101 / 1080 loss=16.445, trans_loss=5.224, nll_loss=3.728, w2v_ctc_loss=21.447, task_loss=2.848, contrastive_loss=0, total=7409.67, n_correct=545.67, ppl=13.25, accuracy=7.364, wps=31814.4, ups=1.48, wpb=21465.9, bsz=753.4, num_updates=100, lr=4.098e-06, gnorm=1.282, clip=0, loss_scale=64, train_wall=73, gb_free=18.1, wall=136
2023-08-23 13:27:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 13:28:13 | INFO | train_inner | epoch 001:    202 / 1080 loss=14.049, trans_loss=5.233, nll_loss=3.792, w2v_ctc_loss=17.733, task_loss=2.541, contrastive_loss=0, total=7504.3, n_correct=539.21, ppl=13.86, accuracy=7.185, wps=32222.6, ups=1.48, wpb=21748.4, bsz=779.8, num_updates=200, lr=8.096e-06, gnorm=4.822, clip=3, loss_scale=32, train_wall=67, gb_free=18.8, wall=203
2023-08-23 13:29:22 | INFO | train_inner | epoch 001:    302 / 1080 loss=7.186, trans_loss=5.617, nll_loss=4.289, w2v_ctc_loss=6.761, task_loss=2.46, contrastive_loss=0, total=7459.07, n_correct=386.9, ppl=19.54, accuracy=5.187, wps=31729.9, ups=1.47, wpb=21610.4, bsz=752.2, num_updates=300, lr=1.2094e-05, gnorm=2.223, clip=0, loss_scale=32, train_wall=67, gb_free=18.2, wall=271
2023-08-23 13:30:28 | INFO | train_inner | epoch 001:    402 / 1080 loss=6.5, trans_loss=5.544, nll_loss=4.219, w2v_ctc_loss=5.782, task_loss=2.278, contrastive_loss=0, total=7435.1, n_correct=389.97, ppl=18.62, accuracy=5.245, wps=32293.5, ups=1.5, wpb=21542, bsz=760.6, num_updates=400, lr=1.6092e-05, gnorm=0.6, clip=0, loss_scale=32, train_wall=66, gb_free=18.3, wall=338
2023-08-23 13:31:35 | INFO | train_inner | epoch 001:    502 / 1080 loss=6.314, trans_loss=5.515, nll_loss=4.194, w2v_ctc_loss=5.528, task_loss=2.214, contrastive_loss=0, total=7411.84, n_correct=388.45, ppl=18.3, accuracy=5.241, wps=32097.4, ups=1.5, wpb=21462.7, bsz=747.1, num_updates=500, lr=2.009e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=66, gb_free=17.4, wall=405
2023-08-23 13:32:42 | INFO | train_inner | epoch 001:    602 / 1080 loss=6.189, trans_loss=5.498, nll_loss=4.181, w2v_ctc_loss=5.353, task_loss=2.057, contrastive_loss=0, total=7432.59, n_correct=420.55, ppl=18.14, accuracy=5.658, wps=32002.1, ups=1.49, wpb=21533.7, bsz=764.2, num_updates=600, lr=2.4088e-05, gnorm=0.241, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=472
2023-08-23 13:33:49 | INFO | train_inner | epoch 001:    702 / 1080 loss=6.139, trans_loss=5.538, nll_loss=4.231, w2v_ctc_loss=5.228, task_loss=2.075, contrastive_loss=0, total=7378.17, n_correct=417.67, ppl=18.78, accuracy=5.661, wps=32030.9, ups=1.5, wpb=21364.1, bsz=727.9, num_updates=700, lr=2.8086e-05, gnorm=0.231, clip=0, loss_scale=32, train_wall=66, gb_free=18.4, wall=539
2023-08-23 13:34:56 | INFO | train_inner | epoch 001:    802 / 1080 loss=5.966, trans_loss=5.584, nll_loss=4.288, w2v_ctc_loss=4.918, task_loss=2.063, contrastive_loss=0, total=7328.32, n_correct=409.15, ppl=19.54, accuracy=5.583, wps=31937.3, ups=1.5, wpb=21239, bsz=743.3, num_updates=800, lr=3.2084e-05, gnorm=0.275, clip=0, loss_scale=32, train_wall=66, gb_free=17.4, wall=605
2023-08-23 13:36:03 | INFO | train_inner | epoch 001:    902 / 1080 loss=5.749, trans_loss=5.62, nll_loss=4.33, w2v_ctc_loss=4.542, task_loss=2.026, contrastive_loss=0, total=7419.88, n_correct=392.44, ppl=20.11, accuracy=5.289, wps=31815.9, ups=1.48, wpb=21507.8, bsz=732.5, num_updates=900, lr=3.6082e-05, gnorm=0.376, clip=0, loss_scale=32, train_wall=67, gb_free=17.4, wall=673
2023-08-23 13:37:10 | INFO | train_inner | epoch 001:   1002 / 1080 loss=5.515, trans_loss=5.637, nll_loss=4.347, w2v_ctc_loss=4.165, task_loss=2.08, contrastive_loss=0, total=7280.02, n_correct=402.92, ppl=20.35, accuracy=5.535, wps=31775.7, ups=1.51, wpb=21097.8, bsz=731, num_updates=1000, lr=4.008e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=66, gb_free=19.2, wall=739
2023-08-23 13:38:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-23 13:38:50 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.586 | trans_loss 11.847 | nll_loss 11.066 | w2v_ctc_loss 5.189 | task_loss 13.338 | contrastive_loss 0 | total 6138.43 | n_correct 391.429 | ppl 2143.64 | accuracy 6.377 | uer 71.489 | wer 68.907 | raw_wer 68.907 | bleu 0 | wps 981.7 | wpb 6138.4 | bsz 201.1 | num_updates 1078
2023-08-23 13:38:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1078 updates
2023-08-23 13:38:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 13:38:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 13:38:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 1 @ 1078 updates, score 0.0) (writing took 4.266992068965919 seconds)
2023-08-23 13:38:55 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-23 13:38:55 | INFO | train | epoch 001 | loss 7.831 | trans_loss 5.51 | nll_loss 4.173 | w2v_ctc_loss 7.867 | task_loss 2.249 | contrastive_loss 0 | total 7394.12 | n_correct 428.686 | ppl 18.03 | accuracy 5.798 | wps 29745.1 | ups 1.39 | wpb 21423 | bsz 748.3 | num_updates 1078 | lr 4.31984e-05 | gnorm 1.049 | clip 0.3 | loss_scale 32 | train_wall 721 | gb_free 17.9 | wall 845
2023-08-23 13:38:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-23 13:38:55 | INFO | fairseq.trainer | begin training epoch 2
2023-08-23 13:38:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 13:39:17 | INFO | train_inner | epoch 002:     22 / 1080 loss=5.342, trans_loss=5.638, nll_loss=4.348, w2v_ctc_loss=3.897, task_loss=1.998, contrastive_loss=0, total=7314.48, n_correct=422.05, ppl=20.36, accuracy=5.77, wps=16615.3, ups=0.78, wpb=21197.6, bsz=743.5, num_updates=1100, lr=4.4078e-05, gnorm=0.488, clip=0, loss_scale=32, train_wall=65, gb_free=18.6, wall=867
2023-08-23 13:40:23 | INFO | train_inner | epoch 002:    122 / 1080 loss=5.212, trans_loss=5.657, nll_loss=4.367, w2v_ctc_loss=3.675, task_loss=2.028, contrastive_loss=0, total=7345.47, n_correct=410.4, ppl=20.64, accuracy=5.587, wps=32228.2, ups=1.51, wpb=21279.4, bsz=738.2, num_updates=1200, lr=4.8076e-05, gnorm=0.479, clip=0, loss_scale=32, train_wall=65, gb_free=17.5, wall=933
2023-08-23 13:41:30 | INFO | train_inner | epoch 002:    222 / 1080 loss=5.093, trans_loss=5.677, nll_loss=4.389, w2v_ctc_loss=3.477, task_loss=1.964, contrastive_loss=0, total=7470.55, n_correct=407.53, ppl=20.95, accuracy=5.455, wps=32468.5, ups=1.5, wpb=21635.4, bsz=758.2, num_updates=1300, lr=5.2074e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=66, gb_free=17.4, wall=1000
2023-08-23 13:42:37 | INFO | train_inner | epoch 002:    322 / 1080 loss=5.004, trans_loss=5.688, nll_loss=4.402, w2v_ctc_loss=3.324, task_loss=2.023, contrastive_loss=0, total=7343.08, n_correct=390.47, ppl=21.14, accuracy=5.318, wps=31623.4, ups=1.49, wpb=21292.3, bsz=745.7, num_updates=1400, lr=5.6072e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=67, gb_free=19, wall=1067
2023-08-23 13:43:44 | INFO | train_inner | epoch 002:    422 / 1080 loss=4.907, trans_loss=5.703, nll_loss=4.419, w2v_ctc_loss=3.164, task_loss=1.926, contrastive_loss=0, total=7453.47, n_correct=377.37, ppl=21.39, accuracy=5.063, wps=32430.5, ups=1.5, wpb=21588.2, bsz=759.4, num_updates=1500, lr=6.007e-05, gnorm=0.636, clip=0, loss_scale=32, train_wall=66, gb_free=18.1, wall=1134
2023-08-23 13:44:50 | INFO | train_inner | epoch 002:    522 / 1080 loss=4.863, trans_loss=5.715, nll_loss=4.435, w2v_ctc_loss=3.079, task_loss=2.171, contrastive_loss=0, total=7267.37, n_correct=366.13, ppl=21.63, accuracy=5.038, wps=31966.4, ups=1.52, wpb=21068.5, bsz=708, num_updates=1600, lr=6.4068e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=65, gb_free=18.6, wall=1200
2023-08-23 13:45:56 | INFO | train_inner | epoch 002:    622 / 1080 loss=4.77, trans_loss=5.72, nll_loss=4.438, w2v_ctc_loss=2.937, task_loss=1.955, contrastive_loss=0, total=7405.49, n_correct=370.66, ppl=21.68, accuracy=5.005, wps=32462.3, ups=1.51, wpb=21448.5, bsz=756.5, num_updates=1700, lr=6.8066e-05, gnorm=0.615, clip=0, loss_scale=32, train_wall=65, gb_free=17.4, wall=1266
2023-08-23 13:47:02 | INFO | train_inner | epoch 002:    722 / 1080 loss=4.722, trans_loss=5.729, nll_loss=4.447, w2v_ctc_loss=2.855, task_loss=1.999, contrastive_loss=0, total=7454.7, n_correct=376.57, ppl=21.81, accuracy=5.051, wps=32423.9, ups=1.5, wpb=21582.6, bsz=756.7, num_updates=1800, lr=7.2064e-05, gnorm=0.682, clip=0, loss_scale=32, train_wall=66, gb_free=18.1, wall=1332
2023-08-23 13:48:09 | INFO | train_inner | epoch 002:    822 / 1080 loss=4.652, trans_loss=5.725, nll_loss=4.442, w2v_ctc_loss=2.753, task_loss=2.028, contrastive_loss=0, total=7401.5, n_correct=365.76, ppl=21.74, accuracy=4.942, wps=32265.7, ups=1.51, wpb=21434.5, bsz=748.8, num_updates=1900, lr=7.6062e-05, gnorm=0.611, clip=0, loss_scale=32, train_wall=66, gb_free=17.4, wall=1399
2023-08-23 13:49:16 | INFO | train_inner | epoch 002:    922 / 1080 loss=4.626, trans_loss=5.733, nll_loss=4.455, w2v_ctc_loss=2.7, task_loss=1.925, contrastive_loss=0, total=7471.3, n_correct=359.79, ppl=21.93, accuracy=4.816, wps=32211.7, ups=1.49, wpb=21650.7, bsz=757.4, num_updates=2000, lr=8.006e-05, gnorm=0.633, clip=0, loss_scale=32, train_wall=67, gb_free=17.7, wall=1466
2023-08-23 13:49:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 13:50:06 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.314 | trans_loss 12.196 | nll_loss 11.456 | w2v_ctc_loss 3.49 | task_loss 13.338 | contrastive_loss 0 | total 6138.43 | n_correct 334.714 | ppl 2808.68 | accuracy 5.453 | uer 53.689 | wer 51.621 | raw_wer 51.621 | bleu 0 | wps 974.7 | wpb 6138.4 | bsz 201.1 | num_updates 2000 | best_bleu 0
2023-08-23 13:50:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-23 13:50:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_2_2000.pt
2023-08-23 13:50:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_2_2000.pt
2023-08-23 13:50:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 12.875104523962364 seconds)
2023-08-23 13:51:25 | INFO | train_inner | epoch 002:   1022 / 1080 loss=4.585, trans_loss=5.722, nll_loss=4.444, w2v_ctc_loss=2.652, task_loss=1.913, contrastive_loss=0, total=7451.29, n_correct=368.14, ppl=21.76, accuracy=4.941, wps=16776.6, ups=0.78, wpb=21596.9, bsz=784.1, num_updates=2100, lr=8.4058e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=65, gb_free=19.2, wall=1595
2023-08-23 13:52:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 13:52:52 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.255 | trans_loss 12.164 | nll_loss 11.418 | w2v_ctc_loss 3.369 | task_loss 13.338 | contrastive_loss 0 | total 6138.43 | n_correct 347.429 | ppl 2737.03 | accuracy 5.66 | uer 51.266 | wer 50.242 | raw_wer 50.242 | bleu 0 | wps 983.6 | wpb 6138.4 | bsz 201.1 | num_updates 2158 | best_bleu 0
2023-08-23 13:52:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2158 updates
2023-08-23 13:52:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 13:52:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 13:53:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 2 @ 2158 updates, score 0.0) (writing took 10.005926069919951 seconds)
2023-08-23 13:53:02 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-23 13:53:02 | INFO | train | epoch 002 | loss 4.839 | trans_loss 5.708 | nll_loss 4.426 | w2v_ctc_loss 3.054 | task_loss 2.003 | contrastive_loss 0 | total 7392.68 | n_correct 377.962 | ppl 21.49 | accuracy 5.113 | wps 27300.9 | ups 1.27 | wpb 21418.9 | bsz 747.9 | num_updates 2158 | lr 8.63768e-05 | gnorm 0.584 | clip 0 | loss_scale 32 | train_wall 709 | gb_free 18 | wall 1692
2023-08-23 13:53:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-23 13:53:02 | INFO | fairseq.trainer | begin training epoch 3
2023-08-23 13:53:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 13:53:38 | INFO | train_inner | epoch 003:     42 / 1080 loss=4.572, trans_loss=5.74, nll_loss=4.466, w2v_ctc_loss=2.608, task_loss=2.204, contrastive_loss=0, total=7220.12, n_correct=353.82, ppl=22.09, accuracy=4.9, wps=15714, ups=0.75, wpb=20916.2, bsz=710.4, num_updates=2200, lr=8.8056e-05, gnorm=0.643, clip=0, loss_scale=32, train_wall=65, gb_free=19.1, wall=1728
2023-08-23 13:54:44 | INFO | train_inner | epoch 003:    142 / 1080 loss=4.528, trans_loss=5.742, nll_loss=4.469, w2v_ctc_loss=2.54, task_loss=1.957, contrastive_loss=0, total=7371.15, n_correct=343.94, ppl=22.15, accuracy=4.666, wps=32316.6, ups=1.51, wpb=21360.1, bsz=756.2, num_updates=2300, lr=9.2054e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=65, gb_free=17.5, wall=1794
2023-08-23 13:55:50 | INFO | train_inner | epoch 003:    242 / 1080 loss=4.48, trans_loss=5.724, nll_loss=4.448, w2v_ctc_loss=2.485, task_loss=2.076, contrastive_loss=0, total=7305.63, n_correct=352.67, ppl=21.83, accuracy=4.827, wps=31975.4, ups=1.51, wpb=21172.6, bsz=743.5, num_updates=2400, lr=9.6052e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=66, gb_free=17.7, wall=1860
2023-08-23 13:56:57 | INFO | train_inner | epoch 003:    342 / 1080 loss=4.479, trans_loss=5.737, nll_loss=4.462, w2v_ctc_loss=2.471, task_loss=2.095, contrastive_loss=0, total=7452, n_correct=355.27, ppl=22.04, accuracy=4.767, wps=32310.2, ups=1.5, wpb=21595.8, bsz=728.4, num_updates=2500, lr=0.00010005, gnorm=0.624, clip=0, loss_scale=64, train_wall=66, gb_free=17.8, wall=1927
2023-08-23 13:58:03 | INFO | train_inner | epoch 003:    442 / 1080 loss=4.444, trans_loss=5.727, nll_loss=4.45, w2v_ctc_loss=2.422, task_loss=2.095, contrastive_loss=0, total=7294.26, n_correct=343.61, ppl=21.86, accuracy=4.711, wps=31985.6, ups=1.51, wpb=21137, bsz=714.5, num_updates=2600, lr=0.000104048, gnorm=0.526, clip=0, loss_scale=64, train_wall=65, gb_free=17.6, wall=1993
2023-08-23 13:59:09 | INFO | train_inner | epoch 003:    542 / 1080 loss=4.416, trans_loss=5.721, nll_loss=4.443, w2v_ctc_loss=2.394, task_loss=2.104, contrastive_loss=0, total=7361.25, n_correct=350.48, ppl=21.76, accuracy=4.761, wps=32176.2, ups=1.51, wpb=21318.4, bsz=734.2, num_updates=2700, lr=0.000108046, gnorm=0.559, clip=0, loss_scale=64, train_wall=65, gb_free=19.1, wall=2059
2023-08-23 14:00:15 | INFO | train_inner | epoch 003:    642 / 1080 loss=4.395, trans_loss=5.71, nll_loss=4.433, w2v_ctc_loss=2.37, task_loss=2.058, contrastive_loss=0, total=7351.38, n_correct=351.25, ppl=21.61, accuracy=4.778, wps=32215.7, ups=1.51, wpb=21280.6, bsz=737.3, num_updates=2800, lr=0.000112044, gnorm=0.523, clip=0, loss_scale=64, train_wall=65, gb_free=17.6, wall=2125
2023-08-23 14:01:21 | INFO | train_inner | epoch 003:    742 / 1080 loss=4.34, trans_loss=5.693, nll_loss=4.415, w2v_ctc_loss=2.309, task_loss=1.727, contrastive_loss=0, total=7592, n_correct=365.65, ppl=21.33, accuracy=4.816, wps=33542.9, ups=1.52, wpb=21997.9, bsz=815.7, num_updates=2900, lr=0.000116042, gnorm=0.518, clip=0, loss_scale=64, train_wall=65, gb_free=18.1, wall=2191
2023-08-23 14:02:27 | INFO | train_inner | epoch 003:    842 / 1080 loss=4.357, trans_loss=5.699, nll_loss=4.423, w2v_ctc_loss=2.326, task_loss=2.145, contrastive_loss=0, total=7328.93, n_correct=359.94, ppl=21.45, accuracy=4.911, wps=32186.7, ups=1.52, wpb=21234.6, bsz=708.5, num_updates=3000, lr=0.00012004, gnorm=0.46, clip=0, loss_scale=64, train_wall=65, gb_free=17.8, wall=2257
2023-08-23 14:02:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 14:02:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-23 14:02:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-23 14:02:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-23 14:04:18 | INFO | train_inner | epoch 003:    946 / 1080 loss=3.141, trans_loss=4.262, nll_loss=2.589, w2v_ctc_loss=1.979, task_loss=1.36, contrastive_loss=0, total=7457.64, n_correct=2210.59, ppl=6.02, accuracy=29.642, wps=19373, ups=0.9, wpb=21602, bsz=769.7, num_updates=3100, lr=0.000124038, gnorm=0.984, clip=0, loss_scale=4, train_wall=111, gb_free=8.6, wall=2368
2023-08-23 14:04:23 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 400.00 MiB (GPU 2; 23.70 GiB total capacity; 21.15 GiB already allocated; 392.56 MiB free; 21.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-08-23 14:04:23 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:04:23 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:04:23 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  20829 MiB |  22047 MiB | 159848 GiB | 159827 GiB |
|       from large pool |  20663 MiB |  21880 MiB | 156203 GiB | 156182 GiB |
|       from small pool |    166 MiB |    167 MiB |   3645 GiB |   3644 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  20829 MiB |  22047 MiB | 159848 GiB | 159827 GiB |
|       from large pool |  20663 MiB |  21880 MiB | 156203 GiB | 156182 GiB |
|       from small pool |    166 MiB |    167 MiB |   3645 GiB |   3644 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  20789 MiB |  22007 MiB | 159418 GiB | 159397 GiB |
|       from large pool |  20623 MiB |  21840 MiB | 155774 GiB | 155754 GiB |
|       from small pool |    166 MiB |    167 MiB |   3643 GiB |   3643 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  22464 MiB |  22774 MiB |  28442 MiB |   5978 MiB |
|       from large pool |  22286 MiB |  22286 MiB |  27880 MiB |   5594 MiB |
|       from small pool |    178 MiB |    488 MiB |    562 MiB |    384 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1234 MiB |   3773 MiB | 167234 GiB | 167233 GiB |
|       from large pool |   1222 MiB |   3747 MiB | 163402 GiB | 163400 GiB |
|       from small pool |     11 MiB |     43 MiB |   3832 GiB |   3832 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    1814    |    1819    |   21371 K  |   21369 K  |
|       from large pool |     852    |     856    |    8780 K  |    8779 K  |
|       from small pool |     962    |     963    |   12591 K  |   12590 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    1814    |    1819    |   21371 K  |   21369 K  |
|       from large pool |     852    |     856    |    8780 K  |    8779 K  |
|       from small pool |     962    |     963    |   12591 K  |   12590 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     143    |     298    |     340    |     197    |
|       from large pool |      54    |      54    |      59    |       5    |
|       from small pool |      89    |     244    |     281    |     192    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      62    |      92    |   10691 K  |   10690 K  |
|       from large pool |      12    |      43    |    4403 K  |    4403 K  |
|       from small pool |      50    |      76    |    6287 K  |    6287 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:04:23 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:04:23 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:04:23 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:04:23 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:04:23 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:04:23 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 1 terminated with signal SIGKILL
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 217 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-23 14:07:52 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15965
2023-08-23 14:07:52 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15965
2023-08-23 14:07:52 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15965
2023-08-23 14:07:52 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15965
2023-08-23 14:07:53 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15965
2023-08-23 14:07:53 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15965
2023-08-23 14:07:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-23 14:07:53 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15965
2023-08-23 14:07:53 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15965
2023-08-23 14:07:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-23 14:07:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-23 14:07:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-23 14:07:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-23 14:07:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-23 14:07:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-23 14:07:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-23 14:07:54 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:07:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-23 14:07:54 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:07:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-23 14:07:54 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:07:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-23 14:07:54 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:07:54 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:07:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-23 14:07:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-23 14:07:54 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:07:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-23 14:07:54 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:07:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-23 14:07:54 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:07:54 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-23 14:07:57 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15965', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 12000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 12000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=12000, max_tokens_valid=12000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=12000, max_tokens_valid=12000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=12000, max_tokens_valid=12000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-23 14:07:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-23 14:07:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-23 14:07:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-23 14:07:57 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-23 14:07:57 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-23 14:08:01 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-23 14:08:01 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-23 14:08:01 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-23 14:08:03 | INFO | root | load pretrained hubert
2023-08-23 14:08:10 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-23 14:08:11 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-23 14:08:17 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-23 14:08:17 | INFO | root | share the sematic adapter and textual encoder
2023-08-23 14:08:17 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-23 14:08:17 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-23 14:08:17 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-23 14:08:17 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-23 14:08:17 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-23 14:08:17 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-23 14:08:17 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-23 14:08:17 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 14:08:17 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 14:08:17 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-23 14:08:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-23 14:08:36 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-23 14:08:36 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-23 14:08:37 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-23 14:08:37 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:08:37 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:08:37 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:08:37 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:08:37 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:08:37 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:08:37 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:08:37 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:08:37 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-23 14:08:37 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-23 14:08:37 | INFO | fairseq_cli.train | max tokens per device = 12000 and max sentences per device = None
2023-08-23 14:08:37 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-23 14:08:39 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(1.)
mt_weight tensor(0.5000)
2023-08-23 14:08:54 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-23 14:08:55 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 3 @ 2158 updates)
2023-08-23 14:08:55 | INFO | fairseq.trainer | loading train data for epoch 3
2023-08-23 14:08:55 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-23 14:08:55 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 14:08:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 14:09:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-23 14:09:02 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-23 14:09:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1080
2023-08-23 14:09:51 | INFO | fairseq.trainer | begin training epoch 3
2023-08-23 14:09:51 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
2023-08-23 14:10:36 | INFO | train_inner | epoch 003:     42 / 1080 loss=4.537, trans_loss=5.716, nll_loss=4.437, w2v_ctc_loss=2.574, task_loss=2.133, contrastive_loss=0, total=7400.48, n_correct=378.31, ppl=21.65, accuracy=5.112, wps=31154.9, ups=1.46, wpb=21423.4, bsz=749.1, num_updates=2200, lr=8.8056e-05, gnorm=0.687, clip=0, loss_scale=32, train_wall=37, gb_free=19.1, wall=119
2023-08-23 14:11:43 | INFO | train_inner | epoch 003:    142 / 1080 loss=4.527, trans_loss=5.743, nll_loss=4.47, w2v_ctc_loss=2.538, task_loss=1.957, contrastive_loss=0, total=7371.15, n_correct=345.58, ppl=22.17, accuracy=4.688, wps=31864.7, ups=1.49, wpb=21360.1, bsz=756.2, num_updates=2300, lr=9.2054e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=66, gb_free=17.5, wall=186
2023-08-23 14:12:50 | INFO | train_inner | epoch 003:    242 / 1080 loss=4.481, trans_loss=5.727, nll_loss=4.451, w2v_ctc_loss=2.484, task_loss=2.076, contrastive_loss=0, total=7305.63, n_correct=350.19, ppl=21.88, accuracy=4.793, wps=31370.1, ups=1.48, wpb=21172.6, bsz=743.5, num_updates=2400, lr=9.6052e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=67, gb_free=17.7, wall=253
2023-08-23 14:13:57 | INFO | train_inner | epoch 003:    342 / 1080 loss=4.479, trans_loss=5.74, nll_loss=4.465, w2v_ctc_loss=2.468, task_loss=2.095, contrastive_loss=0, total=7452, n_correct=353.23, ppl=22.09, accuracy=4.74, wps=32143, ups=1.49, wpb=21595.8, bsz=728.4, num_updates=2500, lr=0.00010005, gnorm=0.549, clip=0, loss_scale=32, train_wall=67, gb_free=17.9, wall=320
2023-08-23 14:15:04 | INFO | train_inner | epoch 003:    442 / 1080 loss=4.447, trans_loss=5.726, nll_loss=4.448, w2v_ctc_loss=2.424, task_loss=2.095, contrastive_loss=0, total=7294.26, n_correct=342.35, ppl=21.83, accuracy=4.693, wps=31853.4, ups=1.51, wpb=21137, bsz=714.5, num_updates=2600, lr=0.000104048, gnorm=0.554, clip=0, loss_scale=32, train_wall=66, gb_free=17.6, wall=387
2023-08-23 14:16:10 | INFO | train_inner | epoch 003:    542 / 1080 loss=4.418, trans_loss=5.724, nll_loss=4.447, w2v_ctc_loss=2.393, task_loss=2.104, contrastive_loss=0, total=7361.25, n_correct=347.39, ppl=21.81, accuracy=4.719, wps=32027.4, ups=1.5, wpb=21318.4, bsz=734.2, num_updates=2700, lr=0.000108046, gnorm=0.574, clip=0, loss_scale=32, train_wall=66, gb_free=19.1, wall=453
2023-08-23 14:17:17 | INFO | train_inner | epoch 003:    642 / 1080 loss=4.392, trans_loss=5.709, nll_loss=4.432, w2v_ctc_loss=2.369, task_loss=2.058, contrastive_loss=0, total=7351.38, n_correct=350.44, ppl=21.59, accuracy=4.767, wps=31877.7, ups=1.5, wpb=21280.6, bsz=737.3, num_updates=2800, lr=0.000112044, gnorm=0.508, clip=0, loss_scale=32, train_wall=66, gb_free=17.6, wall=520
2023-08-23 14:18:23 | INFO | train_inner | epoch 003:    742 / 1080 loss=4.339, trans_loss=5.689, nll_loss=4.409, w2v_ctc_loss=2.311, task_loss=1.727, contrastive_loss=0, total=7592, n_correct=362.68, ppl=21.25, accuracy=4.777, wps=33214.4, ups=1.51, wpb=21997.9, bsz=815.7, num_updates=2900, lr=0.000116042, gnorm=0.53, clip=0, loss_scale=32, train_wall=66, gb_free=18.1, wall=586
2023-08-23 14:19:31 | INFO | train_inner | epoch 003:    842 / 1080 loss=4.356, trans_loss=5.696, nll_loss=4.419, w2v_ctc_loss=2.326, task_loss=2.145, contrastive_loss=0, total=7328.93, n_correct=358.2, ppl=21.39, accuracy=4.887, wps=31481.6, ups=1.48, wpb=21234.6, bsz=708.5, num_updates=3000, lr=0.00012004, gnorm=0.501, clip=0, loss_scale=32, train_wall=67, gb_free=17.8, wall=654
2023-08-23 14:19:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-23 14:19:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-23 14:19:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-23 14:19:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-23 14:21:22 | INFO | train_inner | epoch 003:    946 / 1080 loss=3.147, trans_loss=4.266, nll_loss=2.593, w2v_ctc_loss=1.989, task_loss=1.35, contrastive_loss=0, total=7470.67, n_correct=2229.72, ppl=6.03, accuracy=29.846, wps=19457.7, ups=0.9, wpb=21639.7, bsz=773, num_updates=3100, lr=0.000124038, gnorm=0.992, clip=0, loss_scale=2, train_wall=110, gb_free=8.6, wall=765
2023-08-23 14:22:48 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 408.00 MiB (GPU 2; 23.70 GiB total capacity; 21.19 GiB already allocated; 358.56 MiB free; 21.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-08-23 14:22:48 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:22:48 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:22:48 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 3         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  20864 MiB |  22087 MiB |  59606 GiB |  59586 GiB |
|       from large pool |  20641 MiB |  21864 MiB |  58485 GiB |  58465 GiB |
|       from small pool |    223 MiB |    226 MiB |   1121 GiB |   1120 GiB |
|---------------------------------------------------------------------------|
| Active memory         |  20864 MiB |  22087 MiB |  59606 GiB |  59586 GiB |
|       from large pool |  20641 MiB |  21864 MiB |  58485 GiB |  58465 GiB |
|       from small pool |    223 MiB |    226 MiB |   1121 GiB |   1120 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |  20833 MiB |  22057 MiB |  59451 GiB |  59431 GiB |
|       from large pool |  20610 MiB |  21833 MiB |  58331 GiB |  58310 GiB |
|       from small pool |    223 MiB |    226 MiB |   1120 GiB |   1120 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  22498 MiB |  22738 MiB |  23872 MiB |   1374 MiB |
|       from large pool |  22256 MiB |  22256 MiB |  23056 MiB |    800 MiB |
|       from small pool |    242 MiB |    482 MiB |    816 MiB |    574 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   1633 MiB |   4521 MiB |  69107 GiB |  69106 GiB |
|       from large pool |   1614 MiB |   4431 MiB |  67921 GiB |  67920 GiB |
|       from small pool |     18 MiB |     98 MiB |   1186 GiB |   1186 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    1773    |    1777    |    6962 K  |    6960 K  |
|       from large pool |     716    |     719    |    3056 K  |    3055 K  |
|       from small pool |    1057    |    1058    |    3906 K  |    3905 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    1773    |    1777    |    6962 K  |    6960 K  |
|       from large pool |     716    |     719    |    3056 K  |    3055 K  |
|       from small pool |    1057    |    1058    |    3906 K  |    3905 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     143    |     263    |     432    |     289    |
|       from large pool |      22    |      22    |      24    |       2    |
|       from small pool |     121    |     241    |     408    |     287    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      93    |     135    |    3527 K  |    3527 K  |
|       from large pool |      11    |      40    |    1576 K  |    1576 K  |
|       from small pool |      82    |     115    |    1951 K  |    1950 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:22:48 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:22:48 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:22:48 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:22:48 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-08-23 14:22:48 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-23 14:22:48 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
2023-08-23 14:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13841
2023-08-23 14:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13841
2023-08-23 14:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13841
2023-08-23 14:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13841
2023-08-23 14:31:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-23 14:31:20 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13841
2023-08-23 14:31:21 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13841
2023-08-23 14:31:21 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13841
2023-08-23 14:31:21 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13841
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:31:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:31:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:31:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:31:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:31:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-23 14:31:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-23 14:31:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-23 14:31:21 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:31:21 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 322, in distributed_main
    cfg.distributed_training.distributed_rank = distributed_init(cfg)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 272, in distributed_init
    dist.all_reduce(torch.zeros(1).cuda())
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 5 terminated with signal SIGKILL
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 131 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-23 14:32:49 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15042
2023-08-23 14:32:49 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15042
2023-08-23 14:32:49 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15042
2023-08-23 14:32:49 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15042
2023-08-23 14:32:49 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15042
2023-08-23 14:32:49 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15042
2023-08-23 14:32:49 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15042
2023-08-23 14:32:49 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15042
2023-08-23 14:32:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:32:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-23 14:32:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:32:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:32:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:32:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:32:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:32:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-23 14:32:50 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-23 14:32:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-23 14:32:53 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15042', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-23 14:32:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,998
2023-08-23 14:32:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,998
2023-08-23 14:32:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-23 14:32:53 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-23 14:32:53 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-23 14:32:58 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-23 14:32:58 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-23 14:32:58 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-23 14:33:00 | INFO | root | load pretrained hubert
2023-08-23 14:33:07 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_enfr_baseline
2023-08-23 14:33:11 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-23 14:33:18 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/enfr-baseline/last8.ensemble.pt
2023-08-23 14:33:18 | INFO | root | share the sematic adapter and textual encoder
2023-08-23 14:33:18 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9998, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9998, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9998, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-23 14:33:18 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-23 14:33:18 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-23 14:33:18 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-23 14:33:18 | INFO | fairseq_cli.train | num. shared model params: 134,448,256 (num. trained: 134,448,256)
2023-08-23 14:33:18 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-23 14:33:18 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-23 14:33:18 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 14:33:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 14:33:18 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-23 14:33:33 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-23 14:33:33 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-23 14:33:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-23 14:33:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-23 14:33:34 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:33:34 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:33:34 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:33:34 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:33:34 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:33:34 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:33:34 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:33:34 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-23 14:33:34 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-23 14:33:34 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-23 14:33:34 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-23 14:33:34 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-23 14:33:36 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(1.)
mt_weight tensor(0.5000)
2023-08-23 14:33:53 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-23 14:33:55 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 3 @ 2158 updates)
2023-08-23 14:33:55 | INFO | fairseq.trainer | loading train data for epoch 3
2023-08-23 14:33:55 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-23 14:33:55 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 14:33:55 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-23 14:33:58 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-23 14:34:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
2023-08-23 14:34:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 14:34:51 | INFO | fairseq.trainer | begin training epoch 3
2023-08-23 14:34:51 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
asr_weight tensor(1.)
mt_weight tensor(0.5000)
2023-08-23 14:35:31 | INFO | train_inner | epoch 003:     42 / 1191 loss=4.539, trans_loss=5.716, nll_loss=4.439, w2v_ctc_loss=2.582, task_loss=2.173, contrastive_loss=0, total=6732.6, n_correct=332.952, ppl=21.69, accuracy=4.945, wps=29451.3, ups=1.52, wpb=19510.5, bsz=688.6, num_updates=2200, lr=8.8056e-05, gnorm=0.502, clip=0, loss_scale=32, train_wall=32, gb_free=18.1, wall=117
2023-08-23 14:36:36 | INFO | train_inner | epoch 003:    142 / 1191 loss=4.523, trans_loss=5.723, nll_loss=4.446, w2v_ctc_loss=2.55, task_loss=2.108, contrastive_loss=0, total=6712.59, n_correct=331.35, ppl=21.8, accuracy=4.936, wps=29885.2, ups=1.54, wpb=19467, bsz=702.4, num_updates=2300, lr=9.2054e-05, gnorm=0.636, clip=0, loss_scale=32, train_wall=65, gb_free=19.1, wall=182
2023-08-23 14:37:41 | INFO | train_inner | epoch 003:    242 / 1191 loss=4.502, trans_loss=5.742, nll_loss=4.463, w2v_ctc_loss=2.501, task_loss=2.241, contrastive_loss=0, total=6671.3, n_correct=310.84, ppl=22.05, accuracy=4.659, wps=29583, ups=1.53, wpb=19327.3, bsz=663.4, num_updates=2400, lr=9.6052e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=65, gb_free=17.9, wall=247
2023-08-23 14:38:46 | INFO | train_inner | epoch 003:    342 / 1191 loss=4.49, trans_loss=5.751, nll_loss=4.475, w2v_ctc_loss=2.47, task_loss=2.436, contrastive_loss=0, total=6597.35, n_correct=311.16, ppl=22.24, accuracy=4.716, wps=29457.3, ups=1.54, wpb=19113.2, bsz=639.3, num_updates=2500, lr=0.00010005, gnorm=0.616, clip=0, loss_scale=32, train_wall=64, gb_free=18.1, wall=312
2023-08-23 14:39:50 | INFO | train_inner | epoch 003:    442 / 1191 loss=4.433, trans_loss=5.712, nll_loss=4.429, w2v_ctc_loss=2.426, task_loss=2.145, contrastive_loss=0, total=6715.86, n_correct=325.21, ppl=21.55, accuracy=4.842, wps=30304.5, ups=1.56, wpb=19456, bsz=688.2, num_updates=2600, lr=0.000104048, gnorm=0.498, clip=0, loss_scale=32, train_wall=64, gb_free=18.1, wall=376
2023-08-23 14:40:55 | INFO | train_inner | epoch 003:    542 / 1191 loss=4.43, trans_loss=5.718, nll_loss=4.437, w2v_ctc_loss=2.416, task_loss=2.21, contrastive_loss=0, total=6737.06, n_correct=310.81, ppl=21.66, accuracy=4.613, wps=30185.3, ups=1.55, wpb=19523.1, bsz=669.7, num_updates=2700, lr=0.000108046, gnorm=0.533, clip=0, loss_scale=32, train_wall=64, gb_free=18.5, wall=441
2023-08-23 14:41:59 | INFO | train_inner | epoch 003:    642 / 1191 loss=4.398, trans_loss=5.716, nll_loss=4.434, w2v_ctc_loss=2.368, task_loss=2.166, contrastive_loss=0, total=6761.64, n_correct=308.51, ppl=21.61, accuracy=4.563, wps=30382.7, ups=1.55, wpb=19590.6, bsz=678.2, num_updates=2800, lr=0.000112044, gnorm=0.575, clip=0, loss_scale=32, train_wall=64, gb_free=18.4, wall=506
2023-08-23 14:43:04 | INFO | train_inner | epoch 003:    742 / 1191 loss=4.394, trans_loss=5.728, nll_loss=4.448, w2v_ctc_loss=2.354, task_loss=2.23, contrastive_loss=0, total=6710.55, n_correct=308.65, ppl=21.83, accuracy=4.599, wps=30204.7, ups=1.55, wpb=19447.3, bsz=680.9, num_updates=2900, lr=0.000116042, gnorm=0.548, clip=0, loss_scale=32, train_wall=64, gb_free=18.3, wall=570
2023-08-23 14:44:09 | INFO | train_inner | epoch 003:    842 / 1191 loss=4.346, trans_loss=5.695, nll_loss=4.41, w2v_ctc_loss=2.316, task_loss=1.999, contrastive_loss=0, total=6806.48, n_correct=322.43, ppl=21.26, accuracy=4.737, wps=30236.7, ups=1.53, wpb=19722.8, bsz=716.3, num_updates=3000, lr=0.00012004, gnorm=0.476, clip=0, loss_scale=32, train_wall=65, gb_free=18.1, wall=635
2023-08-23 14:44:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-23 14:44:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-23 14:44:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-23 14:45:53 | INFO | train_inner | epoch 003:    945 / 1191 loss=3.151, trans_loss=4.259, nll_loss=2.583, w2v_ctc_loss=1.999, task_loss=1.432, contrastive_loss=0, total=6788.87, n_correct=2036.29, ppl=5.99, accuracy=29.995, wps=18912.7, ups=0.96, wpb=19672.2, bsz=710.4, num_updates=3100, lr=0.000124038, gnorm=1.018, clip=0, loss_scale=4, train_wall=103, gb_free=13.6, wall=739
2023-08-23 14:47:36 | INFO | train_inner | epoch 003:   1045 / 1191 loss=2.865, trans_loss=4.031, nll_loss=2.282, w2v_ctc_loss=1.802, task_loss=1.758, contrastive_loss=0, total=6541.83, n_correct=2403.53, ppl=4.86, accuracy=36.741, wps=18451.8, ups=0.97, wpb=18954.8, bsz=624.4, num_updates=3200, lr=0.000128036, gnorm=0.753, clip=0, loss_scale=4, train_wall=102, gb_free=13.4, wall=842
2023-08-23 14:49:19 | INFO | train_inner | epoch 003:   1145 / 1191 loss=2.693, trans_loss=3.9, nll_loss=2.106, w2v_ctc_loss=1.68, task_loss=1.51, contrastive_loss=0, total=6739.69, n_correct=2847.04, ppl=4.31, accuracy=42.243, wps=18915.7, ups=0.97, wpb=19508.7, bsz=696.3, num_updates=3300, lr=0.000132034, gnorm=0.724, clip=0, loss_scale=4, train_wall=103, gb_free=12.3, wall=945
2023-08-23 14:50:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-23 14:50:39 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.903 | trans_loss 6.344 | nll_loss 3.912 | w2v_ctc_loss 2.01 | task_loss 7.674 | contrastive_loss 0 | total 6138.43 | n_correct 3050.29 | ppl 15.05 | accuracy 49.692 | uer 32.995 | wer 33.035 | raw_wer 33.035 | bleu 8.91 | wps 1646.5 | wpb 6138.4 | bsz 201.1 | num_updates 3346 | best_bleu 8.91
2023-08-23 14:50:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3346 updates
2023-08-23 14:50:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 14:50:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 14:50:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 3 @ 3346 updates, score 8.91) (writing took 11.086510218097828 seconds)
2023-08-23 14:50:50 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-23 14:50:50 | INFO | train | epoch 003 | loss 3.987 | trans_loss 5.233 | nll_loss 3.817 | w2v_ctc_loss 2.249 | task_loss 2.006 | contrastive_loss 0 | total 6703.54 | n_correct 952.317 | ppl 14.1 | accuracy 14.206 | wps 24350.9 | ups 1.25 | wpb 19422.3 | bsz 678.1 | num_updates 3346 | lr 0.000133873 | gnorm 0.631 | clip 0 | loss_scale 4 | train_wall 899 | gb_free 15.3 | wall 1036
2023-08-23 14:50:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 14:50:50 | INFO | fairseq.trainer | begin training epoch 4
2023-08-23 14:50:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 14:51:53 | INFO | train_inner | epoch 004:     54 / 1191 loss=2.597, trans_loss=3.817, nll_loss=1.996, w2v_ctc_loss=1.611, task_loss=1.657, contrastive_loss=0, total=6545.33, n_correct=2990.14, ppl=3.99, accuracy=45.684, wps=12336.3, ups=0.65, wpb=18951.9, bsz=631.6, num_updates=3400, lr=0.000136032, gnorm=0.718, clip=0, loss_scale=4, train_wall=101, gb_free=12, wall=1099
2023-08-23 14:53:35 | INFO | train_inner | epoch 004:    154 / 1191 loss=2.51, trans_loss=3.745, nll_loss=1.904, w2v_ctc_loss=1.552, task_loss=1.557, contrastive_loss=0, total=6742.77, n_correct=3275.23, ppl=3.74, accuracy=48.574, wps=19002.5, ups=0.97, wpb=19536.1, bsz=668.3, num_updates=3500, lr=0.00014003, gnorm=0.69, clip=0, loss_scale=4, train_wall=102, gb_free=14.4, wall=1202
2023-08-23 14:55:17 | INFO | train_inner | epoch 004:    254 / 1191 loss=2.449, trans_loss=3.706, nll_loss=1.852, w2v_ctc_loss=1.504, task_loss=1.512, contrastive_loss=0, total=6745.48, n_correct=3402.78, ppl=3.61, accuracy=50.445, wps=19245.1, ups=0.98, wpb=19541.7, bsz=689.6, num_updates=3600, lr=0.000144028, gnorm=0.661, clip=0, loss_scale=4, train_wall=101, gb_free=14.4, wall=1303
2023-08-23 14:56:58 | INFO | train_inner | epoch 004:    354 / 1191 loss=2.417, trans_loss=3.675, nll_loss=1.814, w2v_ctc_loss=1.485, task_loss=1.543, contrastive_loss=0, total=6687.43, n_correct=3459.07, ppl=3.52, accuracy=51.725, wps=19155.4, ups=0.99, wpb=19385.1, bsz=665.5, num_updates=3700, lr=0.000148026, gnorm=0.658, clip=0, loss_scale=4, train_wall=101, gb_free=13.3, wall=1404
2023-08-23 14:58:40 | INFO | train_inner | epoch 004:    454 / 1191 loss=2.371, trans_loss=3.655, nll_loss=1.785, w2v_ctc_loss=1.446, task_loss=1.498, contrastive_loss=0, total=6759.18, n_correct=3576.43, ppl=3.45, accuracy=52.912, wps=19247.3, ups=0.98, wpb=19573.2, bsz=701.7, num_updates=3800, lr=0.000152024, gnorm=0.637, clip=0, loss_scale=4, train_wall=101, gb_free=13.8, wall=1506
2023-08-23 15:00:21 | INFO | train_inner | epoch 004:    554 / 1191 loss=2.347, trans_loss=3.626, nll_loss=1.75, w2v_ctc_loss=1.429, task_loss=1.609, contrastive_loss=0, total=6619.95, n_correct=3564.03, ppl=3.36, accuracy=53.838, wps=19058.2, ups=0.99, wpb=19191.8, bsz=659.3, num_updates=3900, lr=0.000156022, gnorm=0.624, clip=0, loss_scale=4, train_wall=100, gb_free=13.4, wall=1607
2023-08-23 15:02:05 | INFO | train_inner | epoch 004:    654 / 1191 loss=2.316, trans_loss=3.616, nll_loss=1.737, w2v_ctc_loss=1.4, task_loss=1.499, contrastive_loss=0, total=6818.61, n_correct=3724.05, ppl=3.33, accuracy=54.616, wps=18988.9, ups=0.96, wpb=19760.6, bsz=705.9, num_updates=4000, lr=0.00016002, gnorm=0.634, clip=0, loss_scale=4, train_wall=103, gb_free=14.3, wall=1711
2023-08-23 15:02:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 15:02:40 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.398 | trans_loss 5.756 | nll_loss 3.124 | w2v_ctc_loss 1.654 | task_loss 7.974 | contrastive_loss 0 | total 6138.43 | n_correct 3609.86 | ppl 8.72 | accuracy 58.808 | uer 27.013 | wer 28.196 | raw_wer 28.196 | bleu 18.75 | wps 1538.9 | wpb 6138.4 | bsz 201.1 | num_updates 4000 | best_bleu 18.75
2023-08-23 15:02:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4000 updates
2023-08-23 15:02:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_4_4000.pt
2023-08-23 15:02:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_4_4000.pt
2023-08-23 15:02:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_4_4000.pt (epoch 4 @ 4000 updates, score 18.75) (writing took 12.291174743091688 seconds)
2023-08-23 15:04:32 | INFO | train_inner | epoch 004:    754 / 1191 loss=2.266, trans_loss=3.592, nll_loss=1.704, w2v_ctc_loss=1.35, task_loss=1.474, contrastive_loss=0, total=6720.83, n_correct=3739.89, ppl=3.26, accuracy=55.646, wps=13223.6, ups=0.68, wpb=19468.3, bsz=700.5, num_updates=4100, lr=0.000164018, gnorm=0.599, clip=0, loss_scale=4, train_wall=99, gb_free=13.6, wall=1858
2023-08-23 15:06:15 | INFO | train_inner | epoch 004:    854 / 1191 loss=2.253, trans_loss=3.586, nll_loss=1.695, w2v_ctc_loss=1.34, task_loss=1.401, contrastive_loss=0, total=6899.66, n_correct=3877.18, ppl=3.24, accuracy=56.194, wps=19375.2, ups=0.97, wpb=19975.7, bsz=730.1, num_updates=4200, lr=0.000168016, gnorm=0.594, clip=0, loss_scale=4, train_wall=102, gb_free=14.1, wall=1961
2023-08-23 15:07:57 | INFO | train_inner | epoch 004:    954 / 1191 loss=2.245, trans_loss=3.576, nll_loss=1.683, w2v_ctc_loss=1.337, task_loss=1.585, contrastive_loss=0, total=6632.61, n_correct=3750.42, ppl=3.21, accuracy=56.545, wps=18883.2, ups=0.98, wpb=19210.7, bsz=673.6, num_updates=4300, lr=0.000172014, gnorm=0.6, clip=0, loss_scale=4, train_wall=101, gb_free=11.7, wall=2063
2023-08-23 15:09:39 | INFO | train_inner | epoch 004:   1054 / 1191 loss=2.229, trans_loss=3.566, nll_loss=1.671, w2v_ctc_loss=1.323, task_loss=1.632, contrastive_loss=0, total=6651.13, n_correct=3789.23, ppl=3.18, accuracy=56.971, wps=18815.1, ups=0.98, wpb=19269.5, bsz=657.2, num_updates=4400, lr=0.000176012, gnorm=0.606, clip=0, loss_scale=4, train_wall=102, gb_free=13.1, wall=2165
2023-08-23 15:11:21 | INFO | train_inner | epoch 004:   1154 / 1191 loss=2.214, trans_loss=3.552, nll_loss=1.654, w2v_ctc_loss=1.312, task_loss=1.642, contrastive_loss=0, total=6591.35, n_correct=3788.65, ppl=3.15, accuracy=57.479, wps=18831.1, ups=0.99, wpb=19106.4, bsz=642.6, num_updates=4500, lr=0.00018001, gnorm=0.596, clip=0, loss_scale=4, train_wall=101, gb_free=14.2, wall=2267
2023-08-23 15:11:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 15:12:32 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.253 | trans_loss 5.601 | nll_loss 2.908 | w2v_ctc_loss 1.524 | task_loss 8.1 | contrastive_loss 0 | total 6138.43 | n_correct 3760.29 | ppl 7.51 | accuracy 61.258 | uer 24.801 | wer 25.917 | raw_wer 25.917 | bleu 21.38 | wps 1619.6 | wpb 6138.4 | bsz 201.1 | num_updates 4537 | best_bleu 21.38
2023-08-23 15:12:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4537 updates
2023-08-23 15:12:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 15:12:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 15:12:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 4 @ 4537 updates, score 21.38) (writing took 11.678672848967835 seconds)
2023-08-23 15:12:44 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-23 15:12:44 | INFO | train | epoch 004 | loss 2.336 | trans_loss 3.632 | nll_loss 1.756 | w2v_ctc_loss 1.412 | task_loss 1.548 | contrastive_loss 0 | total 6703.69 | n_correct 3610.73 | ppl 3.38 | accuracy 53.862 | wps 17603.6 | ups 0.91 | wpb 19422.7 | bsz 678.2 | num_updates 4537 | lr 0.000181489 | gnorm 0.632 | clip 0 | loss_scale 4 | train_wall 1206 | gb_free 13.5 | wall 2350
2023-08-23 15:12:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 15:12:45 | INFO | fairseq.trainer | begin training epoch 5
2023-08-23 15:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 15:13:56 | INFO | train_inner | epoch 005:     63 / 1191 loss=2.158, trans_loss=3.519, nll_loss=1.611, w2v_ctc_loss=1.255, task_loss=1.454, contrastive_loss=0, total=6749.55, n_correct=3956.58, ppl=3.06, accuracy=58.62, wps=12607.8, ups=0.64, wpb=19562.5, bsz=709.5, num_updates=4600, lr=0.000184008, gnorm=0.577, clip=0, loss_scale=4, train_wall=101, gb_free=12.8, wall=2422
2023-08-23 15:15:37 | INFO | train_inner | epoch 005:    163 / 1191 loss=2.142, trans_loss=3.515, nll_loss=1.604, w2v_ctc_loss=1.236, task_loss=1.523, contrastive_loss=0, total=6737.83, n_correct=3975.03, ppl=3.04, accuracy=58.996, wps=19370.7, ups=0.99, wpb=19519.8, bsz=680.6, num_updates=4700, lr=0.000188006, gnorm=0.598, clip=0, loss_scale=4, train_wall=100, gb_free=13.8, wall=2523
2023-08-23 15:17:18 | INFO | train_inner | epoch 005:    263 / 1191 loss=2.129, trans_loss=3.505, nll_loss=1.592, w2v_ctc_loss=1.228, task_loss=1.413, contrastive_loss=0, total=6857.36, n_correct=4073.45, ppl=3.02, accuracy=59.403, wps=19495.9, ups=0.98, wpb=19864.7, bsz=731.7, num_updates=4800, lr=0.000192004, gnorm=0.574, clip=0, loss_scale=4, train_wall=101, gb_free=11.8, wall=2625
2023-08-23 15:19:00 | INFO | train_inner | epoch 005:    363 / 1191 loss=2.136, trans_loss=3.512, nll_loss=1.6, w2v_ctc_loss=1.233, task_loss=1.627, contrastive_loss=0, total=6619.53, n_correct=3921.4, ppl=3.03, accuracy=59.24, wps=18963.1, ups=0.99, wpb=19168.8, bsz=657.1, num_updates=4900, lr=0.000196002, gnorm=0.574, clip=0, loss_scale=4, train_wall=100, gb_free=11.5, wall=2726
2023-08-23 15:20:42 | INFO | train_inner | epoch 005:    463 / 1191 loss=2.125, trans_loss=3.501, nll_loss=1.591, w2v_ctc_loss=1.228, task_loss=1.516, contrastive_loss=0, total=6694.98, n_correct=3986.03, ppl=3.01, accuracy=59.538, wps=18935.6, ups=0.98, wpb=19415.6, bsz=688.9, num_updates=5000, lr=0.0002, gnorm=0.578, clip=0, loss_scale=4, train_wall=102, gb_free=14, wall=2828
mt_weight tensor(0.5000)
asr_weight tensor(0.4557, device='cuda:0')
2023-08-23 15:22:24 | INFO | train_inner | epoch 005:    563 / 1191 loss=2.109, trans_loss=3.501, nll_loss=1.587, w2v_ctc_loss=1.201, task_loss=1.647, contrastive_loss=0, total=6625.55, n_correct=3967.16, ppl=3, accuracy=59.877, wps=18749.4, ups=0.98, wpb=19186.6, bsz=654.8, num_updates=5100, lr=0.00019803, gnorm=0.372, clip=0, loss_scale=8, train_wall=102, gb_free=10.5, wall=2931
2023-08-23 15:24:06 | INFO | train_inner | epoch 005:    663 / 1191 loss=2.1, trans_loss=3.495, nll_loss=1.579, w2v_ctc_loss=1.199, task_loss=1.578, contrastive_loss=0, total=6717.16, n_correct=4043.56, ppl=2.99, accuracy=60.197, wps=19151.1, ups=0.98, wpb=19447.6, bsz=667.3, num_updates=5200, lr=0.000196116, gnorm=0.371, clip=0, loss_scale=8, train_wall=101, gb_free=13.5, wall=3032
2023-08-23 15:25:48 | INFO | train_inner | epoch 005:    763 / 1191 loss=2.083, trans_loss=3.479, nll_loss=1.563, w2v_ctc_loss=1.186, task_loss=1.493, contrastive_loss=0, total=6788.83, n_correct=4121.24, ppl=2.95, accuracy=60.706, wps=19247.7, ups=0.98, wpb=19681, bsz=704.7, num_updates=5300, lr=0.000194257, gnorm=0.365, clip=0, loss_scale=8, train_wall=102, gb_free=12.7, wall=3134
2023-08-23 15:27:30 | INFO | train_inner | epoch 005:    863 / 1191 loss=2.084, trans_loss=3.481, nll_loss=1.564, w2v_ctc_loss=1.186, task_loss=1.545, contrastive_loss=0, total=6709.23, n_correct=4070.26, ppl=2.96, accuracy=60.667, wps=19008.8, ups=0.98, wpb=19437.3, bsz=681.8, num_updates=5400, lr=0.00019245, gnorm=0.367, clip=0, loss_scale=8, train_wall=102, gb_free=10.2, wall=3237
2023-08-23 15:29:13 | INFO | train_inner | epoch 005:    963 / 1191 loss=2.084, trans_loss=3.483, nll_loss=1.567, w2v_ctc_loss=1.187, task_loss=1.618, contrastive_loss=0, total=6639.26, n_correct=4034.21, ppl=2.96, accuracy=60.763, wps=18781, ups=0.98, wpb=19232.5, bsz=655, num_updates=5500, lr=0.000190693, gnorm=0.369, clip=0, loss_scale=8, train_wall=102, gb_free=10.7, wall=3339
2023-08-23 15:30:55 | INFO | train_inner | epoch 005:   1063 / 1191 loss=2.075, trans_loss=3.483, nll_loss=1.566, w2v_ctc_loss=1.177, task_loss=1.641, contrastive_loss=0, total=6651.7, n_correct=4050.37, ppl=2.96, accuracy=60.892, wps=18834.5, ups=0.98, wpb=19269.6, bsz=650.7, num_updates=5600, lr=0.000188982, gnorm=0.364, clip=0, loss_scale=8, train_wall=102, gb_free=12, wall=3441
2023-08-23 15:32:37 | INFO | train_inner | epoch 005:   1163 / 1191 loss=2.074, trans_loss=3.473, nll_loss=1.556, w2v_ctc_loss=1.182, task_loss=1.601, contrastive_loss=0, total=6675.54, n_correct=4082.36, ppl=2.94, accuracy=61.154, wps=19010.4, ups=0.98, wpb=19353, bsz=668.9, num_updates=5700, lr=0.000187317, gnorm=0.371, clip=0, loss_scale=8, train_wall=101, gb_free=12.7, wall=3543
2023-08-23 15:33:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4557, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4557, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4557, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4557, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4557, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4557, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4557, device='cuda:7')
2023-08-23 15:33:38 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.07 | trans_loss 5.426 | nll_loss 2.692 | w2v_ctc_loss 1.308 | task_loss 8.354 | contrastive_loss 0 | total 6138.43 | n_correct 3927.29 | ppl 6.46 | accuracy 63.979 | uer 21.547 | wer 23.31 | raw_wer 23.31 | bleu 23.58 | wps 1762.8 | wpb 6138.4 | bsz 201.1 | num_updates 5728 | best_bleu 23.58
2023-08-23 15:33:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5728 updates
2023-08-23 15:33:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 15:33:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 15:33:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 5 @ 5728 updates, score 23.58) (writing took 10.831062224926427 seconds)
2023-08-23 15:33:49 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-23 15:33:49 | INFO | train | epoch 005 | loss 2.105 | trans_loss 3.494 | nll_loss 1.579 | w2v_ctc_loss 1.205 | task_loss 1.555 | contrastive_loss 0 | total 6703.69 | n_correct 4028.37 | ppl 2.99 | accuracy 60.092 | wps 18286.2 | ups 0.94 | wpb 19422.7 | bsz 678.2 | num_updates 5728 | lr 0.000186859 | gnorm 0.45 | clip 0 | loss_scale 8 | train_wall 1205 | gb_free 11.4 | wall 3615
2023-08-23 15:33:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 15:33:50 | INFO | fairseq.trainer | begin training epoch 6
2023-08-23 15:33:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 15:35:09 | INFO | train_inner | epoch 006:     72 / 1191 loss=2.013, trans_loss=3.439, nll_loss=1.509, w2v_ctc_loss=1.116, task_loss=1.564, contrastive_loss=0, total=6663.64, n_correct=4150.44, ppl=2.85, accuracy=62.285, wps=12698.8, ups=0.66, wpb=19300.8, bsz=669, num_updates=5800, lr=0.000185695, gnorm=0.352, clip=0, loss_scale=8, train_wall=100, gb_free=14.9, wall=3695
2023-08-23 15:36:51 | INFO | train_inner | epoch 006:    172 / 1191 loss=2.006, trans_loss=3.439, nll_loss=1.508, w2v_ctc_loss=1.106, task_loss=1.591, contrastive_loss=0, total=6714.46, n_correct=4190.26, ppl=2.84, accuracy=62.407, wps=19073.1, ups=0.98, wpb=19444.4, bsz=666.1, num_updates=5900, lr=0.000184115, gnorm=0.358, clip=0, loss_scale=8, train_wall=101, gb_free=13.8, wall=3797
2023-08-23 15:38:33 | INFO | train_inner | epoch 006:    272 / 1191 loss=1.997, trans_loss=3.43, nll_loss=1.499, w2v_ctc_loss=1.104, task_loss=1.421, contrastive_loss=0, total=6848.86, n_correct=4294.48, ppl=2.83, accuracy=62.704, wps=19407.7, ups=0.98, wpb=19838.5, bsz=731.5, num_updates=6000, lr=0.000182574, gnorm=0.36, clip=0, loss_scale=8, train_wall=101, gb_free=14.1, wall=3899
2023-08-23 15:38:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 15:39:07 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.064 | trans_loss 5.401 | nll_loss 2.656 | w2v_ctc_loss 1.342 | task_loss 8.413 | contrastive_loss 0 | total 6138.43 | n_correct 3950.29 | ppl 6.3 | accuracy 64.353 | uer 21.239 | wer 22.99 | raw_wer 22.99 | bleu 24.18 | wps 1628.7 | wpb 6138.4 | bsz 201.1 | num_updates 6000 | best_bleu 24.18
2023-08-23 15:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6000 updates
2023-08-23 15:39:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_6_6000.pt
2023-08-23 15:39:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_6_6000.pt
2023-08-23 15:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_6_6000.pt (epoch 6 @ 6000 updates, score 24.18) (writing took 12.674361163983122 seconds)
2023-08-23 15:41:03 | INFO | train_inner | epoch 006:    372 / 1191 loss=2.012, trans_loss=3.438, nll_loss=1.508, w2v_ctc_loss=1.116, task_loss=1.656, contrastive_loss=0, total=6661.31, n_correct=4158.74, ppl=2.85, accuracy=62.431, wps=12923, ups=0.67, wpb=19299.9, bsz=648.1, num_updates=6100, lr=0.000181071, gnorm=0.363, clip=0, loss_scale=8, train_wall=102, gb_free=12.8, wall=4049
2023-08-23 15:42:43 | INFO | train_inner | epoch 006:    472 / 1191 loss=1.995, trans_loss=3.431, nll_loss=1.5, w2v_ctc_loss=1.1, task_loss=1.582, contrastive_loss=0, total=6602.15, n_correct=4143.39, ppl=2.83, accuracy=62.758, wps=19023.7, ups=0.99, wpb=19125.5, bsz=662.6, num_updates=6200, lr=0.000179605, gnorm=0.36, clip=0, loss_scale=8, train_wall=100, gb_free=13.1, wall=4149
2023-08-23 15:44:26 | INFO | train_inner | epoch 006:    572 / 1191 loss=1.985, trans_loss=3.424, nll_loss=1.494, w2v_ctc_loss=1.09, task_loss=1.566, contrastive_loss=0, total=6720.82, n_correct=4230.26, ppl=2.82, accuracy=62.943, wps=18944.6, ups=0.97, wpb=19483.1, bsz=672.2, num_updates=6300, lr=0.000178174, gnorm=0.355, clip=0, loss_scale=8, train_wall=102, gb_free=15.3, wall=4252
2023-08-23 15:46:08 | INFO | train_inner | epoch 006:    672 / 1191 loss=1.998, trans_loss=3.44, nll_loss=1.512, w2v_ctc_loss=1.099, task_loss=1.625, contrastive_loss=0, total=6719.37, n_correct=4205.73, ppl=2.85, accuracy=62.591, wps=19054.4, ups=0.98, wpb=19462.9, bsz=666.8, num_updates=6400, lr=0.000176777, gnorm=0.357, clip=0, loss_scale=8, train_wall=101, gb_free=14.1, wall=4354
2023-08-23 15:47:49 | INFO | train_inner | epoch 006:    772 / 1191 loss=1.977, trans_loss=3.421, nll_loss=1.49, w2v_ctc_loss=1.083, task_loss=1.493, contrastive_loss=0, total=6765.12, n_correct=4276.33, ppl=2.81, accuracy=63.211, wps=19334.6, ups=0.99, wpb=19600.8, bsz=701.4, num_updates=6500, lr=0.000175412, gnorm=0.356, clip=0, loss_scale=8, train_wall=101, gb_free=11.4, wall=4456
2023-08-23 15:49:32 | INFO | train_inner | epoch 006:    872 / 1191 loss=1.987, trans_loss=3.424, nll_loss=1.496, w2v_ctc_loss=1.096, task_loss=1.558, contrastive_loss=0, total=6682.51, n_correct=4209.14, ppl=2.82, accuracy=62.987, wps=18868.2, ups=0.97, wpb=19376.5, bsz=686.6, num_updates=6600, lr=0.000174078, gnorm=0.357, clip=0, loss_scale=8, train_wall=102, gb_free=13.9, wall=4558
2023-08-23 15:51:15 | INFO | train_inner | epoch 006:    972 / 1191 loss=1.987, trans_loss=3.435, nll_loss=1.508, w2v_ctc_loss=1.087, task_loss=1.679, contrastive_loss=0, total=6610.73, n_correct=4153.26, ppl=2.84, accuracy=62.826, wps=18687, ups=0.98, wpb=19156, bsz=650, num_updates=6700, lr=0.000172774, gnorm=0.357, clip=0, loss_scale=8, train_wall=102, gb_free=14.5, wall=4661
2023-08-23 15:52:55 | INFO | train_inner | epoch 006:   1072 / 1191 loss=1.972, trans_loss=3.42, nll_loss=1.489, w2v_ctc_loss=1.078, task_loss=1.584, contrastive_loss=0, total=6664.62, n_correct=4218.77, ppl=2.81, accuracy=63.301, wps=19231.1, ups=1, wpb=19313.7, bsz=662.2, num_updates=6800, lr=0.000171499, gnorm=0.354, clip=0, loss_scale=8, train_wall=100, gb_free=12.3, wall=4761
2023-08-23 15:54:36 | INFO | train_inner | epoch 006:   1172 / 1191 loss=1.958, trans_loss=3.418, nll_loss=1.487, w2v_ctc_loss=1.062, task_loss=1.474, contrastive_loss=0, total=6722.96, n_correct=4272.42, ppl=2.8, accuracy=63.55, wps=19354.6, ups=0.99, wpb=19478.2, bsz=696.5, num_updates=6900, lr=0.000170251, gnorm=0.352, clip=0, loss_scale=8, train_wall=100, gb_free=10.8, wall=4862
2023-08-23 15:54:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 15:55:29 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.008 | trans_loss 5.355 | nll_loss 2.61 | w2v_ctc_loss 1.262 | task_loss 8.381 | contrastive_loss 0 | total 6138.43 | n_correct 3998.71 | ppl 6.11 | accuracy 65.142 | uer 20.72 | wer 22.399 | raw_wer 22.399 | bleu 24.87 | wps 1615.6 | wpb 6138.4 | bsz 201.1 | num_updates 6919 | best_bleu 24.87
2023-08-23 15:55:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6919 updates
2023-08-23 15:55:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 15:55:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 15:55:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 6 @ 6919 updates, score 24.87) (writing took 11.995898005901836 seconds)
2023-08-23 15:55:41 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-23 15:55:41 | INFO | train | epoch 006 | loss 1.989 | trans_loss 3.429 | nll_loss 1.499 | w2v_ctc_loss 1.093 | task_loss 1.557 | contrastive_loss 0 | total 6703.69 | n_correct 4215.42 | ppl 2.83 | accuracy 62.882 | wps 17637.9 | ups 0.91 | wpb 19422.7 | bsz 678.2 | num_updates 6919 | lr 0.000170017 | gnorm 0.357 | clip 0 | loss_scale 8 | train_wall 1202 | gb_free 13.5 | wall 4927
2023-08-23 15:55:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 15:55:41 | INFO | fairseq.trainer | begin training epoch 7
2023-08-23 15:55:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 15:57:11 | INFO | train_inner | epoch 007:     81 / 1191 loss=1.933, trans_loss=3.396, nll_loss=1.457, w2v_ctc_loss=1.037, task_loss=1.464, contrastive_loss=0, total=6775.41, n_correct=4338.89, ppl=2.74, accuracy=64.039, wps=12617, ups=0.64, wpb=19623.5, bsz=713.8, num_updates=7000, lr=0.000169031, gnorm=0.349, clip=0, loss_scale=8, train_wall=101, gb_free=14.3, wall=5017
2023-08-23 15:58:53 | INFO | train_inner | epoch 007:    181 / 1191 loss=1.933, trans_loss=3.391, nll_loss=1.453, w2v_ctc_loss=1.038, task_loss=1.604, contrastive_loss=0, total=6653.21, n_correct=4270.07, ppl=2.74, accuracy=64.181, wps=18943.5, ups=0.98, wpb=19286.7, bsz=663.4, num_updates=7100, lr=0.000167836, gnorm=0.352, clip=0, loss_scale=16, train_wall=101, gb_free=13.4, wall=5119
2023-08-23 16:00:34 | INFO | train_inner | epoch 007:    281 / 1191 loss=1.923, trans_loss=3.382, nll_loss=1.44, w2v_ctc_loss=1.03, task_loss=1.537, contrastive_loss=0, total=6709.37, n_correct=4332.85, ppl=2.71, accuracy=64.579, wps=19225.3, ups=0.99, wpb=19446.4, bsz=678.5, num_updates=7200, lr=0.000166667, gnorm=0.345, clip=0, loss_scale=16, train_wall=100, gb_free=12.6, wall=5220
2023-08-23 16:02:14 | INFO | train_inner | epoch 007:    381 / 1191 loss=1.903, trans_loss=3.378, nll_loss=1.436, w2v_ctc_loss=1.006, task_loss=1.454, contrastive_loss=0, total=6761.77, n_correct=4374.88, ppl=2.71, accuracy=64.7, wps=19744.7, ups=1.01, wpb=19596.7, bsz=703.8, num_updates=7300, lr=0.000165521, gnorm=0.344, clip=0, loss_scale=16, train_wall=99, gb_free=11.1, wall=5320
2023-08-23 16:03:54 | INFO | train_inner | epoch 007:    481 / 1191 loss=1.917, trans_loss=3.391, nll_loss=1.453, w2v_ctc_loss=1.018, task_loss=1.515, contrastive_loss=0, total=6747.53, n_correct=4339.74, ppl=2.74, accuracy=64.316, wps=19429.4, ups=0.99, wpb=19557.2, bsz=692.4, num_updates=7400, lr=0.000164399, gnorm=0.35, clip=0, loss_scale=16, train_wall=100, gb_free=14.9, wall=5420
2023-08-23 16:05:37 | INFO | train_inner | epoch 007:    581 / 1191 loss=1.924, trans_loss=3.399, nll_loss=1.461, w2v_ctc_loss=1.023, task_loss=1.592, contrastive_loss=0, total=6720.23, n_correct=4312.9, ppl=2.75, accuracy=64.178, wps=18941.9, ups=0.97, wpb=19461.3, bsz=676.8, num_updates=7500, lr=0.000163299, gnorm=0.351, clip=0, loss_scale=16, train_wall=102, gb_free=14.6, wall=5523
2023-08-23 16:07:19 | INFO | train_inner | epoch 007:    681 / 1191 loss=1.915, trans_loss=3.39, nll_loss=1.45, w2v_ctc_loss=1.017, task_loss=1.514, contrastive_loss=0, total=6765.61, n_correct=4365.15, ppl=2.73, accuracy=64.52, wps=19154.3, ups=0.98, wpb=19595.8, bsz=693.3, num_updates=7600, lr=0.000162221, gnorm=0.345, clip=0, loss_scale=16, train_wall=102, gb_free=15.2, wall=5625
2023-08-23 16:09:00 | INFO | train_inner | epoch 007:    781 / 1191 loss=1.909, trans_loss=3.39, nll_loss=1.451, w2v_ctc_loss=1.008, task_loss=1.626, contrastive_loss=0, total=6664.82, n_correct=4305.95, ppl=2.73, accuracy=64.607, wps=19081, ups=0.99, wpb=19308.5, bsz=658.3, num_updates=7700, lr=0.000161165, gnorm=0.349, clip=0, loss_scale=16, train_wall=100, gb_free=14.1, wall=5727
2023-08-23 16:10:42 | INFO | train_inner | epoch 007:    881 / 1191 loss=1.912, trans_loss=3.39, nll_loss=1.451, w2v_ctc_loss=1.01, task_loss=1.609, contrastive_loss=0, total=6620.7, n_correct=4274.79, ppl=2.73, accuracy=64.567, wps=18891.8, ups=0.99, wpb=19179.4, bsz=658, num_updates=7800, lr=0.000160128, gnorm=0.349, clip=0, loss_scale=16, train_wall=101, gb_free=14.1, wall=5828
2023-08-23 16:12:25 | INFO | train_inner | epoch 007:    981 / 1191 loss=1.917, trans_loss=3.394, nll_loss=1.455, w2v_ctc_loss=1.019, task_loss=1.639, contrastive_loss=0, total=6671.41, n_correct=4307.63, ppl=2.74, accuracy=64.569, wps=18781.7, ups=0.97, wpb=19317.9, bsz=654.7, num_updates=7900, lr=0.000159111, gnorm=0.35, clip=0, loss_scale=16, train_wall=102, gb_free=13.7, wall=5931
2023-08-23 16:14:07 | INFO | train_inner | epoch 007:   1081 / 1191 loss=1.905, trans_loss=3.387, nll_loss=1.448, w2v_ctc_loss=1.006, task_loss=1.475, contrastive_loss=0, total=6713.03, n_correct=4345.29, ppl=2.73, accuracy=64.729, wps=19088.2, ups=0.98, wpb=19439.8, bsz=705.9, num_updates=8000, lr=0.000158114, gnorm=0.345, clip=0, loss_scale=16, train_wall=101, gb_free=11.1, wall=6033
2023-08-23 16:14:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 16:14:40 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 3.954 | trans_loss 5.302 | nll_loss 2.536 | w2v_ctc_loss 1.201 | task_loss 8.493 | contrastive_loss 0 | total 6138.43 | n_correct 4046.14 | ppl 5.8 | accuracy 65.915 | uer 18.597 | wer 20.45 | raw_wer 20.45 | bleu 25.7 | wps 1721.2 | wpb 6138.4 | bsz 201.1 | num_updates 8000 | best_bleu 25.7
2023-08-23 16:14:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8000 updates
2023-08-23 16:14:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_7_8000.pt
2023-08-23 16:14:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_7_8000.pt
2023-08-23 16:14:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_7_8000.pt (epoch 7 @ 8000 updates, score 25.7) (writing took 12.175197871983983 seconds)
2023-08-23 16:16:34 | INFO | train_inner | epoch 007:   1181 / 1191 loss=1.918, trans_loss=3.393, nll_loss=1.458, w2v_ctc_loss=1.019, task_loss=1.674, contrastive_loss=0, total=6680.29, n_correct=4304.58, ppl=2.75, accuracy=64.437, wps=13173, ups=0.68, wpb=19366.8, bsz=651.9, num_updates=8100, lr=0.000157135, gnorm=0.35, clip=0, loss_scale=16, train_wall=101, gb_free=14.6, wall=6180
2023-08-23 16:16:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 16:17:17 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 3.958 | trans_loss 5.302 | nll_loss 2.537 | w2v_ctc_loss 1.215 | task_loss 8.382 | contrastive_loss 0 | total 6138.43 | n_correct 4043.57 | ppl 5.8 | accuracy 65.873 | uer 19.046 | wer 20.655 | raw_wer 20.655 | bleu 25.67 | wps 1669.7 | wpb 6138.4 | bsz 201.1 | num_updates 8110 | best_bleu 25.7
2023-08-23 16:17:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8110 updates
2023-08-23 16:17:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_25.6709.pt
2023-08-23 16:17:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_25.6709.pt
2023-08-23 16:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_25.6709.pt (epoch 7 @ 8110 updates, score 25.67) (writing took 7.499423781991936 seconds)
2023-08-23 16:17:25 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-23 16:17:25 | INFO | train | epoch 007 | loss 1.916 | trans_loss 3.39 | nll_loss 1.451 | w2v_ctc_loss 1.018 | task_loss 1.559 | contrastive_loss 0 | total 6703.69 | n_correct 4321.63 | ppl 2.73 | accuracy 64.467 | wps 17735.1 | ups 0.91 | wpb 19422.7 | bsz 678.2 | num_updates 8110 | lr 0.000157038 | gnorm 0.348 | clip 0 | loss_scale 16 | train_wall 1201 | gb_free 13.1 | wall 6231
2023-08-23 16:17:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 16:17:25 | INFO | fairseq.trainer | begin training epoch 8
2023-08-23 16:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 16:19:05 | INFO | train_inner | epoch 008:     90 / 1191 loss=1.86, trans_loss=3.358, nll_loss=1.409, w2v_ctc_loss=0.958, task_loss=1.56, contrastive_loss=0, total=6692.44, n_correct=4387.08, ppl=2.66, accuracy=65.553, wps=12799.2, ups=0.66, wpb=19382.4, bsz=673.7, num_updates=8200, lr=0.000156174, gnorm=0.339, clip=0, loss_scale=16, train_wall=101, gb_free=14.8, wall=6331
2023-08-23 16:20:46 | INFO | train_inner | epoch 008:    190 / 1191 loss=1.863, trans_loss=3.35, nll_loss=1.404, w2v_ctc_loss=0.968, task_loss=1.431, contrastive_loss=0, total=6816.01, n_correct=4478.55, ppl=2.65, accuracy=65.706, wps=19500.8, ups=0.99, wpb=19767.9, bsz=733.7, num_updates=8300, lr=0.00015523, gnorm=0.343, clip=0, loss_scale=16, train_wall=101, gb_free=14.6, wall=6433
2023-08-23 16:22:29 | INFO | train_inner | epoch 008:    290 / 1191 loss=1.874, trans_loss=3.368, nll_loss=1.422, w2v_ctc_loss=0.974, task_loss=1.584, contrastive_loss=0, total=6700.06, n_correct=4380.29, ppl=2.68, accuracy=65.377, wps=19012.7, ups=0.98, wpb=19406.2, bsz=678.1, num_updates=8400, lr=0.000154303, gnorm=0.347, clip=0, loss_scale=16, train_wall=101, gb_free=13.5, wall=6535
2023-08-23 16:24:12 | INFO | train_inner | epoch 008:    390 / 1191 loss=1.877, trans_loss=3.368, nll_loss=1.425, w2v_ctc_loss=0.975, task_loss=1.663, contrastive_loss=0, total=6656.3, n_correct=4336.77, ppl=2.69, accuracy=65.153, wps=18747.3, ups=0.97, wpb=19300.5, bsz=648.6, num_updates=8500, lr=0.000153393, gnorm=0.351, clip=0, loss_scale=16, train_wall=102, gb_free=12.7, wall=6638
2023-08-23 16:25:53 | INFO | train_inner | epoch 008:    490 / 1191 loss=1.87, trans_loss=3.362, nll_loss=1.416, w2v_ctc_loss=0.97, task_loss=1.653, contrastive_loss=0, total=6650, n_correct=4355.11, ppl=2.67, accuracy=65.49, wps=18958.5, ups=0.98, wpb=19268.5, bsz=651.1, num_updates=8600, lr=0.000152499, gnorm=0.347, clip=0, loss_scale=16, train_wall=101, gb_free=10, wall=6739
2023-08-23 16:27:35 | INFO | train_inner | epoch 008:    590 / 1191 loss=1.866, trans_loss=3.363, nll_loss=1.418, w2v_ctc_loss=0.964, task_loss=1.569, contrastive_loss=0, total=6684.85, n_correct=4377.99, ppl=2.67, accuracy=65.491, wps=19085.7, ups=0.99, wpb=19367.6, bsz=676.8, num_updates=8700, lr=0.00015162, gnorm=0.345, clip=0, loss_scale=16, train_wall=101, gb_free=14.3, wall=6841
2023-08-23 16:29:15 | INFO | train_inner | epoch 008:    690 / 1191 loss=1.864, trans_loss=3.366, nll_loss=1.422, w2v_ctc_loss=0.963, task_loss=1.554, contrastive_loss=0, total=6725.13, n_correct=4407.56, ppl=2.68, accuracy=65.539, wps=19343.1, ups=0.99, wpb=19487.3, bsz=674.5, num_updates=8800, lr=0.000150756, gnorm=0.342, clip=0, loss_scale=16, train_wall=100, gb_free=13.9, wall=6941
2023-08-23 16:30:56 | INFO | train_inner | epoch 008:    790 / 1191 loss=1.866, trans_loss=3.365, nll_loss=1.422, w2v_ctc_loss=0.964, task_loss=1.618, contrastive_loss=0, total=6662.47, n_correct=4367.14, ppl=2.68, accuracy=65.548, wps=19149.5, ups=0.99, wpb=19305.3, bsz=659.3, num_updates=8900, lr=0.000149906, gnorm=0.344, clip=0, loss_scale=16, train_wall=100, gb_free=12.3, wall=7042
2023-08-23 16:32:37 | INFO | train_inner | epoch 008:    890 / 1191 loss=1.855, trans_loss=3.356, nll_loss=1.411, w2v_ctc_loss=0.958, task_loss=1.415, contrastive_loss=0, total=6816.87, n_correct=4487.35, ppl=2.66, accuracy=65.827, wps=19566.2, ups=0.99, wpb=19751.4, bsz=720.8, num_updates=9000, lr=0.000149071, gnorm=0.344, clip=0, loss_scale=16, train_wall=100, gb_free=14.1, wall=7143
2023-08-23 16:34:19 | INFO | train_inner | epoch 008:    990 / 1191 loss=1.87, trans_loss=3.375, nll_loss=1.432, w2v_ctc_loss=0.967, task_loss=1.634, contrastive_loss=0, total=6634.76, n_correct=4331.42, ppl=2.7, accuracy=65.284, wps=18865.4, ups=0.98, wpb=19213.4, bsz=656.4, num_updates=9100, lr=0.00014825, gnorm=0.347, clip=0, loss_scale=16, train_wall=101, gb_free=14.4, wall=7245
2023-08-23 16:36:00 | INFO | train_inner | epoch 008:   1090 / 1191 loss=1.859, trans_loss=3.364, nll_loss=1.417, w2v_ctc_loss=0.955, task_loss=1.559, contrastive_loss=0, total=6721.6, n_correct=4419.27, ppl=2.67, accuracy=65.747, wps=19179, ups=0.99, wpb=19452.5, bsz=673.6, num_updates=9200, lr=0.000147442, gnorm=0.348, clip=0, loss_scale=32, train_wall=101, gb_free=13.4, wall=7347
2023-08-23 16:37:41 | INFO | train_inner | epoch 008:   1190 / 1191 loss=1.849, trans_loss=3.355, nll_loss=1.411, w2v_ctc_loss=0.947, task_loss=1.513, contrastive_loss=0, total=6677.82, n_correct=4394.24, ppl=2.66, accuracy=65.804, wps=19203.3, ups=0.99, wpb=19354.8, bsz=692.7, num_updates=9300, lr=0.000146647, gnorm=0.344, clip=0, loss_scale=32, train_wall=100, gb_free=15.4, wall=7447
2023-08-23 16:37:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 16:38:16 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 3.936 | trans_loss 5.276 | nll_loss 2.499 | w2v_ctc_loss 1.198 | task_loss 8.453 | contrastive_loss 0 | total 6138.43 | n_correct 4075.57 | ppl 5.65 | accuracy 66.394 | uer 18.137 | wer 19.922 | raw_wer 19.922 | bleu 26.13 | wps 1651.2 | wpb 6138.4 | bsz 201.1 | num_updates 9301 | best_bleu 26.13
2023-08-23 16:38:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 9301 updates
2023-08-23 16:38:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 16:38:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 16:38:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 8 @ 9301 updates, score 26.13) (writing took 12.839486537035555 seconds)
2023-08-23 16:38:29 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-23 16:38:29 | INFO | train | epoch 008 | loss 1.864 | trans_loss 3.362 | nll_loss 1.417 | w2v_ctc_loss 0.963 | task_loss 1.561 | contrastive_loss 0 | total 6703.69 | n_correct 4394.32 | ppl 2.67 | accuracy 65.551 | wps 18306.3 | ups 0.94 | wpb 19422.7 | bsz 678.2 | num_updates 9301 | lr 0.000146639 | gnorm 0.345 | clip 0 | loss_scale 32 | train_wall 1201 | gb_free 14.3 | wall 7495
2023-08-23 16:38:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 16:38:29 | INFO | fairseq.trainer | begin training epoch 9
2023-08-23 16:38:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 16:40:15 | INFO | train_inner | epoch 009:     99 / 1191 loss=1.803, trans_loss=3.328, nll_loss=1.371, w2v_ctc_loss=0.899, task_loss=1.472, contrastive_loss=0, total=6764.93, n_correct=4515.96, ppl=2.59, accuracy=66.755, wps=12707.6, ups=0.65, wpb=19589.8, bsz=708.6, num_updates=9400, lr=0.000145865, gnorm=0.338, clip=0, loss_scale=32, train_wall=99, gb_free=14.6, wall=7601
2023-08-23 16:41:58 | INFO | train_inner | epoch 009:    199 / 1191 loss=1.825, trans_loss=3.332, nll_loss=1.38, w2v_ctc_loss=0.927, task_loss=1.571, contrastive_loss=0, total=6741.18, n_correct=4482.51, ppl=2.6, accuracy=66.494, wps=19117.9, ups=0.98, wpb=19544.9, bsz=681.5, num_updates=9500, lr=0.000145095, gnorm=0.341, clip=0, loss_scale=32, train_wall=101, gb_free=13.6, wall=7704
2023-08-23 16:43:38 | INFO | train_inner | epoch 009:    299 / 1191 loss=1.83, trans_loss=3.343, nll_loss=1.39, w2v_ctc_loss=0.931, task_loss=1.451, contrastive_loss=0, total=6825.68, n_correct=4533.81, ppl=2.62, accuracy=66.423, wps=19614.2, ups=0.99, wpb=19756.6, bsz=710.3, num_updates=9600, lr=0.000144338, gnorm=0.344, clip=0, loss_scale=32, train_wall=100, gb_free=10, wall=7804
2023-08-23 16:45:22 | INFO | train_inner | epoch 009:    399 / 1191 loss=1.829, trans_loss=3.34, nll_loss=1.39, w2v_ctc_loss=0.927, task_loss=1.588, contrastive_loss=0, total=6719.95, n_correct=4460.28, ppl=2.62, accuracy=66.374, wps=18830.6, ups=0.97, wpb=19474.7, bsz=680.6, num_updates=9700, lr=0.000143592, gnorm=0.345, clip=0, loss_scale=32, train_wall=103, gb_free=10.9, wall=7908
2023-08-23 16:47:04 | INFO | train_inner | epoch 009:    499 / 1191 loss=1.829, trans_loss=3.342, nll_loss=1.394, w2v_ctc_loss=0.926, task_loss=1.516, contrastive_loss=0, total=6719.95, n_correct=4459.16, ppl=2.63, accuracy=66.357, wps=19067.2, ups=0.98, wpb=19476.9, bsz=700.2, num_updates=9800, lr=0.000142857, gnorm=0.347, clip=0, loss_scale=32, train_wall=102, gb_free=13.6, wall=8010
2023-08-23 16:48:44 | INFO | train_inner | epoch 009:    599 / 1191 loss=1.824, trans_loss=3.341, nll_loss=1.39, w2v_ctc_loss=0.92, task_loss=1.637, contrastive_loss=0, total=6593.39, n_correct=4382.59, ppl=2.62, accuracy=66.469, wps=19121.1, ups=1, wpb=19101.8, bsz=652.6, num_updates=9900, lr=0.000142134, gnorm=0.346, clip=0, loss_scale=32, train_wall=99, gb_free=12.5, wall=8110
2023-08-23 16:50:24 | INFO | train_inner | epoch 009:    699 / 1191 loss=1.831, trans_loss=3.352, nll_loss=1.404, w2v_ctc_loss=0.922, task_loss=1.732, contrastive_loss=0, total=6574.12, n_correct=4346.74, ppl=2.65, accuracy=66.119, wps=18923.7, ups=0.99, wpb=19038.5, bsz=624.8, num_updates=10000, lr=0.000141421, gnorm=0.348, clip=0, loss_scale=32, train_wall=100, gb_free=9.8, wall=8211
2023-08-23 16:50:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 16:50:58 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.935 | trans_loss 5.263 | nll_loss 2.49 | w2v_ctc_loss 1.224 | task_loss 8.505 | contrastive_loss 0 | total 6138.43 | n_correct 4089.29 | ppl 5.62 | accuracy 66.618 | uer 18.276 | wer 19.877 | raw_wer 19.877 | bleu 25.99 | wps 1653.7 | wpb 6138.4 | bsz 201.1 | num_updates 10000 | best_bleu 26.13
2023-08-23 16:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10000 updates
2023-08-23 16:50:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_9_10000.pt
2023-08-23 16:51:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_9_10000.pt
2023-08-23 16:51:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_9_10000.pt (epoch 9 @ 10000 updates, score 25.99) (writing took 8.673943905043416 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:0')
2023-08-23 16:52:49 | INFO | train_inner | epoch 009:    799 / 1191 loss=1.824, trans_loss=3.346, nll_loss=1.398, w2v_ctc_loss=0.918, task_loss=1.596, contrastive_loss=0, total=6678.12, n_correct=4429.11, ppl=2.64, accuracy=66.323, wps=13402, ups=0.69, wpb=19354.2, bsz=667.4, num_updates=10100, lr=0.00014072, gnorm=0.289, clip=0, loss_scale=32, train_wall=101, gb_free=11.9, wall=8355
2023-08-23 16:54:30 | INFO | train_inner | epoch 009:    899 / 1191 loss=1.82, trans_loss=3.343, nll_loss=1.394, w2v_ctc_loss=0.916, task_loss=1.499, contrastive_loss=0, total=6769.41, n_correct=4502.66, ppl=2.63, accuracy=66.515, wps=19379.7, ups=0.99, wpb=19612.2, bsz=693.4, num_updates=10200, lr=0.000140028, gnorm=0.285, clip=0, loss_scale=32, train_wall=101, gb_free=11.1, wall=8456
2023-08-23 16:56:12 | INFO | train_inner | epoch 009:    999 / 1191 loss=1.827, trans_loss=3.344, nll_loss=1.396, w2v_ctc_loss=0.926, task_loss=1.571, contrastive_loss=0, total=6710.67, n_correct=4451.33, ppl=2.63, accuracy=66.332, wps=19114.4, ups=0.98, wpb=19445.4, bsz=676.4, num_updates=10300, lr=0.000139347, gnorm=0.288, clip=0, loss_scale=32, train_wall=101, gb_free=12.5, wall=8558
2023-08-23 16:57:53 | INFO | train_inner | epoch 009:   1099 / 1191 loss=1.819, trans_loss=3.339, nll_loss=1.392, w2v_ctc_loss=0.917, task_loss=1.526, contrastive_loss=0, total=6673.98, n_correct=4437.4, ppl=2.62, accuracy=66.488, wps=19086.5, ups=0.99, wpb=19345.4, bsz=686, num_updates=10400, lr=0.000138675, gnorm=0.29, clip=0, loss_scale=32, train_wall=101, gb_free=14.8, wall=8659
2023-08-23 16:59:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:5')
2023-08-23 17:00:00 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.922 | trans_loss 5.255 | nll_loss 2.477 | w2v_ctc_loss 1.199 | task_loss 8.478 | contrastive_loss 0 | total 6138.43 | n_correct 4083.86 | ppl 5.57 | accuracy 66.529 | uer 18.15 | wer 19.944 | raw_wer 19.944 | bleu 26.4 | wps 1612.7 | wpb 6138.4 | bsz 201.1 | num_updates 10492 | best_bleu 26.4
2023-08-23 17:00:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10492 updates
2023-08-23 17:00:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 17:00:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 17:00:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 9 @ 10492 updates, score 26.4) (writing took 13.777597622945905 seconds)
2023-08-23 17:00:15 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-23 17:00:15 | INFO | train | epoch 009 | loss 1.824 | trans_loss 3.341 | nll_loss 1.391 | w2v_ctc_loss 0.921 | task_loss 1.563 | contrastive_loss 0 | total 6703.69 | n_correct 4452.6 | ppl 2.62 | accuracy 66.42 | wps 17714.2 | ups 0.91 | wpb 19422.7 | bsz 678.2 | num_updates 10492 | lr 0.000138066 | gnorm 0.321 | clip 0 | loss_scale 32 | train_wall 1198 | gb_free 14.5 | wall 8801
2023-08-23 17:00:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 17:00:15 | INFO | fairseq.trainer | begin training epoch 10
2023-08-23 17:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 17:00:30 | INFO | train_inner | epoch 010:      8 / 1191 loss=1.826, trans_loss=3.342, nll_loss=1.393, w2v_ctc_loss=0.923, task_loss=1.66, contrastive_loss=0, total=6634.33, n_correct=4408.71, ppl=2.63, accuracy=66.453, wps=12225.2, ups=0.64, wpb=19219.1, bsz=644.5, num_updates=10500, lr=0.000138013, gnorm=0.287, clip=0, loss_scale=32, train_wall=100, gb_free=11.9, wall=8816
2023-08-23 17:02:11 | INFO | train_inner | epoch 010:    108 / 1191 loss=1.78, trans_loss=3.311, nll_loss=1.353, w2v_ctc_loss=0.876, task_loss=1.564, contrastive_loss=0, total=6683.11, n_correct=4510.17, ppl=2.55, accuracy=67.486, wps=19276.8, ups=1, wpb=19364.2, bsz=676.6, num_updates=10600, lr=0.000137361, gnorm=0.283, clip=0, loss_scale=32, train_wall=100, gb_free=11.4, wall=8917
2023-08-23 17:03:51 | INFO | train_inner | epoch 010:    208 / 1191 loss=1.791, trans_loss=3.321, nll_loss=1.367, w2v_ctc_loss=0.888, task_loss=1.51, contrastive_loss=0, total=6689.31, n_correct=4486.47, ppl=2.58, accuracy=67.069, wps=19293.2, ups=1, wpb=19387.4, bsz=697.3, num_updates=10700, lr=0.000136717, gnorm=0.287, clip=0, loss_scale=32, train_wall=100, gb_free=13.5, wall=9017
2023-08-23 17:05:34 | INFO | train_inner | epoch 010:    308 / 1191 loss=1.794, trans_loss=3.323, nll_loss=1.366, w2v_ctc_loss=0.89, task_loss=1.562, contrastive_loss=0, total=6782.86, n_correct=4552.48, ppl=2.58, accuracy=67.117, wps=19180.8, ups=0.98, wpb=19640.9, bsz=684.8, num_updates=10800, lr=0.000136083, gnorm=0.285, clip=0, loss_scale=32, train_wall=102, gb_free=10.9, wall=9120
2023-08-23 17:07:16 | INFO | train_inner | epoch 010:    408 / 1191 loss=1.801, trans_loss=3.327, nll_loss=1.374, w2v_ctc_loss=0.9, task_loss=1.473, contrastive_loss=0, total=6805.84, n_correct=4556.83, ppl=2.59, accuracy=66.955, wps=19273.2, ups=0.98, wpb=19710.8, bsz=724, num_updates=10900, lr=0.000135457, gnorm=0.285, clip=0, loss_scale=32, train_wall=102, gb_free=14.1, wall=9222
2023-08-23 17:08:57 | INFO | train_inner | epoch 010:    508 / 1191 loss=1.799, trans_loss=3.322, nll_loss=1.366, w2v_ctc_loss=0.898, task_loss=1.612, contrastive_loss=0, total=6707.8, n_correct=4503.87, ppl=2.58, accuracy=67.144, wps=19252.7, ups=0.99, wpb=19425.2, bsz=659.1, num_updates=11000, lr=0.00013484, gnorm=0.285, clip=0, loss_scale=32, train_wall=100, gb_free=13.9, wall=9323
2023-08-23 17:10:38 | INFO | train_inner | epoch 010:    608 / 1191 loss=1.787, trans_loss=3.323, nll_loss=1.37, w2v_ctc_loss=0.883, task_loss=1.452, contrastive_loss=0, total=6821.62, n_correct=4578.82, ppl=2.59, accuracy=67.122, wps=19646.1, ups=0.99, wpb=19768.3, bsz=704.2, num_updates=11100, lr=0.000134231, gnorm=0.287, clip=0, loss_scale=32, train_wall=100, gb_free=14.8, wall=9424
2023-08-23 17:12:20 | INFO | train_inner | epoch 010:    708 / 1191 loss=1.806, trans_loss=3.329, nll_loss=1.377, w2v_ctc_loss=0.906, task_loss=1.643, contrastive_loss=0, total=6652.8, n_correct=4449.65, ppl=2.6, accuracy=66.884, wps=18886.6, ups=0.98, wpb=19274.7, bsz=661.9, num_updates=11200, lr=0.000133631, gnorm=0.287, clip=0, loss_scale=64, train_wall=101, gb_free=13.6, wall=9526
2023-08-23 17:14:01 | INFO | train_inner | epoch 010:    808 / 1191 loss=1.801, trans_loss=3.323, nll_loss=1.371, w2v_ctc_loss=0.902, task_loss=1.656, contrastive_loss=0, total=6624.55, n_correct=4446.43, ppl=2.59, accuracy=67.12, wps=18894.5, ups=0.98, wpb=19201.1, bsz=654.4, num_updates=11300, lr=0.000133038, gnorm=0.289, clip=0, loss_scale=64, train_wall=101, gb_free=14.4, wall=9627
2023-08-23 17:15:44 | INFO | train_inner | epoch 010:    908 / 1191 loss=1.795, trans_loss=3.327, nll_loss=1.375, w2v_ctc_loss=0.89, task_loss=1.671, contrastive_loss=0, total=6575.8, n_correct=4411.95, ppl=2.59, accuracy=67.094, wps=18596, ups=0.98, wpb=19054.2, bsz=641.6, num_updates=11400, lr=0.000132453, gnorm=0.29, clip=0, loss_scale=64, train_wall=102, gb_free=12.9, wall=9730
2023-08-23 17:17:24 | INFO | train_inner | epoch 010:   1008 / 1191 loss=1.793, trans_loss=3.322, nll_loss=1.37, w2v_ctc_loss=0.891, task_loss=1.516, contrastive_loss=0, total=6717.45, n_correct=4514.46, ppl=2.58, accuracy=67.205, wps=19329.1, ups=0.99, wpb=19464.1, bsz=681.7, num_updates=11500, lr=0.000131876, gnorm=0.286, clip=0, loss_scale=64, train_wall=100, gb_free=12.9, wall=9830
2023-08-23 17:18:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 17:19:08 | INFO | train_inner | epoch 010:   1109 / 1191 loss=1.806, trans_loss=3.326, nll_loss=1.375, w2v_ctc_loss=0.907, task_loss=1.546, contrastive_loss=0, total=6700.4, n_correct=4489.57, ppl=2.59, accuracy=67.005, wps=18812.7, ups=0.97, wpb=19420.2, bsz=681.2, num_updates=11600, lr=0.000131306, gnorm=0.286, clip=0, loss_scale=32, train_wall=103, gb_free=14.2, wall=9934
2023-08-23 17:20:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 17:21:02 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.902 | trans_loss 5.237 | nll_loss 2.456 | w2v_ctc_loss 1.176 | task_loss 8.507 | contrastive_loss 0 | total 6138.43 | n_correct 4105.86 | ppl 5.49 | accuracy 66.888 | uer 17.53 | wer 19.394 | raw_wer 19.394 | bleu 26.57 | wps 1767.4 | wpb 6138.4 | bsz 201.1 | num_updates 11682 | best_bleu 26.57
2023-08-23 17:21:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11682 updates
2023-08-23 17:21:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 17:21:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 17:21:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 10 @ 11682 updates, score 26.57) (writing took 11.721676427056082 seconds)
2023-08-23 17:21:15 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-23 17:21:15 | INFO | train | epoch 010 | loss 1.795 | trans_loss 3.323 | nll_loss 1.37 | w2v_ctc_loss 0.893 | task_loss 1.563 | contrastive_loss 0 | total 6702.9 | n_correct 4498.51 | ppl 2.58 | accuracy 67.113 | wps 18342.9 | ups 0.94 | wpb 19420.4 | bsz 678.1 | num_updates 11682 | lr 0.000130845 | gnorm 0.286 | clip 0 | loss_scale 32 | train_wall 1199 | gb_free 12.3 | wall 10061
2023-08-23 17:21:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 17:21:15 | INFO | fairseq.trainer | begin training epoch 11
2023-08-23 17:21:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 17:21:41 | INFO | train_inner | epoch 011:     18 / 1191 loss=1.79, trans_loss=3.32, nll_loss=1.367, w2v_ctc_loss=0.886, task_loss=1.579, contrastive_loss=0, total=6685.59, n_correct=4494.81, ppl=2.58, accuracy=67.231, wps=12670.7, ups=0.65, wpb=19376.3, bsz=671.1, num_updates=11700, lr=0.000130744, gnorm=0.286, clip=0, loss_scale=32, train_wall=100, gb_free=10.8, wall=10087
2023-08-23 17:23:23 | INFO | train_inner | epoch 011:    118 / 1191 loss=1.772, trans_loss=3.302, nll_loss=1.342, w2v_ctc_loss=0.872, task_loss=1.616, contrastive_loss=0, total=6661.03, n_correct=4511.95, ppl=2.54, accuracy=67.737, wps=19057.6, ups=0.99, wpb=19302, bsz=660.3, num_updates=11800, lr=0.000130189, gnorm=0.288, clip=0, loss_scale=32, train_wall=100, gb_free=15, wall=10189
2023-08-23 17:25:04 | INFO | train_inner | epoch 011:    218 / 1191 loss=1.758, trans_loss=3.303, nll_loss=1.343, w2v_ctc_loss=0.853, task_loss=1.51, contrastive_loss=0, total=6714.74, n_correct=4559.79, ppl=2.54, accuracy=67.907, wps=19239.1, ups=0.99, wpb=19447.2, bsz=699.6, num_updates=11900, lr=0.000129641, gnorm=0.285, clip=0, loss_scale=32, train_wall=100, gb_free=11.9, wall=10290
2023-08-23 17:26:44 | INFO | train_inner | epoch 011:    318 / 1191 loss=1.767, trans_loss=3.302, nll_loss=1.342, w2v_ctc_loss=0.865, task_loss=1.6, contrastive_loss=0, total=6608.12, n_correct=4479.02, ppl=2.54, accuracy=67.781, wps=19029.6, ups=0.99, wpb=19144, bsz=661.1, num_updates=12000, lr=0.000129099, gnorm=0.29, clip=0, loss_scale=32, train_wall=100, gb_free=12.1, wall=10391
2023-08-23 17:26:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 17:27:17 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.899 | trans_loss 5.233 | nll_loss 2.451 | w2v_ctc_loss 1.176 | task_loss 8.569 | contrastive_loss 0 | total 6138.43 | n_correct 4113.57 | ppl 5.47 | accuracy 67.013 | uer 17.255 | wer 18.944 | raw_wer 18.944 | bleu 26.37 | wps 1722.8 | wpb 6138.4 | bsz 201.1 | num_updates 12000 | best_bleu 26.57
2023-08-23 17:27:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12000 updates
2023-08-23 17:27:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_11_12000.pt
2023-08-23 17:27:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_11_12000.pt
2023-08-23 17:27:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_11_12000.pt (epoch 11 @ 12000 updates, score 26.37) (writing took 7.038788354955614 seconds)
2023-08-23 17:29:06 | INFO | train_inner | epoch 011:    418 / 1191 loss=1.773, trans_loss=3.303, nll_loss=1.346, w2v_ctc_loss=0.872, task_loss=1.609, contrastive_loss=0, total=6617.8, n_correct=4482.76, ppl=2.54, accuracy=67.738, wps=13559.7, ups=0.71, wpb=19187.4, bsz=666.6, num_updates=12100, lr=0.000128565, gnorm=0.29, clip=0, loss_scale=32, train_wall=100, gb_free=14, wall=10532
2023-08-23 17:30:48 | INFO | train_inner | epoch 011:    518 / 1191 loss=1.779, trans_loss=3.314, nll_loss=1.359, w2v_ctc_loss=0.876, task_loss=1.693, contrastive_loss=0, total=6625.9, n_correct=4469.15, ppl=2.57, accuracy=67.45, wps=18812.8, ups=0.98, wpb=19202.2, bsz=641.8, num_updates=12200, lr=0.000128037, gnorm=0.287, clip=0, loss_scale=32, train_wall=101, gb_free=14, wall=10634
2023-08-23 17:32:28 | INFO | train_inner | epoch 011:    618 / 1191 loss=1.775, trans_loss=3.305, nll_loss=1.35, w2v_ctc_loss=0.876, task_loss=1.625, contrastive_loss=0, total=6634.5, n_correct=4489.51, ppl=2.55, accuracy=67.669, wps=19230.9, ups=1, wpb=19242.5, bsz=654.1, num_updates=12300, lr=0.000127515, gnorm=0.29, clip=0, loss_scale=32, train_wall=99, gb_free=13.3, wall=10734
2023-08-23 17:34:10 | INFO | train_inner | epoch 011:    718 / 1191 loss=1.768, trans_loss=3.308, nll_loss=1.354, w2v_ctc_loss=0.863, task_loss=1.578, contrastive_loss=0, total=6704.9, n_correct=4538.58, ppl=2.56, accuracy=67.69, wps=19065.5, ups=0.98, wpb=19436, bsz=682.6, num_updates=12400, lr=0.000127, gnorm=0.287, clip=0, loss_scale=32, train_wall=101, gb_free=13.1, wall=10836
2023-08-23 17:35:51 | INFO | train_inner | epoch 011:    818 / 1191 loss=1.785, trans_loss=3.315, nll_loss=1.361, w2v_ctc_loss=0.886, task_loss=1.538, contrastive_loss=0, total=6805.08, n_correct=4595.49, ppl=2.57, accuracy=67.53, wps=19528.1, ups=0.99, wpb=19713.1, bsz=694.2, num_updates=12500, lr=0.000126491, gnorm=0.286, clip=0, loss_scale=32, train_wall=100, gb_free=11.7, wall=10937
2023-08-23 17:37:33 | INFO | train_inner | epoch 011:    918 / 1191 loss=1.764, trans_loss=3.313, nll_loss=1.356, w2v_ctc_loss=0.857, task_loss=1.485, contrastive_loss=0, total=6805.54, n_correct=4609.61, ppl=2.56, accuracy=67.733, wps=19249, ups=0.98, wpb=19705.5, bsz=699.4, num_updates=12600, lr=0.000125988, gnorm=0.283, clip=0, loss_scale=32, train_wall=102, gb_free=9.7, wall=11039
2023-08-23 17:39:16 | INFO | train_inner | epoch 011:   1018 / 1191 loss=1.765, trans_loss=3.312, nll_loss=1.355, w2v_ctc_loss=0.861, task_loss=1.479, contrastive_loss=0, total=6803.97, n_correct=4609.95, ppl=2.56, accuracy=67.754, wps=19259.1, ups=0.98, wpb=19695.5, bsz=702.6, num_updates=12700, lr=0.000125491, gnorm=0.284, clip=0, loss_scale=32, train_wall=102, gb_free=14.4, wall=11142
2023-08-23 17:40:56 | INFO | train_inner | epoch 011:   1118 / 1191 loss=1.777, trans_loss=3.313, nll_loss=1.359, w2v_ctc_loss=0.873, task_loss=1.518, contrastive_loss=0, total=6717.29, n_correct=4535.24, ppl=2.56, accuracy=67.516, wps=19386.1, ups=1, wpb=19459.1, bsz=692.7, num_updates=12800, lr=0.000125, gnorm=0.287, clip=0, loss_scale=32, train_wall=100, gb_free=13.8, wall=11242
2023-08-23 17:42:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 17:42:43 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.901 | trans_loss 5.223 | nll_loss 2.44 | w2v_ctc_loss 1.203 | task_loss 8.532 | contrastive_loss 0 | total 6138.43 | n_correct 4119.29 | ppl 5.43 | accuracy 67.107 | uer 17.244 | wer 18.929 | raw_wer 18.929 | bleu 26.85 | wps 1763.8 | wpb 6138.4 | bsz 201.1 | num_updates 12873 | best_bleu 26.85
2023-08-23 17:42:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12873 updates
2023-08-23 17:42:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 17:42:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 17:42:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 11 @ 12873 updates, score 26.85) (writing took 10.61297132098116 seconds)
2023-08-23 17:42:54 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-23 17:42:54 | INFO | train | epoch 011 | loss 1.772 | trans_loss 3.308 | nll_loss 1.352 | w2v_ctc_loss 0.869 | task_loss 1.564 | contrastive_loss 0 | total 6703.69 | n_correct 4537.63 | ppl 2.55 | accuracy 67.689 | wps 17798.9 | ups 0.92 | wpb 19422.7 | bsz 678.2 | num_updates 12873 | lr 0.000124645 | gnorm 0.287 | clip 0 | loss_scale 32 | train_wall 1199 | gb_free 13.2 | wall 11360
2023-08-23 17:42:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 17:42:54 | INFO | fairseq.trainer | begin training epoch 12
2023-08-23 17:42:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 17:43:29 | INFO | train_inner | epoch 012:     27 / 1191 loss=1.763, trans_loss=3.304, nll_loss=1.346, w2v_ctc_loss=0.86, task_loss=1.457, contrastive_loss=0, total=6806.91, n_correct=4628.28, ppl=2.54, accuracy=67.994, wps=12859.6, ups=0.65, wpb=19706.4, bsz=711.5, num_updates=12900, lr=0.000124515, gnorm=0.285, clip=0, loss_scale=32, train_wall=101, gb_free=12.9, wall=11395
2023-08-23 17:45:11 | INFO | train_inner | epoch 012:    127 / 1191 loss=1.735, trans_loss=3.28, nll_loss=1.315, w2v_ctc_loss=0.834, task_loss=1.537, contrastive_loss=0, total=6772.81, n_correct=4641.65, ppl=2.49, accuracy=68.534, wps=19233, ups=0.98, wpb=19627, bsz=680.8, num_updates=13000, lr=0.000124035, gnorm=0.284, clip=0, loss_scale=32, train_wall=101, gb_free=14, wall=11497
2023-08-23 17:46:52 | INFO | train_inner | epoch 012:    227 / 1191 loss=1.749, trans_loss=3.293, nll_loss=1.331, w2v_ctc_loss=0.845, task_loss=1.59, contrastive_loss=0, total=6693.81, n_correct=4560.57, ppl=2.52, accuracy=68.131, wps=19302.5, ups=1, wpb=19390.6, bsz=664.8, num_updates=13100, lr=0.00012356, gnorm=0.287, clip=0, loss_scale=32, train_wall=100, gb_free=14.2, wall=11598
2023-08-23 17:48:33 | INFO | train_inner | epoch 012:    327 / 1191 loss=1.741, trans_loss=3.289, nll_loss=1.329, w2v_ctc_loss=0.838, task_loss=1.475, contrastive_loss=0, total=6722, n_correct=4587.44, ppl=2.51, accuracy=68.245, wps=19189.3, ups=0.98, wpb=19485.1, bsz=705.4, num_updates=13200, lr=0.000123091, gnorm=0.287, clip=0, loss_scale=32, train_wall=101, gb_free=6.9, wall=11699
2023-08-23 17:50:14 | INFO | train_inner | epoch 012:    427 / 1191 loss=1.739, trans_loss=3.291, nll_loss=1.329, w2v_ctc_loss=0.835, task_loss=1.484, contrastive_loss=0, total=6751.98, n_correct=4613.91, ppl=2.51, accuracy=68.334, wps=19347.1, ups=0.99, wpb=19558.7, bsz=699.1, num_updates=13300, lr=0.000122628, gnorm=0.285, clip=0, loss_scale=32, train_wall=100, gb_free=13.4, wall=11801
2023-08-23 17:51:56 | INFO | train_inner | epoch 012:    527 / 1191 loss=1.739, trans_loss=3.292, nll_loss=1.331, w2v_ctc_loss=0.835, task_loss=1.49, contrastive_loss=0, total=6795.59, n_correct=4645.03, ppl=2.52, accuracy=68.354, wps=19314.2, ups=0.98, wpb=19687.5, bsz=697.2, num_updates=13400, lr=0.000122169, gnorm=0.285, clip=0, loss_scale=32, train_wall=101, gb_free=13.6, wall=11902
2023-08-23 17:53:37 | INFO | train_inner | epoch 012:    627 / 1191 loss=1.755, trans_loss=3.294, nll_loss=1.334, w2v_ctc_loss=0.854, task_loss=1.66, contrastive_loss=0, total=6664.69, n_correct=4540.05, ppl=2.52, accuracy=68.121, wps=19115.6, ups=0.99, wpb=19310.8, bsz=658.1, num_updates=13500, lr=0.000121716, gnorm=0.289, clip=0, loss_scale=32, train_wall=100, gb_free=11.3, wall=12003
2023-08-23 17:55:19 | INFO | train_inner | epoch 012:    727 / 1191 loss=1.744, trans_loss=3.29, nll_loss=1.332, w2v_ctc_loss=0.842, task_loss=1.515, contrastive_loss=0, total=6730.45, n_correct=4597.81, ppl=2.52, accuracy=68.314, wps=19191.8, ups=0.98, wpb=19516, bsz=689.9, num_updates=13600, lr=0.000121268, gnorm=0.285, clip=0, loss_scale=32, train_wall=101, gb_free=14.2, wall=12105
2023-08-23 17:57:01 | INFO | train_inner | epoch 012:    827 / 1191 loss=1.761, trans_loss=3.302, nll_loss=1.344, w2v_ctc_loss=0.858, task_loss=1.658, contrastive_loss=0, total=6641.77, n_correct=4514.6, ppl=2.54, accuracy=67.973, wps=18891.4, ups=0.98, wpb=19236.9, bsz=654.5, num_updates=13700, lr=0.000120824, gnorm=0.29, clip=0, loss_scale=64, train_wall=101, gb_free=14.1, wall=12207
2023-08-23 17:58:43 | INFO | train_inner | epoch 012:    927 / 1191 loss=1.756, trans_loss=3.31, nll_loss=1.354, w2v_ctc_loss=0.851, task_loss=1.604, contrastive_loss=0, total=6694.55, n_correct=4543.53, ppl=2.56, accuracy=67.869, wps=19077.8, ups=0.98, wpb=19387.7, bsz=676.8, num_updates=13800, lr=0.000120386, gnorm=0.289, clip=0, loss_scale=64, train_wall=101, gb_free=13.2, wall=12309
2023-08-23 18:00:24 | INFO | train_inner | epoch 012:   1027 / 1191 loss=1.76, trans_loss=3.297, nll_loss=1.342, w2v_ctc_loss=0.862, task_loss=1.624, contrastive_loss=0, total=6586.8, n_correct=4482.62, ppl=2.53, accuracy=68.055, wps=18918.7, ups=0.99, wpb=19103, bsz=660.5, num_updates=13900, lr=0.000119952, gnorm=0.291, clip=0, loss_scale=64, train_wall=100, gb_free=14.5, wall=12410
2023-08-23 18:02:06 | INFO | train_inner | epoch 012:   1127 / 1191 loss=1.757, trans_loss=3.306, nll_loss=1.349, w2v_ctc_loss=0.853, task_loss=1.615, contrastive_loss=0, total=6669.32, n_correct=4536.75, ppl=2.55, accuracy=68.024, wps=18911.6, ups=0.98, wpb=19308.5, bsz=667.6, num_updates=14000, lr=0.000119523, gnorm=0.287, clip=0, loss_scale=64, train_wall=101, gb_free=13.1, wall=12512
2023-08-23 18:02:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 18:02:38 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.878 | trans_loss 5.217 | nll_loss 2.432 | w2v_ctc_loss 1.141 | task_loss 8.544 | contrastive_loss 0 | total 6138.43 | n_correct 4120.57 | ppl 5.4 | accuracy 67.127 | uer 16.821 | wer 18.672 | raw_wer 18.672 | bleu 26.72 | wps 1772.6 | wpb 6138.4 | bsz 201.1 | num_updates 14000 | best_bleu 26.85
2023-08-23 18:02:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14000 updates
2023-08-23 18:02:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_12_14000.pt
2023-08-23 18:02:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_12_14000.pt
2023-08-23 18:02:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_12_14000.pt (epoch 12 @ 14000 updates, score 26.72) (writing took 7.784055494936183 seconds)
2023-08-23 18:03:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 18:04:24 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.902 | trans_loss 5.225 | nll_loss 2.44 | w2v_ctc_loss 1.2 | task_loss 8.523 | contrastive_loss 0 | total 6138.43 | n_correct 4126.14 | ppl 5.43 | accuracy 67.218 | uer 17.07 | wer 18.858 | raw_wer 18.858 | bleu 26.94 | wps 1725.4 | wpb 6138.4 | bsz 201.1 | num_updates 14064 | best_bleu 26.94
2023-08-23 18:04:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14064 updates
2023-08-23 18:04:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 18:04:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 18:04:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 12 @ 14064 updates, score 26.94) (writing took 9.99000738596078 seconds)
2023-08-23 18:04:34 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-23 18:04:34 | INFO | train | epoch 012 | loss 1.749 | trans_loss 3.295 | nll_loss 1.335 | w2v_ctc_loss 0.846 | task_loss 1.564 | contrastive_loss 0 | total 6703.69 | n_correct 4570.99 | ppl 2.52 | accuracy 68.186 | wps 17794.4 | ups 0.92 | wpb 19422.7 | bsz 678.2 | num_updates 14064 | lr 0.000119251 | gnorm 0.287 | clip 0 | loss_scale 64 | train_wall 1200 | gb_free 14.3 | wall 12660
2023-08-23 18:04:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 18:04:34 | INFO | fairseq.trainer | begin training epoch 13
2023-08-23 18:04:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 18:05:19 | INFO | train_inner | epoch 013:     36 / 1191 loss=1.741, trans_loss=3.29, nll_loss=1.33, w2v_ctc_loss=0.839, task_loss=1.53, contrastive_loss=0, total=6735.01, n_correct=4612.53, ppl=2.51, accuracy=68.486, wps=10071.1, ups=0.52, wpb=19511.2, bsz=691.2, num_updates=14100, lr=0.000119098, gnorm=0.284, clip=0, loss_scale=64, train_wall=101, gb_free=13.1, wall=12705
2023-08-23 18:07:01 | INFO | train_inner | epoch 013:    136 / 1191 loss=1.725, trans_loss=3.275, nll_loss=1.311, w2v_ctc_loss=0.822, task_loss=1.653, contrastive_loss=0, total=6646.88, n_correct=4566.69, ppl=2.48, accuracy=68.704, wps=18947.5, ups=0.98, wpb=19264.8, bsz=656, num_updates=14200, lr=0.000118678, gnorm=0.288, clip=0, loss_scale=64, train_wall=101, gb_free=4.2, wall=12807
2023-08-23 18:08:43 | INFO | train_inner | epoch 013:    236 / 1191 loss=1.726, trans_loss=3.284, nll_loss=1.321, w2v_ctc_loss=0.821, task_loss=1.49, contrastive_loss=0, total=6703.16, n_correct=4597.95, ppl=2.5, accuracy=68.594, wps=19058.7, ups=0.98, wpb=19412.2, bsz=707.5, num_updates=14300, lr=0.000118262, gnorm=0.285, clip=0, loss_scale=64, train_wall=101, gb_free=13.7, wall=12909
2023-08-23 18:10:24 | INFO | train_inner | epoch 013:    336 / 1191 loss=1.719, trans_loss=3.279, nll_loss=1.316, w2v_ctc_loss=0.815, task_loss=1.544, contrastive_loss=0, total=6702.92, n_correct=4609.75, ppl=2.49, accuracy=68.772, wps=19167.3, ups=0.99, wpb=19423.6, bsz=685.2, num_updates=14400, lr=0.000117851, gnorm=0.284, clip=0, loss_scale=64, train_wall=101, gb_free=14.3, wall=13010
2023-08-23 18:12:05 | INFO | train_inner | epoch 013:    436 / 1191 loss=1.725, trans_loss=3.281, nll_loss=1.319, w2v_ctc_loss=0.822, task_loss=1.521, contrastive_loss=0, total=6741.85, n_correct=4629.9, ppl=2.49, accuracy=68.674, wps=19334.5, ups=0.99, wpb=19537, bsz=681.9, num_updates=14500, lr=0.000117444, gnorm=0.286, clip=0, loss_scale=64, train_wall=100, gb_free=13.6, wall=13111
2023-08-23 18:13:47 | INFO | train_inner | epoch 013:    536 / 1191 loss=1.735, trans_loss=3.284, nll_loss=1.323, w2v_ctc_loss=0.832, task_loss=1.636, contrastive_loss=0, total=6666.99, n_correct=4570.69, ppl=2.5, accuracy=68.557, wps=19009.6, ups=0.98, wpb=19321.8, bsz=663.1, num_updates=14600, lr=0.000117041, gnorm=0.287, clip=0, loss_scale=64, train_wall=101, gb_free=13.9, wall=13213
2023-08-23 18:15:29 | INFO | train_inner | epoch 013:    636 / 1191 loss=1.738, trans_loss=3.284, nll_loss=1.322, w2v_ctc_loss=0.836, task_loss=1.656, contrastive_loss=0, total=6683.44, n_correct=4580.86, ppl=2.5, accuracy=68.54, wps=18994.9, ups=0.98, wpb=19363.7, bsz=644.3, num_updates=14700, lr=0.000116642, gnorm=0.287, clip=0, loss_scale=64, train_wall=101, gb_free=10.9, wall=13315
2023-08-23 18:17:10 | INFO | train_inner | epoch 013:    736 / 1191 loss=1.732, trans_loss=3.289, nll_loss=1.326, w2v_ctc_loss=0.826, task_loss=1.605, contrastive_loss=0, total=6651.86, n_correct=4561.19, ppl=2.51, accuracy=68.57, wps=18959.2, ups=0.98, wpb=19261.5, bsz=665.2, num_updates=14800, lr=0.000116248, gnorm=0.29, clip=0, loss_scale=64, train_wall=101, gb_free=13.9, wall=13417
2023-08-23 18:18:52 | INFO | train_inner | epoch 013:    836 / 1191 loss=1.728, trans_loss=3.286, nll_loss=1.324, w2v_ctc_loss=0.823, task_loss=1.545, contrastive_loss=0, total=6748.36, n_correct=4625.21, ppl=2.5, accuracy=68.538, wps=19276.5, ups=0.99, wpb=19552.2, bsz=680, num_updates=14900, lr=0.000115857, gnorm=0.286, clip=0, loss_scale=64, train_wall=101, gb_free=15.1, wall=13518
2023-08-23 18:20:33 | INFO | train_inner | epoch 013:    936 / 1191 loss=1.736, trans_loss=3.286, nll_loss=1.326, w2v_ctc_loss=0.834, task_loss=1.65, contrastive_loss=0, total=6600.52, n_correct=4520.74, ppl=2.51, accuracy=68.491, wps=18918.1, ups=0.99, wpb=19124.1, bsz=655.6, num_updates=15000, lr=0.00011547, gnorm=0.291, clip=0, loss_scale=64, train_wall=100, gb_free=13.7, wall=13619
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:0')
2023-08-23 18:21:45 | INFO | train_inner | epoch 013:   1036 / 1191 loss=1.889, trans_loss=4.743, nll_loss=1.918, w2v_ctc_loss=0.601, task_loss=2.312, contrastive_loss=0, total=6731.6, n_correct=4611.05, ppl=3.78, accuracy=68.499, wps=18702.8, ups=1.38, wpb=13527.4, bsz=457, num_updates=15100, lr=0.000115087, gnorm=0.37, clip=0, loss_scale=64, train_wall=72, gb_free=13.5, wall=13691
2023-08-23 18:22:57 | INFO | train_inner | epoch 013:   1136 / 1191 loss=1.89, trans_loss=4.763, nll_loss=1.924, w2v_ctc_loss=0.598, task_loss=2.189, contrastive_loss=0, total=6791.81, n_correct=4649.92, ppl=3.8, accuracy=68.464, wps=18905.5, ups=1.39, wpb=13583.6, bsz=474.2, num_updates=15200, lr=0.000114708, gnorm=0.366, clip=0, loss_scale=64, train_wall=71, gb_free=14.9, wall=13763
2023-08-23 18:23:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:3')
2023-08-23 18:24:09 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.892 | trans_loss 5.212 | nll_loss 2.423 | w2v_ctc_loss 1.197 | task_loss 8.558 | contrastive_loss 0 | total 6138.43 | n_correct 4133.71 | ppl 5.36 | accuracy 67.342 | uer 16.979 | wer 18.769 | raw_wer 18.769 | bleu 26.63 | wps 1732.6 | wpb 6138.4 | bsz 201.1 | num_updates 15255 | best_bleu 26.94
2023-08-23 18:24:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 15255 updates
2023-08-23 18:24:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_26.6307.pt
2023-08-23 18:24:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_26.6307.pt
2023-08-23 18:24:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_26.6307.pt (epoch 13 @ 15255 updates, score 26.63) (writing took 6.716116772033274 seconds)
2023-08-23 18:24:17 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-23 18:24:17 | INFO | train | epoch 013 | loss 1.755 | trans_loss 3.518 | nll_loss 1.417 | w2v_ctc_loss 0.79 | task_loss 1.686 | contrastive_loss 0 | total 6703.69 | n_correct 4597.19 | ppl 2.67 | accuracy 68.577 | wps 18265.5 | ups 1.01 | wpb 18131.1 | bsz 629 | num_updates 15255 | lr 0.000114501 | gnorm 0.304 | clip 0 | loss_scale 64 | train_wall 1126 | gb_free 10 | wall 13843
2023-08-23 18:24:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 18:24:17 | INFO | fairseq.trainer | begin training epoch 14
2023-08-23 18:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 18:24:57 | INFO | train_inner | epoch 014:     45 / 1191 loss=1.89, trans_loss=4.753, nll_loss=1.91, w2v_ctc_loss=0.603, task_loss=2.32, contrastive_loss=0, total=6696.63, n_correct=4597.63, ppl=3.76, accuracy=68.656, wps=11222.9, ups=0.84, wpb=13393.3, bsz=448.1, num_updates=15300, lr=0.000114332, gnorm=0.37, clip=0, loss_scale=64, train_wall=70, gb_free=14.2, wall=13883
2023-08-23 18:26:07 | INFO | train_inner | epoch 014:    145 / 1191 loss=1.875, trans_loss=4.734, nll_loss=1.886, w2v_ctc_loss=0.587, task_loss=2.19, contrastive_loss=0, total=6702.04, n_correct=4633.89, ppl=3.69, accuracy=69.141, wps=18971.8, ups=1.42, wpb=13404.1, bsz=469.2, num_updates=15400, lr=0.000113961, gnorm=0.369, clip=0, loss_scale=64, train_wall=70, gb_free=15.3, wall=13953
2023-08-23 18:27:19 | INFO | train_inner | epoch 014:    245 / 1191 loss=1.883, trans_loss=4.743, nll_loss=1.896, w2v_ctc_loss=0.591, task_loss=2.534, contrastive_loss=0, total=6570.64, n_correct=4526.43, ppl=3.72, accuracy=68.889, wps=18410.9, ups=1.4, wpb=13141.3, bsz=423.9, num_updates=15500, lr=0.000113592, gnorm=0.372, clip=0, loss_scale=64, train_wall=71, gb_free=14.3, wall=14025
2023-08-23 18:28:31 | INFO | train_inner | epoch 014:    345 / 1191 loss=1.885, trans_loss=4.748, nll_loss=1.903, w2v_ctc_loss=0.593, task_loss=2.379, contrastive_loss=0, total=6763.67, n_correct=4651.4, ppl=3.74, accuracy=68.77, wps=18718.5, ups=1.38, wpb=13527.3, bsz=454.2, num_updates=15600, lr=0.000113228, gnorm=0.37, clip=0, loss_scale=64, train_wall=71, gb_free=13.7, wall=14097
2023-08-23 18:29:43 | INFO | train_inner | epoch 014:    445 / 1191 loss=1.873, trans_loss=4.733, nll_loss=1.885, w2v_ctc_loss=0.582, task_loss=2.242, contrastive_loss=0, total=6815.93, n_correct=4714.51, ppl=3.69, accuracy=69.169, wps=18873.7, ups=1.38, wpb=13631.9, bsz=466.1, num_updates=15700, lr=0.000112867, gnorm=0.367, clip=0, loss_scale=128, train_wall=72, gb_free=12.9, wall=14169
2023-08-23 18:30:55 | INFO | train_inner | epoch 014:    545 / 1191 loss=1.878, trans_loss=4.74, nll_loss=1.894, w2v_ctc_loss=0.592, task_loss=2.23, contrastive_loss=0, total=6774.93, n_correct=4675.16, ppl=3.72, accuracy=69.007, wps=18887, ups=1.39, wpb=13549.9, bsz=472, num_updates=15800, lr=0.000112509, gnorm=0.364, clip=0, loss_scale=128, train_wall=71, gb_free=13.3, wall=14241
2023-08-23 18:32:06 | INFO | train_inner | epoch 014:    645 / 1191 loss=1.88, trans_loss=4.744, nll_loss=1.899, w2v_ctc_loss=0.591, task_loss=2.325, contrastive_loss=0, total=6757.95, n_correct=4662.38, ppl=3.73, accuracy=68.991, wps=18951, ups=1.4, wpb=13515.9, bsz=456.8, num_updates=15900, lr=0.000112154, gnorm=0.37, clip=0, loss_scale=128, train_wall=71, gb_free=14.6, wall=14312
2023-08-23 18:33:18 | INFO | train_inner | epoch 014:    745 / 1191 loss=1.889, trans_loss=4.751, nll_loss=1.909, w2v_ctc_loss=0.601, task_loss=2.365, contrastive_loss=0, total=6695.75, n_correct=4599.17, ppl=3.76, accuracy=68.688, wps=18610.1, ups=1.39, wpb=13391.5, bsz=447.3, num_updates=16000, lr=0.000111803, gnorm=0.372, clip=0, loss_scale=128, train_wall=71, gb_free=13.3, wall=14384
2023-08-23 18:33:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 18:33:51 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.899 | trans_loss 5.21 | nll_loss 2.422 | w2v_ctc_loss 1.225 | task_loss 8.485 | contrastive_loss 0 | total 6138.43 | n_correct 4134.86 | ppl 5.36 | accuracy 67.36 | uer 16.955 | wer 18.628 | raw_wer 18.628 | bleu 27.09 | wps 1693.2 | wpb 6138.4 | bsz 201.1 | num_updates 16000 | best_bleu 27.09
2023-08-23 18:33:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16000 updates
2023-08-23 18:33:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_14_16000.pt
2023-08-23 18:33:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_14_16000.pt
2023-08-23 18:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_14_16000.pt (epoch 14 @ 16000 updates, score 27.09) (writing took 14.059665428008884 seconds)
2023-08-23 18:35:18 | INFO | train_inner | epoch 014:    845 / 1191 loss=1.887, trans_loss=4.756, nll_loss=1.915, w2v_ctc_loss=0.594, task_loss=2.451, contrastive_loss=0, total=6626.1, n_correct=4550.88, ppl=3.77, accuracy=68.681, wps=11039, ups=0.83, wpb=13252.2, bsz=445.5, num_updates=16100, lr=0.000111456, gnorm=0.371, clip=0, loss_scale=128, train_wall=71, gb_free=15.1, wall=14504
2023-08-23 18:36:30 | INFO | train_inner | epoch 014:    945 / 1191 loss=1.883, trans_loss=4.748, nll_loss=1.906, w2v_ctc_loss=0.597, task_loss=2.345, contrastive_loss=0, total=6701.32, n_correct=4616.68, ppl=3.75, accuracy=68.892, wps=18709, ups=1.4, wpb=13402.6, bsz=454.3, num_updates=16200, lr=0.000111111, gnorm=0.368, clip=0, loss_scale=128, train_wall=71, gb_free=12.9, wall=14576
2023-08-23 18:37:41 | INFO | train_inner | epoch 014:   1045 / 1191 loss=1.894, trans_loss=4.761, nll_loss=1.921, w2v_ctc_loss=0.605, task_loss=2.589, contrastive_loss=0, total=6552.98, n_correct=4496.42, ppl=3.79, accuracy=68.616, wps=18303, ups=1.4, wpb=13106, bsz=422.7, num_updates=16300, lr=0.00011077, gnorm=0.381, clip=0, loss_scale=128, train_wall=71, gb_free=13.7, wall=14648
2023-08-23 18:38:52 | INFO | train_inner | epoch 014:   1145 / 1191 loss=1.878, trans_loss=4.745, nll_loss=1.903, w2v_ctc_loss=0.591, task_loss=2.107, contrastive_loss=0, total=6830.05, n_correct=4715.4, ppl=3.74, accuracy=69.039, wps=19287.9, ups=1.41, wpb=13660.1, bsz=481, num_updates=16400, lr=0.000110432, gnorm=0.367, clip=0, loss_scale=128, train_wall=70, gb_free=12.1, wall=14718
2023-08-23 18:39:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 18:39:58 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.902 | trans_loss 5.202 | nll_loss 2.413 | w2v_ctc_loss 1.252 | task_loss 8.519 | contrastive_loss 0 | total 6138.43 | n_correct 4140.57 | ppl 5.33 | accuracy 67.453 | uer 17.172 | wer 18.862 | raw_wer 18.862 | bleu 27.29 | wps 1766.1 | wpb 6138.4 | bsz 201.1 | num_updates 16446 | best_bleu 27.29
2023-08-23 18:39:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16446 updates
2023-08-23 18:39:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 18:40:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 18:40:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 14 @ 16446 updates, score 27.29) (writing took 11.9912548790453 seconds)
2023-08-23 18:40:10 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-23 18:40:10 | INFO | train | epoch 014 | loss 1.882 | trans_loss 4.745 | nll_loss 1.901 | w2v_ctc_loss 0.593 | task_loss 2.343 | contrastive_loss 0 | total 6703.69 | n_correct 4618.89 | ppl 3.74 | accuracy 68.901 | wps 16748 | ups 1.25 | wpb 13407.4 | bsz 452.1 | num_updates 16446 | lr 0.000110277 | gnorm 0.37 | clip 0 | loss_scale 128 | train_wall 844 | gb_free 14.7 | wall 14796
2023-08-23 18:40:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 18:40:10 | INFO | fairseq.trainer | begin training epoch 15
2023-08-23 18:40:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 18:40:56 | INFO | train_inner | epoch 015:     54 / 1191 loss=1.875, trans_loss=4.731, nll_loss=1.882, w2v_ctc_loss=0.59, task_loss=2.311, contrastive_loss=0, total=6705.12, n_correct=4638.66, ppl=3.69, accuracy=69.181, wps=10842.9, ups=0.81, wpb=13410.2, bsz=451.8, num_updates=16500, lr=0.000110096, gnorm=0.371, clip=0, loss_scale=128, train_wall=70, gb_free=14.6, wall=14842
2023-08-23 18:42:08 | INFO | train_inner | epoch 015:    154 / 1191 loss=1.875, trans_loss=4.727, nll_loss=1.877, w2v_ctc_loss=0.591, task_loss=2.432, contrastive_loss=0, total=6675.45, n_correct=4623.71, ppl=3.67, accuracy=69.264, wps=18418.5, ups=1.38, wpb=13350.9, bsz=440.1, num_updates=16600, lr=0.000109764, gnorm=0.371, clip=0, loss_scale=128, train_wall=72, gb_free=14.1, wall=14915
2023-08-23 18:42:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-23 18:43:20 | INFO | train_inner | epoch 015:    255 / 1191 loss=1.864, trans_loss=4.719, nll_loss=1.867, w2v_ctc_loss=0.578, task_loss=2.243, contrastive_loss=0, total=6747.56, n_correct=4695.52, ppl=3.65, accuracy=69.588, wps=18814.5, ups=1.39, wpb=13495.1, bsz=457.6, num_updates=16700, lr=0.000109435, gnorm=0.364, clip=0, loss_scale=64, train_wall=71, gb_free=12.9, wall=14986
2023-08-23 18:44:32 | INFO | train_inner | epoch 015:    355 / 1191 loss=1.871, trans_loss=4.723, nll_loss=1.873, w2v_ctc_loss=0.586, task_loss=2.463, contrastive_loss=0, total=6597.99, n_correct=4578.53, ppl=3.66, accuracy=69.393, wps=18475.1, ups=1.4, wpb=13196, bsz=436.2, num_updates=16800, lr=0.000109109, gnorm=0.376, clip=0, loss_scale=64, train_wall=71, gb_free=13.6, wall=15058
2023-08-23 18:45:43 | INFO | train_inner | epoch 015:    455 / 1191 loss=1.871, trans_loss=4.732, nll_loss=1.885, w2v_ctc_loss=0.584, task_loss=2.276, contrastive_loss=0, total=6762.51, n_correct=4682.05, ppl=3.69, accuracy=69.235, wps=18961.7, ups=1.4, wpb=13525, bsz=467.1, num_updates=16900, lr=0.000108786, gnorm=0.371, clip=0, loss_scale=64, train_wall=71, gb_free=12.7, wall=15129
2023-08-23 18:46:55 | INFO | train_inner | epoch 015:    555 / 1191 loss=1.878, trans_loss=4.734, nll_loss=1.887, w2v_ctc_loss=0.596, task_loss=2.456, contrastive_loss=0, total=6662.27, n_correct=4610.93, ppl=3.7, accuracy=69.21, wps=18489.6, ups=1.39, wpb=13324.5, bsz=441.7, num_updates=17000, lr=0.000108465, gnorm=0.375, clip=0, loss_scale=64, train_wall=72, gb_free=14, wall=15201
2023-08-23 18:48:07 | INFO | train_inner | epoch 015:    655 / 1191 loss=1.877, trans_loss=4.732, nll_loss=1.885, w2v_ctc_loss=0.592, task_loss=2.369, contrastive_loss=0, total=6722.48, n_correct=4648.05, ppl=3.69, accuracy=69.142, wps=18737.1, ups=1.39, wpb=13445, bsz=448.6, num_updates=17100, lr=0.000108148, gnorm=0.373, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=15273
2023-08-23 18:49:18 | INFO | train_inner | epoch 015:    755 / 1191 loss=1.879, trans_loss=4.736, nll_loss=1.891, w2v_ctc_loss=0.593, task_loss=2.523, contrastive_loss=0, total=6574.38, n_correct=4542.67, ppl=3.71, accuracy=69.097, wps=18390.1, ups=1.4, wpb=13148.8, bsz=428.6, num_updates=17200, lr=0.000107833, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=12.7, wall=15344
2023-08-23 18:50:30 | INFO | train_inner | epoch 015:    855 / 1191 loss=1.872, trans_loss=4.734, nll_loss=1.888, w2v_ctc_loss=0.585, task_loss=2.32, contrastive_loss=0, total=6701.04, n_correct=4639.11, ppl=3.7, accuracy=69.23, wps=18694.3, ups=1.39, wpb=13402.1, bsz=456.2, num_updates=17300, lr=0.000107521, gnorm=0.371, clip=0, loss_scale=64, train_wall=71, gb_free=12.9, wall=15416
2023-08-23 18:51:42 | INFO | train_inner | epoch 015:    955 / 1191 loss=1.87, trans_loss=4.732, nll_loss=1.886, w2v_ctc_loss=0.586, task_loss=2.222, contrastive_loss=0, total=6800.03, n_correct=4715.53, ppl=3.7, accuracy=69.346, wps=18804.1, ups=1.38, wpb=13600.1, bsz=471.6, num_updates=17400, lr=0.000107211, gnorm=0.366, clip=0, loss_scale=64, train_wall=72, gb_free=14.1, wall=15488
2023-08-23 18:52:54 | INFO | train_inner | epoch 015:   1055 / 1191 loss=1.877, trans_loss=4.745, nll_loss=1.903, w2v_ctc_loss=0.589, task_loss=2.35, contrastive_loss=0, total=6681.53, n_correct=4613.22, ppl=3.74, accuracy=69.044, wps=18504.4, ups=1.38, wpb=13363.1, bsz=451.2, num_updates=17500, lr=0.000106904, gnorm=0.373, clip=0, loss_scale=64, train_wall=72, gb_free=13.9, wall=15561
2023-08-23 18:54:06 | INFO | train_inner | epoch 015:   1155 / 1191 loss=1.875, trans_loss=4.737, nll_loss=1.893, w2v_ctc_loss=0.589, task_loss=2.319, contrastive_loss=0, total=6782.05, n_correct=4689.47, ppl=3.71, accuracy=69.145, wps=19063.7, ups=1.41, wpb=13564.1, bsz=456.1, num_updates=17600, lr=0.0001066, gnorm=0.368, clip=0, loss_scale=64, train_wall=70, gb_free=13.9, wall=15632
2023-08-23 18:54:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 18:55:04 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.892 | trans_loss 5.206 | nll_loss 2.417 | w2v_ctc_loss 1.211 | task_loss 8.493 | contrastive_loss 0 | total 6138.43 | n_correct 4135.86 | ppl 5.34 | accuracy 67.376 | uer 17.161 | wer 18.832 | raw_wer 18.832 | bleu 27.15 | wps 1753 | wpb 6138.4 | bsz 201.1 | num_updates 17636 | best_bleu 27.29
2023-08-23 18:55:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 17636 updates
2023-08-23 18:55:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.1504.pt
2023-08-23 18:55:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.1504.pt
2023-08-23 18:55:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.1504.pt (epoch 15 @ 17636 updates, score 27.15) (writing took 7.935782530927099 seconds)
2023-08-23 18:55:13 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-23 18:55:13 | INFO | train | epoch 015 | loss 1.873 | trans_loss 4.731 | nll_loss 1.884 | w2v_ctc_loss 0.588 | task_loss 2.348 | contrastive_loss 0 | total 6701.79 | n_correct 4641.38 | ppl 3.69 | accuracy 69.256 | wps 17667.3 | ups 1.32 | wpb 13403.6 | bsz 451.7 | num_updates 17636 | lr 0.000106492 | gnorm 0.372 | clip 0 | loss_scale 64 | train_wall 846 | gb_free 11.8 | wall 15699
2023-08-23 18:55:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 18:55:13 | INFO | fairseq.trainer | begin training epoch 16
2023-08-23 18:55:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 18:56:07 | INFO | train_inner | epoch 016:     64 / 1191 loss=1.869, trans_loss=4.725, nll_loss=1.877, w2v_ctc_loss=0.583, task_loss=2.366, contrastive_loss=0, total=6656.06, n_correct=4621.53, ppl=3.67, accuracy=69.433, wps=11005.4, ups=0.83, wpb=13312.1, bsz=446.2, num_updates=17700, lr=0.000106299, gnorm=0.374, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=15753
2023-08-23 18:57:18 | INFO | train_inner | epoch 016:    164 / 1191 loss=1.862, trans_loss=4.711, nll_loss=1.858, w2v_ctc_loss=0.577, task_loss=2.386, contrastive_loss=0, total=6724.93, n_correct=4686.24, ppl=3.63, accuracy=69.685, wps=18793.1, ups=1.4, wpb=13449.9, bsz=448.3, num_updates=17800, lr=0.000106, gnorm=0.37, clip=0, loss_scale=64, train_wall=71, gb_free=13.9, wall=15824
2023-08-23 18:58:29 | INFO | train_inner | epoch 016:    264 / 1191 loss=1.865, trans_loss=4.712, nll_loss=1.859, w2v_ctc_loss=0.582, task_loss=2.424, contrastive_loss=0, total=6678.98, n_correct=4646.34, ppl=3.63, accuracy=69.567, wps=18736.1, ups=1.4, wpb=13358, bsz=435.4, num_updates=17900, lr=0.000105703, gnorm=0.375, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=15896
2023-08-23 18:59:41 | INFO | train_inner | epoch 016:    364 / 1191 loss=1.86, trans_loss=4.716, nll_loss=1.866, w2v_ctc_loss=0.576, task_loss=2.246, contrastive_loss=0, total=6783.67, n_correct=4726.14, ppl=3.64, accuracy=69.669, wps=18949.6, ups=1.4, wpb=13567.3, bsz=465.7, num_updates=18000, lr=0.000105409, gnorm=0.371, clip=0, loss_scale=64, train_wall=71, gb_free=5.7, wall=15967
2023-08-23 18:59:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 19:00:13 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.89 | trans_loss 5.203 | nll_loss 2.408 | w2v_ctc_loss 1.211 | task_loss 8.496 | contrastive_loss 0 | total 6138.43 | n_correct 4142.43 | ppl 5.31 | accuracy 67.484 | uer 16.813 | wer 18.535 | raw_wer 18.535 | bleu 26.99 | wps 1761.1 | wpb 6138.4 | bsz 201.1 | num_updates 18000 | best_bleu 27.29
2023-08-23 19:00:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 18000 updates
2023-08-23 19:00:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_16_18000.pt
2023-08-23 19:00:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_16_18000.pt
2023-08-23 19:00:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_16_18000.pt (epoch 16 @ 18000 updates, score 26.99) (writing took 7.916635902947746 seconds)
2023-08-23 19:01:33 | INFO | train_inner | epoch 016:    464 / 1191 loss=1.858, trans_loss=4.71, nll_loss=1.857, w2v_ctc_loss=0.576, task_loss=2.264, contrastive_loss=0, total=6697.34, n_correct=4674.63, ppl=3.62, accuracy=69.798, wps=11926, ups=0.89, wpb=13394.7, bsz=458.6, num_updates=18100, lr=0.000105118, gnorm=0.37, clip=0, loss_scale=64, train_wall=71, gb_free=14.2, wall=16079
2023-08-23 19:02:45 | INFO | train_inner | epoch 016:    564 / 1191 loss=1.866, trans_loss=4.719, nll_loss=1.867, w2v_ctc_loss=0.58, task_loss=2.468, contrastive_loss=0, total=6665.2, n_correct=4632.82, ppl=3.65, accuracy=69.508, wps=18593, ups=1.39, wpb=13330.4, bsz=434.6, num_updates=18200, lr=0.000104828, gnorm=0.373, clip=0, loss_scale=64, train_wall=71, gb_free=10.4, wall=16151
2023-08-23 19:03:57 | INFO | train_inner | epoch 016:    664 / 1191 loss=1.867, trans_loss=4.724, nll_loss=1.876, w2v_ctc_loss=0.583, task_loss=2.334, contrastive_loss=0, total=6692.43, n_correct=4646.65, ppl=3.67, accuracy=69.431, wps=18573.7, ups=1.39, wpb=13384.9, bsz=456.9, num_updates=18300, lr=0.000104542, gnorm=0.373, clip=0, loss_scale=64, train_wall=71, gb_free=14, wall=16223
2023-08-23 19:05:09 | INFO | train_inner | epoch 016:    764 / 1191 loss=1.87, trans_loss=4.722, nll_loss=1.873, w2v_ctc_loss=0.59, task_loss=2.466, contrastive_loss=0, total=6616.88, n_correct=4599.62, ppl=3.66, accuracy=69.513, wps=18542.7, ups=1.4, wpb=13233.8, bsz=437.9, num_updates=18400, lr=0.000104257, gnorm=0.376, clip=0, loss_scale=64, train_wall=71, gb_free=13.7, wall=16295
2023-08-23 19:06:20 | INFO | train_inner | epoch 016:    864 / 1191 loss=1.872, trans_loss=4.73, nll_loss=1.883, w2v_ctc_loss=0.588, task_loss=2.422, contrastive_loss=0, total=6704.41, n_correct=4647.4, ppl=3.69, accuracy=69.319, wps=18759.2, ups=1.4, wpb=13408.8, bsz=443.4, num_updates=18500, lr=0.000103975, gnorm=0.376, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=16366
2023-08-23 19:07:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-23 19:07:32 | INFO | train_inner | epoch 016:    965 / 1191 loss=1.861, trans_loss=4.719, nll_loss=1.87, w2v_ctc_loss=0.578, task_loss=2.198, contrastive_loss=0, total=6773.03, n_correct=4714.07, ppl=3.65, accuracy=69.601, wps=18705.9, ups=1.38, wpb=13546.1, bsz=473.6, num_updates=18600, lr=0.000103695, gnorm=0.368, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=16439
2023-08-23 19:08:45 | INFO | train_inner | epoch 016:   1065 / 1191 loss=1.869, trans_loss=4.726, nll_loss=1.88, w2v_ctc_loss=0.591, task_loss=2.289, contrastive_loss=0, total=6708.12, n_correct=4656.71, ppl=3.68, accuracy=69.419, wps=18572.9, ups=1.38, wpb=13416.2, bsz=464.1, num_updates=18700, lr=0.000103418, gnorm=0.374, clip=0, loss_scale=32, train_wall=71, gb_free=14, wall=16511
2023-08-23 19:09:57 | INFO | train_inner | epoch 016:   1165 / 1191 loss=1.871, trans_loss=4.734, nll_loss=1.89, w2v_ctc_loss=0.588, task_loss=2.27, contrastive_loss=0, total=6761.74, n_correct=4679.58, ppl=3.71, accuracy=69.207, wps=18791.4, ups=1.39, wpb=13523.5, bsz=464.6, num_updates=18800, lr=0.000103142, gnorm=0.374, clip=0, loss_scale=32, train_wall=71, gb_free=11.8, wall=16583
2023-08-23 19:10:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 19:10:48 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.873 | trans_loss 5.198 | nll_loss 2.412 | w2v_ctc_loss 1.166 | task_loss 8.468 | contrastive_loss 0 | total 6138.43 | n_correct 4152.86 | ppl 5.32 | accuracy 67.653 | uer 16.918 | wer 18.479 | raw_wer 18.479 | bleu 27.45 | wps 1721.8 | wpb 6138.4 | bsz 201.1 | num_updates 18826 | best_bleu 27.45
2023-08-23 19:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 18826 updates
2023-08-23 19:10:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 19:10:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 19:11:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 16 @ 18826 updates, score 27.45) (writing took 11.465996048063971 seconds)
2023-08-23 19:11:00 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-23 19:11:00 | INFO | train | epoch 016 | loss 1.865 | trans_loss 4.72 | nll_loss 1.87 | w2v_ctc_loss 0.582 | task_loss 2.344 | contrastive_loss 0 | total 6704.48 | n_correct 4661.64 | ppl 3.66 | accuracy 69.53 | wps 16845.3 | ups 1.26 | wpb 13409 | bsz 452.2 | num_updates 18826 | lr 0.000103071 | gnorm 0.373 | clip 0 | loss_scale 32 | train_wall 845 | gb_free 13.8 | wall 16646
2023-08-23 19:11:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 19:11:00 | INFO | fairseq.trainer | begin training epoch 17
2023-08-23 19:11:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 19:12:01 | INFO | train_inner | epoch 017:     74 / 1191 loss=1.858, trans_loss=4.707, nll_loss=1.854, w2v_ctc_loss=0.574, task_loss=2.409, contrastive_loss=0, total=6584.39, n_correct=4596.52, ppl=3.61, accuracy=69.809, wps=10622.1, ups=0.81, wpb=13168.8, bsz=441.8, num_updates=18900, lr=0.000102869, gnorm=0.375, clip=0, loss_scale=32, train_wall=71, gb_free=11.5, wall=16707
2023-08-23 19:13:12 | INFO | train_inner | epoch 017:    174 / 1191 loss=1.849, trans_loss=4.693, nll_loss=1.835, w2v_ctc_loss=0.569, task_loss=2.321, contrastive_loss=0, total=6744.5, n_correct=4731.17, ppl=3.57, accuracy=70.149, wps=18882, ups=1.4, wpb=13489, bsz=458.6, num_updates=19000, lr=0.000102598, gnorm=0.371, clip=0, loss_scale=32, train_wall=71, gb_free=6.5, wall=16778
2023-08-23 19:14:23 | INFO | train_inner | epoch 017:    274 / 1191 loss=1.845, trans_loss=4.69, nll_loss=1.832, w2v_ctc_loss=0.569, task_loss=2.213, contrastive_loss=0, total=6824.61, n_correct=4795.18, ppl=3.56, accuracy=70.263, wps=19135.8, ups=1.4, wpb=13649.2, bsz=473.5, num_updates=19100, lr=0.000102329, gnorm=0.366, clip=0, loss_scale=32, train_wall=71, gb_free=14.3, wall=16849
2023-08-23 19:15:35 | INFO | train_inner | epoch 017:    374 / 1191 loss=1.862, trans_loss=4.71, nll_loss=1.857, w2v_ctc_loss=0.58, task_loss=2.555, contrastive_loss=0, total=6533.05, n_correct=4555.45, ppl=3.62, accuracy=69.729, wps=18366.3, ups=1.41, wpb=13066.1, bsz=422.4, num_updates=19200, lr=0.000102062, gnorm=0.38, clip=0, loss_scale=32, train_wall=70, gb_free=12.9, wall=16921
2023-08-23 19:16:46 | INFO | train_inner | epoch 017:    474 / 1191 loss=1.86, trans_loss=4.714, nll_loss=1.863, w2v_ctc_loss=0.578, task_loss=2.304, contrastive_loss=0, total=6781.67, n_correct=4732.01, ppl=3.64, accuracy=69.776, wps=18941, ups=1.4, wpb=13563.3, bsz=455.3, num_updates=19300, lr=0.000101797, gnorm=0.365, clip=0, loss_scale=32, train_wall=71, gb_free=15.2, wall=16992
2023-08-23 19:17:58 | INFO | train_inner | epoch 017:    574 / 1191 loss=1.857, trans_loss=4.711, nll_loss=1.859, w2v_ctc_loss=0.569, task_loss=2.331, contrastive_loss=0, total=6712.62, n_correct=4681.35, ppl=3.63, accuracy=69.74, wps=18728, ups=1.39, wpb=13425.2, bsz=450.1, num_updates=19400, lr=0.000101535, gnorm=0.369, clip=0, loss_scale=32, train_wall=71, gb_free=13.6, wall=17064
2023-08-23 19:19:09 | INFO | train_inner | epoch 017:    674 / 1191 loss=1.862, trans_loss=4.714, nll_loss=1.862, w2v_ctc_loss=0.582, task_loss=2.34, contrastive_loss=0, total=6658.15, n_correct=4637.33, ppl=3.64, accuracy=69.649, wps=18648.4, ups=1.4, wpb=13316.3, bsz=452.2, num_updates=19500, lr=0.000101274, gnorm=0.376, clip=0, loss_scale=32, train_wall=71, gb_free=9.9, wall=17135
2023-08-23 19:20:21 | INFO | train_inner | epoch 017:    774 / 1191 loss=1.867, trans_loss=4.719, nll_loss=1.869, w2v_ctc_loss=0.585, task_loss=2.519, contrastive_loss=0, total=6646.08, n_correct=4627.61, ppl=3.65, accuracy=69.629, wps=18452.7, ups=1.39, wpb=13292.2, bsz=427.8, num_updates=19600, lr=0.000101015, gnorm=0.374, clip=0, loss_scale=32, train_wall=71, gb_free=10.5, wall=17207
2023-08-23 19:21:33 | INFO | train_inner | epoch 017:    874 / 1191 loss=1.855, trans_loss=4.71, nll_loss=1.859, w2v_ctc_loss=0.569, task_loss=2.336, contrastive_loss=0, total=6688.98, n_correct=4671.52, ppl=3.63, accuracy=69.839, wps=18627, ups=1.39, wpb=13378, bsz=455.8, num_updates=19700, lr=0.000100759, gnorm=0.374, clip=0, loss_scale=32, train_wall=71, gb_free=14.4, wall=17279
2023-08-23 19:22:45 | INFO | train_inner | epoch 017:    974 / 1191 loss=1.851, trans_loss=4.708, nll_loss=1.857, w2v_ctc_loss=0.565, task_loss=2.169, contrastive_loss=0, total=6738.14, n_correct=4710.17, ppl=3.62, accuracy=69.903, wps=18854.1, ups=1.4, wpb=13476.3, bsz=481.5, num_updates=19800, lr=0.000100504, gnorm=0.369, clip=0, loss_scale=32, train_wall=71, gb_free=13.8, wall=17351
2023-08-23 19:23:56 | INFO | train_inner | epoch 017:   1074 / 1191 loss=1.859, trans_loss=4.711, nll_loss=1.86, w2v_ctc_loss=0.577, task_loss=2.441, contrastive_loss=0, total=6610.83, n_correct=4611.45, ppl=3.63, accuracy=69.756, wps=18539.9, ups=1.4, wpb=13221.7, bsz=436.2, num_updates=19900, lr=0.000100251, gnorm=0.375, clip=0, loss_scale=32, train_wall=71, gb_free=12.4, wall=17422
2023-08-23 19:25:08 | INFO | train_inner | epoch 017:   1174 / 1191 loss=1.855, trans_loss=4.71, nll_loss=1.86, w2v_ctc_loss=0.575, task_loss=2.253, contrastive_loss=0, total=6844.43, n_correct=4784.74, ppl=3.63, accuracy=69.907, wps=19055.7, ups=1.39, wpb=13688.9, bsz=465.2, num_updates=20000, lr=0.0001, gnorm=0.368, clip=0, loss_scale=32, train_wall=71, gb_free=15.1, wall=17494
2023-08-23 19:25:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 19:25:41 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.863 | trans_loss 5.192 | nll_loss 2.399 | w2v_ctc_loss 1.146 | task_loss 8.469 | contrastive_loss 0 | total 6138.43 | n_correct 4159.29 | ppl 5.27 | accuracy 67.758 | uer 16.573 | wer 18.416 | raw_wer 18.416 | bleu 27.5 | wps 1753.6 | wpb 6138.4 | bsz 201.1 | num_updates 20000 | best_bleu 27.5
2023-08-23 19:25:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20000 updates
2023-08-23 19:25:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_17_20000.pt
2023-08-23 19:25:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_17_20000.pt
2023-08-23 19:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_17_20000.pt (epoch 17 @ 20000 updates, score 27.5) (writing took 12.5267659870442 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:0')
2023-08-23 19:26:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:5')
2023-08-23 19:26:38 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.868 | trans_loss 5.186 | nll_loss 2.393 | w2v_ctc_loss 1.176 | task_loss 8.505 | contrastive_loss 0 | total 6138.43 | n_correct 4157.86 | ppl 5.25 | accuracy 67.735 | uer 16.717 | wer 18.408 | raw_wer 18.408 | bleu 27.42 | wps 1760.6 | wpb 6138.4 | bsz 201.1 | num_updates 20017 | best_bleu 27.5
2023-08-23 19:26:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20017 updates
2023-08-23 19:26:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4204.pt
2023-08-23 19:26:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4204.pt
2023-08-23 19:26:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4204.pt (epoch 17 @ 20017 updates, score 27.42) (writing took 6.687614520080388 seconds)
2023-08-23 19:26:46 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-23 19:26:46 | INFO | train | epoch 017 | loss 1.856 | trans_loss 4.708 | nll_loss 1.855 | w2v_ctc_loss 0.574 | task_loss 2.343 | contrastive_loss 0 | total 6703.69 | n_correct 4682.82 | ppl 3.62 | accuracy 69.854 | wps 16886.8 | ups 1.26 | wpb 13407.4 | bsz 452.1 | num_updates 20017 | lr 9.99575e-05 | gnorm 0.372 | clip 0 | loss_scale 32 | train_wall 844 | gb_free 14.4 | wall 17592
2023-08-23 19:26:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 19:26:46 | INFO | fairseq.trainer | begin training epoch 18
2023-08-23 19:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 19:27:53 | INFO | train_inner | epoch 018:     83 / 1191 loss=1.842, trans_loss=4.684, nll_loss=1.825, w2v_ctc_loss=0.557, task_loss=2.357, contrastive_loss=0, total=6745.56, n_correct=4743.71, ppl=3.54, accuracy=70.323, wps=8159.6, ups=0.6, wpb=13491.1, bsz=448, num_updates=20100, lr=9.97509e-05, gnorm=0.373, clip=0, loss_scale=32, train_wall=71, gb_free=13.9, wall=17659
2023-08-23 19:29:05 | INFO | train_inner | epoch 018:    183 / 1191 loss=1.85, trans_loss=4.693, nll_loss=1.835, w2v_ctc_loss=0.572, task_loss=2.471, contrastive_loss=0, total=6681.88, n_correct=4691.59, ppl=3.57, accuracy=70.214, wps=18558.6, ups=1.39, wpb=13363.8, bsz=437.3, num_updates=20200, lr=9.95037e-05, gnorm=0.373, clip=0, loss_scale=32, train_wall=71, gb_free=14.1, wall=17731
2023-08-23 19:30:17 | INFO | train_inner | epoch 018:    283 / 1191 loss=1.855, trans_loss=4.698, nll_loss=1.842, w2v_ctc_loss=0.577, task_loss=2.525, contrastive_loss=0, total=6558.48, n_correct=4589.91, ppl=3.58, accuracy=69.984, wps=18278.9, ups=1.39, wpb=13117, bsz=432.2, num_updates=20300, lr=9.92583e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=71, gb_free=14.1, wall=17803
2023-08-23 19:31:28 | INFO | train_inner | epoch 018:    383 / 1191 loss=1.842, trans_loss=4.693, nll_loss=1.837, w2v_ctc_loss=0.558, task_loss=2.172, contrastive_loss=0, total=6808.11, n_correct=4784.46, ppl=3.57, accuracy=70.276, wps=19094.9, ups=1.4, wpb=13616.2, bsz=476.5, num_updates=20400, lr=9.90148e-05, gnorm=0.365, clip=0, loss_scale=32, train_wall=71, gb_free=14.5, wall=17874
2023-08-23 19:32:40 | INFO | train_inner | epoch 018:    483 / 1191 loss=1.847, trans_loss=4.698, nll_loss=1.844, w2v_ctc_loss=0.566, task_loss=2.231, contrastive_loss=0, total=6766.2, n_correct=4745.31, ppl=3.59, accuracy=70.133, wps=18799.4, ups=1.39, wpb=13532.4, bsz=471.5, num_updates=20500, lr=9.8773e-05, gnorm=0.371, clip=0, loss_scale=32, train_wall=71, gb_free=13.8, wall=17946
2023-08-23 19:33:51 | INFO | train_inner | epoch 018:    583 / 1191 loss=1.847, trans_loss=4.695, nll_loss=1.839, w2v_ctc_loss=0.568, task_loss=2.308, contrastive_loss=0, total=6713.82, n_correct=4713.97, ppl=3.58, accuracy=70.213, wps=19044.5, ups=1.42, wpb=13427.6, bsz=454.6, num_updates=20600, lr=9.85329e-05, gnorm=0.374, clip=0, loss_scale=32, train_wall=70, gb_free=12.7, wall=18017
2023-08-23 19:35:02 | INFO | train_inner | epoch 018:    683 / 1191 loss=1.852, trans_loss=4.698, nll_loss=1.844, w2v_ctc_loss=0.569, task_loss=2.474, contrastive_loss=0, total=6632.05, n_correct=4644.61, ppl=3.59, accuracy=70.033, wps=18477.9, ups=1.39, wpb=13264.1, bsz=434.3, num_updates=20700, lr=9.82946e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=18089
2023-08-23 19:36:14 | INFO | train_inner | epoch 018:    783 / 1191 loss=1.854, trans_loss=4.707, nll_loss=1.855, w2v_ctc_loss=0.578, task_loss=2.21, contrastive_loss=0, total=6814.29, n_correct=4761.78, ppl=3.62, accuracy=69.879, wps=19056.7, ups=1.4, wpb=13628.6, bsz=477.7, num_updates=20800, lr=9.80581e-05, gnorm=0.37, clip=0, loss_scale=64, train_wall=71, gb_free=13.9, wall=18160
2023-08-23 19:37:26 | INFO | train_inner | epoch 018:    883 / 1191 loss=1.859, trans_loss=4.711, nll_loss=1.86, w2v_ctc_loss=0.576, task_loss=2.466, contrastive_loss=0, total=6684.22, n_correct=4666.33, ppl=3.63, accuracy=69.811, wps=18448, ups=1.38, wpb=13368.4, bsz=436.2, num_updates=20900, lr=9.78232e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=72, gb_free=14.4, wall=18233
2023-08-23 19:38:37 | INFO | train_inner | epoch 018:    983 / 1191 loss=1.85, trans_loss=4.698, nll_loss=1.846, w2v_ctc_loss=0.572, task_loss=2.193, contrastive_loss=0, total=6756.56, n_correct=4738.98, ppl=3.59, accuracy=70.139, wps=19034.6, ups=1.41, wpb=13513.1, bsz=470.5, num_updates=21000, lr=9.759e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=70, gb_free=14.3, wall=18304
2023-08-23 19:39:49 | INFO | train_inner | epoch 018:   1083 / 1191 loss=1.856, trans_loss=4.706, nll_loss=1.854, w2v_ctc_loss=0.575, task_loss=2.516, contrastive_loss=0, total=6581.63, n_correct=4603.18, ppl=3.61, accuracy=69.94, wps=18488.1, ups=1.4, wpb=13163.3, bsz=426.7, num_updates=21100, lr=9.73585e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=70, gb_free=11.7, wall=18375
2023-08-23 19:41:00 | INFO | train_inner | epoch 018:   1183 / 1191 loss=1.851, trans_loss=4.703, nll_loss=1.851, w2v_ctc_loss=0.569, task_loss=2.288, contrastive_loss=0, total=6742.28, n_correct=4719.63, ppl=3.61, accuracy=70.001, wps=18870.4, ups=1.4, wpb=13484.6, bsz=464.1, num_updates=21200, lr=9.71286e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=18446
2023-08-23 19:41:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 19:41:38 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.87 | trans_loss 5.187 | nll_loss 2.395 | w2v_ctc_loss 1.18 | task_loss 8.505 | contrastive_loss 0 | total 6138.43 | n_correct 4162.43 | ppl 5.26 | accuracy 67.809 | uer 16.693 | wer 18.587 | raw_wer 18.587 | bleu 27.27 | wps 1748.9 | wpb 6138.4 | bsz 201.1 | num_updates 21208 | best_bleu 27.5
2023-08-23 19:41:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 21208 updates
2023-08-23 19:41:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.2708.pt
2023-08-23 19:41:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.2708.pt
2023-08-23 19:41:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.2708.pt (epoch 18 @ 21208 updates, score 27.27) (writing took 6.328406225889921 seconds)
2023-08-23 19:41:45 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-23 19:41:45 | INFO | train | epoch 018 | loss 1.85 | trans_loss 4.698 | nll_loss 1.844 | w2v_ctc_loss 0.57 | task_loss 2.347 | contrastive_loss 0 | total 6703.69 | n_correct 4698.26 | ppl 3.59 | accuracy 70.085 | wps 17749.1 | ups 1.32 | wpb 13407.4 | bsz 452.1 | num_updates 21208 | lr 9.71103e-05 | gnorm 0.373 | clip 0 | loss_scale 64 | train_wall 843 | gb_free 14 | wall 18491
2023-08-23 19:41:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 19:41:46 | INFO | fairseq.trainer | begin training epoch 19
2023-08-23 19:41:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 19:43:00 | INFO | train_inner | epoch 019:     92 / 1191 loss=1.841, trans_loss=4.677, nll_loss=1.816, w2v_ctc_loss=0.564, task_loss=2.503, contrastive_loss=0, total=6609.02, n_correct=4661.01, ppl=3.52, accuracy=70.525, wps=11031.9, ups=0.83, wpb=13218, bsz=429.9, num_updates=21300, lr=9.69003e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=72, gb_free=14.7, wall=18566
2023-08-23 19:44:11 | INFO | train_inner | epoch 019:    192 / 1191 loss=1.836, trans_loss=4.675, nll_loss=1.814, w2v_ctc_loss=0.557, task_loss=2.366, contrastive_loss=0, total=6650.17, n_correct=4694.72, ppl=3.52, accuracy=70.595, wps=18809.4, ups=1.41, wpb=13300.3, bsz=444.5, num_updates=21400, lr=9.66736e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=70, gb_free=14.4, wall=18637
2023-08-23 19:45:23 | INFO | train_inner | epoch 019:    292 / 1191 loss=1.838, trans_loss=4.679, nll_loss=1.819, w2v_ctc_loss=0.56, task_loss=2.233, contrastive_loss=0, total=6799.54, n_correct=4796.65, ppl=3.53, accuracy=70.544, wps=18886.8, ups=1.39, wpb=13599.1, bsz=464.9, num_updates=21500, lr=9.64486e-05, gnorm=0.374, clip=0, loss_scale=64, train_wall=71, gb_free=4.8, wall=18709
2023-08-23 19:46:34 | INFO | train_inner | epoch 019:    392 / 1191 loss=1.838, trans_loss=4.682, nll_loss=1.823, w2v_ctc_loss=0.555, task_loss=2.323, contrastive_loss=0, total=6696.93, n_correct=4720.12, ppl=3.54, accuracy=70.482, wps=18858.1, ups=1.41, wpb=13393.9, bsz=445.2, num_updates=21600, lr=9.6225e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=70, gb_free=11.8, wall=18780
2023-08-23 19:47:46 | INFO | train_inner | epoch 019:    492 / 1191 loss=1.844, trans_loss=4.693, nll_loss=1.837, w2v_ctc_loss=0.563, task_loss=2.27, contrastive_loss=0, total=6707.83, n_correct=4712.32, ppl=3.57, accuracy=70.251, wps=18660.4, ups=1.39, wpb=13415.7, bsz=465.4, num_updates=21700, lr=9.60031e-05, gnorm=0.37, clip=0, loss_scale=64, train_wall=71, gb_free=14.4, wall=18852
2023-08-23 19:48:57 | INFO | train_inner | epoch 019:    592 / 1191 loss=1.84, trans_loss=4.686, nll_loss=1.828, w2v_ctc_loss=0.564, task_loss=2.262, contrastive_loss=0, total=6803.41, n_correct=4795.95, ppl=3.55, accuracy=70.493, wps=18962.9, ups=1.39, wpb=13606.8, bsz=470.6, num_updates=21800, lr=9.57826e-05, gnorm=0.366, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=18923
2023-08-23 19:50:09 | INFO | train_inner | epoch 019:    692 / 1191 loss=1.845, trans_loss=4.691, nll_loss=1.834, w2v_ctc_loss=0.564, task_loss=2.426, contrastive_loss=0, total=6601.41, n_correct=4635.97, ppl=3.57, accuracy=70.227, wps=18539.6, ups=1.4, wpb=13202.8, bsz=443.7, num_updates=21900, lr=9.55637e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=18995
2023-08-23 19:51:20 | INFO | train_inner | epoch 019:    792 / 1191 loss=1.843, trans_loss=4.689, nll_loss=1.834, w2v_ctc_loss=0.565, task_loss=2.241, contrastive_loss=0, total=6792.06, n_correct=4779.73, ppl=3.56, accuracy=70.372, wps=18987.9, ups=1.4, wpb=13584.1, bsz=469.4, num_updates=22000, lr=9.53463e-05, gnorm=0.369, clip=0, loss_scale=64, train_wall=71, gb_free=15.2, wall=19066
2023-08-23 19:51:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 19:51:53 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.886 | trans_loss 5.193 | nll_loss 2.398 | w2v_ctc_loss 1.22 | task_loss 8.56 | contrastive_loss 0 | total 6138.43 | n_correct 4156.14 | ppl 5.27 | accuracy 67.707 | uer 16.805 | wer 18.624 | raw_wer 18.624 | bleu 27.29 | wps 1723.4 | wpb 6138.4 | bsz 201.1 | num_updates 22000 | best_bleu 27.5
2023-08-23 19:51:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22000 updates
2023-08-23 19:51:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_19_22000.pt
2023-08-23 19:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_19_22000.pt
2023-08-23 19:52:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_19_22000.pt (epoch 19 @ 22000 updates, score 27.29) (writing took 6.5639625350013375 seconds)
2023-08-23 19:53:12 | INFO | train_inner | epoch 019:    892 / 1191 loss=1.851, trans_loss=4.699, nll_loss=1.845, w2v_ctc_loss=0.57, task_loss=2.451, contrastive_loss=0, total=6644.21, n_correct=4656.02, ppl=3.59, accuracy=70.076, wps=11876.1, ups=0.89, wpb=13288.4, bsz=439.1, num_updates=22100, lr=9.51303e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=71, gb_free=12.3, wall=19178
2023-08-23 19:54:23 | INFO | train_inner | epoch 019:    992 / 1191 loss=1.851, trans_loss=4.695, nll_loss=1.84, w2v_ctc_loss=0.573, task_loss=2.531, contrastive_loss=0, total=6592.03, n_correct=4624.8, ppl=3.58, accuracy=70.157, wps=18573.3, ups=1.41, wpb=13184.1, bsz=429.6, num_updates=22200, lr=9.49158e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=70, gb_free=12.1, wall=19249
2023-08-23 19:55:35 | INFO | train_inner | epoch 019:   1092 / 1191 loss=1.847, trans_loss=4.696, nll_loss=1.843, w2v_ctc_loss=0.566, task_loss=2.285, contrastive_loss=0, total=6755.14, n_correct=4740.1, ppl=3.59, accuracy=70.17, wps=18741.2, ups=1.39, wpb=13510.3, bsz=457.7, num_updates=22300, lr=9.47027e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=19321
2023-08-23 19:56:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 19:57:19 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.896 | trans_loss 5.199 | nll_loss 2.408 | w2v_ctc_loss 1.241 | task_loss 8.517 | contrastive_loss 0 | total 6138.43 | n_correct 4144.43 | ppl 5.31 | accuracy 67.516 | uer 16.851 | wer 18.52 | raw_wer 18.52 | bleu 27.05 | wps 1723 | wpb 6138.4 | bsz 201.1 | num_updates 22399 | best_bleu 27.5
2023-08-23 19:57:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22399 updates
2023-08-23 19:57:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.0509.pt
2023-08-23 19:57:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.0509.pt
2023-08-23 19:57:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.0509.pt (epoch 19 @ 22399 updates, score 27.05) (writing took 6.715551882982254 seconds)
2023-08-23 19:57:26 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-23 19:57:26 | INFO | train | epoch 019 | loss 1.843 | trans_loss 4.689 | nll_loss 1.832 | w2v_ctc_loss 0.563 | task_loss 2.345 | contrastive_loss 0 | total 6703.69 | n_correct 4715.1 | ppl 3.56 | accuracy 70.336 | wps 16974.3 | ups 1.27 | wpb 13407.4 | bsz 452.1 | num_updates 22399 | lr 9.44932e-05 | gnorm 0.373 | clip 0 | loss_scale 64 | train_wall 844 | gb_free 14.4 | wall 19432
2023-08-23 19:57:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 19:57:26 | INFO | fairseq.trainer | begin training epoch 20
2023-08-23 19:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 19:57:35 | INFO | train_inner | epoch 020:      1 / 1191 loss=1.844, trans_loss=4.701, nll_loss=1.85, w2v_ctc_loss=0.56, task_loss=2.274, contrastive_loss=0, total=6792.89, n_correct=4764.02, ppl=3.6, accuracy=70.132, wps=11345, ups=0.84, wpb=13585.8, bsz=464.6, num_updates=22400, lr=9.44911e-05, gnorm=0.368, clip=0, loss_scale=64, train_wall=71, gb_free=14.4, wall=19441
2023-08-23 19:58:47 | INFO | train_inner | epoch 020:    101 / 1191 loss=1.835, trans_loss=4.667, nll_loss=1.802, w2v_ctc_loss=0.56, task_loss=2.491, contrastive_loss=0, total=6615.85, n_correct=4683.87, ppl=3.49, accuracy=70.798, wps=18373.6, ups=1.39, wpb=13231.7, bsz=437.5, num_updates=22500, lr=9.42809e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=71, gb_free=12.9, wall=19513
2023-08-23 19:59:58 | INFO | train_inner | epoch 020:    201 / 1191 loss=1.832, trans_loss=4.67, nll_loss=1.807, w2v_ctc_loss=0.552, task_loss=2.34, contrastive_loss=0, total=6702.35, n_correct=4740.46, ppl=3.5, accuracy=70.728, wps=18740.1, ups=1.4, wpb=13404.7, bsz=451.6, num_updates=22600, lr=9.40721e-05, gnorm=0.374, clip=0, loss_scale=64, train_wall=71, gb_free=13.7, wall=19584
2023-08-23 20:01:10 | INFO | train_inner | epoch 020:    301 / 1191 loss=1.834, trans_loss=4.675, nll_loss=1.815, w2v_ctc_loss=0.555, task_loss=2.287, contrastive_loss=0, total=6755.72, n_correct=4773.6, ppl=3.52, accuracy=70.66, wps=18904.2, ups=1.4, wpb=13511.4, bsz=460.8, num_updates=22700, lr=9.38647e-05, gnorm=0.373, clip=0, loss_scale=128, train_wall=71, gb_free=14.6, wall=19656
2023-08-23 20:02:21 | INFO | train_inner | epoch 020:    401 / 1191 loss=1.838, trans_loss=4.681, nll_loss=1.822, w2v_ctc_loss=0.56, task_loss=2.293, contrastive_loss=0, total=6730.22, n_correct=4747.21, ppl=3.54, accuracy=70.536, wps=18984.6, ups=1.41, wpb=13460.4, bsz=456.1, num_updates=22800, lr=9.36586e-05, gnorm=0.37, clip=0, loss_scale=128, train_wall=70, gb_free=14.3, wall=19727
2023-08-23 20:03:32 | INFO | train_inner | epoch 020:    501 / 1191 loss=1.835, trans_loss=4.674, nll_loss=1.813, w2v_ctc_loss=0.555, task_loss=2.377, contrastive_loss=0, total=6672.71, n_correct=4713.63, ppl=3.51, accuracy=70.64, wps=18723.2, ups=1.4, wpb=13345.4, bsz=438.4, num_updates=22900, lr=9.34539e-05, gnorm=0.366, clip=0, loss_scale=128, train_wall=70, gb_free=13.1, wall=19798
2023-08-23 20:04:44 | INFO | train_inner | epoch 020:    601 / 1191 loss=1.835, trans_loss=4.677, nll_loss=1.817, w2v_ctc_loss=0.557, task_loss=2.268, contrastive_loss=0, total=6701.08, n_correct=4731.39, ppl=3.52, accuracy=70.606, wps=18736.8, ups=1.4, wpb=13402.2, bsz=465, num_updates=23000, lr=9.32505e-05, gnorm=0.373, clip=0, loss_scale=128, train_wall=71, gb_free=12.5, wall=19870
2023-08-23 20:05:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-23 20:05:56 | INFO | train_inner | epoch 020:    702 / 1191 loss=1.833, trans_loss=4.681, nll_loss=1.823, w2v_ctc_loss=0.549, task_loss=2.22, contrastive_loss=0, total=6713.48, n_correct=4739.64, ppl=3.54, accuracy=70.599, wps=18623.9, ups=1.39, wpb=13427, bsz=469.2, num_updates=23100, lr=9.30484e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=71, gb_free=12.6, wall=19942
2023-08-23 20:07:07 | INFO | train_inner | epoch 020:    802 / 1191 loss=1.839, trans_loss=4.68, nll_loss=1.822, w2v_ctc_loss=0.56, task_loss=2.334, contrastive_loss=0, total=6722.38, n_correct=4746.23, ppl=3.54, accuracy=70.603, wps=18957.5, ups=1.41, wpb=13444.8, bsz=443.5, num_updates=23200, lr=9.28477e-05, gnorm=0.374, clip=0, loss_scale=64, train_wall=70, gb_free=12.1, wall=20013
2023-08-23 20:08:19 | INFO | train_inner | epoch 020:    902 / 1191 loss=1.843, trans_loss=4.689, nll_loss=1.833, w2v_ctc_loss=0.563, task_loss=2.44, contrastive_loss=0, total=6700.12, n_correct=4717.53, ppl=3.56, accuracy=70.41, wps=18448.2, ups=1.38, wpb=13400.2, bsz=441.5, num_updates=23300, lr=9.26482e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=72, gb_free=11.6, wall=20085
2023-08-23 20:09:31 | INFO | train_inner | epoch 020:   1002 / 1191 loss=1.836, trans_loss=4.682, nll_loss=1.826, w2v_ctc_loss=0.551, task_loss=2.462, contrastive_loss=0, total=6721.84, n_correct=4743.18, ppl=3.54, accuracy=70.564, wps=18649.3, ups=1.39, wpb=13443.7, bsz=443.9, num_updates=23400, lr=9.245e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=71, gb_free=11, wall=20157
2023-08-23 20:10:43 | INFO | train_inner | epoch 020:   1102 / 1191 loss=1.845, trans_loss=4.691, nll_loss=1.836, w2v_ctc_loss=0.569, task_loss=2.383, contrastive_loss=0, total=6707.68, n_correct=4712.7, ppl=3.57, accuracy=70.258, wps=18678.4, ups=1.39, wpb=13415.4, bsz=448.3, num_updates=23500, lr=9.22531e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=71, gb_free=12.4, wall=20229
2023-08-23 20:11:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 20:12:20 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.861 | trans_loss 5.18 | nll_loss 2.381 | w2v_ctc_loss 1.167 | task_loss 8.514 | contrastive_loss 0 | total 6138.43 | n_correct 4169.29 | ppl 5.21 | accuracy 67.921 | uer 16.353 | wer 18.208 | raw_wer 18.208 | bleu 27.4 | wps 1766.7 | wpb 6138.4 | bsz 201.1 | num_updates 23589 | best_bleu 27.5
2023-08-23 20:12:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 23589 updates
2023-08-23 20:12:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4004.pt
2023-08-23 20:12:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4004.pt
2023-08-23 20:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4004.pt (epoch 20 @ 23589 updates, score 27.4) (writing took 7.058535116957501 seconds)
2023-08-23 20:12:27 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-23 20:12:27 | INFO | train | epoch 020 | loss 1.837 | trans_loss 4.68 | nll_loss 1.821 | w2v_ctc_loss 0.557 | task_loss 2.343 | contrastive_loss 0 | total 6703.73 | n_correct 4730.27 | ppl 3.53 | accuracy 70.562 | wps 17709.3 | ups 1.32 | wpb 13407.5 | bsz 452 | num_updates 23589 | lr 9.20789e-05 | gnorm 0.373 | clip 0 | loss_scale 64 | train_wall 844 | gb_free 15.4 | wall 20333
2023-08-23 20:12:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 20:12:27 | INFO | fairseq.trainer | begin training epoch 21
2023-08-23 20:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 20:12:43 | INFO | train_inner | epoch 021:     11 / 1191 loss=1.835, trans_loss=4.685, nll_loss=1.828, w2v_ctc_loss=0.553, task_loss=2.216, contrastive_loss=0, total=6726.85, n_correct=4743.38, ppl=3.55, accuracy=70.514, wps=11236.3, ups=0.84, wpb=13453.7, bsz=472, num_updates=23600, lr=9.20575e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=20349
2023-08-23 20:13:54 | INFO | train_inner | epoch 021:    111 / 1191 loss=1.819, trans_loss=4.656, nll_loss=1.79, w2v_ctc_loss=0.542, task_loss=2.194, contrastive_loss=0, total=6783.88, n_correct=4824.32, ppl=3.46, accuracy=71.114, wps=19176, ups=1.41, wpb=13567.8, bsz=479.2, num_updates=23700, lr=9.1863e-05, gnorm=0.365, clip=0, loss_scale=64, train_wall=70, gb_free=14.6, wall=20420
2023-08-23 20:15:05 | INFO | train_inner | epoch 021:    211 / 1191 loss=1.818, trans_loss=4.655, nll_loss=1.788, w2v_ctc_loss=0.54, task_loss=2.246, contrastive_loss=0, total=6759.68, n_correct=4814.04, ppl=3.45, accuracy=71.217, wps=18928.7, ups=1.4, wpb=13519.4, bsz=463.6, num_updates=23800, lr=9.16698e-05, gnorm=0.368, clip=0, loss_scale=64, train_wall=71, gb_free=12.8, wall=20491
2023-08-23 20:16:16 | INFO | train_inner | epoch 021:    311 / 1191 loss=1.832, trans_loss=4.667, nll_loss=1.804, w2v_ctc_loss=0.555, task_loss=2.422, contrastive_loss=0, total=6651.64, n_correct=4712.54, ppl=3.49, accuracy=70.848, wps=18767.5, ups=1.41, wpb=13303.3, bsz=439.2, num_updates=23900, lr=9.14779e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=70, gb_free=12.2, wall=20562
2023-08-23 20:17:28 | INFO | train_inner | epoch 021:    411 / 1191 loss=1.83, trans_loss=4.666, nll_loss=1.803, w2v_ctc_loss=0.551, task_loss=2.485, contrastive_loss=0, total=6602.51, n_correct=4680.95, ppl=3.49, accuracy=70.897, wps=18453.2, ups=1.4, wpb=13205, bsz=430.9, num_updates=24000, lr=9.12871e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=71, gb_free=13.2, wall=20634
2023-08-23 20:17:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 20:18:00 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.861 | trans_loss 5.181 | nll_loss 2.386 | w2v_ctc_loss 1.167 | task_loss 8.53 | contrastive_loss 0 | total 6138.43 | n_correct 4175 | ppl 5.23 | accuracy 68.014 | uer 16.404 | wer 18.341 | raw_wer 18.341 | bleu 27.29 | wps 1767.4 | wpb 6138.4 | bsz 201.1 | num_updates 24000 | best_bleu 27.5
2023-08-23 20:18:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 24000 updates
2023-08-23 20:18:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_21_24000.pt
2023-08-23 20:18:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_21_24000.pt
2023-08-23 20:18:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_21_24000.pt (epoch 21 @ 24000 updates, score 27.29) (writing took 7.063576390966773 seconds)
2023-08-23 20:19:19 | INFO | train_inner | epoch 021:    511 / 1191 loss=1.83, trans_loss=4.666, nll_loss=1.803, w2v_ctc_loss=0.551, task_loss=2.364, contrastive_loss=0, total=6757.09, n_correct=4785.97, ppl=3.49, accuracy=70.829, wps=12080.4, ups=0.89, wpb=13514.2, bsz=449.1, num_updates=24100, lr=9.10975e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=71, gb_free=13.7, wall=20746
2023-08-23 20:20:30 | INFO | train_inner | epoch 021:    611 / 1191 loss=1.837, trans_loss=4.678, nll_loss=1.819, w2v_ctc_loss=0.557, task_loss=2.471, contrastive_loss=0, total=6599.48, n_correct=4663.11, ppl=3.53, accuracy=70.659, wps=18578.8, ups=1.41, wpb=13199, bsz=434.1, num_updates=24200, lr=9.09091e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=70, gb_free=13.3, wall=20817
2023-08-23 20:21:42 | INFO | train_inner | epoch 021:    711 / 1191 loss=1.833, trans_loss=4.675, nll_loss=1.815, w2v_ctc_loss=0.552, task_loss=2.371, contrastive_loss=0, total=6696.79, n_correct=4731.97, ppl=3.52, accuracy=70.66, wps=18659.1, ups=1.39, wpb=13393.6, bsz=453.7, num_updates=24300, lr=9.07218e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=71, gb_free=13.1, wall=20888
2023-08-23 20:22:54 | INFO | train_inner | epoch 021:    811 / 1191 loss=1.836, trans_loss=4.677, nll_loss=1.818, w2v_ctc_loss=0.558, task_loss=2.47, contrastive_loss=0, total=6601.05, n_correct=4661.37, ppl=3.52, accuracy=70.616, wps=18463.5, ups=1.4, wpb=13202.1, bsz=437.1, num_updates=24400, lr=9.05357e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=20960
2023-08-23 20:24:05 | INFO | train_inner | epoch 021:    911 / 1191 loss=1.833, trans_loss=4.677, nll_loss=1.818, w2v_ctc_loss=0.555, task_loss=2.244, contrastive_loss=0, total=6799.15, n_correct=4804.25, ppl=3.53, accuracy=70.66, wps=18977.9, ups=1.4, wpb=13598.3, bsz=464.1, num_updates=24500, lr=9.03508e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=21032
2023-08-23 20:25:17 | INFO | train_inner | epoch 021:   1011 / 1191 loss=1.829, trans_loss=4.678, nll_loss=1.82, w2v_ctc_loss=0.543, task_loss=2.263, contrastive_loss=0, total=6762.06, n_correct=4779.27, ppl=3.53, accuracy=70.678, wps=18846, ups=1.39, wpb=13524.1, bsz=458.2, num_updates=24600, lr=9.0167e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=71, gb_free=11.8, wall=21103
2023-08-23 20:26:29 | INFO | train_inner | epoch 021:   1111 / 1191 loss=1.837, trans_loss=4.684, nll_loss=1.827, w2v_ctc_loss=0.557, task_loss=2.257, contrastive_loss=0, total=6742.05, n_correct=4749.52, ppl=3.55, accuracy=70.446, wps=18655, ups=1.38, wpb=13484.1, bsz=464.7, num_updates=24700, lr=8.99843e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=72, gb_free=13.6, wall=21176
2023-08-23 20:27:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 20:28:00 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.879 | trans_loss 5.182 | nll_loss 2.385 | w2v_ctc_loss 1.224 | task_loss 8.525 | contrastive_loss 0 | total 6138.43 | n_correct 4172.57 | ppl 5.22 | accuracy 67.975 | uer 16.653 | wer 18.446 | raw_wer 18.446 | bleu 27.11 | wps 1732.2 | wpb 6138.4 | bsz 201.1 | num_updates 24780 | best_bleu 27.5
2023-08-23 20:28:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 24780 updates
2023-08-23 20:28:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.1105.pt
2023-08-23 20:28:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.1105.pt
2023-08-23 20:28:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.1105.pt (epoch 21 @ 24780 updates, score 27.11) (writing took 7.0002338599879295 seconds)
2023-08-23 20:28:08 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-23 20:28:08 | INFO | train | epoch 021 | loss 1.83 | trans_loss 4.671 | nll_loss 1.809 | w2v_ctc_loss 0.551 | task_loss 2.343 | contrastive_loss 0 | total 6703.69 | n_correct 4745.84 | ppl 3.51 | accuracy 70.794 | wps 16976.2 | ups 1.27 | wpb 13407.4 | bsz 452.1 | num_updates 24780 | lr 8.98389e-05 | gnorm 0.374 | clip 0 | loss_scale 64 | train_wall 844 | gb_free 13.7 | wall 21274
2023-08-23 20:28:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 20:28:08 | INFO | fairseq.trainer | begin training epoch 22
2023-08-23 20:28:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 20:28:30 | INFO | train_inner | epoch 022:     20 / 1191 loss=1.829, trans_loss=4.671, nll_loss=1.811, w2v_ctc_loss=0.55, task_loss=2.409, contrastive_loss=0, total=6646.7, n_correct=4710.19, ppl=3.51, accuracy=70.865, wps=11040.9, ups=0.83, wpb=13293.4, bsz=446.5, num_updates=24800, lr=8.98027e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=72, gb_free=14.6, wall=21296
2023-08-23 20:29:41 | INFO | train_inner | epoch 022:    120 / 1191 loss=1.814, trans_loss=4.647, nll_loss=1.778, w2v_ctc_loss=0.534, task_loss=2.312, contrastive_loss=0, total=6756.34, n_correct=4823.39, ppl=3.43, accuracy=71.391, wps=19012.4, ups=1.41, wpb=13512.7, bsz=456.5, num_updates=24900, lr=8.96221e-05, gnorm=0.369, clip=0, loss_scale=64, train_wall=70, gb_free=13.7, wall=21367
2023-08-23 20:30:53 | INFO | train_inner | epoch 022:    220 / 1191 loss=1.823, trans_loss=4.658, nll_loss=1.792, w2v_ctc_loss=0.544, task_loss=2.378, contrastive_loss=0, total=6672.57, n_correct=4744.94, ppl=3.46, accuracy=71.111, wps=18620.9, ups=1.4, wpb=13345.1, bsz=446, num_updates=25000, lr=8.94427e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=21439
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:0')
2023-08-23 20:32:04 | INFO | train_inner | epoch 022:    320 / 1191 loss=1.822, trans_loss=4.658, nll_loss=1.793, w2v_ctc_loss=0.547, task_loss=2.296, contrastive_loss=0, total=6725.78, n_correct=4781.32, ppl=3.47, accuracy=71.089, wps=18731.3, ups=1.39, wpb=13451.6, bsz=465.6, num_updates=25100, lr=8.92644e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=71, gb_free=14.2, wall=21511
2023-08-23 20:33:17 | INFO | train_inner | epoch 022:    420 / 1191 loss=1.82, trans_loss=4.654, nll_loss=1.789, w2v_ctc_loss=0.545, task_loss=2.32, contrastive_loss=0, total=6687.3, n_correct=4761.27, ppl=3.46, accuracy=71.199, wps=18534.6, ups=1.39, wpb=13374.6, bsz=460.6, num_updates=25200, lr=8.90871e-05, gnorm=0.373, clip=0, loss_scale=128, train_wall=72, gb_free=11.7, wall=21583
2023-08-23 20:34:28 | INFO | train_inner | epoch 022:    520 / 1191 loss=1.83, trans_loss=4.669, nll_loss=1.808, w2v_ctc_loss=0.555, task_loss=2.298, contrastive_loss=0, total=6750.17, n_correct=4786.02, ppl=3.5, accuracy=70.902, wps=18950.1, ups=1.4, wpb=13500.3, bsz=461, num_updates=25300, lr=8.89108e-05, gnorm=0.376, clip=0, loss_scale=128, train_wall=71, gb_free=12.9, wall=21654
2023-08-23 20:35:40 | INFO | train_inner | epoch 022:    620 / 1191 loss=1.823, trans_loss=4.663, nll_loss=1.8, w2v_ctc_loss=0.54, task_loss=2.431, contrastive_loss=0, total=6685.8, n_correct=4749.53, ppl=3.48, accuracy=71.039, wps=18518.2, ups=1.38, wpb=13371.6, bsz=439.6, num_updates=25400, lr=8.87357e-05, gnorm=0.376, clip=0, loss_scale=128, train_wall=72, gb_free=11.3, wall=21726
2023-08-23 20:36:51 | INFO | train_inner | epoch 022:    720 / 1191 loss=1.825, trans_loss=4.666, nll_loss=1.805, w2v_ctc_loss=0.545, task_loss=2.232, contrastive_loss=0, total=6722.6, n_correct=4765.4, ppl=3.49, accuracy=70.886, wps=18941.1, ups=1.41, wpb=13445.2, bsz=462.2, num_updates=25500, lr=8.85615e-05, gnorm=0.377, clip=0, loss_scale=128, train_wall=70, gb_free=13.7, wall=21797
2023-08-23 20:38:02 | INFO | train_inner | epoch 022:    820 / 1191 loss=1.83, trans_loss=4.664, nll_loss=1.801, w2v_ctc_loss=0.555, task_loss=2.537, contrastive_loss=0, total=6517.08, n_correct=4627.45, ppl=3.48, accuracy=71.005, wps=18481.3, ups=1.42, wpb=13034.2, bsz=421.8, num_updates=25600, lr=8.83883e-05, gnorm=0.383, clip=0, loss_scale=128, train_wall=70, gb_free=6.1, wall=21868
2023-08-23 20:39:14 | INFO | train_inner | epoch 022:    920 / 1191 loss=1.829, trans_loss=4.675, nll_loss=1.816, w2v_ctc_loss=0.545, task_loss=2.313, contrastive_loss=0, total=6754.24, n_correct=4776.32, ppl=3.52, accuracy=70.716, wps=18577, ups=1.38, wpb=13508.5, bsz=463.4, num_updates=25700, lr=8.82162e-05, gnorm=0.373, clip=0, loss_scale=128, train_wall=72, gb_free=13.1, wall=21940
2023-08-23 20:39:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-23 20:40:27 | INFO | train_inner | epoch 022:   1021 / 1191 loss=1.825, trans_loss=4.666, nll_loss=1.804, w2v_ctc_loss=0.545, task_loss=2.215, contrastive_loss=0, total=6837.89, n_correct=4851.23, ppl=3.49, accuracy=70.946, wps=18809.7, ups=1.38, wpb=13675.8, bsz=470.1, num_updates=25800, lr=8.80451e-05, gnorm=0.37, clip=0, loss_scale=64, train_wall=72, gb_free=11.9, wall=22013
2023-08-23 20:41:38 | INFO | train_inner | epoch 022:   1121 / 1191 loss=1.831, trans_loss=4.672, nll_loss=1.812, w2v_ctc_loss=0.553, task_loss=2.378, contrastive_loss=0, total=6699.31, n_correct=4742.85, ppl=3.51, accuracy=70.796, wps=18925.1, ups=1.41, wpb=13398.6, bsz=443.3, num_updates=25900, lr=8.7875e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=70, gb_free=13.6, wall=22084
2023-08-23 20:42:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:3')
2023-08-23 20:43:01 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.895 | trans_loss 5.185 | nll_loss 2.389 | w2v_ctc_loss 1.267 | task_loss 8.551 | contrastive_loss 0 | total 6138.43 | n_correct 4163.57 | ppl 5.24 | accuracy 67.828 | uer 16.843 | wer 18.695 | raw_wer 18.695 | bleu 27.41 | wps 1722.2 | wpb 6138.4 | bsz 201.1 | num_updates 25970 | best_bleu 27.5
2023-08-23 20:43:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 25970 updates
2023-08-23 20:43:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4105.pt
2023-08-23 20:43:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4105.pt
2023-08-23 20:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4105.pt (epoch 22 @ 25970 updates, score 27.41) (writing took 6.829779383027926 seconds)
2023-08-23 20:43:08 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-23 20:43:08 | INFO | train | epoch 022 | loss 1.825 | trans_loss 4.663 | nll_loss 1.801 | w2v_ctc_loss 0.546 | task_loss 2.346 | contrastive_loss 0 | total 6703.3 | n_correct 4759.22 | ppl 3.48 | accuracy 70.998 | wps 17713 | ups 1.32 | wpb 13406.6 | bsz 452.1 | num_updates 25970 | lr 8.77564e-05 | gnorm 0.375 | clip 0 | loss_scale 64 | train_wall 844 | gb_free 13.6 | wall 22174
2023-08-23 20:43:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 20:43:08 | INFO | fairseq.trainer | begin training epoch 23
2023-08-23 20:43:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 20:43:38 | INFO | train_inner | epoch 023:     30 / 1191 loss=1.825, trans_loss=4.664, nll_loss=1.802, w2v_ctc_loss=0.542, task_loss=2.479, contrastive_loss=0, total=6668.41, n_correct=4732.6, ppl=3.49, accuracy=70.97, wps=11104.3, ups=0.83, wpb=13336.8, bsz=437.7, num_updates=26000, lr=8.77058e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=22204
2023-08-23 20:43:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 20:44:11 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.906 | trans_loss 5.191 | nll_loss 2.397 | w2v_ctc_loss 1.292 | task_loss 8.53 | contrastive_loss 0 | total 6138.43 | n_correct 4157.57 | ppl 5.27 | accuracy 67.73 | uer 16.674 | wer 18.546 | raw_wer 18.546 | bleu 27.22 | wps 1746.1 | wpb 6138.4 | bsz 201.1 | num_updates 26000 | best_bleu 27.5
2023-08-23 20:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 26000 updates
2023-08-23 20:44:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_23_26000.pt
2023-08-23 20:44:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_23_26000.pt
2023-08-23 20:44:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_23_26000.pt (epoch 23 @ 26000 updates, score 27.22) (writing took 6.946877766982652 seconds)
2023-08-23 20:45:29 | INFO | train_inner | epoch 023:    130 / 1191 loss=1.815, trans_loss=4.643, nll_loss=1.774, w2v_ctc_loss=0.541, task_loss=2.37, contrastive_loss=0, total=6679.5, n_correct=4771.46, ppl=3.42, accuracy=71.434, wps=12015.7, ups=0.9, wpb=13359, bsz=449, num_updates=26100, lr=8.75376e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=70, gb_free=13.3, wall=22315
2023-08-23 20:46:41 | INFO | train_inner | epoch 023:    230 / 1191 loss=1.809, trans_loss=4.644, nll_loss=1.775, w2v_ctc_loss=0.531, task_loss=2.222, contrastive_loss=0, total=6807.53, n_correct=4863.28, ppl=3.42, accuracy=71.44, wps=19025.1, ups=1.4, wpb=13615.1, bsz=469.1, num_updates=26200, lr=8.73704e-05, gnorm=0.368, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=22387
2023-08-23 20:47:53 | INFO | train_inner | epoch 023:    330 / 1191 loss=1.817, trans_loss=4.653, nll_loss=1.786, w2v_ctc_loss=0.538, task_loss=2.343, contrastive_loss=0, total=6788.3, n_correct=4836.33, ppl=3.45, accuracy=71.245, wps=18840.9, ups=1.39, wpb=13576.6, bsz=454.7, num_updates=26300, lr=8.72041e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=71, gb_free=14, wall=22459
2023-08-23 20:49:05 | INFO | train_inner | epoch 023:    430 / 1191 loss=1.82, trans_loss=4.654, nll_loss=1.788, w2v_ctc_loss=0.541, task_loss=2.391, contrastive_loss=0, total=6708.59, n_correct=4771.76, ppl=3.45, accuracy=71.129, wps=18688, ups=1.39, wpb=13417.2, bsz=442.6, num_updates=26400, lr=8.70388e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=71, gb_free=14.5, wall=22531
2023-08-23 20:50:16 | INFO | train_inner | epoch 023:    530 / 1191 loss=1.812, trans_loss=4.651, nll_loss=1.786, w2v_ctc_loss=0.531, task_loss=2.231, contrastive_loss=0, total=6760.85, n_correct=4823.93, ppl=3.45, accuracy=71.351, wps=18961.6, ups=1.4, wpb=13521.7, bsz=471.2, num_updates=26500, lr=8.68744e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=71, gb_free=12, wall=22602
2023-08-23 20:51:27 | INFO | train_inner | epoch 023:    630 / 1191 loss=1.822, trans_loss=4.658, nll_loss=1.794, w2v_ctc_loss=0.542, task_loss=2.396, contrastive_loss=0, total=6594.09, n_correct=4690.16, ppl=3.47, accuracy=71.127, wps=18502.2, ups=1.4, wpb=13188.2, bsz=436.9, num_updates=26600, lr=8.6711e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=71, gb_free=13.9, wall=22673
2023-08-23 20:52:40 | INFO | train_inner | epoch 023:    730 / 1191 loss=1.822, trans_loss=4.66, nll_loss=1.797, w2v_ctc_loss=0.541, task_loss=2.45, contrastive_loss=0, total=6685.78, n_correct=4751.22, ppl=3.47, accuracy=71.065, wps=18451.8, ups=1.38, wpb=13371.6, bsz=439, num_updates=26700, lr=8.65485e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=72, gb_free=13, wall=22746
2023-08-23 20:53:52 | INFO | train_inner | epoch 023:    830 / 1191 loss=1.823, trans_loss=4.661, nll_loss=1.799, w2v_ctc_loss=0.545, task_loss=2.417, contrastive_loss=0, total=6690.66, n_correct=4755.08, ppl=3.48, accuracy=71.07, wps=18497.7, ups=1.38, wpb=13381.3, bsz=447.6, num_updates=26800, lr=8.63868e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=72, gb_free=10.8, wall=22818
2023-08-23 20:55:03 | INFO | train_inner | epoch 023:    930 / 1191 loss=1.815, trans_loss=4.651, nll_loss=1.786, w2v_ctc_loss=0.541, task_loss=2.184, contrastive_loss=0, total=6746.05, n_correct=4811.75, ppl=3.45, accuracy=71.327, wps=18978.6, ups=1.41, wpb=13492.1, bsz=469.6, num_updates=26900, lr=8.62261e-05, gnorm=0.374, clip=0, loss_scale=64, train_wall=70, gb_free=12.8, wall=22889
2023-08-23 20:56:14 | INFO | train_inner | epoch 023:   1030 / 1191 loss=1.821, trans_loss=4.661, nll_loss=1.799, w2v_ctc_loss=0.546, task_loss=2.26, contrastive_loss=0, total=6677.09, n_correct=4753.84, ppl=3.48, accuracy=71.196, wps=18699.7, ups=1.4, wpb=13354.2, bsz=465.7, num_updates=27000, lr=8.60663e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=71, gb_free=10.2, wall=22961
2023-08-23 20:57:26 | INFO | train_inner | epoch 023:   1130 / 1191 loss=1.824, trans_loss=4.667, nll_loss=1.806, w2v_ctc_loss=0.538, task_loss=2.478, contrastive_loss=0, total=6655.6, n_correct=4721.12, ppl=3.5, accuracy=70.935, wps=18651.4, ups=1.4, wpb=13311.2, bsz=439, num_updates=27100, lr=8.59074e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=15.5, wall=23032
2023-08-23 20:58:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 20:58:42 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.881 | trans_loss 5.179 | nll_loss 2.381 | w2v_ctc_loss 1.236 | task_loss 8.576 | contrastive_loss 0 | total 6138.43 | n_correct 4176.71 | ppl 5.21 | accuracy 68.042 | uer 16.254 | wer 18.141 | raw_wer 18.141 | bleu 27.72 | wps 1772.3 | wpb 6138.4 | bsz 201.1 | num_updates 27161 | best_bleu 27.72
2023-08-23 20:58:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 27161 updates
2023-08-23 20:58:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 20:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 20:58:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 23 @ 27161 updates, score 27.72) (writing took 10.704084052005783 seconds)
2023-08-23 20:58:53 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-23 20:58:53 | INFO | train | epoch 023 | loss 1.819 | trans_loss 4.655 | nll_loss 1.79 | w2v_ctc_loss 0.54 | task_loss 2.346 | contrastive_loss 0 | total 6703.69 | n_correct 4772.89 | ppl 3.46 | accuracy 71.198 | wps 16896.5 | ups 1.26 | wpb 13407.4 | bsz 452.1 | num_updates 27161 | lr 8.58108e-05 | gnorm 0.375 | clip 0 | loss_scale 64 | train_wall 845 | gb_free 14.8 | wall 23119
2023-08-23 20:58:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 20:58:54 | INFO | fairseq.trainer | begin training epoch 24
2023-08-23 20:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 20:59:29 | INFO | train_inner | epoch 024:     39 / 1191 loss=1.818, trans_loss=4.654, nll_loss=1.789, w2v_ctc_loss=0.54, task_loss=2.372, contrastive_loss=0, total=6689.11, n_correct=4761.82, ppl=3.46, accuracy=71.188, wps=10858.1, ups=0.81, wpb=13378.2, bsz=448.4, num_updates=27200, lr=8.57493e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=12.2, wall=23155
2023-08-23 21:00:41 | INFO | train_inner | epoch 024:    139 / 1191 loss=1.811, trans_loss=4.643, nll_loss=1.774, w2v_ctc_loss=0.536, task_loss=2.325, contrastive_loss=0, total=6687.62, n_correct=4781.18, ppl=3.42, accuracy=71.493, wps=18719.9, ups=1.4, wpb=13375.2, bsz=463.1, num_updates=27300, lr=8.55921e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=23227
2023-08-23 21:01:51 | INFO | train_inner | epoch 024:    239 / 1191 loss=1.803, trans_loss=4.636, nll_loss=1.766, w2v_ctc_loss=0.524, task_loss=2.144, contrastive_loss=0, total=6815.44, n_correct=4882.09, ppl=3.4, accuracy=71.633, wps=19209, ups=1.41, wpb=13630.9, bsz=477.8, num_updates=27400, lr=8.54358e-05, gnorm=0.368, clip=0, loss_scale=64, train_wall=70, gb_free=14, wall=23298
2023-08-23 21:03:03 | INFO | train_inner | epoch 024:    339 / 1191 loss=1.812, trans_loss=4.646, nll_loss=1.778, w2v_ctc_loss=0.531, task_loss=2.366, contrastive_loss=0, total=6718.23, n_correct=4801.98, ppl=3.43, accuracy=71.477, wps=18758.8, ups=1.4, wpb=13436.5, bsz=448.7, num_updates=27500, lr=8.52803e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=71, gb_free=14.2, wall=23369
2023-08-23 21:04:15 | INFO | train_inner | epoch 024:    439 / 1191 loss=1.813, trans_loss=4.642, nll_loss=1.774, w2v_ctc_loss=0.536, task_loss=2.401, contrastive_loss=0, total=6677.55, n_correct=4768.69, ppl=3.42, accuracy=71.414, wps=18670.6, ups=1.4, wpb=13355.1, bsz=440.9, num_updates=27600, lr=8.51257e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=71, gb_free=14.3, wall=23441
2023-08-23 21:05:27 | INFO | train_inner | epoch 024:    539 / 1191 loss=1.811, trans_loss=4.648, nll_loss=1.781, w2v_ctc_loss=0.531, task_loss=2.339, contrastive_loss=0, total=6703.4, n_correct=4781.53, ppl=3.44, accuracy=71.33, wps=18633.4, ups=1.39, wpb=13406.8, bsz=464.1, num_updates=27700, lr=8.49719e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=71, gb_free=13.5, wall=23513
2023-08-23 21:06:38 | INFO | train_inner | epoch 024:    639 / 1191 loss=1.824, trans_loss=4.653, nll_loss=1.787, w2v_ctc_loss=0.548, task_loss=2.547, contrastive_loss=0, total=6544.69, n_correct=4661.05, ppl=3.45, accuracy=71.219, wps=18322.7, ups=1.4, wpb=13089.4, bsz=417.9, num_updates=27800, lr=8.48189e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=23584
2023-08-23 21:07:49 | INFO | train_inner | epoch 024:    739 / 1191 loss=1.812, trans_loss=4.648, nll_loss=1.782, w2v_ctc_loss=0.533, task_loss=2.263, contrastive_loss=0, total=6734.28, n_correct=4809.3, ppl=3.44, accuracy=71.415, wps=18953.4, ups=1.41, wpb=13468.6, bsz=467.1, num_updates=27900, lr=8.46668e-05, gnorm=0.374, clip=0, loss_scale=128, train_wall=70, gb_free=14.7, wall=23655
2023-08-23 21:09:00 | INFO | train_inner | epoch 024:    839 / 1191 loss=1.818, trans_loss=4.65, nll_loss=1.783, w2v_ctc_loss=0.544, task_loss=2.368, contrastive_loss=0, total=6691.34, n_correct=4773.25, ppl=3.44, accuracy=71.335, wps=18888.1, ups=1.41, wpb=13382.7, bsz=438.7, num_updates=28000, lr=8.45154e-05, gnorm=0.375, clip=0, loss_scale=128, train_wall=70, gb_free=14.5, wall=23726
2023-08-23 21:09:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 21:09:33 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.879 | trans_loss 5.187 | nll_loss 2.393 | w2v_ctc_loss 1.211 | task_loss 8.551 | contrastive_loss 0 | total 6138.43 | n_correct 4165.14 | ppl 5.25 | accuracy 67.854 | uer 16.396 | wer 18.181 | raw_wer 18.181 | bleu 27.59 | wps 1730.7 | wpb 6138.4 | bsz 201.1 | num_updates 28000 | best_bleu 27.72
2023-08-23 21:09:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28000 updates
2023-08-23 21:09:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_24_28000.pt
2023-08-23 21:09:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_24_28000.pt
2023-08-23 21:09:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_24_28000.pt (epoch 24 @ 28000 updates, score 27.59) (writing took 7.316762651898898 seconds)
2023-08-23 21:10:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-23 21:10:53 | INFO | train_inner | epoch 024:    940 / 1191 loss=1.813, trans_loss=4.652, nll_loss=1.787, w2v_ctc_loss=0.535, task_loss=2.306, contrastive_loss=0, total=6748.59, n_correct=4817.17, ppl=3.45, accuracy=71.38, wps=11913.2, ups=0.88, wpb=13497.2, bsz=458.8, num_updates=28100, lr=8.43649e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=72, gb_free=12.8, wall=23839
2023-08-23 21:12:05 | INFO | train_inner | epoch 024:   1040 / 1191 loss=1.817, trans_loss=4.657, nll_loss=1.793, w2v_ctc_loss=0.534, task_loss=2.477, contrastive_loss=0, total=6611.31, n_correct=4709.68, ppl=3.47, accuracy=71.237, wps=18376.7, ups=1.39, wpb=13222.6, bsz=438, num_updates=28200, lr=8.42152e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=14.9, wall=23911
2023-08-23 21:13:18 | INFO | train_inner | epoch 024:   1140 / 1191 loss=1.818, trans_loss=4.653, nll_loss=1.787, w2v_ctc_loss=0.537, task_loss=2.479, contrastive_loss=0, total=6662.88, n_correct=4748.09, ppl=3.45, accuracy=71.262, wps=18269.9, ups=1.37, wpb=13325.8, bsz=433.1, num_updates=28300, lr=8.40663e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=72, gb_free=13.9, wall=23984
2023-08-23 21:13:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 21:14:27 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.882 | trans_loss 5.182 | nll_loss 2.387 | w2v_ctc_loss 1.233 | task_loss 8.588 | contrastive_loss 0 | total 6138.43 | n_correct 4176.86 | ppl 5.23 | accuracy 68.044 | uer 16.391 | wer 18.129 | raw_wer 18.129 | bleu 27.67 | wps 1760.1 | wpb 6138.4 | bsz 201.1 | num_updates 28351 | best_bleu 27.72
2023-08-23 21:14:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28351 updates
2023-08-23 21:14:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.6709.pt
2023-08-23 21:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.6709.pt
2023-08-23 21:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.6709.pt (epoch 24 @ 28351 updates, score 27.67) (writing took 6.386385259917006 seconds)
2023-08-23 21:14:34 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-23 21:14:34 | INFO | train | epoch 024 | loss 1.813 | trans_loss 4.648 | nll_loss 1.781 | w2v_ctc_loss 0.535 | task_loss 2.347 | contrastive_loss 0 | total 6702.96 | n_correct 4785.59 | ppl 3.44 | accuracy 71.395 | wps 16957.1 | ups 1.26 | wpb 13405.9 | bsz 451.8 | num_updates 28351 | lr 8.39906e-05 | gnorm 0.375 | clip 0 | loss_scale 64 | train_wall 845 | gb_free 15.1 | wall 24060
2023-08-23 21:14:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 21:14:34 | INFO | fairseq.trainer | begin training epoch 25
2023-08-23 21:14:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 21:15:17 | INFO | train_inner | epoch 025:     49 / 1191 loss=1.811, trans_loss=4.644, nll_loss=1.776, w2v_ctc_loss=0.532, task_loss=2.331, contrastive_loss=0, total=6706.68, n_correct=4795.11, ppl=3.43, accuracy=71.498, wps=11265.6, ups=0.84, wpb=13413.4, bsz=454.8, num_updates=28400, lr=8.39181e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=70, gb_free=14.5, wall=24103
2023-08-23 21:16:29 | INFO | train_inner | epoch 025:    149 / 1191 loss=1.804, trans_loss=4.628, nll_loss=1.754, w2v_ctc_loss=0.527, task_loss=2.524, contrastive_loss=0, total=6583.66, n_correct=4730.33, ppl=3.37, accuracy=71.85, wps=18424.9, ups=1.4, wpb=13167.3, bsz=430.4, num_updates=28500, lr=8.37708e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=14, wall=24175
2023-08-23 21:17:40 | INFO | train_inner | epoch 025:    249 / 1191 loss=1.801, trans_loss=4.631, nll_loss=1.759, w2v_ctc_loss=0.526, task_loss=2.254, contrastive_loss=0, total=6772.17, n_correct=4869.46, ppl=3.39, accuracy=71.904, wps=18911.6, ups=1.4, wpb=13544.3, bsz=470.4, num_updates=28600, lr=8.36242e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=71, gb_free=12, wall=24246
2023-08-23 21:18:52 | INFO | train_inner | epoch 025:    349 / 1191 loss=1.816, trans_loss=4.643, nll_loss=1.774, w2v_ctc_loss=0.539, task_loss=2.541, contrastive_loss=0, total=6593.02, n_correct=4711.68, ppl=3.42, accuracy=71.465, wps=18327.4, ups=1.39, wpb=13186, bsz=423.2, num_updates=28700, lr=8.34784e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=71, gb_free=13.7, wall=24318
2023-08-23 21:20:04 | INFO | train_inner | epoch 025:    449 / 1191 loss=1.806, trans_loss=4.637, nll_loss=1.767, w2v_ctc_loss=0.53, task_loss=2.379, contrastive_loss=0, total=6716.86, n_correct=4814.5, ppl=3.4, accuracy=71.678, wps=18711, ups=1.39, wpb=13433.7, bsz=448.6, num_updates=28800, lr=8.33333e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=71, gb_free=13.4, wall=24390
2023-08-23 21:21:15 | INFO | train_inner | epoch 025:    549 / 1191 loss=1.801, trans_loss=4.637, nll_loss=1.768, w2v_ctc_loss=0.52, task_loss=2.224, contrastive_loss=0, total=6773.06, n_correct=4856.41, ppl=3.4, accuracy=71.702, wps=19070.3, ups=1.41, wpb=13546.1, bsz=468.1, num_updates=28900, lr=8.3189e-05, gnorm=0.37, clip=0, loss_scale=64, train_wall=70, gb_free=13.2, wall=24461
2023-08-23 21:22:27 | INFO | train_inner | epoch 025:    649 / 1191 loss=1.808, trans_loss=4.638, nll_loss=1.77, w2v_ctc_loss=0.529, task_loss=2.338, contrastive_loss=0, total=6761.4, n_correct=4843.17, ppl=3.41, accuracy=71.63, wps=18846.1, ups=1.39, wpb=13522.8, bsz=453, num_updates=29000, lr=8.30455e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=71, gb_free=12.6, wall=24533
2023-08-23 21:23:38 | INFO | train_inner | epoch 025:    749 / 1191 loss=1.814, trans_loss=4.65, nll_loss=1.784, w2v_ctc_loss=0.535, task_loss=2.295, contrastive_loss=0, total=6717.77, n_correct=4791.29, ppl=3.44, accuracy=71.323, wps=18864.1, ups=1.4, wpb=13435.5, bsz=458.8, num_updates=29100, lr=8.29027e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=70, gb_free=12.5, wall=24604
2023-08-23 21:24:50 | INFO | train_inner | epoch 025:    849 / 1191 loss=1.81, trans_loss=4.645, nll_loss=1.778, w2v_ctc_loss=0.53, task_loss=2.34, contrastive_loss=0, total=6684.71, n_correct=4774.72, ppl=3.43, accuracy=71.427, wps=18688.9, ups=1.4, wpb=13369.4, bsz=452.2, num_updates=29200, lr=8.27606e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=24676
2023-08-23 21:26:02 | INFO | train_inner | epoch 025:    949 / 1191 loss=1.808, trans_loss=4.643, nll_loss=1.776, w2v_ctc_loss=0.528, task_loss=2.23, contrastive_loss=0, total=6774.11, n_correct=4841.68, ppl=3.43, accuracy=71.473, wps=18803.6, ups=1.39, wpb=13548.2, bsz=468, num_updates=29300, lr=8.26192e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=71, gb_free=12.5, wall=24748
2023-08-23 21:27:12 | INFO | train_inner | epoch 025:   1049 / 1191 loss=1.811, trans_loss=4.65, nll_loss=1.785, w2v_ctc_loss=0.532, task_loss=2.293, contrastive_loss=0, total=6664.17, n_correct=4756.09, ppl=3.45, accuracy=71.368, wps=18849.7, ups=1.41, wpb=13328.3, bsz=454.9, num_updates=29400, lr=8.24786e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=70, gb_free=13.8, wall=24818
2023-08-23 21:28:25 | INFO | train_inner | epoch 025:   1149 / 1191 loss=1.821, trans_loss=4.658, nll_loss=1.795, w2v_ctc_loss=0.544, task_loss=2.514, contrastive_loss=0, total=6669.85, n_correct=4748.24, ppl=3.47, accuracy=71.19, wps=18462.7, ups=1.38, wpb=13339.7, bsz=438.1, num_updates=29500, lr=8.23387e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=72, gb_free=13.7, wall=24891
2023-08-23 21:28:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 21:29:27 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.882 | trans_loss 5.174 | nll_loss 2.379 | w2v_ctc_loss 1.248 | task_loss 8.558 | contrastive_loss 0 | total 6138.43 | n_correct 4177.71 | ppl 5.2 | accuracy 68.058 | uer 16.404 | wer 18.196 | raw_wer 18.196 | bleu 27.66 | wps 1745.2 | wpb 6138.4 | bsz 201.1 | num_updates 29542 | best_bleu 27.72
2023-08-23 21:29:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 29542 updates
2023-08-23 21:29:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.6608.pt
2023-08-23 21:29:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.6608.pt
2023-08-23 21:29:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.6608.pt (epoch 25 @ 29542 updates, score 27.66) (writing took 6.851443600957282 seconds)
2023-08-23 21:29:35 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-23 21:29:35 | INFO | train | epoch 025 | loss 1.809 | trans_loss 4.642 | nll_loss 1.774 | w2v_ctc_loss 0.531 | task_loss 2.346 | contrastive_loss 0 | total 6703.69 | n_correct 4796.03 | ppl 3.42 | accuracy 71.543 | wps 17733.4 | ups 1.32 | wpb 13407.4 | bsz 452.1 | num_updates 29542 | lr 8.22801e-05 | gnorm 0.376 | clip 0 | loss_scale 64 | train_wall 844 | gb_free 11.8 | wall 24961
2023-08-23 21:29:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 21:29:35 | INFO | fairseq.trainer | begin training epoch 26
2023-08-23 21:29:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 21:30:24 | INFO | train_inner | epoch 026:     58 / 1191 loss=1.8, trans_loss=4.634, nll_loss=1.764, w2v_ctc_loss=0.519, task_loss=2.192, contrastive_loss=0, total=6841.74, n_correct=4912.07, ppl=3.4, accuracy=71.796, wps=11472.6, ups=0.84, wpb=13683.5, bsz=470.5, num_updates=29600, lr=8.21995e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=71, gb_free=14.2, wall=25010
2023-08-23 21:31:36 | INFO | train_inner | epoch 026:    158 / 1191 loss=1.799, trans_loss=4.623, nll_loss=1.75, w2v_ctc_loss=0.524, task_loss=2.343, contrastive_loss=0, total=6694.68, n_correct=4815.52, ppl=3.36, accuracy=71.931, wps=18677, ups=1.39, wpb=13389.4, bsz=453.3, num_updates=29700, lr=8.2061e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=71, gb_free=12.1, wall=25082
2023-08-23 21:32:47 | INFO | train_inner | epoch 026:    258 / 1191 loss=1.8, trans_loss=4.625, nll_loss=1.751, w2v_ctc_loss=0.525, task_loss=2.315, contrastive_loss=0, total=6715.19, n_correct=4830.67, ppl=3.37, accuracy=71.936, wps=18804.4, ups=1.4, wpb=13430.4, bsz=453.5, num_updates=29800, lr=8.19232e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=10.3, wall=25153
2023-08-23 21:33:59 | INFO | train_inner | epoch 026:    358 / 1191 loss=1.797, trans_loss=4.628, nll_loss=1.757, w2v_ctc_loss=0.525, task_loss=2.058, contrastive_loss=0, total=6866.81, n_correct=4934.09, ppl=3.38, accuracy=71.854, wps=19191.9, ups=1.4, wpb=13733.6, bsz=496.9, num_updates=29900, lr=8.17861e-05, gnorm=0.372, clip=0, loss_scale=64, train_wall=71, gb_free=5.6, wall=25225
2023-08-23 21:35:10 | INFO | train_inner | epoch 026:    458 / 1191 loss=1.806, trans_loss=4.634, nll_loss=1.762, w2v_ctc_loss=0.528, task_loss=2.498, contrastive_loss=0, total=6569.15, n_correct=4710.06, ppl=3.39, accuracy=71.7, wps=18389.5, ups=1.4, wpb=13138.3, bsz=428.5, num_updates=30000, lr=8.16497e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=4.5, wall=25296
2023-08-23 21:35:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 21:35:42 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.886 | trans_loss 5.19 | nll_loss 2.394 | w2v_ctc_loss 1.226 | task_loss 8.549 | contrastive_loss 0 | total 6138.43 | n_correct 4173.29 | ppl 5.26 | accuracy 67.986 | uer 16.321 | wer 18.089 | raw_wer 18.089 | bleu 27.46 | wps 1768.7 | wpb 6138.4 | bsz 201.1 | num_updates 30000 | best_bleu 27.72
2023-08-23 21:35:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30000 updates
2023-08-23 21:35:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_26_30000.pt
2023-08-23 21:35:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_26_30000.pt
2023-08-23 21:35:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_26_30000.pt (epoch 26 @ 30000 updates, score 27.46) (writing took 7.221706776064821 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:0')
2023-08-23 21:37:02 | INFO | train_inner | epoch 026:    558 / 1191 loss=1.804, trans_loss=4.636, nll_loss=1.766, w2v_ctc_loss=0.522, task_loss=2.387, contrastive_loss=0, total=6698.35, n_correct=4804.64, ppl=3.4, accuracy=71.729, wps=12005.6, ups=0.9, wpb=13396.7, bsz=449.4, num_updates=30100, lr=8.15139e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=71, gb_free=11.3, wall=25408
2023-08-23 21:38:13 | INFO | train_inner | epoch 026:    658 / 1191 loss=1.808, trans_loss=4.636, nll_loss=1.766, w2v_ctc_loss=0.527, task_loss=2.566, contrastive_loss=0, total=6616.98, n_correct=4742.8, ppl=3.4, accuracy=71.676, wps=18563.3, ups=1.4, wpb=13234, bsz=422.1, num_updates=30200, lr=8.13788e-05, gnorm=0.382, clip=0, loss_scale=128, train_wall=71, gb_free=14.5, wall=25479
2023-08-23 21:39:25 | INFO | train_inner | epoch 026:    758 / 1191 loss=1.802, trans_loss=4.634, nll_loss=1.764, w2v_ctc_loss=0.522, task_loss=2.341, contrastive_loss=0, total=6742.67, n_correct=4839.77, ppl=3.4, accuracy=71.778, wps=18735.3, ups=1.39, wpb=13485.3, bsz=448.4, num_updates=30300, lr=8.12444e-05, gnorm=0.374, clip=0, loss_scale=128, train_wall=71, gb_free=14.5, wall=25551
2023-08-23 21:40:36 | INFO | train_inner | epoch 026:    858 / 1191 loss=1.805, trans_loss=4.638, nll_loss=1.769, w2v_ctc_loss=0.526, task_loss=2.327, contrastive_loss=0, total=6658.15, n_correct=4771.66, ppl=3.41, accuracy=71.666, wps=18819.2, ups=1.41, wpb=13316.3, bsz=452.6, num_updates=30400, lr=8.11107e-05, gnorm=0.378, clip=0, loss_scale=128, train_wall=70, gb_free=14.4, wall=25622
2023-08-23 21:41:48 | INFO | train_inner | epoch 026:    958 / 1191 loss=1.81, trans_loss=4.646, nll_loss=1.78, w2v_ctc_loss=0.529, task_loss=2.369, contrastive_loss=0, total=6721.34, n_correct=4804.52, ppl=3.43, accuracy=71.482, wps=18658.9, ups=1.39, wpb=13442.7, bsz=453, num_updates=30500, lr=8.09776e-05, gnorm=0.378, clip=0, loss_scale=128, train_wall=71, gb_free=12.4, wall=25694
2023-08-23 21:42:59 | INFO | train_inner | epoch 026:   1058 / 1191 loss=1.809, trans_loss=4.642, nll_loss=1.774, w2v_ctc_loss=0.529, task_loss=2.429, contrastive_loss=0, total=6671.8, n_correct=4771.6, ppl=3.42, accuracy=71.519, wps=18640.3, ups=1.4, wpb=13343.6, bsz=440.3, num_updates=30600, lr=8.08452e-05, gnorm=0.383, clip=0, loss_scale=128, train_wall=71, gb_free=13, wall=25765
2023-08-23 21:43:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-23 21:44:12 | INFO | train_inner | epoch 026:   1159 / 1191 loss=1.808, trans_loss=4.647, nll_loss=1.782, w2v_ctc_loss=0.53, task_loss=2.219, contrastive_loss=0, total=6788.04, n_correct=4851.2, ppl=3.44, accuracy=71.467, wps=18699.7, ups=1.38, wpb=13576.1, bsz=476.8, num_updates=30700, lr=8.07134e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=72, gb_free=13.4, wall=25838
2023-08-23 21:44:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:1')
2023-08-23 21:45:08 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.877 | trans_loss 5.183 | nll_loss 2.387 | w2v_ctc_loss 1.213 | task_loss 8.528 | contrastive_loss 0 | total 6138.43 | n_correct 4168.71 | ppl 5.23 | accuracy 67.912 | uer 16.45 | wer 18.282 | raw_wer 18.282 | bleu 27.49 | wps 1704.4 | wpb 6138.4 | bsz 201.1 | num_updates 30732 | best_bleu 27.72
2023-08-23 21:45:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30732 updates
2023-08-23 21:45:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4908.pt
2023-08-23 21:45:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4908.pt
2023-08-23 21:45:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4908.pt (epoch 26 @ 30732 updates, score 27.49) (writing took 7.7496351229492575 seconds)
2023-08-23 21:45:16 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-23 21:45:16 | INFO | train | epoch 026 | loss 1.804 | trans_loss 4.635 | nll_loss 1.766 | w2v_ctc_loss 0.526 | task_loss 2.347 | contrastive_loss 0 | total 6703.68 | n_correct 4807.42 | ppl 3.4 | accuracy 71.713 | wps 16950.5 | ups 1.26 | wpb 13407.4 | bsz 452 | num_updates 30732 | lr 8.06714e-05 | gnorm 0.378 | clip 0 | loss_scale 64 | train_wall 845 | gb_free 12.7 | wall 25902
2023-08-23 21:45:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 21:45:16 | INFO | fairseq.trainer | begin training epoch 27
2023-08-23 21:45:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 21:46:13 | INFO | train_inner | epoch 027:     68 / 1191 loss=1.799, trans_loss=4.625, nll_loss=1.752, w2v_ctc_loss=0.524, task_loss=2.353, contrastive_loss=0, total=6651.07, n_correct=4785.05, ppl=3.37, accuracy=71.944, wps=10971.5, ups=0.82, wpb=13302.1, bsz=445.1, num_updates=30800, lr=8.05823e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=71, gb_free=13.5, wall=25959
2023-08-23 21:47:25 | INFO | train_inner | epoch 027:    168 / 1191 loss=1.788, trans_loss=4.613, nll_loss=1.737, w2v_ctc_loss=0.51, task_loss=2.205, contrastive_loss=0, total=6787.32, n_correct=4901.58, ppl=3.33, accuracy=72.217, wps=18957.7, ups=1.4, wpb=13574.6, bsz=479.5, num_updates=30900, lr=8.04518e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=71, gb_free=13.2, wall=26031
2023-08-23 21:48:36 | INFO | train_inner | epoch 027:    268 / 1191 loss=1.791, trans_loss=4.617, nll_loss=1.743, w2v_ctc_loss=0.517, task_loss=2.161, contrastive_loss=0, total=6823.18, n_correct=4920.77, ppl=3.35, accuracy=72.118, wps=19106.8, ups=1.4, wpb=13646.4, bsz=480.4, num_updates=31000, lr=8.03219e-05, gnorm=0.37, clip=0, loss_scale=64, train_wall=71, gb_free=11.1, wall=26102
2023-08-23 21:49:48 | INFO | train_inner | epoch 027:    368 / 1191 loss=1.795, trans_loss=4.623, nll_loss=1.75, w2v_ctc_loss=0.515, task_loss=2.421, contrastive_loss=0, total=6624.26, n_correct=4772.85, ppl=3.36, accuracy=72.051, wps=18411.6, ups=1.39, wpb=13248.5, bsz=441.3, num_updates=31100, lr=8.01927e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=12.5, wall=26174
2023-08-23 21:51:00 | INFO | train_inner | epoch 027:    468 / 1191 loss=1.803, trans_loss=4.634, nll_loss=1.764, w2v_ctc_loss=0.526, task_loss=2.373, contrastive_loss=0, total=6666.4, n_correct=4782.49, ppl=3.4, accuracy=71.74, wps=18627, ups=1.4, wpb=13332.8, bsz=453.7, num_updates=31200, lr=8.00641e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=71, gb_free=14.2, wall=26246
2023-08-23 21:52:12 | INFO | train_inner | epoch 027:    568 / 1191 loss=1.799, trans_loss=4.627, nll_loss=1.756, w2v_ctc_loss=0.522, task_loss=2.365, contrastive_loss=0, total=6740.41, n_correct=4852.76, ppl=3.38, accuracy=71.995, wps=18740, ups=1.39, wpb=13480.8, bsz=450, num_updates=31300, lr=7.99361e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=26318
2023-08-23 21:53:22 | INFO | train_inner | epoch 027:    668 / 1191 loss=1.801, trans_loss=4.63, nll_loss=1.758, w2v_ctc_loss=0.521, task_loss=2.314, contrastive_loss=0, total=6747.68, n_correct=4846.61, ppl=3.38, accuracy=71.826, wps=19072.5, ups=1.41, wpb=13495.4, bsz=456.4, num_updates=31400, lr=7.98087e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=70, gb_free=11.6, wall=26389
2023-08-23 21:54:34 | INFO | train_inner | epoch 027:    768 / 1191 loss=1.799, trans_loss=4.63, nll_loss=1.759, w2v_ctc_loss=0.52, task_loss=2.394, contrastive_loss=0, total=6672.29, n_correct=4790.83, ppl=3.39, accuracy=71.802, wps=18701.9, ups=1.4, wpb=13344.6, bsz=450.2, num_updates=31500, lr=7.96819e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=11.7, wall=26460
2023-08-23 21:55:45 | INFO | train_inner | epoch 027:    868 / 1191 loss=1.81, trans_loss=4.64, nll_loss=1.771, w2v_ctc_loss=0.533, task_loss=2.579, contrastive_loss=0, total=6578.97, n_correct=4713.59, ppl=3.41, accuracy=71.646, wps=18414.2, ups=1.4, wpb=13157.9, bsz=422.4, num_updates=31600, lr=7.95557e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=71, gb_free=12.9, wall=26531
2023-08-23 21:56:58 | INFO | train_inner | epoch 027:    968 / 1191 loss=1.81, trans_loss=4.643, nll_loss=1.776, w2v_ctc_loss=0.528, task_loss=2.504, contrastive_loss=0, total=6667.85, n_correct=4771.07, ppl=3.42, accuracy=71.553, wps=18448.8, ups=1.38, wpb=13335.7, bsz=430.6, num_updates=31700, lr=7.94301e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=72, gb_free=13.6, wall=26604
2023-08-23 21:58:09 | INFO | train_inner | epoch 027:   1068 / 1191 loss=1.802, trans_loss=4.635, nll_loss=1.766, w2v_ctc_loss=0.522, task_loss=2.339, contrastive_loss=0, total=6657.56, n_correct=4779.58, ppl=3.4, accuracy=71.792, wps=18707.7, ups=1.4, wpb=13315.1, bsz=449.3, num_updates=31800, lr=7.93052e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=70, gb_free=13.1, wall=26675
2023-08-23 21:59:21 | INFO | train_inner | epoch 027:   1168 / 1191 loss=1.804, trans_loss=4.639, nll_loss=1.771, w2v_ctc_loss=0.522, task_loss=2.312, contrastive_loss=0, total=6728.11, n_correct=4821.87, ppl=3.41, accuracy=71.668, wps=18726.1, ups=1.39, wpb=13456.2, bsz=449.7, num_updates=31900, lr=7.91808e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=71, gb_free=15.4, wall=26747
2023-08-23 21:59:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 22:00:10 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.893 | trans_loss 5.181 | nll_loss 2.385 | w2v_ctc_loss 1.27 | task_loss 8.571 | contrastive_loss 0 | total 6138.43 | n_correct 4176.29 | ppl 5.22 | accuracy 68.035 | uer 16.26 | wer 17.973 | raw_wer 17.973 | bleu 27.61 | wps 1714.2 | wpb 6138.4 | bsz 201.1 | num_updates 31923 | best_bleu 27.72
2023-08-23 22:00:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 31923 updates
2023-08-23 22:00:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.6103.pt
2023-08-23 22:00:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.6103.pt
2023-08-23 22:00:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.6103.pt (epoch 27 @ 31923 updates, score 27.61) (writing took 7.242872129078023 seconds)
2023-08-23 22:00:18 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-23 22:00:18 | INFO | train | epoch 027 | loss 1.799 | trans_loss 4.629 | nll_loss 1.757 | w2v_ctc_loss 0.521 | task_loss 2.345 | contrastive_loss 0 | total 6703.69 | n_correct 4818.84 | ppl 3.38 | accuracy 71.883 | wps 17709 | ups 1.32 | wpb 13407.4 | bsz 452.1 | num_updates 31923 | lr 7.91522e-05 | gnorm 0.378 | clip 0 | loss_scale 64 | train_wall 845 | gb_free 13.5 | wall 26804
2023-08-23 22:00:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 22:00:18 | INFO | fairseq.trainer | begin training epoch 28
2023-08-23 22:00:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 22:01:21 | INFO | train_inner | epoch 028:     77 / 1191 loss=1.787, trans_loss=4.61, nll_loss=1.733, w2v_ctc_loss=0.51, task_loss=2.305, contrastive_loss=0, total=6703, n_correct=4846.42, ppl=3.33, accuracy=72.302, wps=11180.1, ups=0.83, wpb=13406, bsz=454.7, num_updates=32000, lr=7.90569e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=70, gb_free=13, wall=26867
2023-08-23 22:01:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 22:01:54 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.903 | trans_loss 5.191 | nll_loss 2.395 | w2v_ctc_loss 1.284 | task_loss 8.546 | contrastive_loss 0 | total 6138.43 | n_correct 4174.71 | ppl 5.26 | accuracy 68.009 | uer 16.498 | wer 18.304 | raw_wer 18.304 | bleu 27.77 | wps 1682.3 | wpb 6138.4 | bsz 201.1 | num_updates 32000 | best_bleu 27.77
2023-08-23 22:01:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 32000 updates
2023-08-23 22:01:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_28_32000.pt
2023-08-23 22:01:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_28_32000.pt
2023-08-23 22:02:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_28_32000.pt (epoch 28 @ 32000 updates, score 27.77) (writing took 15.202063600998372 seconds)
2023-08-23 22:03:20 | INFO | train_inner | epoch 028:    177 / 1191 loss=1.799, trans_loss=4.621, nll_loss=1.746, w2v_ctc_loss=0.526, task_loss=2.415, contrastive_loss=0, total=6685.83, n_correct=4818.7, ppl=3.35, accuracy=72.073, wps=11157.8, ups=0.83, wpb=13371.7, bsz=441, num_updates=32100, lr=7.89337e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=70, gb_free=13.9, wall=26986
2023-08-23 22:04:32 | INFO | train_inner | epoch 028:    277 / 1191 loss=1.792, trans_loss=4.619, nll_loss=1.744, w2v_ctc_loss=0.515, task_loss=2.313, contrastive_loss=0, total=6703.02, n_correct=4833.37, ppl=3.35, accuracy=72.107, wps=18691, ups=1.39, wpb=13406, bsz=457.6, num_updates=32200, lr=7.8811e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=12.7, wall=27058
2023-08-23 22:05:44 | INFO | train_inner | epoch 028:    377 / 1191 loss=1.791, trans_loss=4.616, nll_loss=1.741, w2v_ctc_loss=0.515, task_loss=2.231, contrastive_loss=0, total=6777.7, n_correct=4892.03, ppl=3.34, accuracy=72.178, wps=18899.5, ups=1.39, wpb=13555.4, bsz=470.3, num_updates=32300, lr=7.86889e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=71, gb_free=10.7, wall=27130
2023-08-23 22:06:56 | INFO | train_inner | epoch 028:    477 / 1191 loss=1.793, trans_loss=4.62, nll_loss=1.746, w2v_ctc_loss=0.517, task_loss=2.317, contrastive_loss=0, total=6773.66, n_correct=4887.61, ppl=3.35, accuracy=72.156, wps=18697.6, ups=1.38, wpb=13547.3, bsz=462, num_updates=32400, lr=7.85674e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=72, gb_free=13.4, wall=27202
2023-08-23 22:08:07 | INFO | train_inner | epoch 028:    577 / 1191 loss=1.791, trans_loss=4.621, nll_loss=1.747, w2v_ctc_loss=0.512, task_loss=2.333, contrastive_loss=0, total=6684.68, n_correct=4823.18, ppl=3.36, accuracy=72.153, wps=19018.9, ups=1.42, wpb=13369.4, bsz=452.9, num_updates=32500, lr=7.84465e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=70, gb_free=11.2, wall=27273
2023-08-23 22:09:18 | INFO | train_inner | epoch 028:    677 / 1191 loss=1.793, trans_loss=4.622, nll_loss=1.749, w2v_ctc_loss=0.511, task_loss=2.387, contrastive_loss=0, total=6695.28, n_correct=4825.18, ppl=3.36, accuracy=72.068, wps=18804.3, ups=1.4, wpb=13390.6, bsz=442.1, num_updates=32600, lr=7.8326e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=10.7, wall=27344
2023-08-23 22:10:29 | INFO | train_inner | epoch 028:    777 / 1191 loss=1.791, trans_loss=4.619, nll_loss=1.746, w2v_ctc_loss=0.515, task_loss=2.249, contrastive_loss=0, total=6751.72, n_correct=4870.62, ppl=3.35, accuracy=72.139, wps=18912.3, ups=1.4, wpb=13503.4, bsz=466.1, num_updates=32700, lr=7.82062e-05, gnorm=0.379, clip=0, loss_scale=128, train_wall=71, gb_free=14.4, wall=27415
2023-08-23 22:10:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-23 22:11:42 | INFO | train_inner | epoch 028:    878 / 1191 loss=1.8, trans_loss=4.631, nll_loss=1.761, w2v_ctc_loss=0.522, task_loss=2.435, contrastive_loss=0, total=6591, n_correct=4737.25, ppl=3.39, accuracy=71.875, wps=18212.8, ups=1.38, wpb=13182, bsz=441.7, num_updates=32800, lr=7.80869e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=72, gb_free=14.5, wall=27488
2023-08-23 22:12:53 | INFO | train_inner | epoch 028:    978 / 1191 loss=1.8, trans_loss=4.63, nll_loss=1.759, w2v_ctc_loss=0.521, task_loss=2.386, contrastive_loss=0, total=6691.97, n_correct=4810.36, ppl=3.38, accuracy=71.883, wps=18626.6, ups=1.39, wpb=13383.9, bsz=444, num_updates=32900, lr=7.79681e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=71, gb_free=14.2, wall=27560
2023-08-23 22:14:05 | INFO | train_inner | epoch 028:   1078 / 1191 loss=1.804, trans_loss=4.639, nll_loss=1.77, w2v_ctc_loss=0.519, task_loss=2.481, contrastive_loss=0, total=6671.15, n_correct=4782, ppl=3.41, accuracy=71.682, wps=18533.9, ups=1.39, wpb=13342.3, bsz=438.4, num_updates=33000, lr=7.78499e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=71, gb_free=8.5, wall=27632
2023-08-23 22:15:17 | INFO | train_inner | epoch 028:   1178 / 1191 loss=1.797, trans_loss=4.631, nll_loss=1.762, w2v_ctc_loss=0.514, task_loss=2.301, contrastive_loss=0, total=6726.74, n_correct=4835.29, ppl=3.39, accuracy=71.882, wps=18722.2, ups=1.39, wpb=13453.5, bsz=458.1, num_updates=33100, lr=7.77322e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=14.4, wall=27703
2023-08-23 22:15:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 22:16:00 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.886 | trans_loss 5.182 | nll_loss 2.385 | w2v_ctc_loss 1.245 | task_loss 8.507 | contrastive_loss 0 | total 6138.43 | n_correct 4175.86 | ppl 5.22 | accuracy 68.028 | uer 16.359 | wer 18.141 | raw_wer 18.141 | bleu 27.49 | wps 1678.8 | wpb 6138.4 | bsz 201.1 | num_updates 33113 | best_bleu 27.77
2023-08-23 22:16:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 33113 updates
2023-08-23 22:16:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4904.pt
2023-08-23 22:16:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4904.pt
2023-08-23 22:16:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.4904.pt (epoch 28 @ 33113 updates, score 27.49) (writing took 6.821959877968766 seconds)
2023-08-23 22:16:07 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-23 22:16:07 | INFO | train | epoch 028 | loss 1.795 | trans_loss 4.623 | nll_loss 1.75 | w2v_ctc_loss 0.517 | task_loss 2.345 | contrastive_loss 0 | total 6703.98 | n_correct 4829.75 | ppl 3.36 | accuracy 72.043 | wps 16801.4 | ups 1.25 | wpb 13408 | bsz 452.3 | num_updates 33113 | lr 7.77169e-05 | gnorm 0.379 | clip 0 | loss_scale 64 | train_wall 844 | gb_free 13.4 | wall 27753
2023-08-23 22:16:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 22:16:07 | INFO | fairseq.trainer | begin training epoch 29
2023-08-23 22:16:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 22:17:18 | INFO | train_inner | epoch 029:     87 / 1191 loss=1.78, trans_loss=4.603, nll_loss=1.724, w2v_ctc_loss=0.505, task_loss=2.183, contrastive_loss=0, total=6790.31, n_correct=4923.95, ppl=3.3, accuracy=72.514, wps=11260.1, ups=0.83, wpb=13580.6, bsz=472.3, num_updates=33200, lr=7.76151e-05, gnorm=0.373, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=27824
2023-08-23 22:18:29 | INFO | train_inner | epoch 029:    187 / 1191 loss=1.791, trans_loss=4.609, nll_loss=1.731, w2v_ctc_loss=0.515, task_loss=2.488, contrastive_loss=0, total=6625.86, n_correct=4790.75, ppl=3.32, accuracy=72.304, wps=18667.3, ups=1.41, wpb=13251.7, bsz=424.9, num_updates=33300, lr=7.74984e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=70, gb_free=12.5, wall=27895
2023-08-23 22:19:42 | INFO | train_inner | epoch 029:    287 / 1191 loss=1.785, trans_loss=4.613, nll_loss=1.737, w2v_ctc_loss=0.501, task_loss=2.302, contrastive_loss=0, total=6701.09, n_correct=4840.59, ppl=3.33, accuracy=72.236, wps=18365.4, ups=1.37, wpb=13402.2, bsz=462.3, num_updates=33400, lr=7.73823e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=72, gb_free=13.1, wall=27968
2023-08-23 22:20:54 | INFO | train_inner | epoch 029:    387 / 1191 loss=1.792, trans_loss=4.618, nll_loss=1.743, w2v_ctc_loss=0.515, task_loss=2.349, contrastive_loss=0, total=6735.14, n_correct=4857.3, ppl=3.35, accuracy=72.119, wps=18735.8, ups=1.39, wpb=13470.3, bsz=453, num_updates=33500, lr=7.72667e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=71, gb_free=10.1, wall=28040
2023-08-23 22:22:05 | INFO | train_inner | epoch 029:    487 / 1191 loss=1.79, trans_loss=4.614, nll_loss=1.738, w2v_ctc_loss=0.513, task_loss=2.279, contrastive_loss=0, total=6755.5, n_correct=4882.31, ppl=3.34, accuracy=72.272, wps=18861.3, ups=1.4, wpb=13511, bsz=458.8, num_updates=33600, lr=7.71517e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=14, wall=28111
2023-08-23 22:23:17 | INFO | train_inner | epoch 029:    587 / 1191 loss=1.795, trans_loss=4.618, nll_loss=1.743, w2v_ctc_loss=0.522, task_loss=2.43, contrastive_loss=0, total=6662.88, n_correct=4807.82, ppl=3.35, accuracy=72.158, wps=18736.8, ups=1.41, wpb=13325.8, bsz=439.7, num_updates=33700, lr=7.70371e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=70, gb_free=14.5, wall=28183
2023-08-23 22:24:28 | INFO | train_inner | epoch 029:    687 / 1191 loss=1.792, trans_loss=4.619, nll_loss=1.745, w2v_ctc_loss=0.515, task_loss=2.332, contrastive_loss=0, total=6704.85, n_correct=4834.76, ppl=3.35, accuracy=72.108, wps=18697, ups=1.39, wpb=13409.7, bsz=456.3, num_updates=33800, lr=7.69231e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=28254
2023-08-23 22:25:40 | INFO | train_inner | epoch 029:    787 / 1191 loss=1.789, trans_loss=4.615, nll_loss=1.741, w2v_ctc_loss=0.51, task_loss=2.352, contrastive_loss=0, total=6656.4, n_correct=4812.58, ppl=3.34, accuracy=72.3, wps=18649.1, ups=1.4, wpb=13312.8, bsz=444.8, num_updates=33900, lr=7.68095e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=14.2, wall=28326
2023-08-23 22:26:51 | INFO | train_inner | epoch 029:    887 / 1191 loss=1.805, trans_loss=4.631, nll_loss=1.76, w2v_ctc_loss=0.53, task_loss=2.524, contrastive_loss=0, total=6593.67, n_correct=4734.76, ppl=3.39, accuracy=71.808, wps=18373.9, ups=1.39, wpb=13187.3, bsz=429, num_updates=34000, lr=7.66965e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=71, gb_free=13.2, wall=28398
2023-08-23 22:26:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 22:27:24 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.889 | trans_loss 5.181 | nll_loss 2.387 | w2v_ctc_loss 1.259 | task_loss 8.535 | contrastive_loss 0 | total 6138.43 | n_correct 4172.57 | ppl 5.23 | accuracy 67.975 | uer 16.335 | wer 18.059 | raw_wer 18.059 | bleu 27.61 | wps 1756.6 | wpb 6138.4 | bsz 201.1 | num_updates 34000 | best_bleu 27.77
2023-08-23 22:27:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34000 updates
2023-08-23 22:27:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_29_34000.pt
2023-08-23 22:27:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_29_34000.pt
2023-08-23 22:27:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_29_34000.pt (epoch 29 @ 34000 updates, score 27.61) (writing took 7.231750742997974 seconds)
2023-08-23 22:28:43 | INFO | train_inner | epoch 029:    987 / 1191 loss=1.794, trans_loss=4.624, nll_loss=1.753, w2v_ctc_loss=0.516, task_loss=2.204, contrastive_loss=0, total=6789.29, n_correct=4886.8, ppl=3.37, accuracy=71.978, wps=12214.7, ups=0.9, wpb=13578.6, bsz=477, num_updates=34100, lr=7.6584e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=70, gb_free=12.8, wall=28509
2023-08-23 22:29:54 | INFO | train_inner | epoch 029:   1087 / 1191 loss=1.796, trans_loss=4.629, nll_loss=1.758, w2v_ctc_loss=0.513, task_loss=2.377, contrastive_loss=0, total=6725.17, n_correct=4842.64, ppl=3.38, accuracy=72.008, wps=18795.9, ups=1.4, wpb=13450.3, bsz=449.4, num_updates=34200, lr=7.64719e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=28580
2023-08-23 22:31:06 | INFO | train_inner | epoch 029:   1187 / 1191 loss=1.789, trans_loss=4.621, nll_loss=1.749, w2v_ctc_loss=0.509, task_loss=2.283, contrastive_loss=0, total=6733.11, n_correct=4860.5, ppl=3.36, accuracy=72.188, wps=18756.1, ups=1.39, wpb=13466.2, bsz=461.7, num_updates=34300, lr=7.63604e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=28652
2023-08-23 22:31:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 22:31:42 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.885 | trans_loss 5.185 | nll_loss 2.39 | w2v_ctc_loss 1.236 | task_loss 8.549 | contrastive_loss 0 | total 6138.43 | n_correct 4175.29 | ppl 5.24 | accuracy 68.019 | uer 16.476 | wer 18.308 | raw_wer 18.308 | bleu 27.49 | wps 1714.5 | wpb 6138.4 | bsz 201.1 | num_updates 34304 | best_bleu 27.77
2023-08-23 22:31:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34304 updates
2023-08-23 22:31:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-23 22:31:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-23 22:31:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 29 @ 34304 updates, score 27.49) (writing took 6.285119537962601 seconds)
2023-08-23 22:31:48 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-23 22:31:48 | INFO | train | epoch 029 | loss 1.791 | trans_loss 4.618 | nll_loss 1.744 | w2v_ctc_loss 0.513 | task_loss 2.342 | contrastive_loss 0 | total 6703.69 | n_correct 4837.85 | ppl 3.35 | accuracy 72.167 | wps 16971.8 | ups 1.27 | wpb 13407.4 | bsz 452.1 | num_updates 34304 | lr 7.63559e-05 | gnorm 0.379 | clip 0 | loss_scale 64 | train_wall 845 | gb_free 13.6 | wall 28694
2023-08-23 22:31:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 22:31:48 | INFO | fairseq.trainer | begin training epoch 30
2023-08-23 22:31:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 22:33:04 | INFO | train_inner | epoch 030:     96 / 1191 loss=1.776, trans_loss=4.598, nll_loss=1.718, w2v_ctc_loss=0.499, task_loss=2.138, contrastive_loss=0, total=6808.52, n_correct=4946.18, ppl=3.29, accuracy=72.647, wps=11497.3, ups=0.84, wpb=13617, bsz=474.4, num_updates=34400, lr=7.62493e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=70, gb_free=15.2, wall=28770
2023-08-23 22:34:16 | INFO | train_inner | epoch 030:    196 / 1191 loss=1.779, trans_loss=4.6, nll_loss=1.72, w2v_ctc_loss=0.503, task_loss=2.295, contrastive_loss=0, total=6703.69, n_correct=4868.52, ppl=3.29, accuracy=72.624, wps=18820.8, ups=1.4, wpb=13407.4, bsz=455.3, num_updates=34500, lr=7.61387e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=71, gb_free=14.5, wall=28842
2023-08-23 22:35:27 | INFO | train_inner | epoch 030:    296 / 1191 loss=1.778, trans_loss=4.597, nll_loss=1.717, w2v_ctc_loss=0.5, task_loss=2.268, contrastive_loss=0, total=6740.86, n_correct=4900.22, ppl=3.29, accuracy=72.694, wps=18959.8, ups=1.41, wpb=13481.7, bsz=458.9, num_updates=34600, lr=7.60286e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=71, gb_free=13, wall=28913
2023-08-23 22:36:39 | INFO | train_inner | epoch 030:    396 / 1191 loss=1.776, trans_loss=4.603, nll_loss=1.726, w2v_ctc_loss=0.499, task_loss=2.06, contrastive_loss=0, total=6910.15, n_correct=5012.34, ppl=3.31, accuracy=72.536, wps=19152.1, ups=1.39, wpb=13820.3, bsz=498.7, num_updates=34700, lr=7.5919e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=72, gb_free=10.2, wall=28985
2023-08-23 22:37:51 | INFO | train_inner | epoch 030:    496 / 1191 loss=1.791, trans_loss=4.615, nll_loss=1.739, w2v_ctc_loss=0.515, task_loss=2.521, contrastive_loss=0, total=6615.51, n_correct=4783.09, ppl=3.34, accuracy=72.301, wps=18453, ups=1.39, wpb=13231, bsz=437.4, num_updates=34800, lr=7.58098e-05, gnorm=0.385, clip=0, loss_scale=128, train_wall=71, gb_free=14.5, wall=29057
2023-08-23 22:39:02 | INFO | train_inner | epoch 030:    596 / 1191 loss=1.787, trans_loss=4.612, nll_loss=1.737, w2v_ctc_loss=0.506, task_loss=2.403, contrastive_loss=0, total=6651.2, n_correct=4807.22, ppl=3.33, accuracy=72.276, wps=18572.3, ups=1.4, wpb=13302.4, bsz=440.8, num_updates=34900, lr=7.57011e-05, gnorm=0.382, clip=0, loss_scale=128, train_wall=71, gb_free=12.1, wall=29128
2023-08-23 22:40:14 | INFO | train_inner | epoch 030:    696 / 1191 loss=1.792, trans_loss=4.613, nll_loss=1.737, w2v_ctc_loss=0.514, task_loss=2.526, contrastive_loss=0, total=6597.75, n_correct=4763.69, ppl=3.33, accuracy=72.202, wps=18446.1, ups=1.4, wpb=13195.5, bsz=426.8, num_updates=35000, lr=7.55929e-05, gnorm=0.388, clip=0, loss_scale=128, train_wall=71, gb_free=12.5, wall=29200
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:0')
2023-08-23 22:40:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-23 22:41:27 | INFO | train_inner | epoch 030:    797 / 1191 loss=1.796, trans_loss=4.621, nll_loss=1.747, w2v_ctc_loss=0.512, task_loss=2.634, contrastive_loss=0, total=6564.48, n_correct=4735.06, ppl=3.36, accuracy=72.132, wps=17932.2, ups=1.37, wpb=13129, bsz=419.6, num_updates=35100, lr=7.54851e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=73, gb_free=14.6, wall=29273
2023-08-23 22:42:38 | INFO | train_inner | epoch 030:    897 / 1191 loss=1.788, trans_loss=4.614, nll_loss=1.739, w2v_ctc_loss=0.507, task_loss=2.327, contrastive_loss=0, total=6692.24, n_correct=4837.34, ppl=3.34, accuracy=72.283, wps=18786.4, ups=1.4, wpb=13384.5, bsz=453, num_updates=35200, lr=7.53778e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=12.8, wall=29344
2023-08-23 22:43:50 | INFO | train_inner | epoch 030:    997 / 1191 loss=1.799, trans_loss=4.629, nll_loss=1.758, w2v_ctc_loss=0.52, task_loss=2.484, contrastive_loss=0, total=6660.61, n_correct=4793.19, ppl=3.38, accuracy=71.963, wps=18584.2, ups=1.4, wpb=13321.2, bsz=440, num_updates=35300, lr=7.5271e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=71, gb_free=11.1, wall=29416
2023-08-23 22:45:02 | INFO | train_inner | epoch 030:   1097 / 1191 loss=1.786, trans_loss=4.614, nll_loss=1.74, w2v_ctc_loss=0.509, task_loss=2.229, contrastive_loss=0, total=6815.19, n_correct=4935.3, ppl=3.34, accuracy=72.416, wps=18893.7, ups=1.39, wpb=13630.4, bsz=469.2, num_updates=35400, lr=7.51646e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=72, gb_free=13.4, wall=29488
2023-08-23 22:46:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:5')
2023-08-23 22:46:42 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.882 | trans_loss 5.175 | nll_loss 2.378 | w2v_ctc_loss 1.248 | task_loss 8.556 | contrastive_loss 0 | total 6138.43 | n_correct 4184.14 | ppl 5.2 | accuracy 68.163 | uer 16.38 | wer 18.155 | raw_wer 18.155 | bleu 28.26 | wps 1767.1 | wpb 6138.4 | bsz 201.1 | num_updates 35494 | best_bleu 28.26
2023-08-23 22:46:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 35494 updates
2023-08-23 22:46:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 22:46:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt
2023-08-23 22:46:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_best.pt (epoch 30 @ 35494 updates, score 28.26) (writing took 11.06834981997963 seconds)
2023-08-23 22:46:53 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-23 22:46:53 | INFO | train | epoch 030 | loss 1.786 | trans_loss 4.612 | nll_loss 1.736 | w2v_ctc_loss 0.507 | task_loss 2.345 | contrastive_loss 0 | total 6702.24 | n_correct 4849.22 | ppl 3.33 | accuracy 72.352 | wps 17626.6 | ups 1.31 | wpb 13404.5 | bsz 451.7 | num_updates 35494 | lr 7.5065e-05 | gnorm 0.38 | clip 0 | loss_scale 64 | train_wall 845 | gb_free 14.6 | wall 29599
2023-08-23 22:46:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 22:46:53 | INFO | fairseq.trainer | begin training epoch 31
2023-08-23 22:46:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 22:47:05 | INFO | train_inner | epoch 031:      6 / 1191 loss=1.787, trans_loss=4.623, nll_loss=1.751, w2v_ctc_loss=0.504, task_loss=2.289, contrastive_loss=0, total=6692.99, n_correct=4831.34, ppl=3.37, accuracy=72.185, wps=10860.5, ups=0.81, wpb=13386, bsz=454.1, num_updates=35500, lr=7.50587e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=70, gb_free=14.6, wall=29611
2023-08-23 22:48:17 | INFO | train_inner | epoch 031:    106 / 1191 loss=1.781, trans_loss=4.595, nll_loss=1.713, w2v_ctc_loss=0.502, task_loss=2.518, contrastive_loss=0, total=6616.95, n_correct=4810.58, ppl=3.28, accuracy=72.701, wps=18492.4, ups=1.4, wpb=13233.9, bsz=423.8, num_updates=35600, lr=7.49532e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=71, gb_free=13.3, wall=29683
2023-08-23 22:49:29 | INFO | train_inner | epoch 031:    206 / 1191 loss=1.78, trans_loss=4.598, nll_loss=1.717, w2v_ctc_loss=0.506, task_loss=2.342, contrastive_loss=0, total=6698.27, n_correct=4867.97, ppl=3.29, accuracy=72.675, wps=18609.3, ups=1.39, wpb=13396.5, bsz=453.1, num_updates=35700, lr=7.48481e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=13, wall=29755
2023-08-23 22:50:40 | INFO | train_inner | epoch 031:    306 / 1191 loss=1.787, trans_loss=4.604, nll_loss=1.725, w2v_ctc_loss=0.511, task_loss=2.581, contrastive_loss=0, total=6555.34, n_correct=4752.77, ppl=3.31, accuracy=72.502, wps=18404.5, ups=1.4, wpb=13110.7, bsz=426.2, num_updates=35800, lr=7.47435e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=71, gb_free=13.2, wall=29826
2023-08-23 22:51:52 | INFO | train_inner | epoch 031:    406 / 1191 loss=1.78, trans_loss=4.604, nll_loss=1.726, w2v_ctc_loss=0.501, task_loss=2.328, contrastive_loss=0, total=6737.59, n_correct=4886.89, ppl=3.31, accuracy=72.532, wps=18880.5, ups=1.4, wpb=13475.2, bsz=456.5, num_updates=35900, lr=7.46393e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=71, gb_free=13.5, wall=29898
2023-08-23 22:53:03 | INFO | train_inner | epoch 031:    506 / 1191 loss=1.789, trans_loss=4.613, nll_loss=1.737, w2v_ctc_loss=0.508, task_loss=2.508, contrastive_loss=0, total=6681.97, n_correct=4833.88, ppl=3.33, accuracy=72.342, wps=18697, ups=1.4, wpb=13363.9, bsz=429.8, num_updates=36000, lr=7.45356e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=13.6, wall=29969
2023-08-23 22:53:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 22:53:36 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.895 | trans_loss 5.185 | nll_loss 2.388 | w2v_ctc_loss 1.27 | task_loss 8.556 | contrastive_loss 0 | total 6138.43 | n_correct 4177.71 | ppl 5.23 | accuracy 68.058 | uer 16.458 | wer 18.193 | raw_wer 18.193 | bleu 27.37 | wps 1702.3 | wpb 6138.4 | bsz 201.1 | num_updates 36000 | best_bleu 28.26
2023-08-23 22:53:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36000 updates
2023-08-23 22:53:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_31_36000.pt
2023-08-23 22:53:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_31_36000.pt
2023-08-23 22:53:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_31_36000.pt (epoch 31 @ 36000 updates, score 27.37) (writing took 6.473222402040847 seconds)
2023-08-23 22:54:54 | INFO | train_inner | epoch 031:    606 / 1191 loss=1.782, trans_loss=4.607, nll_loss=1.73, w2v_ctc_loss=0.503, task_loss=2.303, contrastive_loss=0, total=6693.89, n_correct=4847.94, ppl=3.32, accuracy=72.423, wps=12027, ups=0.9, wpb=13387.8, bsz=458.3, num_updates=36100, lr=7.44323e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=71, gb_free=14.4, wall=30080
2023-08-23 22:56:06 | INFO | train_inner | epoch 031:    706 / 1191 loss=1.78, trans_loss=4.601, nll_loss=1.723, w2v_ctc_loss=0.509, task_loss=2.094, contrastive_loss=0, total=6873.8, n_correct=4990.05, ppl=3.3, accuracy=72.595, wps=19153.1, ups=1.39, wpb=13747.6, bsz=490.6, num_updates=36200, lr=7.43294e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=11.8, wall=30152
2023-08-23 22:57:18 | INFO | train_inner | epoch 031:    806 / 1191 loss=1.779, trans_loss=4.609, nll_loss=1.733, w2v_ctc_loss=0.5, task_loss=2.216, contrastive_loss=0, total=6774.44, n_correct=4910.28, ppl=3.33, accuracy=72.482, wps=18852.3, ups=1.39, wpb=13548.9, bsz=470.8, num_updates=36300, lr=7.4227e-05, gnorm=0.376, clip=0, loss_scale=64, train_wall=71, gb_free=12.9, wall=30224
2023-08-23 22:58:30 | INFO | train_inner | epoch 031:    906 / 1191 loss=1.789, trans_loss=4.617, nll_loss=1.743, w2v_ctc_loss=0.509, task_loss=2.435, contrastive_loss=0, total=6620.12, n_correct=4784.56, ppl=3.35, accuracy=72.273, wps=18496.3, ups=1.4, wpb=13240.2, bsz=441.2, num_updates=36400, lr=7.41249e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=71, gb_free=13.5, wall=30296
2023-08-23 22:59:41 | INFO | train_inner | epoch 031:   1006 / 1191 loss=1.787, trans_loss=4.61, nll_loss=1.735, w2v_ctc_loss=0.511, task_loss=2.361, contrastive_loss=0, total=6669.42, n_correct=4822.93, ppl=3.33, accuracy=72.314, wps=18642.3, ups=1.4, wpb=13338.8, bsz=448.3, num_updates=36500, lr=7.40233e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=71, gb_free=14.3, wall=30367
2023-08-23 23:00:52 | INFO | train_inner | epoch 031:   1106 / 1191 loss=1.774, trans_loss=4.604, nll_loss=1.727, w2v_ctc_loss=0.494, task_loss=2.074, contrastive_loss=0, total=6900.54, n_correct=5010.98, ppl=3.31, accuracy=72.617, wps=19407.2, ups=1.41, wpb=13801.1, bsz=490.1, num_updates=36600, lr=7.39221e-05, gnorm=0.371, clip=0, loss_scale=64, train_wall=70, gb_free=12.5, wall=30438
2023-08-23 23:01:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 23:02:26 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.875 | trans_loss 5.18 | nll_loss 2.382 | w2v_ctc_loss 1.213 | task_loss 8.525 | contrastive_loss 0 | total 6138.43 | n_correct 4175.86 | ppl 5.21 | accuracy 68.028 | uer 16.276 | wer 18.103 | raw_wer 18.103 | bleu 27.47 | wps 1743.4 | wpb 6138.4 | bsz 201.1 | num_updates 36685 | best_bleu 28.26
2023-08-23 23:02:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36685 updates
2023-08-23 23:02:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-23 23:02:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-23 23:02:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 31 @ 36685 updates, score 27.47) (writing took 6.8001185269095 seconds)
2023-08-23 23:02:32 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-23 23:02:32 | INFO | train | epoch 031 | loss 1.783 | trans_loss 4.606 | nll_loss 1.729 | w2v_ctc_loss 0.505 | task_loss 2.343 | contrastive_loss 0 | total 6703.69 | n_correct 4858.89 | ppl 3.31 | accuracy 72.481 | wps 16999.5 | ups 1.27 | wpb 13407.4 | bsz 452.1 | num_updates 36685 | lr 7.38364e-05 | gnorm 0.381 | clip 0 | loss_scale 64 | train_wall 844 | gb_free 10.3 | wall 30539
2023-08-23 23:02:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 23:02:33 | INFO | fairseq.trainer | begin training epoch 32
2023-08-23 23:02:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 23:02:51 | INFO | train_inner | epoch 032:     15 / 1191 loss=1.787, trans_loss=4.61, nll_loss=1.734, w2v_ctc_loss=0.51, task_loss=2.392, contrastive_loss=0, total=6628.84, n_correct=4794.61, ppl=3.33, accuracy=72.33, wps=11149.5, ups=0.84, wpb=13257.7, bsz=441.6, num_updates=36700, lr=7.38213e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=70, gb_free=13.4, wall=30557
2023-08-23 23:04:02 | INFO | train_inner | epoch 032:    115 / 1191 loss=1.769, trans_loss=4.583, nll_loss=1.699, w2v_ctc_loss=0.492, task_loss=2.308, contrastive_loss=0, total=6730.61, n_correct=4916.17, ppl=3.25, accuracy=73.042, wps=18888, ups=1.4, wpb=13461.2, bsz=452.4, num_updates=36800, lr=7.3721e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=71, gb_free=4.4, wall=30629
2023-08-23 23:05:14 | INFO | train_inner | epoch 032:    215 / 1191 loss=1.773, trans_loss=4.595, nll_loss=1.715, w2v_ctc_loss=0.494, task_loss=2.218, contrastive_loss=0, total=6790.87, n_correct=4939.41, ppl=3.28, accuracy=72.736, wps=19011.7, ups=1.4, wpb=13581.7, bsz=468.9, num_updates=36900, lr=7.3621e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=71, gb_free=13.8, wall=30700
2023-08-23 23:06:26 | INFO | train_inner | epoch 032:    315 / 1191 loss=1.777, trans_loss=4.596, nll_loss=1.715, w2v_ctc_loss=0.5, task_loss=2.388, contrastive_loss=0, total=6687.07, n_correct=4864.36, ppl=3.28, accuracy=72.743, wps=18569.8, ups=1.39, wpb=13374.1, bsz=450.2, num_updates=37000, lr=7.35215e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=71, gb_free=12, wall=30772
2023-08-23 23:07:38 | INFO | train_inner | epoch 032:    415 / 1191 loss=1.776, trans_loss=4.592, nll_loss=1.711, w2v_ctc_loss=0.501, task_loss=2.323, contrastive_loss=0, total=6742.26, n_correct=4906.04, ppl=3.27, accuracy=72.766, wps=18782.8, ups=1.39, wpb=13484.5, bsz=452.3, num_updates=37100, lr=7.34223e-05, gnorm=0.378, clip=0, loss_scale=128, train_wall=71, gb_free=5.3, wall=30844
2023-08-23 23:08:49 | INFO | train_inner | epoch 032:    515 / 1191 loss=1.777, trans_loss=4.6, nll_loss=1.722, w2v_ctc_loss=0.495, task_loss=2.36, contrastive_loss=0, total=6705.94, n_correct=4874.68, ppl=3.3, accuracy=72.692, wps=18701.5, ups=1.39, wpb=13411.9, bsz=446.8, num_updates=37200, lr=7.33236e-05, gnorm=0.38, clip=0, loss_scale=128, train_wall=71, gb_free=14.3, wall=30915
2023-08-23 23:10:01 | INFO | train_inner | epoch 032:    615 / 1191 loss=1.778, trans_loss=4.599, nll_loss=1.72, w2v_ctc_loss=0.502, task_loss=2.338, contrastive_loss=0, total=6718.45, n_correct=4884.57, ppl=3.29, accuracy=72.704, wps=18744.2, ups=1.39, wpb=13436.9, bsz=453.9, num_updates=37300, lr=7.32252e-05, gnorm=0.379, clip=0, loss_scale=128, train_wall=71, gb_free=13.2, wall=30987
2023-08-23 23:11:13 | INFO | train_inner | epoch 032:    715 / 1191 loss=1.783, trans_loss=4.604, nll_loss=1.726, w2v_ctc_loss=0.505, task_loss=2.423, contrastive_loss=0, total=6731.13, n_correct=4883.91, ppl=3.31, accuracy=72.557, wps=18607.8, ups=1.38, wpb=13462.3, bsz=445.4, num_updates=37400, lr=7.31272e-05, gnorm=0.387, clip=0, loss_scale=128, train_wall=72, gb_free=14.9, wall=31060
2023-08-23 23:12:25 | INFO | train_inner | epoch 032:    815 / 1191 loss=1.784, trans_loss=4.606, nll_loss=1.73, w2v_ctc_loss=0.504, task_loss=2.418, contrastive_loss=0, total=6681.74, n_correct=4839.41, ppl=3.32, accuracy=72.427, wps=18553.9, ups=1.39, wpb=13363.5, bsz=445.9, num_updates=37500, lr=7.30297e-05, gnorm=0.385, clip=0, loss_scale=128, train_wall=71, gb_free=14.8, wall=31132
2023-08-23 23:13:37 | INFO | train_inner | epoch 032:    915 / 1191 loss=1.788, trans_loss=4.616, nll_loss=1.743, w2v_ctc_loss=0.506, task_loss=2.42, contrastive_loss=0, total=6689.38, n_correct=4835.81, ppl=3.35, accuracy=72.291, wps=18617.3, ups=1.39, wpb=13378.8, bsz=447.5, num_updates=37600, lr=7.29325e-05, gnorm=0.384, clip=0, loss_scale=128, train_wall=71, gb_free=13.1, wall=31203
2023-08-23 23:14:48 | INFO | train_inner | epoch 032:   1015 / 1191 loss=1.776, trans_loss=4.601, nll_loss=1.724, w2v_ctc_loss=0.499, task_loss=2.219, contrastive_loss=0, total=6692.18, n_correct=4863.33, ppl=3.3, accuracy=72.672, wps=18859.2, ups=1.41, wpb=13384.4, bsz=463.3, num_updates=37700, lr=7.28357e-05, gnorm=0.38, clip=0, loss_scale=128, train_wall=70, gb_free=14.6, wall=31274
2023-08-23 23:15:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-23 23:16:00 | INFO | train_inner | epoch 032:   1116 / 1191 loss=1.791, trans_loss=4.614, nll_loss=1.738, w2v_ctc_loss=0.513, task_loss=2.631, contrastive_loss=0, total=6530.04, n_correct=4720.23, ppl=3.34, accuracy=72.285, wps=18307.2, ups=1.4, wpb=13060.1, bsz=414.3, num_updates=37800, lr=7.27393e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=71, gb_free=13.7, wall=31346
2023-08-23 23:16:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 23:17:27 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.872 | trans_loss 5.177 | nll_loss 2.382 | w2v_ctc_loss 1.209 | task_loss 8.519 | contrastive_loss 0 | total 6138.43 | n_correct 4181.14 | ppl 5.21 | accuracy 68.114 | uer 16.174 | wer 17.962 | raw_wer 17.962 | bleu 27.43 | wps 1686.4 | wpb 6138.4 | bsz 201.1 | num_updates 37875 | best_bleu 28.26
2023-08-23 23:17:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 37875 updates
2023-08-23 23:17:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-23 23:17:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-23 23:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 32 @ 37875 updates, score 27.43) (writing took 5.992624587961473 seconds)
2023-08-23 23:17:33 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-23 23:17:33 | INFO | train | epoch 032 | loss 1.779 | trans_loss 4.601 | nll_loss 1.723 | w2v_ctc_loss 0.5 | task_loss 2.345 | contrastive_loss 0 | total 6703.33 | n_correct 4867.74 | ppl 3.3 | accuracy 72.617 | wps 17718.7 | ups 1.32 | wpb 13406.7 | bsz 452.1 | num_updates 37875 | lr 7.26672e-05 | gnorm 0.382 | clip 0 | loss_scale 64 | train_wall 845 | gb_free 11.5 | wall 31439
2023-08-23 23:17:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 23:17:33 | INFO | fairseq.trainer | begin training epoch 33
2023-08-23 23:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 23:17:59 | INFO | train_inner | epoch 033:     25 / 1191 loss=1.772, trans_loss=4.604, nll_loss=1.728, w2v_ctc_loss=0.491, task_loss=2.083, contrastive_loss=0, total=6775.55, n_correct=4919.37, ppl=3.31, accuracy=72.605, wps=11380.9, ups=0.84, wpb=13551.1, bsz=496.1, num_updates=37900, lr=7.26433e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=71, gb_free=12.4, wall=31465
2023-08-23 23:19:11 | INFO | train_inner | epoch 033:    125 / 1191 loss=1.767, trans_loss=4.585, nll_loss=1.701, w2v_ctc_loss=0.486, task_loss=2.304, contrastive_loss=0, total=6788.77, n_correct=4955.9, ppl=3.25, accuracy=73.001, wps=18848.9, ups=1.39, wpb=13577.5, bsz=459.2, num_updates=38000, lr=7.25476e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=13.2, wall=31537
2023-08-23 23:19:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 23:19:44 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.885 | trans_loss 5.183 | nll_loss 2.387 | w2v_ctc_loss 1.24 | task_loss 8.617 | contrastive_loss 0 | total 6138.43 | n_correct 4183.14 | ppl 5.23 | accuracy 68.147 | uer 16.249 | wer 18.062 | raw_wer 18.062 | bleu 27.57 | wps 1741.6 | wpb 6138.4 | bsz 201.1 | num_updates 38000 | best_bleu 28.26
2023-08-23 23:19:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 38000 updates
2023-08-23 23:19:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_33_38000.pt
2023-08-23 23:19:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_33_38000.pt
2023-08-23 23:19:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_33_38000.pt (epoch 33 @ 38000 updates, score 27.57) (writing took 6.659543575020507 seconds)
2023-08-23 23:21:02 | INFO | train_inner | epoch 033:    225 / 1191 loss=1.773, trans_loss=4.589, nll_loss=1.707, w2v_ctc_loss=0.496, task_loss=2.33, contrastive_loss=0, total=6688.74, n_correct=4872.06, ppl=3.26, accuracy=72.84, wps=12052.3, ups=0.9, wpb=13377.5, bsz=451.8, num_updates=38100, lr=7.24524e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=70, gb_free=8.7, wall=31648
2023-08-23 23:22:13 | INFO | train_inner | epoch 033:    325 / 1191 loss=1.777, trans_loss=4.592, nll_loss=1.71, w2v_ctc_loss=0.499, task_loss=2.499, contrastive_loss=0, total=6608.81, n_correct=4807.21, ppl=3.27, accuracy=72.739, wps=18495.9, ups=1.4, wpb=13217.6, bsz=432.5, num_updates=38200, lr=7.23575e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=71, gb_free=12.8, wall=31719
2023-08-23 23:23:24 | INFO | train_inner | epoch 033:    425 / 1191 loss=1.777, trans_loss=4.595, nll_loss=1.714, w2v_ctc_loss=0.499, task_loss=2.383, contrastive_loss=0, total=6643.95, n_correct=4835.95, ppl=3.28, accuracy=72.787, wps=18835.2, ups=1.42, wpb=13287.9, bsz=440.4, num_updates=38300, lr=7.22629e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=70, gb_free=11.9, wall=31790
2023-08-23 23:24:35 | INFO | train_inner | epoch 033:    525 / 1191 loss=1.775, trans_loss=4.595, nll_loss=1.714, w2v_ctc_loss=0.494, task_loss=2.392, contrastive_loss=0, total=6665.13, n_correct=4846.55, ppl=3.28, accuracy=72.715, wps=18752.6, ups=1.41, wpb=13330.3, bsz=443.4, num_updates=38400, lr=7.21688e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=31861
2023-08-23 23:25:47 | INFO | train_inner | epoch 033:    625 / 1191 loss=1.772, trans_loss=4.591, nll_loss=1.71, w2v_ctc_loss=0.499, task_loss=2.224, contrastive_loss=0, total=6748.12, n_correct=4915.27, ppl=3.27, accuracy=72.839, wps=18688.2, ups=1.38, wpb=13496.2, bsz=472.6, num_updates=38500, lr=7.2075e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=72, gb_free=12.8, wall=31933
2023-08-23 23:26:59 | INFO | train_inner | epoch 033:    725 / 1191 loss=1.778, trans_loss=4.599, nll_loss=1.719, w2v_ctc_loss=0.498, task_loss=2.431, contrastive_loss=0, total=6660.13, n_correct=4842.04, ppl=3.29, accuracy=72.702, wps=18547.9, ups=1.39, wpb=13320.3, bsz=436.6, num_updates=38600, lr=7.19816e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=13.9, wall=32005
2023-08-23 23:28:10 | INFO | train_inner | epoch 033:    825 / 1191 loss=1.771, trans_loss=4.594, nll_loss=1.715, w2v_ctc_loss=0.491, task_loss=2.238, contrastive_loss=0, total=6765.78, n_correct=4927.94, ppl=3.28, accuracy=72.836, wps=19010.3, ups=1.4, wpb=13531.6, bsz=463.7, num_updates=38700, lr=7.18885e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=32076
2023-08-23 23:29:23 | INFO | train_inner | epoch 033:    925 / 1191 loss=1.784, trans_loss=4.61, nll_loss=1.735, w2v_ctc_loss=0.503, task_loss=2.432, contrastive_loss=0, total=6705.91, n_correct=4854.32, ppl=3.33, accuracy=72.389, wps=18519.2, ups=1.38, wpb=13411.8, bsz=447.3, num_updates=38800, lr=7.17958e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=72, gb_free=13.3, wall=32149
2023-08-23 23:30:34 | INFO | train_inner | epoch 033:   1025 / 1191 loss=1.78, trans_loss=4.606, nll_loss=1.729, w2v_ctc_loss=0.498, task_loss=2.326, contrastive_loss=0, total=6728.6, n_correct=4879.23, ppl=3.31, accuracy=72.515, wps=18792.2, ups=1.4, wpb=13457.2, bsz=454.7, num_updates=38900, lr=7.17035e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=32220
2023-08-23 23:31:47 | INFO | train_inner | epoch 033:   1125 / 1191 loss=1.783, trans_loss=4.607, nll_loss=1.73, w2v_ctc_loss=0.509, task_loss=2.32, contrastive_loss=0, total=6754.07, n_correct=4896.26, ppl=3.32, accuracy=72.493, wps=18643.4, ups=1.38, wpb=13508.1, bsz=461, num_updates=39000, lr=7.16115e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=72, gb_free=7.2, wall=32293
2023-08-23 23:32:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 23:33:07 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.887 | trans_loss 5.179 | nll_loss 2.383 | w2v_ctc_loss 1.256 | task_loss 8.526 | contrastive_loss 0 | total 6138.43 | n_correct 4181.29 | ppl 5.22 | accuracy 68.117 | uer 16.204 | wer 18.1 | raw_wer 18.1 | bleu 27.57 | wps 1753.6 | wpb 6138.4 | bsz 201.1 | num_updates 39066 | best_bleu 28.26
2023-08-23 23:33:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 39066 updates
2023-08-23 23:33:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.5703.pt
2023-08-23 23:33:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.5703.pt
2023-08-23 23:33:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.5703.pt (epoch 33 @ 39066 updates, score 27.57) (writing took 6.988554297015071 seconds)
2023-08-23 23:33:14 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-23 23:33:14 | INFO | train | epoch 033 | loss 1.776 | trans_loss 4.597 | nll_loss 1.717 | w2v_ctc_loss 0.497 | task_loss 2.344 | contrastive_loss 0 | total 6703.69 | n_correct 4874.66 | ppl 3.29 | accuracy 72.716 | wps 16968.1 | ups 1.27 | wpb 13407.4 | bsz 452.1 | num_updates 39066 | lr 7.1551e-05 | gnorm 0.383 | clip 0 | loss_scale 64 | train_wall 846 | gb_free 10.7 | wall 32380
2023-08-23 23:33:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 23:33:14 | INFO | fairseq.trainer | begin training epoch 34
2023-08-23 23:33:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 23:33:46 | INFO | train_inner | epoch 034:     34 / 1191 loss=1.773, trans_loss=4.597, nll_loss=1.718, w2v_ctc_loss=0.496, task_loss=2.19, contrastive_loss=0, total=6745.71, n_correct=4907.15, ppl=3.29, accuracy=72.745, wps=11344.2, ups=0.84, wpb=13491.4, bsz=477.3, num_updates=39100, lr=7.15199e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=70, gb_free=14.6, wall=32412
2023-08-23 23:34:57 | INFO | train_inner | epoch 034:    134 / 1191 loss=1.762, trans_loss=4.578, nll_loss=1.692, w2v_ctc_loss=0.483, task_loss=2.267, contrastive_loss=0, total=6747.97, n_correct=4937.2, ppl=3.23, accuracy=73.166, wps=18855.6, ups=1.4, wpb=13495.9, bsz=463.4, num_updates=39200, lr=7.14286e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=71, gb_free=13.6, wall=32483
2023-08-23 23:36:09 | INFO | train_inner | epoch 034:    234 / 1191 loss=1.771, trans_loss=4.583, nll_loss=1.699, w2v_ctc_loss=0.497, task_loss=2.46, contrastive_loss=0, total=6623.05, n_correct=4835.99, ppl=3.25, accuracy=73.018, wps=18463.6, ups=1.39, wpb=13246.1, bsz=441.6, num_updates=39300, lr=7.13376e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=71, gb_free=12.7, wall=32555
2023-08-23 23:37:21 | INFO | train_inner | epoch 034:    334 / 1191 loss=1.773, trans_loss=4.59, nll_loss=1.708, w2v_ctc_loss=0.496, task_loss=2.502, contrastive_loss=0, total=6615.91, n_correct=4823.16, ppl=3.27, accuracy=72.902, wps=18378.3, ups=1.39, wpb=13231.8, bsz=433.1, num_updates=39400, lr=7.1247e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=32627
2023-08-23 23:38:33 | INFO | train_inner | epoch 034:    434 / 1191 loss=1.77, trans_loss=4.586, nll_loss=1.703, w2v_ctc_loss=0.49, task_loss=2.346, contrastive_loss=0, total=6747.26, n_correct=4922.31, ppl=3.26, accuracy=72.953, wps=18810.6, ups=1.39, wpb=13494.5, bsz=447.3, num_updates=39500, lr=7.11568e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=71, gb_free=13, wall=32699
2023-08-23 23:39:44 | INFO | train_inner | epoch 034:    534 / 1191 loss=1.774, trans_loss=4.596, nll_loss=1.717, w2v_ctc_loss=0.495, task_loss=2.371, contrastive_loss=0, total=6718.89, n_correct=4890.86, ppl=3.29, accuracy=72.793, wps=18781.6, ups=1.4, wpb=13437.8, bsz=450.5, num_updates=39600, lr=7.10669e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=13.9, wall=32770
2023-08-23 23:40:55 | INFO | train_inner | epoch 034:    634 / 1191 loss=1.778, trans_loss=4.596, nll_loss=1.716, w2v_ctc_loss=0.5, task_loss=2.409, contrastive_loss=0, total=6641.07, n_correct=4826.15, ppl=3.28, accuracy=72.671, wps=18718, ups=1.41, wpb=13282.1, bsz=448, num_updates=39700, lr=7.09773e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=70, gb_free=14.5, wall=32841
2023-08-23 23:42:06 | INFO | train_inner | epoch 034:    734 / 1191 loss=1.771, trans_loss=4.589, nll_loss=1.708, w2v_ctc_loss=0.495, task_loss=2.307, contrastive_loss=0, total=6657.04, n_correct=4852.37, ppl=3.27, accuracy=72.891, wps=18763.1, ups=1.41, wpb=13314.1, bsz=451.3, num_updates=39800, lr=7.08881e-05, gnorm=0.386, clip=0, loss_scale=128, train_wall=70, gb_free=14, wall=32912
2023-08-23 23:42:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-23 23:43:19 | INFO | train_inner | epoch 034:    835 / 1191 loss=1.775, trans_loss=4.596, nll_loss=1.716, w2v_ctc_loss=0.497, task_loss=2.48, contrastive_loss=0, total=6624.3, n_correct=4823.6, ppl=3.29, accuracy=72.817, wps=18270, ups=1.38, wpb=13248.6, bsz=438.6, num_updates=39900, lr=7.07992e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=72, gb_free=14.2, wall=32985
2023-08-23 23:44:30 | INFO | train_inner | epoch 034:    935 / 1191 loss=1.778, trans_loss=4.596, nll_loss=1.716, w2v_ctc_loss=0.5, task_loss=2.464, contrastive_loss=0, total=6687.66, n_correct=4862.76, ppl=3.28, accuracy=72.712, wps=18710.3, ups=1.4, wpb=13375.3, bsz=432.1, num_updates=40000, lr=7.07107e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=71, gb_free=13.9, wall=33056
2023-08-23 23:44:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-23 23:45:03 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.898 | trans_loss 5.188 | nll_loss 2.39 | w2v_ctc_loss 1.272 | task_loss 8.558 | contrastive_loss 0 | total 6138.43 | n_correct 4182.43 | ppl 5.24 | accuracy 68.135 | uer 16.393 | wer 18.271 | raw_wer 18.271 | bleu 27.45 | wps 1698.1 | wpb 6138.4 | bsz 201.1 | num_updates 40000 | best_bleu 28.26
2023-08-23 23:45:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40000 updates
2023-08-23 23:45:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_34_40000.pt
2023-08-23 23:45:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_34_40000.pt
2023-08-23 23:45:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_34_40000.pt (epoch 34 @ 40000 updates, score 27.45) (writing took 6.624019223963842 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:0')
2023-08-23 23:46:21 | INFO | train_inner | epoch 034:   1035 / 1191 loss=1.775, trans_loss=4.6, nll_loss=1.722, w2v_ctc_loss=0.494, task_loss=2.306, contrastive_loss=0, total=6707.03, n_correct=4881.92, ppl=3.3, accuracy=72.788, wps=12088.7, ups=0.9, wpb=13414.1, bsz=451.6, num_updates=40100, lr=7.06225e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=70, gb_free=13.8, wall=33167
2023-08-23 23:47:32 | INFO | train_inner | epoch 034:   1135 / 1191 loss=1.769, trans_loss=4.597, nll_loss=1.718, w2v_ctc_loss=0.487, task_loss=2.184, contrastive_loss=0, total=6848.22, n_correct=4986.39, ppl=3.29, accuracy=72.813, wps=19185.9, ups=1.4, wpb=13696.4, bsz=477, num_updates=40200, lr=7.05346e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=71, gb_free=12.2, wall=33239
2023-08-23 23:48:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:2')
2023-08-23 23:48:46 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.88 | trans_loss 5.179 | nll_loss 2.382 | w2v_ctc_loss 1.234 | task_loss 8.54 | contrastive_loss 0 | total 6138.43 | n_correct 4182.86 | ppl 5.21 | accuracy 68.142 | uer 16.225 | wer 17.988 | raw_wer 17.988 | bleu 27.72 | wps 1733.7 | wpb 6138.4 | bsz 201.1 | num_updates 40256 | best_bleu 28.26
2023-08-23 23:48:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40256 updates
2023-08-23 23:48:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7204.pt
2023-08-23 23:48:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7204.pt
2023-08-23 23:48:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7204.pt (epoch 34 @ 40256 updates, score 27.72) (writing took 6.496146093006246 seconds)
2023-08-23 23:48:53 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-23 23:48:53 | INFO | train | epoch 034 | loss 1.772 | trans_loss 4.591 | nll_loss 1.71 | w2v_ctc_loss 0.494 | task_loss 2.343 | contrastive_loss 0 | total 6703.92 | n_correct 4885.47 | ppl 3.27 | accuracy 72.875 | wps 16997.1 | ups 1.27 | wpb 13407.8 | bsz 452.3 | num_updates 40256 | lr 7.04855e-05 | gnorm 0.383 | clip 0 | loss_scale 64 | train_wall 844 | gb_free 14.1 | wall 33319
2023-08-23 23:48:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-23 23:48:53 | INFO | fairseq.trainer | begin training epoch 35
2023-08-23 23:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-23 23:49:32 | INFO | train_inner | epoch 035:     44 / 1191 loss=1.769, trans_loss=4.587, nll_loss=1.706, w2v_ctc_loss=0.493, task_loss=2.27, contrastive_loss=0, total=6708.37, n_correct=4894.38, ppl=3.26, accuracy=72.959, wps=11244.1, ups=0.84, wpb=13416.7, bsz=461.1, num_updates=40300, lr=7.0447e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=10.5, wall=33358
2023-08-23 23:50:43 | INFO | train_inner | epoch 035:    144 / 1191 loss=1.763, trans_loss=4.581, nll_loss=1.697, w2v_ctc_loss=0.485, task_loss=2.245, contrastive_loss=0, total=6762.2, n_correct=4945.71, ppl=3.24, accuracy=73.138, wps=18971.4, ups=1.4, wpb=13524.4, bsz=470.3, num_updates=40400, lr=7.03598e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=15.8, wall=33429
2023-08-23 23:51:54 | INFO | train_inner | epoch 035:    244 / 1191 loss=1.766, trans_loss=4.578, nll_loss=1.692, w2v_ctc_loss=0.487, task_loss=2.56, contrastive_loss=0, total=6586.93, n_correct=4819.74, ppl=3.23, accuracy=73.171, wps=18474.4, ups=1.4, wpb=13173.9, bsz=426.5, num_updates=40500, lr=7.02728e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=71, gb_free=12.8, wall=33500
2023-08-23 23:53:06 | INFO | train_inner | epoch 035:    344 / 1191 loss=1.757, trans_loss=4.571, nll_loss=1.684, w2v_ctc_loss=0.481, task_loss=2.193, contrastive_loss=0, total=6799.94, n_correct=4995.52, ppl=3.21, accuracy=73.464, wps=19034.2, ups=1.4, wpb=13599.9, bsz=470.4, num_updates=40600, lr=7.01862e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=70, gb_free=13.4, wall=33572
2023-08-23 23:54:18 | INFO | train_inner | epoch 035:    444 / 1191 loss=1.775, trans_loss=4.59, nll_loss=1.707, w2v_ctc_loss=0.496, task_loss=2.655, contrastive_loss=0, total=6568.29, n_correct=4788.67, ppl=3.27, accuracy=72.906, wps=18284.1, ups=1.39, wpb=13136.6, bsz=417.4, num_updates=40700, lr=7.01e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=71, gb_free=14.5, wall=33644
2023-08-23 23:55:30 | INFO | train_inner | epoch 035:    544 / 1191 loss=1.768, trans_loss=4.583, nll_loss=1.7, w2v_ctc_loss=0.493, task_loss=2.371, contrastive_loss=0, total=6692.46, n_correct=4884.83, ppl=3.25, accuracy=72.99, wps=18486, ups=1.38, wpb=13384.9, bsz=455.1, num_updates=40800, lr=7.0014e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=72, gb_free=15.2, wall=33716
2023-08-23 23:56:42 | INFO | train_inner | epoch 035:    644 / 1191 loss=1.77, trans_loss=4.589, nll_loss=1.707, w2v_ctc_loss=0.491, task_loss=2.341, contrastive_loss=0, total=6713.27, n_correct=4895.82, ppl=3.27, accuracy=72.928, wps=18658.7, ups=1.39, wpb=13426.5, bsz=447.8, num_updates=40900, lr=6.99284e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=33788
2023-08-23 23:57:53 | INFO | train_inner | epoch 035:    744 / 1191 loss=1.771, trans_loss=4.592, nll_loss=1.712, w2v_ctc_loss=0.49, task_loss=2.342, contrastive_loss=0, total=6720.86, n_correct=4891.87, ppl=3.28, accuracy=72.786, wps=18929.2, ups=1.41, wpb=13441.7, bsz=452.5, num_updates=41000, lr=6.9843e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=70, gb_free=14.6, wall=33859
2023-08-23 23:59:05 | INFO | train_inner | epoch 035:    844 / 1191 loss=1.769, trans_loss=4.594, nll_loss=1.714, w2v_ctc_loss=0.487, task_loss=2.202, contrastive_loss=0, total=6757.78, n_correct=4920.36, ppl=3.28, accuracy=72.81, wps=18840.6, ups=1.39, wpb=13515.6, bsz=468.5, num_updates=41100, lr=6.9758e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=14.4, wall=33931
2023-08-24 00:00:16 | INFO | train_inner | epoch 035:    944 / 1191 loss=1.765, trans_loss=4.587, nll_loss=1.706, w2v_ctc_loss=0.486, task_loss=2.192, contrastive_loss=0, total=6792.38, n_correct=4962.53, ppl=3.26, accuracy=73.06, wps=19114.5, ups=1.41, wpb=13584.8, bsz=468.7, num_updates=41200, lr=6.96733e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=70, gb_free=13.4, wall=34002
2023-08-24 00:01:27 | INFO | train_inner | epoch 035:   1044 / 1191 loss=1.773, trans_loss=4.589, nll_loss=1.707, w2v_ctc_loss=0.5, task_loss=2.278, contrastive_loss=0, total=6768.96, n_correct=4932.08, ppl=3.27, accuracy=72.863, wps=18929.4, ups=1.4, wpb=13537.9, bsz=457.8, num_updates=41300, lr=6.95889e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=71, gb_free=12.5, wall=34073
2023-08-24 00:02:39 | INFO | train_inner | epoch 035:   1144 / 1191 loss=1.779, trans_loss=4.603, nll_loss=1.725, w2v_ctc_loss=0.498, task_loss=2.579, contrastive_loss=0, total=6527.74, n_correct=4740.24, ppl=3.31, accuracy=72.617, wps=18131.4, ups=1.39, wpb=13055.5, bsz=423.4, num_updates=41400, lr=6.95048e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=71, gb_free=12.7, wall=34145
2023-08-24 00:03:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 00:03:46 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 3.892 | trans_loss 5.184 | nll_loss 2.387 | w2v_ctc_loss 1.261 | task_loss 8.532 | contrastive_loss 0 | total 6138.43 | n_correct 4179.57 | ppl 5.23 | accuracy 68.089 | uer 16.311 | wer 18.185 | raw_wer 18.185 | bleu 27.3 | wps 1740 | wpb 6138.4 | bsz 201.1 | num_updates 41447 | best_bleu 28.26
2023-08-24 00:03:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 41447 updates
2023-08-24 00:03:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 00:03:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 00:03:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 35 @ 41447 updates, score 27.3) (writing took 5.984128475072794 seconds)
2023-08-24 00:03:52 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-08-24 00:03:52 | INFO | train | epoch 035 | loss 1.768 | trans_loss 4.587 | nll_loss 1.705 | w2v_ctc_loss 0.49 | task_loss 2.345 | contrastive_loss 0 | total 6703.69 | n_correct 4892.56 | ppl 3.26 | accuracy 72.983 | wps 17752.6 | ups 1.32 | wpb 13407.4 | bsz 452.1 | num_updates 41447 | lr 6.94654e-05 | gnorm 0.382 | clip 0 | loss_scale 64 | train_wall 844 | gb_free 14.1 | wall 34218
2023-08-24 00:03:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-24 00:03:52 | INFO | fairseq.trainer | begin training epoch 36
2023-08-24 00:03:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 00:04:37 | INFO | train_inner | epoch 036:     53 / 1191 loss=1.761, trans_loss=4.581, nll_loss=1.698, w2v_ctc_loss=0.481, task_loss=2.231, contrastive_loss=0, total=6769.09, n_correct=4950.98, ppl=3.25, accuracy=73.141, wps=11471.3, ups=0.85, wpb=13538.2, bsz=469.6, num_updates=41500, lr=6.9421e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=70, gb_free=14.3, wall=34264
2023-08-24 00:05:49 | INFO | train_inner | epoch 036:    153 / 1191 loss=1.759, trans_loss=4.569, nll_loss=1.681, w2v_ctc_loss=0.481, task_loss=2.388, contrastive_loss=0, total=6618.42, n_correct=4858.41, ppl=3.21, accuracy=73.407, wps=18594.5, ups=1.4, wpb=13236.8, bsz=446, num_updates=41600, lr=6.93375e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=71, gb_free=13.5, wall=34335
2023-08-24 00:06:59 | INFO | train_inner | epoch 036:    253 / 1191 loss=1.75, trans_loss=4.561, nll_loss=1.672, w2v_ctc_loss=0.472, task_loss=2.228, contrastive_loss=0, total=6756.31, n_correct=4970.72, ppl=3.19, accuracy=73.572, wps=19061.8, ups=1.41, wpb=13512.6, bsz=467.7, num_updates=41700, lr=6.92543e-05, gnorm=0.378, clip=0, loss_scale=64, train_wall=70, gb_free=13.4, wall=34406
2023-08-24 00:08:11 | INFO | train_inner | epoch 036:    353 / 1191 loss=1.761, trans_loss=4.577, nll_loss=1.692, w2v_ctc_loss=0.489, task_loss=2.196, contrastive_loss=0, total=6795.64, n_correct=4978.32, ppl=3.23, accuracy=73.258, wps=19137.8, ups=1.41, wpb=13591.3, bsz=474.6, num_updates=41800, lr=6.91714e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=70, gb_free=6.1, wall=34477
2023-08-24 00:09:23 | INFO | train_inner | epoch 036:    453 / 1191 loss=1.768, trans_loss=4.586, nll_loss=1.703, w2v_ctc_loss=0.49, task_loss=2.242, contrastive_loss=0, total=6785.3, n_correct=4955.76, ppl=3.26, accuracy=73.037, wps=18753.3, ups=1.38, wpb=13570.6, bsz=466.7, num_updates=41900, lr=6.90889e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=72, gb_free=13.4, wall=34549
2023-08-24 00:10:35 | INFO | train_inner | epoch 036:    553 / 1191 loss=1.761, trans_loss=4.58, nll_loss=1.697, w2v_ctc_loss=0.479, task_loss=2.185, contrastive_loss=0, total=6808.86, n_correct=4981.09, ppl=3.24, accuracy=73.156, wps=18889.2, ups=1.39, wpb=13617.7, bsz=474.1, num_updates=42000, lr=6.90066e-05, gnorm=0.378, clip=0, loss_scale=128, train_wall=72, gb_free=14.4, wall=34621
2023-08-24 00:10:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 00:11:08 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.89 | trans_loss 5.184 | nll_loss 2.386 | w2v_ctc_loss 1.254 | task_loss 8.528 | contrastive_loss 0 | total 6138.43 | n_correct 4187.86 | ppl 5.23 | accuracy 68.224 | uer 16.196 | wer 18.014 | raw_wer 18.014 | bleu 27.44 | wps 1743.1 | wpb 6138.4 | bsz 201.1 | num_updates 42000 | best_bleu 28.26
2023-08-24 00:11:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42000 updates
2023-08-24 00:11:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_36_42000.pt
2023-08-24 00:11:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_36_42000.pt
2023-08-24 00:11:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_36_42000.pt (epoch 36 @ 42000 updates, score 27.44) (writing took 6.283484891988337 seconds)
2023-08-24 00:12:25 | INFO | train_inner | epoch 036:    653 / 1191 loss=1.769, trans_loss=4.584, nll_loss=1.7, w2v_ctc_loss=0.49, task_loss=2.472, contrastive_loss=0, total=6620.09, n_correct=4842.01, ppl=3.25, accuracy=73.141, wps=12036.9, ups=0.91, wpb=13240.2, bsz=428.2, num_updates=42100, lr=6.89246e-05, gnorm=0.385, clip=0, loss_scale=128, train_wall=70, gb_free=15.1, wall=34731
2023-08-24 00:13:37 | INFO | train_inner | epoch 036:    753 / 1191 loss=1.768, trans_loss=4.588, nll_loss=1.706, w2v_ctc_loss=0.489, task_loss=2.32, contrastive_loss=0, total=6746.33, n_correct=4925.85, ppl=3.26, accuracy=73.015, wps=18671.4, ups=1.38, wpb=13492.7, bsz=459.3, num_updates=42200, lr=6.88428e-05, gnorm=0.384, clip=0, loss_scale=128, train_wall=72, gb_free=14.5, wall=34803
2023-08-24 00:14:50 | INFO | train_inner | epoch 036:    853 / 1191 loss=1.77, trans_loss=4.59, nll_loss=1.708, w2v_ctc_loss=0.489, task_loss=2.45, contrastive_loss=0, total=6664.18, n_correct=4860.52, ppl=3.27, accuracy=72.935, wps=18431.8, ups=1.38, wpb=13328.4, bsz=442.5, num_updates=42300, lr=6.87614e-05, gnorm=0.39, clip=0, loss_scale=128, train_wall=72, gb_free=13.8, wall=34876
2023-08-24 00:16:01 | INFO | train_inner | epoch 036:    953 / 1191 loss=1.776, trans_loss=4.595, nll_loss=1.715, w2v_ctc_loss=0.494, task_loss=2.537, contrastive_loss=0, total=6674.27, n_correct=4858.22, ppl=3.28, accuracy=72.79, wps=18581.1, ups=1.39, wpb=13348.5, bsz=427.6, num_updates=42400, lr=6.86803e-05, gnorm=0.389, clip=0, loss_scale=128, train_wall=71, gb_free=13.7, wall=34948
2023-08-24 00:17:13 | INFO | train_inner | epoch 036:   1053 / 1191 loss=1.765, trans_loss=4.589, nll_loss=1.709, w2v_ctc_loss=0.487, task_loss=2.17, contrastive_loss=0, total=6745.43, n_correct=4923.5, ppl=3.27, accuracy=72.99, wps=18873.1, ups=1.4, wpb=13490.9, bsz=480.1, num_updates=42500, lr=6.85994e-05, gnorm=0.378, clip=0, loss_scale=128, train_wall=71, gb_free=14, wall=35019
2023-08-24 00:18:24 | INFO | train_inner | epoch 036:   1153 / 1191 loss=1.781, trans_loss=4.598, nll_loss=1.719, w2v_ctc_loss=0.503, task_loss=2.662, contrastive_loss=0, total=6512.62, n_correct=4730.98, ppl=3.29, accuracy=72.643, wps=18251.5, ups=1.4, wpb=13025.2, bsz=407.9, num_updates=42600, lr=6.85189e-05, gnorm=0.399, clip=0, loss_scale=128, train_wall=71, gb_free=13.2, wall=35090
2023-08-24 00:18:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-24 00:18:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 00:19:25 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.894 | trans_loss 5.183 | nll_loss 2.386 | w2v_ctc_loss 1.268 | task_loss 8.509 | contrastive_loss 0 | total 6138.43 | n_correct 4184.71 | ppl 5.23 | accuracy 68.172 | uer 16.391 | wer 18.185 | raw_wer 18.185 | bleu 27.71 | wps 1677.7 | wpb 6138.4 | bsz 201.1 | num_updates 42637 | best_bleu 28.26
2023-08-24 00:19:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42637 updates
2023-08-24 00:19:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7108.pt
2023-08-24 00:19:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7108.pt
2023-08-24 00:19:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7108.pt (epoch 36 @ 42637 updates, score 27.71) (writing took 7.1640693040098995 seconds)
2023-08-24 00:19:33 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-08-24 00:19:33 | INFO | train | epoch 036 | loss 1.766 | trans_loss 4.583 | nll_loss 1.7 | w2v_ctc_loss 0.487 | task_loss 2.345 | contrastive_loss 0 | total 6702.6 | n_correct 4898.72 | ppl 3.25 | accuracy 73.087 | wps 16961.4 | ups 1.27 | wpb 13405.2 | bsz 451.7 | num_updates 42637 | lr 6.84891e-05 | gnorm 0.385 | clip 0 | loss_scale 64 | train_wall 845 | gb_free 12.9 | wall 35159
2023-08-24 00:19:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-24 00:19:33 | INFO | fairseq.trainer | begin training epoch 37
2023-08-24 00:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 00:20:26 | INFO | train_inner | epoch 037:     63 / 1191 loss=1.762, trans_loss=4.579, nll_loss=1.694, w2v_ctc_loss=0.483, task_loss=2.33, contrastive_loss=0, total=6738.04, n_correct=4931.3, ppl=3.24, accuracy=73.186, wps=11048, ups=0.82, wpb=13476.1, bsz=457.9, num_updates=42700, lr=6.84386e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=72, gb_free=13.4, wall=35212
2023-08-24 00:21:38 | INFO | train_inner | epoch 037:    163 / 1191 loss=1.756, trans_loss=4.568, nll_loss=1.68, w2v_ctc_loss=0.478, task_loss=2.275, contrastive_loss=0, total=6740.91, n_correct=4950.01, ppl=3.2, accuracy=73.432, wps=18842.9, ups=1.4, wpb=13481.8, bsz=454.2, num_updates=42800, lr=6.83586e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=35284
2023-08-24 00:22:49 | INFO | train_inner | epoch 037:    263 / 1191 loss=1.761, trans_loss=4.57, nll_loss=1.683, w2v_ctc_loss=0.487, task_loss=2.312, contrastive_loss=0, total=6750.66, n_correct=4952.45, ppl=3.21, accuracy=73.362, wps=18923.4, ups=1.4, wpb=13501.3, bsz=454.6, num_updates=42900, lr=6.82789e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=35355
2023-08-24 00:24:01 | INFO | train_inner | epoch 037:    363 / 1191 loss=1.761, trans_loss=4.572, nll_loss=1.685, w2v_ctc_loss=0.484, task_loss=2.404, contrastive_loss=0, total=6600.74, n_correct=4840.82, ppl=3.22, accuracy=73.338, wps=18455.5, ups=1.4, wpb=13201.5, bsz=442, num_updates=43000, lr=6.81994e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=71, gb_free=12.5, wall=35427
2023-08-24 00:25:12 | INFO | train_inner | epoch 037:    463 / 1191 loss=1.759, trans_loss=4.571, nll_loss=1.683, w2v_ctc_loss=0.48, task_loss=2.453, contrastive_loss=0, total=6658.63, n_correct=4888.95, ppl=3.21, accuracy=73.423, wps=18631.6, ups=1.4, wpb=13317.3, bsz=433.2, num_updates=43100, lr=6.81203e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=71, gb_free=15.3, wall=35498
2023-08-24 00:26:24 | INFO | train_inner | epoch 037:    563 / 1191 loss=1.762, trans_loss=4.578, nll_loss=1.693, w2v_ctc_loss=0.483, task_loss=2.358, contrastive_loss=0, total=6666.47, n_correct=4876.55, ppl=3.23, accuracy=73.15, wps=18541.4, ups=1.39, wpb=13332.9, bsz=454.9, num_updates=43200, lr=6.80414e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=71, gb_free=14.8, wall=35570
2023-08-24 00:27:36 | INFO | train_inner | epoch 037:    663 / 1191 loss=1.765, trans_loss=4.585, nll_loss=1.701, w2v_ctc_loss=0.478, task_loss=2.452, contrastive_loss=0, total=6671.6, n_correct=4875.76, ppl=3.25, accuracy=73.082, wps=18482, ups=1.39, wpb=13343.2, bsz=436, num_updates=43300, lr=6.79628e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=72, gb_free=14.7, wall=35642
2023-08-24 00:28:48 | INFO | train_inner | epoch 037:    763 / 1191 loss=1.762, trans_loss=4.575, nll_loss=1.69, w2v_ctc_loss=0.485, task_loss=2.289, contrastive_loss=0, total=6733.07, n_correct=4935.04, ppl=3.23, accuracy=73.296, wps=18884, ups=1.4, wpb=13466.1, bsz=456.8, num_updates=43400, lr=6.78844e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=71, gb_free=13.1, wall=35714
2023-08-24 00:30:00 | INFO | train_inner | epoch 037:    863 / 1191 loss=1.763, trans_loss=4.585, nll_loss=1.703, w2v_ctc_loss=0.484, task_loss=2.275, contrastive_loss=0, total=6780.07, n_correct=4957.87, ppl=3.26, accuracy=73.124, wps=18776.1, ups=1.38, wpb=13560.1, bsz=462, num_updates=43500, lr=6.78064e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=72, gb_free=15.4, wall=35786
2023-08-24 00:31:12 | INFO | train_inner | epoch 037:    963 / 1191 loss=1.759, trans_loss=4.58, nll_loss=1.698, w2v_ctc_loss=0.482, task_loss=2.156, contrastive_loss=0, total=6799.83, n_correct=4973.34, ppl=3.24, accuracy=73.139, wps=18922.8, ups=1.39, wpb=13599.7, bsz=483.5, num_updates=43600, lr=6.77285e-05, gnorm=0.38, clip=0, loss_scale=64, train_wall=71, gb_free=14.4, wall=35858
2023-08-24 00:32:24 | INFO | train_inner | epoch 037:   1063 / 1191 loss=1.768, trans_loss=4.587, nll_loss=1.705, w2v_ctc_loss=0.49, task_loss=2.366, contrastive_loss=0, total=6741.59, n_correct=4919.7, ppl=3.26, accuracy=72.975, wps=18691.5, ups=1.39, wpb=13483.2, bsz=452.7, num_updates=43700, lr=6.7651e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=72, gb_free=14.4, wall=35930
2023-08-24 00:33:35 | INFO | train_inner | epoch 037:   1163 / 1191 loss=1.776, trans_loss=4.598, nll_loss=1.72, w2v_ctc_loss=0.496, task_loss=2.455, contrastive_loss=0, total=6612.83, n_correct=4809.77, ppl=3.29, accuracy=72.734, wps=18471.6, ups=1.4, wpb=13225.7, bsz=438.3, num_updates=43800, lr=6.75737e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=71, gb_free=14.3, wall=36002
2023-08-24 00:33:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 00:34:29 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.887 | trans_loss 5.178 | nll_loss 2.382 | w2v_ctc_loss 1.257 | task_loss 8.61 | contrastive_loss 0 | total 6138.43 | n_correct 4182.57 | ppl 5.21 | accuracy 68.137 | uer 16.471 | wer 18.193 | raw_wer 18.193 | bleu 27.72 | wps 1684.6 | wpb 6138.4 | bsz 201.1 | num_updates 43828 | best_bleu 28.26
2023-08-24 00:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 43828 updates
2023-08-24 00:34:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7200.pt
2023-08-24 00:34:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7200.pt
2023-08-24 00:34:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7200.pt (epoch 37 @ 43828 updates, score 27.72) (writing took 7.133052205084823 seconds)
2023-08-24 00:34:36 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-08-24 00:34:36 | INFO | train | epoch 037 | loss 1.763 | trans_loss 4.579 | nll_loss 1.694 | w2v_ctc_loss 0.484 | task_loss 2.342 | contrastive_loss 0 | total 6703.69 | n_correct 4906.59 | ppl 3.24 | accuracy 73.192 | wps 17674.4 | ups 1.32 | wpb 13407.4 | bsz 452.1 | num_updates 43828 | lr 6.75521e-05 | gnorm 0.385 | clip 0 | loss_scale 64 | train_wall 846 | gb_free 13.5 | wall 36062
2023-08-24 00:34:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-24 00:34:36 | INFO | fairseq.trainer | begin training epoch 38
2023-08-24 00:34:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 00:35:35 | INFO | train_inner | epoch 038:     72 / 1191 loss=1.761, trans_loss=4.573, nll_loss=1.686, w2v_ctc_loss=0.484, task_loss=2.423, contrastive_loss=0, total=6637.51, n_correct=4865.97, ppl=3.22, accuracy=73.31, wps=11106.7, ups=0.84, wpb=13275, bsz=437.2, num_updates=43900, lr=6.74967e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=70, gb_free=14.6, wall=36121
2023-08-24 00:36:47 | INFO | train_inner | epoch 038:    172 / 1191 loss=1.752, trans_loss=4.56, nll_loss=1.669, w2v_ctc_loss=0.476, task_loss=2.342, contrastive_loss=0, total=6679.38, n_correct=4921.79, ppl=3.18, accuracy=73.686, wps=18543.8, ups=1.39, wpb=13358.8, bsz=447.6, num_updates=44000, lr=6.742e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=9.9, wall=36193
2023-08-24 00:36:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 00:37:20 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 3.909 | trans_loss 5.187 | nll_loss 2.392 | w2v_ctc_loss 1.311 | task_loss 8.638 | contrastive_loss 0 | total 6138.43 | n_correct 4176.86 | ppl 5.25 | accuracy 68.044 | uer 16.375 | wer 18.137 | raw_wer 18.137 | bleu 27.51 | wps 1736.3 | wpb 6138.4 | bsz 201.1 | num_updates 44000 | best_bleu 28.26
2023-08-24 00:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 44000 updates
2023-08-24 00:37:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_38_44000.pt
2023-08-24 00:37:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_38_44000.pt
2023-08-24 00:37:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_38_44000.pt (epoch 38 @ 44000 updates, score 27.51) (writing took 6.485310983029194 seconds)
2023-08-24 00:38:38 | INFO | train_inner | epoch 038:    272 / 1191 loss=1.758, trans_loss=4.571, nll_loss=1.684, w2v_ctc_loss=0.477, task_loss=2.362, contrastive_loss=0, total=6677.86, n_correct=4898.51, ppl=3.21, accuracy=73.354, wps=12018.1, ups=0.9, wpb=13355.7, bsz=454.5, num_updates=44100, lr=6.73435e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=71, gb_free=11.6, wall=36304
2023-08-24 00:39:50 | INFO | train_inner | epoch 038:    372 / 1191 loss=1.76, trans_loss=4.569, nll_loss=1.682, w2v_ctc_loss=0.489, task_loss=2.384, contrastive_loss=0, total=6684.77, n_correct=4904.48, ppl=3.21, accuracy=73.368, wps=18530.3, ups=1.39, wpb=13369.5, bsz=448.3, num_updates=44200, lr=6.72673e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=72, gb_free=14.7, wall=36376
2023-08-24 00:41:02 | INFO | train_inner | epoch 038:    472 / 1191 loss=1.755, trans_loss=4.57, nll_loss=1.684, w2v_ctc_loss=0.477, task_loss=2.199, contrastive_loss=0, total=6757.14, n_correct=4957.82, ppl=3.21, accuracy=73.372, wps=18934.5, ups=1.4, wpb=13514.3, bsz=477, num_updates=44300, lr=6.71913e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=70, gb_free=14, wall=36448
2023-08-24 00:42:14 | INFO | train_inner | epoch 038:    572 / 1191 loss=1.758, trans_loss=4.574, nll_loss=1.688, w2v_ctc_loss=0.48, task_loss=2.273, contrastive_loss=0, total=6842.54, n_correct=5021.15, ppl=3.22, accuracy=73.381, wps=19026, ups=1.39, wpb=13685.1, bsz=462.8, num_updates=44400, lr=6.71156e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=71, gb_free=10, wall=36520
2023-08-24 00:43:26 | INFO | train_inner | epoch 038:    672 / 1191 loss=1.759, trans_loss=4.58, nll_loss=1.696, w2v_ctc_loss=0.478, task_loss=2.235, contrastive_loss=0, total=6773.43, n_correct=4964.11, ppl=3.24, accuracy=73.288, wps=18650.9, ups=1.38, wpb=13546.9, bsz=466.6, num_updates=44500, lr=6.70402e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=72, gb_free=12.9, wall=36592
2023-08-24 00:44:37 | INFO | train_inner | epoch 038:    772 / 1191 loss=1.758, trans_loss=4.574, nll_loss=1.689, w2v_ctc_loss=0.482, task_loss=2.228, contrastive_loss=0, total=6774.24, n_correct=4967.82, ppl=3.22, accuracy=73.334, wps=19107.8, ups=1.41, wpb=13548.5, bsz=471.3, num_updates=44600, lr=6.6965e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=70, gb_free=11.2, wall=36663
2023-08-24 00:45:49 | INFO | train_inner | epoch 038:    872 / 1191 loss=1.77, trans_loss=4.584, nll_loss=1.702, w2v_ctc_loss=0.493, task_loss=2.472, contrastive_loss=0, total=6660.3, n_correct=4865.37, ppl=3.25, accuracy=73.05, wps=18554, ups=1.39, wpb=13320.6, bsz=433.8, num_updates=44700, lr=6.689e-05, gnorm=0.392, clip=0, loss_scale=128, train_wall=71, gb_free=13, wall=36735
2023-08-24 00:47:01 | INFO | train_inner | epoch 038:    972 / 1191 loss=1.76, trans_loss=4.578, nll_loss=1.693, w2v_ctc_loss=0.478, task_loss=2.401, contrastive_loss=0, total=6674.2, n_correct=4892.64, ppl=3.23, accuracy=73.307, wps=18582.1, ups=1.39, wpb=13348.4, bsz=443.4, num_updates=44800, lr=6.68153e-05, gnorm=0.386, clip=0, loss_scale=128, train_wall=71, gb_free=14.9, wall=36807
2023-08-24 00:48:12 | INFO | train_inner | epoch 038:   1072 / 1191 loss=1.762, trans_loss=4.577, nll_loss=1.694, w2v_ctc_loss=0.482, task_loss=2.425, contrastive_loss=0, total=6653.02, n_correct=4869.73, ppl=3.23, accuracy=73.196, wps=18724.8, ups=1.41, wpb=13306, bsz=445.3, num_updates=44900, lr=6.67409e-05, gnorm=0.389, clip=0, loss_scale=128, train_wall=70, gb_free=11.4, wall=36878
2023-08-24 00:49:24 | INFO | train_inner | epoch 038:   1172 / 1191 loss=1.76, trans_loss=4.581, nll_loss=1.697, w2v_ctc_loss=0.477, task_loss=2.398, contrastive_loss=0, total=6667.1, n_correct=4880.43, ppl=3.24, accuracy=73.202, wps=18543.8, ups=1.39, wpb=13334.2, bsz=445.3, num_updates=45000, lr=6.66667e-05, gnorm=0.387, clip=0, loss_scale=128, train_wall=71, gb_free=14.1, wall=36950
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:0')
2023-08-24 00:49:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2339, device='cuda:4')
2023-08-24 00:50:10 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 3.896 | trans_loss 5.185 | nll_loss 2.388 | w2v_ctc_loss 1.272 | task_loss 8.56 | contrastive_loss 0 | total 6138.43 | n_correct 4187.86 | ppl 5.24 | accuracy 68.224 | uer 16.153 | wer 17.936 | raw_wer 17.936 | bleu 27.45 | wps 1764.5 | wpb 6138.4 | bsz 201.1 | num_updates 45019 | best_bleu 28.26
2023-08-24 00:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 45019 updates
2023-08-24 00:50:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 00:50:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 00:50:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 38 @ 45019 updates, score 27.45) (writing took 7.248970986925997 seconds)
2023-08-24 00:50:17 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-08-24 00:50:17 | INFO | train | epoch 038 | loss 1.759 | trans_loss 4.574 | nll_loss 1.689 | w2v_ctc_loss 0.481 | task_loss 2.347 | contrastive_loss 0 | total 6703.69 | n_correct 4915.24 | ppl 3.22 | accuracy 73.321 | wps 16974.3 | ups 1.27 | wpb 13407.4 | bsz 452.1 | num_updates 45019 | lr 6.66526e-05 | gnorm 0.386 | clip 0 | loss_scale 128 | train_wall 845 | gb_free 14.1 | wall 37003
2023-08-24 00:50:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-24 00:50:17 | INFO | fairseq.trainer | begin training epoch 39
2023-08-24 00:50:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 00:51:23 | INFO | train_inner | epoch 039:     81 / 1191 loss=1.76, trans_loss=4.568, nll_loss=1.68, w2v_ctc_loss=0.481, task_loss=2.618, contrastive_loss=0, total=6550.2, n_correct=4812.15, ppl=3.2, accuracy=73.466, wps=10964.1, ups=0.84, wpb=13100.4, bsz=417.8, num_updates=45100, lr=6.65927e-05, gnorm=0.392, clip=0, loss_scale=128, train_wall=71, gb_free=13.7, wall=37069
2023-08-24 00:52:35 | INFO | train_inner | epoch 039:    181 / 1191 loss=1.755, trans_loss=4.562, nll_loss=1.672, w2v_ctc_loss=0.481, task_loss=2.437, contrastive_loss=0, total=6643.3, n_correct=4887.53, ppl=3.19, accuracy=73.571, wps=18485.9, ups=1.39, wpb=13286.6, bsz=439.6, num_updates=45200, lr=6.6519e-05, gnorm=0.393, clip=0, loss_scale=128, train_wall=71, gb_free=15.2, wall=37141
2023-08-24 00:53:47 | INFO | train_inner | epoch 039:    281 / 1191 loss=1.756, trans_loss=4.569, nll_loss=1.68, w2v_ctc_loss=0.476, task_loss=2.444, contrastive_loss=0, total=6635.11, n_correct=4876.85, ppl=3.21, accuracy=73.501, wps=18571.1, ups=1.4, wpb=13270.2, bsz=439.7, num_updates=45300, lr=6.64455e-05, gnorm=0.388, clip=0, loss_scale=128, train_wall=71, gb_free=12.8, wall=37213
2023-08-24 00:54:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-24 00:55:00 | INFO | train_inner | epoch 039:    382 / 1191 loss=1.757, trans_loss=4.567, nll_loss=1.679, w2v_ctc_loss=0.479, task_loss=2.429, contrastive_loss=0, total=6697.59, n_correct=4920.1, ppl=3.2, accuracy=73.461, wps=18277, ups=1.36, wpb=13395.2, bsz=443.4, num_updates=45400, lr=6.63723e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=73, gb_free=14.6, wall=37286
2023-08-24 00:56:11 | INFO | train_inner | epoch 039:    482 / 1191 loss=1.756, trans_loss=4.569, nll_loss=1.682, w2v_ctc_loss=0.473, task_loss=2.351, contrastive_loss=0, total=6668.88, n_correct=4897.55, ppl=3.21, accuracy=73.439, wps=18679.5, ups=1.4, wpb=13337.8, bsz=450, num_updates=45500, lr=6.62994e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=14.4, wall=37357
2023-08-24 00:57:23 | INFO | train_inner | epoch 039:    582 / 1191 loss=1.757, trans_loss=4.569, nll_loss=1.682, w2v_ctc_loss=0.479, task_loss=2.362, contrastive_loss=0, total=6708.27, n_correct=4924.39, ppl=3.21, accuracy=73.408, wps=18671.8, ups=1.39, wpb=13416.5, bsz=449, num_updates=45600, lr=6.62266e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=71, gb_free=12.7, wall=37429
2023-08-24 00:58:35 | INFO | train_inner | epoch 039:    682 / 1191 loss=1.756, trans_loss=4.573, nll_loss=1.687, w2v_ctc_loss=0.478, task_loss=2.272, contrastive_loss=0, total=6763.52, n_correct=4962.57, ppl=3.22, accuracy=73.373, wps=18889.3, ups=1.4, wpb=13527, bsz=471, num_updates=45700, lr=6.61541e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=12.1, wall=37501
2023-08-24 00:59:46 | INFO | train_inner | epoch 039:    782 / 1191 loss=1.758, trans_loss=4.576, nll_loss=1.691, w2v_ctc_loss=0.477, task_loss=2.333, contrastive_loss=0, total=6718.95, n_correct=4927.79, ppl=3.23, accuracy=73.342, wps=18755.9, ups=1.4, wpb=13437.9, bsz=455.2, num_updates=45800, lr=6.60819e-05, gnorm=0.384, clip=0, loss_scale=64, train_wall=71, gb_free=14, wall=37573
2023-08-24 01:00:58 | INFO | train_inner | epoch 039:    882 / 1191 loss=1.751, trans_loss=4.569, nll_loss=1.683, w2v_ctc_loss=0.472, task_loss=2.099, contrastive_loss=0, total=6886.73, n_correct=5062.31, ppl=3.21, accuracy=73.508, wps=19274.8, ups=1.4, wpb=13773.5, bsz=486.4, num_updates=45900, lr=6.60098e-05, gnorm=0.377, clip=0, loss_scale=64, train_wall=71, gb_free=14.2, wall=37644
2023-08-24 01:02:10 | INFO | train_inner | epoch 039:    982 / 1191 loss=1.749, trans_loss=4.566, nll_loss=1.679, w2v_ctc_loss=0.468, task_loss=2.202, contrastive_loss=0, total=6788.37, n_correct=4992.66, ppl=3.2, accuracy=73.547, wps=18928.3, ups=1.39, wpb=13576.7, bsz=477.4, num_updates=46000, lr=6.5938e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=71, gb_free=11, wall=37716
2023-08-24 01:02:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 01:02:43 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.9 | trans_loss 5.181 | nll_loss 2.382 | w2v_ctc_loss 1.295 | task_loss 8.597 | contrastive_loss 0 | total 6138.43 | n_correct 4185.57 | ppl 5.21 | accuracy 68.186 | uer 16.169 | wer 17.981 | raw_wer 17.981 | bleu 27.28 | wps 1697.5 | wpb 6138.4 | bsz 201.1 | num_updates 46000 | best_bleu 28.26
2023-08-24 01:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46000 updates
2023-08-24 01:02:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_39_46000.pt
2023-08-24 01:02:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_39_46000.pt
2023-08-24 01:02:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_39_46000.pt (epoch 39 @ 46000 updates, score 27.28) (writing took 6.273208349011838 seconds)
2023-08-24 01:04:01 | INFO | train_inner | epoch 039:   1082 / 1191 loss=1.759, trans_loss=4.577, nll_loss=1.692, w2v_ctc_loss=0.475, task_loss=2.404, contrastive_loss=0, total=6689.76, n_correct=4899.59, ppl=3.23, accuracy=73.24, wps=12048.6, ups=0.9, wpb=13379.5, bsz=440.3, num_updates=46100, lr=6.58665e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=70, gb_free=13.7, wall=37827
2023-08-24 01:05:11 | INFO | train_inner | epoch 039:   1182 / 1191 loss=1.76, trans_loss=4.575, nll_loss=1.69, w2v_ctc_loss=0.481, task_loss=2.368, contrastive_loss=0, total=6590.41, n_correct=4830.95, ppl=3.23, accuracy=73.303, wps=18661.1, ups=1.42, wpb=13180.8, bsz=440.8, num_updates=46200, lr=6.57952e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=70, gb_free=15.1, wall=37897
2023-08-24 01:05:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 01:05:50 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.91 | trans_loss 5.187 | nll_loss 2.391 | w2v_ctc_loss 1.314 | task_loss 8.532 | contrastive_loss 0 | total 6138.43 | n_correct 4183.14 | ppl 5.24 | accuracy 68.147 | uer 16.335 | wer 18.263 | raw_wer 18.263 | bleu 27.49 | wps 1753.6 | wpb 6138.4 | bsz 201.1 | num_updates 46209 | best_bleu 28.26
2023-08-24 01:05:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46209 updates
2023-08-24 01:05:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 01:05:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 01:05:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 39 @ 46209 updates, score 27.49) (writing took 5.875830123084597 seconds)
2023-08-24 01:05:56 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-08-24 01:05:56 | INFO | train | epoch 039 | loss 1.756 | trans_loss 4.57 | nll_loss 1.683 | w2v_ctc_loss 0.477 | task_loss 2.346 | contrastive_loss 0 | total 6703.29 | n_correct 4922.83 | ppl 3.21 | accuracy 73.439 | wps 16980.7 | ups 1.27 | wpb 13406.6 | bsz 452.1 | num_updates 46209 | lr 6.57888e-05 | gnorm 0.386 | clip 0 | loss_scale 64 | train_wall 845 | gb_free 13.4 | wall 37942
2023-08-24 01:05:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-24 01:05:57 | INFO | fairseq.trainer | begin training epoch 40
2023-08-24 01:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 01:07:10 | INFO | train_inner | epoch 040:     91 / 1191 loss=1.747, trans_loss=4.553, nll_loss=1.661, w2v_ctc_loss=0.471, task_loss=2.274, contrastive_loss=0, total=6814.41, n_correct=5030.18, ppl=3.16, accuracy=73.817, wps=11513.3, ups=0.84, wpb=13628.8, bsz=462.8, num_updates=46300, lr=6.57241e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=11.7, wall=38016
2023-08-24 01:08:21 | INFO | train_inner | epoch 040:    191 / 1191 loss=1.746, trans_loss=4.554, nll_loss=1.663, w2v_ctc_loss=0.472, task_loss=2.273, contrastive_loss=0, total=6720.32, n_correct=4964.18, ppl=3.17, accuracy=73.868, wps=18907, ups=1.41, wpb=13440.6, bsz=460.3, num_updates=46400, lr=6.56532e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=70, gb_free=13.9, wall=38087
2023-08-24 01:09:33 | INFO | train_inner | epoch 040:    291 / 1191 loss=1.748, trans_loss=4.556, nll_loss=1.666, w2v_ctc_loss=0.472, task_loss=2.275, contrastive_loss=0, total=6706.42, n_correct=4938.19, ppl=3.17, accuracy=73.634, wps=18648.9, ups=1.39, wpb=13412.8, bsz=460.7, num_updates=46500, lr=6.55826e-05, gnorm=0.386, clip=0, loss_scale=64, train_wall=71, gb_free=13, wall=38159
2023-08-24 01:10:45 | INFO | train_inner | epoch 040:    391 / 1191 loss=1.754, trans_loss=4.565, nll_loss=1.676, w2v_ctc_loss=0.473, task_loss=2.467, contrastive_loss=0, total=6682.13, n_correct=4919.01, ppl=3.2, accuracy=73.614, wps=18572.6, ups=1.39, wpb=13364.3, bsz=439.1, num_updates=46600, lr=6.55122e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=38231
2023-08-24 01:11:56 | INFO | train_inner | epoch 040:    491 / 1191 loss=1.753, trans_loss=4.565, nll_loss=1.677, w2v_ctc_loss=0.476, task_loss=2.333, contrastive_loss=0, total=6671.5, n_correct=4911, ppl=3.2, accuracy=73.612, wps=18761.8, ups=1.41, wpb=13343, bsz=452.5, num_updates=46700, lr=6.5442e-05, gnorm=0.387, clip=0, loss_scale=64, train_wall=70, gb_free=13.1, wall=38302
2023-08-24 01:13:07 | INFO | train_inner | epoch 040:    591 / 1191 loss=1.75, trans_loss=4.565, nll_loss=1.678, w2v_ctc_loss=0.466, task_loss=2.298, contrastive_loss=0, total=6695.84, n_correct=4926.2, ppl=3.2, accuracy=73.571, wps=18742.3, ups=1.4, wpb=13391.7, bsz=456.4, num_updates=46800, lr=6.5372e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=12.6, wall=38373
2023-08-24 01:14:20 | INFO | train_inner | epoch 040:    691 / 1191 loss=1.761, trans_loss=4.572, nll_loss=1.685, w2v_ctc_loss=0.482, task_loss=2.412, contrastive_loss=0, total=6690.75, n_correct=4905.88, ppl=3.22, accuracy=73.323, wps=18466.5, ups=1.38, wpb=13381.5, bsz=442.2, num_updates=46900, lr=6.53023e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=72, gb_free=14.2, wall=38446
2023-08-24 01:15:31 | INFO | train_inner | epoch 040:    791 / 1191 loss=1.756, trans_loss=4.572, nll_loss=1.686, w2v_ctc_loss=0.477, task_loss=2.346, contrastive_loss=0, total=6687.44, n_correct=4910.29, ppl=3.22, accuracy=73.426, wps=18704.3, ups=1.4, wpb=13374.9, bsz=452.5, num_updates=47000, lr=6.52328e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=71, gb_free=13.4, wall=38517
2023-08-24 01:16:43 | INFO | train_inner | epoch 040:    891 / 1191 loss=1.761, trans_loss=4.575, nll_loss=1.689, w2v_ctc_loss=0.481, task_loss=2.471, contrastive_loss=0, total=6680.76, n_correct=4898.91, ppl=3.23, accuracy=73.329, wps=18557.4, ups=1.39, wpb=13361.5, bsz=439, num_updates=47100, lr=6.51635e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=71, gb_free=12.8, wall=38589
2023-08-24 01:17:54 | INFO | train_inner | epoch 040:    991 / 1191 loss=1.757, trans_loss=4.574, nll_loss=1.689, w2v_ctc_loss=0.475, task_loss=2.323, contrastive_loss=0, total=6689.67, n_correct=4908.47, ppl=3.22, accuracy=73.374, wps=18891.2, ups=1.41, wpb=13379.3, bsz=448.3, num_updates=47200, lr=6.50945e-05, gnorm=0.388, clip=0, loss_scale=64, train_wall=70, gb_free=14, wall=38660
2023-08-24 01:19:06 | INFO | train_inner | epoch 040:   1091 / 1191 loss=1.756, trans_loss=4.57, nll_loss=1.684, w2v_ctc_loss=0.483, task_loss=2.265, contrastive_loss=0, total=6749.8, n_correct=4956.43, ppl=3.21, accuracy=73.431, wps=18865.2, ups=1.4, wpb=13499.6, bsz=468, num_updates=47300, lr=6.50256e-05, gnorm=0.383, clip=0, loss_scale=64, train_wall=71, gb_free=11.1, wall=38732
2023-08-24 01:20:17 | INFO | train_inner | epoch 040:   1191 / 1191 loss=1.756, trans_loss=4.575, nll_loss=1.691, w2v_ctc_loss=0.473, task_loss=2.41, contrastive_loss=0, total=6667.77, n_correct=4890.49, ppl=3.23, accuracy=73.345, wps=18779.8, ups=1.41, wpb=13335.5, bsz=444.6, num_updates=47400, lr=6.4957e-05, gnorm=0.39, clip=0, loss_scale=128, train_wall=70, gb_free=12.3, wall=38803
2023-08-24 01:20:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 01:20:49 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 3.888 | trans_loss 5.182 | nll_loss 2.382 | w2v_ctc_loss 1.252 | task_loss 8.635 | contrastive_loss 0 | total 6138.43 | n_correct 4189.29 | ppl 5.21 | accuracy 68.247 | uer 15.99 | wer 17.992 | raw_wer 17.992 | bleu 27.75 | wps 1769 | wpb 6138.4 | bsz 201.1 | num_updates 47400 | best_bleu 28.26
2023-08-24 01:20:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 47400 updates
2023-08-24 01:20:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7509.pt
2023-08-24 01:20:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7509.pt
2023-08-24 01:20:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint.best_bleu_27.7509.pt (epoch 40 @ 47400 updates, score 27.75) (writing took 6.97699106100481 seconds)
2023-08-24 01:20:57 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-08-24 01:20:57 | INFO | train | epoch 040 | loss 1.754 | trans_loss 4.566 | nll_loss 1.679 | w2v_ctc_loss 0.475 | task_loss 2.346 | contrastive_loss 0 | total 6703.69 | n_correct 4929.25 | ppl 3.2 | accuracy 73.53 | wps 17734.7 | ups 1.32 | wpb 13407.4 | bsz 452.1 | num_updates 47400 | lr 6.4957e-05 | gnorm 0.386 | clip 0 | loss_scale 128 | train_wall 844 | gb_free 12.3 | wall 38843
2023-08-24 01:20:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-24 01:20:57 | INFO | fairseq.trainer | begin training epoch 41
2023-08-24 01:20:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 01:21:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-24 01:22:17 | INFO | train_inner | epoch 041:    101 / 1191 loss=1.747, trans_loss=4.556, nll_loss=1.666, w2v_ctc_loss=0.469, task_loss=2.301, contrastive_loss=0, total=6725.03, n_correct=4956.67, ppl=3.17, accuracy=73.705, wps=11160.7, ups=0.83, wpb=13450.1, bsz=466.2, num_updates=47500, lr=6.48886e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=72, gb_free=13.3, wall=38923
2023-08-24 01:23:28 | INFO | train_inner | epoch 041:    201 / 1191 loss=1.749, trans_loss=4.558, nll_loss=1.668, w2v_ctc_loss=0.468, task_loss=2.306, contrastive_loss=0, total=6708.89, n_correct=4941.01, ppl=3.18, accuracy=73.649, wps=18921.3, ups=1.41, wpb=13417.8, bsz=455.2, num_updates=47600, lr=6.48204e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=70, gb_free=11.1, wall=38994
2023-08-24 01:24:40 | INFO | train_inner | epoch 041:    301 / 1191 loss=1.744, trans_loss=4.555, nll_loss=1.664, w2v_ctc_loss=0.469, task_loss=2.229, contrastive_loss=0, total=6808.55, n_correct=5032.83, ppl=3.17, accuracy=73.919, wps=18877.8, ups=1.39, wpb=13617.1, bsz=478.1, num_updates=47700, lr=6.47524e-05, gnorm=0.379, clip=0, loss_scale=64, train_wall=72, gb_free=12.5, wall=39066
2023-08-24 01:25:52 | INFO | train_inner | epoch 041:    401 / 1191 loss=1.747, trans_loss=4.558, nll_loss=1.667, w2v_ctc_loss=0.469, task_loss=2.292, contrastive_loss=0, total=6761.53, n_correct=4987.86, ppl=3.18, accuracy=73.768, wps=18922, ups=1.4, wpb=13523.1, bsz=452.2, num_updates=47800, lr=6.46846e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=39138
2023-08-24 01:27:03 | INFO | train_inner | epoch 041:    501 / 1191 loss=1.748, trans_loss=4.56, nll_loss=1.67, w2v_ctc_loss=0.473, task_loss=2.151, contrastive_loss=0, total=6854.45, n_correct=5056.95, ppl=3.18, accuracy=73.776, wps=19165.8, ups=1.4, wpb=13708.9, bsz=478.7, num_updates=47900, lr=6.46171e-05, gnorm=0.382, clip=0, loss_scale=64, train_wall=71, gb_free=6.9, wall=39209
2023-08-24 01:28:15 | INFO | train_inner | epoch 041:    601 / 1191 loss=1.747, trans_loss=4.557, nll_loss=1.665, w2v_ctc_loss=0.463, task_loss=2.433, contrastive_loss=0, total=6674.34, n_correct=4925.01, ppl=3.17, accuracy=73.79, wps=18606.6, ups=1.39, wpb=13348.7, bsz=432.2, num_updates=48000, lr=6.45497e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=39281
2023-08-24 01:28:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 01:28:47 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.901 | trans_loss 5.193 | nll_loss 2.396 | w2v_ctc_loss 1.268 | task_loss 8.553 | contrastive_loss 0 | total 6138.43 | n_correct 4179.43 | ppl 5.26 | accuracy 68.086 | uer 16.024 | wer 17.958 | raw_wer 17.958 | bleu 27.83 | wps 1771.1 | wpb 6138.4 | bsz 201.1 | num_updates 48000 | best_bleu 28.26
2023-08-24 01:28:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48000 updates
2023-08-24 01:28:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_41_48000.pt
2023-08-24 01:28:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_41_48000.pt
2023-08-24 01:28:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_41_48000.pt (epoch 41 @ 48000 updates, score 27.83) (writing took 7.619248628965579 seconds)
2023-08-24 01:30:06 | INFO | train_inner | epoch 041:    701 / 1191 loss=1.756, trans_loss=4.565, nll_loss=1.677, w2v_ctc_loss=0.482, task_loss=2.382, contrastive_loss=0, total=6651.81, n_correct=4891.67, ppl=3.2, accuracy=73.539, wps=11949.4, ups=0.9, wpb=13303.6, bsz=448.6, num_updates=48100, lr=6.44826e-05, gnorm=0.39, clip=0, loss_scale=64, train_wall=70, gb_free=14, wall=39392
2023-08-24 01:31:17 | INFO | train_inner | epoch 041:    801 / 1191 loss=1.755, trans_loss=4.567, nll_loss=1.679, w2v_ctc_loss=0.476, task_loss=2.525, contrastive_loss=0, total=6568.67, n_correct=4826.79, ppl=3.2, accuracy=73.482, wps=18456.9, ups=1.4, wpb=13137.3, bsz=427.8, num_updates=48200, lr=6.44157e-05, gnorm=0.389, clip=0, loss_scale=64, train_wall=71, gb_free=13.6, wall=39464
2023-08-24 01:32:30 | INFO | train_inner | epoch 041:    901 / 1191 loss=1.759, trans_loss=4.569, nll_loss=1.683, w2v_ctc_loss=0.479, task_loss=2.493, contrastive_loss=0, total=6623.57, n_correct=4865.92, ppl=3.21, accuracy=73.464, wps=18316.1, ups=1.38, wpb=13247.1, bsz=432.8, num_updates=48300, lr=6.43489e-05, gnorm=0.391, clip=0, loss_scale=64, train_wall=72, gb_free=12.5, wall=39536
2023-08-24 01:33:42 | INFO | train_inner | epoch 041:   1001 / 1191 loss=1.751, trans_loss=4.568, nll_loss=1.682, w2v_ctc_loss=0.471, task_loss=2.296, contrastive_loss=0, total=6733.48, n_correct=4948.81, ppl=3.21, accuracy=73.496, wps=18761.6, ups=1.39, wpb=13467, bsz=463.5, num_updates=48400, lr=6.42824e-05, gnorm=0.385, clip=0, loss_scale=64, train_wall=71, gb_free=12.5, wall=39608
2023-08-24 01:34:53 | INFO | train_inner | epoch 041:   1101 / 1191 loss=1.75, trans_loss=4.57, nll_loss=1.684, w2v_ctc_loss=0.468, task_loss=2.27, contrastive_loss=0, total=6782.07, n_correct=4989.34, ppl=3.21, accuracy=73.567, wps=18893.8, ups=1.39, wpb=13564.1, bsz=465.7, num_updates=48500, lr=6.42161e-05, gnorm=0.381, clip=0, loss_scale=64, train_wall=71, gb_free=12.9, wall=39679
2023-08-24 01:35:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 01:36:30 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.893 | trans_loss 5.181 | nll_loss 2.384 | w2v_ctc_loss 1.273 | task_loss 8.583 | contrastive_loss 0 | total 6138.43 | n_correct 4182.71 | ppl 5.22 | accuracy 68.14 | uer 16.067 | wer 17.966 | raw_wer 17.966 | bleu 27.47 | wps 1777.2 | wpb 6138.4 | bsz 201.1 | num_updates 48590 | best_bleu 28.26
2023-08-24 01:36:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48590 updates
2023-08-24 01:36:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 01:36:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 01:36:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 41 @ 48590 updates, score 27.47) (writing took 6.5317765939980745 seconds)
2023-08-24 01:36:37 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-08-24 01:36:37 | INFO | train | epoch 041 | loss 1.751 | trans_loss 4.563 | nll_loss 1.674 | w2v_ctc_loss 0.472 | task_loss 2.348 | contrastive_loss 0 | total 6702.75 | n_correct 4935.12 | ppl 3.19 | accuracy 73.628 | wps 16970.8 | ups 1.27 | wpb 13405.5 | bsz 451.7 | num_updates 48590 | lr 6.41566e-05 | gnorm 0.387 | clip 0 | loss_scale 64 | train_wall 845 | gb_free 11.5 | wall 39783
2023-08-24 01:36:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-24 01:36:37 | INFO | fairseq.trainer | begin training epoch 42
2023-08-24 01:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 01:36:52 | INFO | train_inner | epoch 042:     10 / 1191 loss=1.758, trans_loss=4.57, nll_loss=1.683, w2v_ctc_loss=0.475, task_loss=2.537, contrastive_loss=0, total=6558.92, n_correct=4814.65, ppl=3.21, accuracy=73.406, wps=11041.8, ups=0.84, wpb=13117.8, bsz=420.2, num_updates=48600, lr=6.415e-05, gnorm=0.395, clip=0, loss_scale=64, train_wall=71, gb_free=13.7, wall=39798
2023-08-24 01:37:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-24 01:38:04 | INFO | train_inner | epoch 042:    111 / 1191 loss=1.739, trans_loss=4.546, nll_loss=1.653, w2v_ctc_loss=0.464, task_loss=2.126, contrastive_loss=0, total=6848.63, n_correct=5068.44, ppl=3.14, accuracy=74.007, wps=19073.6, ups=1.39, wpb=13697.3, bsz=485.4, num_updates=48700, lr=6.40841e-05, gnorm=0.381, clip=0, loss_scale=32, train_wall=71, gb_free=14.7, wall=39870
2023-08-24 01:39:16 | INFO | train_inner | epoch 042:    211 / 1191 loss=1.745, trans_loss=4.552, nll_loss=1.659, w2v_ctc_loss=0.467, task_loss=2.359, contrastive_loss=0, total=6705.86, n_correct=4953.71, ppl=3.16, accuracy=73.871, wps=18638.6, ups=1.39, wpb=13411.7, bsz=451.4, num_updates=48800, lr=6.40184e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=71, gb_free=11.6, wall=39942
2023-08-24 01:40:27 | INFO | train_inner | epoch 042:    311 / 1191 loss=1.747, trans_loss=4.551, nll_loss=1.659, w2v_ctc_loss=0.473, task_loss=2.388, contrastive_loss=0, total=6622.69, n_correct=4890.07, ppl=3.16, accuracy=73.838, wps=18539.5, ups=1.4, wpb=13245.4, bsz=446.1, num_updates=48900, lr=6.39529e-05, gnorm=0.393, clip=0, loss_scale=32, train_wall=71, gb_free=14.7, wall=40013
2023-08-24 01:41:39 | INFO | train_inner | epoch 042:    411 / 1191 loss=1.75, trans_loss=4.56, nll_loss=1.67, w2v_ctc_loss=0.47, task_loss=2.554, contrastive_loss=0, total=6597.65, n_correct=4863.53, ppl=3.18, accuracy=73.716, wps=18367.5, ups=1.39, wpb=13195.3, bsz=431.6, num_updates=49000, lr=6.38877e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=71, gb_free=14.9, wall=40085
2023-08-24 01:42:51 | INFO | train_inner | epoch 042:    511 / 1191 loss=1.757, trans_loss=4.565, nll_loss=1.676, w2v_ctc_loss=0.479, task_loss=2.577, contrastive_loss=0, total=6630.44, n_correct=4878.19, ppl=3.2, accuracy=73.573, wps=18403.7, ups=1.39, wpb=13260.9, bsz=422.1, num_updates=49100, lr=6.38226e-05, gnorm=0.396, clip=0, loss_scale=32, train_wall=71, gb_free=12.6, wall=40157
2023-08-24 01:44:03 | INFO | train_inner | epoch 042:    611 / 1191 loss=1.752, trans_loss=4.564, nll_loss=1.676, w2v_ctc_loss=0.475, task_loss=2.374, contrastive_loss=0, total=6690.98, n_correct=4924.65, ppl=3.19, accuracy=73.601, wps=18785.4, ups=1.4, wpb=13382, bsz=450.4, num_updates=49200, lr=6.37577e-05, gnorm=0.389, clip=0, loss_scale=32, train_wall=71, gb_free=12.8, wall=40229
2023-08-24 01:45:14 | INFO | train_inner | epoch 042:    711 / 1191 loss=1.74, trans_loss=4.556, nll_loss=1.666, w2v_ctc_loss=0.458, task_loss=2.152, contrastive_loss=0, total=6798.54, n_correct=5020.57, ppl=3.17, accuracy=73.848, wps=19054.1, ups=1.4, wpb=13597.1, bsz=477, num_updates=49300, lr=6.3693e-05, gnorm=0.386, clip=0, loss_scale=32, train_wall=71, gb_free=14.1, wall=40300
2023-08-24 01:46:26 | INFO | train_inner | epoch 042:    811 / 1191 loss=1.748, trans_loss=4.564, nll_loss=1.676, w2v_ctc_loss=0.469, task_loss=2.291, contrastive_loss=0, total=6694.42, n_correct=4932.22, ppl=3.2, accuracy=73.677, wps=18688.9, ups=1.4, wpb=13388.8, bsz=459.4, num_updates=49400, lr=6.36285e-05, gnorm=0.39, clip=0, loss_scale=32, train_wall=71, gb_free=12.2, wall=40372
2023-08-24 01:47:37 | INFO | train_inner | epoch 042:    911 / 1191 loss=1.751, trans_loss=4.56, nll_loss=1.671, w2v_ctc_loss=0.473, task_loss=2.513, contrastive_loss=0, total=6513.3, n_correct=4793.78, ppl=3.18, accuracy=73.6, wps=18321.4, ups=1.41, wpb=13026.6, bsz=429.7, num_updates=49500, lr=6.35642e-05, gnorm=0.398, clip=0, loss_scale=32, train_wall=70, gb_free=13.7, wall=40443
2023-08-24 01:48:49 | INFO | train_inner | epoch 042:   1011 / 1191 loss=1.743, trans_loss=4.558, nll_loss=1.67, w2v_ctc_loss=0.461, task_loss=2.149, contrastive_loss=0, total=6851.68, n_correct=5050.47, ppl=3.18, accuracy=73.711, wps=19066, ups=1.39, wpb=13703.4, bsz=480.3, num_updates=49600, lr=6.35001e-05, gnorm=0.38, clip=0, loss_scale=32, train_wall=71, gb_free=12.5, wall=40515
2023-08-24 01:49:59 | INFO | train_inner | epoch 042:   1111 / 1191 loss=1.754, trans_loss=4.566, nll_loss=1.678, w2v_ctc_loss=0.474, task_loss=2.475, contrastive_loss=0, total=6686.05, n_correct=4917.75, ppl=3.2, accuracy=73.552, wps=18869.3, ups=1.41, wpb=13372.1, bsz=430.2, num_updates=49700, lr=6.34361e-05, gnorm=0.392, clip=0, loss_scale=32, train_wall=70, gb_free=13.3, wall=40585
2023-08-24 01:50:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 01:51:30 | INFO | dev_st | epoch 042 | valid on 'dev_st' subset | loss 3.899 | trans_loss 5.187 | nll_loss 2.391 | w2v_ctc_loss 1.277 | task_loss 8.59 | contrastive_loss 0 | total 6138.43 | n_correct 4173.57 | ppl 5.25 | accuracy 67.991 | uer 16.327 | wer 18.144 | raw_wer 18.144 | bleu 27.25 | wps 1759.6 | wpb 6138.4 | bsz 201.1 | num_updates 49780 | best_bleu 28.26
2023-08-24 01:51:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 49780 updates
2023-08-24 01:51:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 01:51:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt
2023-08-24 01:51:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_last.pt (epoch 42 @ 49780 updates, score 27.25) (writing took 6.738337463932112 seconds)
2023-08-24 01:51:37 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-08-24 01:51:37 | INFO | train | epoch 042 | loss 1.748 | trans_loss 4.559 | nll_loss 1.669 | w2v_ctc_loss 0.469 | task_loss 2.345 | contrastive_loss 0 | total 6704.81 | n_correct 4943.29 | ppl 3.18 | accuracy 73.727 | wps 17730 | ups 1.32 | wpb 13409.6 | bsz 452.3 | num_updates 49780 | lr 6.33852e-05 | gnorm 0.389 | clip 0 | loss_scale 32 | train_wall 844 | gb_free 11.1 | wall 40683
2023-08-24 01:51:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-24 01:51:37 | INFO | fairseq.trainer | begin training epoch 43
2023-08-24 01:51:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-24 01:51:59 | INFO | train_inner | epoch 043:     20 / 1191 loss=1.747, trans_loss=4.562, nll_loss=1.674, w2v_ctc_loss=0.466, task_loss=2.22, contrastive_loss=0, total=6840.31, n_correct=5042.34, ppl=3.19, accuracy=73.715, wps=11415.8, ups=0.83, wpb=13680.6, bsz=474.3, num_updates=49800, lr=6.33724e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=72, gb_free=12.7, wall=40705
2023-08-24 01:53:10 | INFO | train_inner | epoch 043:    120 / 1191 loss=1.737, trans_loss=4.538, nll_loss=1.642, w2v_ctc_loss=0.461, task_loss=2.362, contrastive_loss=0, total=6690.13, n_correct=4965.54, ppl=3.12, accuracy=74.222, wps=18780.5, ups=1.4, wpb=13380.3, bsz=441.2, num_updates=49900, lr=6.33089e-05, gnorm=0.385, clip=0, loss_scale=32, train_wall=70, gb_free=12.3, wall=40777
2023-08-24 01:54:22 | INFO | train_inner | epoch 043:    220 / 1191 loss=1.745, trans_loss=4.549, nll_loss=1.655, w2v_ctc_loss=0.468, task_loss=2.465, contrastive_loss=0, total=6640.49, n_correct=4913.73, ppl=3.15, accuracy=73.996, wps=18454, ups=1.39, wpb=13281, bsz=433.9, num_updates=50000, lr=6.32456e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=71, gb_free=13.9, wall=40849
2023-08-24 01:54:22 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-24 01:54:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-24 01:54:55 | INFO | dev_st | epoch 043 | valid on 'dev_st' subset | loss 3.924 | trans_loss 5.192 | nll_loss 2.396 | w2v_ctc_loss 1.348 | task_loss 8.562 | contrastive_loss 0 | total 6138.43 | n_correct 4188.29 | ppl 5.26 | accuracy 68.231 | uer 16.252 | wer 17.999 | raw_wer 17.999 | bleu 27.32 | wps 1721.5 | wpb 6138.4 | bsz 201.1 | num_updates 50000 | best_bleu 28.26
2023-08-24 01:54:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 50000 updates
2023-08-24 01:54:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_43_50000.pt
2023-08-24 01:54:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_43_50000.pt
2023-08-24 01:55:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_large_0822_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5/checkpoint_43_50000.pt (epoch 43 @ 50000 updates, score 27.32) (writing took 6.802448728005402 seconds)
2023-08-24 01:55:03 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-08-24 01:55:03 | INFO | train | epoch 043 | loss 1.741 | trans_loss 4.544 | nll_loss 1.65 | w2v_ctc_loss 0.464 | task_loss 2.379 | contrastive_loss 0 | total 6687.5 | n_correct 4954.27 | ppl 3.14 | accuracy 74.083 | wps 14302.8 | ups 1.07 | wpb 13375 | bsz 443.7 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.386 | clip 0 | loss_scale 32 | train_wall 156 | gb_free 13.9 | wall 40889
2023-08-24 01:55:03 | INFO | fairseq_cli.train | done training in 40811.9 seconds
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1680 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
