2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12770
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12770
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12770
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12770
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12770
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12770
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12770
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12770
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-31 09:42:50 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-31 09:42:50 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-31 09:42:54 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12770', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enes_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-31 09:42:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-31 09:42:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-31 09:42:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-31 09:42:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-31 09:42:54 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
2023-08-31 09:42:58 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-31 09:42:58 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enes_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-31 09:42:58 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-31 09:43:00 | INFO | root | load pretrained hubert
2023-08-31 09:43:07 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
2023-08-31 09:43:10 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt
2023-08-31 09:43:16 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt
2023-08-31 09:43:16 | INFO | root | share the sematic adapter and textual encoder
2023-08-31 09:43:16 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-31 09:43:16 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-31 09:43:16 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-31 09:43:16 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-31 09:43:16 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-31 09:43:16 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-31 09:43:16 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-31 09:43:16 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-31 09:43:17 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-31 09:43:17 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1312, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-31 09:43:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-31 09:43:33 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-31 09:43:33 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-31 09:43:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-31 09:43:33 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 09:43:33 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 09:43:33 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 09:43:33 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 09:43:33 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 09:43:33 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 09:43:33 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 09:43:33 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-31 09:43:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-31 09:43:33 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-31 09:43:33 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-31 09:43:33 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_last.pt
2023-08-31 09:43:33 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_last.pt
2023-08-31 09:43:33 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-31 09:43:33 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-31 09:43:33 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-31 09:43:33 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enes_lcrm/sentencepiece.bpe.model'}
2023-08-31 09:43:35 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=260049, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-31 09:43:38 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=260049, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-31 09:44:27 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-31 09:44:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 09:44:27 | INFO | fairseq.trainer | begin training epoch 1
2023-08-31 09:44:27 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
2023-08-31 09:44:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
True False
None None None
2023-08-31 09:44:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
2023-08-31 09:45:37 | INFO | train_inner | epoch 001:    102 / 1826 loss=17.957, trans_loss=5.725, nll_loss=4.568, w2v_ctc_loss=23.234, task_loss=5.582, contrastive_loss=0, total=3940, n_correct=63.9, ppl=23.72, accuracy=1.622, wps=20220.1, ups=1.71, wpb=11837.1, bsz=400.3, num_updates=100, lr=4.098e-06, gnorm=3.665, clip=0, loss_scale=32, train_wall=62, gb_free=19, wall=123
2023-08-31 09:46:34 | INFO | train_inner | epoch 001:    202 / 1826 loss=12.997, trans_loss=5.742, nll_loss=4.614, w2v_ctc_loss=15.592, task_loss=4.552, contrastive_loss=0, total=4000.63, n_correct=63.18, ppl=24.49, accuracy=1.579, wps=20804.4, ups=1.73, wpb=12045.3, bsz=454.7, num_updates=200, lr=8.096e-06, gnorm=8.415, clip=33, loss_scale=32, train_wall=57, gb_free=19.6, wall=181
2023-08-31 09:47:33 | INFO | train_inner | epoch 001:    302 / 1826 loss=7.205, trans_loss=5.704, nll_loss=4.59, w2v_ctc_loss=6.714, task_loss=4.261, contrastive_loss=0, total=3981.48, n_correct=63.34, ppl=24.08, accuracy=1.591, wps=20591.1, ups=1.72, wpb=11963.3, bsz=445.6, num_updates=300, lr=1.2094e-05, gnorm=1.331, clip=0, loss_scale=32, train_wall=57, gb_free=18.6, wall=239
2023-08-31 09:48:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 09:48:32 | INFO | train_inner | epoch 001:    403 / 1826 loss=6.742, trans_loss=5.61, nll_loss=4.502, w2v_ctc_loss=6.092, task_loss=4.007, contrastive_loss=0, total=4007.21, n_correct=83.28, ppl=22.65, accuracy=2.078, wps=20446, ups=1.7, wpb=12059.5, bsz=431.7, num_updates=400, lr=1.6092e-05, gnorm=0.613, clip=0, loss_scale=16, train_wall=58, gb_free=19.7, wall=298
2023-08-31 09:49:30 | INFO | train_inner | epoch 001:    503 / 1826 loss=6.493, trans_loss=5.543, nll_loss=4.423, w2v_ctc_loss=5.778, task_loss=3.616, contrastive_loss=0, total=3994.6, n_correct=81.44, ppl=21.44, accuracy=2.039, wps=20713.5, ups=1.72, wpb=12013, bsz=442.9, num_updates=500, lr=2.009e-05, gnorm=0.44, clip=0, loss_scale=16, train_wall=57, gb_free=19.1, wall=356
2023-08-31 09:50:27 | INFO | train_inner | epoch 001:    603 / 1826 loss=6.344, trans_loss=5.524, nll_loss=4.409, w2v_ctc_loss=5.569, task_loss=3.677, contrastive_loss=0, total=3946.86, n_correct=98.11, ppl=21.25, accuracy=2.486, wps=20533.3, ups=1.73, wpb=11872, bsz=424.9, num_updates=600, lr=2.4088e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=57, gb_free=18.5, wall=414
2023-08-31 09:51:25 | INFO | train_inner | epoch 001:    703 / 1826 loss=6.044, trans_loss=5.521, nll_loss=4.401, w2v_ctc_loss=5.114, task_loss=3.432, contrastive_loss=0, total=3953.79, n_correct=104.01, ppl=21.13, accuracy=2.631, wps=20706.4, ups=1.74, wpb=11877.7, bsz=431.2, num_updates=700, lr=2.8086e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=471
2023-08-31 09:52:23 | INFO | train_inner | epoch 001:    803 / 1826 loss=5.79, trans_loss=5.515, nll_loss=4.399, w2v_ctc_loss=4.727, task_loss=3.47, contrastive_loss=0, total=3973.13, n_correct=88.23, ppl=21.1, accuracy=2.221, wps=20594.1, ups=1.72, wpb=11951.9, bsz=428.7, num_updates=800, lr=3.2084e-05, gnorm=0.726, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=529
2023-08-31 09:53:20 | INFO | train_inner | epoch 001:    903 / 1826 loss=5.582, trans_loss=5.522, nll_loss=4.408, w2v_ctc_loss=4.399, task_loss=3.322, contrastive_loss=0, total=3998.85, n_correct=98.69, ppl=21.23, accuracy=2.468, wps=20867.4, ups=1.73, wpb=12033.4, bsz=439.4, num_updates=900, lr=3.6082e-05, gnorm=0.898, clip=0, loss_scale=16, train_wall=57, gb_free=19.1, wall=587
2023-08-31 09:54:19 | INFO | train_inner | epoch 001:   1003 / 1826 loss=5.45, trans_loss=5.538, nll_loss=4.421, w2v_ctc_loss=4.179, task_loss=3.187, contrastive_loss=0, total=3988.93, n_correct=99.55, ppl=21.42, accuracy=2.496, wps=20665.1, ups=1.72, wpb=12000.5, bsz=449.7, num_updates=1000, lr=4.008e-05, gnorm=0.91, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=645
2023-08-31 09:55:17 | INFO | train_inner | epoch 001:   1103 / 1826 loss=5.372, trans_loss=5.56, nll_loss=4.445, w2v_ctc_loss=4.03, task_loss=3.62, contrastive_loss=0, total=3947.12, n_correct=101.81, ppl=21.78, accuracy=2.579, wps=20456.4, ups=1.72, wpb=11874.1, bsz=420.8, num_updates=1100, lr=4.4078e-05, gnorm=1.033, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=703
2023-08-31 09:56:14 | INFO | train_inner | epoch 001:   1203 / 1826 loss=5.283, trans_loss=5.57, nll_loss=4.453, w2v_ctc_loss=3.882, task_loss=3.69, contrastive_loss=0, total=3914.85, n_correct=115.3, ppl=21.9, accuracy=2.945, wps=20449.1, ups=1.74, wpb=11775.7, bsz=401.2, num_updates=1200, lr=4.8076e-05, gnorm=1.073, clip=0, loss_scale=16, train_wall=57, gb_free=18.5, wall=761
2023-08-31 09:57:12 | INFO | train_inner | epoch 001:   1303 / 1826 loss=5.195, trans_loss=5.568, nll_loss=4.45, w2v_ctc_loss=3.749, task_loss=3.571, contrastive_loss=0, total=3925.76, n_correct=119.67, ppl=21.85, accuracy=3.048, wps=20506.1, ups=1.74, wpb=11815, bsz=424.1, num_updates=1300, lr=5.2074e-05, gnorm=1.019, clip=0, loss_scale=16, train_wall=57, gb_free=19.2, wall=818
2023-08-31 09:58:09 | INFO | train_inner | epoch 001:   1403 / 1826 loss=5.135, trans_loss=5.575, nll_loss=4.455, w2v_ctc_loss=3.649, task_loss=3.576, contrastive_loss=0, total=3918.07, n_correct=126.16, ppl=21.93, accuracy=3.22, wps=20565.8, ups=1.75, wpb=11779.6, bsz=410.4, num_updates=1400, lr=5.6072e-05, gnorm=1.17, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=876
2023-08-31 09:59:07 | INFO | train_inner | epoch 001:   1503 / 1826 loss=5.056, trans_loss=5.579, nll_loss=4.458, w2v_ctc_loss=3.526, task_loss=3.516, contrastive_loss=0, total=3995.02, n_correct=129.2, ppl=21.98, accuracy=3.234, wps=20628.1, ups=1.72, wpb=12005.7, bsz=425.9, num_updates=1500, lr=6.007e-05, gnorm=1.065, clip=0, loss_scale=16, train_wall=58, gb_free=19.6, wall=934
2023-08-31 10:00:05 | INFO | train_inner | epoch 001:   1603 / 1826 loss=5.003, trans_loss=5.565, nll_loss=4.444, w2v_ctc_loss=3.453, task_loss=3.61, contrastive_loss=0, total=3877.45, n_correct=127.8, ppl=21.77, accuracy=3.296, wps=20118.7, ups=1.72, wpb=11667.5, bsz=409.1, num_updates=1600, lr=6.4068e-05, gnorm=1.073, clip=0, loss_scale=16, train_wall=57, gb_free=19.6, wall=992
2023-08-31 10:01:02 | INFO | train_inner | epoch 001:   1703 / 1826 loss=4.938, trans_loss=5.568, nll_loss=4.449, w2v_ctc_loss=3.354, task_loss=3.399, contrastive_loss=0, total=3947.06, n_correct=130.99, ppl=21.84, accuracy=3.319, wps=20779.5, ups=1.75, wpb=11879.5, bsz=425.7, num_updates=1700, lr=6.8066e-05, gnorm=1.18, clip=0, loss_scale=16, train_wall=57, gb_free=18.7, wall=1049
2023-08-31 10:02:00 | INFO | train_inner | epoch 001:   1803 / 1826 loss=4.889, trans_loss=5.569, nll_loss=4.45, w2v_ctc_loss=3.278, task_loss=3.384, contrastive_loss=0, total=3948.71, n_correct=132.87, ppl=21.85, accuracy=3.365, wps=20782.2, ups=1.75, wpb=11885.2, bsz=430.7, num_updates=1800, lr=7.2064e-05, gnorm=1.038, clip=0, loss_scale=16, train_wall=57, gb_free=18.8, wall=1106
2023-08-31 10:02:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
tensor([5.9605e-08], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 10:03:06 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.448 | trans_loss 12.079 | nll_loss 11.521 | w2v_ctc_loss 4.235 | task_loss 22.626 | contrastive_loss 0 | total 3505.91 | n_correct 178.364 | ppl 2937.84 | accuracy 5.088 | uer 56.353 | wer 55.84 | raw_wer 55.84 | bleu 0 | wps 823.1 | wpb 3505.9 | bsz 119.3 | num_updates 1823
2023-08-31 10:03:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1823 updates
2023-08-31 10:03:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 10:03:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 10:03:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 1 @ 1823 updates, score 0.0) (writing took 3.8863719110086095 seconds)
2023-08-31 10:03:10 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-31 10:03:10 | INFO | train | epoch 001 | loss 6.729 | trans_loss 5.583 | nll_loss 4.463 | w2v_ctc_loss 6.099 | task_loss 3.741 | contrastive_loss 0 | total 3956.53 | n_correct 101.902 | ppl 22.06 | accuracy 2.576 | wps 19509.3 | ups 1.64 | wpb 11900.6 | bsz 427.4 | num_updates 1823 | lr 7.29835e-05 | gnorm 1.476 | clip 1.8 | loss_scale 16 | train_wall 1047 | gb_free 19 | wall 1177
2023-08-31 10:03:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 10:03:10 | INFO | fairseq.trainer | begin training epoch 2
2023-08-31 10:03:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 10:04:06 | INFO | train_inner | epoch 002:     77 / 1826 loss=4.853, trans_loss=5.567, nll_loss=4.446, w2v_ctc_loss=3.22, task_loss=3.489, contrastive_loss=0, total=3877.76, n_correct=130.62, ppl=21.8, accuracy=3.368, wps=9271.4, ups=0.79, wpb=11670.1, bsz=418.5, num_updates=1900, lr=7.6062e-05, gnorm=0.929, clip=0, loss_scale=16, train_wall=57, gb_free=19.4, wall=1232
2023-08-31 10:05:03 | INFO | train_inner | epoch 002:    177 / 1826 loss=4.808, trans_loss=5.567, nll_loss=4.448, w2v_ctc_loss=3.147, task_loss=3.539, contrastive_loss=0, total=3945.55, n_correct=134.48, ppl=21.82, accuracy=3.408, wps=20594.7, ups=1.73, wpb=11878.2, bsz=423.1, num_updates=2000, lr=8.006e-05, gnorm=1.034, clip=0, loss_scale=16, train_wall=57, gb_free=19.5, wall=1290
2023-08-31 10:05:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([5.9605e-08], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 10:05:56 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 9.4 | trans_loss 12.087 | nll_loss 11.533 | w2v_ctc_loss 4.057 | task_loss 22.626 | contrastive_loss 0 | total 3505.91 | n_correct 178.091 | ppl 2963.06 | accuracy 5.08 | uer 54.837 | wer 54.196 | raw_wer 54.196 | bleu 0 | wps 818.7 | wpb 3505.9 | bsz 119.3 | num_updates 2000 | best_bleu 0
2023-08-31 10:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-31 10:05:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_2_2000.pt
2023-08-31 10:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_2_2000.pt
2023-08-31 10:06:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 13.672560328006512 seconds)
2023-08-31 10:07:08 | INFO | train_inner | epoch 002:    277 / 1826 loss=4.753, trans_loss=5.571, nll_loss=4.452, w2v_ctc_loss=3.063, task_loss=3.556, contrastive_loss=0, total=3980.57, n_correct=139.9, ppl=21.88, accuracy=3.515, wps=9601.1, ups=0.8, wpb=11976.8, bsz=426.2, num_updates=2100, lr=8.4058e-05, gnorm=0.965, clip=0, loss_scale=16, train_wall=57, gb_free=18.6, wall=1415
2023-08-31 10:08:05 | INFO | train_inner | epoch 002:    377 / 1826 loss=4.73, trans_loss=5.577, nll_loss=4.458, w2v_ctc_loss=3.025, task_loss=3.441, contrastive_loss=0, total=3951.89, n_correct=134.98, ppl=21.98, accuracy=3.416, wps=20766.2, ups=1.75, wpb=11884.4, bsz=426.5, num_updates=2200, lr=8.8056e-05, gnorm=0.91, clip=0, loss_scale=16, train_wall=57, gb_free=19.3, wall=1472
2023-08-31 10:09:03 | INFO | train_inner | epoch 002:    477 / 1826 loss=4.669, trans_loss=5.578, nll_loss=4.46, w2v_ctc_loss=2.931, task_loss=3.172, contrastive_loss=0, total=3989.48, n_correct=136.7, ppl=22, accuracy=3.427, wps=20888.2, ups=1.74, wpb=11999.9, bsz=452.2, num_updates=2300, lr=9.2054e-05, gnorm=0.953, clip=0, loss_scale=16, train_wall=57, gb_free=19.4, wall=1529
2023-08-31 10:10:00 | INFO | train_inner | epoch 002:    577 / 1826 loss=4.646, trans_loss=5.577, nll_loss=4.459, w2v_ctc_loss=2.897, task_loss=3.248, contrastive_loss=0, total=4010.91, n_correct=139.17, ppl=21.99, accuracy=3.47, wps=20866.4, ups=1.73, wpb=12062.1, bsz=444.2, num_updates=2400, lr=9.6052e-05, gnorm=0.801, clip=0, loss_scale=32, train_wall=57, gb_free=19.2, wall=1587
2023-08-31 10:10:58 | INFO | train_inner | epoch 002:    677 / 1826 loss=4.631, trans_loss=5.555, nll_loss=4.436, w2v_ctc_loss=2.876, task_loss=3.68, contrastive_loss=0, total=3863.36, n_correct=139.34, ppl=21.65, accuracy=3.607, wps=20372, ups=1.75, wpb=11638.9, bsz=397.9, num_updates=2500, lr=0.00010005, gnorm=0.904, clip=0, loss_scale=32, train_wall=56, gb_free=19.4, wall=1644
2023-08-31 10:11:55 | INFO | train_inner | epoch 002:    777 / 1826 loss=4.598, trans_loss=5.571, nll_loss=4.455, w2v_ctc_loss=2.824, task_loss=3.374, contrastive_loss=0, total=3968.04, n_correct=138.24, ppl=21.93, accuracy=3.484, wps=20698.9, ups=1.73, wpb=11939.6, bsz=431.9, num_updates=2600, lr=0.000104048, gnorm=0.881, clip=0, loss_scale=32, train_wall=57, gb_free=19.3, wall=1702
2023-08-31 10:12:54 | INFO | train_inner | epoch 002:    877 / 1826 loss=4.582, trans_loss=5.573, nll_loss=4.458, w2v_ctc_loss=2.796, task_loss=3.312, contrastive_loss=0, total=3980.03, n_correct=135.58, ppl=21.97, accuracy=3.407, wps=20542.2, ups=1.72, wpb=11977.6, bsz=438.8, num_updates=2700, lr=0.000108046, gnorm=0.901, clip=0, loss_scale=32, train_wall=58, gb_free=18.8, wall=1760
2023-08-31 10:13:51 | INFO | train_inner | epoch 002:    977 / 1826 loss=4.566, trans_loss=5.577, nll_loss=4.463, w2v_ctc_loss=2.766, task_loss=3.496, contrastive_loss=0, total=3945.98, n_correct=137.08, ppl=22.05, accuracy=3.474, wps=20655.6, ups=1.74, wpb=11874, bsz=425.1, num_updates=2800, lr=0.000112044, gnorm=0.841, clip=0, loss_scale=32, train_wall=57, gb_free=19.4, wall=1818
2023-08-31 10:14:48 | INFO | train_inner | epoch 002:   1077 / 1826 loss=4.524, trans_loss=5.59, nll_loss=4.476, w2v_ctc_loss=2.697, task_loss=3.289, contrastive_loss=0, total=3979.79, n_correct=134.27, ppl=22.25, accuracy=3.374, wps=20980.7, ups=1.75, wpb=11956.7, bsz=440.4, num_updates=2900, lr=0.000116042, gnorm=0.779, clip=0, loss_scale=32, train_wall=56, gb_free=19.2, wall=1875
2023-08-31 10:15:45 | INFO | train_inner | epoch 002:   1177 / 1826 loss=4.533, trans_loss=5.587, nll_loss=4.472, w2v_ctc_loss=2.702, task_loss=3.776, contrastive_loss=0, total=3887.16, n_correct=134.73, ppl=22.2, accuracy=3.466, wps=20534.9, ups=1.76, wpb=11682, bsz=391.1, num_updates=3000, lr=0.00012004, gnorm=0.769, clip=0, loss_scale=32, train_wall=56, gb_free=18.5, wall=1932
2023-08-31 10:15:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 10:15:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-31 10:17:13 | INFO | train_inner | epoch 002:   1279 / 1826 loss=3.9, trans_loss=4.967, nll_loss=3.671, w2v_ctc_loss=2.386, task_loss=2.495, contrastive_loss=0, total=3929.23, n_correct=339.41, ppl=12.74, accuracy=8.638, wps=13460.4, ups=1.14, wpb=11812.3, bsz=416.9, num_updates=3100, lr=0.000124038, gnorm=1.587, clip=0, loss_scale=8, train_wall=87, gb_free=15.9, wall=2019
2023-08-31 10:18:38 | INFO | train_inner | epoch 002:   1379 / 1826 loss=3.285, trans_loss=4.315, nll_loss=2.801, w2v_ctc_loss=2.135, task_loss=2.278, contrastive_loss=0, total=4014.04, n_correct=956.21, ppl=6.97, accuracy=23.822, wps=14142.1, ups=1.17, wpb=12070.4, bsz=449.7, num_updates=3200, lr=0.000128036, gnorm=1.314, clip=0, loss_scale=8, train_wall=85, gb_free=16.7, wall=2105
2023-08-31 10:20:04 | INFO | train_inner | epoch 002:   1479 / 1826 loss=3.1, trans_loss=4.155, nll_loss=2.594, w2v_ctc_loss=2.018, task_loss=2.273, contrastive_loss=0, total=4011, n_correct=1159.63, ppl=6.04, accuracy=28.911, wps=13991.7, ups=1.16, wpb=12058.4, bsz=450.7, num_updates=3300, lr=0.000132034, gnorm=1.143, clip=0, loss_scale=8, train_wall=86, gb_free=15.5, wall=2191
2023-08-31 10:21:30 | INFO | train_inner | epoch 002:   1579 / 1826 loss=3.042, trans_loss=4.118, nll_loss=2.551, w2v_ctc_loss=1.961, task_loss=2.454, contrastive_loss=0, total=4002.57, n_correct=1201.86, ppl=5.86, accuracy=30.027, wps=13982.8, ups=1.16, wpb=12046, bsz=432, num_updates=3400, lr=0.000136032, gnorm=1.066, clip=0, loss_scale=8, train_wall=86, gb_free=15.7, wall=2277
2023-08-31 10:22:55 | INFO | train_inner | epoch 002:   1679 / 1826 loss=2.973, trans_loss=4.099, nll_loss=2.524, w2v_ctc_loss=1.872, task_loss=2.393, contrastive_loss=0, total=3942.23, n_correct=1206.58, ppl=5.75, accuracy=30.607, wps=14044.9, ups=1.18, wpb=11854.9, bsz=424.3, num_updates=3500, lr=0.00014003, gnorm=0.978, clip=0, loss_scale=8, train_wall=84, gb_free=17.5, wall=2361
2023-08-31 10:24:20 | INFO | train_inner | epoch 002:   1779 / 1826 loss=2.948, trans_loss=4.094, nll_loss=2.516, w2v_ctc_loss=1.841, task_loss=2.597, contrastive_loss=0, total=3960.82, n_correct=1224.68, ppl=5.72, accuracy=30.92, wps=13913.5, ups=1.17, wpb=11899.2, bsz=411.9, num_updates=3600, lr=0.000144028, gnorm=1.039, clip=0, loss_scale=8, train_wall=85, gb_free=16.7, wall=2447
2023-08-31 10:25:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([1.7881e-07], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 10:25:40 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 5.845 | trans_loss 7.668 | nll_loss 5.701 | w2v_ctc_loss 2.181 | task_loss 12.382 | contrastive_loss 0 | total 3505.91 | n_correct 1082.27 | ppl 52 | accuracy 30.87 | uer 32.159 | wer 32.699 | raw_wer 32.699 | bleu 0.27 | wps 1122.2 | wpb 3505.9 | bsz 119.3 | num_updates 3647 | best_bleu 0.27
2023-08-31 10:25:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 3647 updates
2023-08-31 10:25:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 10:25:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 10:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 2 @ 3647 updates, score 0.27) (writing took 12.505813523006509 seconds)
2023-08-31 10:25:53 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-31 10:25:53 | INFO | train | epoch 002 | loss 4.132 | trans_loss 5.113 | nll_loss 3.852 | w2v_ctc_loss 2.59 | task_loss 3.078 | contrastive_loss 0 | total 3956.32 | n_correct 452.288 | ppl 14.44 | accuracy 11.432 | wps 15921.6 | ups 1.34 | wpb 11900 | bsz 427.2 | num_updates 3647 | lr 0.000145907 | gnorm 0.987 | clip 0 | loss_scale 8 | train_wall 1221 | gb_free 16.4 | wall 2540
2023-08-31 10:25:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 10:25:53 | INFO | fairseq.trainer | begin training epoch 3
2023-08-31 10:25:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 10:26:46 | INFO | train_inner | epoch 003:     53 / 1826 loss=2.907, trans_loss=4.074, nll_loss=2.492, w2v_ctc_loss=1.79, task_loss=2.534, contrastive_loss=0, total=3870.82, n_correct=1210.15, ppl=5.63, accuracy=31.263, wps=7994.8, ups=0.69, wpb=11638.8, bsz=402.1, num_updates=3700, lr=0.000148026, gnorm=0.96, clip=0, loss_scale=8, train_wall=84, gb_free=14.5, wall=2593
2023-08-31 10:28:10 | INFO | train_inner | epoch 003:    153 / 1826 loss=2.853, trans_loss=4.06, nll_loss=2.477, w2v_ctc_loss=1.718, task_loss=2.286, contrastive_loss=0, total=3972.92, n_correct=1248.72, ppl=5.57, accuracy=31.431, wps=14210.6, ups=1.19, wpb=11959.8, bsz=442.8, num_updates=3800, lr=0.000152024, gnorm=0.913, clip=0, loss_scale=8, train_wall=83, gb_free=14.9, wall=2677
2023-08-31 10:29:36 | INFO | train_inner | epoch 003:    253 / 1826 loss=2.846, trans_loss=4.061, nll_loss=2.477, w2v_ctc_loss=1.71, task_loss=2.351, contrastive_loss=0, total=3987.3, n_correct=1260.27, ppl=5.57, accuracy=31.607, wps=13987.1, ups=1.17, wpb=11991.7, bsz=436.4, num_updates=3900, lr=0.000156022, gnorm=0.966, clip=0, loss_scale=8, train_wall=85, gb_free=14.6, wall=2762
2023-08-31 10:31:01 | INFO | train_inner | epoch 003:    353 / 1826 loss=2.804, trans_loss=4.058, nll_loss=2.471, w2v_ctc_loss=1.654, task_loss=2.165, contrastive_loss=0, total=4052.04, n_correct=1287.42, ppl=5.55, accuracy=31.772, wps=14233.7, ups=1.17, wpb=12182.4, bsz=465.3, num_updates=4000, lr=0.00016002, gnorm=0.937, clip=0, loss_scale=8, train_wall=85, gb_free=15.4, wall=2848
2023-08-31 10:31:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([5.9605e-08], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 10:31:41 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.801 | trans_loss 7.627 | nll_loss 5.649 | w2v_ctc_loss 2.127 | task_loss 12.42 | contrastive_loss 0 | total 3505.91 | n_correct 1103.73 | ppl 50.18 | accuracy 31.482 | uer 30.576 | wer 31.022 | raw_wer 31.022 | bleu 0.22 | wps 1157.9 | wpb 3505.9 | bsz 119.3 | num_updates 4000 | best_bleu 0.27
2023-08-31 10:31:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-31 10:31:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_3_4000.pt
2023-08-31 10:31:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_3_4000.pt
2023-08-31 10:31:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 0.22) (writing took 7.163791062004748 seconds)
2023-08-31 10:33:13 | INFO | train_inner | epoch 003:    453 / 1826 loss=2.814, trans_loss=4.059, nll_loss=2.473, w2v_ctc_loss=1.665, task_loss=2.456, contrastive_loss=0, total=3933.57, n_correct=1245.91, ppl=5.55, accuracy=31.674, wps=8997.1, ups=0.76, wpb=11831.1, bsz=421.1, num_updates=4100, lr=0.000164018, gnorm=0.934, clip=0, loss_scale=8, train_wall=84, gb_free=14.8, wall=2980
2023-08-31 10:34:39 | INFO | train_inner | epoch 003:    553 / 1826 loss=2.797, trans_loss=4.051, nll_loss=2.465, w2v_ctc_loss=1.649, task_loss=2.413, contrastive_loss=0, total=3955.37, n_correct=1264.54, ppl=5.52, accuracy=31.97, wps=13782.9, ups=1.16, wpb=11905.2, bsz=436.9, num_updates=4200, lr=0.000168016, gnorm=0.915, clip=0, loss_scale=8, train_wall=86, gb_free=16.3, wall=3066
2023-08-31 10:36:04 | INFO | train_inner | epoch 003:    653 / 1826 loss=2.769, trans_loss=4.043, nll_loss=2.455, w2v_ctc_loss=1.612, task_loss=2.243, contrastive_loss=0, total=4015.46, n_correct=1294.08, ppl=5.48, accuracy=32.227, wps=14281, ups=1.18, wpb=12085.4, bsz=446.4, num_updates=4300, lr=0.000172014, gnorm=0.877, clip=0, loss_scale=8, train_wall=84, gb_free=16, wall=3151
2023-08-31 10:37:29 | INFO | train_inner | epoch 003:    753 / 1826 loss=2.776, trans_loss=4.04, nll_loss=2.451, w2v_ctc_loss=1.625, task_loss=2.431, contrastive_loss=0, total=3965.92, n_correct=1280.15, ppl=5.47, accuracy=32.279, wps=14021.6, ups=1.18, wpb=11932.5, bsz=425.4, num_updates=4400, lr=0.000176012, gnorm=0.893, clip=0, loss_scale=8, train_wall=85, gb_free=11.5, wall=3236
2023-08-31 10:38:54 | INFO | train_inner | epoch 003:    853 / 1826 loss=2.757, trans_loss=4.048, nll_loss=2.458, w2v_ctc_loss=1.587, task_loss=2.556, contrastive_loss=0, total=3923.6, n_correct=1260.46, ppl=5.49, accuracy=32.125, wps=13828.4, ups=1.17, wpb=11793.5, bsz=409.8, num_updates=4500, lr=0.00018001, gnorm=0.853, clip=0, loss_scale=8, train_wall=85, gb_free=14.6, wall=3321
2023-08-31 10:40:19 | INFO | train_inner | epoch 003:    953 / 1826 loss=2.735, trans_loss=4.027, nll_loss=2.435, w2v_ctc_loss=1.567, task_loss=2.4, contrastive_loss=0, total=3981, n_correct=1285.17, ppl=5.41, accuracy=32.283, wps=14125.3, ups=1.18, wpb=11981, bsz=429.9, num_updates=4600, lr=0.000184008, gnorm=0.824, clip=0, loss_scale=8, train_wall=84, gb_free=16.3, wall=3406
2023-08-31 10:41:45 | INFO | train_inner | epoch 003:   1053 / 1826 loss=2.734, trans_loss=4.034, nll_loss=2.441, w2v_ctc_loss=1.568, task_loss=2.39, contrastive_loss=0, total=3974.74, n_correct=1290.68, ppl=5.43, accuracy=32.472, wps=13984, ups=1.17, wpb=11951.6, bsz=435.6, num_updates=4700, lr=0.000188006, gnorm=0.869, clip=0, loss_scale=8, train_wall=85, gb_free=15.6, wall=3491
2023-08-31 10:43:11 | INFO | train_inner | epoch 003:   1153 / 1826 loss=2.715, trans_loss=4.03, nll_loss=2.437, w2v_ctc_loss=1.537, task_loss=2.561, contrastive_loss=0, total=3906.86, n_correct=1269.14, ppl=5.42, accuracy=32.485, wps=13660.7, ups=1.16, wpb=11755.5, bsz=407, num_updates=4800, lr=0.000192004, gnorm=0.822, clip=0, loss_scale=8, train_wall=85, gb_free=12.7, wall=3577
2023-08-31 10:44:36 | INFO | train_inner | epoch 003:   1253 / 1826 loss=2.711, trans_loss=4.034, nll_loss=2.441, w2v_ctc_loss=1.534, task_loss=2.461, contrastive_loss=0, total=3999.95, n_correct=1304.62, ppl=5.43, accuracy=32.616, wps=14121, ups=1.17, wpb=12025.1, bsz=427.4, num_updates=4900, lr=0.000196002, gnorm=0.825, clip=0, loss_scale=8, train_wall=85, gb_free=14.8, wall=3662
2023-08-31 10:46:01 | INFO | train_inner | epoch 003:   1353 / 1826 loss=2.704, trans_loss=4.031, nll_loss=2.437, w2v_ctc_loss=1.521, task_loss=2.615, contrastive_loss=0, total=3932.16, n_correct=1281.74, ppl=5.42, accuracy=32.596, wps=13960.2, ups=1.18, wpb=11824.6, bsz=404.8, num_updates=5000, lr=0.0002, gnorm=0.814, clip=0, loss_scale=8, train_wall=84, gb_free=15.8, wall=3747
mt_weight tensor(0.5000)
asr_weight tensor(0.3230, device='cuda:0')
2023-08-31 10:47:24 | INFO | train_inner | epoch 003:   1453 / 1826 loss=2.687, trans_loss=4.021, nll_loss=2.424, w2v_ctc_loss=1.506, task_loss=2.451, contrastive_loss=0, total=3859.8, n_correct=1264.16, ppl=5.37, accuracy=32.752, wps=13839.3, ups=1.19, wpb=11609, bsz=414.4, num_updates=5100, lr=0.00019803, gnorm=0.479, clip=0, loss_scale=16, train_wall=83, gb_free=16.4, wall=3831
2023-08-31 10:47:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-31 10:48:50 | INFO | train_inner | epoch 003:   1554 / 1826 loss=2.702, trans_loss=4.028, nll_loss=2.435, w2v_ctc_loss=1.526, task_loss=2.57, contrastive_loss=0, total=3905.64, n_correct=1275.42, ppl=5.41, accuracy=32.656, wps=13699.3, ups=1.17, wpb=11751.4, bsz=404.5, num_updates=5200, lr=0.000196116, gnorm=0.445, clip=0, loss_scale=8, train_wall=85, gb_free=16.9, wall=3917
2023-08-31 10:49:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-31 10:50:16 | INFO | train_inner | epoch 003:   1655 / 1826 loss=2.682, trans_loss=4.021, nll_loss=2.425, w2v_ctc_loss=1.501, task_loss=2.474, contrastive_loss=0, total=3920.14, n_correct=1291.46, ppl=5.37, accuracy=32.944, wps=13702.6, ups=1.16, wpb=11792.2, bsz=421.2, num_updates=5300, lr=0.000194257, gnorm=0.441, clip=0, loss_scale=4, train_wall=85, gb_free=16.6, wall=4003
2023-08-31 10:51:41 | INFO | train_inner | epoch 003:   1755 / 1826 loss=2.657, trans_loss=4.012, nll_loss=2.412, w2v_ctc_loss=1.473, task_loss=2.318, contrastive_loss=0, total=3976.28, n_correct=1322.38, ppl=5.32, accuracy=33.257, wps=14102.4, ups=1.18, wpb=11954.2, bsz=443.5, num_updates=5400, lr=0.00019245, gnorm=0.441, clip=0, loss_scale=4, train_wall=84, gb_free=17.1, wall=4088
2023-08-31 10:52:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.3230, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.3230, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.3230, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.3230, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.3230, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.3230, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.3230, device='cuda:1')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 10:53:21 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.559 | trans_loss 7.475 | nll_loss 5.454 | w2v_ctc_loss 1.663 | task_loss 13.216 | contrastive_loss 0 | total 3505.91 | n_correct 1149.55 | ppl 43.85 | accuracy 32.789 | uer 25.138 | wer 26.796 | raw_wer 26.796 | bleu 0.29 | wps 1128.3 | wpb 3505.9 | bsz 119.3 | num_updates 5471 | best_bleu 0.29
2023-08-31 10:53:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 5471 updates
2023-08-31 10:53:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 10:53:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 10:53:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 3 @ 5471 updates, score 0.29) (writing took 12.202396298991516 seconds)
2023-08-31 10:53:33 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-31 10:53:33 | INFO | train | epoch 003 | loss 2.752 | trans_loss 4.039 | nll_loss 2.448 | w2v_ctc_loss 1.588 | task_loss 2.421 | contrastive_loss 0 | total 3954.74 | n_correct 1277.28 | ppl 5.46 | accuracy 32.297 | wps 13070.4 | ups 1.1 | wpb 11895.4 | bsz 426.6 | num_updates 5471 | lr 0.000191197 | gnorm 0.772 | clip 0 | loss_scale 4 | train_wall 1541 | gb_free 17 | wall 4200
2023-08-31 10:53:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 10:53:33 | INFO | fairseq.trainer | begin training epoch 4
2023-08-31 10:53:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 10:54:06 | INFO | train_inner | epoch 004:     29 / 1826 loss=2.674, trans_loss=4.011, nll_loss=2.41, w2v_ctc_loss=1.497, task_loss=2.396, contrastive_loss=0, total=3985.85, n_correct=1319.16, ppl=5.32, accuracy=33.096, wps=8296, ups=0.69, wpb=11983.7, bsz=427.7, num_updates=5500, lr=0.000190693, gnorm=0.477, clip=0, loss_scale=4, train_wall=84, gb_free=16.4, wall=4232
2023-08-31 10:55:30 | INFO | train_inner | epoch 004:    129 / 1826 loss=2.623, trans_loss=3.991, nll_loss=2.387, w2v_ctc_loss=1.433, task_loss=2.436, contrastive_loss=0, total=3968.21, n_correct=1333.02, ppl=5.23, accuracy=33.592, wps=14185.1, ups=1.19, wpb=11944.7, bsz=429.4, num_updates=5600, lr=0.000188982, gnorm=0.447, clip=0, loss_scale=4, train_wall=84, gb_free=15.9, wall=4316
2023-08-31 10:56:55 | INFO | train_inner | epoch 004:    229 / 1826 loss=2.606, trans_loss=3.986, nll_loss=2.379, w2v_ctc_loss=1.415, task_loss=2.312, contrastive_loss=0, total=3995.38, n_correct=1356.12, ppl=5.2, accuracy=33.942, wps=14165.8, ups=1.18, wpb=12013.3, bsz=438.5, num_updates=5700, lr=0.000187317, gnorm=0.437, clip=0, loss_scale=4, train_wall=84, gb_free=15.9, wall=4401
2023-08-31 10:58:19 | INFO | train_inner | epoch 004:    329 / 1826 loss=2.619, trans_loss=3.981, nll_loss=2.372, w2v_ctc_loss=1.439, task_loss=2.296, contrastive_loss=0, total=3975.24, n_correct=1349.52, ppl=5.18, accuracy=33.948, wps=14128.4, ups=1.18, wpb=11951.3, bsz=443.6, num_updates=5800, lr=0.000185695, gnorm=0.492, clip=0, loss_scale=4, train_wall=84, gb_free=16.5, wall=4486
2023-08-31 10:59:45 | INFO | train_inner | epoch 004:    429 / 1826 loss=2.621, trans_loss=3.974, nll_loss=2.363, w2v_ctc_loss=1.44, task_loss=2.385, contrastive_loss=0, total=3984.44, n_correct=1360.07, ppl=5.14, accuracy=34.135, wps=14019.7, ups=1.17, wpb=11979.5, bsz=433.6, num_updates=5900, lr=0.000184115, gnorm=0.495, clip=0, loss_scale=4, train_wall=85, gb_free=16.4, wall=4571
2023-08-31 11:01:10 | INFO | train_inner | epoch 004:    529 / 1826 loss=2.598, trans_loss=3.979, nll_loss=2.37, w2v_ctc_loss=1.407, task_loss=2.495, contrastive_loss=0, total=3916.27, n_correct=1332.25, ppl=5.17, accuracy=34.018, wps=13742.8, ups=1.17, wpb=11777.7, bsz=421.6, num_updates=6000, lr=0.000182574, gnorm=0.45, clip=0, loss_scale=4, train_wall=85, gb_free=16.3, wall=4657
2023-08-31 11:01:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 11:01:49 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.529 | trans_loss 7.411 | nll_loss 5.364 | w2v_ctc_loss 1.704 | task_loss 13.171 | contrastive_loss 0 | total 3505.91 | n_correct 1186.73 | ppl 41.18 | accuracy 33.849 | uer 25.245 | wer 26.875 | raw_wer 26.875 | bleu 0.46 | wps 1192.5 | wpb 3505.9 | bsz 119.3 | num_updates 6000 | best_bleu 0.46
2023-08-31 11:01:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 6000 updates
2023-08-31 11:01:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_4_6000.pt
2023-08-31 11:01:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_4_6000.pt
2023-08-31 11:02:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_4_6000.pt (epoch 4 @ 6000 updates, score 0.46) (writing took 14.538367226006812 seconds)
2023-08-31 11:03:28 | INFO | train_inner | epoch 004:    629 / 1826 loss=2.597, trans_loss=3.981, nll_loss=2.369, w2v_ctc_loss=1.411, task_loss=2.347, contrastive_loss=0, total=4013.62, n_correct=1378.64, ppl=5.17, accuracy=34.349, wps=8781.8, ups=0.73, wpb=12059.1, bsz=438.2, num_updates=6100, lr=0.000181071, gnorm=0.445, clip=0, loss_scale=4, train_wall=83, gb_free=16.5, wall=4794
2023-08-31 11:04:53 | INFO | train_inner | epoch 004:    729 / 1826 loss=2.588, trans_loss=3.962, nll_loss=2.352, w2v_ctc_loss=1.405, task_loss=2.613, contrastive_loss=0, total=3910.43, n_correct=1342.83, ppl=5.1, accuracy=34.34, wps=13820.5, ups=1.17, wpb=11776.9, bsz=405.2, num_updates=6200, lr=0.000179605, gnorm=0.453, clip=0, loss_scale=4, train_wall=85, gb_free=17.5, wall=4879
2023-08-31 11:06:19 | INFO | train_inner | epoch 004:    829 / 1826 loss=2.569, trans_loss=3.953, nll_loss=2.335, w2v_ctc_loss=1.39, task_loss=2.25, contrastive_loss=0, total=4018.4, n_correct=1409.99, ppl=5.05, accuracy=35.088, wps=14016.5, ups=1.16, wpb=12083.9, bsz=452, num_updates=6300, lr=0.000178174, gnorm=0.44, clip=0, loss_scale=4, train_wall=86, gb_free=12.2, wall=4966
2023-08-31 11:07:44 | INFO | train_inner | epoch 004:    929 / 1826 loss=2.59, trans_loss=3.961, nll_loss=2.346, w2v_ctc_loss=1.417, task_loss=2.437, contrastive_loss=0, total=3972.03, n_correct=1387.44, ppl=5.09, accuracy=34.93, wps=14057.7, ups=1.18, wpb=11943.3, bsz=432.5, num_updates=6400, lr=0.000176777, gnorm=0.495, clip=0, loss_scale=4, train_wall=84, gb_free=14.1, wall=5051
2023-08-31 11:09:09 | INFO | train_inner | epoch 004:   1029 / 1826 loss=2.581, trans_loss=3.951, nll_loss=2.333, w2v_ctc_loss=1.407, task_loss=2.501, contrastive_loss=0, total=3921.06, n_correct=1369.07, ppl=5.04, accuracy=34.916, wps=13940.4, ups=1.18, wpb=11792.9, bsz=414.7, num_updates=6500, lr=0.000175412, gnorm=0.487, clip=0, loss_scale=4, train_wall=84, gb_free=17.2, wall=5135
2023-08-31 11:10:34 | INFO | train_inner | epoch 004:   1129 / 1826 loss=2.58, trans_loss=3.946, nll_loss=2.327, w2v_ctc_loss=1.406, task_loss=2.657, contrastive_loss=0, total=3911.31, n_correct=1371.49, ppl=5.02, accuracy=35.065, wps=13823.3, ups=1.17, wpb=11765.2, bsz=397, num_updates=6600, lr=0.000174078, gnorm=0.498, clip=0, loss_scale=4, train_wall=84, gb_free=17.4, wall=5220
2023-08-31 11:11:59 | INFO | train_inner | epoch 004:   1229 / 1826 loss=2.558, trans_loss=3.938, nll_loss=2.315, w2v_ctc_loss=1.387, task_loss=2.459, contrastive_loss=0, total=3976.2, n_correct=1415.62, ppl=4.98, accuracy=35.602, wps=14094.5, ups=1.18, wpb=11952.7, bsz=423.4, num_updates=6700, lr=0.000172774, gnorm=0.509, clip=0, loss_scale=4, train_wall=84, gb_free=16.3, wall=5305
2023-08-31 11:13:24 | INFO | train_inner | epoch 004:   1329 / 1826 loss=2.569, trans_loss=3.936, nll_loss=2.314, w2v_ctc_loss=1.407, task_loss=2.607, contrastive_loss=0, total=3851.45, n_correct=1370.94, ppl=4.97, accuracy=35.595, wps=13601, ups=1.17, wpb=11581, bsz=397.9, num_updates=6800, lr=0.000171499, gnorm=0.512, clip=0, loss_scale=4, train_wall=84, gb_free=16.7, wall=5390
2023-08-31 11:14:48 | INFO | train_inner | epoch 004:   1429 / 1826 loss=2.548, trans_loss=3.924, nll_loss=2.299, w2v_ctc_loss=1.393, task_loss=2.276, contrastive_loss=0, total=3977.92, n_correct=1439.97, ppl=4.92, accuracy=36.199, wps=14137, ups=1.18, wpb=11964.6, bsz=450.4, num_updates=6900, lr=0.000170251, gnorm=0.523, clip=0, loss_scale=4, train_wall=84, gb_free=15.9, wall=5475
2023-08-31 11:16:13 | INFO | train_inner | epoch 004:   1529 / 1826 loss=2.533, trans_loss=3.912, nll_loss=2.285, w2v_ctc_loss=1.378, task_loss=2.269, contrastive_loss=0, total=4016.81, n_correct=1468.36, ppl=4.87, accuracy=36.555, wps=14225.8, ups=1.18, wpb=12091.4, bsz=454.6, num_updates=7000, lr=0.000169031, gnorm=0.479, clip=0, loss_scale=4, train_wall=84, gb_free=15.7, wall=5560
2023-08-31 11:17:39 | INFO | train_inner | epoch 004:   1629 / 1826 loss=2.533, trans_loss=3.904, nll_loss=2.274, w2v_ctc_loss=1.383, task_loss=2.411, contrastive_loss=0, total=3952, n_correct=1452.22, ppl=4.84, accuracy=36.746, wps=13910, ups=1.17, wpb=11891.4, bsz=425.3, num_updates=7100, lr=0.000167836, gnorm=0.509, clip=0, loss_scale=4, train_wall=85, gb_free=16.3, wall=5645
2023-08-31 11:19:02 | INFO | train_inner | epoch 004:   1729 / 1826 loss=2.532, trans_loss=3.908, nll_loss=2.279, w2v_ctc_loss=1.382, task_loss=2.589, contrastive_loss=0, total=3873.19, n_correct=1421.82, ppl=4.85, accuracy=36.709, wps=13952.2, ups=1.2, wpb=11660, bsz=399.1, num_updates=7200, lr=0.000166667, gnorm=0.467, clip=0, loss_scale=4, train_wall=83, gb_free=17.4, wall=5729
2023-08-31 11:20:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 11:21:03 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.284 | trans_loss 7.102 | nll_loss 4.962 | w2v_ctc_loss 1.589 | task_loss 13.218 | contrastive_loss 0 | total 3505.91 | n_correct 1325.45 | ppl 31.16 | accuracy 37.806 | uer 23.848 | wer 25.625 | raw_wer 25.625 | bleu 2.09 | wps 1186.3 | wpb 3505.9 | bsz 119.3 | num_updates 7297 | best_bleu 2.09
2023-08-31 11:21:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 7297 updates
2023-08-31 11:21:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 11:21:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 11:21:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 4 @ 7297 updates, score 2.09) (writing took 12.727204486000119 seconds)
2023-08-31 11:21:17 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-31 11:21:17 | INFO | train | epoch 004 | loss 2.577 | trans_loss 3.95 | nll_loss 2.332 | w2v_ctc_loss 1.405 | task_loss 2.425 | contrastive_loss 0 | total 3956.37 | n_correct 1390.13 | ppl 5.04 | accuracy 35.137 | wps 13063.5 | ups 1.1 | wpb 11900.1 | bsz 427.2 | num_updates 7297 | lr 0.000165555 | gnorm 0.48 | clip 0 | loss_scale 4 | train_wall 1538 | gb_free 16.8 | wall 5863
2023-08-31 11:21:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 11:21:17 | INFO | fairseq.trainer | begin training epoch 5
2023-08-31 11:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 11:21:26 | INFO | train_inner | epoch 005:      3 / 1826 loss=2.512, trans_loss=3.895, nll_loss=2.261, w2v_ctc_loss=1.365, task_loss=2.469, contrastive_loss=0, total=3929.35, n_correct=1465.45, ppl=4.79, accuracy=37.295, wps=8214.8, ups=0.7, wpb=11819.2, bsz=419.2, num_updates=7300, lr=0.000165521, gnorm=0.495, clip=0, loss_scale=4, train_wall=84, gb_free=15.1, wall=5873
2023-08-31 11:22:50 | INFO | train_inner | epoch 005:    103 / 1826 loss=2.462, trans_loss=3.862, nll_loss=2.216, w2v_ctc_loss=1.313, task_loss=2.327, contrastive_loss=0, total=3932.1, n_correct=1505.28, ppl=4.65, accuracy=38.282, wps=14107.9, ups=1.19, wpb=11821.8, bsz=440.1, num_updates=7400, lr=0.000164399, gnorm=0.492, clip=0, loss_scale=8, train_wall=83, gb_free=16.1, wall=5957
2023-08-31 11:24:14 | INFO | train_inner | epoch 005:    203 / 1826 loss=2.46, trans_loss=3.854, nll_loss=2.21, w2v_ctc_loss=1.322, task_loss=2.251, contrastive_loss=0, total=3985.54, n_correct=1542.87, ppl=4.63, accuracy=38.712, wps=14284, ups=1.19, wpb=11997.6, bsz=449.5, num_updates=7500, lr=0.000163299, gnorm=0.509, clip=0, loss_scale=8, train_wall=83, gb_free=16.5, wall=6041
2023-08-31 11:24:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-31 11:25:39 | INFO | train_inner | epoch 005:    304 / 1826 loss=2.469, trans_loss=3.852, nll_loss=2.203, w2v_ctc_loss=1.334, task_loss=2.467, contrastive_loss=0, total=3960.62, n_correct=1534.72, ppl=4.6, accuracy=38.749, wps=13976.4, ups=1.17, wpb=11908, bsz=421.8, num_updates=7600, lr=0.000162221, gnorm=0.485, clip=0, loss_scale=4, train_wall=85, gb_free=16.5, wall=6126
2023-08-31 11:27:04 | INFO | train_inner | epoch 005:    404 / 1826 loss=2.477, trans_loss=3.845, nll_loss=2.196, w2v_ctc_loss=1.355, task_loss=2.545, contrastive_loss=0, total=3937.75, n_correct=1537.96, ppl=4.58, accuracy=39.057, wps=13899.2, ups=1.17, wpb=11843.6, bsz=413.3, num_updates=7700, lr=0.000161165, gnorm=0.496, clip=0, loss_scale=4, train_wall=85, gb_free=14.9, wall=6211
2023-08-31 11:28:30 | INFO | train_inner | epoch 005:    504 / 1826 loss=2.422, trans_loss=3.811, nll_loss=2.155, w2v_ctc_loss=1.301, task_loss=2.328, contrastive_loss=0, total=3982.86, n_correct=1594.79, ppl=4.45, accuracy=40.041, wps=14068.5, ups=1.17, wpb=11992.6, bsz=446.7, num_updates=7800, lr=0.000160128, gnorm=0.513, clip=0, loss_scale=4, train_wall=85, gb_free=16.1, wall=6296
2023-08-31 11:29:55 | INFO | train_inner | epoch 005:    604 / 1826 loss=2.435, trans_loss=3.813, nll_loss=2.154, w2v_ctc_loss=1.325, task_loss=2.485, contrastive_loss=0, total=3964.35, n_correct=1601.1, ppl=4.45, accuracy=40.387, wps=14020.7, ups=1.18, wpb=11924.1, bsz=421.7, num_updates=7900, lr=0.000159111, gnorm=0.557, clip=0, loss_scale=4, train_wall=84, gb_free=16.4, wall=6381
2023-08-31 11:31:19 | INFO | train_inner | epoch 005:    704 / 1826 loss=2.426, trans_loss=3.794, nll_loss=2.13, w2v_ctc_loss=1.329, task_loss=2.569, contrastive_loss=0, total=3884.31, n_correct=1601.29, ppl=4.38, accuracy=41.225, wps=13883, ups=1.19, wpb=11686.5, bsz=407.4, num_updates=8000, lr=0.000158114, gnorm=0.556, clip=0, loss_scale=4, train_wall=83, gb_free=16.7, wall=6466
2023-08-31 11:31:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 11:31:59 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.051 | trans_loss 6.732 | nll_loss 4.472 | w2v_ctc_loss 1.646 | task_loss 13.325 | contrastive_loss 0 | total 3505.91 | n_correct 1516.18 | ppl 22.19 | accuracy 43.246 | uer 23.121 | wer 24.856 | raw_wer 24.856 | bleu 5.71 | wps 1152.2 | wpb 3505.9 | bsz 119.3 | num_updates 8000 | best_bleu 5.71
2023-08-31 11:31:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 8000 updates
2023-08-31 11:31:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_5_8000.pt
2023-08-31 11:32:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_5_8000.pt
2023-08-31 11:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_5_8000.pt (epoch 5 @ 8000 updates, score 5.71) (writing took 11.594635376997758 seconds)
2023-08-31 11:33:35 | INFO | train_inner | epoch 005:    804 / 1826 loss=2.426, trans_loss=3.78, nll_loss=2.11, w2v_ctc_loss=1.34, task_loss=2.627, contrastive_loss=0, total=3876.66, n_correct=1625.23, ppl=4.32, accuracy=41.923, wps=8575.2, ups=0.74, wpb=11660.1, bsz=403.9, num_updates=8100, lr=0.000157135, gnorm=0.568, clip=0, loss_scale=4, train_wall=84, gb_free=16.1, wall=6602
2023-08-31 11:34:59 | INFO | train_inner | epoch 005:    904 / 1826 loss=2.393, trans_loss=3.75, nll_loss=2.074, w2v_ctc_loss=1.33, task_loss=2.321, contrastive_loss=0, total=4004.14, n_correct=1737.39, ppl=4.21, accuracy=43.39, wps=14261.2, ups=1.18, wpb=12054.4, bsz=445.8, num_updates=8200, lr=0.000156174, gnorm=0.553, clip=0, loss_scale=4, train_wall=84, gb_free=17.2, wall=6686
2023-08-31 11:36:24 | INFO | train_inner | epoch 005:   1004 / 1826 loss=2.383, trans_loss=3.729, nll_loss=2.044, w2v_ctc_loss=1.335, task_loss=2.484, contrastive_loss=0, total=3995.32, n_correct=1773.04, ppl=4.12, accuracy=44.378, wps=14181.5, ups=1.18, wpb=12020.1, bsz=425.6, num_updates=8300, lr=0.00015523, gnorm=0.559, clip=0, loss_scale=4, train_wall=84, gb_free=16.2, wall=6771
2023-08-31 11:37:49 | INFO | train_inner | epoch 005:   1104 / 1826 loss=2.362, trans_loss=3.699, nll_loss=2.004, w2v_ctc_loss=1.34, task_loss=2.321, contrastive_loss=0, total=3962.38, n_correct=1815.59, ppl=4.01, accuracy=45.821, wps=14024.9, ups=1.18, wpb=11917.5, bsz=447.3, num_updates=8400, lr=0.000154303, gnorm=0.625, clip=0, loss_scale=4, train_wall=84, gb_free=16.1, wall=6856
2023-08-31 11:39:15 | INFO | train_inner | epoch 005:   1204 / 1826 loss=2.338, trans_loss=3.675, nll_loss=1.972, w2v_ctc_loss=1.329, task_loss=2.613, contrastive_loss=0, total=3916.75, n_correct=1831.22, ppl=3.92, accuracy=46.754, wps=13678.6, ups=1.16, wpb=11776.4, bsz=406, num_updates=8500, lr=0.000153393, gnorm=0.593, clip=0, loss_scale=4, train_wall=85, gb_free=15.6, wall=6942
2023-08-31 11:40:40 | INFO | train_inner | epoch 005:   1304 / 1826 loss=2.311, trans_loss=3.636, nll_loss=1.921, w2v_ctc_loss=1.324, task_loss=2.36, contrastive_loss=0, total=3978.72, n_correct=1923.48, ppl=3.79, accuracy=48.344, wps=14195.3, ups=1.19, wpb=11965.4, bsz=433.5, num_updates=8600, lr=0.000152499, gnorm=0.59, clip=0, loss_scale=4, train_wall=84, gb_free=15, wall=7026
2023-08-31 11:42:04 | INFO | train_inner | epoch 005:   1404 / 1826 loss=2.304, trans_loss=3.623, nll_loss=1.903, w2v_ctc_loss=1.331, task_loss=2.386, contrastive_loss=0, total=3981.04, n_correct=1963.28, ppl=3.74, accuracy=49.316, wps=14192.2, ups=1.19, wpb=11963.1, bsz=429.3, num_updates=8700, lr=0.00015162, gnorm=0.594, clip=0, loss_scale=4, train_wall=84, gb_free=16.6, wall=7110
2023-08-31 11:43:29 | INFO | train_inner | epoch 005:   1504 / 1826 loss=2.29, trans_loss=3.591, nll_loss=1.864, w2v_ctc_loss=1.34, task_loss=2.534, contrastive_loss=0, total=3937.22, n_correct=1985.28, ppl=3.64, accuracy=50.423, wps=13899.8, ups=1.17, wpb=11847.9, bsz=414, num_updates=8800, lr=0.000150756, gnorm=0.57, clip=0, loss_scale=4, train_wall=85, gb_free=15.3, wall=7196
2023-08-31 11:44:55 | INFO | train_inner | epoch 005:   1604 / 1826 loss=2.26, trans_loss=3.564, nll_loss=1.828, w2v_ctc_loss=1.325, task_loss=2.357, contrastive_loss=0, total=4001.21, n_correct=2068.47, ppl=3.55, accuracy=51.696, wps=14067.6, ups=1.17, wpb=12033.7, bsz=430, num_updates=8900, lr=0.000149906, gnorm=0.516, clip=0, loss_scale=4, train_wall=85, gb_free=16.5, wall=7281
2023-08-31 11:46:19 | INFO | train_inner | epoch 005:   1704 / 1826 loss=2.244, trans_loss=3.554, nll_loss=1.813, w2v_ctc_loss=1.316, task_loss=2.348, contrastive_loss=0, total=3999.89, n_correct=2100.16, ppl=3.51, accuracy=52.505, wps=14182.3, ups=1.18, wpb=12016.4, bsz=431.6, num_updates=9000, lr=0.000149071, gnorm=0.521, clip=0, loss_scale=4, train_wall=84, gb_free=15.5, wall=7366
2023-08-31 11:47:44 | INFO | train_inner | epoch 005:   1804 / 1826 loss=2.22, trans_loss=3.529, nll_loss=1.783, w2v_ctc_loss=1.304, task_loss=2.326, contrastive_loss=0, total=3997.09, n_correct=2127.48, ppl=3.44, accuracy=53.226, wps=14181.9, ups=1.18, wpb=12018.6, bsz=442.5, num_updates=9100, lr=0.00014825, gnorm=0.544, clip=0, loss_scale=4, train_wall=84, gb_free=16, wall=7451
2023-08-31 11:48:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 11:48:42 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.328 | trans_loss 5.727 | nll_loss 3.157 | w2v_ctc_loss 1.502 | task_loss 13.316 | contrastive_loss 0 | total 3505.91 | n_correct 2036.45 | ppl 8.92 | accuracy 58.086 | uer 22.675 | wer 24.409 | raw_wer 24.409 | bleu 19.85 | wps 1152.6 | wpb 3505.9 | bsz 119.3 | num_updates 9122 | best_bleu 19.85
2023-08-31 11:48:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 9122 updates
2023-08-31 11:48:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 11:48:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 11:48:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 5 @ 9122 updates, score 19.85) (writing took 12.737299407002865 seconds)
2023-08-31 11:48:55 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-31 11:48:55 | INFO | train | epoch 005 | loss 2.37 | trans_loss 3.718 | nll_loss 2.029 | w2v_ctc_loss 1.327 | task_loss 2.427 | contrastive_loss 0 | total 3956.4 | n_correct 1771.69 | ppl 4.08 | accuracy 44.78 | wps 13097.1 | ups 1.1 | wpb 11900.2 | bsz 427.2 | num_updates 9122 | lr 0.000148071 | gnorm 0.546 | clip 0 | loss_scale 4 | train_wall 1535 | gb_free 17.1 | wall 7521
2023-08-31 11:48:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 11:48:55 | INFO | fairseq.trainer | begin training epoch 6
2023-08-31 11:48:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 11:50:08 | INFO | train_inner | epoch 006:     78 / 1826 loss=2.174, trans_loss=3.496, nll_loss=1.741, w2v_ctc_loss=1.258, task_loss=2.491, contrastive_loss=0, total=3898.11, n_correct=2118.31, ppl=3.34, accuracy=54.342, wps=8158.5, ups=0.7, wpb=11726.7, bsz=413, num_updates=9200, lr=0.000147442, gnorm=0.498, clip=0, loss_scale=4, train_wall=83, gb_free=15.7, wall=7595
2023-08-31 11:51:34 | INFO | train_inner | epoch 006:    178 / 1826 loss=2.187, trans_loss=3.491, nll_loss=1.733, w2v_ctc_loss=1.285, task_loss=2.573, contrastive_loss=0, total=3953.57, n_correct=2161.01, ppl=3.32, accuracy=54.66, wps=13788.4, ups=1.16, wpb=11890.2, bsz=415, num_updates=9300, lr=0.000146647, gnorm=0.54, clip=0, loss_scale=4, train_wall=86, gb_free=17.2, wall=7681
2023-08-31 11:52:59 | INFO | train_inner | epoch 006:    278 / 1826 loss=2.176, trans_loss=3.476, nll_loss=1.716, w2v_ctc_loss=1.283, task_loss=2.554, contrastive_loss=0, total=3921.02, n_correct=2165.27, ppl=3.29, accuracy=55.222, wps=13903.8, ups=1.18, wpb=11798.2, bsz=410.9, num_updates=9400, lr=0.000145865, gnorm=0.511, clip=0, loss_scale=4, train_wall=84, gb_free=16.8, wall=7766
2023-08-31 11:54:24 | INFO | train_inner | epoch 006:    378 / 1826 loss=2.155, trans_loss=3.452, nll_loss=1.686, w2v_ctc_loss=1.27, task_loss=2.381, contrastive_loss=0, total=3977.69, n_correct=2232.75, ppl=3.22, accuracy=56.132, wps=14087.3, ups=1.18, wpb=11972.5, bsz=437.6, num_updates=9500, lr=0.000145095, gnorm=0.493, clip=0, loss_scale=4, train_wall=84, gb_free=14.4, wall=7851
2023-08-31 11:55:48 | INFO | train_inner | epoch 006:    478 / 1826 loss=2.149, trans_loss=3.447, nll_loss=1.678, w2v_ctc_loss=1.272, task_loss=2.559, contrastive_loss=0, total=3925.99, n_correct=2212.58, ppl=3.2, accuracy=56.357, wps=14010.5, ups=1.19, wpb=11811.9, bsz=412.5, num_updates=9600, lr=0.000144338, gnorm=0.489, clip=0, loss_scale=8, train_wall=84, gb_free=17.4, wall=7935
2023-08-31 11:57:14 | INFO | train_inner | epoch 006:    578 / 1826 loss=2.141, trans_loss=3.446, nll_loss=1.675, w2v_ctc_loss=1.264, task_loss=2.441, contrastive_loss=0, total=3961.06, n_correct=2248.88, ppl=3.19, accuracy=56.775, wps=13959.5, ups=1.17, wpb=11910, bsz=424.8, num_updates=9700, lr=0.000143592, gnorm=0.475, clip=0, loss_scale=8, train_wall=85, gb_free=17.6, wall=8020
2023-08-31 11:58:38 | INFO | train_inner | epoch 006:    678 / 1826 loss=2.124, trans_loss=3.425, nll_loss=1.651, w2v_ctc_loss=1.253, task_loss=2.356, contrastive_loss=0, total=3962.11, n_correct=2274.72, ppl=3.14, accuracy=57.412, wps=14077.6, ups=1.18, wpb=11922.3, bsz=431.9, num_updates=9800, lr=0.000142857, gnorm=0.47, clip=0, loss_scale=8, train_wall=84, gb_free=16.9, wall=8105
2023-08-31 12:00:03 | INFO | train_inner | epoch 006:    778 / 1826 loss=2.115, trans_loss=3.421, nll_loss=1.645, w2v_ctc_loss=1.247, task_loss=2.384, contrastive_loss=0, total=3994.23, n_correct=2308.41, ppl=3.13, accuracy=57.794, wps=14219.5, ups=1.18, wpb=12010.9, bsz=435.9, num_updates=9900, lr=0.000142134, gnorm=0.475, clip=0, loss_scale=8, train_wall=84, gb_free=15, wall=8189
2023-08-31 12:01:28 | INFO | train_inner | epoch 006:    878 / 1826 loss=2.111, trans_loss=3.415, nll_loss=1.639, w2v_ctc_loss=1.246, task_loss=2.373, contrastive_loss=0, total=3963.99, n_correct=2296.63, ppl=3.11, accuracy=57.937, wps=14029.4, ups=1.18, wpb=11928, bsz=434.2, num_updates=10000, lr=0.000141421, gnorm=0.465, clip=0, loss_scale=8, train_wall=84, gb_free=17.1, wall=8274
2023-08-31 12:01:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 12:02:07 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.156 | trans_loss 5.453 | nll_loss 2.815 | w2v_ctc_loss 1.548 | task_loss 13.489 | contrastive_loss 0 | total 3505.91 | n_correct 2188 | ppl 7.04 | accuracy 62.409 | uer 21.224 | wer 22.716 | raw_wer 22.716 | bleu 24.1 | wps 1189.4 | wpb 3505.9 | bsz 119.3 | num_updates 10000 | best_bleu 24.1
2023-08-31 12:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 10000 updates
2023-08-31 12:02:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_6_10000.pt
2023-08-31 12:02:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_6_10000.pt
2023-08-31 12:02:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_6_10000.pt (epoch 6 @ 10000 updates, score 24.1) (writing took 13.36797846200352 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:0')
2023-08-31 12:03:44 | INFO | train_inner | epoch 006:    978 / 1826 loss=2.103, trans_loss=3.412, nll_loss=1.632, w2v_ctc_loss=1.241, task_loss=2.292, contrastive_loss=0, total=4004.17, n_correct=2334.38, ppl=3.1, accuracy=58.299, wps=8818.6, ups=0.73, wpb=12032, bsz=444.8, num_updates=10100, lr=0.00014072, gnorm=0.437, clip=0, loss_scale=8, train_wall=83, gb_free=16.3, wall=8411
2023-08-31 12:05:08 | INFO | train_inner | epoch 006:   1078 / 1826 loss=2.103, trans_loss=3.397, nll_loss=1.615, w2v_ctc_loss=1.253, task_loss=2.409, contrastive_loss=0, total=3952.95, n_correct=2320.15, ppl=3.06, accuracy=58.694, wps=14209, ups=1.19, wpb=11893.5, bsz=422.9, num_updates=10200, lr=0.000140028, gnorm=0.449, clip=0, loss_scale=8, train_wall=83, gb_free=16.1, wall=8495
2023-08-31 12:06:32 | INFO | train_inner | epoch 006:   1178 / 1826 loss=2.095, trans_loss=3.397, nll_loss=1.616, w2v_ctc_loss=1.243, task_loss=2.465, contrastive_loss=0, total=3919.76, n_correct=2301.64, ppl=3.06, accuracy=58.719, wps=14010.1, ups=1.19, wpb=11794.6, bsz=423.3, num_updates=10300, lr=0.000139347, gnorm=0.44, clip=0, loss_scale=8, train_wall=84, gb_free=15.3, wall=8579
2023-08-31 12:07:57 | INFO | train_inner | epoch 006:   1278 / 1826 loss=2.089, trans_loss=3.38, nll_loss=1.594, w2v_ctc_loss=1.244, task_loss=2.312, contrastive_loss=0, total=3957.79, n_correct=2339.43, ppl=3.02, accuracy=59.11, wps=14086.5, ups=1.18, wpb=11907.5, bsz=441.4, num_updates=10400, lr=0.000138675, gnorm=0.447, clip=0, loss_scale=8, train_wall=84, gb_free=17.4, wall=8663
2023-08-31 12:09:22 | INFO | train_inner | epoch 006:   1378 / 1826 loss=2.098, trans_loss=3.388, nll_loss=1.602, w2v_ctc_loss=1.251, task_loss=2.594, contrastive_loss=0, total=3937.9, n_correct=2327.72, ppl=3.04, accuracy=59.111, wps=13876.9, ups=1.17, wpb=11838.1, bsz=409.6, num_updates=10500, lr=0.000138013, gnorm=0.462, clip=0, loss_scale=8, train_wall=85, gb_free=16.4, wall=8749
2023-08-31 12:10:47 | INFO | train_inner | epoch 006:   1478 / 1826 loss=2.088, trans_loss=3.386, nll_loss=1.598, w2v_ctc_loss=1.242, task_loss=2.456, contrastive_loss=0, total=3946.83, n_correct=2340.13, ppl=3.03, accuracy=59.291, wps=13924, ups=1.17, wpb=11859.6, bsz=426.1, num_updates=10600, lr=0.000137361, gnorm=0.44, clip=0, loss_scale=8, train_wall=84, gb_free=16.1, wall=8834
2023-08-31 12:12:12 | INFO | train_inner | epoch 006:   1578 / 1826 loss=2.084, trans_loss=3.384, nll_loss=1.598, w2v_ctc_loss=1.237, task_loss=2.516, contrastive_loss=0, total=3944.52, n_correct=2348.94, ppl=3.03, accuracy=59.549, wps=13971.5, ups=1.18, wpb=11859.3, bsz=421.2, num_updates=10700, lr=0.000136717, gnorm=0.457, clip=0, loss_scale=8, train_wall=84, gb_free=15.5, wall=8919
2023-08-31 12:13:37 | INFO | train_inner | epoch 006:   1678 / 1826 loss=2.059, trans_loss=3.367, nll_loss=1.576, w2v_ctc_loss=1.215, task_loss=2.35, contrastive_loss=0, total=3973.29, n_correct=2389.47, ppl=2.98, accuracy=60.138, wps=14136.1, ups=1.18, wpb=11948.7, bsz=433.7, num_updates=10800, lr=0.000136083, gnorm=0.423, clip=0, loss_scale=8, train_wall=84, gb_free=17.1, wall=9003
2023-08-31 12:15:00 | INFO | train_inner | epoch 006:   1778 / 1826 loss=2.072, trans_loss=3.371, nll_loss=1.585, w2v_ctc_loss=1.234, task_loss=2.384, contrastive_loss=0, total=3956.46, n_correct=2371.53, ppl=3, accuracy=59.941, wps=14229.5, ups=1.19, wpb=11909.1, bsz=429.1, num_updates=10900, lr=0.000135457, gnorm=0.427, clip=0, loss_scale=8, train_wall=83, gb_free=15.4, wall=9087
2023-08-31 12:15:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:2')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 12:16:20 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.065 | trans_loss 5.332 | nll_loss 2.659 | w2v_ctc_loss 1.521 | task_loss 13.521 | contrastive_loss 0 | total 3505.91 | n_correct 2253 | ppl 6.32 | accuracy 64.263 | uer 20.991 | wer 22.638 | raw_wer 22.638 | bleu 25.92 | wps 1188.4 | wpb 3505.9 | bsz 119.3 | num_updates 10948 | best_bleu 25.92
2023-08-31 12:16:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 10948 updates
2023-08-31 12:16:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 12:16:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 12:16:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 6 @ 10948 updates, score 25.92) (writing took 11.72584429300332 seconds)
2023-08-31 12:16:32 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-31 12:16:32 | INFO | train | epoch 006 | loss 2.115 | trans_loss 3.417 | nll_loss 1.64 | w2v_ctc_loss 1.251 | task_loss 2.428 | contrastive_loss 0 | total 3956.37 | n_correct 2289.31 | ppl 3.12 | accuracy 57.864 | wps 13114 | ups 1.1 | wpb 11900.1 | bsz 427.2 | num_updates 10948 | lr 0.00013516 | gnorm 0.465 | clip 0 | loss_scale 8 | train_wall 1534 | gb_free 16.6 | wall 9178
2023-08-31 12:16:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 12:16:32 | INFO | fairseq.trainer | begin training epoch 7
2023-08-31 12:16:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 12:17:23 | INFO | train_inner | epoch 007:     52 / 1826 loss=2.06, trans_loss=3.354, nll_loss=1.562, w2v_ctc_loss=1.223, task_loss=2.373, contrastive_loss=0, total=3931.13, n_correct=2372.26, ppl=2.95, accuracy=60.345, wps=8314.8, ups=0.7, wpb=11831.4, bsz=427.9, num_updates=11000, lr=0.00013484, gnorm=0.43, clip=0, loss_scale=8, train_wall=83, gb_free=16.2, wall=9229
2023-08-31 12:18:47 | INFO | train_inner | epoch 007:    152 / 1826 loss=2.026, trans_loss=3.344, nll_loss=1.547, w2v_ctc_loss=1.187, task_loss=2.382, contrastive_loss=0, total=3953.01, n_correct=2404.21, ppl=2.92, accuracy=60.82, wps=14126.9, ups=1.19, wpb=11890.5, bsz=431.4, num_updates=11100, lr=0.000134231, gnorm=0.423, clip=0, loss_scale=8, train_wall=84, gb_free=12.7, wall=9313
2023-08-31 12:20:11 | INFO | train_inner | epoch 007:    252 / 1826 loss=2.043, trans_loss=3.345, nll_loss=1.548, w2v_ctc_loss=1.207, task_loss=2.655, contrastive_loss=0, total=3898.38, n_correct=2370.8, ppl=2.92, accuracy=60.815, wps=13907.8, ups=1.19, wpb=11720.9, bsz=401.6, num_updates=11200, lr=0.000133631, gnorm=0.445, clip=0, loss_scale=8, train_wall=84, gb_free=15.6, wall=9398
2023-08-31 12:21:35 | INFO | train_inner | epoch 007:    352 / 1826 loss=2.021, trans_loss=3.343, nll_loss=1.548, w2v_ctc_loss=1.182, task_loss=2.17, contrastive_loss=0, total=4034.29, n_correct=2460.34, ppl=2.92, accuracy=60.986, wps=14400.4, ups=1.19, wpb=12139.1, bsz=466.5, num_updates=11300, lr=0.000133038, gnorm=0.425, clip=0, loss_scale=8, train_wall=84, gb_free=16.9, wall=9482
2023-08-31 12:22:59 | INFO | train_inner | epoch 007:    452 / 1826 loss=2.02, trans_loss=3.336, nll_loss=1.539, w2v_ctc_loss=1.187, task_loss=2.278, contrastive_loss=0, total=3989.92, n_correct=2443.81, ppl=2.91, accuracy=61.25, wps=14290.7, ups=1.19, wpb=12006.9, bsz=444.5, num_updates=11400, lr=0.000132453, gnorm=0.415, clip=0, loss_scale=8, train_wall=83, gb_free=15.2, wall=9566
2023-08-31 12:24:24 | INFO | train_inner | epoch 007:    552 / 1826 loss=2.029, trans_loss=3.331, nll_loss=1.53, w2v_ctc_loss=1.2, task_loss=2.352, contrastive_loss=0, total=3952.57, n_correct=2431.34, ppl=2.89, accuracy=61.513, wps=14042.7, ups=1.18, wpb=11886.2, bsz=433.2, num_updates=11500, lr=0.000131876, gnorm=0.414, clip=0, loss_scale=8, train_wall=84, gb_free=16.8, wall=9651
2023-08-31 12:25:49 | INFO | train_inner | epoch 007:    652 / 1826 loss=2.015, trans_loss=3.332, nll_loss=1.532, w2v_ctc_loss=1.18, task_loss=2.462, contrastive_loss=0, total=3942.35, n_correct=2419.52, ppl=2.89, accuracy=61.373, wps=13939.7, ups=1.18, wpb=11857.5, bsz=423.7, num_updates=11600, lr=0.000131306, gnorm=0.411, clip=0, loss_scale=8, train_wall=84, gb_free=16.8, wall=9736
2023-08-31 12:27:14 | INFO | train_inner | epoch 007:    752 / 1826 loss=2.006, trans_loss=3.331, nll_loss=1.531, w2v_ctc_loss=1.169, task_loss=2.42, contrastive_loss=0, total=3949.88, n_correct=2435.4, ppl=2.89, accuracy=61.658, wps=14044, ups=1.18, wpb=11876.3, bsz=431.9, num_updates=11700, lr=0.000130744, gnorm=0.414, clip=0, loss_scale=16, train_wall=84, gb_free=15.5, wall=9820
2023-08-31 12:28:38 | INFO | train_inner | epoch 007:    852 / 1826 loss=2.019, trans_loss=3.328, nll_loss=1.527, w2v_ctc_loss=1.189, task_loss=2.599, contrastive_loss=0, total=3930.38, n_correct=2419.02, ppl=2.88, accuracy=61.547, wps=13971.8, ups=1.18, wpb=11820.2, bsz=404.7, num_updates=11800, lr=0.000130189, gnorm=0.41, clip=0, loss_scale=16, train_wall=84, gb_free=11.3, wall=9905
2023-08-31 12:30:03 | INFO | train_inner | epoch 007:    952 / 1826 loss=2.009, trans_loss=3.322, nll_loss=1.52, w2v_ctc_loss=1.179, task_loss=2.312, contrastive_loss=0, total=4048.82, n_correct=2503.49, ppl=2.87, accuracy=61.833, wps=14321.7, ups=1.18, wpb=12177.2, bsz=443.4, num_updates=11900, lr=0.000129641, gnorm=0.415, clip=0, loss_scale=16, train_wall=84, gb_free=15.9, wall=9990
2023-08-31 12:31:28 | INFO | train_inner | epoch 007:   1052 / 1826 loss=2.004, trans_loss=3.315, nll_loss=1.511, w2v_ctc_loss=1.178, task_loss=2.418, contrastive_loss=0, total=3928.57, n_correct=2435.86, ppl=2.85, accuracy=62.004, wps=13974.5, ups=1.18, wpb=11816.1, bsz=424.5, num_updates=12000, lr=0.000129099, gnorm=0.435, clip=0, loss_scale=16, train_wall=84, gb_free=13.8, wall=10075
2023-08-31 12:31:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 12:32:07 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 3.985 | trans_loss 5.254 | nll_loss 2.566 | w2v_ctc_loss 1.425 | task_loss 13.556 | contrastive_loss 0 | total 3505.91 | n_correct 2287.82 | ppl 5.92 | accuracy 65.256 | uer 20.194 | wer 21.864 | raw_wer 21.864 | bleu 27.02 | wps 1168.2 | wpb 3505.9 | bsz 119.3 | num_updates 12000 | best_bleu 27.02
2023-08-31 12:32:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 12000 updates
2023-08-31 12:32:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_7_12000.pt
2023-08-31 12:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_7_12000.pt
2023-08-31 12:32:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_7_12000.pt (epoch 7 @ 12000 updates, score 27.02) (writing took 12.887550875995657 seconds)
2023-08-31 12:33:46 | INFO | train_inner | epoch 007:   1152 / 1826 loss=2.024, trans_loss=3.323, nll_loss=1.523, w2v_ctc_loss=1.204, task_loss=2.621, contrastive_loss=0, total=3932.31, n_correct=2428.99, ppl=2.87, accuracy=61.77, wps=8552.6, ups=0.72, wpb=11834.7, bsz=408.4, num_updates=12100, lr=0.000128565, gnorm=0.415, clip=0, loss_scale=16, train_wall=85, gb_free=15.6, wall=10213
2023-08-31 12:35:11 | INFO | train_inner | epoch 007:   1252 / 1826 loss=2.004, trans_loss=3.321, nll_loss=1.52, w2v_ctc_loss=1.174, task_loss=2.437, contrastive_loss=0, total=3998.13, n_correct=2476.3, ppl=2.87, accuracy=61.936, wps=14190.5, ups=1.18, wpb=12030.8, bsz=433.4, num_updates=12200, lr=0.000128037, gnorm=0.435, clip=0, loss_scale=16, train_wall=84, gb_free=15.9, wall=10298
2023-08-31 12:36:35 | INFO | train_inner | epoch 007:   1352 / 1826 loss=2.007, trans_loss=3.316, nll_loss=1.514, w2v_ctc_loss=1.184, task_loss=2.552, contrastive_loss=0, total=3909.99, n_correct=2423.63, ppl=2.86, accuracy=61.986, wps=13953.5, ups=1.19, wpb=11765, bsz=411.2, num_updates=12300, lr=0.000127515, gnorm=0.413, clip=0, loss_scale=16, train_wall=84, gb_free=15.8, wall=10382
2023-08-31 12:38:01 | INFO | train_inner | epoch 007:   1452 / 1826 loss=2.007, trans_loss=3.321, nll_loss=1.518, w2v_ctc_loss=1.182, task_loss=2.35, contrastive_loss=0, total=3964.82, n_correct=2461.05, ppl=2.86, accuracy=62.072, wps=13996.1, ups=1.17, wpb=11915.6, bsz=435.9, num_updates=12400, lr=0.000127, gnorm=0.433, clip=0, loss_scale=16, train_wall=85, gb_free=17.5, wall=10467
2023-08-31 12:39:26 | INFO | train_inner | epoch 007:   1552 / 1826 loss=1.999, trans_loss=3.316, nll_loss=1.513, w2v_ctc_loss=1.172, task_loss=2.56, contrastive_loss=0, total=3929.01, n_correct=2440.63, ppl=2.85, accuracy=62.118, wps=13913.5, ups=1.18, wpb=11818.4, bsz=413.4, num_updates=12500, lr=0.000126491, gnorm=0.413, clip=0, loss_scale=16, train_wall=84, gb_free=11.7, wall=10552
2023-08-31 12:40:50 | INFO | train_inner | epoch 007:   1652 / 1826 loss=1.978, trans_loss=3.314, nll_loss=1.509, w2v_ctc_loss=1.146, task_loss=2.267, contrastive_loss=0, total=3986.3, n_correct=2485.4, ppl=2.85, accuracy=62.349, wps=14102.9, ups=1.18, wpb=11985.1, bsz=449.1, num_updates=12600, lr=0.000125988, gnorm=0.4, clip=0, loss_scale=16, train_wall=84, gb_free=16, wall=10637
2023-08-31 12:42:15 | INFO | train_inner | epoch 007:   1752 / 1826 loss=2, trans_loss=3.316, nll_loss=1.513, w2v_ctc_loss=1.176, task_loss=2.436, contrastive_loss=0, total=3979.89, n_correct=2475.87, ppl=2.85, accuracy=62.21, wps=14139.3, ups=1.18, wpb=11965.7, bsz=429.8, num_updates=12700, lr=0.000125491, gnorm=0.435, clip=0, loss_scale=16, train_wall=84, gb_free=17.4, wall=10722
2023-08-31 12:43:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 12:43:56 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.218 | nll_loss 2.521 | w2v_ctc_loss 1.409 | task_loss 13.489 | contrastive_loss 0 | total 3505.91 | n_correct 2303.64 | ppl 5.74 | accuracy 65.707 | uer 19.73 | wer 21.579 | raw_wer 21.579 | bleu 27.76 | wps 1199 | wpb 3505.9 | bsz 119.3 | num_updates 12774 | best_bleu 27.76
2023-08-31 12:43:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 12774 updates
2023-08-31 12:43:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 12:44:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 12:44:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 7 @ 12774 updates, score 27.76) (writing took 11.5691126419988 seconds)
2023-08-31 12:44:07 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-31 12:44:08 | INFO | train | epoch 007 | loss 2.013 | trans_loss 3.326 | nll_loss 1.526 | w2v_ctc_loss 1.183 | task_loss 2.431 | contrastive_loss 0 | total 3956.37 | n_correct 2439.38 | ppl 2.88 | accuracy 61.657 | wps 13124.8 | ups 1.1 | wpb 11900.1 | bsz 427.2 | num_updates 12774 | lr 0.000125127 | gnorm 0.421 | clip 0 | loss_scale 16 | train_wall 1533 | gb_free 16.5 | wall 10834
2023-08-31 12:44:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 12:44:08 | INFO | fairseq.trainer | begin training epoch 8
2023-08-31 12:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 12:44:37 | INFO | train_inner | epoch 008:     26 / 1826 loss=1.994, trans_loss=3.304, nll_loss=1.499, w2v_ctc_loss=1.172, task_loss=2.645, contrastive_loss=0, total=3885.49, n_correct=2423.56, ppl=2.83, accuracy=62.375, wps=8245.2, ups=0.71, wpb=11693.8, bsz=401.5, num_updates=12800, lr=0.000125, gnorm=0.428, clip=0, loss_scale=16, train_wall=83, gb_free=9.1, wall=10864
2023-08-31 12:46:01 | INFO | train_inner | epoch 008:    126 / 1826 loss=1.968, trans_loss=3.286, nll_loss=1.476, w2v_ctc_loss=1.145, task_loss=2.486, contrastive_loss=0, total=3955.57, n_correct=2492.1, ppl=2.78, accuracy=63.002, wps=14116, ups=1.19, wpb=11904.6, bsz=420.5, num_updates=12900, lr=0.000124515, gnorm=0.411, clip=0, loss_scale=16, train_wall=84, gb_free=16.9, wall=10948
2023-08-31 12:47:27 | INFO | train_inner | epoch 008:    226 / 1826 loss=1.953, trans_loss=3.281, nll_loss=1.47, w2v_ctc_loss=1.129, task_loss=2.445, contrastive_loss=0, total=3921.96, n_correct=2481.81, ppl=2.77, accuracy=63.28, wps=13816.9, ups=1.17, wpb=11805, bsz=428, num_updates=13000, lr=0.000124035, gnorm=0.409, clip=0, loss_scale=16, train_wall=85, gb_free=15.9, wall=11033
2023-08-31 12:48:51 | INFO | train_inner | epoch 008:    326 / 1826 loss=1.959, trans_loss=3.286, nll_loss=1.475, w2v_ctc_loss=1.133, task_loss=2.578, contrastive_loss=0, total=3887.36, n_correct=2453.51, ppl=2.78, accuracy=63.115, wps=13915.6, ups=1.19, wpb=11693.5, bsz=406.4, num_updates=13100, lr=0.00012356, gnorm=0.402, clip=0, loss_scale=16, train_wall=83, gb_free=11.6, wall=11117
2023-08-31 12:50:16 | INFO | train_inner | epoch 008:    426 / 1826 loss=1.959, trans_loss=3.286, nll_loss=1.475, w2v_ctc_loss=1.131, task_loss=2.568, contrastive_loss=0, total=3929.14, n_correct=2480.95, ppl=2.78, accuracy=63.142, wps=13893.6, ups=1.18, wpb=11818.2, bsz=411.9, num_updates=13200, lr=0.000123091, gnorm=0.407, clip=0, loss_scale=16, train_wall=84, gb_free=15.6, wall=11202
2023-08-31 12:51:42 | INFO | train_inner | epoch 008:    526 / 1826 loss=1.965, trans_loss=3.286, nll_loss=1.476, w2v_ctc_loss=1.145, task_loss=2.485, contrastive_loss=0, total=3997.46, n_correct=2527.29, ppl=2.78, accuracy=63.222, wps=13973.5, ups=1.16, wpb=12027.4, bsz=435.5, num_updates=13300, lr=0.000122628, gnorm=0.398, clip=0, loss_scale=16, train_wall=86, gb_free=15.5, wall=11288
2023-08-31 12:53:07 | INFO | train_inner | epoch 008:    626 / 1826 loss=1.952, trans_loss=3.287, nll_loss=1.477, w2v_ctc_loss=1.128, task_loss=2.226, contrastive_loss=0, total=4026.89, n_correct=2546.86, ppl=2.78, accuracy=63.246, wps=14203.8, ups=1.17, wpb=12112.3, bsz=460.2, num_updates=13400, lr=0.000122169, gnorm=0.394, clip=0, loss_scale=16, train_wall=85, gb_free=16.5, wall=11374
2023-08-31 12:54:31 | INFO | train_inner | epoch 008:    726 / 1826 loss=1.952, trans_loss=3.291, nll_loss=1.48, w2v_ctc_loss=1.126, task_loss=2.46, contrastive_loss=0, total=3935.44, n_correct=2488.16, ppl=2.79, accuracy=63.224, wps=14107.1, ups=1.19, wpb=11831.7, bsz=421.4, num_updates=13500, lr=0.000121716, gnorm=0.4, clip=0, loss_scale=16, train_wall=83, gb_free=15.3, wall=11458
2023-08-31 12:55:56 | INFO | train_inner | epoch 008:    826 / 1826 loss=1.954, trans_loss=3.288, nll_loss=1.475, w2v_ctc_loss=1.126, task_loss=2.407, contrastive_loss=0, total=3996.46, n_correct=2534.42, ppl=2.78, accuracy=63.417, wps=14054.7, ups=1.17, wpb=12007.6, bsz=432.5, num_updates=13600, lr=0.000121268, gnorm=0.399, clip=0, loss_scale=16, train_wall=85, gb_free=16.5, wall=11543
2023-08-31 12:57:21 | INFO | train_inner | epoch 008:    926 / 1826 loss=1.957, trans_loss=3.279, nll_loss=1.465, w2v_ctc_loss=1.137, task_loss=2.546, contrastive_loss=0, total=3885.41, n_correct=2469.19, ppl=2.76, accuracy=63.55, wps=13844.1, ups=1.18, wpb=11686, bsz=406.3, num_updates=13700, lr=0.000120824, gnorm=0.407, clip=0, loss_scale=32, train_wall=84, gb_free=11.4, wall=11627
2023-08-31 12:58:45 | INFO | train_inner | epoch 008:   1026 / 1826 loss=1.963, trans_loss=3.277, nll_loss=1.464, w2v_ctc_loss=1.148, task_loss=2.545, contrastive_loss=0, total=3950.23, n_correct=2508.6, ppl=2.76, accuracy=63.505, wps=14107.1, ups=1.19, wpb=11884.1, bsz=413.4, num_updates=13800, lr=0.000120386, gnorm=0.405, clip=0, loss_scale=32, train_wall=84, gb_free=15.7, wall=11712
2023-08-31 13:00:10 | INFO | train_inner | epoch 008:   1126 / 1826 loss=1.939, trans_loss=3.276, nll_loss=1.463, w2v_ctc_loss=1.115, task_loss=2.342, contrastive_loss=0, total=3967.4, n_correct=2527.93, ppl=2.76, accuracy=63.718, wps=14067.9, ups=1.18, wpb=11931.2, bsz=436.8, num_updates=13900, lr=0.000119952, gnorm=0.402, clip=0, loss_scale=32, train_wall=84, gb_free=15.1, wall=11797
2023-08-31 13:01:36 | INFO | train_inner | epoch 008:   1226 / 1826 loss=1.931, trans_loss=3.275, nll_loss=1.46, w2v_ctc_loss=1.108, task_loss=2.313, contrastive_loss=0, total=4000.75, n_correct=2554.88, ppl=2.75, accuracy=63.86, wps=14061.9, ups=1.17, wpb=12030.1, bsz=442.5, num_updates=14000, lr=0.000119523, gnorm=0.421, clip=0, loss_scale=32, train_wall=85, gb_free=16.6, wall=11882
2023-08-31 13:01:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 13:02:14 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 3.927 | trans_loss 5.179 | nll_loss 2.473 | w2v_ctc_loss 1.404 | task_loss 13.603 | contrastive_loss 0 | total 3505.91 | n_correct 2320.36 | ppl 5.55 | accuracy 66.184 | uer 19.526 | wer 21.317 | raw_wer 21.317 | bleu 27.88 | wps 1189.5 | wpb 3505.9 | bsz 119.3 | num_updates 14000 | best_bleu 27.88
2023-08-31 13:02:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 14000 updates
2023-08-31 13:02:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_8_14000.pt
2023-08-31 13:02:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_8_14000.pt
2023-08-31 13:02:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_8_14000.pt (epoch 8 @ 14000 updates, score 27.88) (writing took 12.784886701003416 seconds)
2023-08-31 13:03:52 | INFO | train_inner | epoch 008:   1326 / 1826 loss=1.95, trans_loss=3.284, nll_loss=1.472, w2v_ctc_loss=1.128, task_loss=2.555, contrastive_loss=0, total=3927.23, n_correct=2494.01, ppl=2.77, accuracy=63.506, wps=8677.9, ups=0.73, wpb=11813, bsz=411.5, num_updates=14100, lr=0.000119098, gnorm=0.406, clip=0, loss_scale=32, train_wall=83, gb_free=16.1, wall=12018
2023-08-31 13:05:16 | INFO | train_inner | epoch 008:   1426 / 1826 loss=1.92, trans_loss=3.274, nll_loss=1.46, w2v_ctc_loss=1.09, task_loss=2.301, contrastive_loss=0, total=3987.61, n_correct=2542.07, ppl=2.75, accuracy=63.749, wps=14272.1, ups=1.19, wpb=11989.8, bsz=441.2, num_updates=14200, lr=0.000118678, gnorm=0.403, clip=0, loss_scale=32, train_wall=83, gb_free=16.2, wall=12102
2023-08-31 13:06:40 | INFO | train_inner | epoch 008:   1526 / 1826 loss=1.938, trans_loss=3.273, nll_loss=1.459, w2v_ctc_loss=1.117, task_loss=2.26, contrastive_loss=0, total=3997.99, n_correct=2552.44, ppl=2.75, accuracy=63.843, wps=14298.2, ups=1.19, wpb=12027.4, bsz=444.4, num_updates=14300, lr=0.000118262, gnorm=0.395, clip=0, loss_scale=32, train_wall=83, gb_free=16, wall=12186
2023-08-31 13:08:04 | INFO | train_inner | epoch 008:   1626 / 1826 loss=1.949, trans_loss=3.277, nll_loss=1.466, w2v_ctc_loss=1.131, task_loss=2.504, contrastive_loss=0, total=3947.23, n_correct=2509.8, ppl=2.76, accuracy=63.584, wps=14106.3, ups=1.19, wpb=11878.9, bsz=415.7, num_updates=14400, lr=0.000117851, gnorm=0.42, clip=0, loss_scale=32, train_wall=84, gb_free=17, wall=12271
2023-08-31 13:09:29 | INFO | train_inner | epoch 008:   1726 / 1826 loss=1.949, trans_loss=3.284, nll_loss=1.473, w2v_ctc_loss=1.126, task_loss=2.393, contrastive_loss=0, total=3957.64, n_correct=2509.03, ppl=2.78, accuracy=63.397, wps=14057.3, ups=1.18, wpb=11901.8, bsz=433.4, num_updates=14500, lr=0.000117444, gnorm=0.401, clip=0, loss_scale=32, train_wall=84, gb_free=15.1, wall=12355
2023-08-31 13:10:52 | INFO | train_inner | epoch 008:   1826 / 1826 loss=1.944, trans_loss=3.277, nll_loss=1.464, w2v_ctc_loss=1.124, task_loss=2.35, contrastive_loss=0, total=3953.77, n_correct=2519.88, ppl=2.76, accuracy=63.734, wps=14210.2, ups=1.2, wpb=11888.9, bsz=433.6, num_updates=14600, lr=0.000117041, gnorm=0.425, clip=0, loss_scale=32, train_wall=83, gb_free=16.6, wall=12439
2023-08-31 13:10:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 13:11:33 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 3.912 | trans_loss 5.16 | nll_loss 2.448 | w2v_ctc_loss 1.398 | task_loss 13.577 | contrastive_loss 0 | total 3505.91 | n_correct 2336.18 | ppl 5.46 | accuracy 66.636 | uer 19.113 | wer 20.96 | raw_wer 20.96 | bleu 28.19 | wps 1124.1 | wpb 3505.9 | bsz 119.3 | num_updates 14600 | best_bleu 28.19
2023-08-31 13:11:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 14600 updates
2023-08-31 13:11:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 13:11:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 13:11:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 8 @ 14600 updates, score 28.19) (writing took 12.314421329996549 seconds)
2023-08-31 13:11:45 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-31 13:11:45 | INFO | train | epoch 008 | loss 1.95 | trans_loss 3.282 | nll_loss 1.47 | w2v_ctc_loss 1.128 | task_loss 2.43 | contrastive_loss 0 | total 3956.37 | n_correct 2509.77 | ppl 2.77 | accuracy 63.436 | wps 13106.9 | ups 1.1 | wpb 11900.1 | bsz 427.2 | num_updates 14600 | lr 0.000117041 | gnorm 0.406 | clip 0 | loss_scale 32 | train_wall 1534 | gb_free 16.6 | wall 12492
2023-08-31 13:11:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 13:11:46 | INFO | fairseq.trainer | begin training epoch 9
2023-08-31 13:11:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 13:13:17 | INFO | train_inner | epoch 009:    100 / 1826 loss=1.906, trans_loss=3.252, nll_loss=1.43, w2v_ctc_loss=1.08, task_loss=2.448, contrastive_loss=0, total=3922.53, n_correct=2531.81, ppl=2.7, accuracy=64.545, wps=8131.7, ups=0.69, wpb=11792.7, bsz=419.4, num_updates=14700, lr=0.000116642, gnorm=0.408, clip=0, loss_scale=32, train_wall=84, gb_free=17, wall=12584
2023-08-31 13:14:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 13:14:42 | INFO | train_inner | epoch 009:    201 / 1826 loss=1.902, trans_loss=3.253, nll_loss=1.429, w2v_ctc_loss=1.077, task_loss=2.421, contrastive_loss=0, total=3976.16, n_correct=2570.91, ppl=2.69, accuracy=64.658, wps=14060.9, ups=1.18, wpb=11941.7, bsz=425, num_updates=14800, lr=0.000116248, gnorm=0.409, clip=0, loss_scale=16, train_wall=84, gb_free=15.6, wall=12669
2023-08-31 13:16:07 | INFO | train_inner | epoch 009:    301 / 1826 loss=1.911, trans_loss=3.256, nll_loss=1.435, w2v_ctc_loss=1.091, task_loss=2.327, contrastive_loss=0, total=4021.68, n_correct=2590.63, ppl=2.7, accuracy=64.417, wps=14256.9, ups=1.18, wpb=12092.8, bsz=445.4, num_updates=14900, lr=0.000115857, gnorm=0.43, clip=0, loss_scale=16, train_wall=84, gb_free=15.4, wall=12754
2023-08-31 13:17:31 | INFO | train_inner | epoch 009:    401 / 1826 loss=1.904, trans_loss=3.252, nll_loss=1.432, w2v_ctc_loss=1.081, task_loss=2.365, contrastive_loss=0, total=3977.48, n_correct=2566.63, ppl=2.7, accuracy=64.529, wps=14192.3, ups=1.19, wpb=11963.7, bsz=437.7, num_updates=15000, lr=0.00011547, gnorm=0.401, clip=0, loss_scale=16, train_wall=84, gb_free=10.3, wall=12838
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:0')
2023-08-31 13:18:34 | INFO | train_inner | epoch 009:    501 / 1826 loss=2.04, trans_loss=4.879, nll_loss=2.16, w2v_ctc_loss=0.834, task_loss=3.749, contrastive_loss=0, total=3929.06, n_correct=2526.65, ppl=4.47, accuracy=64.307, wps=12708.5, ups=1.61, wpb=7898.8, bsz=274.6, num_updates=15100, lr=0.000115087, gnorm=0.577, clip=0, loss_scale=16, train_wall=61, gb_free=11.5, wall=12900
2023-08-31 13:19:35 | INFO | train_inner | epoch 009:    601 / 1826 loss=2.032, trans_loss=4.901, nll_loss=2.166, w2v_ctc_loss=0.811, task_loss=3.475, contrastive_loss=0, total=3990.97, n_correct=2565.97, ppl=4.49, accuracy=64.294, wps=13032.4, ups=1.63, wpb=7981.9, bsz=293.4, num_updates=15200, lr=0.000114708, gnorm=0.548, clip=0, loss_scale=16, train_wall=61, gb_free=17.3, wall=12961
2023-08-31 13:20:36 | INFO | train_inner | epoch 009:    701 / 1826 loss=2.027, trans_loss=4.891, nll_loss=2.154, w2v_ctc_loss=0.81, task_loss=3.703, contrastive_loss=0, total=3920.39, n_correct=2536.78, ppl=4.45, accuracy=64.707, wps=12808, ups=1.63, wpb=7840.8, bsz=279.5, num_updates=15300, lr=0.000114332, gnorm=0.544, clip=0, loss_scale=16, train_wall=61, gb_free=14.4, wall=13023
2023-08-31 13:21:38 | INFO | train_inner | epoch 009:    801 / 1826 loss=2.043, trans_loss=4.91, nll_loss=2.178, w2v_ctc_loss=0.83, task_loss=3.676, contrastive_loss=0, total=3935.56, n_correct=2523.39, ppl=4.52, accuracy=64.118, wps=12802.7, ups=1.63, wpb=7871.1, bsz=284.5, num_updates=15400, lr=0.000113961, gnorm=0.565, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=13084
2023-08-31 13:22:39 | INFO | train_inner | epoch 009:    901 / 1826 loss=2.04, trans_loss=4.902, nll_loss=2.168, w2v_ctc_loss=0.833, task_loss=3.675, contrastive_loss=0, total=3924.5, n_correct=2522.49, ppl=4.49, accuracy=64.275, wps=12717.8, ups=1.62, wpb=7849, bsz=283.7, num_updates=15500, lr=0.000113592, gnorm=0.556, clip=0, loss_scale=16, train_wall=61, gb_free=10.2, wall=13146
2023-08-31 13:23:41 | INFO | train_inner | epoch 009:   1001 / 1826 loss=2.036, trans_loss=4.895, nll_loss=2.16, w2v_ctc_loss=0.829, task_loss=3.598, contrastive_loss=0, total=3972.59, n_correct=2553.24, ppl=4.47, accuracy=64.271, wps=12771.1, ups=1.61, wpb=7945.2, bsz=292.2, num_updates=15600, lr=0.000113228, gnorm=0.552, clip=0, loss_scale=16, train_wall=62, gb_free=14.7, wall=13208
2023-08-31 13:24:43 | INFO | train_inner | epoch 009:   1101 / 1826 loss=2.037, trans_loss=4.9, nll_loss=2.166, w2v_ctc_loss=0.828, task_loss=3.727, contrastive_loss=0, total=3941, n_correct=2531.2, ppl=4.49, accuracy=64.227, wps=12866.5, ups=1.63, wpb=7882, bsz=283.6, num_updates=15700, lr=0.000112867, gnorm=0.571, clip=0, loss_scale=16, train_wall=61, gb_free=15.2, wall=13269
2023-08-31 13:25:44 | INFO | train_inner | epoch 009:   1201 / 1826 loss=2.031, trans_loss=4.888, nll_loss=2.15, w2v_ctc_loss=0.825, task_loss=3.625, contrastive_loss=0, total=4009.72, n_correct=2589, ppl=4.44, accuracy=64.568, wps=13096.7, ups=1.63, wpb=8019.4, bsz=287.6, num_updates=15800, lr=0.000112509, gnorm=0.555, clip=0, loss_scale=16, train_wall=61, gb_free=12.5, wall=13331
2023-08-31 13:26:45 | INFO | train_inner | epoch 009:   1301 / 1826 loss=2.04, trans_loss=4.9, nll_loss=2.166, w2v_ctc_loss=0.832, task_loss=3.851, contrastive_loss=0, total=3908.1, n_correct=2513, ppl=4.49, accuracy=64.302, wps=12726.7, ups=1.63, wpb=7816.2, bsz=272, num_updates=15900, lr=0.000112154, gnorm=0.562, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=13392
2023-08-31 13:27:47 | INFO | train_inner | epoch 009:   1401 / 1826 loss=2.035, trans_loss=4.901, nll_loss=2.168, w2v_ctc_loss=0.825, task_loss=3.544, contrastive_loss=0, total=3974.66, n_correct=2557.71, ppl=4.49, accuracy=64.35, wps=12910.2, ups=1.62, wpb=7949.3, bsz=291.4, num_updates=16000, lr=0.000111803, gnorm=0.568, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=13454
2023-08-31 13:27:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:4')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 13:28:26 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.897 | trans_loss 5.128 | nll_loss 2.408 | w2v_ctc_loss 1.419 | task_loss 13.619 | contrastive_loss 0 | total 3505.91 | n_correct 2352.64 | ppl 5.31 | accuracy 67.105 | uer 19.308 | wer 21.208 | raw_wer 21.208 | bleu 28.92 | wps 1205.9 | wpb 3505.9 | bsz 119.3 | num_updates 16000 | best_bleu 28.92
2023-08-31 13:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 16000 updates
2023-08-31 13:28:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_9_16000.pt
2023-08-31 13:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_9_16000.pt
2023-08-31 13:28:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_9_16000.pt (epoch 9 @ 16000 updates, score 28.92) (writing took 13.179668748998665 seconds)
2023-08-31 13:29:41 | INFO | train_inner | epoch 009:   1501 / 1826 loss=2.039, trans_loss=4.895, nll_loss=2.16, w2v_ctc_loss=0.842, task_loss=3.75, contrastive_loss=0, total=3942.41, n_correct=2541.08, ppl=4.47, accuracy=64.455, wps=6923.4, ups=0.88, wpb=7884.8, bsz=282.3, num_updates=16100, lr=0.000111456, gnorm=0.576, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=13567
2023-08-31 13:30:42 | INFO | train_inner | epoch 009:   1601 / 1826 loss=2.028, trans_loss=4.887, nll_loss=2.15, w2v_ctc_loss=0.829, task_loss=3.343, contrastive_loss=0, total=4021.15, n_correct=2599.74, ppl=4.44, accuracy=64.652, wps=13187.7, ups=1.64, wpb=8042.3, bsz=306.6, num_updates=16200, lr=0.000111111, gnorm=0.568, clip=0, loss_scale=16, train_wall=60, gb_free=15.3, wall=13628
2023-08-31 13:31:43 | INFO | train_inner | epoch 009:   1701 / 1826 loss=2.038, trans_loss=4.891, nll_loss=2.155, w2v_ctc_loss=0.84, task_loss=3.841, contrastive_loss=0, total=3918.63, n_correct=2529, ppl=4.45, accuracy=64.538, wps=12846.5, ups=1.64, wpb=7837.3, bsz=272.4, num_updates=16300, lr=0.00011077, gnorm=0.6, clip=0, loss_scale=16, train_wall=60, gb_free=16.7, wall=13689
2023-08-31 13:32:44 | INFO | train_inner | epoch 009:   1801 / 1826 loss=2.039, trans_loss=4.896, nll_loss=2.161, w2v_ctc_loss=0.84, task_loss=3.886, contrastive_loss=0, total=3934.13, n_correct=2540.06, ppl=4.47, accuracy=64.565, wps=12881.7, ups=1.64, wpb=7868.3, bsz=270.5, num_updates=16400, lr=0.000110432, gnorm=0.552, clip=0, loss_scale=16, train_wall=60, gb_free=16.9, wall=13751
2023-08-31 13:32:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 13:33:38 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.897 | trans_loss 5.126 | nll_loss 2.406 | w2v_ctc_loss 1.421 | task_loss 13.59 | contrastive_loss 0 | total 3505.91 | n_correct 2356.91 | ppl 5.3 | accuracy 67.227 | uer 19.469 | wer 21.241 | raw_wer 21.241 | bleu 28.61 | wps 1196.3 | wpb 3505.9 | bsz 119.3 | num_updates 16425 | best_bleu 28.92
2023-08-31 13:33:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 16425 updates
2023-08-31 13:33:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_28.6107.pt
2023-08-31 13:33:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_28.6107.pt
2023-08-31 13:33:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_28.6107.pt (epoch 9 @ 16425 updates, score 28.61) (writing took 7.32824489599443 seconds)
2023-08-31 13:33:46 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-31 13:33:46 | INFO | train | epoch 009 | loss 1.997 | trans_loss 4.406 | nll_loss 1.944 | w2v_ctc_loss 0.904 | task_loss 3.283 | contrastive_loss 0 | total 3956.13 | n_correct 2549.15 | ppl 3.85 | accuracy 64.435 | wps 12152.1 | ups 1.38 | wpb 8790.9 | bsz 316.5 | num_updates 16425 | lr 0.000110347 | gnorm 0.531 | clip 0 | loss_scale 16 | train_wall 1203 | gb_free 17.4 | wall 13812
2023-08-31 13:33:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 13:33:46 | INFO | fairseq.trainer | begin training epoch 10
2023-08-31 13:33:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 13:34:40 | INFO | train_inner | epoch 010:     75 / 1826 loss=2.02, trans_loss=4.873, nll_loss=2.132, w2v_ctc_loss=0.822, task_loss=3.606, contrastive_loss=0, total=3948.73, n_correct=2566.85, ppl=4.38, accuracy=65.004, wps=6824.6, ups=0.86, wpb=7897.5, bsz=287.7, num_updates=16500, lr=0.000110096, gnorm=0.583, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=13866
2023-08-31 13:35:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-31 13:35:42 | INFO | train_inner | epoch 010:    176 / 1826 loss=2.023, trans_loss=4.872, nll_loss=2.13, w2v_ctc_loss=0.822, task_loss=3.855, contrastive_loss=0, total=3926.15, n_correct=2550.52, ppl=4.38, accuracy=64.962, wps=12690.6, ups=1.62, wpb=7852.3, bsz=273.9, num_updates=16600, lr=0.000109764, gnorm=0.587, clip=0, loss_scale=8, train_wall=61, gb_free=16.7, wall=13928
2023-08-31 13:36:42 | INFO | train_inner | epoch 010:    276 / 1826 loss=2.003, trans_loss=4.851, nll_loss=2.103, w2v_ctc_loss=0.8, task_loss=3.61, contrastive_loss=0, total=3944.85, n_correct=2586.02, ppl=4.3, accuracy=65.554, wps=13001.6, ups=1.65, wpb=7889.7, bsz=282.9, num_updates=16700, lr=0.000109435, gnorm=0.553, clip=0, loss_scale=8, train_wall=60, gb_free=16.6, wall=13989
2023-08-31 13:37:44 | INFO | train_inner | epoch 010:    376 / 1826 loss=2.014, trans_loss=4.874, nll_loss=2.133, w2v_ctc_loss=0.808, task_loss=3.383, contrastive_loss=0, total=4002.59, n_correct=2601.45, ppl=4.39, accuracy=64.994, wps=13028.9, ups=1.63, wpb=8005.2, bsz=305.4, num_updates=16800, lr=0.000109109, gnorm=0.558, clip=0, loss_scale=8, train_wall=61, gb_free=12.8, wall=14050
2023-08-31 13:38:45 | INFO | train_inner | epoch 010:    476 / 1826 loss=2.014, trans_loss=4.867, nll_loss=2.123, w2v_ctc_loss=0.815, task_loss=3.561, contrastive_loss=0, total=3980.3, n_correct=2594.31, ppl=4.36, accuracy=65.179, wps=13003.6, ups=1.63, wpb=7960.6, bsz=290.4, num_updates=16900, lr=0.000108786, gnorm=0.553, clip=0, loss_scale=8, train_wall=61, gb_free=12.4, wall=14112
2023-08-31 13:39:46 | INFO | train_inner | epoch 010:    576 / 1826 loss=2.008, trans_loss=4.86, nll_loss=2.116, w2v_ctc_loss=0.805, task_loss=3.532, contrastive_loss=0, total=3964.26, n_correct=2586.88, ppl=4.33, accuracy=65.255, wps=12948.8, ups=1.63, wpb=7928.5, bsz=291.2, num_updates=17000, lr=0.000108465, gnorm=0.545, clip=0, loss_scale=8, train_wall=61, gb_free=15.6, wall=14173
2023-08-31 13:40:48 | INFO | train_inner | epoch 010:    676 / 1826 loss=2.014, trans_loss=4.865, nll_loss=2.122, w2v_ctc_loss=0.81, task_loss=3.738, contrastive_loss=0, total=3912.57, n_correct=2546.87, ppl=4.35, accuracy=65.095, wps=12746.1, ups=1.63, wpb=7825.1, bsz=280.5, num_updates=17100, lr=0.000108148, gnorm=0.554, clip=0, loss_scale=8, train_wall=61, gb_free=16.9, wall=14234
2023-08-31 13:41:49 | INFO | train_inner | epoch 010:    776 / 1826 loss=2.009, trans_loss=4.86, nll_loss=2.116, w2v_ctc_loss=0.806, task_loss=3.616, contrastive_loss=0, total=3951.47, n_correct=2581.33, ppl=4.33, accuracy=65.326, wps=12891.2, ups=1.63, wpb=7902.9, bsz=284.1, num_updates=17200, lr=0.000107833, gnorm=0.554, clip=0, loss_scale=8, train_wall=61, gb_free=15.8, wall=14295
2023-08-31 13:42:51 | INFO | train_inner | epoch 010:    876 / 1826 loss=2.019, trans_loss=4.864, nll_loss=2.121, w2v_ctc_loss=0.822, task_loss=3.93, contrastive_loss=0, total=3951.45, n_correct=2578.03, ppl=4.35, accuracy=65.243, wps=12815.7, ups=1.62, wpb=7902.9, bsz=273.9, num_updates=17300, lr=0.000107521, gnorm=0.558, clip=0, loss_scale=8, train_wall=61, gb_free=16.3, wall=14357
2023-08-31 13:43:52 | INFO | train_inner | epoch 010:    976 / 1826 loss=2.018, trans_loss=4.873, nll_loss=2.133, w2v_ctc_loss=0.818, task_loss=3.457, contrastive_loss=0, total=4049.4, n_correct=2632.89, ppl=4.39, accuracy=65.019, wps=13253.3, ups=1.64, wpb=8098.8, bsz=299, num_updates=17400, lr=0.000107211, gnorm=0.56, clip=0, loss_scale=8, train_wall=61, gb_free=14.2, wall=14418
2023-08-31 13:44:53 | INFO | train_inner | epoch 010:   1076 / 1826 loss=2.024, trans_loss=4.88, nll_loss=2.141, w2v_ctc_loss=0.826, task_loss=3.766, contrastive_loss=0, total=3919.19, n_correct=2543.18, ppl=4.41, accuracy=64.89, wps=12823.8, ups=1.64, wpb=7838.4, bsz=277.8, num_updates=17500, lr=0.000106904, gnorm=0.56, clip=0, loss_scale=8, train_wall=61, gb_free=16.1, wall=14479
2023-08-31 13:45:54 | INFO | train_inner | epoch 010:   1176 / 1826 loss=2.01, trans_loss=4.853, nll_loss=2.107, w2v_ctc_loss=0.819, task_loss=3.636, contrastive_loss=0, total=3942.97, n_correct=2580.65, ppl=4.31, accuracy=65.449, wps=12896.4, ups=1.64, wpb=7885.9, bsz=282.5, num_updates=17600, lr=0.0001066, gnorm=0.556, clip=0, loss_scale=8, train_wall=60, gb_free=16.3, wall=14541
2023-08-31 13:46:56 | INFO | train_inner | epoch 010:   1276 / 1826 loss=2.016, trans_loss=4.866, nll_loss=2.124, w2v_ctc_loss=0.825, task_loss=3.493, contrastive_loss=0, total=4014.15, n_correct=2617.65, ppl=4.36, accuracy=65.211, wps=12964.5, ups=1.61, wpb=8028.3, bsz=298.1, num_updates=17700, lr=0.000106299, gnorm=0.545, clip=0, loss_scale=8, train_wall=61, gb_free=9.7, wall=14602
2023-08-31 13:47:57 | INFO | train_inner | epoch 010:   1376 / 1826 loss=2.021, trans_loss=4.863, nll_loss=2.119, w2v_ctc_loss=0.83, task_loss=3.919, contrastive_loss=0, total=3921.55, n_correct=2560.4, ppl=4.34, accuracy=65.291, wps=12866.6, ups=1.64, wpb=7843.1, bsz=267.7, num_updates=17800, lr=0.000106, gnorm=0.639, clip=0, loss_scale=8, train_wall=60, gb_free=16.3, wall=14663
2023-08-31 13:48:58 | INFO | train_inner | epoch 010:   1476 / 1826 loss=2.006, trans_loss=4.847, nll_loss=2.099, w2v_ctc_loss=0.805, task_loss=3.857, contrastive_loss=0, total=3905.12, n_correct=2559.77, ppl=4.28, accuracy=65.549, wps=12821.6, ups=1.64, wpb=7810.2, bsz=269.4, num_updates=17900, lr=0.000105703, gnorm=0.553, clip=0, loss_scale=8, train_wall=60, gb_free=11.7, wall=14724
2023-08-31 13:49:59 | INFO | train_inner | epoch 010:   1576 / 1826 loss=2.002, trans_loss=4.845, nll_loss=2.097, w2v_ctc_loss=0.807, task_loss=3.579, contrastive_loss=0, total=3959.92, n_correct=2599.11, ppl=4.28, accuracy=65.635, wps=12977.3, ups=1.64, wpb=7919.8, bsz=285.8, num_updates=18000, lr=0.000105409, gnorm=0.551, clip=0, loss_scale=8, train_wall=60, gb_free=16.1, wall=14785
2023-08-31 13:49:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 13:50:37 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.891 | trans_loss 5.095 | nll_loss 2.368 | w2v_ctc_loss 1.473 | task_loss 13.601 | contrastive_loss 0 | total 3505.91 | n_correct 2361.82 | ppl 5.16 | accuracy 67.367 | uer 19.456 | wer 21.365 | raw_wer 21.365 | bleu 29.2 | wps 1206.8 | wpb 3505.9 | bsz 119.3 | num_updates 18000 | best_bleu 29.2
2023-08-31 13:50:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 18000 updates
2023-08-31 13:50:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_10_18000.pt
2023-08-31 13:50:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_10_18000.pt
2023-08-31 13:50:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_10_18000.pt (epoch 10 @ 18000 updates, score 29.2) (writing took 13.622400430002017 seconds)
2023-08-31 13:51:52 | INFO | train_inner | epoch 010:   1676 / 1826 loss=2.01, trans_loss=4.858, nll_loss=2.113, w2v_ctc_loss=0.816, task_loss=3.737, contrastive_loss=0, total=3940.69, n_correct=2580.18, ppl=4.33, accuracy=65.475, wps=6934.8, ups=0.88, wpb=7881.4, bsz=279.2, num_updates=18100, lr=0.000105118, gnorm=0.557, clip=0, loss_scale=8, train_wall=60, gb_free=17.4, wall=14899
2023-08-31 13:52:54 | INFO | train_inner | epoch 010:   1776 / 1826 loss=2.005, trans_loss=4.863, nll_loss=2.12, w2v_ctc_loss=0.8, task_loss=3.338, contrastive_loss=0, total=4007.29, n_correct=2615.61, ppl=4.35, accuracy=65.271, wps=13008.2, ups=1.62, wpb=8014.6, bsz=305.3, num_updates=18200, lr=0.000104828, gnorm=0.561, clip=0, loss_scale=8, train_wall=61, gb_free=15.6, wall=14961
2023-08-31 13:53:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 13:54:03 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.872 | trans_loss 5.098 | nll_loss 2.374 | w2v_ctc_loss 1.404 | task_loss 13.537 | contrastive_loss 0 | total 3505.91 | n_correct 2366.18 | ppl 5.18 | accuracy 67.491 | uer 19.367 | wer 21.211 | raw_wer 21.211 | bleu 29.42 | wps 1204.4 | wpb 3505.9 | bsz 119.3 | num_updates 18250 | best_bleu 29.42
2023-08-31 13:54:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 18250 updates
2023-08-31 13:54:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 13:54:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 13:54:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 10 @ 18250 updates, score 29.42) (writing took 11.921789525993518 seconds)
2023-08-31 13:54:16 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-31 13:54:16 | INFO | train | epoch 010 | loss 2.013 | trans_loss 4.863 | nll_loss 2.119 | w2v_ctc_loss 0.814 | task_loss 3.647 | contrastive_loss 0 | total 3956.22 | n_correct 2581.33 | ppl 4.34 | accuracy 65.247 | wps 11739.5 | ups 1.48 | wpb 7912.4 | bsz 284.8 | num_updates 18250 | lr 0.000104685 | gnorm 0.564 | clip 0 | loss_scale 8 | train_wall 1107 | gb_free 17.1 | wall 15042
2023-08-31 13:54:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 13:54:16 | INFO | fairseq.trainer | begin training epoch 11
2023-08-31 13:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 13:54:54 | INFO | train_inner | epoch 011:     50 / 1826 loss=2.007, trans_loss=4.852, nll_loss=2.105, w2v_ctc_loss=0.81, task_loss=3.732, contrastive_loss=0, total=3889.17, n_correct=2547.47, ppl=4.3, accuracy=65.502, wps=6489.6, ups=0.83, wpb=7778.3, bsz=278.1, num_updates=18300, lr=0.000104542, gnorm=0.595, clip=0, loss_scale=8, train_wall=60, gb_free=14.8, wall=15080
2023-08-31 13:55:56 | INFO | train_inner | epoch 011:    150 / 1826 loss=1.995, trans_loss=4.838, nll_loss=2.087, w2v_ctc_loss=0.796, task_loss=3.688, contrastive_loss=0, total=3991.44, n_correct=2623.08, ppl=4.25, accuracy=65.718, wps=12933.7, ups=1.62, wpb=7982.9, bsz=288, num_updates=18400, lr=0.000104257, gnorm=0.562, clip=0, loss_scale=8, train_wall=61, gb_free=15.1, wall=15142
2023-08-31 13:56:56 | INFO | train_inner | epoch 011:    250 / 1826 loss=1.999, trans_loss=4.838, nll_loss=2.087, w2v_ctc_loss=0.804, task_loss=3.724, contrastive_loss=0, total=3911.44, n_correct=2572.56, ppl=4.25, accuracy=65.77, wps=12870.2, ups=1.65, wpb=7822.9, bsz=278.5, num_updates=18500, lr=0.000103975, gnorm=0.563, clip=0, loss_scale=8, train_wall=60, gb_free=14.9, wall=15203
2023-08-31 13:57:57 | INFO | train_inner | epoch 011:    350 / 1826 loss=1.989, trans_loss=4.828, nll_loss=2.075, w2v_ctc_loss=0.79, task_loss=3.666, contrastive_loss=0, total=3940.75, n_correct=2600.44, ppl=4.21, accuracy=65.988, wps=12933.4, ups=1.64, wpb=7881.5, bsz=278.6, num_updates=18600, lr=0.000103695, gnorm=0.553, clip=0, loss_scale=16, train_wall=60, gb_free=17.3, wall=15264
2023-08-31 13:58:59 | INFO | train_inner | epoch 011:    450 / 1826 loss=1.991, trans_loss=4.827, nll_loss=2.073, w2v_ctc_loss=0.796, task_loss=3.809, contrastive_loss=0, total=3946.18, n_correct=2605.94, ppl=4.21, accuracy=66.037, wps=12770.3, ups=1.62, wpb=7892.4, bsz=278, num_updates=18700, lr=0.000103418, gnorm=0.543, clip=0, loss_scale=16, train_wall=61, gb_free=14.7, wall=15326
2023-08-31 14:00:01 | INFO | train_inner | epoch 011:    550 / 1826 loss=1.993, trans_loss=4.832, nll_loss=2.081, w2v_ctc_loss=0.798, task_loss=3.782, contrastive_loss=0, total=3949.12, n_correct=2607.86, ppl=4.23, accuracy=66.036, wps=12847.8, ups=1.63, wpb=7898.2, bsz=278.1, num_updates=18800, lr=0.000103142, gnorm=0.551, clip=0, loss_scale=16, train_wall=61, gb_free=11.5, wall=15387
2023-08-31 14:01:01 | INFO | train_inner | epoch 011:    650 / 1826 loss=1.999, trans_loss=4.839, nll_loss=2.089, w2v_ctc_loss=0.808, task_loss=3.789, contrastive_loss=0, total=3910.12, n_correct=2574.92, ppl=4.26, accuracy=65.853, wps=12949.7, ups=1.66, wpb=7820.2, bsz=277, num_updates=18900, lr=0.000102869, gnorm=0.556, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=15448
2023-08-31 14:02:02 | INFO | train_inner | epoch 011:    750 / 1826 loss=1.998, trans_loss=4.842, nll_loss=2.093, w2v_ctc_loss=0.804, task_loss=3.639, contrastive_loss=0, total=3946.22, n_correct=2596.85, ppl=4.27, accuracy=65.806, wps=12872.2, ups=1.63, wpb=7892.4, bsz=282.7, num_updates=19000, lr=0.000102598, gnorm=0.591, clip=0, loss_scale=16, train_wall=61, gb_free=10.9, wall=15509
2023-08-31 14:03:03 | INFO | train_inner | epoch 011:    850 / 1826 loss=1.996, trans_loss=4.839, nll_loss=2.089, w2v_ctc_loss=0.796, task_loss=3.74, contrastive_loss=0, total=3920.77, n_correct=2580.37, ppl=4.25, accuracy=65.813, wps=12845.9, ups=1.64, wpb=7841.5, bsz=278.5, num_updates=19100, lr=0.000102329, gnorm=0.577, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=15570
2023-08-31 14:04:06 | INFO | train_inner | epoch 011:    950 / 1826 loss=1.999, trans_loss=4.841, nll_loss=2.092, w2v_ctc_loss=0.803, task_loss=3.691, contrastive_loss=0, total=4000.2, n_correct=2630.12, ppl=4.26, accuracy=65.75, wps=12885.2, ups=1.61, wpb=8000.4, bsz=289.2, num_updates=19200, lr=0.000102062, gnorm=0.544, clip=0, loss_scale=16, train_wall=62, gb_free=15.8, wall=15632
2023-08-31 14:05:07 | INFO | train_inner | epoch 011:   1050 / 1826 loss=1.999, trans_loss=4.835, nll_loss=2.083, w2v_ctc_loss=0.81, task_loss=3.791, contrastive_loss=0, total=3962.25, n_correct=2609.6, ppl=4.24, accuracy=65.862, wps=12924.2, ups=1.63, wpb=7924.5, bsz=277.4, num_updates=19300, lr=0.000101797, gnorm=0.559, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=15693
2023-08-31 14:06:07 | INFO | train_inner | epoch 011:   1150 / 1826 loss=1.994, trans_loss=4.836, nll_loss=2.086, w2v_ctc_loss=0.797, task_loss=3.739, contrastive_loss=0, total=3942.9, n_correct=2600.38, ppl=4.25, accuracy=65.951, wps=13036.8, ups=1.65, wpb=7885.8, bsz=275.9, num_updates=19400, lr=0.000101535, gnorm=0.561, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=15754
2023-08-31 14:07:08 | INFO | train_inner | epoch 011:   1250 / 1826 loss=2, trans_loss=4.836, nll_loss=2.085, w2v_ctc_loss=0.807, task_loss=4.004, contrastive_loss=0, total=3869.34, n_correct=2544.33, ppl=4.24, accuracy=65.756, wps=12673.9, ups=1.64, wpb=7738.7, bsz=265.7, num_updates=19500, lr=0.000101274, gnorm=0.566, clip=0, loss_scale=16, train_wall=60, gb_free=12.1, wall=15815
2023-08-31 14:08:10 | INFO | train_inner | epoch 011:   1350 / 1826 loss=1.993, trans_loss=4.838, nll_loss=2.088, w2v_ctc_loss=0.801, task_loss=3.403, contrastive_loss=0, total=3983.96, n_correct=2626.49, ppl=4.25, accuracy=65.927, wps=13021.6, ups=1.63, wpb=7967.9, bsz=297.1, num_updates=19600, lr=0.000101015, gnorm=0.564, clip=0, loss_scale=16, train_wall=61, gb_free=17.1, wall=15876
2023-08-31 14:09:12 | INFO | train_inner | epoch 011:   1450 / 1826 loss=1.993, trans_loss=4.838, nll_loss=2.089, w2v_ctc_loss=0.802, task_loss=3.535, contrastive_loss=0, total=4000.92, n_correct=2640.49, ppl=4.25, accuracy=65.997, wps=12880.7, ups=1.61, wpb=8001.8, bsz=293.5, num_updates=19700, lr=0.000100759, gnorm=0.559, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=15938
2023-08-31 14:10:13 | INFO | train_inner | epoch 011:   1550 / 1826 loss=1.992, trans_loss=4.839, nll_loss=2.09, w2v_ctc_loss=0.797, task_loss=3.364, contrastive_loss=0, total=4013.12, n_correct=2645.79, ppl=4.26, accuracy=65.929, wps=13065.7, ups=1.63, wpb=8026.2, bsz=304.4, num_updates=19800, lr=0.000100504, gnorm=0.546, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=16000
2023-08-31 14:11:14 | INFO | train_inner | epoch 011:   1650 / 1826 loss=1.991, trans_loss=4.835, nll_loss=2.084, w2v_ctc_loss=0.799, task_loss=3.441, contrastive_loss=0, total=3975.76, n_correct=2628.99, ppl=4.24, accuracy=66.125, wps=13083.4, ups=1.65, wpb=7951.5, bsz=290.5, num_updates=19900, lr=0.000100251, gnorm=0.542, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=16060
2023-08-31 14:12:16 | INFO | train_inner | epoch 011:   1750 / 1826 loss=1.988, trans_loss=4.838, nll_loss=2.089, w2v_ctc_loss=0.789, task_loss=3.4, contrastive_loss=0, total=4033.09, n_correct=2659.41, ppl=4.25, accuracy=65.94, wps=13074, ups=1.62, wpb=8066.2, bsz=306.4, num_updates=20000, lr=0.0001, gnorm=0.567, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=16122
2023-08-31 14:12:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 14:12:55 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.858 | trans_loss 5.072 | nll_loss 2.341 | w2v_ctc_loss 1.414 | task_loss 13.514 | contrastive_loss 0 | total 3505.91 | n_correct 2382.73 | ppl 5.07 | accuracy 67.963 | uer 18.748 | wer 20.581 | raw_wer 20.581 | bleu 29.46 | wps 1171.6 | wpb 3505.9 | bsz 119.3 | num_updates 20000 | best_bleu 29.46
2023-08-31 14:12:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 20000 updates
2023-08-31 14:12:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_11_20000.pt
2023-08-31 14:12:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_11_20000.pt
2023-08-31 14:13:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_11_20000.pt (epoch 11 @ 20000 updates, score 29.46) (writing took 13.170879926008638 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:0')
2023-08-31 14:13:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:1')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 14:14:33 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.855 | trans_loss 5.07 | nll_loss 2.339 | w2v_ctc_loss 1.408 | task_loss 13.575 | contrastive_loss 0 | total 3505.91 | n_correct 2383.45 | ppl 5.06 | accuracy 67.984 | uer 18.737 | wer 20.626 | raw_wer 20.626 | bleu 29.56 | wps 1204.3 | wpb 3505.9 | bsz 119.3 | num_updates 20076 | best_bleu 29.56
2023-08-31 14:14:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 20076 updates
2023-08-31 14:14:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 14:14:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 14:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 11 @ 20076 updates, score 29.56) (writing took 12.789507387002232 seconds)
2023-08-31 14:14:46 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-31 14:14:46 | INFO | train | epoch 011 | loss 1.994 | trans_loss 4.836 | nll_loss 2.085 | w2v_ctc_loss 0.799 | task_loss 3.643 | contrastive_loss 0 | total 3956.37 | n_correct 2607.72 | ppl 4.24 | accuracy 65.912 | wps 11739.5 | ups 1.48 | wpb 7912.7 | bsz 284.8 | num_updates 20076 | lr 9.98105e-05 | gnorm 0.559 | clip 0 | loss_scale 16 | train_wall 1107 | gb_free 15.6 | wall 16273
2023-08-31 14:14:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 14:14:47 | INFO | fairseq.trainer | begin training epoch 12
2023-08-31 14:14:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 14:15:09 | INFO | train_inner | epoch 012:     24 / 1826 loss=1.978, trans_loss=4.819, nll_loss=2.064, w2v_ctc_loss=0.782, task_loss=3.457, contrastive_loss=0, total=3952.69, n_correct=2620.36, ppl=4.18, accuracy=66.293, wps=4564.2, ups=0.58, wpb=7905.4, bsz=289, num_updates=20100, lr=9.97509e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=16295
2023-08-31 14:16:10 | INFO | train_inner | epoch 012:    124 / 1826 loss=1.986, trans_loss=4.819, nll_loss=2.063, w2v_ctc_loss=0.794, task_loss=3.948, contrastive_loss=0, total=3862.92, n_correct=2559.74, ppl=4.18, accuracy=66.264, wps=12685.4, ups=1.64, wpb=7725.8, bsz=267, num_updates=20200, lr=9.95037e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=60, gb_free=15.1, wall=16356
2023-08-31 14:17:11 | INFO | train_inner | epoch 012:    224 / 1826 loss=1.972, trans_loss=4.811, nll_loss=2.053, w2v_ctc_loss=0.774, task_loss=3.474, contrastive_loss=0, total=3993.93, n_correct=2656.67, ppl=4.15, accuracy=66.518, wps=13120.9, ups=1.64, wpb=7987.9, bsz=292.7, num_updates=20300, lr=9.92583e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=60, gb_free=11.8, wall=16417
2023-08-31 14:18:12 | INFO | train_inner | epoch 012:    324 / 1826 loss=1.975, trans_loss=4.812, nll_loss=2.054, w2v_ctc_loss=0.779, task_loss=3.521, contrastive_loss=0, total=3964.38, n_correct=2637.36, ppl=4.15, accuracy=66.526, wps=13021.5, ups=1.64, wpb=7928.8, bsz=290.2, num_updates=20400, lr=9.90148e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=60, gb_free=16.2, wall=16478
2023-08-31 14:19:12 | INFO | train_inner | epoch 012:    424 / 1826 loss=1.981, trans_loss=4.815, nll_loss=2.06, w2v_ctc_loss=0.792, task_loss=3.546, contrastive_loss=0, total=3984.39, n_correct=2648.24, ppl=4.17, accuracy=66.465, wps=13069.2, ups=1.64, wpb=7968.8, bsz=293.8, num_updates=20500, lr=9.8773e-05, gnorm=0.625, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=16539
2023-08-31 14:20:14 | INFO | train_inner | epoch 012:    524 / 1826 loss=1.975, trans_loss=4.806, nll_loss=2.047, w2v_ctc_loss=0.784, task_loss=3.637, contrastive_loss=0, total=3956.92, n_correct=2633.32, ppl=4.13, accuracy=66.55, wps=12951.2, ups=1.64, wpb=7913.8, bsz=283.7, num_updates=20600, lr=9.85329e-05, gnorm=0.606, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=16600
2023-08-31 14:21:15 | INFO | train_inner | epoch 012:    624 / 1826 loss=1.978, trans_loss=4.81, nll_loss=2.053, w2v_ctc_loss=0.789, task_loss=3.682, contrastive_loss=0, total=3953.03, n_correct=2629.03, ppl=4.15, accuracy=66.507, wps=12949.4, ups=1.64, wpb=7906.1, bsz=280.1, num_updates=20700, lr=9.82946e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=60, gb_free=14.5, wall=16661
2023-08-31 14:22:16 | INFO | train_inner | epoch 012:    724 / 1826 loss=1.983, trans_loss=4.817, nll_loss=2.061, w2v_ctc_loss=0.794, task_loss=3.707, contrastive_loss=0, total=3952.49, n_correct=2620.73, ppl=4.17, accuracy=66.306, wps=12925, ups=1.64, wpb=7905, bsz=282.3, num_updates=20800, lr=9.80581e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=16722
2023-08-31 14:23:17 | INFO | train_inner | epoch 012:    824 / 1826 loss=1.986, trans_loss=4.816, nll_loss=2.06, w2v_ctc_loss=0.793, task_loss=3.998, contrastive_loss=0, total=3920.99, n_correct=2601.38, ppl=4.17, accuracy=66.345, wps=12852.6, ups=1.64, wpb=7842, bsz=265.2, num_updates=20900, lr=9.78232e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=16783
2023-08-31 14:24:18 | INFO | train_inner | epoch 012:    924 / 1826 loss=1.963, trans_loss=4.801, nll_loss=2.042, w2v_ctc_loss=0.766, task_loss=3.146, contrastive_loss=0, total=4064.59, n_correct=2713.11, ppl=4.12, accuracy=66.75, wps=13290.3, ups=1.63, wpb=8129.2, bsz=315.7, num_updates=21000, lr=9.759e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=16845
2023-08-31 14:25:19 | INFO | train_inner | epoch 012:   1024 / 1826 loss=1.962, trans_loss=4.797, nll_loss=2.035, w2v_ctc_loss=0.769, task_loss=3.288, contrastive_loss=0, total=4027.9, n_correct=2689.86, ppl=4.1, accuracy=66.781, wps=13303, ups=1.65, wpb=8055.8, bsz=307.1, num_updates=21100, lr=9.73585e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=16905
2023-08-31 14:26:20 | INFO | train_inner | epoch 012:   1124 / 1826 loss=1.975, trans_loss=4.805, nll_loss=2.047, w2v_ctc_loss=0.787, task_loss=3.599, contrastive_loss=0, total=3982.26, n_correct=2650.65, ppl=4.13, accuracy=66.561, wps=12959.5, ups=1.63, wpb=7964.5, bsz=286.6, num_updates=21200, lr=9.71286e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=16967
2023-08-31 14:27:21 | INFO | train_inner | epoch 012:   1224 / 1826 loss=1.98, trans_loss=4.82, nll_loss=2.067, w2v_ctc_loss=0.787, task_loss=3.69, contrastive_loss=0, total=3949.09, n_correct=2623.82, ppl=4.19, accuracy=66.441, wps=12912.4, ups=1.63, wpb=7898.2, bsz=285.4, num_updates=21300, lr=9.69003e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=61, gb_free=12.3, wall=17028
2023-08-31 14:28:22 | INFO | train_inner | epoch 012:   1324 / 1826 loss=1.972, trans_loss=4.814, nll_loss=2.057, w2v_ctc_loss=0.774, task_loss=3.518, contrastive_loss=0, total=3963.34, n_correct=2631.01, ppl=4.16, accuracy=66.384, wps=13017, ups=1.64, wpb=7926.7, bsz=290.9, num_updates=21400, lr=9.66736e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=60, gb_free=12.9, wall=17089
2023-08-31 14:29:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 14:29:24 | INFO | train_inner | epoch 012:   1425 / 1826 loss=1.984, trans_loss=4.813, nll_loss=2.056, w2v_ctc_loss=0.794, task_loss=4.02, contrastive_loss=0, total=3933.22, n_correct=2608.98, ppl=4.16, accuracy=66.332, wps=12695.2, ups=1.61, wpb=7866.4, bsz=268.3, num_updates=21500, lr=9.64486e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=61, gb_free=10.9, wall=17151
2023-08-31 14:30:25 | INFO | train_inner | epoch 012:   1525 / 1826 loss=1.989, trans_loss=4.84, nll_loss=2.092, w2v_ctc_loss=0.793, task_loss=3.494, contrastive_loss=0, total=4006.68, n_correct=2645.22, ppl=4.26, accuracy=66.02, wps=13102.6, ups=1.64, wpb=8013.4, bsz=299.5, num_updates=21600, lr=9.6225e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=60, gb_free=12.5, wall=17212
2023-08-31 14:31:27 | INFO | train_inner | epoch 012:   1625 / 1826 loss=1.989, trans_loss=4.824, nll_loss=2.071, w2v_ctc_loss=0.796, task_loss=4.127, contrastive_loss=0, total=3889.61, n_correct=2575.54, ppl=4.2, accuracy=66.216, wps=12540, ups=1.61, wpb=7779.2, bsz=264.2, num_updates=21700, lr=9.60031e-05, gnorm=0.563, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=17274
2023-08-31 14:32:28 | INFO | train_inner | epoch 012:   1725 / 1826 loss=1.984, trans_loss=4.822, nll_loss=2.069, w2v_ctc_loss=0.797, task_loss=3.685, contrastive_loss=0, total=3912.29, n_correct=2596.65, ppl=4.2, accuracy=66.372, wps=12815.7, ups=1.64, wpb=7824.6, bsz=282, num_updates=21800, lr=9.57826e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=60, gb_free=10.2, wall=17335
2023-08-31 14:33:29 | INFO | train_inner | epoch 012:   1825 / 1826 loss=1.97, trans_loss=4.8, nll_loss=2.04, w2v_ctc_loss=0.774, task_loss=3.842, contrastive_loss=0, total=3918.09, n_correct=2615.24, ppl=4.11, accuracy=66.748, wps=12822.2, ups=1.64, wpb=7836.2, bsz=273.2, num_updates=21900, lr=9.55637e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=17396
2023-08-31 14:33:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 14:34:09 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.859 | trans_loss 5.067 | nll_loss 2.335 | w2v_ctc_loss 1.428 | task_loss 13.607 | contrastive_loss 0 | total 3505.91 | n_correct 2382.09 | ppl 5.05 | accuracy 67.945 | uer 19.115 | wer 21.028 | raw_wer 21.028 | bleu 29.51 | wps 1206 | wpb 3505.9 | bsz 119.3 | num_updates 21901 | best_bleu 29.56
2023-08-31 14:34:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 21901 updates
2023-08-31 14:34:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_29.5104.pt
2023-08-31 14:34:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_29.5104.pt
2023-08-31 14:34:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_29.5104.pt (epoch 12 @ 21901 updates, score 29.51) (writing took 7.219276950010681 seconds)
2023-08-31 14:34:16 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-31 14:34:16 | INFO | train | epoch 012 | loss 1.978 | trans_loss 4.813 | nll_loss 2.057 | w2v_ctc_loss 0.785 | task_loss 3.649 | contrastive_loss 0 | total 3956.59 | n_correct 2629.21 | ppl 4.16 | accuracy 66.451 | wps 12345.6 | ups 1.56 | wpb 7913.2 | bsz 284.9 | num_updates 21901 | lr 9.55615e-05 | gnorm 0.567 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 9.9 | wall 17443
2023-08-31 14:34:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 14:34:16 | INFO | fairseq.trainer | begin training epoch 13
2023-08-31 14:34:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 14:35:24 | INFO | train_inner | epoch 013:     99 / 1826 loss=1.955, trans_loss=4.789, nll_loss=2.025, w2v_ctc_loss=0.758, task_loss=3.484, contrastive_loss=0, total=3951.79, n_correct=2653.68, ppl=4.07, accuracy=67.151, wps=6897.8, ups=0.87, wpb=7903.6, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=60, gb_free=16.9, wall=17511
2023-08-31 14:35:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 14:36:03 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.858 | trans_loss 5.061 | nll_loss 2.33 | w2v_ctc_loss 1.441 | task_loss 13.666 | contrastive_loss 0 | total 3505.91 | n_correct 2387.73 | ppl 5.03 | accuracy 68.106 | uer 18.989 | wer 20.892 | raw_wer 20.892 | bleu 29.96 | wps 1194 | wpb 3505.9 | bsz 119.3 | num_updates 22000 | best_bleu 29.96
2023-08-31 14:36:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 22000 updates
2023-08-31 14:36:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_13_22000.pt
2023-08-31 14:36:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_13_22000.pt
2023-08-31 14:36:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_13_22000.pt (epoch 13 @ 22000 updates, score 29.96) (writing took 13.839685011000256 seconds)
2023-08-31 14:37:19 | INFO | train_inner | epoch 013:    199 / 1826 loss=1.966, trans_loss=4.794, nll_loss=2.032, w2v_ctc_loss=0.78, task_loss=3.669, contrastive_loss=0, total=3970.4, n_correct=2656.49, ppl=4.09, accuracy=66.907, wps=6929.1, ups=0.87, wpb=7940.8, bsz=284.8, num_updates=22100, lr=9.51303e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=60, gb_free=13, wall=17625
2023-08-31 14:38:20 | INFO | train_inner | epoch 013:    299 / 1826 loss=1.965, trans_loss=4.796, nll_loss=2.035, w2v_ctc_loss=0.773, task_loss=3.674, contrastive_loss=0, total=3986.51, n_correct=2666.77, ppl=4.1, accuracy=66.895, wps=13041.1, ups=1.64, wpb=7973, bsz=283.1, num_updates=22200, lr=9.49158e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=61, gb_free=17.5, wall=17686
2023-08-31 14:39:21 | INFO | train_inner | epoch 013:    399 / 1826 loss=1.962, trans_loss=4.798, nll_loss=2.038, w2v_ctc_loss=0.766, task_loss=3.305, contrastive_loss=0, total=4001.88, n_correct=2669.69, ppl=4.11, accuracy=66.711, wps=13047.5, ups=1.63, wpb=8003.8, bsz=306.1, num_updates=22300, lr=9.47027e-05, gnorm=0.655, clip=0, loss_scale=16, train_wall=61, gb_free=17.2, wall=17748
2023-08-31 14:40:22 | INFO | train_inner | epoch 013:    499 / 1826 loss=1.965, trans_loss=4.792, nll_loss=2.029, w2v_ctc_loss=0.773, task_loss=3.668, contrastive_loss=0, total=3901.27, n_correct=2610.14, ppl=4.08, accuracy=66.905, wps=12722.2, ups=1.63, wpb=7802.5, bsz=284.4, num_updates=22400, lr=9.44911e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=17809
2023-08-31 14:41:24 | INFO | train_inner | epoch 013:    599 / 1826 loss=1.97, trans_loss=4.798, nll_loss=2.037, w2v_ctc_loss=0.781, task_loss=3.799, contrastive_loss=0, total=3897.32, n_correct=2602.39, ppl=4.1, accuracy=66.774, wps=12762.3, ups=1.64, wpb=7794.6, bsz=275.1, num_updates=22500, lr=9.42809e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=17870
2023-08-31 14:42:25 | INFO | train_inner | epoch 013:    699 / 1826 loss=1.972, trans_loss=4.796, nll_loss=2.035, w2v_ctc_loss=0.789, task_loss=3.877, contrastive_loss=0, total=3937.91, n_correct=2635.21, ppl=4.1, accuracy=66.919, wps=12832.9, ups=1.63, wpb=7875.8, bsz=273.4, num_updates=22600, lr=9.40721e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=17932
2023-08-31 14:43:26 | INFO | train_inner | epoch 013:    799 / 1826 loss=1.965, trans_loss=4.797, nll_loss=2.036, w2v_ctc_loss=0.77, task_loss=3.733, contrastive_loss=0, total=3984.41, n_correct=2663.51, ppl=4.1, accuracy=66.848, wps=12970.3, ups=1.63, wpb=7968.8, bsz=286, num_updates=22700, lr=9.38647e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=17993
2023-08-31 14:44:28 | INFO | train_inner | epoch 013:    899 / 1826 loss=1.962, trans_loss=4.788, nll_loss=2.025, w2v_ctc_loss=0.773, task_loss=3.665, contrastive_loss=0, total=3960.48, n_correct=2656.76, ppl=4.07, accuracy=67.082, wps=12937, ups=1.63, wpb=7921, bsz=282.4, num_updates=22800, lr=9.36586e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=61, gb_free=11.5, wall=18054
2023-08-31 14:45:28 | INFO | train_inner | epoch 013:    999 / 1826 loss=1.956, trans_loss=4.784, nll_loss=2.019, w2v_ctc_loss=0.761, task_loss=3.697, contrastive_loss=0, total=3909.32, n_correct=2623.4, ppl=4.05, accuracy=67.106, wps=12880, ups=1.65, wpb=7818.6, bsz=278.3, num_updates=22900, lr=9.34539e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=60, gb_free=15.4, wall=18115
2023-08-31 14:46:30 | INFO | train_inner | epoch 013:   1099 / 1826 loss=1.966, trans_loss=4.794, nll_loss=2.033, w2v_ctc_loss=0.775, task_loss=3.673, contrastive_loss=0, total=3990.21, n_correct=2667.6, ppl=4.09, accuracy=66.854, wps=13003.6, ups=1.63, wpb=7980.4, bsz=285.5, num_updates=23000, lr=9.32505e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=18176
2023-08-31 14:47:31 | INFO | train_inner | epoch 013:   1199 / 1826 loss=1.967, trans_loss=4.8, nll_loss=2.04, w2v_ctc_loss=0.778, task_loss=3.592, contrastive_loss=0, total=3993.59, n_correct=2666.14, ppl=4.11, accuracy=66.76, wps=13073.6, ups=1.64, wpb=7987.2, bsz=288.7, num_updates=23100, lr=9.30484e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=18237
2023-08-31 14:48:32 | INFO | train_inner | epoch 013:   1299 / 1826 loss=1.965, trans_loss=4.798, nll_loss=2.037, w2v_ctc_loss=0.773, task_loss=3.671, contrastive_loss=0, total=3979.84, n_correct=2662.25, ppl=4.1, accuracy=66.893, wps=12948.9, ups=1.63, wpb=7959.7, bsz=285, num_updates=23200, lr=9.28477e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=61, gb_free=14.6, wall=18299
2023-08-31 14:49:33 | INFO | train_inner | epoch 013:   1399 / 1826 loss=1.96, trans_loss=4.791, nll_loss=2.029, w2v_ctc_loss=0.769, task_loss=3.454, contrastive_loss=0, total=3968.45, n_correct=2660.65, ppl=4.08, accuracy=67.045, wps=13064.5, ups=1.65, wpb=7936.9, bsz=292.5, num_updates=23300, lr=9.26482e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=18360
2023-08-31 14:50:34 | INFO | train_inner | epoch 013:   1499 / 1826 loss=1.963, trans_loss=4.792, nll_loss=2.031, w2v_ctc_loss=0.769, task_loss=3.829, contrastive_loss=0, total=3926.75, n_correct=2628.64, ppl=4.09, accuracy=66.942, wps=12856.4, ups=1.64, wpb=7853.5, bsz=276.5, num_updates=23400, lr=9.245e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=60, gb_free=17.2, wall=18421
2023-08-31 14:51:35 | INFO | train_inner | epoch 013:   1599 / 1826 loss=1.963, trans_loss=4.787, nll_loss=2.024, w2v_ctc_loss=0.77, task_loss=3.859, contrastive_loss=0, total=3880.79, n_correct=2599.51, ppl=4.07, accuracy=66.984, wps=12692.9, ups=1.64, wpb=7761.6, bsz=270.5, num_updates=23500, lr=9.22531e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=60, gb_free=14.2, wall=18482
2023-08-31 14:52:37 | INFO | train_inner | epoch 013:   1699 / 1826 loss=1.961, trans_loss=4.79, nll_loss=2.028, w2v_ctc_loss=0.771, task_loss=3.655, contrastive_loss=0, total=3971.14, n_correct=2659.79, ppl=4.08, accuracy=66.978, wps=12913.6, ups=1.63, wpb=7942.3, bsz=286.1, num_updates=23600, lr=9.20575e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=18543
2023-08-31 14:53:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 14:53:38 | INFO | train_inner | epoch 013:   1800 / 1826 loss=1.96, trans_loss=4.802, nll_loss=2.044, w2v_ctc_loss=0.76, task_loss=3.38, contrastive_loss=0, total=4010.64, n_correct=2679.89, ppl=4.12, accuracy=66.82, wps=13129.6, ups=1.64, wpb=8021.3, bsz=300.1, num_updates=23700, lr=9.1863e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=60, gb_free=15.1, wall=18604
2023-08-31 14:53:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 14:54:32 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.838 | trans_loss 5.045 | nll_loss 2.306 | w2v_ctc_loss 1.41 | task_loss 13.586 | contrastive_loss 0 | total 3505.91 | n_correct 2393.09 | ppl 4.95 | accuracy 68.259 | uer 19.174 | wer 21.189 | raw_wer 21.189 | bleu 30.16 | wps 1194.3 | wpb 3505.9 | bsz 119.3 | num_updates 23726 | best_bleu 30.16
2023-08-31 14:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 23726 updates
2023-08-31 14:54:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 14:54:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 14:54:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 13 @ 23726 updates, score 30.16) (writing took 14.145060757000465 seconds)
2023-08-31 14:54:47 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-31 14:54:47 | INFO | train | epoch 013 | loss 1.964 | trans_loss 4.794 | nll_loss 2.032 | w2v_ctc_loss 0.772 | task_loss 3.649 | contrastive_loss 0 | total 3956.26 | n_correct 2647.47 | ppl 4.09 | accuracy 66.919 | wps 11734.3 | ups 1.48 | wpb 7912.5 | bsz 284.8 | num_updates 23726 | lr 9.18127e-05 | gnorm 0.558 | clip 0 | loss_scale 16 | train_wall 1104 | gb_free 11.5 | wall 18673
2023-08-31 14:54:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 14:54:47 | INFO | fairseq.trainer | begin training epoch 14
2023-08-31 14:54:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 14:55:40 | INFO | train_inner | epoch 014:     74 / 1826 loss=1.956, trans_loss=4.778, nll_loss=2.011, w2v_ctc_loss=0.766, task_loss=3.824, contrastive_loss=0, total=3897.07, n_correct=2622.51, ppl=4.03, accuracy=67.294, wps=6382.5, ups=0.82, wpb=7794.1, bsz=272.2, num_updates=23800, lr=9.16698e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=61, gb_free=13.7, wall=18727
2023-08-31 14:56:41 | INFO | train_inner | epoch 014:    174 / 1826 loss=1.946, trans_loss=4.771, nll_loss=2.002, w2v_ctc_loss=0.756, task_loss=3.592, contrastive_loss=0, total=3939.44, n_correct=2657.08, ppl=4.01, accuracy=67.448, wps=12947.3, ups=1.64, wpb=7878.9, bsz=288.3, num_updates=23900, lr=9.14779e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=60, gb_free=15.1, wall=18787
2023-08-31 14:57:42 | INFO | train_inner | epoch 014:    274 / 1826 loss=1.946, trans_loss=4.774, nll_loss=2.007, w2v_ctc_loss=0.756, task_loss=3.476, contrastive_loss=0, total=3978.85, n_correct=2682.95, ppl=4.02, accuracy=67.43, wps=13077.2, ups=1.64, wpb=7957.7, bsz=296.6, num_updates=24000, lr=9.12871e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=60, gb_free=14.4, wall=18848
2023-08-31 14:57:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 14:58:21 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.828 | trans_loss 5.042 | nll_loss 2.302 | w2v_ctc_loss 1.381 | task_loss 13.498 | contrastive_loss 0 | total 3505.91 | n_correct 2391.64 | ppl 4.93 | accuracy 68.217 | uer 18.866 | wer 20.881 | raw_wer 20.881 | bleu 29.68 | wps 1199.3 | wpb 3505.9 | bsz 119.3 | num_updates 24000 | best_bleu 30.16
2023-08-31 14:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 24000 updates
2023-08-31 14:58:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_14_24000.pt
2023-08-31 14:58:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_14_24000.pt
2023-08-31 14:58:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_14_24000.pt (epoch 14 @ 24000 updates, score 29.68) (writing took 8.088812860994949 seconds)
2023-08-31 14:59:30 | INFO | train_inner | epoch 014:    374 / 1826 loss=1.949, trans_loss=4.777, nll_loss=2.01, w2v_ctc_loss=0.755, task_loss=3.688, contrastive_loss=0, total=3929.39, n_correct=2645.38, ppl=4.03, accuracy=67.323, wps=7251.4, ups=0.92, wpb=7858.8, bsz=282.3, num_updates=24100, lr=9.10975e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=60, gb_free=13.5, wall=18957
2023-08-31 15:00:31 | INFO | train_inner | epoch 014:    474 / 1826 loss=1.95, trans_loss=4.771, nll_loss=2.002, w2v_ctc_loss=0.76, task_loss=3.748, contrastive_loss=0, total=3901.94, n_correct=2631.97, ppl=4.01, accuracy=67.453, wps=12834.2, ups=1.64, wpb=7803.9, bsz=272.6, num_updates=24200, lr=9.09091e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=60, gb_free=16.1, wall=19017
2023-08-31 15:01:32 | INFO | train_inner | epoch 014:    574 / 1826 loss=1.953, trans_loss=4.778, nll_loss=2.012, w2v_ctc_loss=0.761, task_loss=3.719, contrastive_loss=0, total=3923.37, n_correct=2640.03, ppl=4.03, accuracy=67.29, wps=12858.6, ups=1.64, wpb=7846.7, bsz=278.4, num_updates=24300, lr=9.07218e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=60, gb_free=13.3, wall=19078
2023-08-31 15:02:33 | INFO | train_inner | epoch 014:    674 / 1826 loss=1.952, trans_loss=4.778, nll_loss=2.012, w2v_ctc_loss=0.763, task_loss=3.518, contrastive_loss=0, total=3955.77, n_correct=2660.24, ppl=4.03, accuracy=67.25, wps=12915.4, ups=1.63, wpb=7911.5, bsz=293.4, num_updates=24400, lr=9.05357e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=19140
2023-08-31 15:03:34 | INFO | train_inner | epoch 014:    774 / 1826 loss=1.942, trans_loss=4.769, nll_loss=2.001, w2v_ctc_loss=0.746, task_loss=3.486, contrastive_loss=0, total=4025.16, n_correct=2717.38, ppl=4, accuracy=67.51, wps=13260.7, ups=1.65, wpb=8050.3, bsz=294.5, num_updates=24500, lr=9.03508e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=19200
2023-08-31 15:04:35 | INFO | train_inner | epoch 014:    874 / 1826 loss=1.954, trans_loss=4.773, nll_loss=2.005, w2v_ctc_loss=0.763, task_loss=3.957, contrastive_loss=0, total=3993.11, n_correct=2687.67, ppl=4.01, accuracy=67.308, wps=12976.6, ups=1.62, wpb=7986.2, bsz=269.9, num_updates=24600, lr=9.0167e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=19262
2023-08-31 15:05:37 | INFO | train_inner | epoch 014:    974 / 1826 loss=1.945, trans_loss=4.775, nll_loss=2.009, w2v_ctc_loss=0.748, task_loss=3.417, contrastive_loss=0, total=4044.19, n_correct=2727.06, ppl=4.02, accuracy=67.432, wps=13188.1, ups=1.63, wpb=8088.4, bsz=302.6, num_updates=24700, lr=8.99843e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=19323
2023-08-31 15:06:39 | INFO | train_inner | epoch 014:   1074 / 1826 loss=1.946, trans_loss=4.768, nll_loss=2, w2v_ctc_loss=0.756, task_loss=3.646, contrastive_loss=0, total=3947.31, n_correct=2664.76, ppl=4, accuracy=67.508, wps=12762.3, ups=1.62, wpb=7894.6, bsz=284.2, num_updates=24800, lr=8.98027e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=61, gb_free=16.6, wall=19385
2023-08-31 15:07:40 | INFO | train_inner | epoch 014:   1174 / 1826 loss=1.953, trans_loss=4.778, nll_loss=2.012, w2v_ctc_loss=0.757, task_loss=3.706, contrastive_loss=0, total=3972.36, n_correct=2671.69, ppl=4.03, accuracy=67.257, wps=12955.3, ups=1.63, wpb=7944.7, bsz=284.6, num_updates=24900, lr=8.96221e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=19447
2023-08-31 15:08:41 | INFO | train_inner | epoch 014:   1274 / 1826 loss=1.947, trans_loss=4.774, nll_loss=2.008, w2v_ctc_loss=0.753, task_loss=3.61, contrastive_loss=0, total=3940.94, n_correct=2655.54, ppl=4.02, accuracy=67.383, wps=12995.4, ups=1.65, wpb=7881.9, bsz=286, num_updates=25000, lr=8.94427e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=60, gb_free=12.6, wall=19507
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:0')
2023-08-31 15:09:42 | INFO | train_inner | epoch 014:   1374 / 1826 loss=1.955, trans_loss=4.783, nll_loss=2.019, w2v_ctc_loss=0.761, task_loss=3.599, contrastive_loss=0, total=3938.73, n_correct=2643.21, ppl=4.05, accuracy=67.108, wps=12799.8, ups=1.62, wpb=7877.5, bsz=290.2, num_updates=25100, lr=8.92644e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=19569
2023-08-31 15:10:43 | INFO | train_inner | epoch 014:   1474 / 1826 loss=1.954, trans_loss=4.782, nll_loss=2.017, w2v_ctc_loss=0.762, task_loss=3.752, contrastive_loss=0, total=3956.81, n_correct=2660.11, ppl=4.05, accuracy=67.229, wps=12973.3, ups=1.64, wpb=7913.6, bsz=280, num_updates=25200, lr=8.90871e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=60, gb_free=15.4, wall=19630
2023-08-31 15:11:45 | INFO | train_inner | epoch 014:   1574 / 1826 loss=1.957, trans_loss=4.777, nll_loss=2.011, w2v_ctc_loss=0.767, task_loss=4.029, contrastive_loss=0, total=3893.92, n_correct=2622.49, ppl=4.03, accuracy=67.348, wps=12691.3, ups=1.63, wpb=7787.8, bsz=265.4, num_updates=25300, lr=8.89108e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=15.4, wall=19691
2023-08-31 15:12:46 | INFO | train_inner | epoch 014:   1674 / 1826 loss=1.949, trans_loss=4.782, nll_loss=2.018, w2v_ctc_loss=0.756, task_loss=3.433, contrastive_loss=0, total=4015.62, n_correct=2701.79, ppl=4.05, accuracy=67.282, wps=13132.9, ups=1.64, wpb=8031.2, bsz=297.5, num_updates=25400, lr=8.87357e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=19752
2023-08-31 15:13:47 | INFO | train_inner | epoch 014:   1774 / 1826 loss=1.945, trans_loss=4.767, nll_loss=2, w2v_ctc_loss=0.753, task_loss=3.58, contrastive_loss=0, total=3969.64, n_correct=2682.09, ppl=4, accuracy=67.565, wps=12994.7, ups=1.64, wpb=7939.3, bsz=286.7, num_updates=25500, lr=8.85615e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=19813
2023-08-31 15:14:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:1')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 15:14:57 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.833 | trans_loss 5.035 | nll_loss 2.292 | w2v_ctc_loss 1.416 | task_loss 13.62 | contrastive_loss 0 | total 3505.91 | n_correct 2402.73 | ppl 4.9 | accuracy 68.534 | uer 18.774 | wer 20.746 | raw_wer 20.746 | bleu 30.37 | wps 1206.5 | wpb 3505.9 | bsz 119.3 | num_updates 25552 | best_bleu 30.37
2023-08-31 15:14:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 25552 updates
2023-08-31 15:14:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 15:15:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 15:15:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 14 @ 25552 updates, score 30.37) (writing took 11.921891164995031 seconds)
2023-08-31 15:15:09 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-31 15:15:09 | INFO | train | epoch 014 | loss 1.95 | trans_loss 4.775 | nll_loss 2.009 | w2v_ctc_loss 0.757 | task_loss 3.646 | contrastive_loss 0 | total 3956.37 | n_correct 2665.18 | ppl 4.02 | accuracy 67.364 | wps 11818.2 | ups 1.49 | wpb 7912.7 | bsz 284.8 | num_updates 25552 | lr 8.84713e-05 | gnorm 0.544 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 17 | wall 19896
2023-08-31 15:15:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 15:15:10 | INFO | fairseq.trainer | begin training epoch 15
2023-08-31 15:15:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 15:15:46 | INFO | train_inner | epoch 015:     48 / 1826 loss=1.944, trans_loss=4.771, nll_loss=2.003, w2v_ctc_loss=0.754, task_loss=3.645, contrastive_loss=0, total=3896.19, n_correct=2638.01, ppl=4.01, accuracy=67.707, wps=6522.9, ups=0.84, wpb=7792.4, bsz=281.4, num_updates=25600, lr=8.83883e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=60, gb_free=17.2, wall=19933
2023-08-31 15:16:47 | INFO | train_inner | epoch 015:    148 / 1826 loss=1.94, trans_loss=4.759, nll_loss=1.987, w2v_ctc_loss=0.749, task_loss=3.692, contrastive_loss=0, total=3927.24, n_correct=2660.71, ppl=3.96, accuracy=67.75, wps=12843.9, ups=1.64, wpb=7854.5, bsz=279.7, num_updates=25700, lr=8.82162e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=61, gb_free=14.9, wall=19994
2023-08-31 15:17:49 | INFO | train_inner | epoch 015:    248 / 1826 loss=1.935, trans_loss=4.756, nll_loss=1.983, w2v_ctc_loss=0.742, task_loss=3.698, contrastive_loss=0, total=3950.05, n_correct=2682.4, ppl=3.95, accuracy=67.908, wps=12807.2, ups=1.62, wpb=7900.1, bsz=280.6, num_updates=25800, lr=8.80451e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=20056
2023-08-31 15:18:50 | INFO | train_inner | epoch 015:    348 / 1826 loss=1.935, trans_loss=4.75, nll_loss=1.976, w2v_ctc_loss=0.744, task_loss=3.614, contrastive_loss=0, total=3981.94, n_correct=2705.07, ppl=3.93, accuracy=67.933, wps=13129.3, ups=1.65, wpb=7963.9, bsz=285.7, num_updates=25900, lr=8.7875e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=60, gb_free=15.5, wall=20116
2023-08-31 15:19:51 | INFO | train_inner | epoch 015:    448 / 1826 loss=1.94, trans_loss=4.758, nll_loss=1.986, w2v_ctc_loss=0.746, task_loss=3.985, contrastive_loss=0, total=3884.54, n_correct=2629.11, ppl=3.96, accuracy=67.681, wps=12719.1, ups=1.64, wpb=7769.1, bsz=265.1, num_updates=26000, lr=8.77058e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=60, gb_free=11, wall=20177
2023-08-31 15:19:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 15:20:29 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.837 | trans_loss 5.038 | nll_loss 2.296 | w2v_ctc_loss 1.422 | task_loss 13.596 | contrastive_loss 0 | total 3505.91 | n_correct 2408.27 | ppl 4.91 | accuracy 68.692 | uer 18.568 | wer 20.427 | raw_wer 20.427 | bleu 30.28 | wps 1209.5 | wpb 3505.9 | bsz 119.3 | num_updates 26000 | best_bleu 30.37
2023-08-31 15:20:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 26000 updates
2023-08-31 15:20:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_15_26000.pt
2023-08-31 15:20:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_15_26000.pt
2023-08-31 15:20:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_15_26000.pt (epoch 15 @ 26000 updates, score 30.28) (writing took 7.110021373999189 seconds)
2023-08-31 15:21:38 | INFO | train_inner | epoch 015:    548 / 1826 loss=1.93, trans_loss=4.752, nll_loss=1.979, w2v_ctc_loss=0.734, task_loss=3.441, contrastive_loss=0, total=3934.61, n_correct=2669.75, ppl=3.94, accuracy=67.853, wps=7364, ups=0.94, wpb=7869.2, bsz=294.8, num_updates=26100, lr=8.75376e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=20284
2023-08-31 15:22:39 | INFO | train_inner | epoch 015:    648 / 1826 loss=1.933, trans_loss=4.752, nll_loss=1.979, w2v_ctc_loss=0.744, task_loss=3.478, contrastive_loss=0, total=3963.95, n_correct=2693.55, ppl=3.94, accuracy=67.951, wps=12938.1, ups=1.63, wpb=7927.9, bsz=292.7, num_updates=26200, lr=8.73704e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=20346
2023-08-31 15:23:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 15:23:40 | INFO | train_inner | epoch 015:    749 / 1826 loss=1.94, trans_loss=4.761, nll_loss=1.99, w2v_ctc_loss=0.747, task_loss=3.794, contrastive_loss=0, total=3893.34, n_correct=2637.2, ppl=3.97, accuracy=67.736, wps=12665.8, ups=1.63, wpb=7786.7, bsz=272.3, num_updates=26300, lr=8.72041e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=61, gb_free=11.9, wall=20407
2023-08-31 15:24:41 | INFO | train_inner | epoch 015:    849 / 1826 loss=1.943, trans_loss=4.757, nll_loss=1.985, w2v_ctc_loss=0.755, task_loss=3.843, contrastive_loss=0, total=3925.07, n_correct=2657.2, ppl=3.96, accuracy=67.698, wps=12870.2, ups=1.64, wpb=7850.1, bsz=273.6, num_updates=26400, lr=8.70388e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=20468
2023-08-31 15:25:43 | INFO | train_inner | epoch 015:    949 / 1826 loss=1.942, trans_loss=4.772, nll_loss=2.005, w2v_ctc_loss=0.745, task_loss=3.692, contrastive_loss=0, total=3976.4, n_correct=2682.68, ppl=4.01, accuracy=67.465, wps=12981.8, ups=1.63, wpb=7952.8, bsz=285.9, num_updates=26500, lr=8.68744e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=61, gb_free=11.3, wall=20529
2023-08-31 15:26:44 | INFO | train_inner | epoch 015:   1049 / 1826 loss=1.939, trans_loss=4.767, nll_loss=1.998, w2v_ctc_loss=0.745, task_loss=3.549, contrastive_loss=0, total=3984.81, n_correct=2694.52, ppl=4, accuracy=67.62, wps=12911.8, ups=1.62, wpb=7969.6, bsz=293.2, num_updates=26600, lr=8.6711e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=61, gb_free=14.4, wall=20591
2023-08-31 15:27:47 | INFO | train_inner | epoch 015:   1149 / 1826 loss=1.941, trans_loss=4.765, nll_loss=1.996, w2v_ctc_loss=0.747, task_loss=3.816, contrastive_loss=0, total=3977.04, n_correct=2690.98, ppl=3.99, accuracy=67.663, wps=12812.3, ups=1.61, wpb=7954.1, bsz=278.6, num_updates=26700, lr=8.65485e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=61, gb_free=11.8, wall=20653
2023-08-31 15:28:47 | INFO | train_inner | epoch 015:   1249 / 1826 loss=1.939, trans_loss=4.758, nll_loss=1.987, w2v_ctc_loss=0.75, task_loss=3.599, contrastive_loss=0, total=3973.86, n_correct=2694.59, ppl=3.96, accuracy=67.808, wps=13043.1, ups=1.64, wpb=7947.7, bsz=285.8, num_updates=26800, lr=8.63868e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=20714
2023-08-31 15:29:49 | INFO | train_inner | epoch 015:   1349 / 1826 loss=1.931, trans_loss=4.757, nll_loss=1.985, w2v_ctc_loss=0.73, task_loss=3.508, contrastive_loss=0, total=3976.34, n_correct=2694.18, ppl=3.96, accuracy=67.755, wps=12909.2, ups=1.62, wpb=7952.7, bsz=298.5, num_updates=26900, lr=8.62261e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=61, gb_free=17.2, wall=20776
2023-08-31 15:30:50 | INFO | train_inner | epoch 015:   1449 / 1826 loss=1.928, trans_loss=4.756, nll_loss=1.986, w2v_ctc_loss=0.732, task_loss=3.279, contrastive_loss=0, total=4020.69, n_correct=2727.46, ppl=3.96, accuracy=67.836, wps=13186.8, ups=1.64, wpb=8041.4, bsz=307.7, num_updates=27000, lr=8.60663e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=60, gb_free=14.2, wall=20837
2023-08-31 15:31:51 | INFO | train_inner | epoch 015:   1549 / 1826 loss=1.949, trans_loss=4.767, nll_loss=1.999, w2v_ctc_loss=0.764, task_loss=3.763, contrastive_loss=0, total=3928.65, n_correct=2651.52, ppl=4, accuracy=67.492, wps=12842.1, ups=1.63, wpb=7857.3, bsz=278.6, num_updates=27100, lr=8.59074e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=20898
2023-08-31 15:32:52 | INFO | train_inner | epoch 015:   1649 / 1826 loss=1.943, trans_loss=4.761, nll_loss=1.991, w2v_ctc_loss=0.753, task_loss=3.777, contrastive_loss=0, total=3972.5, n_correct=2688.11, ppl=3.98, accuracy=67.668, wps=13012.7, ups=1.64, wpb=7945, bsz=276.9, num_updates=27200, lr=8.57493e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=60, gb_free=14.9, wall=20959
2023-08-31 15:33:54 | INFO | train_inner | epoch 015:   1749 / 1826 loss=1.949, trans_loss=4.768, nll_loss=2, w2v_ctc_loss=0.765, task_loss=3.742, contrastive_loss=0, total=3976.02, n_correct=2690.62, ppl=4, accuracy=67.671, wps=12968.2, ups=1.63, wpb=7952, bsz=282, num_updates=27300, lr=8.55921e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=21020
2023-08-31 15:34:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 15:35:20 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.813 | trans_loss 5.032 | nll_loss 2.291 | w2v_ctc_loss 1.355 | task_loss 13.588 | contrastive_loss 0 | total 3505.91 | n_correct 2402.45 | ppl 4.89 | accuracy 68.526 | uer 18.375 | wer 20.487 | raw_wer 20.487 | bleu 30.06 | wps 1195.8 | wpb 3505.9 | bsz 119.3 | num_updates 27377 | best_bleu 30.37
2023-08-31 15:35:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 27377 updates
2023-08-31 15:35:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.0601.pt
2023-08-31 15:35:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.0601.pt
2023-08-31 15:35:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.0601.pt (epoch 15 @ 27377 updates, score 30.06) (writing took 7.315465709994896 seconds)
2023-08-31 15:35:28 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-31 15:35:28 | INFO | train | epoch 015 | loss 1.938 | trans_loss 4.76 | nll_loss 1.989 | w2v_ctc_loss 0.746 | task_loss 3.646 | contrastive_loss 0 | total 3956.7 | n_correct 2680.15 | ppl 3.97 | accuracy 67.737 | wps 11855 | ups 1.5 | wpb 7913.4 | bsz 284.9 | num_updates 27377 | lr 8.54716e-05 | gnorm 0.544 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 15.6 | wall 21114
2023-08-31 15:35:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 15:35:28 | INFO | fairseq.trainer | begin training epoch 16
2023-08-31 15:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 15:35:49 | INFO | train_inner | epoch 016:     23 / 1826 loss=1.938, trans_loss=4.763, nll_loss=1.993, w2v_ctc_loss=0.745, task_loss=3.531, contrastive_loss=0, total=3975.21, n_correct=2689.49, ppl=3.98, accuracy=67.657, wps=6866.9, ups=0.86, wpb=7950.4, bsz=290.5, num_updates=27400, lr=8.54358e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=21136
2023-08-31 15:36:50 | INFO | train_inner | epoch 016:    123 / 1826 loss=1.91, trans_loss=4.734, nll_loss=1.957, w2v_ctc_loss=0.71, task_loss=3.392, contrastive_loss=0, total=4011.89, n_correct=2743.41, ppl=3.88, accuracy=68.382, wps=13208.6, ups=1.65, wpb=8023.8, bsz=300.8, num_updates=27500, lr=8.52803e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=21197
2023-08-31 15:37:51 | INFO | train_inner | epoch 016:    223 / 1826 loss=1.935, trans_loss=4.753, nll_loss=1.98, w2v_ctc_loss=0.746, task_loss=3.576, contrastive_loss=0, total=3965.21, n_correct=2689.01, ppl=3.95, accuracy=67.815, wps=12975.3, ups=1.64, wpb=7930.4, bsz=289.5, num_updates=27600, lr=8.51257e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=60, gb_free=15.4, wall=21258
2023-08-31 15:38:52 | INFO | train_inner | epoch 016:    323 / 1826 loss=1.929, trans_loss=4.747, nll_loss=1.972, w2v_ctc_loss=0.734, task_loss=3.719, contrastive_loss=0, total=3905.2, n_correct=2654.56, ppl=3.92, accuracy=67.975, wps=12805, ups=1.64, wpb=7810.4, bsz=278, num_updates=27700, lr=8.49719e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=60, gb_free=15.6, wall=21319
2023-08-31 15:39:53 | INFO | train_inner | epoch 016:    423 / 1826 loss=1.925, trans_loss=4.748, nll_loss=1.974, w2v_ctc_loss=0.734, task_loss=3.436, contrastive_loss=0, total=3984.93, n_correct=2713.98, ppl=3.93, accuracy=68.106, wps=13122.5, ups=1.65, wpb=7969.9, bsz=299.3, num_updates=27800, lr=8.48189e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=21380
2023-08-31 15:40:54 | INFO | train_inner | epoch 016:    523 / 1826 loss=1.929, trans_loss=4.746, nll_loss=1.972, w2v_ctc_loss=0.733, task_loss=3.812, contrastive_loss=0, total=3949.35, n_correct=2685.85, ppl=3.92, accuracy=68.007, wps=12862.9, ups=1.63, wpb=7898.7, bsz=277.3, num_updates=27900, lr=8.46668e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=21441
2023-08-31 15:41:56 | INFO | train_inner | epoch 016:    623 / 1826 loss=1.933, trans_loss=4.747, nll_loss=1.973, w2v_ctc_loss=0.739, task_loss=3.706, contrastive_loss=0, total=3937.39, n_correct=2675.38, ppl=3.92, accuracy=67.948, wps=12857.4, ups=1.63, wpb=7874.8, bsz=283.1, num_updates=28000, lr=8.45154e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=61, gb_free=13.5, wall=21502
2023-08-31 15:41:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 15:42:34 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.829 | trans_loss 5.031 | nll_loss 2.288 | w2v_ctc_loss 1.409 | task_loss 13.733 | contrastive_loss 0 | total 3505.91 | n_correct 2410 | ppl 4.88 | accuracy 68.741 | uer 18.206 | wer 20.183 | raw_wer 20.183 | bleu 30.64 | wps 1215.6 | wpb 3505.9 | bsz 119.3 | num_updates 28000 | best_bleu 30.64
2023-08-31 15:42:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 28000 updates
2023-08-31 15:42:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_16_28000.pt
2023-08-31 15:42:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_16_28000.pt
2023-08-31 15:42:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_16_28000.pt (epoch 16 @ 28000 updates, score 30.64) (writing took 12.105649263001396 seconds)
2023-08-31 15:43:48 | INFO | train_inner | epoch 016:    723 / 1826 loss=1.929, trans_loss=4.745, nll_loss=1.971, w2v_ctc_loss=0.74, task_loss=3.609, contrastive_loss=0, total=3963.14, n_correct=2697.67, ppl=3.92, accuracy=68.069, wps=7032.8, ups=0.89, wpb=7926.3, bsz=287.6, num_updates=28100, lr=8.43649e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=61, gb_free=14.9, wall=21615
2023-08-31 15:44:50 | INFO | train_inner | epoch 016:    823 / 1826 loss=1.93, trans_loss=4.745, nll_loss=1.97, w2v_ctc_loss=0.738, task_loss=3.86, contrastive_loss=0, total=3929.71, n_correct=2676.08, ppl=3.92, accuracy=68.099, wps=12813.9, ups=1.63, wpb=7859.4, bsz=274.4, num_updates=28200, lr=8.42152e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=21676
2023-08-31 15:45:51 | INFO | train_inner | epoch 016:    923 / 1826 loss=1.934, trans_loss=4.751, nll_loss=1.978, w2v_ctc_loss=0.74, task_loss=3.855, contrastive_loss=0, total=3932.85, n_correct=2671.48, ppl=3.94, accuracy=67.927, wps=12860.2, ups=1.63, wpb=7865.7, bsz=272.2, num_updates=28300, lr=8.40663e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=61, gb_free=12.7, wall=21737
2023-08-31 15:46:52 | INFO | train_inner | epoch 016:   1023 / 1826 loss=1.929, trans_loss=4.747, nll_loss=1.973, w2v_ctc_loss=0.737, task_loss=3.695, contrastive_loss=0, total=3929.66, n_correct=2671.29, ppl=3.92, accuracy=67.978, wps=12872.4, ups=1.64, wpb=7859.3, bsz=281.7, num_updates=28400, lr=8.39181e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=60, gb_free=11.9, wall=21799
2023-08-31 15:47:53 | INFO | train_inner | epoch 016:   1123 / 1826 loss=1.932, trans_loss=4.748, nll_loss=1.975, w2v_ctc_loss=0.74, task_loss=3.627, contrastive_loss=0, total=3988.26, n_correct=2711.46, ppl=3.93, accuracy=67.986, wps=13158.1, ups=1.65, wpb=7976.5, bsz=280.8, num_updates=28500, lr=8.37708e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=21859
2023-08-31 15:48:54 | INFO | train_inner | epoch 016:   1223 / 1826 loss=1.917, trans_loss=4.736, nll_loss=1.959, w2v_ctc_loss=0.721, task_loss=3.546, contrastive_loss=0, total=3963.52, n_correct=2710.3, ppl=3.89, accuracy=68.381, wps=12980.4, ups=1.64, wpb=7927, bsz=290.7, num_updates=28600, lr=8.36242e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=21920
2023-08-31 15:49:55 | INFO | train_inner | epoch 016:   1323 / 1826 loss=1.937, trans_loss=4.747, nll_loss=1.972, w2v_ctc_loss=0.75, task_loss=4.009, contrastive_loss=0, total=3907.39, n_correct=2653.85, ppl=3.92, accuracy=67.919, wps=12725, ups=1.63, wpb=7814.8, bsz=268.1, num_updates=28700, lr=8.34784e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=61, gb_free=14.7, wall=21982
2023-08-31 15:50:56 | INFO | train_inner | epoch 016:   1423 / 1826 loss=1.927, trans_loss=4.743, nll_loss=1.969, w2v_ctc_loss=0.734, task_loss=3.678, contrastive_loss=0, total=3965.35, n_correct=2699.25, ppl=3.91, accuracy=68.071, wps=12918.6, ups=1.63, wpb=7930.7, bsz=288, num_updates=28800, lr=8.33333e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=22043
2023-08-31 15:51:58 | INFO | train_inner | epoch 016:   1523 / 1826 loss=1.937, trans_loss=4.752, nll_loss=1.979, w2v_ctc_loss=0.753, task_loss=3.733, contrastive_loss=0, total=3946.03, n_correct=2678.92, ppl=3.94, accuracy=67.889, wps=12860.1, ups=1.63, wpb=7892.1, bsz=281.3, num_updates=28900, lr=8.3189e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=22104
2023-08-31 15:52:59 | INFO | train_inner | epoch 016:   1623 / 1826 loss=1.925, trans_loss=4.747, nll_loss=1.973, w2v_ctc_loss=0.73, task_loss=3.54, contrastive_loss=0, total=3992.41, n_correct=2717.74, ppl=3.93, accuracy=68.073, wps=13066.3, ups=1.64, wpb=7984.8, bsz=293.5, num_updates=29000, lr=8.30455e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=61, gb_free=14, wall=22166
2023-08-31 15:54:01 | INFO | train_inner | epoch 016:   1723 / 1826 loss=1.93, trans_loss=4.752, nll_loss=1.98, w2v_ctc_loss=0.739, task_loss=3.545, contrastive_loss=0, total=4015.55, n_correct=2727.67, ppl=3.94, accuracy=67.928, wps=13006.1, ups=1.62, wpb=8031.1, bsz=296.5, num_updates=29100, lr=8.29027e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=22227
2023-08-31 15:55:01 | INFO | train_inner | epoch 016:   1823 / 1826 loss=1.926, trans_loss=4.745, nll_loss=1.971, w2v_ctc_loss=0.735, task_loss=3.435, contrastive_loss=0, total=3968.67, n_correct=2706.12, ppl=3.92, accuracy=68.187, wps=13137, ups=1.66, wpb=7937.3, bsz=290.9, num_updates=29200, lr=8.27606e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=22288
2023-08-31 15:55:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 15:55:42 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.801 | trans_loss 5.022 | nll_loss 2.28 | w2v_ctc_loss 1.338 | task_loss 13.563 | contrastive_loss 0 | total 3505.91 | n_correct 2410.18 | ppl 4.86 | accuracy 68.746 | uer 18.557 | wer 20.682 | raw_wer 20.682 | bleu 30.56 | wps 1197.9 | wpb 3505.9 | bsz 119.3 | num_updates 29203 | best_bleu 30.64
2023-08-31 15:55:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 29203 updates
2023-08-31 15:55:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.5608.pt
2023-08-31 15:55:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.5608.pt
2023-08-31 15:55:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.5608.pt (epoch 16 @ 29203 updates, score 30.56) (writing took 6.337954082002398 seconds)
2023-08-31 15:55:48 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-31 15:55:48 | INFO | train | epoch 016 | loss 1.929 | trans_loss 4.746 | nll_loss 1.972 | w2v_ctc_loss 0.737 | task_loss 3.652 | contrastive_loss 0 | total 3956.37 | n_correct 2691.94 | ppl 3.92 | accuracy 68.041 | wps 11836.4 | ups 1.5 | wpb 7912.7 | bsz 284.8 | num_updates 29203 | lr 8.27563e-05 | gnorm 0.549 | clip 0 | loss_scale 32 | train_wall 1104 | gb_free 15.6 | wall 22335
2023-08-31 15:55:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 15:55:49 | INFO | fairseq.trainer | begin training epoch 17
2023-08-31 15:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 15:56:55 | INFO | train_inner | epoch 017:     97 / 1826 loss=1.918, trans_loss=4.725, nll_loss=1.945, w2v_ctc_loss=0.728, task_loss=3.56, contrastive_loss=0, total=3928.4, n_correct=2687.45, ppl=3.85, accuracy=68.411, wps=6875.2, ups=0.88, wpb=7856.8, bsz=283.7, num_updates=29300, lr=8.26192e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=61, gb_free=17.3, wall=22402
2023-08-31 15:57:56 | INFO | train_inner | epoch 017:    197 / 1826 loss=1.906, trans_loss=4.713, nll_loss=1.93, w2v_ctc_loss=0.72, task_loss=3.344, contrastive_loss=0, total=3988.93, n_correct=2740.62, ppl=3.81, accuracy=68.706, wps=13175.9, ups=1.65, wpb=7977.9, bsz=302.4, num_updates=29400, lr=8.24786e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=22463
2023-08-31 15:58:57 | INFO | train_inner | epoch 017:    297 / 1826 loss=1.925, trans_loss=4.733, nll_loss=1.954, w2v_ctc_loss=0.733, task_loss=4.084, contrastive_loss=0, total=3861.43, n_correct=2636.39, ppl=3.87, accuracy=68.275, wps=12668.1, ups=1.64, wpb=7722.9, bsz=260.6, num_updates=29500, lr=8.23387e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=22524
2023-08-31 15:59:58 | INFO | train_inner | epoch 017:    397 / 1826 loss=1.921, trans_loss=4.732, nll_loss=1.953, w2v_ctc_loss=0.731, task_loss=3.667, contrastive_loss=0, total=3958.44, n_correct=2704.88, ppl=3.87, accuracy=68.332, wps=12900, ups=1.63, wpb=7916.9, bsz=287.9, num_updates=29600, lr=8.21995e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=61, gb_free=12.8, wall=22585
2023-08-31 16:00:59 | INFO | train_inner | epoch 017:    497 / 1826 loss=1.916, trans_loss=4.735, nll_loss=1.957, w2v_ctc_loss=0.725, task_loss=3.391, contrastive_loss=0, total=4001.44, n_correct=2733.04, ppl=3.88, accuracy=68.301, wps=13242.5, ups=1.65, wpb=8002.9, bsz=300.2, num_updates=29700, lr=8.2061e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=22645
2023-08-31 16:02:01 | INFO | train_inner | epoch 017:    597 / 1826 loss=1.917, trans_loss=4.734, nll_loss=1.956, w2v_ctc_loss=0.721, task_loss=3.599, contrastive_loss=0, total=3977.51, n_correct=2722.41, ppl=3.88, accuracy=68.445, wps=12881.6, ups=1.62, wpb=7955, bsz=287.7, num_updates=29800, lr=8.19232e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=22707
2023-08-31 16:03:02 | INFO | train_inner | epoch 017:    697 / 1826 loss=1.924, trans_loss=4.739, nll_loss=1.963, w2v_ctc_loss=0.731, task_loss=3.797, contrastive_loss=0, total=3917.79, n_correct=2671.04, ppl=3.9, accuracy=68.177, wps=12785.3, ups=1.63, wpb=7835.6, bsz=278, num_updates=29900, lr=8.17861e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=22768
2023-08-31 16:04:03 | INFO | train_inner | epoch 017:    797 / 1826 loss=1.924, trans_loss=4.74, nll_loss=1.965, w2v_ctc_loss=0.732, task_loss=3.854, contrastive_loss=0, total=3902.07, n_correct=2666.66, ppl=3.9, accuracy=68.34, wps=12705.7, ups=1.63, wpb=7804.1, bsz=276.1, num_updates=30000, lr=8.16497e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=22830
2023-08-31 16:04:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 16:04:42 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.823 | trans_loss 5.024 | nll_loss 2.278 | w2v_ctc_loss 1.406 | task_loss 13.579 | contrastive_loss 0 | total 3505.91 | n_correct 2405.36 | ppl 4.85 | accuracy 68.609 | uer 18.447 | wer 20.491 | raw_wer 20.491 | bleu 30.74 | wps 1196.5 | wpb 3505.9 | bsz 119.3 | num_updates 30000 | best_bleu 30.74
2023-08-31 16:04:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 30000 updates
2023-08-31 16:04:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_17_30000.pt
2023-08-31 16:04:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_17_30000.pt
2023-08-31 16:04:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_17_30000.pt (epoch 17 @ 30000 updates, score 30.74) (writing took 12.589202429007855 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:0')
2023-08-31 16:05:56 | INFO | train_inner | epoch 017:    897 / 1826 loss=1.923, trans_loss=4.735, nll_loss=1.958, w2v_ctc_loss=0.731, task_loss=3.759, contrastive_loss=0, total=3981.01, n_correct=2721.02, ppl=3.89, accuracy=68.35, wps=7031, ups=0.88, wpb=7962, bsz=277.5, num_updates=30100, lr=8.15139e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=22943
2023-08-31 16:06:57 | INFO | train_inner | epoch 017:    997 / 1826 loss=1.918, trans_loss=4.735, nll_loss=1.957, w2v_ctc_loss=0.722, task_loss=3.578, contrastive_loss=0, total=3999.96, n_correct=2733, ppl=3.88, accuracy=68.326, wps=13138.1, ups=1.64, wpb=7999.9, bsz=288.6, num_updates=30200, lr=8.13788e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=23004
2023-08-31 16:07:59 | INFO | train_inner | epoch 017:   1097 / 1826 loss=1.923, trans_loss=4.734, nll_loss=1.956, w2v_ctc_loss=0.731, task_loss=3.871, contrastive_loss=0, total=3926.87, n_correct=2681.73, ppl=3.88, accuracy=68.292, wps=12820.4, ups=1.63, wpb=7853.7, bsz=272.3, num_updates=30300, lr=8.12444e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=23065
2023-08-31 16:08:59 | INFO | train_inner | epoch 017:   1197 / 1826 loss=1.917, trans_loss=4.733, nll_loss=1.955, w2v_ctc_loss=0.722, task_loss=3.665, contrastive_loss=0, total=3954.16, n_correct=2703.11, ppl=3.88, accuracy=68.361, wps=13067.4, ups=1.65, wpb=7908.3, bsz=284.2, num_updates=30400, lr=8.11107e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=60, gb_free=12.1, wall=23126
2023-08-31 16:09:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-31 16:10:00 | INFO | train_inner | epoch 017:   1298 / 1826 loss=1.913, trans_loss=4.726, nll_loss=1.946, w2v_ctc_loss=0.724, task_loss=3.51, contrastive_loss=0, total=3981.08, n_correct=2728.26, ppl=3.85, accuracy=68.531, wps=12993.7, ups=1.63, wpb=7962.2, bsz=288.1, num_updates=30500, lr=8.09776e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=23187
2023-08-31 16:11:01 | INFO | train_inner | epoch 017:   1398 / 1826 loss=1.915, trans_loss=4.724, nll_loss=1.943, w2v_ctc_loss=0.725, task_loss=3.803, contrastive_loss=0, total=3917.91, n_correct=2686.07, ppl=3.85, accuracy=68.559, wps=12835.8, ups=1.64, wpb=7835.8, bsz=275.5, num_updates=30600, lr=8.08452e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=23248
2023-08-31 16:12:04 | INFO | train_inner | epoch 017:   1498 / 1826 loss=1.925, trans_loss=4.748, nll_loss=1.976, w2v_ctc_loss=0.73, task_loss=3.524, contrastive_loss=0, total=3964.73, n_correct=2691.62, ppl=3.93, accuracy=67.889, wps=12758.3, ups=1.61, wpb=7929.5, bsz=301.2, num_updates=30700, lr=8.07134e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=62, gb_free=16.1, wall=23310
2023-08-31 16:13:05 | INFO | train_inner | epoch 017:   1598 / 1826 loss=1.922, trans_loss=4.743, nll_loss=1.969, w2v_ctc_loss=0.728, task_loss=3.542, contrastive_loss=0, total=3982.88, n_correct=2713.97, ppl=3.91, accuracy=68.141, wps=13045, ups=1.64, wpb=7965.8, bsz=294.1, num_updates=30800, lr=8.05823e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=23371
2023-08-31 16:14:06 | INFO | train_inner | epoch 017:   1698 / 1826 loss=1.915, trans_loss=4.734, nll_loss=1.957, w2v_ctc_loss=0.717, task_loss=3.611, contrastive_loss=0, total=4008.39, n_correct=2741.03, ppl=3.88, accuracy=68.382, wps=13041.3, ups=1.63, wpb=8016.8, bsz=287.6, num_updates=30900, lr=8.04518e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=23433
2023-08-31 16:14:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 16:15:08 | INFO | train_inner | epoch 017:   1799 / 1826 loss=1.917, trans_loss=4.728, nll_loss=1.948, w2v_ctc_loss=0.726, task_loss=3.788, contrastive_loss=0, total=3940.26, n_correct=2697.86, ppl=3.86, accuracy=68.469, wps=12748.2, ups=1.62, wpb=7880.5, bsz=278.8, num_updates=31000, lr=8.03219e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=23495
2023-08-31 16:15:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:1')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 16:16:03 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.815 | trans_loss 5.015 | nll_loss 2.268 | w2v_ctc_loss 1.401 | task_loss 13.72 | contrastive_loss 0 | total 3505.91 | n_correct 2415 | ppl 4.82 | accuracy 68.884 | uer 18.273 | wer 20.292 | raw_wer 20.292 | bleu 30.94 | wps 1208.5 | wpb 3505.9 | bsz 119.3 | num_updates 31027 | best_bleu 30.94
2023-08-31 16:16:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 31027 updates
2023-08-31 16:16:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 16:16:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 16:16:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 17 @ 31027 updates, score 30.94) (writing took 12.625500100999488 seconds)
2023-08-31 16:16:16 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-31 16:16:16 | INFO | train | epoch 017 | loss 1.919 | trans_loss 4.733 | nll_loss 1.955 | w2v_ctc_loss 0.726 | task_loss 3.654 | contrastive_loss 0 | total 3956.41 | n_correct 2704.31 | ppl 3.88 | accuracy 68.353 | wps 11757 | ups 1.49 | wpb 7912.8 | bsz 284.9 | num_updates 31027 | lr 8.0287e-05 | gnorm 0.546 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 13.6 | wall 23563
2023-08-31 16:16:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 16:16:16 | INFO | fairseq.trainer | begin training epoch 18
2023-08-31 16:16:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 16:17:08 | INFO | train_inner | epoch 018:     73 / 1826 loss=1.904, trans_loss=4.715, nll_loss=1.931, w2v_ctc_loss=0.712, task_loss=3.384, contrastive_loss=0, total=4013.13, n_correct=2760.54, ppl=3.81, accuracy=68.788, wps=6664.4, ups=0.83, wpb=8026.3, bsz=301.3, num_updates=31100, lr=8.01927e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=23615
2023-08-31 16:18:10 | INFO | train_inner | epoch 018:    173 / 1826 loss=1.902, trans_loss=4.714, nll_loss=1.931, w2v_ctc_loss=0.708, task_loss=3.413, contrastive_loss=0, total=4003.81, n_correct=2757.62, ppl=3.81, accuracy=68.875, wps=13107.9, ups=1.64, wpb=8007.6, bsz=300.8, num_updates=31200, lr=8.00641e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=61, gb_free=15.4, wall=23676
2023-08-31 16:19:10 | INFO | train_inner | epoch 018:    273 / 1826 loss=1.896, trans_loss=4.71, nll_loss=1.926, w2v_ctc_loss=0.697, task_loss=3.545, contrastive_loss=0, total=3991.27, n_correct=2752.53, ppl=3.8, accuracy=68.964, wps=13112.5, ups=1.64, wpb=7982.5, bsz=288.8, num_updates=31300, lr=7.99361e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=60, gb_free=16.7, wall=23737
2023-08-31 16:20:12 | INFO | train_inner | epoch 018:    373 / 1826 loss=1.908, trans_loss=4.708, nll_loss=1.923, w2v_ctc_loss=0.719, task_loss=3.695, contrastive_loss=0, total=3961.94, n_correct=2724.82, ppl=3.79, accuracy=68.775, wps=12879.7, ups=1.63, wpb=7923.9, bsz=279.3, num_updates=31400, lr=7.98087e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=23799
2023-08-31 16:21:13 | INFO | train_inner | epoch 018:    473 / 1826 loss=1.908, trans_loss=4.717, nll_loss=1.934, w2v_ctc_loss=0.718, task_loss=3.596, contrastive_loss=0, total=3963.48, n_correct=2723.67, ppl=3.82, accuracy=68.719, wps=12936.6, ups=1.63, wpb=7927, bsz=289, num_updates=31500, lr=7.96819e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=23860
2023-08-31 16:22:14 | INFO | train_inner | epoch 018:    573 / 1826 loss=1.913, trans_loss=4.724, nll_loss=1.944, w2v_ctc_loss=0.725, task_loss=3.457, contrastive_loss=0, total=3998.24, n_correct=2740.36, ppl=3.85, accuracy=68.539, wps=13112, ups=1.64, wpb=7996.5, bsz=294.7, num_updates=31600, lr=7.95557e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=60, gb_free=11.9, wall=23921
2023-08-31 16:23:16 | INFO | train_inner | epoch 018:    673 / 1826 loss=1.912, trans_loss=4.72, nll_loss=1.938, w2v_ctc_loss=0.717, task_loss=3.905, contrastive_loss=0, total=3922.57, n_correct=2691.82, ppl=3.83, accuracy=68.624, wps=12761.5, ups=1.63, wpb=7845.1, bsz=272.7, num_updates=31700, lr=7.94301e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=16.1, wall=23982
2023-08-31 16:24:17 | INFO | train_inner | epoch 018:    773 / 1826 loss=1.911, trans_loss=4.724, nll_loss=1.943, w2v_ctc_loss=0.712, task_loss=3.843, contrastive_loss=0, total=3942.29, n_correct=2701.17, ppl=3.84, accuracy=68.518, wps=12849.9, ups=1.63, wpb=7884.6, bsz=276.5, num_updates=31800, lr=7.93052e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=61, gb_free=12.9, wall=24044
2023-08-31 16:25:18 | INFO | train_inner | epoch 018:    873 / 1826 loss=1.907, trans_loss=4.716, nll_loss=1.933, w2v_ctc_loss=0.714, task_loss=3.675, contrastive_loss=0, total=3968.62, n_correct=2731.65, ppl=3.82, accuracy=68.831, wps=13093, ups=1.65, wpb=7937.2, bsz=281.7, num_updates=31900, lr=7.91808e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=60, gb_free=13.7, wall=24104
2023-08-31 16:26:19 | INFO | train_inner | epoch 018:    973 / 1826 loss=1.914, trans_loss=4.722, nll_loss=1.942, w2v_ctc_loss=0.73, task_loss=3.594, contrastive_loss=0, total=3937.15, n_correct=2702.97, ppl=3.84, accuracy=68.653, wps=12910.9, ups=1.64, wpb=7874.3, bsz=288.7, num_updates=32000, lr=7.90569e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=24165
2023-08-31 16:26:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 16:26:57 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.812 | trans_loss 5.019 | nll_loss 2.276 | w2v_ctc_loss 1.38 | task_loss 13.66 | contrastive_loss 0 | total 3505.91 | n_correct 2410.82 | ppl 4.84 | accuracy 68.764 | uer 18.267 | wer 20.168 | raw_wer 20.168 | bleu 30.35 | wps 1211.7 | wpb 3505.9 | bsz 119.3 | num_updates 32000 | best_bleu 30.94
2023-08-31 16:26:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 32000 updates
2023-08-31 16:26:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_18_32000.pt
2023-08-31 16:26:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_18_32000.pt
2023-08-31 16:27:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_18_32000.pt (epoch 18 @ 32000 updates, score 30.35) (writing took 7.781022277005832 seconds)
2023-08-31 16:28:07 | INFO | train_inner | epoch 018:   1073 / 1826 loss=1.904, trans_loss=4.72, nll_loss=1.939, w2v_ctc_loss=0.706, task_loss=3.434, contrastive_loss=0, total=4017.18, n_correct=2759.22, ppl=3.83, accuracy=68.685, wps=7446.4, ups=0.93, wpb=8034.4, bsz=303.7, num_updates=32100, lr=7.89337e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=24273
2023-08-31 16:29:08 | INFO | train_inner | epoch 018:   1173 / 1826 loss=1.908, trans_loss=4.718, nll_loss=1.936, w2v_ctc_loss=0.714, task_loss=3.694, contrastive_loss=0, total=3956.34, n_correct=2716.98, ppl=3.83, accuracy=68.674, wps=12889, ups=1.63, wpb=7912.7, bsz=282, num_updates=32200, lr=7.8811e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=61, gb_free=15.4, wall=24335
2023-08-31 16:30:09 | INFO | train_inner | epoch 018:   1273 / 1826 loss=1.908, trans_loss=4.717, nll_loss=1.934, w2v_ctc_loss=0.715, task_loss=3.677, contrastive_loss=0, total=3982.5, n_correct=2739.45, ppl=3.82, accuracy=68.787, wps=13084.5, ups=1.64, wpb=7965, bsz=280.8, num_updates=32300, lr=7.86889e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=60, gb_free=16.1, wall=24395
2023-08-31 16:31:10 | INFO | train_inner | epoch 018:   1373 / 1826 loss=1.911, trans_loss=4.73, nll_loss=1.951, w2v_ctc_loss=0.716, task_loss=3.617, contrastive_loss=0, total=3955.15, n_correct=2709.06, ppl=3.87, accuracy=68.494, wps=12939.3, ups=1.64, wpb=7910.3, bsz=287.8, num_updates=32400, lr=7.85674e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=60, gb_free=12.2, wall=24457
2023-08-31 16:32:11 | INFO | train_inner | epoch 018:   1473 / 1826 loss=1.908, trans_loss=4.718, nll_loss=1.937, w2v_ctc_loss=0.712, task_loss=3.624, contrastive_loss=0, total=3955.16, n_correct=2715.04, ppl=3.83, accuracy=68.646, wps=12907.1, ups=1.63, wpb=7910.3, bsz=285.5, num_updates=32500, lr=7.84465e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=61, gb_free=17.5, wall=24518
2023-08-31 16:33:12 | INFO | train_inner | epoch 018:   1573 / 1826 loss=1.916, trans_loss=4.723, nll_loss=1.943, w2v_ctc_loss=0.721, task_loss=4.022, contrastive_loss=0, total=3833.6, n_correct=2628.37, ppl=3.85, accuracy=68.561, wps=12635.9, ups=1.65, wpb=7667.2, bsz=261.9, num_updates=32600, lr=7.8326e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=24579
2023-08-31 16:34:13 | INFO | train_inner | epoch 018:   1673 / 1826 loss=1.92, trans_loss=4.727, nll_loss=1.948, w2v_ctc_loss=0.736, task_loss=3.845, contrastive_loss=0, total=3917.26, n_correct=2679.25, ppl=3.86, accuracy=68.396, wps=12802.4, ups=1.63, wpb=7834.5, bsz=276.6, num_updates=32700, lr=7.82062e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=24640
2023-08-31 16:35:14 | INFO | train_inner | epoch 018:   1773 / 1826 loss=1.916, trans_loss=4.734, nll_loss=1.957, w2v_ctc_loss=0.721, task_loss=3.92, contrastive_loss=0, total=3894.45, n_correct=2666.51, ppl=3.88, accuracy=68.469, wps=12789.8, ups=1.64, wpb=7788.9, bsz=273.5, num_updates=32800, lr=7.80869e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=60, gb_free=10.9, wall=24701
2023-08-31 16:35:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 16:36:25 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.805 | trans_loss 5.012 | nll_loss 2.266 | w2v_ctc_loss 1.375 | task_loss 13.742 | contrastive_loss 0 | total 3505.91 | n_correct 2414.82 | ppl 4.81 | accuracy 68.879 | uer 18.233 | wer 20.239 | raw_wer 20.239 | bleu 30.97 | wps 1200.3 | wpb 3505.9 | bsz 119.3 | num_updates 32853 | best_bleu 30.97
2023-08-31 16:36:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 32853 updates
2023-08-31 16:36:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 16:36:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 16:36:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 18 @ 32853 updates, score 30.97) (writing took 11.997228071006248 seconds)
2023-08-31 16:36:37 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-31 16:36:37 | INFO | train | epoch 018 | loss 1.909 | trans_loss 4.72 | nll_loss 1.939 | w2v_ctc_loss 0.716 | task_loss 3.656 | contrastive_loss 0 | total 3956.37 | n_correct 2716.61 | ppl 3.83 | accuracy 68.664 | wps 11829.4 | ups 1.49 | wpb 7912.7 | bsz 284.8 | num_updates 32853 | lr 7.80239e-05 | gnorm 0.546 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 15.6 | wall 24784
2023-08-31 16:36:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 16:36:38 | INFO | fairseq.trainer | begin training epoch 19
2023-08-31 16:36:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 16:37:14 | INFO | train_inner | epoch 019:     47 / 1826 loss=1.906, trans_loss=4.722, nll_loss=1.941, w2v_ctc_loss=0.705, task_loss=3.606, contrastive_loss=0, total=3931.09, n_correct=2700.51, ppl=3.84, accuracy=68.696, wps=6577, ups=0.84, wpb=7862.2, bsz=283.1, num_updates=32900, lr=7.79681e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=60, gb_free=14.5, wall=24820
2023-08-31 16:38:15 | INFO | train_inner | epoch 019:    147 / 1826 loss=1.892, trans_loss=4.701, nll_loss=1.914, w2v_ctc_loss=0.696, task_loss=3.551, contrastive_loss=0, total=4000.63, n_correct=2765.75, ppl=3.77, accuracy=69.133, wps=13037.5, ups=1.63, wpb=8001.3, bsz=293.7, num_updates=33000, lr=7.78499e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=24882
2023-08-31 16:39:16 | INFO | train_inner | epoch 019:    247 / 1826 loss=1.899, trans_loss=4.7, nll_loss=1.912, w2v_ctc_loss=0.708, task_loss=3.744, contrastive_loss=0, total=3952.29, n_correct=2733.45, ppl=3.76, accuracy=69.161, wps=12956.9, ups=1.64, wpb=7904.6, bsz=278, num_updates=33100, lr=7.77322e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=24943
2023-08-31 16:40:17 | INFO | train_inner | epoch 019:    347 / 1826 loss=1.897, trans_loss=4.705, nll_loss=1.919, w2v_ctc_loss=0.704, task_loss=3.661, contrastive_loss=0, total=3956.11, n_correct=2730.55, ppl=3.78, accuracy=69.021, wps=12981.9, ups=1.64, wpb=7912.2, bsz=285.4, num_updates=33200, lr=7.76151e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=25004
2023-08-31 16:41:18 | INFO | train_inner | epoch 019:    447 / 1826 loss=1.901, trans_loss=4.704, nll_loss=1.918, w2v_ctc_loss=0.713, task_loss=3.565, contrastive_loss=0, total=3974.51, n_correct=2742.33, ppl=3.78, accuracy=68.998, wps=13103.2, ups=1.65, wpb=7949, bsz=286.6, num_updates=33300, lr=7.74984e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=25064
2023-08-31 16:42:19 | INFO | train_inner | epoch 019:    547 / 1826 loss=1.9, trans_loss=4.706, nll_loss=1.92, w2v_ctc_loss=0.707, task_loss=3.713, contrastive_loss=0, total=3968.12, n_correct=2737.11, ppl=3.79, accuracy=68.978, wps=12865.9, ups=1.62, wpb=7936.2, bsz=283.1, num_updates=33400, lr=7.73823e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=25126
2023-08-31 16:43:21 | INFO | train_inner | epoch 019:    647 / 1826 loss=1.898, trans_loss=4.711, nll_loss=1.927, w2v_ctc_loss=0.697, task_loss=3.585, contrastive_loss=0, total=3987.93, n_correct=2748.43, ppl=3.8, accuracy=68.919, wps=13006.8, ups=1.63, wpb=7975.9, bsz=290.7, num_updates=33500, lr=7.72667e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=25187
2023-08-31 16:44:23 | INFO | train_inner | epoch 019:    747 / 1826 loss=1.902, trans_loss=4.71, nll_loss=1.926, w2v_ctc_loss=0.708, task_loss=3.64, contrastive_loss=0, total=3986.45, n_correct=2748.28, ppl=3.8, accuracy=68.941, wps=12871.9, ups=1.61, wpb=7972.9, bsz=287.8, num_updates=33600, lr=7.71517e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=25249
2023-08-31 16:45:23 | INFO | train_inner | epoch 019:    847 / 1826 loss=1.91, trans_loss=4.717, nll_loss=1.934, w2v_ctc_loss=0.723, task_loss=3.719, contrastive_loss=0, total=3913.82, n_correct=2689.33, ppl=3.82, accuracy=68.714, wps=12939.8, ups=1.65, wpb=7827.6, bsz=280.2, num_updates=33700, lr=7.70371e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=25310
2023-08-31 16:46:24 | INFO | train_inner | epoch 019:    947 / 1826 loss=1.893, trans_loss=4.698, nll_loss=1.91, w2v_ctc_loss=0.698, task_loss=3.566, contrastive_loss=0, total=3948.02, n_correct=2728.77, ppl=3.76, accuracy=69.117, wps=13049.7, ups=1.65, wpb=7896, bsz=287.6, num_updates=33800, lr=7.69231e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=25370
2023-08-31 16:47:25 | INFO | train_inner | epoch 019:   1047 / 1826 loss=1.902, trans_loss=4.707, nll_loss=1.921, w2v_ctc_loss=0.711, task_loss=3.636, contrastive_loss=0, total=4005.73, n_correct=2758.9, ppl=3.79, accuracy=68.874, wps=13127.9, ups=1.64, wpb=8011.5, bsz=287.2, num_updates=33900, lr=7.68095e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=25431
2023-08-31 16:48:26 | INFO | train_inner | epoch 019:   1147 / 1826 loss=1.902, trans_loss=4.708, nll_loss=1.924, w2v_ctc_loss=0.71, task_loss=3.741, contrastive_loss=0, total=3884.43, n_correct=2678.09, ppl=3.79, accuracy=68.944, wps=12697.1, ups=1.63, wpb=7768.9, bsz=276.3, num_updates=34000, lr=7.66965e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=25492
2023-08-31 16:48:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 16:49:05 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.811 | trans_loss 5.006 | nll_loss 2.258 | w2v_ctc_loss 1.408 | task_loss 13.575 | contrastive_loss 0 | total 3505.91 | n_correct 2419 | ppl 4.78 | accuracy 68.998 | uer 18.423 | wer 20.435 | raw_wer 20.435 | bleu 30.78 | wps 1196.9 | wpb 3505.9 | bsz 119.3 | num_updates 34000 | best_bleu 30.97
2023-08-31 16:49:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 34000 updates
2023-08-31 16:49:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_19_34000.pt
2023-08-31 16:49:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_19_34000.pt
2023-08-31 16:49:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_19_34000.pt (epoch 19 @ 34000 updates, score 30.78) (writing took 7.292558219996863 seconds)
2023-08-31 16:50:14 | INFO | train_inner | epoch 019:   1247 / 1826 loss=1.903, trans_loss=4.714, nll_loss=1.931, w2v_ctc_loss=0.711, task_loss=3.469, contrastive_loss=0, total=3996.79, n_correct=2748.67, ppl=3.81, accuracy=68.772, wps=7409.2, ups=0.93, wpb=7993.6, bsz=299, num_updates=34100, lr=7.6584e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=25600
2023-08-31 16:51:15 | INFO | train_inner | epoch 019:   1347 / 1826 loss=1.906, trans_loss=4.709, nll_loss=1.925, w2v_ctc_loss=0.715, task_loss=3.808, contrastive_loss=0, total=3885.02, n_correct=2672.3, ppl=3.8, accuracy=68.785, wps=12669.7, ups=1.63, wpb=7770, bsz=275.8, num_updates=34200, lr=7.64719e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=25662
2023-08-31 16:51:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 16:52:17 | INFO | train_inner | epoch 019:   1448 / 1826 loss=1.903, trans_loss=4.713, nll_loss=1.929, w2v_ctc_loss=0.71, task_loss=3.588, contrastive_loss=0, total=4002.76, n_correct=2760.02, ppl=3.81, accuracy=68.953, wps=12918.7, ups=1.61, wpb=8005.5, bsz=292.2, num_updates=34300, lr=7.63604e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=25724
2023-08-31 16:53:18 | INFO | train_inner | epoch 019:   1548 / 1826 loss=1.906, trans_loss=4.718, nll_loss=1.936, w2v_ctc_loss=0.712, task_loss=3.674, contrastive_loss=0, total=3931.11, n_correct=2704.43, ppl=3.83, accuracy=68.796, wps=12894.6, ups=1.64, wpb=7862.2, bsz=279.8, num_updates=34400, lr=7.62493e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=60, gb_free=15.2, wall=25785
2023-08-31 16:54:19 | INFO | train_inner | epoch 019:   1648 / 1826 loss=1.907, trans_loss=4.712, nll_loss=1.929, w2v_ctc_loss=0.719, task_loss=3.668, contrastive_loss=0, total=3953.66, n_correct=2727.73, ppl=3.81, accuracy=68.993, wps=12960.6, ups=1.64, wpb=7907.3, bsz=280.1, num_updates=34500, lr=7.61387e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=25846
2023-08-31 16:55:20 | INFO | train_inner | epoch 019:   1748 / 1826 loss=1.904, trans_loss=4.721, nll_loss=1.94, w2v_ctc_loss=0.711, task_loss=3.561, contrastive_loss=0, total=3974.95, n_correct=2731.53, ppl=3.84, accuracy=68.719, wps=12948.7, ups=1.63, wpb=7949.9, bsz=290.9, num_updates=34600, lr=7.60286e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=25907
2023-08-31 16:56:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 16:56:47 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.793 | trans_loss 5.011 | nll_loss 2.265 | w2v_ctc_loss 1.336 | task_loss 13.634 | contrastive_loss 0 | total 3505.91 | n_correct 2414.09 | ppl 4.81 | accuracy 68.858 | uer 17.857 | wer 19.857 | raw_wer 19.857 | bleu 30.89 | wps 1191.8 | wpb 3505.9 | bsz 119.3 | num_updates 34678 | best_bleu 30.97
2023-08-31 16:56:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 34678 updates
2023-08-31 16:56:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.8907.pt
2023-08-31 16:56:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.8907.pt
2023-08-31 16:56:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.8907.pt (epoch 19 @ 34678 updates, score 30.89) (writing took 7.5567185020045144 seconds)
2023-08-31 16:56:56 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-31 16:56:56 | INFO | train | epoch 019 | loss 1.902 | trans_loss 4.709 | nll_loss 1.925 | w2v_ctc_loss 0.709 | task_loss 3.645 | contrastive_loss 0 | total 3956.7 | n_correct 2727.1 | ppl 3.8 | accuracy 68.924 | wps 11854.4 | ups 1.5 | wpb 7913.4 | bsz 284.9 | num_updates 34678 | lr 7.5943e-05 | gnorm 0.555 | clip 0 | loss_scale 16 | train_wall 1106 | gb_free 16.8 | wall 26002
2023-08-31 16:56:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 16:56:56 | INFO | fairseq.trainer | begin training epoch 20
2023-08-31 16:56:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 16:57:17 | INFO | train_inner | epoch 020:     22 / 1826 loss=1.905, trans_loss=4.711, nll_loss=1.928, w2v_ctc_loss=0.714, task_loss=3.739, contrastive_loss=0, total=3918.35, n_correct=2697.25, ppl=3.8, accuracy=68.836, wps=6740.3, ups=0.86, wpb=7836.7, bsz=278.2, num_updates=34700, lr=7.5919e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=61, gb_free=15, wall=26023
2023-08-31 16:58:18 | INFO | train_inner | epoch 020:    122 / 1826 loss=1.886, trans_loss=4.693, nll_loss=1.904, w2v_ctc_loss=0.687, task_loss=3.575, contrastive_loss=0, total=3985.48, n_correct=2760.69, ppl=3.74, accuracy=69.269, wps=13076.1, ups=1.64, wpb=7971, bsz=289.1, num_updates=34800, lr=7.58098e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=60, gb_free=15, wall=26084
2023-08-31 16:59:19 | INFO | train_inner | epoch 020:    222 / 1826 loss=1.895, trans_loss=4.692, nll_loss=1.903, w2v_ctc_loss=0.706, task_loss=3.715, contrastive_loss=0, total=4019.73, n_correct=2786.56, ppl=3.74, accuracy=69.322, wps=13098.5, ups=1.63, wpb=8039.5, bsz=284.6, num_updates=34900, lr=7.57011e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=26146
2023-08-31 17:00:20 | INFO | train_inner | epoch 020:    322 / 1826 loss=1.892, trans_loss=4.702, nll_loss=1.916, w2v_ctc_loss=0.697, task_loss=3.409, contrastive_loss=0, total=4025.12, n_correct=2784.21, ppl=3.77, accuracy=69.171, wps=13226.4, ups=1.64, wpb=8050.2, bsz=297.1, num_updates=35000, lr=7.55929e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=60, gb_free=12.5, wall=26206
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:0')
2023-08-31 17:01:22 | INFO | train_inner | epoch 020:    422 / 1826 loss=1.891, trans_loss=4.692, nll_loss=1.902, w2v_ctc_loss=0.703, task_loss=3.522, contrastive_loss=0, total=3991.7, n_correct=2765.54, ppl=3.74, accuracy=69.282, wps=12932.1, ups=1.62, wpb=7983.4, bsz=291, num_updates=35100, lr=7.54851e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=61, gb_free=11.7, wall=26268
2023-08-31 17:02:23 | INFO | train_inner | epoch 020:    522 / 1826 loss=1.888, trans_loss=4.694, nll_loss=1.906, w2v_ctc_loss=0.689, task_loss=3.642, contrastive_loss=0, total=3928.38, n_correct=2722.5, ppl=3.75, accuracy=69.303, wps=12818.1, ups=1.63, wpb=7856.8, bsz=281, num_updates=35200, lr=7.53778e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=61, gb_free=16.6, wall=26329
2023-08-31 17:03:24 | INFO | train_inner | epoch 020:    622 / 1826 loss=1.895, trans_loss=4.697, nll_loss=1.909, w2v_ctc_loss=0.705, task_loss=3.721, contrastive_loss=0, total=3950.3, n_correct=2731.47, ppl=3.76, accuracy=69.146, wps=13013.8, ups=1.65, wpb=7900.6, bsz=280.7, num_updates=35300, lr=7.5271e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=26390
2023-08-31 17:04:25 | INFO | train_inner | epoch 020:    722 / 1826 loss=1.895, trans_loss=4.695, nll_loss=1.907, w2v_ctc_loss=0.703, task_loss=3.757, contrastive_loss=0, total=3930.59, n_correct=2718.02, ppl=3.75, accuracy=69.15, wps=12902.7, ups=1.64, wpb=7861.2, bsz=276.2, num_updates=35400, lr=7.51646e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=26451
2023-08-31 17:05:25 | INFO | train_inner | epoch 020:    822 / 1826 loss=1.896, trans_loss=4.705, nll_loss=1.92, w2v_ctc_loss=0.693, task_loss=3.798, contrastive_loss=0, total=3918.81, n_correct=2704.68, ppl=3.78, accuracy=69.018, wps=12864.1, ups=1.64, wpb=7837.6, bsz=275.5, num_updates=35500, lr=7.50587e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=60, gb_free=15.6, wall=26512
2023-08-31 17:06:27 | INFO | train_inner | epoch 020:    922 / 1826 loss=1.899, trans_loss=4.696, nll_loss=1.909, w2v_ctc_loss=0.71, task_loss=3.819, contrastive_loss=0, total=3863.44, n_correct=2669.57, ppl=3.75, accuracy=69.098, wps=12647.2, ups=1.64, wpb=7726.9, bsz=274.2, num_updates=35600, lr=7.49532e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=26573
2023-08-31 17:07:28 | INFO | train_inner | epoch 020:   1022 / 1826 loss=1.895, trans_loss=4.702, nll_loss=1.915, w2v_ctc_loss=0.698, task_loss=3.755, contrastive_loss=0, total=3941.45, n_correct=2724.5, ppl=3.77, accuracy=69.124, wps=12886.6, ups=1.63, wpb=7882.9, bsz=276.8, num_updates=35700, lr=7.48481e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=61, gb_free=10.7, wall=26634
2023-08-31 17:08:29 | INFO | train_inner | epoch 020:   1122 / 1826 loss=1.888, trans_loss=4.696, nll_loss=1.909, w2v_ctc_loss=0.694, task_loss=3.473, contrastive_loss=0, total=3985.43, n_correct=2761.56, ppl=3.76, accuracy=69.291, wps=13113.5, ups=1.65, wpb=7970.9, bsz=294.7, num_updates=35800, lr=7.47435e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=26695
2023-08-31 17:09:30 | INFO | train_inner | epoch 020:   1222 / 1826 loss=1.893, trans_loss=4.71, nll_loss=1.926, w2v_ctc_loss=0.696, task_loss=3.425, contrastive_loss=0, total=4008.65, n_correct=2765.52, ppl=3.8, accuracy=68.989, wps=12945.2, ups=1.61, wpb=8017.3, bsz=304, num_updates=35900, lr=7.46393e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=61, gb_free=12.3, wall=26757
2023-08-31 17:10:32 | INFO | train_inner | epoch 020:   1322 / 1826 loss=1.893, trans_loss=4.704, nll_loss=1.919, w2v_ctc_loss=0.696, task_loss=3.352, contrastive_loss=0, total=4037.41, n_correct=2787.33, ppl=3.78, accuracy=69.038, wps=13091.1, ups=1.62, wpb=8074.8, bsz=307.8, num_updates=36000, lr=7.45356e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=26819
2023-08-31 17:10:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:3')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 17:11:11 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.792 | trans_loss 5 | nll_loss 2.251 | w2v_ctc_loss 1.356 | task_loss 13.681 | contrastive_loss 0 | total 3505.91 | n_correct 2423.09 | ppl 4.76 | accuracy 69.114 | uer 17.921 | wer 19.89 | raw_wer 19.89 | bleu 30.67 | wps 1198.9 | wpb 3505.9 | bsz 119.3 | num_updates 36000 | best_bleu 30.97
2023-08-31 17:11:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 36000 updates
2023-08-31 17:11:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_20_36000.pt
2023-08-31 17:11:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_20_36000.pt
2023-08-31 17:11:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_20_36000.pt (epoch 20 @ 36000 updates, score 30.67) (writing took 8.011473179998575 seconds)
2023-08-31 17:12:21 | INFO | train_inner | epoch 020:   1422 / 1826 loss=1.898, trans_loss=4.694, nll_loss=1.905, w2v_ctc_loss=0.709, task_loss=3.821, contrastive_loss=0, total=3880.04, n_correct=2684.12, ppl=3.75, accuracy=69.178, wps=7145.7, ups=0.92, wpb=7760.1, bsz=273.1, num_updates=36100, lr=7.44323e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=60, gb_free=16.6, wall=26927
2023-08-31 17:13:23 | INFO | train_inner | epoch 020:   1522 / 1826 loss=1.908, trans_loss=4.703, nll_loss=1.916, w2v_ctc_loss=0.721, task_loss=4.154, contrastive_loss=0, total=3892.6, n_correct=2681.2, ppl=3.77, accuracy=68.879, wps=12598.2, ups=1.62, wpb=7785.2, bsz=260.9, num_updates=36200, lr=7.43294e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=61, gb_free=13.8, wall=26989
2023-08-31 17:14:24 | INFO | train_inner | epoch 020:   1622 / 1826 loss=1.895, trans_loss=4.699, nll_loss=1.911, w2v_ctc_loss=0.704, task_loss=3.694, contrastive_loss=0, total=3975.65, n_correct=2750.72, ppl=3.76, accuracy=69.189, wps=12998.2, ups=1.63, wpb=7951.3, bsz=283.1, num_updates=36300, lr=7.4227e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=61, gb_free=17.5, wall=27050
2023-08-31 17:14:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 17:15:26 | INFO | train_inner | epoch 020:   1723 / 1826 loss=1.902, trans_loss=4.702, nll_loss=1.916, w2v_ctc_loss=0.714, task_loss=3.742, contrastive_loss=0, total=3940.86, n_correct=2716.92, ppl=3.77, accuracy=68.942, wps=12754.3, ups=1.62, wpb=7881.7, bsz=280.9, num_updates=36400, lr=7.41249e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=27112
2023-08-31 17:16:27 | INFO | train_inner | epoch 020:   1823 / 1826 loss=1.897, trans_loss=4.711, nll_loss=1.928, w2v_ctc_loss=0.702, task_loss=3.465, contrastive_loss=0, total=3961.06, n_correct=2733.08, ppl=3.81, accuracy=68.999, wps=12964.2, ups=1.64, wpb=7922.1, bsz=295.1, num_updates=36500, lr=7.40233e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=27173
2023-08-31 17:16:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 17:17:07 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.81 | trans_loss 4.999 | nll_loss 2.251 | w2v_ctc_loss 1.42 | task_loss 13.679 | contrastive_loss 0 | total 3505.91 | n_correct 2425 | ppl 4.76 | accuracy 69.169 | uer 17.658 | wer 19.616 | raw_wer 19.616 | bleu 30.71 | wps 1205.7 | wpb 3505.9 | bsz 119.3 | num_updates 36503 | best_bleu 30.97
2023-08-31 17:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 36503 updates
2023-08-31 17:17:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.7100.pt
2023-08-31 17:17:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.7100.pt
2023-08-31 17:17:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.7100.pt (epoch 20 @ 36503 updates, score 30.71) (writing took 6.363026342994999 seconds)
2023-08-31 17:17:14 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-31 17:17:14 | INFO | train | epoch 020 | loss 1.895 | trans_loss 4.699 | nll_loss 1.912 | w2v_ctc_loss 0.702 | task_loss 3.649 | contrastive_loss 0 | total 3956.44 | n_correct 2735.27 | ppl 3.76 | accuracy 69.135 | wps 11854.3 | ups 1.5 | wpb 7912.9 | bsz 284.8 | num_updates 36503 | lr 7.40203e-05 | gnorm 0.551 | clip 0 | loss_scale 16 | train_wall 1107 | gb_free 15.5 | wall 27220
2023-08-31 17:17:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 17:17:14 | INFO | fairseq.trainer | begin training epoch 21
2023-08-31 17:17:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 17:18:21 | INFO | train_inner | epoch 021:     97 / 1826 loss=1.886, trans_loss=4.691, nll_loss=1.901, w2v_ctc_loss=0.692, task_loss=3.633, contrastive_loss=0, total=3944.57, n_correct=2737, ppl=3.74, accuracy=69.387, wps=6884.8, ups=0.87, wpb=7889.1, bsz=286.1, num_updates=36600, lr=7.39221e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=27288
2023-08-31 17:19:22 | INFO | train_inner | epoch 021:    197 / 1826 loss=1.877, trans_loss=4.681, nll_loss=1.888, w2v_ctc_loss=0.68, task_loss=3.456, contrastive_loss=0, total=3982.15, n_correct=2771.68, ppl=3.7, accuracy=69.603, wps=13122.9, ups=1.65, wpb=7964.3, bsz=294.2, num_updates=36700, lr=7.38213e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=60, gb_free=15.3, wall=27349
2023-08-31 17:20:23 | INFO | train_inner | epoch 021:    297 / 1826 loss=1.888, trans_loss=4.689, nll_loss=1.899, w2v_ctc_loss=0.693, task_loss=3.755, contrastive_loss=0, total=3942.32, n_correct=2734.78, ppl=3.73, accuracy=69.37, wps=12890.8, ups=1.63, wpb=7884.6, bsz=276.2, num_updates=36800, lr=7.3721e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=27410
2023-08-31 17:21:25 | INFO | train_inner | epoch 021:    397 / 1826 loss=1.874, trans_loss=4.676, nll_loss=1.883, w2v_ctc_loss=0.678, task_loss=3.375, contrastive_loss=0, total=4050.42, n_correct=2823.57, ppl=3.69, accuracy=69.711, wps=13153.6, ups=1.62, wpb=8100.8, bsz=305.5, num_updates=36900, lr=7.3621e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=61, gb_free=12.9, wall=27471
2023-08-31 17:22:26 | INFO | train_inner | epoch 021:    497 / 1826 loss=1.89, trans_loss=4.691, nll_loss=1.901, w2v_ctc_loss=0.698, task_loss=3.702, contrastive_loss=0, total=3970.88, n_correct=2753.12, ppl=3.74, accuracy=69.333, wps=13044.8, ups=1.64, wpb=7941.8, bsz=279.6, num_updates=37000, lr=7.35215e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=27532
2023-08-31 17:23:27 | INFO | train_inner | epoch 021:    597 / 1826 loss=1.882, trans_loss=4.689, nll_loss=1.899, w2v_ctc_loss=0.68, task_loss=3.714, contrastive_loss=0, total=3947.71, n_correct=2742.35, ppl=3.73, accuracy=69.467, wps=12892.4, ups=1.63, wpb=7895.4, bsz=280.3, num_updates=37100, lr=7.34223e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=27593
2023-08-31 17:24:28 | INFO | train_inner | epoch 021:    697 / 1826 loss=1.88, trans_loss=4.682, nll_loss=1.89, w2v_ctc_loss=0.683, task_loss=3.487, contrastive_loss=0, total=3975.34, n_correct=2765.04, ppl=3.71, accuracy=69.555, wps=12973.8, ups=1.63, wpb=7950.7, bsz=295.4, num_updates=37200, lr=7.33236e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=16, wall=27655
2023-08-31 17:25:29 | INFO | train_inner | epoch 021:    797 / 1826 loss=1.888, trans_loss=4.69, nll_loss=1.901, w2v_ctc_loss=0.693, task_loss=3.734, contrastive_loss=0, total=3944.26, n_correct=2739.7, ppl=3.73, accuracy=69.46, wps=12968.1, ups=1.64, wpb=7888.5, bsz=275.9, num_updates=37300, lr=7.32252e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=60, gb_free=10.3, wall=27716
2023-08-31 17:26:30 | INFO | train_inner | epoch 021:    897 / 1826 loss=1.884, trans_loss=4.679, nll_loss=1.886, w2v_ctc_loss=0.693, task_loss=3.664, contrastive_loss=0, total=3932.14, n_correct=2732.91, ppl=3.7, accuracy=69.502, wps=12854.2, ups=1.63, wpb=7864.3, bsz=285.3, num_updates=37400, lr=7.31272e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=27777
2023-08-31 17:27:31 | INFO | train_inner | epoch 021:    997 / 1826 loss=1.889, trans_loss=4.69, nll_loss=1.9, w2v_ctc_loss=0.698, task_loss=3.719, contrastive_loss=0, total=3922.65, n_correct=2721.15, ppl=3.73, accuracy=69.37, wps=12972.2, ups=1.65, wpb=7845.3, bsz=279, num_updates=37500, lr=7.30297e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=27837
2023-08-31 17:28:32 | INFO | train_inner | epoch 021:   1097 / 1826 loss=1.885, trans_loss=4.687, nll_loss=1.897, w2v_ctc_loss=0.689, task_loss=3.548, contrastive_loss=0, total=3947.04, n_correct=2738.43, ppl=3.72, accuracy=69.379, wps=12869.8, ups=1.63, wpb=7894.1, bsz=290.5, num_updates=37600, lr=7.29325e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=27899
2023-08-31 17:29:33 | INFO | train_inner | epoch 021:   1197 / 1826 loss=1.894, trans_loss=4.693, nll_loss=1.904, w2v_ctc_loss=0.701, task_loss=3.788, contrastive_loss=0, total=3915.98, n_correct=2710.78, ppl=3.74, accuracy=69.224, wps=12745.9, ups=1.63, wpb=7832, bsz=273.1, num_updates=37700, lr=7.28357e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=61, gb_free=12.4, wall=27960
2023-08-31 17:30:34 | INFO | train_inner | epoch 021:   1297 / 1826 loss=1.894, trans_loss=4.693, nll_loss=1.904, w2v_ctc_loss=0.704, task_loss=3.738, contrastive_loss=0, total=3945.52, n_correct=2733.75, ppl=3.74, accuracy=69.287, wps=12956.3, ups=1.64, wpb=7891, bsz=279.4, num_updates=37800, lr=7.27393e-05, gnorm=0.553, clip=0, loss_scale=16, train_wall=60, gb_free=15.1, wall=28021
2023-08-31 17:31:36 | INFO | train_inner | epoch 021:   1397 / 1826 loss=1.896, trans_loss=4.695, nll_loss=1.907, w2v_ctc_loss=0.703, task_loss=4.033, contrastive_loss=0, total=3939.39, n_correct=2723.11, ppl=3.75, accuracy=69.125, wps=12834.3, ups=1.63, wpb=7878.8, bsz=271.4, num_updates=37900, lr=7.26433e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=28082
2023-08-31 17:32:37 | INFO | train_inner | epoch 021:   1497 / 1826 loss=1.886, trans_loss=4.692, nll_loss=1.903, w2v_ctc_loss=0.69, task_loss=3.489, contrastive_loss=0, total=3969.73, n_correct=2753.96, ppl=3.74, accuracy=69.374, wps=12917.2, ups=1.63, wpb=7939.5, bsz=289.2, num_updates=38000, lr=7.25476e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=61, gb_free=17.5, wall=28144
2023-08-31 17:32:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 17:33:16 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.794 | trans_loss 5.002 | nll_loss 2.254 | w2v_ctc_loss 1.36 | task_loss 13.66 | contrastive_loss 0 | total 3505.91 | n_correct 2421.27 | ppl 4.77 | accuracy 69.063 | uer 17.948 | wer 20.011 | raw_wer 20.011 | bleu 30.94 | wps 1199.4 | wpb 3505.9 | bsz 119.3 | num_updates 38000 | best_bleu 30.97
2023-08-31 17:33:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 38000 updates
2023-08-31 17:33:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_21_38000.pt
2023-08-31 17:33:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_21_38000.pt
2023-08-31 17:33:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_21_38000.pt (epoch 21 @ 38000 updates, score 30.94) (writing took 7.69481117799296 seconds)
2023-08-31 17:34:25 | INFO | train_inner | epoch 021:   1597 / 1826 loss=1.886, trans_loss=4.687, nll_loss=1.897, w2v_ctc_loss=0.692, task_loss=3.516, contrastive_loss=0, total=3987.36, n_correct=2765.62, ppl=3.72, accuracy=69.36, wps=7387.5, ups=0.93, wpb=7974.7, bsz=293.7, num_updates=38100, lr=7.24524e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=60, gb_free=16.2, wall=28252
2023-08-31 17:35:26 | INFO | train_inner | epoch 021:   1697 / 1826 loss=1.889, trans_loss=4.701, nll_loss=1.915, w2v_ctc_loss=0.689, task_loss=3.536, contrastive_loss=0, total=3959.43, n_correct=2741.41, ppl=3.77, accuracy=69.237, wps=12903.6, ups=1.63, wpb=7918.9, bsz=291.6, num_updates=38200, lr=7.23575e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=28313
2023-08-31 17:36:28 | INFO | train_inner | epoch 021:   1797 / 1826 loss=1.887, trans_loss=4.687, nll_loss=1.897, w2v_ctc_loss=0.699, task_loss=3.74, contrastive_loss=0, total=3935.52, n_correct=2732.89, ppl=3.72, accuracy=69.442, wps=12708.4, ups=1.61, wpb=7871, bsz=284, num_updates=38300, lr=7.22629e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=61, gb_free=11.4, wall=28375
2023-08-31 17:36:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 17:37:25 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.793 | trans_loss 4.994 | nll_loss 2.242 | w2v_ctc_loss 1.373 | task_loss 13.704 | contrastive_loss 0 | total 3505.91 | n_correct 2426.64 | ppl 4.73 | accuracy 69.216 | uer 17.72 | wer 19.598 | raw_wer 19.598 | bleu 30.8 | wps 1200.8 | wpb 3505.9 | bsz 119.3 | num_updates 38329 | best_bleu 30.97
2023-08-31 17:37:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 38329 updates
2023-08-31 17:37:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.8007.pt
2023-08-31 17:37:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.8007.pt
2023-08-31 17:37:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.8007.pt (epoch 21 @ 38329 updates, score 30.8) (writing took 7.141953198006377 seconds)
2023-08-31 17:37:32 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-31 17:37:32 | INFO | train | epoch 021 | loss 1.886 | trans_loss 4.688 | nll_loss 1.898 | w2v_ctc_loss 0.692 | task_loss 3.645 | contrastive_loss 0 | total 3956.37 | n_correct 2745.77 | ppl 3.73 | accuracy 69.401 | wps 11858.8 | ups 1.5 | wpb 7912.7 | bsz 284.8 | num_updates 38329 | lr 7.22356e-05 | gnorm 0.542 | clip 0 | loss_scale 16 | train_wall 1106 | gb_free 15.2 | wall 28439
2023-08-31 17:37:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 17:37:32 | INFO | fairseq.trainer | begin training epoch 22
2023-08-31 17:37:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 17:38:23 | INFO | train_inner | epoch 022:     71 / 1826 loss=1.871, trans_loss=4.674, nll_loss=1.88, w2v_ctc_loss=0.672, task_loss=3.511, contrastive_loss=0, total=3950, n_correct=2757.38, ppl=3.68, accuracy=69.807, wps=6923.2, ups=0.88, wpb=7900, bsz=287.1, num_updates=38400, lr=7.21688e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=59, gb_free=17, wall=28489
2023-08-31 17:39:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 17:39:24 | INFO | train_inner | epoch 022:    172 / 1826 loss=1.88, trans_loss=4.681, nll_loss=1.889, w2v_ctc_loss=0.678, task_loss=3.681, contrastive_loss=0, total=3970.21, n_correct=2756.06, ppl=3.7, accuracy=69.418, wps=12847.9, ups=1.62, wpb=7940.4, bsz=290.9, num_updates=38500, lr=7.2075e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=28551
2023-08-31 17:40:26 | INFO | train_inner | epoch 022:    272 / 1826 loss=1.874, trans_loss=4.668, nll_loss=1.872, w2v_ctc_loss=0.683, task_loss=3.513, contrastive_loss=0, total=3983.29, n_correct=2781.33, ppl=3.66, accuracy=69.825, wps=12970.2, ups=1.63, wpb=7966.6, bsz=290.3, num_updates=38600, lr=7.19816e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=28612
2023-08-31 17:41:27 | INFO | train_inner | epoch 022:    372 / 1826 loss=1.872, trans_loss=4.674, nll_loss=1.879, w2v_ctc_loss=0.678, task_loss=3.386, contrastive_loss=0, total=3996.29, n_correct=2786.08, ppl=3.68, accuracy=69.717, wps=13075.9, ups=1.64, wpb=7992.6, bsz=300, num_updates=38700, lr=7.18885e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=61, gb_free=14.8, wall=28673
2023-08-31 17:42:28 | INFO | train_inner | epoch 022:    472 / 1826 loss=1.87, trans_loss=4.668, nll_loss=1.873, w2v_ctc_loss=0.672, task_loss=3.655, contrastive_loss=0, total=3949.66, n_correct=2759.22, ppl=3.66, accuracy=69.86, wps=12921.5, ups=1.64, wpb=7899.3, bsz=285.1, num_updates=38800, lr=7.17958e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=28735
2023-08-31 17:43:29 | INFO | train_inner | epoch 022:    572 / 1826 loss=1.878, trans_loss=4.684, nll_loss=1.894, w2v_ctc_loss=0.681, task_loss=3.556, contrastive_loss=0, total=3941.03, n_correct=2742.63, ppl=3.72, accuracy=69.592, wps=12854.2, ups=1.63, wpb=7882.1, bsz=291.6, num_updates=38900, lr=7.17035e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=61, gb_free=12, wall=28796
2023-08-31 17:44:31 | INFO | train_inner | epoch 022:    672 / 1826 loss=1.889, trans_loss=4.69, nll_loss=1.901, w2v_ctc_loss=0.692, task_loss=3.761, contrastive_loss=0, total=3959.82, n_correct=2750.38, ppl=3.73, accuracy=69.457, wps=12895.5, ups=1.63, wpb=7919.6, bsz=279.6, num_updates=39000, lr=7.16115e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=61, gb_free=15.6, wall=28857
2023-08-31 17:45:32 | INFO | train_inner | epoch 022:    772 / 1826 loss=1.886, trans_loss=4.679, nll_loss=1.886, w2v_ctc_loss=0.694, task_loss=3.909, contrastive_loss=0, total=3987.93, n_correct=2771.24, ppl=3.7, accuracy=69.491, wps=12953.7, ups=1.62, wpb=7975.9, bsz=277.5, num_updates=39100, lr=7.15199e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=28919
2023-08-31 17:46:34 | INFO | train_inner | epoch 022:    872 / 1826 loss=1.88, trans_loss=4.683, nll_loss=1.891, w2v_ctc_loss=0.684, task_loss=3.678, contrastive_loss=0, total=3984.42, n_correct=2773.53, ppl=3.71, accuracy=69.609, wps=13001.4, ups=1.63, wpb=7968.8, bsz=286.3, num_updates=39200, lr=7.14286e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=61, gb_free=9.5, wall=28980
2023-08-31 17:47:34 | INFO | train_inner | epoch 022:    972 / 1826 loss=1.88, trans_loss=4.684, nll_loss=1.893, w2v_ctc_loss=0.68, task_loss=3.579, contrastive_loss=0, total=3977.63, n_correct=2765.66, ppl=3.72, accuracy=69.53, wps=13100.1, ups=1.65, wpb=7955.3, bsz=285, num_updates=39300, lr=7.13376e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=60, gb_free=15.6, wall=29041
2023-08-31 17:48:36 | INFO | train_inner | epoch 022:   1072 / 1826 loss=1.884, trans_loss=4.687, nll_loss=1.896, w2v_ctc_loss=0.69, task_loss=3.723, contrastive_loss=0, total=3977.39, n_correct=2761.52, ppl=3.72, accuracy=69.43, wps=12971, ups=1.63, wpb=7954.8, bsz=283.2, num_updates=39400, lr=7.1247e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=29102
2023-08-31 17:49:37 | INFO | train_inner | epoch 022:   1172 / 1826 loss=1.883, trans_loss=4.679, nll_loss=1.886, w2v_ctc_loss=0.692, task_loss=3.82, contrastive_loss=0, total=3946.71, n_correct=2750.1, ppl=3.7, accuracy=69.681, wps=12870.8, ups=1.63, wpb=7893.4, bsz=275.8, num_updates=39500, lr=7.11568e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=8.9, wall=29164
2023-08-31 17:50:38 | INFO | train_inner | epoch 022:   1272 / 1826 loss=1.878, trans_loss=4.679, nll_loss=1.887, w2v_ctc_loss=0.68, task_loss=3.659, contrastive_loss=0, total=3918.49, n_correct=2726.12, ppl=3.7, accuracy=69.571, wps=12756.6, ups=1.63, wpb=7837, bsz=285.2, num_updates=39600, lr=7.10669e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=29225
2023-08-31 17:51:39 | INFO | train_inner | epoch 022:   1372 / 1826 loss=1.88, trans_loss=4.677, nll_loss=1.884, w2v_ctc_loss=0.686, task_loss=3.686, contrastive_loss=0, total=3927.97, n_correct=2733.22, ppl=3.69, accuracy=69.584, wps=12965.5, ups=1.65, wpb=7855.9, bsz=276.4, num_updates=39700, lr=7.09773e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=60, gb_free=15.5, wall=29286
2023-08-31 17:52:41 | INFO | train_inner | epoch 022:   1472 / 1826 loss=1.888, trans_loss=4.688, nll_loss=1.898, w2v_ctc_loss=0.697, task_loss=3.509, contrastive_loss=0, total=3961.73, n_correct=2747.44, ppl=3.73, accuracy=69.35, wps=12846.7, ups=1.62, wpb=7923.5, bsz=294.1, num_updates=39800, lr=7.08881e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=61, gb_free=17.3, wall=29347
2023-08-31 17:53:42 | INFO | train_inner | epoch 022:   1572 / 1826 loss=1.875, trans_loss=4.673, nll_loss=1.879, w2v_ctc_loss=0.686, task_loss=3.528, contrastive_loss=0, total=3949.79, n_correct=2758.27, ppl=3.68, accuracy=69.833, wps=12966.6, ups=1.64, wpb=7899.6, bsz=289.4, num_updates=39900, lr=7.07992e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=60, gb_free=15, wall=29408
2023-08-31 17:54:42 | INFO | train_inner | epoch 022:   1672 / 1826 loss=1.883, trans_loss=4.679, nll_loss=1.887, w2v_ctc_loss=0.691, task_loss=3.648, contrastive_loss=0, total=3942.02, n_correct=2743.74, ppl=3.7, accuracy=69.602, wps=12995.6, ups=1.65, wpb=7884, bsz=283.3, num_updates=40000, lr=7.07107e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=29469
2023-08-31 17:54:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 17:55:21 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.802 | trans_loss 4.994 | nll_loss 2.243 | w2v_ctc_loss 1.402 | task_loss 13.7 | contrastive_loss 0 | total 3505.91 | n_correct 2420.73 | ppl 4.73 | accuracy 69.047 | uer 18.072 | wer 20.119 | raw_wer 20.119 | bleu 30.84 | wps 1213.1 | wpb 3505.9 | bsz 119.3 | num_updates 40000 | best_bleu 30.97
2023-08-31 17:55:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 40000 updates
2023-08-31 17:55:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_22_40000.pt
2023-08-31 17:55:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_22_40000.pt
2023-08-31 17:55:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_22_40000.pt (epoch 22 @ 40000 updates, score 30.84) (writing took 7.764283634998719 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:0')
2023-08-31 17:56:30 | INFO | train_inner | epoch 022:   1772 / 1826 loss=1.885, trans_loss=4.682, nll_loss=1.89, w2v_ctc_loss=0.689, task_loss=3.854, contrastive_loss=0, total=3933.49, n_correct=2733.13, ppl=3.71, accuracy=69.484, wps=7291.6, ups=0.93, wpb=7867, bsz=274.4, num_updates=40100, lr=7.06225e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=29577
2023-08-31 17:57:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:3')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 17:57:41 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.794 | trans_loss 4.994 | nll_loss 2.244 | w2v_ctc_loss 1.375 | task_loss 13.693 | contrastive_loss 0 | total 3505.91 | n_correct 2424.64 | ppl 4.74 | accuracy 69.159 | uer 17.565 | wer 19.628 | raw_wer 19.628 | bleu 30.96 | wps 1204.7 | wpb 3505.9 | bsz 119.3 | num_updates 40154 | best_bleu 30.97
2023-08-31 17:57:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 40154 updates
2023-08-31 17:57:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.9606.pt
2023-08-31 17:57:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.9606.pt
2023-08-31 17:57:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.9606.pt (epoch 22 @ 40154 updates, score 30.96) (writing took 6.518203088999144 seconds)
2023-08-31 17:57:48 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-31 17:57:48 | INFO | train | epoch 022 | loss 1.88 | trans_loss 4.68 | nll_loss 1.887 | w2v_ctc_loss 0.685 | task_loss 3.653 | contrastive_loss 0 | total 3956.08 | n_correct 2753.31 | ppl 3.7 | accuracy 69.597 | wps 11873.8 | ups 1.5 | wpb 7912.2 | bsz 284.8 | num_updates 40154 | lr 7.0575e-05 | gnorm 0.542 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 12.6 | wall 29655
2023-08-31 17:57:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 17:57:49 | INFO | fairseq.trainer | begin training epoch 23
2023-08-31 17:57:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 17:58:24 | INFO | train_inner | epoch 023:     46 / 1826 loss=1.883, trans_loss=4.68, nll_loss=1.887, w2v_ctc_loss=0.685, task_loss=3.976, contrastive_loss=0, total=3889.53, n_correct=2705.12, ppl=3.7, accuracy=69.549, wps=6824.2, ups=0.88, wpb=7779.1, bsz=263.8, num_updates=40200, lr=7.05346e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=60, gb_free=15.4, wall=29691
2023-08-31 17:59:25 | INFO | train_inner | epoch 023:    146 / 1826 loss=1.867, trans_loss=4.67, nll_loss=1.875, w2v_ctc_loss=0.669, task_loss=3.474, contrastive_loss=0, total=3974.32, n_correct=2779.33, ppl=3.67, accuracy=69.932, wps=13166.1, ups=1.66, wpb=7948.6, bsz=294.1, num_updates=40300, lr=7.0447e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=60, gb_free=15.3, wall=29751
2023-08-31 18:00:25 | INFO | train_inner | epoch 023:    246 / 1826 loss=1.873, trans_loss=4.664, nll_loss=1.867, w2v_ctc_loss=0.682, task_loss=3.667, contrastive_loss=0, total=3934.29, n_correct=2752.04, ppl=3.65, accuracy=69.95, wps=12978.3, ups=1.65, wpb=7868.6, bsz=282.4, num_updates=40400, lr=7.03598e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=60, gb_free=16.1, wall=29812
2023-08-31 18:01:26 | INFO | train_inner | epoch 023:    346 / 1826 loss=1.876, trans_loss=4.669, nll_loss=1.873, w2v_ctc_loss=0.682, task_loss=3.801, contrastive_loss=0, total=3906.92, n_correct=2727.81, ppl=3.66, accuracy=69.82, wps=12860.8, ups=1.65, wpb=7813.8, bsz=275, num_updates=40500, lr=7.02728e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=60, gb_free=14.4, wall=29873
2023-08-31 18:02:27 | INFO | train_inner | epoch 023:    446 / 1826 loss=1.866, trans_loss=4.666, nll_loss=1.869, w2v_ctc_loss=0.669, task_loss=3.412, contrastive_loss=0, total=4007.87, n_correct=2801.17, ppl=3.65, accuracy=69.892, wps=13072.6, ups=1.63, wpb=8015.7, bsz=301.9, num_updates=40600, lr=7.01862e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=29934
2023-08-31 18:03:28 | INFO | train_inner | epoch 023:    546 / 1826 loss=1.871, trans_loss=4.671, nll_loss=1.876, w2v_ctc_loss=0.675, task_loss=3.633, contrastive_loss=0, total=3952.3, n_correct=2759.52, ppl=3.67, accuracy=69.821, wps=12956.1, ups=1.64, wpb=7904.6, bsz=289.4, num_updates=40700, lr=7.01e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=29995
2023-08-31 18:04:29 | INFO | train_inner | epoch 023:    646 / 1826 loss=1.873, trans_loss=4.67, nll_loss=1.875, w2v_ctc_loss=0.678, task_loss=3.705, contrastive_loss=0, total=3963.31, n_correct=2769.3, ppl=3.67, accuracy=69.873, wps=13034.3, ups=1.64, wpb=7926.6, bsz=281.6, num_updates=40800, lr=7.0014e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=60, gb_free=12.3, wall=30056
2023-08-31 18:05:31 | INFO | train_inner | epoch 023:    746 / 1826 loss=1.873, trans_loss=4.67, nll_loss=1.874, w2v_ctc_loss=0.678, task_loss=3.661, contrastive_loss=0, total=3975.41, n_correct=2778.2, ppl=3.67, accuracy=69.885, wps=12959.5, ups=1.63, wpb=7950.8, bsz=281.8, num_updates=40900, lr=6.99284e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=30117
2023-08-31 18:06:32 | INFO | train_inner | epoch 023:    846 / 1826 loss=1.873, trans_loss=4.668, nll_loss=1.872, w2v_ctc_loss=0.682, task_loss=3.545, contrastive_loss=0, total=3993.74, n_correct=2790.8, ppl=3.66, accuracy=69.879, wps=13044.2, ups=1.63, wpb=7987.5, bsz=291.2, num_updates=41000, lr=6.9843e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=30178
2023-08-31 18:07:33 | INFO | train_inner | epoch 023:    946 / 1826 loss=1.87, trans_loss=4.665, nll_loss=1.868, w2v_ctc_loss=0.674, task_loss=3.572, contrastive_loss=0, total=3954.06, n_correct=2766.92, ppl=3.65, accuracy=69.977, wps=12911.6, ups=1.63, wpb=7908.1, bsz=285.9, num_updates=41100, lr=6.9758e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=30240
2023-08-31 18:08:34 | INFO | train_inner | epoch 023:   1046 / 1826 loss=1.873, trans_loss=4.667, nll_loss=1.871, w2v_ctc_loss=0.676, task_loss=3.807, contrastive_loss=0, total=3945.08, n_correct=2756.7, ppl=3.66, accuracy=69.877, wps=12958.6, ups=1.64, wpb=7890.2, bsz=276.4, num_updates=41200, lr=6.96733e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=30300
2023-08-31 18:09:35 | INFO | train_inner | epoch 023:   1146 / 1826 loss=1.875, trans_loss=4.668, nll_loss=1.873, w2v_ctc_loss=0.686, task_loss=3.54, contrastive_loss=0, total=3983.71, n_correct=2778.52, ppl=3.66, accuracy=69.747, wps=13030.2, ups=1.64, wpb=7967.4, bsz=293, num_updates=41300, lr=6.95889e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=30362
2023-08-31 18:10:36 | INFO | train_inner | epoch 023:   1246 / 1826 loss=1.873, trans_loss=4.664, nll_loss=1.868, w2v_ctc_loss=0.679, task_loss=3.69, contrastive_loss=0, total=3933.18, n_correct=2748.2, ppl=3.65, accuracy=69.872, wps=12886.3, ups=1.64, wpb=7866.4, bsz=283.3, num_updates=41400, lr=6.95048e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=60, gb_free=14.8, wall=30423
2023-08-31 18:11:37 | INFO | train_inner | epoch 023:   1346 / 1826 loss=1.883, trans_loss=4.68, nll_loss=1.888, w2v_ctc_loss=0.686, task_loss=3.892, contrastive_loss=0, total=3899.1, n_correct=2711.77, ppl=3.7, accuracy=69.549, wps=12701, ups=1.63, wpb=7798.2, bsz=271.6, num_updates=41500, lr=6.9421e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=61, gb_free=15.2, wall=30484
2023-08-31 18:12:38 | INFO | train_inner | epoch 023:   1446 / 1826 loss=1.878, trans_loss=4.681, nll_loss=1.889, w2v_ctc_loss=0.687, task_loss=3.513, contrastive_loss=0, total=3992.43, n_correct=2779.29, ppl=3.7, accuracy=69.614, wps=13095.9, ups=1.64, wpb=7984.9, bsz=294.9, num_updates=41600, lr=6.93375e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=30545
2023-08-31 18:13:39 | INFO | train_inner | epoch 023:   1546 / 1826 loss=1.875, trans_loss=4.67, nll_loss=1.874, w2v_ctc_loss=0.685, task_loss=3.673, contrastive_loss=0, total=3930.04, n_correct=2741.12, ppl=3.67, accuracy=69.748, wps=12923.4, ups=1.64, wpb=7860.1, bsz=282.8, num_updates=41700, lr=6.92543e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=30606
2023-08-31 18:14:41 | INFO | train_inner | epoch 023:   1646 / 1826 loss=1.869, trans_loss=4.669, nll_loss=1.873, w2v_ctc_loss=0.669, task_loss=3.506, contrastive_loss=0, total=3980.48, n_correct=2779.08, ppl=3.66, accuracy=69.818, wps=12911.2, ups=1.62, wpb=7961, bsz=292, num_updates=41800, lr=6.91714e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=30668
2023-08-31 18:15:42 | INFO | train_inner | epoch 023:   1746 / 1826 loss=1.881, trans_loss=4.678, nll_loss=1.885, w2v_ctc_loss=0.686, task_loss=3.752, contrastive_loss=0, total=3964.67, n_correct=2756.91, ppl=3.69, accuracy=69.537, wps=12942.3, ups=1.63, wpb=7929.3, bsz=281.9, num_updates=41900, lr=6.90889e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=30729
2023-08-31 18:16:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 18:17:10 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.808 | trans_loss 4.988 | nll_loss 2.234 | w2v_ctc_loss 1.438 | task_loss 13.811 | contrastive_loss 0 | total 3505.91 | n_correct 2431.36 | ppl 4.71 | accuracy 69.35 | uer 18.064 | wer 20.243 | raw_wer 20.243 | bleu 31.14 | wps 1210.6 | wpb 3505.9 | bsz 119.3 | num_updates 41980 | best_bleu 31.14
2023-08-31 18:17:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 41980 updates
2023-08-31 18:17:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 18:17:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 18:17:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 23 @ 41980 updates, score 31.14) (writing took 11.485977250005817 seconds)
2023-08-31 18:17:22 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-31 18:17:22 | INFO | train | epoch 023 | loss 1.874 | trans_loss 4.67 | nll_loss 1.875 | w2v_ctc_loss 0.679 | task_loss 3.652 | contrastive_loss 0 | total 3956.37 | n_correct 2761.83 | ppl 3.67 | accuracy 69.807 | wps 12314.7 | ups 1.56 | wpb 7912.7 | bsz 284.8 | num_updates 41980 | lr 6.9023e-05 | gnorm 0.541 | clip 0 | loss_scale 32 | train_wall 1104 | gb_free 16.1 | wall 30828
2023-08-31 18:17:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 18:17:22 | INFO | fairseq.trainer | begin training epoch 24
2023-08-31 18:17:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 18:17:42 | INFO | train_inner | epoch 024:     20 / 1826 loss=1.873, trans_loss=4.671, nll_loss=1.876, w2v_ctc_loss=0.667, task_loss=3.764, contrastive_loss=0, total=3952.68, n_correct=2758.76, ppl=3.67, accuracy=69.795, wps=6618.9, ups=0.84, wpb=7905.4, bsz=281.4, num_updates=42000, lr=6.90066e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=61, gb_free=12.6, wall=30848
2023-08-31 18:17:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 18:18:21 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.793 | trans_loss 4.988 | nll_loss 2.238 | w2v_ctc_loss 1.387 | task_loss 13.72 | contrastive_loss 0 | total 3505.91 | n_correct 2434.45 | ppl 4.72 | accuracy 69.439 | uer 17.581 | wer 19.594 | raw_wer 19.594 | bleu 31.31 | wps 1191.1 | wpb 3505.9 | bsz 119.3 | num_updates 42000 | best_bleu 31.31
2023-08-31 18:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 42000 updates
2023-08-31 18:18:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_24_42000.pt
2023-08-31 18:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_24_42000.pt
2023-08-31 18:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_24_42000.pt (epoch 24 @ 42000 updates, score 31.31) (writing took 14.456571449001785 seconds)
2023-08-31 18:19:36 | INFO | train_inner | epoch 024:    120 / 1826 loss=1.862, trans_loss=4.658, nll_loss=1.86, w2v_ctc_loss=0.67, task_loss=3.338, contrastive_loss=0, total=4034.77, n_correct=2829.75, ppl=3.63, accuracy=70.134, wps=7035.6, ups=0.87, wpb=8069.5, bsz=307.2, num_updates=42100, lr=6.89246e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=30963
2023-08-31 18:20:38 | INFO | train_inner | epoch 024:    220 / 1826 loss=1.859, trans_loss=4.664, nll_loss=1.868, w2v_ctc_loss=0.655, task_loss=3.238, contrastive_loss=0, total=4050.07, n_correct=2838.13, ppl=3.65, accuracy=70.076, wps=13207.2, ups=1.63, wpb=8100.1, bsz=314.8, num_updates=42200, lr=6.88428e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=61, gb_free=15.5, wall=31024
2023-08-31 18:21:39 | INFO | train_inner | epoch 024:    320 / 1826 loss=1.858, trans_loss=4.642, nll_loss=1.839, w2v_ctc_loss=0.665, task_loss=3.773, contrastive_loss=0, total=3901.71, n_correct=2748.14, ppl=3.58, accuracy=70.434, wps=12709.1, ups=1.63, wpb=7803.4, bsz=275.4, num_updates=42300, lr=6.87614e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=61, gb_free=16.4, wall=31086
2023-08-31 18:22:40 | INFO | train_inner | epoch 024:    420 / 1826 loss=1.861, trans_loss=4.644, nll_loss=1.842, w2v_ctc_loss=0.67, task_loss=3.654, contrastive_loss=0, total=3977.96, n_correct=2798.08, ppl=3.58, accuracy=70.34, wps=12996.7, ups=1.63, wpb=7955.9, bsz=283.4, num_updates=42400, lr=6.86803e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=61, gb_free=14.5, wall=31147
2023-08-31 18:23:41 | INFO | train_inner | epoch 024:    520 / 1826 loss=1.88, trans_loss=4.672, nll_loss=1.876, w2v_ctc_loss=0.686, task_loss=3.997, contrastive_loss=0, total=3893.28, n_correct=2715.8, ppl=3.67, accuracy=69.756, wps=12875.6, ups=1.65, wpb=7786.6, bsz=265.5, num_updates=42500, lr=6.85994e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=31207
2023-08-31 18:24:42 | INFO | train_inner | epoch 024:    620 / 1826 loss=1.858, trans_loss=4.656, nll_loss=1.857, w2v_ctc_loss=0.66, task_loss=3.459, contrastive_loss=0, total=4003.37, n_correct=2809.01, ppl=3.62, accuracy=70.166, wps=13081.6, ups=1.63, wpb=8006.7, bsz=295.5, num_updates=42600, lr=6.85189e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=61, gb_free=14.9, wall=31269
2023-08-31 18:25:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-31 18:25:44 | INFO | train_inner | epoch 024:    721 / 1826 loss=1.871, trans_loss=4.663, nll_loss=1.866, w2v_ctc_loss=0.676, task_loss=3.759, contrastive_loss=0, total=3930.49, n_correct=2748.3, ppl=3.65, accuracy=69.923, wps=12737.2, ups=1.62, wpb=7861, bsz=279, num_updates=42700, lr=6.84386e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=31330
2023-08-31 18:26:45 | INFO | train_inner | epoch 024:    821 / 1826 loss=1.87, trans_loss=4.666, nll_loss=1.869, w2v_ctc_loss=0.674, task_loss=3.642, contrastive_loss=0, total=3976.98, n_correct=2780.4, ppl=3.65, accuracy=69.912, wps=12920.7, ups=1.62, wpb=7954, bsz=289.8, num_updates=42800, lr=6.83586e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=31392
2023-08-31 18:27:46 | INFO | train_inner | epoch 024:    921 / 1826 loss=1.87, trans_loss=4.668, nll_loss=1.873, w2v_ctc_loss=0.672, task_loss=3.662, contrastive_loss=0, total=3915.33, n_correct=2736.75, ppl=3.66, accuracy=69.898, wps=12877.8, ups=1.64, wpb=7830.7, bsz=281.3, num_updates=42900, lr=6.82789e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=31453
2023-08-31 18:28:47 | INFO | train_inner | epoch 024:   1021 / 1826 loss=1.873, trans_loss=4.671, nll_loss=1.876, w2v_ctc_loss=0.672, task_loss=3.795, contrastive_loss=0, total=3931.56, n_correct=2743.92, ppl=3.67, accuracy=69.792, wps=12885.7, ups=1.64, wpb=7863.1, bsz=275.5, num_updates=43000, lr=6.81994e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=60, gb_free=14.8, wall=31514
2023-08-31 18:29:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 18:29:49 | INFO | train_inner | epoch 024:   1122 / 1826 loss=1.869, trans_loss=4.66, nll_loss=1.863, w2v_ctc_loss=0.677, task_loss=3.568, contrastive_loss=0, total=4007.48, n_correct=2802.6, ppl=3.64, accuracy=69.934, wps=12999.3, ups=1.62, wpb=8015, bsz=294.5, num_updates=43100, lr=6.81203e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=31575
2023-08-31 18:30:50 | INFO | train_inner | epoch 024:   1222 / 1826 loss=1.877, trans_loss=4.664, nll_loss=1.868, w2v_ctc_loss=0.682, task_loss=4.13, contrastive_loss=0, total=3876.89, n_correct=2711.38, ppl=3.65, accuracy=69.937, wps=12705.2, ups=1.64, wpb=7753.8, bsz=259.7, num_updates=43200, lr=6.80414e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=31636
2023-08-31 18:31:51 | INFO | train_inner | epoch 024:   1322 / 1826 loss=1.864, trans_loss=4.668, nll_loss=1.872, w2v_ctc_loss=0.662, task_loss=3.473, contrastive_loss=0, total=3964.57, n_correct=2773.12, ppl=3.66, accuracy=69.948, wps=12892.2, ups=1.63, wpb=7929.1, bsz=290.7, num_updates=43300, lr=6.79628e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=15.2, wall=31698
2023-08-31 18:32:53 | INFO | train_inner | epoch 024:   1422 / 1826 loss=1.873, trans_loss=4.674, nll_loss=1.88, w2v_ctc_loss=0.673, task_loss=3.706, contrastive_loss=0, total=3989.62, n_correct=2785.89, ppl=3.68, accuracy=69.828, wps=13004.1, ups=1.63, wpb=7979.2, bsz=282.7, num_updates=43400, lr=6.78844e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=31759
2023-08-31 18:33:54 | INFO | train_inner | epoch 024:   1522 / 1826 loss=1.867, trans_loss=4.664, nll_loss=1.867, w2v_ctc_loss=0.675, task_loss=3.457, contrastive_loss=0, total=3981.7, n_correct=2785.22, ppl=3.65, accuracy=69.951, wps=13019.2, ups=1.63, wpb=7963.4, bsz=297.2, num_updates=43500, lr=6.78064e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=31821
2023-08-31 18:34:55 | INFO | train_inner | epoch 024:   1622 / 1826 loss=1.869, trans_loss=4.659, nll_loss=1.861, w2v_ctc_loss=0.671, task_loss=3.967, contrastive_loss=0, total=3878.37, n_correct=2716.74, ppl=3.63, accuracy=70.048, wps=12781.2, ups=1.65, wpb=7756.7, bsz=266.5, num_updates=43600, lr=6.77285e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=60, gb_free=10.7, wall=31881
2023-08-31 18:35:55 | INFO | train_inner | epoch 024:   1722 / 1826 loss=1.879, trans_loss=4.669, nll_loss=1.873, w2v_ctc_loss=0.693, task_loss=3.848, contrastive_loss=0, total=3924.66, n_correct=2738.34, ppl=3.66, accuracy=69.773, wps=12917.8, ups=1.65, wpb=7849.3, bsz=274.5, num_updates=43700, lr=6.7651e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=31942
2023-08-31 18:36:56 | INFO | train_inner | epoch 024:   1822 / 1826 loss=1.866, trans_loss=4.661, nll_loss=1.863, w2v_ctc_loss=0.675, task_loss=3.502, contrastive_loss=0, total=3982.77, n_correct=2786.93, ppl=3.64, accuracy=69.975, wps=13117.1, ups=1.65, wpb=7965.5, bsz=293.1, num_updates=43800, lr=6.75737e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=32003
2023-08-31 18:36:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 18:37:37 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.788 | trans_loss 4.993 | nll_loss 2.242 | w2v_ctc_loss 1.359 | task_loss 13.674 | contrastive_loss 0 | total 3505.91 | n_correct 2424.73 | ppl 4.73 | accuracy 69.161 | uer 17.776 | wer 20.007 | raw_wer 20.007 | bleu 31.39 | wps 1203.9 | wpb 3505.9 | bsz 119.3 | num_updates 43804 | best_bleu 31.39
2023-08-31 18:37:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 43804 updates
2023-08-31 18:37:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 18:37:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt
2023-08-31 18:37:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_best.pt (epoch 24 @ 43804 updates, score 31.39) (writing took 12.576216675006435 seconds)
2023-08-31 18:37:50 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-31 18:37:50 | INFO | train | epoch 024 | loss 1.868 | trans_loss 4.662 | nll_loss 1.865 | w2v_ctc_loss 0.672 | task_loss 3.652 | contrastive_loss 0 | total 3956.64 | n_correct 2769.19 | ppl 3.64 | accuracy 69.988 | wps 11746.7 | ups 1.48 | wpb 7913.3 | bsz 284.9 | num_updates 43804 | lr 6.75707e-05 | gnorm 0.547 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 17 | wall 32057
2023-08-31 18:37:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 18:37:51 | INFO | fairseq.trainer | begin training epoch 25
2023-08-31 18:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 18:38:57 | INFO | train_inner | epoch 025:     96 / 1826 loss=1.862, trans_loss=4.659, nll_loss=1.86, w2v_ctc_loss=0.666, task_loss=3.429, contrastive_loss=0, total=3969.87, n_correct=2785, ppl=3.63, accuracy=70.153, wps=6591.7, ups=0.83, wpb=7939.7, bsz=291, num_updates=43900, lr=6.74967e-05, gnorm=0.563, clip=0, loss_scale=16, train_wall=60, gb_free=15.2, wall=32123
2023-08-31 18:39:58 | INFO | train_inner | epoch 025:    196 / 1826 loss=1.858, trans_loss=4.652, nll_loss=1.852, w2v_ctc_loss=0.657, task_loss=3.527, contrastive_loss=0, total=3981.71, n_correct=2794.75, ppl=3.61, accuracy=70.19, wps=13041.9, ups=1.64, wpb=7963.4, bsz=293.8, num_updates=44000, lr=6.742e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=60, gb_free=14.8, wall=32184
2023-08-31 18:39:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 18:40:37 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.787 | trans_loss 4.991 | nll_loss 2.238 | w2v_ctc_loss 1.36 | task_loss 13.676 | contrastive_loss 0 | total 3505.91 | n_correct 2428.82 | ppl 4.72 | accuracy 69.278 | uer 17.586 | wer 19.519 | raw_wer 19.519 | bleu 30.98 | wps 1199.8 | wpb 3505.9 | bsz 119.3 | num_updates 44000 | best_bleu 31.39
2023-08-31 18:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 44000 updates
2023-08-31 18:40:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_25_44000.pt
2023-08-31 18:40:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_25_44000.pt
2023-08-31 18:40:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_25_44000.pt (epoch 25 @ 44000 updates, score 30.98) (writing took 8.264587666009902 seconds)
2023-08-31 18:41:47 | INFO | train_inner | epoch 025:    296 / 1826 loss=1.867, trans_loss=4.653, nll_loss=1.852, w2v_ctc_loss=0.675, task_loss=3.827, contrastive_loss=0, total=3975.03, n_correct=2783.84, ppl=3.61, accuracy=70.033, wps=7285.9, ups=0.92, wpb=7950.1, bsz=280.1, num_updates=44100, lr=6.73435e-05, gnorm=0.563, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=32293
2023-08-31 18:42:47 | INFO | train_inner | epoch 025:    396 / 1826 loss=1.861, trans_loss=4.652, nll_loss=1.851, w2v_ctc_loss=0.662, task_loss=3.899, contrastive_loss=0, total=3873.22, n_correct=2721.18, ppl=3.61, accuracy=70.256, wps=12795.7, ups=1.65, wpb=7746.4, bsz=265.3, num_updates=44200, lr=6.72673e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=60, gb_free=11.6, wall=32354
2023-08-31 18:43:49 | INFO | train_inner | epoch 025:    496 / 1826 loss=1.865, trans_loss=4.655, nll_loss=1.855, w2v_ctc_loss=0.667, task_loss=3.986, contrastive_loss=0, total=3905.32, n_correct=2740.27, ppl=3.62, accuracy=70.168, wps=12625.4, ups=1.62, wpb=7810.6, bsz=267.1, num_updates=44300, lr=6.71913e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=61, gb_free=12.9, wall=32416
2023-08-31 18:44:50 | INFO | train_inner | epoch 025:    596 / 1826 loss=1.865, trans_loss=4.656, nll_loss=1.856, w2v_ctc_loss=0.668, task_loss=3.714, contrastive_loss=0, total=3926.39, n_correct=2748.87, ppl=3.62, accuracy=70.01, wps=12867.1, ups=1.64, wpb=7852.8, bsz=281.8, num_updates=44400, lr=6.71156e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=60, gb_free=15.6, wall=32477
2023-08-31 18:45:51 | INFO | train_inner | epoch 025:    696 / 1826 loss=1.864, trans_loss=4.659, nll_loss=1.861, w2v_ctc_loss=0.67, task_loss=3.599, contrastive_loss=0, total=3963.7, n_correct=2779.49, ppl=3.63, accuracy=70.124, wps=13068.8, ups=1.65, wpb=7927.4, bsz=287.2, num_updates=44500, lr=6.70402e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=32538
2023-08-31 18:46:52 | INFO | train_inner | epoch 025:    796 / 1826 loss=1.864, trans_loss=4.66, nll_loss=1.863, w2v_ctc_loss=0.672, task_loss=3.499, contrastive_loss=0, total=3974.95, n_correct=2786.13, ppl=3.64, accuracy=70.092, wps=12967.4, ups=1.63, wpb=7949.9, bsz=297.5, num_updates=44600, lr=6.6965e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=61, gb_free=15, wall=32599
2023-08-31 18:47:53 | INFO | train_inner | epoch 025:    896 / 1826 loss=1.859, trans_loss=4.653, nll_loss=1.853, w2v_ctc_loss=0.654, task_loss=3.66, contrastive_loss=0, total=3995.97, n_correct=2805.6, ppl=3.61, accuracy=70.211, wps=13086.6, ups=1.64, wpb=7991.9, bsz=286.6, num_updates=44700, lr=6.689e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=61, gb_free=15.6, wall=32660
2023-08-31 18:48:55 | INFO | train_inner | epoch 025:    996 / 1826 loss=1.853, trans_loss=4.644, nll_loss=1.842, w2v_ctc_loss=0.657, task_loss=3.535, contrastive_loss=0, total=4046.08, n_correct=2853.05, ppl=3.58, accuracy=70.514, wps=13204.6, ups=1.63, wpb=8092.2, bsz=295.4, num_updates=44800, lr=6.68153e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=32721
2023-08-31 18:49:57 | INFO | train_inner | epoch 025:   1096 / 1826 loss=1.859, trans_loss=4.651, nll_loss=1.851, w2v_ctc_loss=0.662, task_loss=3.447, contrastive_loss=0, total=3954.45, n_correct=2776.71, ppl=3.61, accuracy=70.217, wps=12755, ups=1.61, wpb=7908.9, bsz=294.1, num_updates=44900, lr=6.67409e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=32783
2023-08-31 18:50:58 | INFO | train_inner | epoch 025:   1196 / 1826 loss=1.856, trans_loss=4.649, nll_loss=1.849, w2v_ctc_loss=0.659, task_loss=3.464, contrastive_loss=0, total=4002.81, n_correct=2816.19, ppl=3.6, accuracy=70.355, wps=13171.6, ups=1.65, wpb=8005.6, bsz=294.1, num_updates=45000, lr=6.66667e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=32844
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:0')
2023-08-31 18:51:59 | INFO | train_inner | epoch 025:   1296 / 1826 loss=1.86, trans_loss=4.651, nll_loss=1.851, w2v_ctc_loss=0.662, task_loss=3.642, contrastive_loss=0, total=3968.78, n_correct=2784.63, ppl=3.61, accuracy=70.163, wps=12830.3, ups=1.62, wpb=7937.6, bsz=289.8, num_updates=45100, lr=6.65927e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=32906
2023-08-31 18:53:00 | INFO | train_inner | epoch 025:   1396 / 1826 loss=1.861, trans_loss=4.643, nll_loss=1.84, w2v_ctc_loss=0.67, task_loss=3.814, contrastive_loss=0, total=3910.18, n_correct=2750.72, ppl=3.58, accuracy=70.348, wps=12929.1, ups=1.65, wpb=7820.4, bsz=271.7, num_updates=45200, lr=6.6519e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=60, gb_free=14.7, wall=32966
2023-08-31 18:54:01 | INFO | train_inner | epoch 025:   1496 / 1826 loss=1.868, trans_loss=4.659, nll_loss=1.861, w2v_ctc_loss=0.671, task_loss=3.834, contrastive_loss=0, total=3927.96, n_correct=2754.99, ppl=3.63, accuracy=70.138, wps=12794.1, ups=1.63, wpb=7855.9, bsz=273.5, num_updates=45300, lr=6.64455e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=33028
2023-08-31 18:55:02 | INFO | train_inner | epoch 025:   1596 / 1826 loss=1.864, trans_loss=4.657, nll_loss=1.858, w2v_ctc_loss=0.666, task_loss=3.796, contrastive_loss=0, total=3875.31, n_correct=2716.4, ppl=3.63, accuracy=70.095, wps=12683.6, ups=1.64, wpb=7750.6, bsz=272.1, num_updates=45400, lr=6.63723e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=33089
2023-08-31 18:56:03 | INFO | train_inner | epoch 025:   1696 / 1826 loss=1.864, trans_loss=4.658, nll_loss=1.86, w2v_ctc_loss=0.672, task_loss=3.626, contrastive_loss=0, total=3940.67, n_correct=2762.51, ppl=3.63, accuracy=70.103, wps=12921.1, ups=1.64, wpb=7881.3, bsz=286.7, num_updates=45500, lr=6.62994e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=33150
2023-08-31 18:57:04 | INFO | train_inner | epoch 025:   1796 / 1826 loss=1.864, trans_loss=4.663, nll_loss=1.867, w2v_ctc_loss=0.665, task_loss=3.496, contrastive_loss=0, total=4001.31, n_correct=2801.23, ppl=3.65, accuracy=70.008, wps=13103.1, ups=1.64, wpb=8002.6, bsz=297.4, num_updates=45600, lr=6.62266e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=33211
2023-08-31 18:57:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2164, device='cuda:1')
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 18:58:02 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.803 | trans_loss 4.996 | nll_loss 2.246 | w2v_ctc_loss 1.401 | task_loss 13.664 | contrastive_loss 0 | total 3505.91 | n_correct 2428.36 | ppl 4.74 | accuracy 69.265 | uer 17.683 | wer 19.778 | raw_wer 19.778 | bleu 31.33 | wps 1190.6 | wpb 3505.9 | bsz 119.3 | num_updates 45630 | best_bleu 31.39
2023-08-31 18:58:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 45630 updates
2023-08-31 18:58:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.3301.pt
2023-08-31 18:58:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.3301.pt
2023-08-31 18:58:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_31.3301.pt (epoch 25 @ 45630 updates, score 31.33) (writing took 7.957045105998986 seconds)
2023-08-31 18:58:10 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-31 18:58:10 | INFO | train | epoch 025 | loss 1.862 | trans_loss 4.654 | nll_loss 1.854 | w2v_ctc_loss 0.665 | task_loss 3.649 | contrastive_loss 0 | total 3956.37 | n_correct 2776.56 | ppl 3.62 | accuracy 70.18 | wps 11847.7 | ups 1.5 | wpb 7912.7 | bsz 284.8 | num_updates 45630 | lr 6.62048e-05 | gnorm 0.546 | clip 0 | loss_scale 32 | train_wall 1106 | gb_free 11.8 | wall 33277
2023-08-31 18:58:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 18:58:10 | INFO | fairseq.trainer | begin training epoch 26
2023-08-31 18:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 18:59:00 | INFO | train_inner | epoch 026:     70 / 1826 loss=1.854, trans_loss=4.634, nll_loss=1.827, w2v_ctc_loss=0.659, task_loss=3.901, contrastive_loss=0, total=3888.8, n_correct=2742.98, ppl=3.55, accuracy=70.535, wps=6710.2, ups=0.86, wpb=7777.6, bsz=269.7, num_updates=45700, lr=6.61541e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=33327
2023-08-31 19:00:01 | INFO | train_inner | epoch 026:    170 / 1826 loss=1.857, trans_loss=4.638, nll_loss=1.834, w2v_ctc_loss=0.66, task_loss=3.884, contrastive_loss=0, total=3911.85, n_correct=2755.46, ppl=3.56, accuracy=70.439, wps=12974.2, ups=1.66, wpb=7823.7, bsz=269.2, num_updates=45800, lr=6.60819e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=33387
2023-08-31 19:01:02 | INFO | train_inner | epoch 026:    270 / 1826 loss=1.852, trans_loss=4.643, nll_loss=1.84, w2v_ctc_loss=0.657, task_loss=3.56, contrastive_loss=0, total=3959.89, n_correct=2790.45, ppl=3.58, accuracy=70.468, wps=12932.5, ups=1.63, wpb=7919.8, bsz=291.7, num_updates=45900, lr=6.60098e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=61, gb_free=13.9, wall=33449
2023-08-31 19:02:03 | INFO | train_inner | epoch 026:    370 / 1826 loss=1.856, trans_loss=4.649, nll_loss=1.847, w2v_ctc_loss=0.66, task_loss=3.531, contrastive_loss=0, total=3976.8, n_correct=2794.48, ppl=3.6, accuracy=70.27, wps=13071.2, ups=1.64, wpb=7953.6, bsz=289.6, num_updates=46000, lr=6.5938e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=33509
2023-08-31 19:02:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 19:02:41 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.79 | trans_loss 4.991 | nll_loss 2.236 | w2v_ctc_loss 1.371 | task_loss 13.664 | contrastive_loss 0 | total 3505.91 | n_correct 2434.36 | ppl 4.71 | accuracy 69.436 | uer 17.283 | wer 19.305 | raw_wer 19.305 | bleu 31.1 | wps 1210.4 | wpb 3505.9 | bsz 119.3 | num_updates 46000 | best_bleu 31.39
2023-08-31 19:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 46000 updates
2023-08-31 19:02:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_26_46000.pt
2023-08-31 19:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_26_46000.pt
2023-08-31 19:02:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_26_46000.pt (epoch 26 @ 46000 updates, score 31.1) (writing took 7.1957337869971525 seconds)
2023-08-31 19:03:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 19:03:51 | INFO | train_inner | epoch 026:    471 / 1826 loss=1.851, trans_loss=4.648, nll_loss=1.847, w2v_ctc_loss=0.645, task_loss=3.503, contrastive_loss=0, total=3967.01, n_correct=2787.37, ppl=3.6, accuracy=70.264, wps=7312.6, ups=0.92, wpb=7934, bsz=295.9, num_updates=46100, lr=6.58665e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=61, gb_free=10.9, wall=33618
2023-08-31 19:04:53 | INFO | train_inner | epoch 026:    571 / 1826 loss=1.848, trans_loss=4.643, nll_loss=1.84, w2v_ctc_loss=0.647, task_loss=3.361, contrastive_loss=0, total=4027.25, n_correct=2836.66, ppl=3.58, accuracy=70.437, wps=13113.4, ups=1.63, wpb=8054.5, bsz=307.6, num_updates=46200, lr=6.57952e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=33679
2023-08-31 19:05:54 | INFO | train_inner | epoch 026:    671 / 1826 loss=1.852, trans_loss=4.645, nll_loss=1.842, w2v_ctc_loss=0.652, task_loss=3.562, contrastive_loss=0, total=3968.14, n_correct=2793.02, ppl=3.59, accuracy=70.386, wps=13069.9, ups=1.65, wpb=7936.3, bsz=289.5, num_updates=46300, lr=6.57241e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=33740
2023-08-31 19:06:55 | INFO | train_inner | epoch 026:    771 / 1826 loss=1.862, trans_loss=4.655, nll_loss=1.856, w2v_ctc_loss=0.662, task_loss=3.78, contrastive_loss=0, total=3924.92, n_correct=2758.25, ppl=3.62, accuracy=70.275, wps=12857.8, ups=1.64, wpb=7849.8, bsz=273.2, num_updates=46400, lr=6.56532e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=60, gb_free=14.6, wall=33801
2023-08-31 19:07:56 | INFO | train_inner | epoch 026:    871 / 1826 loss=1.849, trans_loss=4.642, nll_loss=1.839, w2v_ctc_loss=0.65, task_loss=3.412, contrastive_loss=0, total=3984.63, n_correct=2808.69, ppl=3.58, accuracy=70.488, wps=13013.2, ups=1.63, wpb=7969.3, bsz=293.8, num_updates=46500, lr=6.55826e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=61, gb_free=15.3, wall=33862
2023-08-31 19:08:57 | INFO | train_inner | epoch 026:    971 / 1826 loss=1.857, trans_loss=4.646, nll_loss=1.844, w2v_ctc_loss=0.662, task_loss=3.701, contrastive_loss=0, total=3957.37, n_correct=2785.24, ppl=3.59, accuracy=70.381, wps=12839, ups=1.62, wpb=7914.7, bsz=281.2, num_updates=46600, lr=6.55122e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=61, gb_free=9.6, wall=33924
2023-08-31 19:09:59 | INFO | train_inner | epoch 026:   1071 / 1826 loss=1.853, trans_loss=4.641, nll_loss=1.838, w2v_ctc_loss=0.652, task_loss=3.695, contrastive_loss=0, total=3950.86, n_correct=2784.9, ppl=3.57, accuracy=70.488, wps=12879.6, ups=1.63, wpb=7901.7, bsz=280.8, num_updates=46700, lr=6.5442e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=61, gb_free=12.1, wall=33985
2023-08-31 19:10:59 | INFO | train_inner | epoch 026:   1171 / 1826 loss=1.855, trans_loss=4.651, nll_loss=1.851, w2v_ctc_loss=0.654, task_loss=3.5, contrastive_loss=0, total=4006.65, n_correct=2816.17, ppl=3.61, accuracy=70.287, wps=13218.8, ups=1.65, wpb=8013.3, bsz=291.2, num_updates=46800, lr=6.5372e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=60, gb_free=12.5, wall=34046
2023-08-31 19:12:01 | INFO | train_inner | epoch 026:   1271 / 1826 loss=1.856, trans_loss=4.646, nll_loss=1.845, w2v_ctc_loss=0.658, task_loss=3.583, contrastive_loss=0, total=3997.72, n_correct=2817.7, ppl=3.59, accuracy=70.483, wps=13065.7, ups=1.63, wpb=7995.4, bsz=290.8, num_updates=46900, lr=6.53023e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=34107
2023-08-31 19:13:02 | INFO | train_inner | epoch 026:   1371 / 1826 loss=1.866, trans_loss=4.649, nll_loss=1.848, w2v_ctc_loss=0.676, task_loss=3.869, contrastive_loss=0, total=3921.17, n_correct=2754.63, ppl=3.6, accuracy=70.25, wps=12717.5, ups=1.62, wpb=7842.3, bsz=273.8, num_updates=47000, lr=6.52328e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=61, gb_free=17, wall=34169
2023-08-31 19:14:04 | INFO | train_inner | epoch 026:   1471 / 1826 loss=1.86, trans_loss=4.646, nll_loss=1.844, w2v_ctc_loss=0.666, task_loss=3.857, contrastive_loss=0, total=3929.77, n_correct=2762.32, ppl=3.59, accuracy=70.292, wps=12737.4, ups=1.62, wpb=7859.5, bsz=278.3, num_updates=47100, lr=6.51635e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=61, gb_free=14.7, wall=34231
2023-08-31 19:15:05 | INFO | train_inner | epoch 026:   1571 / 1826 loss=1.861, trans_loss=4.644, nll_loss=1.842, w2v_ctc_loss=0.667, task_loss=3.997, contrastive_loss=0, total=3886.23, n_correct=2735.78, ppl=3.58, accuracy=70.397, wps=12684.1, ups=1.63, wpb=7772.5, bsz=265, num_updates=47200, lr=6.50945e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=34292
2023-08-31 19:16:07 | INFO | train_inner | epoch 026:   1671 / 1826 loss=1.856, trans_loss=4.648, nll_loss=1.848, w2v_ctc_loss=0.659, task_loss=3.692, contrastive_loss=0, total=3968.2, n_correct=2790.26, ppl=3.6, accuracy=70.316, wps=12822.3, ups=1.62, wpb=7936.4, bsz=286.2, num_updates=47300, lr=6.50256e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=34354
2023-08-31 19:17:09 | INFO | train_inner | epoch 026:   1771 / 1826 loss=1.86, trans_loss=4.655, nll_loss=1.856, w2v_ctc_loss=0.668, task_loss=3.496, contrastive_loss=0, total=4007.68, n_correct=2818.56, ppl=3.62, accuracy=70.329, wps=13018.8, ups=1.62, wpb=8015.4, bsz=297.5, num_updates=47400, lr=6.4957e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=61, gb_free=12.8, wall=34415
2023-08-31 19:17:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 19:18:21 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.801 | trans_loss 4.985 | nll_loss 2.234 | w2v_ctc_loss 1.422 | task_loss 13.721 | contrastive_loss 0 | total 3505.91 | n_correct 2434.73 | ppl 4.7 | accuracy 69.446 | uer 17.425 | wer 19.373 | raw_wer 19.373 | bleu 30.98 | wps 1207.9 | wpb 3505.9 | bsz 119.3 | num_updates 47455 | best_bleu 31.39
2023-08-31 19:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 47455 updates
2023-08-31 19:18:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.9808.pt
2023-08-31 19:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.9808.pt
2023-08-31 19:18:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint.best_bleu_30.9808.pt (epoch 26 @ 47455 updates, score 30.98) (writing took 6.80065480300982 seconds)
2023-08-31 19:18:28 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-31 19:18:28 | INFO | train | epoch 026 | loss 1.856 | trans_loss 4.646 | nll_loss 1.844 | w2v_ctc_loss 0.658 | task_loss 3.653 | contrastive_loss 0 | total 3955.88 | n_correct 2784.04 | ppl 3.59 | accuracy 70.377 | wps 11858.6 | ups 1.5 | wpb 7911.8 | bsz 284.7 | num_updates 47455 | lr 6.49193e-05 | gnorm 0.535 | clip 0 | loss_scale 16 | train_wall 1107 | gb_free 15.2 | wall 34494
2023-08-31 19:18:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 19:18:28 | INFO | fairseq.trainer | begin training epoch 27
2023-08-31 19:18:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 19:19:03 | INFO | train_inner | epoch 027:     45 / 1826 loss=1.85, trans_loss=4.639, nll_loss=1.836, w2v_ctc_loss=0.654, task_loss=3.647, contrastive_loss=0, total=3903.86, n_correct=2753.09, ppl=3.57, accuracy=70.522, wps=6823.7, ups=0.87, wpb=7807.7, bsz=282.2, num_updates=47500, lr=6.48886e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=60, gb_free=14.5, wall=34530
2023-08-31 19:20:04 | INFO | train_inner | epoch 027:    145 / 1826 loss=1.845, trans_loss=4.629, nll_loss=1.822, w2v_ctc_loss=0.648, task_loss=3.701, contrastive_loss=0, total=3934.64, n_correct=2785.19, ppl=3.54, accuracy=70.786, wps=12876.6, ups=1.64, wpb=7869.3, bsz=281.8, num_updates=47600, lr=6.48204e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=60, gb_free=16.6, wall=34591
2023-08-31 19:21:05 | INFO | train_inner | epoch 027:    245 / 1826 loss=1.849, trans_loss=4.635, nll_loss=1.83, w2v_ctc_loss=0.65, task_loss=3.721, contrastive_loss=0, total=3939.62, n_correct=2781.09, ppl=3.56, accuracy=70.593, wps=12959.4, ups=1.64, wpb=7879.2, bsz=282.5, num_updates=47700, lr=6.47524e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=60, gb_free=16.2, wall=34652
2023-08-31 19:22:06 | INFO | train_inner | epoch 027:    345 / 1826 loss=1.845, trans_loss=4.637, nll_loss=1.833, w2v_ctc_loss=0.647, task_loss=3.401, contrastive_loss=0, total=3977.4, n_correct=2812.55, ppl=3.56, accuracy=70.713, wps=13118.4, ups=1.65, wpb=7954.8, bsz=300.8, num_updates=47800, lr=6.46846e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=34712
2023-08-31 19:23:07 | INFO | train_inner | epoch 027:    445 / 1826 loss=1.843, trans_loss=4.627, nll_loss=1.819, w2v_ctc_loss=0.644, task_loss=3.842, contrastive_loss=0, total=3893.64, n_correct=2759.76, ppl=3.53, accuracy=70.879, wps=12677.3, ups=1.63, wpb=7787.3, bsz=273.4, num_updates=47900, lr=6.46171e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=61, gb_free=16.3, wall=34774
2023-08-31 19:24:09 | INFO | train_inner | epoch 027:    545 / 1826 loss=1.843, trans_loss=4.634, nll_loss=1.829, w2v_ctc_loss=0.646, task_loss=3.387, contrastive_loss=0, total=4046.71, n_correct=2862.38, ppl=3.55, accuracy=70.734, wps=13181.9, ups=1.63, wpb=8093.4, bsz=302.4, num_updates=48000, lr=6.45497e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=34835
2023-08-31 19:24:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 19:24:47 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.798 | trans_loss 4.99 | nll_loss 2.236 | w2v_ctc_loss 1.399 | task_loss 13.676 | contrastive_loss 0 | total 3505.91 | n_correct 2430.45 | ppl 4.71 | accuracy 69.325 | uer 17.629 | wer 19.605 | raw_wer 19.605 | bleu 30.92 | wps 1209.1 | wpb 3505.9 | bsz 119.3 | num_updates 48000 | best_bleu 31.39
2023-08-31 19:24:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 48000 updates
2023-08-31 19:24:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_27_48000.pt
2023-08-31 19:24:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_27_48000.pt
2023-08-31 19:24:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_27_48000.pt (epoch 27 @ 48000 updates, score 30.92) (writing took 6.321027227997547 seconds)
2023-08-31 19:25:54 | INFO | train_inner | epoch 027:    645 / 1826 loss=1.857, trans_loss=4.646, nll_loss=1.844, w2v_ctc_loss=0.657, task_loss=3.843, contrastive_loss=0, total=3871.95, n_correct=2724.77, ppl=3.59, accuracy=70.372, wps=7323.1, ups=0.95, wpb=7743.9, bsz=269.2, num_updates=48100, lr=6.44826e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=60, gb_free=15.1, wall=34941
2023-08-31 19:26:56 | INFO | train_inner | epoch 027:    745 / 1826 loss=1.845, trans_loss=4.633, nll_loss=1.827, w2v_ctc_loss=0.644, task_loss=3.654, contrastive_loss=0, total=3917, n_correct=2764.92, ppl=3.55, accuracy=70.588, wps=12789.6, ups=1.63, wpb=7834, bsz=285.4, num_updates=48200, lr=6.44157e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=61, gb_free=15.8, wall=35002
2023-08-31 19:27:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-31 19:27:58 | INFO | train_inner | epoch 027:    846 / 1826 loss=1.844, trans_loss=4.633, nll_loss=1.828, w2v_ctc_loss=0.644, task_loss=3.506, contrastive_loss=0, total=4055.82, n_correct=2865.78, ppl=3.55, accuracy=70.658, wps=13011.5, ups=1.6, wpb=8111.6, bsz=299.8, num_updates=48300, lr=6.43489e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=62, gb_free=11.3, wall=35065
2023-08-31 19:29:00 | INFO | train_inner | epoch 027:    946 / 1826 loss=1.857, trans_loss=4.645, nll_loss=1.843, w2v_ctc_loss=0.658, task_loss=3.814, contrastive_loss=0, total=3969.26, n_correct=2790.19, ppl=3.59, accuracy=70.295, wps=12878, ups=1.62, wpb=7938.5, bsz=278.2, num_updates=48400, lr=6.42824e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=35126
2023-08-31 19:30:01 | INFO | train_inner | epoch 027:   1046 / 1826 loss=1.851, trans_loss=4.638, nll_loss=1.834, w2v_ctc_loss=0.654, task_loss=3.752, contrastive_loss=0, total=3965.03, n_correct=2801.61, ppl=3.57, accuracy=70.658, wps=12982.7, ups=1.64, wpb=7930.1, bsz=278.5, num_updates=48500, lr=6.42161e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=60, gb_free=16.1, wall=35187
2023-08-31 19:31:02 | INFO | train_inner | epoch 027:   1146 / 1826 loss=1.857, trans_loss=4.645, nll_loss=1.843, w2v_ctc_loss=0.663, task_loss=3.707, contrastive_loss=0, total=3940.95, n_correct=2773.59, ppl=3.59, accuracy=70.379, wps=12925.3, ups=1.64, wpb=7881.9, bsz=278.5, num_updates=48600, lr=6.415e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=60, gb_free=15.2, wall=35248
2023-08-31 19:32:03 | INFO | train_inner | epoch 027:   1246 / 1826 loss=1.851, trans_loss=4.642, nll_loss=1.839, w2v_ctc_loss=0.649, task_loss=3.647, contrastive_loss=0, total=3960.96, n_correct=2793.19, ppl=3.58, accuracy=70.518, wps=12995.2, ups=1.64, wpb=7921.9, bsz=285.5, num_updates=48700, lr=6.40841e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=60, gb_free=15.6, wall=35309
2023-08-31 19:33:04 | INFO | train_inner | epoch 027:   1346 / 1826 loss=1.844, trans_loss=4.626, nll_loss=1.818, w2v_ctc_loss=0.647, task_loss=3.664, contrastive_loss=0, total=3972.75, n_correct=2812.14, ppl=3.53, accuracy=70.786, wps=13044.6, ups=1.64, wpb=7945.5, bsz=284.4, num_updates=48800, lr=6.40184e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=35370
2023-08-31 19:34:05 | INFO | train_inner | epoch 027:   1446 / 1826 loss=1.855, trans_loss=4.641, nll_loss=1.838, w2v_ctc_loss=0.659, task_loss=3.825, contrastive_loss=0, total=3965.81, n_correct=2792.46, ppl=3.58, accuracy=70.413, wps=12987.4, ups=1.64, wpb=7931.6, bsz=277.4, num_updates=48900, lr=6.39529e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=35431
2023-08-31 19:35:06 | INFO | train_inner | epoch 027:   1546 / 1826 loss=1.855, trans_loss=4.638, nll_loss=1.833, w2v_ctc_loss=0.661, task_loss=3.861, contrastive_loss=0, total=3884.69, n_correct=2740.63, ppl=3.56, accuracy=70.55, wps=12650.3, ups=1.63, wpb=7769.4, bsz=270.7, num_updates=49000, lr=6.38877e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=35493
2023-08-31 19:36:07 | INFO | train_inner | epoch 027:   1646 / 1826 loss=1.853, trans_loss=4.643, nll_loss=1.841, w2v_ctc_loss=0.653, task_loss=3.569, contrastive_loss=0, total=3960.41, n_correct=2789.05, ppl=3.58, accuracy=70.423, wps=13033.7, ups=1.65, wpb=7920.8, bsz=288.6, num_updates=49100, lr=6.38226e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=60, gb_free=16.2, wall=35553
2023-08-31 19:37:08 | INFO | train_inner | epoch 027:   1746 / 1826 loss=1.857, trans_loss=4.655, nll_loss=1.857, w2v_ctc_loss=0.657, task_loss=3.477, contrastive_loss=0, total=4003.3, n_correct=2813.68, ppl=3.62, accuracy=70.284, wps=13121.5, ups=1.64, wpb=8006.6, bsz=295.5, num_updates=49200, lr=6.37577e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=35614
2023-08-31 19:37:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 19:38:35 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.785 | trans_loss 4.986 | nll_loss 2.233 | w2v_ctc_loss 1.365 | task_loss 13.756 | contrastive_loss 0 | total 3505.91 | n_correct 2433 | ppl 4.7 | accuracy 69.397 | uer 17.208 | wer 19.26 | raw_wer 19.26 | bleu 30.78 | wps 1196 | wpb 3505.9 | bsz 119.3 | num_updates 49280 | best_bleu 31.39
2023-08-31 19:38:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 49280 updates
2023-08-31 19:38:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_last.pt
2023-08-31 19:38:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_last.pt
2023-08-31 19:38:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_last.pt (epoch 27 @ 49280 updates, score 30.78) (writing took 6.647245601998293 seconds)
2023-08-31 19:38:42 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-31 19:38:42 | INFO | train | epoch 027 | loss 1.85 | trans_loss 4.638 | nll_loss 1.834 | w2v_ctc_loss 0.652 | task_loss 3.648 | contrastive_loss 0 | total 3956.32 | n_correct 2792.11 | ppl 3.56 | accuracy 70.574 | wps 11891.8 | ups 1.5 | wpb 7912.6 | bsz 284.8 | num_updates 49280 | lr 6.37059e-05 | gnorm 0.543 | clip 0 | loss_scale 16 | train_wall 1105 | gb_free 16.9 | wall 35708
2023-08-31 19:38:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1826
2023-08-31 19:38:42 | INFO | fairseq.trainer | begin training epoch 28
2023-08-31 19:38:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-31 19:39:02 | INFO | train_inner | epoch 028:     20 / 1826 loss=1.844, trans_loss=4.634, nll_loss=1.829, w2v_ctc_loss=0.65, task_loss=3.3, contrastive_loss=0, total=3965.35, n_correct=2806.2, ppl=3.55, accuracy=70.768, wps=6973.5, ups=0.88, wpb=7930.7, bsz=297.7, num_updates=49300, lr=6.3693e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=60, gb_free=15.4, wall=35728
2023-08-31 19:40:02 | INFO | train_inner | epoch 028:    120 / 1826 loss=1.841, trans_loss=4.623, nll_loss=1.814, w2v_ctc_loss=0.647, task_loss=3.653, contrastive_loss=0, total=3926.83, n_correct=2785.94, ppl=3.52, accuracy=70.946, wps=12933, ups=1.65, wpb=7853.7, bsz=282.2, num_updates=49400, lr=6.36285e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=60, gb_free=15.6, wall=35789
2023-08-31 19:41:04 | INFO | train_inner | epoch 028:    220 / 1826 loss=1.847, trans_loss=4.628, nll_loss=1.821, w2v_ctc_loss=0.651, task_loss=3.737, contrastive_loss=0, total=3971.99, n_correct=2809.33, ppl=3.53, accuracy=70.729, wps=12916.3, ups=1.63, wpb=7944, bsz=281.6, num_updates=49500, lr=6.35642e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=35850
2023-08-31 19:42:05 | INFO | train_inner | epoch 028:    320 / 1826 loss=1.845, trans_loss=4.628, nll_loss=1.82, w2v_ctc_loss=0.652, task_loss=3.588, contrastive_loss=0, total=3985.91, n_correct=2818.37, ppl=3.53, accuracy=70.708, wps=13053.9, ups=1.64, wpb=7971.8, bsz=289.8, num_updates=49600, lr=6.35001e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=61, gb_free=15.5, wall=35911
2023-08-31 19:43:06 | INFO | train_inner | epoch 028:    420 / 1826 loss=1.842, trans_loss=4.631, nll_loss=1.825, w2v_ctc_loss=0.644, task_loss=3.365, contrastive_loss=0, total=4004.43, n_correct=2834.27, ppl=3.54, accuracy=70.778, wps=13158.6, ups=1.64, wpb=8008.9, bsz=299.2, num_updates=49700, lr=6.34361e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=60, gb_free=15.7, wall=35972
2023-08-31 19:44:07 | INFO | train_inner | epoch 028:    520 / 1826 loss=1.849, trans_loss=4.635, nll_loss=1.829, w2v_ctc_loss=0.647, task_loss=3.801, contrastive_loss=0, total=3952.95, n_correct=2792.29, ppl=3.55, accuracy=70.638, wps=12907.7, ups=1.63, wpb=7905.9, bsz=278.2, num_updates=49800, lr=6.33724e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=61, gb_free=16.9, wall=36034
2023-08-31 19:45:08 | INFO | train_inner | epoch 028:    620 / 1826 loss=1.843, trans_loss=4.627, nll_loss=1.819, w2v_ctc_loss=0.645, task_loss=3.649, contrastive_loss=0, total=3935.49, n_correct=2784.81, ppl=3.53, accuracy=70.761, wps=12881.5, ups=1.64, wpb=7871, bsz=287.1, num_updates=49900, lr=6.33089e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=36095
2023-08-31 19:46:09 | INFO | train_inner | epoch 028:    720 / 1826 loss=1.852, trans_loss=4.64, nll_loss=1.836, w2v_ctc_loss=0.652, task_loss=3.747, contrastive_loss=0, total=3930.78, n_correct=2773.38, ppl=3.57, accuracy=70.555, wps=12833.1, ups=1.63, wpb=7861.6, bsz=278.3, num_updates=50000, lr=6.32456e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=61, gb_free=9.7, wall=36156
2023-08-31 19:46:09 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-31 19:46:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor([0.], device='cuda:0', dtype=torch.float16) torch.Size([1]) 1
2023-08-31 19:46:48 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.787 | trans_loss 4.986 | nll_loss 2.233 | w2v_ctc_loss 1.371 | task_loss 13.615 | contrastive_loss 0 | total 3505.91 | n_correct 2437.45 | ppl 4.7 | accuracy 69.524 | uer 17.46 | wer 19.474 | raw_wer 19.474 | bleu 31.51 | wps 1183.9 | wpb 3505.9 | bsz 119.3 | num_updates 50000 | best_bleu 31.51
2023-08-31 19:46:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 50000 updates
2023-08-31 19:46:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_28_50000.pt
2023-08-31 19:46:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_28_50000.pt
2023-08-31 19:47:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enes_shrink_v2_merge_wmt_0831_soft_noCL_AT_sentence_mixup0307_scale2.5_alpha0_mt0.5_lowgrad_highnograd/checkpoint_28_50000.pt (epoch 28 @ 50000 updates, score 31.51) (writing took 11.956304182996973 seconds)
2023-08-31 19:47:01 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-31 19:47:01 | INFO | train | epoch 028 | loss 1.845 | trans_loss 4.63 | nll_loss 1.823 | w2v_ctc_loss 0.648 | task_loss 3.631 | contrastive_loss 0 | total 3958.32 | n_correct 2800.43 | ppl 3.54 | accuracy 70.748 | wps 11422.2 | ups 1.44 | wpb 7916.6 | bsz 285.8 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.541 | clip 0 | loss_scale 16 | train_wall 436 | gb_free 9.7 | wall 36207
2023-08-31 19:47:01 | INFO | fairseq_cli.train | done training in 36153.6 seconds
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    self.run()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1280 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
