2023-09-06 16:30:42 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:15320
2023-09-06 16:30:42 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:15320
2023-09-06 16:30:42 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:15320
2023-09-06 16:30:42 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:15320
2023-09-06 16:30:42 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:15320
2023-09-06 16:30:42 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:15320
2023-09-06 16:30:42 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:15320
2023-09-06 16:30:42 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:15320
2023-09-06 16:30:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 16:30:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 16:30:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-09-06 16:30:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 16:30:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-09-06 16:30:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 16:30:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 16:30:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-09-06 16:30:43 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-09-06 16:30:43 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-09-06 16:30:47 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15320', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=2.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=0.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mix_tag=0.5, mixup_change_id=True, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-06 16:30:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,999
2023-09-06 16:30:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,999
2023-09-06 16:30:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-09-06 16:30:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-09-06 16:30:47 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-09-06 16:30:51 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-09-06 16:30:51 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-09-06 16:30:51 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-09-06 16:30:53 | INFO | root | load pretrained hubert
2023-09-06 16:31:01 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-09-06 16:31:04 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-09-06 16:31:11 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-09-06 16:31:11 | INFO | root | share the sematic adapter and textual encoder
2023-09-06 16:31:11 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9999, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9999, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-09-06 16:31:11 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-09-06 16:31:11 | INFO | fairseq_cli.train | model: S2TJoint
2023-09-06 16:31:11 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-09-06 16:31:11 | INFO | fairseq_cli.train | num. shared model params: 147,043,968 (num. trained: 147,043,968)
2023-09-06 16:31:11 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-06 16:31:11 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-06 16:31:11 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 16:31:11 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 16:31:11 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 16:31:26 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-06 16:31:26 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-09-06 16:31:26 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-09-06 16:31:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-06 16:31:27 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 16:31:27 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 16:31:27 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 16:31:27 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 16:31:27 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 16:31:27 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 16:31:27 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 16:31:27 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-09-06 16:31:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-09-06 16:31:27 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-09-06 16:31:27 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-09-06 16:31:27 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 16:31:27 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_last.pt
2023-09-06 16:31:27 | INFO | fairseq.trainer | loading train data for epoch 1
2023-09-06 16:31:27 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-09-06 16:31:27 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 16:31:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-09-06 16:31:29 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 16:31:31 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-09-06 16:32:22 | INFO | fairseq.optim.adam | using FusedAdam
2023-09-06 16:32:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 16:32:22 | INFO | fairseq.trainer | begin training epoch 1
2023-09-06 16:32:22 | INFO | fairseq_cli.train | Start iterating over samples
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-06 16:32:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
2023-09-06 16:33:42 | INFO | train_inner | epoch 001:    101 / 1191 loss=17.16, trans_loss=6.401, nll_loss=5.175, w2v_ctc_loss=21.38, task_loss=1.731, task_loss_gen=2.029, contrastive_loss=0, total=6742.88, n_correct=205.36, ppl=36.13, accuracy=3.046, wps=29200.8, ups=1.5, wpb=19527.6, bsz=683.2, num_updates=100, lr=4.098e-06, gnorm=1.634, clip=0, loss_scale=64, train_wall=71, gb_free=17.7, wall=134
2023-09-06 16:33:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 16:34:48 | INFO | train_inner | epoch 001:    202 / 1191 loss=13.548, trans_loss=6.32, nll_loss=5.118, w2v_ctc_loss=15.898, task_loss=1.322, task_loss_gen=2.234, contrastive_loss=0, total=6677.34, n_correct=191.45, ppl=34.72, accuracy=2.867, wps=29133.7, ups=1.51, wpb=19352.7, bsz=677.6, num_updates=200, lr=8.096e-06, gnorm=6.139, clip=4, loss_scale=32, train_wall=66, gb_free=17.8, wall=201
2023-09-06 16:35:54 | INFO | train_inner | epoch 001:    302 / 1191 loss=8.437, trans_loss=6.223, nll_loss=5.054, w2v_ctc_loss=8.128, task_loss=0.674, task_loss_gen=2.56, contrastive_loss=0, total=6864.64, n_correct=200.08, ppl=33.21, accuracy=2.915, wps=30056.9, ups=1.51, wpb=19894.5, bsz=719.8, num_updates=300, lr=1.2094e-05, gnorm=1.619, clip=0, loss_scale=32, train_wall=65, gb_free=18.2, wall=267
2023-09-06 16:37:01 | INFO | train_inner | epoch 001:    402 / 1191 loss=7.904, trans_loss=6.136, nll_loss=4.986, w2v_ctc_loss=7.387, task_loss=0.329, task_loss_gen=4.246, contrastive_loss=0, total=6664.2, n_correct=185.36, ppl=31.69, accuracy=2.781, wps=29020.2, ups=1.5, wpb=19324, bsz=657.6, num_updates=400, lr=1.6092e-05, gnorm=0.833, clip=0, loss_scale=32, train_wall=66, gb_free=17.9, wall=334
2023-09-06 16:38:06 | INFO | train_inner | epoch 001:    502 / 1191 loss=7.647, trans_loss=6.107, nll_loss=4.961, w2v_ctc_loss=7.029, task_loss=0.098, task_loss_gen=5.559, contrastive_loss=0, total=6743.88, n_correct=179.97, ppl=31.15, accuracy=2.669, wps=29927.1, ups=1.53, wpb=19536.7, bsz=687.8, num_updates=500, lr=2.009e-05, gnorm=0.702, clip=0, loss_scale=32, train_wall=64, gb_free=17.7, wall=399
2023-09-06 16:39:12 | INFO | train_inner | epoch 001:    602 / 1191 loss=7.547, trans_loss=6.083, nll_loss=4.941, w2v_ctc_loss=6.898, task_loss=0.03, task_loss_gen=7.34, contrastive_loss=0, total=6761.26, n_correct=171.1, ppl=30.71, accuracy=2.531, wps=29897.9, ups=1.53, wpb=19590.9, bsz=685.7, num_updates=600, lr=2.4088e-05, gnorm=0.852, clip=0, loss_scale=32, train_wall=65, gb_free=18.9, wall=465
2023-09-06 16:40:17 | INFO | train_inner | epoch 001:    702 / 1191 loss=7.439, trans_loss=6.047, nll_loss=4.905, w2v_ctc_loss=6.768, task_loss=0.009, task_loss_gen=9.22, contrastive_loss=0, total=6642.51, n_correct=157.45, ppl=29.97, accuracy=2.37, wps=29583.4, ups=1.54, wpb=19237.1, bsz=677.7, num_updates=700, lr=2.8086e-05, gnorm=0.875, clip=0, loss_scale=32, train_wall=64, gb_free=17.6, wall=530
2023-09-06 16:41:21 | INFO | train_inner | epoch 001:    802 / 1191 loss=7.378, trans_loss=5.986, nll_loss=4.837, w2v_ctc_loss=6.738, task_loss=0.003, task_loss_gen=10.399, contrastive_loss=0, total=6747.81, n_correct=149.5, ppl=28.58, accuracy=2.216, wps=30122.5, ups=1.54, wpb=19542.8, bsz=688.1, num_updates=800, lr=3.2084e-05, gnorm=0.908, clip=0, loss_scale=32, train_wall=64, gb_free=17.7, wall=594
2023-09-06 16:41:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 16:42:28 | INFO | train_inner | epoch 001:    903 / 1191 loss=6.963, trans_loss=5.853, nll_loss=4.686, w2v_ctc_loss=6.236, task_loss=0.002, task_loss_gen=12.394, contrastive_loss=0, total=6690.14, n_correct=86.97, ppl=25.75, accuracy=1.3, wps=29301.8, ups=1.51, wpb=19388, bsz=669.3, num_updates=900, lr=3.6082e-05, gnorm=1.31, clip=0, loss_scale=16, train_wall=65, gb_free=17.6, wall=661
2023-09-06 16:43:34 | INFO | train_inner | epoch 001:   1003 / 1191 loss=6.284, trans_loss=5.884, nll_loss=4.721, w2v_ctc_loss=5.159, task_loss=0, task_loss_gen=15.273, contrastive_loss=0, total=6668.9, n_correct=24.83, ppl=26.37, accuracy=0.372, wps=29170, ups=1.51, wpb=19321.9, bsz=662.2, num_updates=1000, lr=4.008e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=65, gb_free=18.5, wall=727
2023-09-06 16:44:38 | INFO | train_inner | epoch 001:   1103 / 1191 loss=6.208, trans_loss=6.162, nll_loss=5.047, w2v_ctc_loss=4.743, task_loss=0.335, task_loss_gen=9.413, contrastive_loss=0, total=6578.13, n_correct=20.34, ppl=33.05, accuracy=0.309, wps=29563.5, ups=1.55, wpb=19050.5, bsz=647.4, num_updates=1100, lr=4.4078e-05, gnorm=0.493, clip=0, loss_scale=16, train_wall=64, gb_free=17.6, wall=791
2023-09-06 16:45:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
mix_tag: 0.5 at_nopad: True at_low_pos: False mixup_change_id: True
tokens_add_noise: None 
lengths_add_noise: None 
ids: None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-06 16:46:19 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 11.707 | trans_loss 14.773 | nll_loss 14.938 | w2v_ctc_loss 5.646 | task_loss 5.302 | task_loss_gen 13.4 | contrastive_loss 0 | total 6138.43 | n_correct 0.142857 | ppl 31381.8 | accuracy 0.002 | uer 75.728 | wer 73.648 | raw_wer 73.648 | bleu 0 | wps 1211.3 | wpb 6138.4 | bsz 201.1 | num_updates 1188
2023-09-06 16:46:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1188 updates
2023-09-06 16:46:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 16:46:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 16:46:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 1 @ 1188 updates, score 0.0) (writing took 5.434759157011285 seconds)
2023-09-06 16:46:24 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-09-06 16:46:24 | INFO | train | epoch 001 | loss 8.579 | trans_loss 6.123 | nll_loss 4.971 | w2v_ctc_loss 8.445 | task_loss 0.476 | task_loss_gen 6.924 | contrastive_loss 0 | total 6702.44 | n_correct 134.025 | ppl 31.36 | accuracy 2 | wps 27799.8 | ups 1.43 | wpb 19419.2 | bsz 677.7 | num_updates 1188 | lr 4.75962e-05 | gnorm 1.37 | clip 0.3 | loss_scale 16 | train_wall 775 | gb_free 18.5 | wall 897
2023-09-06 16:46:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 16:46:25 | INFO | fairseq.trainer | begin training epoch 2
2023-09-06 16:46:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 16:46:40 | INFO | train_inner | epoch 002:     12 / 1191 loss=5.995, trans_loss=6.28, nll_loss=5.25, w2v_ctc_loss=4.294, task_loss=1.221, task_loss_gen=2.393, contrastive_loss=0, total=6631.26, n_correct=20.55, ppl=38.06, accuracy=0.31, wps=15793.4, ups=0.82, wpb=19218.6, bsz=679.5, num_updates=1200, lr=4.8076e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=63, gb_free=17.5, wall=913
2023-09-06 16:47:45 | INFO | train_inner | epoch 002:    112 / 1191 loss=5.703, trans_loss=6.174, nll_loss=5.114, w2v_ctc_loss=3.955, task_loss=0.942, task_loss_gen=2.561, contrastive_loss=0, total=6617.43, n_correct=22.59, ppl=34.64, accuracy=0.341, wps=29561.6, ups=1.54, wpb=19164.1, bsz=662.2, num_updates=1300, lr=5.2074e-05, gnorm=0.644, clip=0, loss_scale=16, train_wall=64, gb_free=17.6, wall=978
2023-09-06 16:48:50 | INFO | train_inner | epoch 002:    212 / 1191 loss=5.689, trans_loss=6.398, nll_loss=5.37, w2v_ctc_loss=3.697, task_loss=0.702, task_loss_gen=2.806, contrastive_loss=0, total=6716.9, n_correct=2.9, ppl=41.34, accuracy=0.043, wps=29842.3, ups=1.53, wpb=19456.2, bsz=672.8, num_updates=1400, lr=5.6072e-05, gnorm=0.691, clip=0, loss_scale=16, train_wall=64, gb_free=17.5, wall=1043
2023-09-06 16:49:56 | INFO | train_inner | epoch 002:    312 / 1191 loss=5.523, trans_loss=6.346, nll_loss=5.319, w2v_ctc_loss=3.497, task_loss=0.762, task_loss_gen=2.51, contrastive_loss=0, total=6776.25, n_correct=10.8, ppl=39.92, accuracy=0.159, wps=29558.4, ups=1.51, wpb=19634.6, bsz=690.8, num_updates=1500, lr=6.007e-05, gnorm=0.734, clip=0, loss_scale=16, train_wall=66, gb_free=18, wall=1109
2023-09-06 16:51:01 | INFO | train_inner | epoch 002:    412 / 1191 loss=5.378, trans_loss=6.284, nll_loss=5.231, w2v_ctc_loss=3.34, task_loss=0.594, task_loss_gen=2.84, contrastive_loss=0, total=6718.15, n_correct=19.53, ppl=37.55, accuracy=0.291, wps=29973.2, ups=1.54, wpb=19472.2, bsz=690.8, num_updates=1600, lr=6.4068e-05, gnorm=0.934, clip=0, loss_scale=16, train_wall=64, gb_free=17.8, wall=1174
2023-09-06 16:52:06 | INFO | train_inner | epoch 002:    512 / 1191 loss=5.368, trans_loss=6.381, nll_loss=5.354, w2v_ctc_loss=3.218, task_loss=0.486, task_loss_gen=3.189, contrastive_loss=0, total=6696.54, n_correct=14.42, ppl=40.89, accuracy=0.215, wps=29891.5, ups=1.54, wpb=19408.7, bsz=678.7, num_updates=1700, lr=6.8066e-05, gnorm=0.753, clip=0, loss_scale=16, train_wall=64, gb_free=18.1, wall=1239
2023-09-06 16:53:11 | INFO | train_inner | epoch 002:    612 / 1191 loss=5.028, trans_loss=6.009, nll_loss=4.89, w2v_ctc_loss=3.086, task_loss=0.362, task_loss_gen=3.658, contrastive_loss=0, total=6640.77, n_correct=63.25, ppl=29.66, accuracy=0.952, wps=29759.2, ups=1.55, wpb=19228.2, bsz=659.1, num_updates=1800, lr=7.2064e-05, gnorm=0.775, clip=0, loss_scale=16, train_wall=64, gb_free=17.8, wall=1304
2023-09-06 16:54:15 | INFO | train_inner | epoch 002:    712 / 1191 loss=5.018, trans_loss=6.094, nll_loss=4.997, w2v_ctc_loss=2.985, task_loss=0.269, task_loss_gen=3.628, contrastive_loss=0, total=6799.78, n_correct=41.2, ppl=31.92, accuracy=0.606, wps=30652.5, ups=1.56, wpb=19685.9, bsz=701.6, num_updates=1900, lr=7.6062e-05, gnorm=0.767, clip=0, loss_scale=16, train_wall=63, gb_free=17.9, wall=1368
2023-09-06 16:55:19 | INFO | train_inner | epoch 002:    812 / 1191 loss=5.008, trans_loss=6.15, nll_loss=5.07, w2v_ctc_loss=2.906, task_loss=0.244, task_loss_gen=3.91, contrastive_loss=0, total=6729.15, n_correct=58.28, ppl=33.58, accuracy=0.866, wps=30378.1, ups=1.56, wpb=19495.9, bsz=677.7, num_updates=2000, lr=8.006e-05, gnorm=0.754, clip=0, loss_scale=16, train_wall=63, gb_free=17.7, wall=1432
2023-09-06 16:55:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 16:56:03 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.221 | trans_loss 13.455 | nll_loss 13.2 | w2v_ctc_loss 3.672 | task_loss 2.667 | task_loss_gen 16.701 | contrastive_loss 0 | total 6138.43 | n_correct 0.571429 | ppl 9408.57 | accuracy 0.009 | uer 55.08 | wer 53.589 | raw_wer 53.589 | bleu 0 | wps 1211.9 | wpb 6138.4 | bsz 201.1 | num_updates 2000 | best_bleu 0
2023-09-06 16:56:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-09-06 16:56:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_2_2000.pt
2023-09-06 16:56:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_2_2000.pt
2023-09-06 16:56:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 15.152476767078042 seconds)
2023-09-06 16:57:25 | INFO | train_inner | epoch 002:    912 / 1191 loss=4.994, trans_loss=6.206, nll_loss=5.141, w2v_ctc_loss=2.829, task_loss=0.123, task_loss_gen=4.731, contrastive_loss=0, total=6738.95, n_correct=27.96, ppl=35.29, accuracy=0.415, wps=15590.7, ups=0.8, wpb=19533.2, bsz=703.8, num_updates=2100, lr=8.4058e-05, gnorm=0.843, clip=0, loss_scale=16, train_wall=65, gb_free=17.8, wall=1558
2023-09-06 16:58:30 | INFO | train_inner | epoch 002:   1012 / 1191 loss=4.945, trans_loss=6.178, nll_loss=5.102, w2v_ctc_loss=2.779, task_loss=0.07, task_loss_gen=5.665, contrastive_loss=0, total=6774.79, n_correct=56.33, ppl=34.35, accuracy=0.831, wps=30291.1, ups=1.54, wpb=19640.8, bsz=687.3, num_updates=2200, lr=8.8056e-05, gnorm=0.694, clip=0, loss_scale=16, train_wall=64, gb_free=18.1, wall=1623
2023-09-06 16:59:34 | INFO | train_inner | epoch 002:   1112 / 1191 loss=4.888, trans_loss=6.148, nll_loss=5.07, w2v_ctc_loss=2.722, task_loss=0.041, task_loss_gen=6.88, contrastive_loss=0, total=6659.17, n_correct=10.37, ppl=33.6, accuracy=0.156, wps=29916.3, ups=1.55, wpb=19287, bsz=656.7, num_updates=2300, lr=9.2054e-05, gnorm=0.659, clip=0, loss_scale=16, train_wall=64, gb_free=18.4, wall=1687
2023-09-06 17:00:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 17:01:09 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.743 | trans_loss 14.363 | nll_loss 14.337 | w2v_ctc_loss 3.361 | task_loss 0.273 | task_loss_gen 33.538 | contrastive_loss 0 | total 6138.43 | n_correct 3.14286 | ppl 20700.2 | accuracy 0.051 | uer 50.844 | wer 50.643 | raw_wer 50.643 | bleu 0 | wps 1207.4 | wpb 6138.4 | bsz 201.1 | num_updates 2379 | best_bleu 0
2023-09-06 17:01:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2379 updates
2023-09-06 17:01:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 17:01:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 17:01:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 2 @ 2379 updates, score 0.0) (writing took 12.330437807017006 seconds)
2023-09-06 17:01:22 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-09-06 17:01:22 | INFO | train | epoch 002 | loss 5.208 | trans_loss 6.204 | nll_loss 5.136 | w2v_ctc_loss 3.16 | task_loss 0.399 | task_loss_gen 4.101 | contrastive_loss 0 | total 6703.69 | n_correct 29.6675 | ppl 35.17 | accuracy 0.443 | wps 25775.2 | ups 1.33 | wpb 19422.7 | bsz 678.2 | num_updates 2379 | lr 9.52124e-05 | gnorm 0.754 | clip 0 | loss_scale 16 | train_wall 763 | gb_free 17.7 | wall 1795
2023-09-06 17:01:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 17:01:22 | INFO | fairseq.trainer | begin training epoch 3
2023-09-06 17:01:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 17:01:43 | INFO | train_inner | epoch 003:     21 / 1191 loss=4.859, trans_loss=6.136, nll_loss=5.046, w2v_ctc_loss=2.688, task_loss=0.019, task_loss_gen=8.235, contrastive_loss=0, total=6599.17, n_correct=25.67, ppl=33.05, accuracy=0.389, wps=14809.3, ups=0.77, wpb=19129.9, bsz=657.1, num_updates=2400, lr=9.6052e-05, gnorm=0.793, clip=0, loss_scale=16, train_wall=64, gb_free=18.1, wall=1816
2023-09-06 17:02:48 | INFO | train_inner | epoch 003:    121 / 1191 loss=4.957, trans_loss=6.336, nll_loss=5.312, w2v_ctc_loss=2.624, task_loss=0.01, task_loss_gen=8.436, contrastive_loss=0, total=6686.57, n_correct=5.57, ppl=39.74, accuracy=0.083, wps=30008.4, ups=1.55, wpb=19387.8, bsz=684.3, num_updates=2500, lr=0.00010005, gnorm=0.712, clip=0, loss_scale=16, train_wall=64, gb_free=18.6, wall=1881
2023-09-06 17:03:53 | INFO | train_inner | epoch 003:    221 / 1191 loss=4.839, trans_loss=6.237, nll_loss=5.191, w2v_ctc_loss=2.554, task_loss=0.005, task_loss_gen=9.171, contrastive_loss=0, total=6719.64, n_correct=14.04, ppl=36.52, accuracy=0.209, wps=29767.7, ups=1.53, wpb=19473.2, bsz=686.5, num_updates=2600, lr=0.000104048, gnorm=0.667, clip=0, loss_scale=16, train_wall=64, gb_free=18.8, wall=1946
2023-09-06 17:04:59 | INFO | train_inner | epoch 003:    321 / 1191 loss=4.814, trans_loss=6.196, nll_loss=5.122, w2v_ctc_loss=2.548, task_loss=0.003, task_loss_gen=11.913, contrastive_loss=0, total=6583.91, n_correct=13.66, ppl=34.82, accuracy=0.207, wps=29054.8, ups=1.52, wpb=19066, bsz=626, num_updates=2700, lr=0.000108046, gnorm=0.69, clip=0, loss_scale=16, train_wall=65, gb_free=17.6, wall=2012
2023-09-06 17:06:03 | INFO | train_inner | epoch 003:    421 / 1191 loss=4.798, trans_loss=6.242, nll_loss=5.184, w2v_ctc_loss=2.481, task_loss=0.001, task_loss_gen=11.339, contrastive_loss=0, total=6692.35, n_correct=6.98, ppl=36.36, accuracy=0.104, wps=30072.9, ups=1.55, wpb=19390.6, bsz=688.7, num_updates=2800, lr=0.000112044, gnorm=0.565, clip=0, loss_scale=16, train_wall=64, gb_free=17.4, wall=2076
2023-09-06 17:07:08 | INFO | train_inner | epoch 003:    521 / 1191 loss=4.779, trans_loss=6.227, nll_loss=5.16, w2v_ctc_loss=2.47, task_loss=0.001, task_loss_gen=12.151, contrastive_loss=0, total=6739.55, n_correct=29.26, ppl=35.74, accuracy=0.434, wps=30159.3, ups=1.54, wpb=19529.7, bsz=674.5, num_updates=2900, lr=0.000116042, gnorm=0.608, clip=0, loss_scale=32, train_wall=64, gb_free=17.9, wall=2141
2023-09-06 17:07:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-06 17:08:14 | INFO | train_inner | epoch 003:    622 / 1191 loss=4.782, trans_loss=6.254, nll_loss=5.209, w2v_ctc_loss=2.437, task_loss=0, task_loss_gen=13.59, contrastive_loss=0, total=6744.3, n_correct=19.69, ppl=37, accuracy=0.292, wps=29855.7, ups=1.53, wpb=19545.7, bsz=659.7, num_updates=3000, lr=0.00012004, gnorm=0.595, clip=0, loss_scale=16, train_wall=65, gb_free=18.6, wall=2207
2023-09-06 17:08:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-06 17:08:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-06 17:09:59 | INFO | train_inner | epoch 003:    724 / 1191 loss=3.905, trans_loss=5.331, nll_loss=4.038, w2v_ctc_loss=2.077, task_loss=1.144, task_loss_gen=6.392, contrastive_loss=0, total=6744.87, n_correct=341.93, ppl=16.43, accuracy=5.069, wps=18503.7, ups=0.95, wpb=19549.7, bsz=703.5, num_updates=3100, lr=0.000124038, gnorm=1.227, clip=0, loss_scale=4, train_wall=105, gb_free=14.3, wall=2312
2023-09-06 17:11:42 | INFO | train_inner | epoch 003:    824 / 1191 loss=3.507, trans_loss=5, nll_loss=3.599, w2v_ctc_loss=1.827, task_loss=0.439, task_loss_gen=3.23, contrastive_loss=0, total=6767.26, n_correct=902.48, ppl=12.12, accuracy=13.336, wps=19120, ups=0.97, wpb=19615.8, bsz=703.5, num_updates=3200, lr=0.000128036, gnorm=0.931, clip=0, loss_scale=4, train_wall=102, gb_free=13.5, wall=2415
2023-09-06 17:13:23 | INFO | train_inner | epoch 003:    924 / 1191 loss=2.904, trans_loss=4.222, nll_loss=2.566, w2v_ctc_loss=1.726, task_loss=0.346, task_loss_gen=3.282, contrastive_loss=0, total=6810.72, n_correct=2166.34, ppl=5.92, accuracy=31.808, wps=19409.7, ups=0.98, wpb=19727.4, bsz=717.9, num_updates=3300, lr=0.000132034, gnorm=0.904, clip=0, loss_scale=4, train_wall=101, gb_free=12.9, wall=2516
2023-09-06 17:15:07 | INFO | train_inner | epoch 003:   1024 / 1191 loss=2.83, trans_loss=4.142, nll_loss=2.465, w2v_ctc_loss=1.691, task_loss=0.435, task_loss_gen=4.453, contrastive_loss=0, total=6546.4, n_correct=2240.49, ppl=5.52, accuracy=34.225, wps=18277.2, ups=0.96, wpb=18970.7, bsz=618.6, num_updates=3400, lr=0.000136032, gnorm=0.831, clip=0, loss_scale=4, train_wall=103, gb_free=13.3, wall=2620
2023-09-06 17:16:51 | INFO | train_inner | epoch 003:   1124 / 1191 loss=2.755, trans_loss=4.126, nll_loss=2.442, w2v_ctc_loss=1.601, task_loss=0.347, task_loss_gen=4.058, contrastive_loss=0, total=6759.46, n_correct=2363.49, ppl=5.43, accuracy=34.966, wps=18914.7, ups=0.97, wpb=19569.3, bsz=704, num_updates=3500, lr=0.00014003, gnorm=0.816, clip=0, loss_scale=4, train_wall=103, gb_free=13.8, wall=2724
2023-09-06 17:17:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 17:18:32 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.323 | trans_loss 7.051 | nll_loss 4.888 | w2v_ctc_loss 1.814 | task_loss 0.726 | task_loss_gen 15.279 | contrastive_loss 0 | total 6138.43 | n_correct 2293.43 | ppl 29.6 | accuracy 37.362 | uer 30.46 | wer 30.774 | raw_wer 30.774 | bleu 0.25 | wps 1734.3 | wpb 6138.4 | bsz 201.1 | num_updates 3567 | best_bleu 0.25
2023-09-06 17:18:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3567 updates
2023-09-06 17:18:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 17:18:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 17:18:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 3 @ 3567 updates, score 0.25) (writing took 13.229354057926685 seconds)
2023-09-06 17:18:45 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-09-06 17:18:45 | INFO | train | epoch 003 | loss 4.02 | trans_loss 5.425 | nll_loss 4.132 | w2v_ctc_loss 2.158 | task_loss 0.255 | task_loss_gen 7.749 | contrastive_loss 0 | total 6704.59 | n_correct 814.228 | ppl 17.53 | accuracy 12.144 | wps 22124.5 | ups 1.14 | wpb 19425.3 | bsz 678.4 | num_updates 3567 | lr 0.000142709 | gnorm 0.776 | clip 0 | loss_scale 4 | train_wall 979 | gb_free 15 | wall 2838
2023-09-06 17:18:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 17:18:45 | INFO | fairseq.trainer | begin training epoch 4
2023-09-06 17:18:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 17:19:27 | INFO | train_inner | epoch 004:     33 / 1191 loss=2.719, trans_loss=4.119, nll_loss=2.432, w2v_ctc_loss=1.558, task_loss=0.377, task_loss_gen=4.583, contrastive_loss=0, total=6584.98, n_correct=2327.42, ppl=5.39, accuracy=35.344, wps=12196.4, ups=0.64, wpb=19058.3, bsz=650.5, num_updates=3600, lr=0.000144028, gnorm=0.769, clip=0, loss_scale=4, train_wall=101, gb_free=13.3, wall=2880
2023-09-06 17:21:11 | INFO | train_inner | epoch 004:    133 / 1191 loss=2.675, trans_loss=4.099, nll_loss=2.409, w2v_ctc_loss=1.504, task_loss=0.349, task_loss_gen=4.326, contrastive_loss=0, total=6725.65, n_correct=2410.75, ppl=5.31, accuracy=35.844, wps=18776.6, ups=0.96, wpb=19481.6, bsz=657.2, num_updates=3700, lr=0.000148026, gnorm=0.786, clip=0, loss_scale=4, train_wall=103, gb_free=12.1, wall=2984
2023-09-06 17:22:54 | INFO | train_inner | epoch 004:    233 / 1191 loss=2.641, trans_loss=4.092, nll_loss=2.403, w2v_ctc_loss=1.465, task_loss=0.405, task_loss_gen=4.739, contrastive_loss=0, total=6748.29, n_correct=2441.1, ppl=5.29, accuracy=36.174, wps=18976.6, ups=0.97, wpb=19555.5, bsz=700.2, num_updates=3800, lr=0.000152024, gnorm=0.775, clip=0, loss_scale=4, train_wall=102, gb_free=11.6, wall=3087
2023-09-06 17:24:35 | INFO | train_inner | epoch 004:    333 / 1191 loss=2.63, trans_loss=4.09, nll_loss=2.401, w2v_ctc_loss=1.449, task_loss=0.4, task_loss_gen=5.325, contrastive_loss=0, total=6673.75, n_correct=2416.56, ppl=5.28, accuracy=36.21, wps=19027.6, ups=0.98, wpb=19340, bsz=664.8, num_updates=3900, lr=0.000156022, gnorm=0.753, clip=0, loss_scale=4, train_wall=101, gb_free=13.2, wall=3188
2023-09-06 17:26:18 | INFO | train_inner | epoch 004:    433 / 1191 loss=2.616, trans_loss=4.083, nll_loss=2.392, w2v_ctc_loss=1.436, task_loss=0.429, task_loss_gen=5.409, contrastive_loss=0, total=6706.67, n_correct=2445.33, ppl=5.25, accuracy=36.461, wps=18902.5, ups=0.97, wpb=19435.3, bsz=683.2, num_updates=4000, lr=0.00016002, gnorm=0.731, clip=0, loss_scale=4, train_wall=102, gb_free=14.2, wall=3291
2023-09-06 17:26:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 17:26:52 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.216 | trans_loss 6.973 | nll_loss 4.791 | w2v_ctc_loss 1.635 | task_loss 0.017 | task_loss_gen 41.637 | contrastive_loss 0 | total 6138.43 | n_correct 2339.71 | ppl 27.69 | accuracy 38.116 | uer 26.839 | wer 27.951 | raw_wer 27.951 | bleu 0.39 | wps 1656.1 | wpb 6138.4 | bsz 201.1 | num_updates 4000 | best_bleu 0.39
2023-09-06 17:26:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4000 updates
2023-09-06 17:26:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_4_4000.pt
2023-09-06 17:26:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_4_4000.pt
2023-09-06 17:27:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_4_4000.pt (epoch 4 @ 4000 updates, score 0.39) (writing took 14.259407400037162 seconds)
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([ 0.0126,  0.0136, -0.0345,  0.0002,  0.0031], device='cuda:0',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.3672,  3.4336, -1.2725,  ..., -0.9385,  0.1780,  0.9775],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3418,  0.1378,  0.7134,  ..., -0.2642, -0.5356,  0.3140]],
       device='cuda:0', dtype=torch.float16)
task_net layer_norm.weight True tensor([ 0.0126,  0.0136, -0.0345,  0.0002,  0.0031], device='cuda:0',
       dtype=torch.float16)
--------------------
2023-09-06 17:28:49 | INFO | train_inner | epoch 004:    533 / 1191 loss=2.595, trans_loss=4.078, nll_loss=2.385, w2v_ctc_loss=1.407, task_loss=0.448, task_loss_gen=5.979, contrastive_loss=0, total=6664.83, n_correct=2433.85, ppl=5.22, accuracy=36.518, wps=12802.1, ups=0.66, wpb=19309.1, bsz=662.9, num_updates=4100, lr=0.000164018, gnorm=0.748, clip=0, loss_scale=4, train_wall=102, gb_free=12.8, wall=3442
2023-09-06 17:30:32 | INFO | train_inner | epoch 004:    633 / 1191 loss=2.572, trans_loss=4.064, nll_loss=2.368, w2v_ctc_loss=1.391, task_loss=0.479, task_loss_gen=5.153, contrastive_loss=0, total=6836.09, n_correct=2528.37, ppl=5.16, accuracy=36.986, wps=19208.3, ups=0.97, wpb=19815.3, bsz=714.8, num_updates=4200, lr=0.000168016, gnorm=0.77, clip=0, loss_scale=4, train_wall=102, gb_free=15, wall=3545
2023-09-06 17:32:14 | INFO | train_inner | epoch 004:    733 / 1191 loss=2.556, trans_loss=4.075, nll_loss=2.38, w2v_ctc_loss=1.364, task_loss=0.43, task_loss_gen=4.887, contrastive_loss=0, total=6692.34, n_correct=2484.59, ppl=5.21, accuracy=37.126, wps=19068.3, ups=0.98, wpb=19385.6, bsz=683.6, num_updates=4300, lr=0.000172014, gnorm=0.763, clip=0, loss_scale=4, train_wall=101, gb_free=14.7, wall=3647
2023-09-06 17:33:58 | INFO | train_inner | epoch 004:    833 / 1191 loss=2.539, trans_loss=4.082, nll_loss=2.387, w2v_ctc_loss=1.346, task_loss=0.61, task_loss_gen=4.214, contrastive_loss=0, total=6858.25, n_correct=2559.72, ppl=5.23, accuracy=37.323, wps=19165.9, ups=0.96, wpb=19861.5, bsz=722.4, num_updates=4400, lr=0.000176012, gnorm=0.791, clip=0, loss_scale=4, train_wall=103, gb_free=11.3, wall=3751
2023-09-06 17:35:40 | INFO | train_inner | epoch 004:    933 / 1191 loss=2.528, trans_loss=4.07, nll_loss=2.371, w2v_ctc_loss=1.335, task_loss=0.53, task_loss_gen=4.092, contrastive_loss=0, total=6733.97, n_correct=2528.71, ppl=5.17, accuracy=37.552, wps=18972.5, ups=0.97, wpb=19496.2, bsz=702.5, num_updates=4500, lr=0.00018001, gnorm=0.755, clip=0, loss_scale=4, train_wall=102, gb_free=12.9, wall=3853
2023-09-06 17:37:24 | INFO | train_inner | epoch 004:   1033 / 1191 loss=2.534, trans_loss=4.06, nll_loss=2.361, w2v_ctc_loss=1.337, task_loss=1.747, task_loss_gen=4.059, contrastive_loss=0, total=6643.72, n_correct=2496.52, ppl=5.14, accuracy=37.577, wps=18524.8, ups=0.96, wpb=19244.1, bsz=662.2, num_updates=4600, lr=0.000184008, gnorm=1.086, clip=0, loss_scale=4, train_wall=103, gb_free=14.1, wall=3957
2023-09-06 17:39:07 | INFO | train_inner | epoch 004:   1133 / 1191 loss=2.527, trans_loss=4.039, nll_loss=2.338, w2v_ctc_loss=1.332, task_loss=2.088, task_loss_gen=3.582, contrastive_loss=0, total=6564.89, n_correct=2464.01, ppl=5.06, accuracy=37.533, wps=18600, ups=0.98, wpb=19032.7, bsz=632.2, num_updates=4700, lr=0.000188006, gnorm=1.179, clip=0, loss_scale=4, train_wall=102, gb_free=14.1, wall=4059
2023-09-06 17:40:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([ 0.1299,  0.0513, -0.1907, -0.0141, -0.0250], device='cuda:6',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.6440,  5.6953, -0.2184,  ..., -1.3066,  0.7495,  1.0596],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 3.5137,  2.6602,  5.4570,  ..., -0.3745, -0.8164,  0.1671]],
       device='cuda:6', dtype=torch.float16)
task_net layer_norm.weight True tensor([ 0.1299,  0.0513, -0.1907, -0.0141, -0.0250], device='cuda:6',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([ 0.0002,  0.0005, -0.0011, -0.0004, -0.0004], device='cuda:3',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.8315,  0.1730, -0.1240,  ..., -0.2573,  0.1774,  0.3342],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1065,  0.3628,  0.2598,  ..., -0.0129, -0.1305,  0.0648]],
       device='cuda:3', dtype=torch.float16)
task_net layer_norm.weight True tensor([ 0.0002,  0.0005, -0.0011, -0.0004, -0.0004], device='cuda:3',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([ 4.5013e-03,  4.4556e-03, -1.3336e-02,  1.0908e-05, -1.0786e-03],
       device='cuda:2', dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.2285,  0.7417, -0.5566,  ..., -0.8271,  0.1929,  0.3875],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 1.5449,  0.7305,  0.1244,  ..., -0.0938, -0.3311,  0.2400]],
       device='cuda:2', dtype=torch.float16)
task_net layer_norm.weight True tensor([ 4.5013e-03,  4.4556e-03, -1.3336e-02,  1.0908e-05, -1.0786e-03],
       device='cuda:2', dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([ 0.0007,  0.0033, -0.0121, -0.0016, -0.0024], device='cuda:4',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-1.1875,  1.1318,  0.2207,  ..., -0.5942,  0.2286,  0.4875],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.5117,  0.2104,  0.0674,  ..., -0.0452, -0.2292,  0.1376]],
       device='cuda:4', dtype=torch.float16)
task_net layer_norm.weight True tensor([ 0.0007,  0.0033, -0.0121, -0.0016, -0.0024], device='cuda:4',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([ 0.0480,  0.0093, -0.0822, -0.0006, -0.0056], device='cuda:1',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-1.8340,  2.3086, -2.3145,  ..., -1.1260,  0.4053,  0.9980],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.1099,  1.1592,  2.7051,  ..., -0.2810, -0.7856,  0.3914]],
       device='cuda:1', dtype=torch.float16)
task_net layer_norm.weight True tensor([ 0.0480,  0.0093, -0.0822, -0.0006, -0.0056], device='cuda:1',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([ 0.0310, -0.0025, -0.0292, -0.0001, -0.0120], device='cuda:7',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.4316,  0.3538,  3.4863,  ..., -1.2676,  0.0778,  0.9395],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 3.4199,  1.0352, -0.5010,  ..., -0.3704, -0.6230,  0.0353]],
       device='cuda:7', dtype=torch.float16)
task_net layer_norm.weight True tensor([ 0.0310, -0.0025, -0.0292, -0.0001, -0.0120], device='cuda:7',
       dtype=torch.float16)
--------------------
--------------------
Before gen at loss:
task_net layer_norm.weight True tensor([ 0.0005,  0.0015, -0.0092, -0.0007, -0.0008], device='cuda:5',
       dtype=torch.float16)
After gen at loss:
textual_encoder embed_tokens.weight True tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3323,  0.5835, -0.9214,  ..., -0.5962,  0.3464,  0.4014],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.6475,  0.8560,  0.6611,  ..., -0.0693, -0.2852,  0.0612]],
       device='cuda:5', dtype=torch.float16)
task_net layer_norm.weight True tensor([ 0.0005,  0.0015, -0.0092, -0.0007, -0.0008], device='cuda:5',
       dtype=torch.float16)
--------------------
2023-09-06 17:40:42 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.103 | trans_loss 6.873 | nll_loss 4.664 | w2v_ctc_loss 1.482 | task_loss 3.726 | task_loss_gen 13.527 | contrastive_loss 0 | total 6138.43 | n_correct 2433.57 | ppl 25.36 | accuracy 39.645 | uer 24.384 | wer 25.456 | raw_wer 25.456 | bleu 0.38 | wps 1492.3 | wpb 6138.4 | bsz 201.1 | num_updates 4758 | best_bleu 0.39
2023-09-06 17:40:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4758 updates
2023-09-06 17:40:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_0.3807.pt
2023-09-06 17:40:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_0.3807.pt
2023-09-06 17:40:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_0.3807.pt (epoch 4 @ 4758 updates, score 0.38) (writing took 7.948386807925999 seconds)
2023-09-06 17:40:50 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-09-06 17:40:50 | INFO | train | epoch 004 | loss 2.583 | trans_loss 4.074 | nll_loss 2.379 | w2v_ctc_loss 1.398 | task_loss 0.769 | task_loss_gen 4.634 | contrastive_loss 0 | total 6703.69 | n_correct 2471.47 | ppl 5.2 | accuracy 36.867 | wps 17460.5 | ups 0.9 | wpb 19422.7 | bsz 678.2 | num_updates 4758 | lr 0.000190325 | gnorm 0.843 | clip 0 | loss_scale 4 | train_wall 1215 | gb_free 13.2 | wall 4163
2023-09-06 17:40:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 17:40:50 | INFO | fairseq.trainer | begin training epoch 5
2023-09-06 17:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 17:41:41 | INFO | train_inner | epoch 005:     42 / 1191 loss=2.484, trans_loss=4.009, nll_loss=2.3, w2v_ctc_loss=1.29, task_loss=1.749, task_loss_gen=2.676, contrastive_loss=0, total=6756.35, n_correct=2594.44, ppl=4.92, accuracy=38.4, wps=12692.4, ups=0.65, wpb=19580.7, bsz=706.7, num_updates=4800, lr=0.000192004, gnorm=1.018, clip=0, loss_scale=4, train_wall=101, gb_free=13.3, wall=4214
2023-09-06 17:43:24 | INFO | train_inner | epoch 005:    142 / 1191 loss=2.469, trans_loss=4.004, nll_loss=2.292, w2v_ctc_loss=1.269, task_loss=1.928, task_loss_gen=2.714, contrastive_loss=0, total=6729.54, n_correct=2594.06, ppl=4.9, accuracy=38.547, wps=18949.2, ups=0.97, wpb=19497.4, bsz=684.1, num_updates=4900, lr=0.000196002, gnorm=0.987, clip=0, loss_scale=4, train_wall=102, gb_free=13.5, wall=4317
2023-09-06 17:45:06 | INFO | train_inner | epoch 005:    242 / 1191 loss=2.449, trans_loss=3.99, nll_loss=2.275, w2v_ctc_loss=1.25, task_loss=1.469, task_loss_gen=2.225, contrastive_loss=0, total=6861.39, n_correct=2673.39, ppl=4.84, accuracy=38.963, wps=19428.3, ups=0.98, wpb=19875.8, bsz=728.4, num_updates=5000, lr=0.0002, gnorm=0.829, clip=0, loss_scale=4, train_wall=101, gb_free=13.4, wall=4419
mt_weight tensor(0.5000)
asr_weight tensor(0.3377, device='cuda:0')
2023-09-06 17:45:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-06 17:46:50 | INFO | train_inner | epoch 005:    343 / 1191 loss=2.444, trans_loss=3.993, nll_loss=2.278, w2v_ctc_loss=1.237, task_loss=1.443, task_loss_gen=2.487, contrastive_loss=0, total=6613.89, n_correct=2568.48, ppl=4.85, accuracy=38.835, wps=18481.3, ups=0.96, wpb=19162.4, bsz=659.5, num_updates=5100, lr=0.00019803, gnorm=0.918, clip=0, loss_scale=2, train_wall=103, gb_free=13, wall=4523
2023-09-06 17:48:33 | INFO | train_inner | epoch 005:    443 / 1191 loss=2.46, trans_loss=3.991, nll_loss=2.278, w2v_ctc_loss=1.262, task_loss=1.245, task_loss_gen=2.151, contrastive_loss=0, total=6682.75, n_correct=2589.18, ppl=4.85, accuracy=38.744, wps=18840.4, ups=0.97, wpb=19374.4, bsz=677.7, num_updates=5200, lr=0.000196116, gnorm=0.812, clip=0, loss_scale=2, train_wall=102, gb_free=13.3, wall=4625
2023-09-06 17:49:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-09-06 17:50:17 | INFO | train_inner | epoch 005:    544 / 1191 loss=2.562, trans_loss=4.07, nll_loss=2.377, w2v_ctc_loss=1.345, task_loss=1.063, task_loss_gen=2.237, contrastive_loss=0, total=6680, n_correct=2452.4, ppl=5.2, accuracy=36.713, wps=18576.1, ups=0.96, wpb=19349.2, bsz=679.2, num_updates=5300, lr=0.000194257, gnorm=1.443, clip=1, loss_scale=1, train_wall=103, gb_free=12.6, wall=4730
2023-09-06 17:51:58 | INFO | train_inner | epoch 005:    644 / 1191 loss=2.458, trans_loss=4.004, nll_loss=2.29, w2v_ctc_loss=1.253, task_loss=0.911, task_loss_gen=2.094, contrastive_loss=0, total=6701.47, n_correct=2599.78, ppl=4.89, accuracy=38.794, wps=19107.1, ups=0.98, wpb=19404.6, bsz=666.6, num_updates=5400, lr=0.00019245, gnorm=0.905, clip=0, loss_scale=1, train_wall=101, gb_free=13.4, wall=4831
2023-09-06 17:52:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2023-09-06 17:52:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
2023-09-06 17:52:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
2023-09-06 17:53:45 | INFO | train_inner | epoch 005:    747 / 1191 loss=2.922, trans_loss=4.144, nll_loss=2.471, w2v_ctc_loss=1.844, task_loss=0.882, task_loss_gen=2.306, contrastive_loss=0, total=6733.38, n_correct=2302.82, ppl=5.54, accuracy=34.2, wps=18270.1, ups=0.94, wpb=19516.9, bsz=692.4, num_updates=5500, lr=0.000190693, gnorm=11.808, clip=36, loss_scale=0.125, train_wall=106, gb_free=13.1, wall=4938
2023-09-06 17:55:27 | INFO | train_inner | epoch 005:    847 / 1191 loss=2.889, trans_loss=4.092, nll_loss=2.399, w2v_ctc_loss=1.867, task_loss=1.001, task_loss_gen=1.896, contrastive_loss=0, total=6760.8, n_correct=2466.81, ppl=5.27, accuracy=36.487, wps=19163.4, ups=0.98, wpb=19582.5, bsz=685.9, num_updates=5600, lr=0.000188982, gnorm=9.127, clip=21, loss_scale=0.125, train_wall=101, gb_free=13.7, wall=5040
2023-09-06 17:57:10 | INFO | train_inner | epoch 005:    947 / 1191 loss=2.786, trans_loss=4.074, nll_loss=2.379, w2v_ctc_loss=1.714, task_loss=1.085, task_loss_gen=1.837, contrastive_loss=0, total=6601.84, n_correct=2436.47, ppl=5.2, accuracy=36.906, wps=18611.4, ups=0.97, wpb=19127.6, bsz=656.9, num_updates=5700, lr=0.000187317, gnorm=8.057, clip=21, loss_scale=0.125, train_wall=102, gb_free=13.5, wall=5143
2023-09-06 17:58:53 | INFO | train_inner | epoch 005:   1047 / 1191 loss=2.575, trans_loss=4.048, nll_loss=2.347, w2v_ctc_loss=1.402, task_loss=1.31, task_loss_gen=1.909, contrastive_loss=0, total=6646.75, n_correct=2488.34, ppl=5.09, accuracy=37.437, wps=18736.6, ups=0.97, wpb=19260.2, bsz=648.1, num_updates=5800, lr=0.000185695, gnorm=7.681, clip=21, loss_scale=0.125, train_wall=102, gb_free=14.3, wall=5246
2023-09-06 18:00:35 | INFO | train_inner | epoch 005:   1147 / 1191 loss=2.504, trans_loss=4.031, nll_loss=2.326, w2v_ctc_loss=1.309, task_loss=1.173, task_loss_gen=1.803, contrastive_loss=0, total=6692.64, n_correct=2551.13, ppl=5.01, accuracy=38.118, wps=18919.2, ups=0.98, wpb=19392.9, bsz=666, num_updates=5900, lr=0.000184115, gnorm=5.742, clip=3, loss_scale=0.125, train_wall=102, gb_free=13, wall=5348
2023-09-06 18:01:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.3377, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.3377, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.3377, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.3377, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.3377, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.3377, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.3377, device='cuda:5')
2023-09-06 18:01:57 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 5.052 | trans_loss 6.825 | nll_loss 4.589 | w2v_ctc_loss 1.421 | task_loss 5.788 | task_loss_gen 6.761 | contrastive_loss 0 | total 6138.43 | n_correct 2465.71 | ppl 24.06 | accuracy 40.168 | uer 24.293 | wer 25.798 | raw_wer 25.798 | bleu 0.57 | wps 1447.4 | wpb 6138.4 | bsz 201.1 | num_updates 5944 | best_bleu 0.57
2023-09-06 18:01:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5944 updates
2023-09-06 18:01:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 18:02:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 18:02:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 5 @ 5944 updates, score 0.57) (writing took 12.102619932033122 seconds)
2023-09-06 18:02:09 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-09-06 18:02:09 | INFO | train | epoch 005 | loss 2.583 | trans_loss 4.038 | nll_loss 2.335 | w2v_ctc_loss 1.419 | task_loss 1.232 | task_loss_gen 2.149 | contrastive_loss 0 | total 6704.37 | n_correct 2526.13 | ppl 5.04 | accuracy 37.679 | wps 18004.6 | ups 0.93 | wpb 19424.8 | bsz 678.6 | num_updates 5944 | lr 0.000183432 | gnorm 4.358 | clip 9.1 | loss_scale 0.125 | train_wall 1212 | gb_free 11.1 | wall 5442
2023-09-06 18:02:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 18:02:10 | INFO | fairseq.trainer | begin training epoch 6
2023-09-06 18:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 18:03:13 | INFO | train_inner | epoch 006:     56 / 1191 loss=2.453, trans_loss=4.012, nll_loss=2.301, w2v_ctc_loss=1.244, task_loss=1.203, task_loss_gen=1.766, contrastive_loss=0, total=6649.43, n_correct=2559.9, ppl=4.93, accuracy=38.498, wps=12183.8, ups=0.63, wpb=19266.9, bsz=661.3, num_updates=6000, lr=0.000182574, gnorm=6.152, clip=8, loss_scale=0.125, train_wall=101, gb_free=11.9, wall=5506
2023-09-06 18:03:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 18:03:50 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 5.087 | trans_loss 6.826 | nll_loss 4.586 | w2v_ctc_loss 1.535 | task_loss 10.802 | task_loss_gen 7.365 | contrastive_loss 0 | total 6138.43 | n_correct 2471.14 | ppl 24.02 | accuracy 40.257 | uer 24.609 | wer 26.292 | raw_wer 26.292 | bleu 0.64 | wps 1481.5 | wpb 6138.4 | bsz 201.1 | num_updates 6000 | best_bleu 0.64
2023-09-06 18:03:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6000 updates
2023-09-06 18:03:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_6_6000.pt
2023-09-06 18:03:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_6_6000.pt
2023-09-06 18:04:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_6_6000.pt (epoch 6 @ 6000 updates, score 0.64) (writing took 12.600858167978004 seconds)
2023-09-06 18:05:45 | INFO | train_inner | epoch 006:    156 / 1191 loss=2.441, trans_loss=4.013, nll_loss=2.3, w2v_ctc_loss=1.228, task_loss=1.147, task_loss_gen=1.776, contrastive_loss=0, total=6733.25, n_correct=2605.3, ppl=4.92, accuracy=38.693, wps=12848, ups=0.66, wpb=19494.4, bsz=682.6, num_updates=6100, lr=0.000181071, gnorm=6.234, clip=8, loss_scale=0.125, train_wall=102, gb_free=13.7, wall=5658
2023-09-06 18:07:28 | INFO | train_inner | epoch 006:    256 / 1191 loss=2.411, trans_loss=3.992, nll_loss=2.276, w2v_ctc_loss=1.199, task_loss=1.116, task_loss_gen=1.556, contrastive_loss=0, total=6846.74, n_correct=2677.05, ppl=4.84, accuracy=39.1, wps=19361.7, ups=0.98, wpb=19835.6, bsz=722.1, num_updates=6200, lr=0.000179605, gnorm=5.253, clip=3, loss_scale=0.125, train_wall=102, gb_free=13.7, wall=5761
2023-09-06 18:09:11 | INFO | train_inner | epoch 006:    356 / 1191 loss=2.417, trans_loss=3.996, nll_loss=2.28, w2v_ctc_loss=1.201, task_loss=1.196, task_loss_gen=1.72, contrastive_loss=0, total=6703.31, n_correct=2614.73, ppl=4.86, accuracy=39.007, wps=18715.4, ups=0.96, wpb=19415.6, bsz=665.1, num_updates=6300, lr=0.000178174, gnorm=4.751, clip=2, loss_scale=0.125, train_wall=103, gb_free=12.6, wall=5864
2023-09-06 18:10:54 | INFO | train_inner | epoch 006:    456 / 1191 loss=2.408, trans_loss=3.997, nll_loss=2.281, w2v_ctc_loss=1.193, task_loss=1.267, task_loss_gen=1.772, contrastive_loss=0, total=6584.98, n_correct=2577.71, ppl=4.86, accuracy=39.145, wps=18669, ups=0.98, wpb=19079.6, bsz=656.9, num_updates=6400, lr=0.000176777, gnorm=5.711, clip=6, loss_scale=0.125, train_wall=101, gb_free=14, wall=5967
2023-09-06 18:12:37 | INFO | train_inner | epoch 006:    556 / 1191 loss=2.397, trans_loss=3.986, nll_loss=2.27, w2v_ctc_loss=1.183, task_loss=1.311, task_loss_gen=1.807, contrastive_loss=0, total=6697.34, n_correct=2623.63, ppl=4.82, accuracy=39.174, wps=18860.1, ups=0.97, wpb=19416.7, bsz=661.4, num_updates=6500, lr=0.000175412, gnorm=5.223, clip=2, loss_scale=0.125, train_wall=102, gb_free=13.9, wall=6070
2023-09-06 18:14:19 | INFO | train_inner | epoch 006:    656 / 1191 loss=2.385, trans_loss=3.985, nll_loss=2.266, w2v_ctc_loss=1.164, task_loss=1.241, task_loss_gen=1.768, contrastive_loss=0, total=6681.62, n_correct=2632.1, ppl=4.81, accuracy=39.393, wps=18858, ups=0.97, wpb=19351.7, bsz=660.1, num_updates=6600, lr=0.000174078, gnorm=4.509, clip=0, loss_scale=0.125, train_wall=102, gb_free=12, wall=6172
2023-09-06 18:16:02 | INFO | train_inner | epoch 006:    756 / 1191 loss=2.373, trans_loss=3.97, nll_loss=2.247, w2v_ctc_loss=1.159, task_loss=1.143, task_loss_gen=1.573, contrastive_loss=0, total=6838.86, n_correct=2725.03, ppl=4.75, accuracy=39.846, wps=19355.9, ups=0.98, wpb=19812.1, bsz=721.3, num_updates=6700, lr=0.000172774, gnorm=4.539, clip=0, loss_scale=0.125, train_wall=101, gb_free=15.1, wall=6275
2023-09-06 18:17:45 | INFO | train_inner | epoch 006:    856 / 1191 loss=2.385, trans_loss=3.968, nll_loss=2.248, w2v_ctc_loss=1.177, task_loss=1.305, task_loss_gen=1.775, contrastive_loss=0, total=6625.65, n_correct=2629.76, ppl=4.75, accuracy=39.691, wps=18645.2, ups=0.97, wpb=19212.6, bsz=678.1, num_updates=6800, lr=0.000171499, gnorm=4.981, clip=4, loss_scale=0.125, train_wall=102, gb_free=4, wall=6378
2023-09-06 18:19:28 | INFO | train_inner | epoch 006:    956 / 1191 loss=2.378, trans_loss=3.972, nll_loss=2.251, w2v_ctc_loss=1.162, task_loss=1.346, task_loss_gen=1.812, contrastive_loss=0, total=6618.81, n_correct=2624.47, ppl=4.76, accuracy=39.652, wps=18591.2, ups=0.97, wpb=19178.6, bsz=639, num_updates=6900, lr=0.000170251, gnorm=4.078, clip=0, loss_scale=0.125, train_wall=102, gb_free=12.3, wall=6481
2023-09-06 18:21:10 | INFO | train_inner | epoch 006:   1056 / 1191 loss=2.353, trans_loss=3.961, nll_loss=2.236, w2v_ctc_loss=1.133, task_loss=1.192, task_loss_gen=1.652, contrastive_loss=0, total=6688.56, n_correct=2675.51, ppl=4.71, accuracy=40.001, wps=18922.1, ups=0.98, wpb=19379.7, bsz=670.8, num_updates=7000, lr=0.000169031, gnorm=4.552, clip=0, loss_scale=0.125, train_wall=102, gb_free=13.7, wall=6583
2023-09-06 18:22:51 | INFO | train_inner | epoch 006:   1156 / 1191 loss=2.342, trans_loss=3.955, nll_loss=2.23, w2v_ctc_loss=1.122, task_loss=1.115, task_loss_gen=1.554, contrastive_loss=0, total=6741.52, n_correct=2705.11, ppl=4.69, accuracy=40.126, wps=19341.8, ups=0.99, wpb=19542.2, bsz=706.4, num_updates=7100, lr=0.000167836, gnorm=4.353, clip=2, loss_scale=0.125, train_wall=100, gb_free=13.9, wall=6684
2023-09-06 18:23:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 18:24:02 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.951 | trans_loss 6.72 | nll_loss 4.457 | w2v_ctc_loss 1.323 | task_loss 5.656 | task_loss_gen 6.868 | contrastive_loss 0 | total 6138.43 | n_correct 2545.29 | ppl 21.96 | accuracy 41.465 | uer 22.403 | wer 23.935 | raw_wer 23.935 | bleu 0.93 | wps 1584.6 | wpb 6138.4 | bsz 201.1 | num_updates 7135 | best_bleu 0.93
2023-09-06 18:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 7135 updates
2023-09-06 18:24:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 18:24:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 18:24:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 6 @ 7135 updates, score 0.93) (writing took 12.026265538064763 seconds)
2023-09-06 18:24:14 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-09-06 18:24:14 | INFO | train | epoch 006 | loss 2.391 | trans_loss 3.982 | nll_loss 2.263 | w2v_ctc_loss 1.176 | task_loss 1.211 | task_loss_gen 1.7 | contrastive_loss 0 | total 6703.69 | n_correct 2642.91 | ppl 4.8 | accuracy 39.425 | wps 17466.6 | ups 0.9 | wpb 19422.7 | bsz 678.2 | num_updates 7135 | lr 0.000167424 | gnorm 4.943 | clip 2.5 | loss_scale 0.125 | train_wall 1211 | gb_free 13.3 | wall 6767
2023-09-06 18:24:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 18:24:14 | INFO | fairseq.trainer | begin training epoch 7
2023-09-06 18:24:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 18:25:28 | INFO | train_inner | epoch 007:     65 / 1191 loss=2.323, trans_loss=3.947, nll_loss=2.216, w2v_ctc_loss=1.098, task_loss=1.15, task_loss_gen=1.608, contrastive_loss=0, total=6733.62, n_correct=2720.91, ppl=4.65, accuracy=40.408, wps=12446.4, ups=0.64, wpb=19492.4, bsz=690.7, num_updates=7200, lr=0.000166667, gnorm=3.936, clip=0, loss_scale=0.125, train_wall=101, gb_free=14.3, wall=6841
2023-09-06 18:27:11 | INFO | train_inner | epoch 007:    165 / 1191 loss=2.305, trans_loss=3.934, nll_loss=2.204, w2v_ctc_loss=1.081, task_loss=1.3, task_loss_gen=1.691, contrastive_loss=0, total=6665.28, n_correct=2700.84, ppl=4.61, accuracy=40.521, wps=18793.8, ups=0.97, wpb=19331, bsz=675.2, num_updates=7300, lr=0.000165521, gnorm=4.299, clip=0, loss_scale=0.125, train_wall=102, gb_free=14.2, wall=6944
2023-09-06 18:28:53 | INFO | train_inner | epoch 007:    265 / 1191 loss=2.31, trans_loss=3.933, nll_loss=2.2, w2v_ctc_loss=1.085, task_loss=1.146, task_loss_gen=1.644, contrastive_loss=0, total=6692.59, n_correct=2719.53, ppl=4.6, accuracy=40.635, wps=18934.5, ups=0.98, wpb=19394.9, bsz=673.2, num_updates=7400, lr=0.000164399, gnorm=3.762, clip=0, loss_scale=0.125, train_wall=102, gb_free=13.5, wall=7046
2023-09-06 18:30:34 | INFO | train_inner | epoch 007:    365 / 1191 loss=2.286, trans_loss=3.922, nll_loss=2.187, w2v_ctc_loss=1.061, task_loss=1.121, task_loss_gen=1.589, contrastive_loss=0, total=6734.17, n_correct=2759.59, ppl=4.56, accuracy=40.979, wps=19353.2, ups=0.99, wpb=19516.4, bsz=689.9, num_updates=7500, lr=0.000163299, gnorm=3.596, clip=0, loss_scale=0.125, train_wall=100, gb_free=13.4, wall=7147
2023-09-06 18:32:16 | INFO | train_inner | epoch 007:    465 / 1191 loss=2.291, trans_loss=3.925, nll_loss=2.191, w2v_ctc_loss=1.07, task_loss=1.047, task_loss_gen=1.55, contrastive_loss=0, total=6768.82, n_correct=2772.63, ppl=4.57, accuracy=40.962, wps=19294.3, ups=0.98, wpb=19613.7, bsz=705.2, num_updates=7600, lr=0.000162221, gnorm=1.826, clip=0, loss_scale=0.25, train_wall=101, gb_free=12.2, wall=7249
2023-09-06 18:33:58 | INFO | train_inner | epoch 007:    565 / 1191 loss=2.294, trans_loss=3.924, nll_loss=2.189, w2v_ctc_loss=1.071, task_loss=1.175, task_loss_gen=1.679, contrastive_loss=0, total=6721.82, n_correct=2755.25, ppl=4.56, accuracy=40.99, wps=18949.4, ups=0.97, wpb=19472.2, bsz=676.5, num_updates=7700, lr=0.000161165, gnorm=1.893, clip=0, loss_scale=0.25, train_wall=102, gb_free=13.5, wall=7351
2023-09-06 18:35:42 | INFO | train_inner | epoch 007:    665 / 1191 loss=2.278, trans_loss=3.92, nll_loss=2.184, w2v_ctc_loss=1.054, task_loss=1.074, task_loss_gen=1.606, contrastive_loss=0, total=6764.61, n_correct=2782.51, ppl=4.54, accuracy=41.133, wps=18971.7, ups=0.97, wpb=19596.2, bsz=698.1, num_updates=7800, lr=0.000160128, gnorm=1.658, clip=0, loss_scale=0.25, train_wall=102, gb_free=13.1, wall=7455
2023-09-06 18:37:24 | INFO | train_inner | epoch 007:    765 / 1191 loss=2.281, trans_loss=3.919, nll_loss=2.18, w2v_ctc_loss=1.056, task_loss=1.202, task_loss_gen=1.698, contrastive_loss=0, total=6662.5, n_correct=2741.9, ppl=4.53, accuracy=41.154, wps=18821.3, ups=0.98, wpb=19294.5, bsz=662.9, num_updates=7900, lr=0.000159111, gnorm=1.82, clip=0, loss_scale=0.25, train_wall=102, gb_free=13.8, wall=7557
2023-09-06 18:39:07 | INFO | train_inner | epoch 007:    865 / 1191 loss=2.281, trans_loss=3.917, nll_loss=2.18, w2v_ctc_loss=1.056, task_loss=1.261, task_loss_gen=1.759, contrastive_loss=0, total=6638.23, n_correct=2726.48, ppl=4.53, accuracy=41.072, wps=18663.3, ups=0.97, wpb=19232, bsz=652.4, num_updates=8000, lr=0.000158114, gnorm=2.05, clip=0, loss_scale=0.25, train_wall=102, gb_free=12.3, wall=7660
2023-09-06 18:39:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 18:39:44 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.88 | trans_loss 6.644 | nll_loss 4.36 | w2v_ctc_loss 1.255 | task_loss 6.442 | task_loss_gen 6.898 | contrastive_loss 0 | total 6138.43 | n_correct 2598.71 | ppl 20.54 | accuracy 42.335 | uer 20.761 | wer 22.35 | raw_wer 22.35 | bleu 1.17 | wps 1462.9 | wpb 6138.4 | bsz 201.1 | num_updates 8000 | best_bleu 1.17
2023-09-06 18:39:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8000 updates
2023-09-06 18:39:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_7_8000.pt
2023-09-06 18:39:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_7_8000.pt
2023-09-06 18:39:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_7_8000.pt (epoch 7 @ 8000 updates, score 1.17) (writing took 12.771510616061278 seconds)
2023-09-06 18:41:39 | INFO | train_inner | epoch 007:    965 / 1191 loss=2.274, trans_loss=3.912, nll_loss=2.173, w2v_ctc_loss=1.048, task_loss=1.181, task_loss_gen=1.74, contrastive_loss=0, total=6662.44, n_correct=2743.49, ppl=4.51, accuracy=41.178, wps=12688.8, ups=0.66, wpb=19297.8, bsz=651.1, num_updates=8100, lr=0.000157135, gnorm=1.844, clip=0, loss_scale=0.25, train_wall=102, gb_free=14.5, wall=7812
2023-09-06 18:43:22 | INFO | train_inner | epoch 007:   1065 / 1191 loss=2.265, trans_loss=3.903, nll_loss=2.16, w2v_ctc_loss=1.049, task_loss=1.239, task_loss_gen=1.609, contrastive_loss=0, total=6680.36, n_correct=2786.63, ppl=4.47, accuracy=41.714, wps=18929.3, ups=0.98, wpb=19342.7, bsz=695.6, num_updates=8200, lr=0.000156174, gnorm=2.035, clip=0, loss_scale=0.25, train_wall=101, gb_free=10.9, wall=7915
2023-09-06 18:45:04 | INFO | train_inner | epoch 007:   1165 / 1191 loss=2.264, trans_loss=3.904, nll_loss=2.164, w2v_ctc_loss=1.045, task_loss=1.252, task_loss_gen=1.674, contrastive_loss=0, total=6716.49, n_correct=2781.59, ppl=4.48, accuracy=41.414, wps=19076.3, ups=0.98, wpb=19469.2, bsz=674, num_updates=8300, lr=0.00015523, gnorm=1.552, clip=0, loss_scale=0.25, train_wall=101, gb_free=13.2, wall=8017
2023-09-06 18:45:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 18:46:05 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.858 | trans_loss 6.625 | nll_loss 4.338 | w2v_ctc_loss 1.225 | task_loss 6.602 | task_loss_gen 6.854 | contrastive_loss 0 | total 6138.43 | n_correct 2619.43 | ppl 20.22 | accuracy 42.673 | uer 19.993 | wer 21.558 | raw_wer 21.558 | bleu 1.23 | wps 1569.2 | wpb 6138.4 | bsz 201.1 | num_updates 8326 | best_bleu 1.23
2023-09-06 18:46:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8326 updates
2023-09-06 18:46:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 18:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 18:46:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 7 @ 8326 updates, score 1.23) (writing took 12.38986266090069 seconds)
2023-09-06 18:46:18 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-09-06 18:46:18 | INFO | train | epoch 007 | loss 2.286 | trans_loss 3.92 | nll_loss 2.184 | w2v_ctc_loss 1.062 | task_loss 1.178 | task_loss_gen 1.653 | contrastive_loss 0 | total 6703.69 | n_correct 2751.59 | ppl 4.54 | accuracy 41.046 | wps 17473.8 | ups 0.9 | wpb 19422.7 | bsz 678.2 | num_updates 8326 | lr 0.000154988 | gnorm 2.442 | clip 0 | loss_scale 0.25 | train_wall 1209 | gb_free 12.7 | wall 8091
2023-09-06 18:46:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 18:46:18 | INFO | fairseq.trainer | begin training epoch 8
2023-09-06 18:46:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 18:47:41 | INFO | train_inner | epoch 008:     74 / 1191 loss=2.234, trans_loss=3.892, nll_loss=2.147, w2v_ctc_loss=1, task_loss=1.22, task_loss_gen=1.601, contrastive_loss=0, total=6735.91, n_correct=2812.13, ppl=4.43, accuracy=41.748, wps=12401.5, ups=0.64, wpb=19506.1, bsz=674.3, num_updates=8400, lr=0.000154303, gnorm=1.611, clip=0, loss_scale=0.25, train_wall=101, gb_free=12.7, wall=8174
2023-09-06 18:49:24 | INFO | train_inner | epoch 008:    174 / 1191 loss=2.222, trans_loss=3.875, nll_loss=2.128, w2v_ctc_loss=1.001, task_loss=1.127, task_loss_gen=1.597, contrastive_loss=0, total=6733.69, n_correct=2840.05, ppl=4.37, accuracy=42.177, wps=18934.2, ups=0.97, wpb=19530.2, bsz=709.9, num_updates=8500, lr=0.000153393, gnorm=1.73, clip=0, loss_scale=0.25, train_wall=102, gb_free=10.2, wall=8277
2023-09-06 18:51:08 | INFO | train_inner | epoch 008:    274 / 1191 loss=2.223, trans_loss=3.884, nll_loss=2.136, w2v_ctc_loss=0.996, task_loss=1.212, task_loss_gen=1.617, contrastive_loss=0, total=6723.6, n_correct=2832.15, ppl=4.4, accuracy=42.123, wps=18792.1, ups=0.96, wpb=19475.4, bsz=686.2, num_updates=8600, lr=0.000152499, gnorm=1.307, clip=0, loss_scale=0.25, train_wall=103, gb_free=12.7, wall=8381
2023-09-06 18:52:52 | INFO | train_inner | epoch 008:    374 / 1191 loss=2.234, trans_loss=3.887, nll_loss=2.143, w2v_ctc_loss=1.009, task_loss=1.348, task_loss_gen=1.715, contrastive_loss=0, total=6677.46, n_correct=2790.71, ppl=4.42, accuracy=41.793, wps=18631.1, ups=0.96, wpb=19360.7, bsz=652.5, num_updates=8700, lr=0.00015162, gnorm=1.422, clip=0, loss_scale=0.25, train_wall=103, gb_free=15.1, wall=8485
2023-09-06 18:54:34 | INFO | train_inner | epoch 008:    474 / 1191 loss=2.223, trans_loss=3.88, nll_loss=2.133, w2v_ctc_loss=0.996, task_loss=1.282, task_loss_gen=1.701, contrastive_loss=0, total=6656.87, n_correct=2799.67, ppl=4.39, accuracy=42.057, wps=18818.2, ups=0.98, wpb=19291.7, bsz=657.8, num_updates=8800, lr=0.000150756, gnorm=1.793, clip=0, loss_scale=0.25, train_wall=102, gb_free=14.7, wall=8587
2023-09-06 18:56:16 | INFO | train_inner | epoch 008:    574 / 1191 loss=2.213, trans_loss=3.88, nll_loss=2.133, w2v_ctc_loss=0.985, task_loss=1.465, task_loss_gen=1.761, contrastive_loss=0, total=6672.48, n_correct=2812.34, ppl=4.39, accuracy=42.148, wps=18984.9, ups=0.98, wpb=19333.2, bsz=669.1, num_updates=8900, lr=0.000149906, gnorm=1.827, clip=0, loss_scale=0.25, train_wall=101, gb_free=12.1, wall=8689
2023-09-06 18:57:57 | INFO | train_inner | epoch 008:    674 / 1191 loss=2.212, trans_loss=3.876, nll_loss=2.127, w2v_ctc_loss=0.988, task_loss=1.261, task_loss_gen=1.572, contrastive_loss=0, total=6736.04, n_correct=2855.12, ppl=4.37, accuracy=42.386, wps=19354.8, ups=0.99, wpb=19514.2, bsz=680.3, num_updates=9000, lr=0.000149071, gnorm=1.118, clip=0, loss_scale=0.25, train_wall=100, gb_free=14.1, wall=8790
2023-09-06 18:59:40 | INFO | train_inner | epoch 008:    774 / 1191 loss=2.213, trans_loss=3.871, nll_loss=2.121, w2v_ctc_loss=0.993, task_loss=1.299, task_loss_gen=1.616, contrastive_loss=0, total=6683.09, n_correct=2827.99, ppl=4.35, accuracy=42.316, wps=18836.7, ups=0.97, wpb=19367.8, bsz=669.7, num_updates=9100, lr=0.00014825, gnorm=1.068, clip=0, loss_scale=0.25, train_wall=102, gb_free=11.7, wall=8893
2023-09-06 19:01:21 | INFO | train_inner | epoch 008:    874 / 1191 loss=2.206, trans_loss=3.864, nll_loss=2.112, w2v_ctc_loss=0.989, task_loss=1.151, task_loss_gen=1.481, contrastive_loss=0, total=6805.29, n_correct=2902.42, ppl=4.32, accuracy=42.649, wps=19401.5, ups=0.98, wpb=19720.2, bsz=708.8, num_updates=9200, lr=0.000147442, gnorm=1.272, clip=0, loss_scale=0.25, train_wall=101, gb_free=14.8, wall=8994
2023-09-06 19:03:03 | INFO | train_inner | epoch 008:    974 / 1191 loss=2.213, trans_loss=3.875, nll_loss=2.124, w2v_ctc_loss=0.988, task_loss=1.363, task_loss_gen=1.695, contrastive_loss=0, total=6628.6, n_correct=2806.93, ppl=4.36, accuracy=42.346, wps=18805.8, ups=0.98, wpb=19194.8, bsz=656.4, num_updates=9300, lr=0.000146647, gnorm=1.466, clip=0, loss_scale=0.25, train_wall=101, gb_free=10.4, wall=9096
2023-09-06 19:04:45 | INFO | train_inner | epoch 008:   1074 / 1191 loss=2.205, trans_loss=3.868, nll_loss=2.113, w2v_ctc_loss=0.98, task_loss=1.262, task_loss_gen=1.607, contrastive_loss=0, total=6728.92, n_correct=2867.03, ppl=4.33, accuracy=42.608, wps=19119.5, ups=0.98, wpb=19468.3, bsz=671.2, num_updates=9400, lr=0.000145865, gnorm=0.945, clip=0, loss_scale=0.25, train_wall=101, gb_free=9.8, wall=9198
2023-09-06 19:06:27 | INFO | train_inner | epoch 008:   1174 / 1191 loss=2.188, trans_loss=3.852, nll_loss=2.097, w2v_ctc_loss=0.971, task_loss=1.202, task_loss_gen=1.523, contrastive_loss=0, total=6690.49, n_correct=2878.05, ppl=4.28, accuracy=43.017, wps=19126.8, ups=0.99, wpb=19390.4, bsz=710.2, num_updates=9500, lr=0.000145095, gnorm=1.012, clip=0, loss_scale=0.25, train_wall=100, gb_free=10, wall=9300
2023-09-06 19:06:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 19:07:19 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.804 | trans_loss 6.551 | nll_loss 4.236 | w2v_ctc_loss 1.214 | task_loss 5.221 | task_loss_gen 6.896 | contrastive_loss 0 | total 6138.43 | n_correct 2670.86 | ppl 18.85 | accuracy 43.51 | uer 19.164 | wer 20.602 | raw_wer 20.602 | bleu 1.7 | wps 1562 | wpb 6138.4 | bsz 201.1 | num_updates 9517 | best_bleu 1.7
2023-09-06 19:07:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 9517 updates
2023-09-06 19:07:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 19:07:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 19:07:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 8 @ 9517 updates, score 1.7) (writing took 13.223033424001187 seconds)
2023-09-06 19:07:32 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-09-06 19:07:32 | INFO | train | epoch 008 | loss 2.214 | trans_loss 3.875 | nll_loss 2.125 | w2v_ctc_loss 0.99 | task_loss 1.268 | task_loss_gen 1.624 | contrastive_loss 0 | total 6703.69 | n_correct 2835.32 | ppl 4.36 | accuracy 42.295 | wps 18147.9 | ups 0.93 | wpb 19422.7 | bsz 678.2 | num_updates 9517 | lr 0.000144966 | gnorm 1.379 | clip 0 | loss_scale 0.25 | train_wall 1208 | gb_free 13.9 | wall 9365
2023-09-06 19:07:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 19:07:32 | INFO | fairseq.trainer | begin training epoch 9
2023-09-06 19:07:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 19:09:04 | INFO | train_inner | epoch 009:     83 / 1191 loss=2.169, trans_loss=3.849, nll_loss=2.091, w2v_ctc_loss=0.939, task_loss=1.251, task_loss_gen=1.575, contrastive_loss=0, total=6705.51, n_correct=2883.5, ppl=4.26, accuracy=43.002, wps=12327.5, ups=0.63, wpb=19426.4, bsz=684.9, num_updates=9600, lr=0.000144338, gnorm=1.223, clip=0, loss_scale=0.5, train_wall=100, gb_free=13.2, wall=9457
2023-09-06 19:10:47 | INFO | train_inner | epoch 009:    183 / 1191 loss=2.159, trans_loss=3.838, nll_loss=2.079, w2v_ctc_loss=0.932, task_loss=1.313, task_loss_gen=1.616, contrastive_loss=0, total=6741.3, n_correct=2909.09, ppl=4.23, accuracy=43.153, wps=19036.1, ups=0.97, wpb=19540.6, bsz=683, num_updates=9700, lr=0.000143592, gnorm=0.777, clip=0, loss_scale=0.5, train_wall=102, gb_free=14.4, wall=9560
2023-09-06 19:12:28 | INFO | train_inner | epoch 009:    283 / 1191 loss=2.173, trans_loss=3.845, nll_loss=2.084, w2v_ctc_loss=0.954, task_loss=1.188, task_loss_gen=1.532, contrastive_loss=0, total=6823.55, n_correct=2952, ppl=4.24, accuracy=43.262, wps=19481.7, ups=0.99, wpb=19753, bsz=709.1, num_updates=9800, lr=0.000142857, gnorm=0.65, clip=0, loss_scale=0.5, train_wall=101, gb_free=13.5, wall=9661
2023-09-06 19:14:12 | INFO | train_inner | epoch 009:    383 / 1191 loss=2.164, trans_loss=3.841, nll_loss=2.081, w2v_ctc_loss=0.94, task_loss=1.304, task_loss_gen=1.61, contrastive_loss=0, total=6742.7, n_correct=2914.48, ppl=4.23, accuracy=43.224, wps=18733.9, ups=0.96, wpb=19536.6, bsz=687.8, num_updates=9900, lr=0.000142134, gnorm=0.762, clip=0, loss_scale=0.5, train_wall=104, gb_free=14.2, wall=9765
2023-09-06 19:15:56 | INFO | train_inner | epoch 009:    483 / 1191 loss=2.172, trans_loss=3.839, nll_loss=2.08, w2v_ctc_loss=0.951, task_loss=1.193, task_loss_gen=1.572, contrastive_loss=0, total=6747.22, n_correct=2924.98, ppl=4.23, accuracy=43.351, wps=18930, ups=0.97, wpb=19557, bsz=699.1, num_updates=10000, lr=0.000141421, gnorm=0.502, clip=0, loss_scale=0.5, train_wall=103, gb_free=13.3, wall=9869
2023-09-06 19:15:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 19:16:30 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.777 | trans_loss 6.52 | nll_loss 4.202 | w2v_ctc_loss 1.192 | task_loss 4.028 | task_loss_gen 7.431 | contrastive_loss 0 | total 6138.43 | n_correct 2700.43 | ppl 18.4 | accuracy 43.992 | uer 18.471 | wer 20.071 | raw_wer 20.071 | bleu 1.89 | wps 1633.3 | wpb 6138.4 | bsz 201.1 | num_updates 10000 | best_bleu 1.89
2023-09-06 19:16:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10000 updates
2023-09-06 19:16:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_9_10000.pt
2023-09-06 19:16:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_9_10000.pt
2023-09-06 19:16:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_9_10000.pt (epoch 9 @ 10000 updates, score 1.89) (writing took 12.721345958998427 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:0')
2023-09-06 19:18:25 | INFO | train_inner | epoch 009:    583 / 1191 loss=2.16, trans_loss=3.838, nll_loss=2.077, w2v_ctc_loss=0.933, task_loss=1.278, task_loss_gen=1.689, contrastive_loss=0, total=6606.54, n_correct=2861.73, ppl=4.22, accuracy=43.317, wps=12847.6, ups=0.67, wpb=19137, bsz=659.1, num_updates=10100, lr=0.00014072, gnorm=0.522, clip=0, loss_scale=0.5, train_wall=100, gb_free=11.8, wall=10018
2023-09-06 19:20:07 | INFO | train_inner | epoch 009:    683 / 1191 loss=2.173, trans_loss=3.852, nll_loss=2.094, w2v_ctc_loss=0.942, task_loss=1.412, task_loss_gen=1.778, contrastive_loss=0, total=6562.83, n_correct=2818.18, ppl=4.27, accuracy=42.942, wps=18626, ups=0.98, wpb=19007.9, bsz=624.6, num_updates=10200, lr=0.000140028, gnorm=0.716, clip=0, loss_scale=0.5, train_wall=101, gb_free=13.4, wall=10120
2023-09-06 19:21:48 | INFO | train_inner | epoch 009:    783 / 1191 loss=2.16, trans_loss=3.834, nll_loss=2.073, w2v_ctc_loss=0.94, task_loss=1.267, task_loss_gen=1.574, contrastive_loss=0, total=6697.32, n_correct=2917.44, ppl=4.21, accuracy=43.561, wps=19091.7, ups=0.98, wpb=19411.8, bsz=686.2, num_updates=10300, lr=0.000139347, gnorm=0.635, clip=0, loss_scale=0.5, train_wall=101, gb_free=14.1, wall=10221
2023-09-06 19:23:31 | INFO | train_inner | epoch 009:    883 / 1191 loss=2.16, trans_loss=3.838, nll_loss=2.077, w2v_ctc_loss=0.939, task_loss=1.262, task_loss_gen=1.629, contrastive_loss=0, total=6733.87, n_correct=2921.8, ppl=4.22, accuracy=43.39, wps=19090.8, ups=0.98, wpb=19511.2, bsz=672, num_updates=10400, lr=0.000138675, gnorm=0.611, clip=0, loss_scale=0.5, train_wall=101, gb_free=11.1, wall=10324
2023-09-06 19:25:13 | INFO | train_inner | epoch 009:    983 / 1191 loss=2.154, trans_loss=3.832, nll_loss=2.069, w2v_ctc_loss=0.934, task_loss=1.249, task_loss_gen=1.6, contrastive_loss=0, total=6691.27, n_correct=2913.88, ppl=4.2, accuracy=43.547, wps=18886.8, ups=0.97, wpb=19384, bsz=674.7, num_updates=10500, lr=0.000138013, gnorm=0.673, clip=0, loss_scale=0.5, train_wall=102, gb_free=14.8, wall=10426
2023-09-06 19:26:55 | INFO | train_inner | epoch 009:   1083 / 1191 loss=2.152, trans_loss=3.829, nll_loss=2.066, w2v_ctc_loss=0.933, task_loss=1.268, task_loss_gen=1.558, contrastive_loss=0, total=6676.46, n_correct=2916.05, ppl=4.19, accuracy=43.677, wps=19028.3, ups=0.98, wpb=19349, bsz=680.7, num_updates=10600, lr=0.000137361, gnorm=0.686, clip=0, loss_scale=0.5, train_wall=101, gb_free=13.6, wall=10528
2023-09-06 19:28:38 | INFO | train_inner | epoch 009:   1183 / 1191 loss=2.167, trans_loss=3.832, nll_loss=2.07, w2v_ctc_loss=0.952, task_loss=1.365, task_loss_gen=1.707, contrastive_loss=0, total=6682.16, n_correct=2906.17, ppl=4.2, accuracy=43.491, wps=18858.8, ups=0.97, wpb=19364.2, bsz=657.2, num_updates=10700, lr=0.000136717, gnorm=0.879, clip=0, loss_scale=0.5, train_wall=102, gb_free=14.2, wall=10631
2023-09-06 19:28:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:4')
2023-09-06 19:29:21 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.752 | trans_loss 6.485 | nll_loss 4.148 | w2v_ctc_loss 1.19 | task_loss 8.113 | task_loss_gen 6.864 | contrastive_loss 0 | total 6138.43 | n_correct 2731.86 | ppl 17.73 | accuracy 44.504 | uer 18.517 | wer 19.97 | raw_wer 19.97 | bleu 2.12 | wps 1586.7 | wpb 6138.4 | bsz 201.1 | num_updates 10708 | best_bleu 2.12
2023-09-06 19:29:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10708 updates
2023-09-06 19:29:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 19:29:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 19:29:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 9 @ 10708 updates, score 2.12) (writing took 12.530471846926957 seconds)
2023-09-06 19:29:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-09-06 19:29:34 | INFO | train | epoch 009 | loss 2.163 | trans_loss 3.838 | nll_loss 2.077 | w2v_ctc_loss 0.94 | task_loss 1.275 | task_loss_gen 1.615 | contrastive_loss 0 | total 6703.69 | n_correct 2906.41 | ppl 4.22 | accuracy 43.355 | wps 17503.7 | ups 0.9 | wpb 19422.7 | bsz 678.2 | num_updates 10708 | lr 0.000136666 | gnorm 0.714 | clip 0 | loss_scale 0.5 | train_wall 1208 | gb_free 14.2 | wall 10687
2023-09-06 19:29:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 19:29:34 | INFO | fairseq.trainer | begin training epoch 10
2023-09-06 19:29:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 19:31:15 | INFO | train_inner | epoch 010:     92 / 1191 loss=2.119, trans_loss=3.81, nll_loss=2.041, w2v_ctc_loss=0.893, task_loss=1.338, task_loss_gen=1.647, contrastive_loss=0, total=6648.84, n_correct=2935.34, ppl=4.12, accuracy=44.148, wps=12236.3, ups=0.64, wpb=19263.8, bsz=669.9, num_updates=10800, lr=0.000136083, gnorm=0.726, clip=0, loss_scale=0.5, train_wall=100, gb_free=10.7, wall=10788
2023-09-06 19:32:56 | INFO | train_inner | epoch 010:    192 / 1191 loss=2.124, trans_loss=3.814, nll_loss=2.047, w2v_ctc_loss=0.903, task_loss=1.279, task_loss_gen=1.599, contrastive_loss=0, total=6679.63, n_correct=2948.75, ppl=4.13, accuracy=44.145, wps=19099.1, ups=0.99, wpb=19355.1, bsz=686.2, num_updates=10900, lr=0.000135457, gnorm=0.683, clip=0, loss_scale=0.5, train_wall=100, gb_free=14, wall=10889
2023-09-06 19:34:39 | INFO | train_inner | epoch 010:    292 / 1191 loss=2.121, trans_loss=3.809, nll_loss=2.038, w2v_ctc_loss=0.899, task_loss=1.308, task_loss_gen=1.581, contrastive_loss=0, total=6778.08, n_correct=2997.65, ppl=4.11, accuracy=44.226, wps=19134.1, ups=0.97, wpb=19629.6, bsz=690.4, num_updates=11000, lr=0.00013484, gnorm=0.853, clip=0, loss_scale=0.5, train_wall=102, gb_free=13.9, wall=10992
2023-09-06 19:36:22 | INFO | train_inner | epoch 010:    392 / 1191 loss=2.122, trans_loss=3.806, nll_loss=2.036, w2v_ctc_loss=0.907, task_loss=1.204, task_loss_gen=1.51, contrastive_loss=0, total=6812.8, n_correct=3022.26, ppl=4.1, accuracy=44.361, wps=19130.3, ups=0.97, wpb=19739.4, bsz=722.2, num_updates=11100, lr=0.000134231, gnorm=0.628, clip=0, loss_scale=0.5, train_wall=102, gb_free=11, wall=11095
2023-09-06 19:38:05 | INFO | train_inner | epoch 010:    492 / 1191 loss=2.134, trans_loss=3.808, nll_loss=2.037, w2v_ctc_loss=0.916, task_loss=1.327, task_loss_gen=1.658, contrastive_loss=0, total=6717.35, n_correct=2967.99, ppl=4.1, accuracy=44.184, wps=19015.6, ups=0.98, wpb=19450.9, bsz=667.4, num_updates=11200, lr=0.000133631, gnorm=0.802, clip=0, loss_scale=0.5, train_wall=102, gb_free=8.5, wall=11198
2023-09-06 19:39:46 | INFO | train_inner | epoch 010:    592 / 1191 loss=2.12, trans_loss=3.809, nll_loss=2.04, w2v_ctc_loss=0.899, task_loss=1.289, task_loss_gen=1.613, contrastive_loss=0, total=6734.42, n_correct=2983.01, ppl=4.11, accuracy=44.295, wps=19215.4, ups=0.98, wpb=19509.4, bsz=679.8, num_updates=11300, lr=0.000133038, gnorm=0.734, clip=0, loss_scale=0.5, train_wall=101, gb_free=14.1, wall=11299
2023-09-06 19:41:29 | INFO | train_inner | epoch 010:    692 / 1191 loss=2.124, trans_loss=3.807, nll_loss=2.036, w2v_ctc_loss=0.908, task_loss=1.255, task_loss_gen=1.594, contrastive_loss=0, total=6756.76, n_correct=3001.62, ppl=4.1, accuracy=44.424, wps=19104.3, ups=0.98, wpb=19575.2, bsz=695, num_updates=11400, lr=0.000132453, gnorm=0.807, clip=0, loss_scale=0.5, train_wall=101, gb_free=13.6, wall=11402
2023-09-06 19:43:11 | INFO | train_inner | epoch 010:    792 / 1191 loss=2.125, trans_loss=3.809, nll_loss=2.041, w2v_ctc_loss=0.906, task_loss=1.409, task_loss_gen=1.737, contrastive_loss=0, total=6626.19, n_correct=2922.09, ppl=4.12, accuracy=44.099, wps=18776.5, ups=0.98, wpb=19205.3, bsz=648.9, num_updates=11500, lr=0.000131876, gnorm=0.911, clip=0, loss_scale=0.5, train_wall=101, gb_free=15.1, wall=11504
2023-09-06 19:44:54 | INFO | train_inner | epoch 010:    892 / 1191 loss=2.131, trans_loss=3.806, nll_loss=2.036, w2v_ctc_loss=0.916, task_loss=1.385, task_loss_gen=1.749, contrastive_loss=0, total=6560.1, n_correct=2901.61, ppl=4.1, accuracy=44.231, wps=18378.7, ups=0.97, wpb=19013.5, bsz=641, num_updates=11600, lr=0.000131306, gnorm=0.686, clip=0, loss_scale=1, train_wall=103, gb_free=14.1, wall=11607
2023-09-06 19:46:36 | INFO | train_inner | epoch 010:    992 / 1191 loss=2.118, trans_loss=3.798, nll_loss=2.025, w2v_ctc_loss=0.903, task_loss=1.177, task_loss_gen=1.559, contrastive_loss=0, total=6729.63, n_correct=2999.08, ppl=4.07, accuracy=44.565, wps=19098.9, ups=0.98, wpb=19495.9, bsz=682.6, num_updates=11700, lr=0.000130744, gnorm=0.412, clip=0, loss_scale=1, train_wall=101, gb_free=12, wall=11709
2023-09-06 19:48:19 | INFO | train_inner | epoch 010:   1092 / 1191 loss=2.125, trans_loss=3.796, nll_loss=2.025, w2v_ctc_loss=0.915, task_loss=1.283, task_loss_gen=1.629, contrastive_loss=0, total=6694.81, n_correct=2980.38, ppl=4.07, accuracy=44.518, wps=18898, ups=0.97, wpb=19409, bsz=674.2, num_updates=11800, lr=0.000130189, gnorm=0.437, clip=0, loss_scale=1, train_wall=102, gb_free=6.4, wall=11812
2023-09-06 19:50:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 19:50:35 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.712 | trans_loss 6.439 | nll_loss 4.078 | w2v_ctc_loss 1.161 | task_loss 7.151 | task_loss_gen 6.827 | contrastive_loss 0 | total 6138.43 | n_correct 2764.29 | ppl 16.89 | accuracy 45.032 | uer 17.68 | wer 19.375 | raw_wer 19.375 | bleu 2.35 | wps 1584.1 | wpb 6138.4 | bsz 201.1 | num_updates 11899 | best_bleu 2.35
2023-09-06 19:50:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11899 updates
2023-09-06 19:50:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 19:50:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 19:50:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 10 @ 11899 updates, score 2.35) (writing took 13.435536599019542 seconds)
2023-09-06 19:50:48 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-09-06 19:50:48 | INFO | train | epoch 010 | loss 2.123 | trans_loss 3.806 | nll_loss 2.036 | w2v_ctc_loss 0.905 | task_loss 1.285 | task_loss_gen 1.623 | contrastive_loss 0 | total 6703.69 | n_correct 2970.5 | ppl 4.1 | accuracy 44.311 | wps 18150.6 | ups 0.93 | wpb 19422.7 | bsz 678.2 | num_updates 11899 | lr 0.000129646 | gnorm 0.67 | clip 0 | loss_scale 1 | train_wall 1207 | gb_free 11.9 | wall 11961
2023-09-06 19:50:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 19:50:49 | INFO | fairseq.trainer | begin training epoch 11
2023-09-06 19:50:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 19:50:57 | INFO | train_inner | epoch 011:      1 / 1191 loss=2.114, trans_loss=3.798, nll_loss=2.025, w2v_ctc_loss=0.901, task_loss=1.192, task_loss_gen=1.618, contrastive_loss=0, total=6695.18, n_correct=2981.07, ppl=4.07, accuracy=44.526, wps=12273.5, ups=0.63, wpb=19394.5, bsz=683.9, num_updates=11900, lr=0.000129641, gnorm=0.383, clip=0, loss_scale=1, train_wall=101, gb_free=14.9, wall=11970
2023-09-06 19:52:39 | INFO | train_inner | epoch 011:    101 / 1191 loss=2.101, trans_loss=3.788, nll_loss=2.013, w2v_ctc_loss=0.882, task_loss=1.288, task_loss_gen=1.763, contrastive_loss=0, total=6663.56, n_correct=2973.48, ppl=4.04, accuracy=44.623, wps=18882.2, ups=0.98, wpb=19314.1, bsz=655.9, num_updates=12000, lr=0.000129099, gnorm=0.421, clip=0, loss_scale=1, train_wall=101, gb_free=13.7, wall=12072
2023-09-06 19:52:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 19:53:15 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.719 | trans_loss 6.434 | nll_loss 4.074 | w2v_ctc_loss 1.194 | task_loss 5.362 | task_loss_gen 7.019 | contrastive_loss 0 | total 6138.43 | n_correct 2769.43 | ppl 16.84 | accuracy 45.116 | uer 17.971 | wer 19.818 | raw_wer 19.818 | bleu 2.46 | wps 1532.9 | wpb 6138.4 | bsz 201.1 | num_updates 12000 | best_bleu 2.46
2023-09-06 19:53:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12000 updates
2023-09-06 19:53:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_11_12000.pt
2023-09-06 19:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_11_12000.pt
2023-09-06 19:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_11_12000.pt (epoch 11 @ 12000 updates, score 2.46) (writing took 12.260648184921592 seconds)
2023-09-06 19:55:09 | INFO | train_inner | epoch 011:    201 / 1191 loss=2.083, trans_loss=3.784, nll_loss=2.005, w2v_ctc_loss=0.864, task_loss=1.273, task_loss_gen=1.604, contrastive_loss=0, total=6715.32, n_correct=3029.9, ppl=4.01, accuracy=45.119, wps=13020.1, ups=0.67, wpb=19447.9, bsz=691.5, num_updates=12100, lr=0.000128565, gnorm=0.479, clip=0, loss_scale=1, train_wall=100, gb_free=13.7, wall=12222
2023-09-06 19:56:51 | INFO | train_inner | epoch 011:    301 / 1191 loss=2.089, trans_loss=3.782, nll_loss=2.004, w2v_ctc_loss=0.871, task_loss=1.255, task_loss_gen=1.644, contrastive_loss=0, total=6611.24, n_correct=2968.05, ppl=4.01, accuracy=44.894, wps=18709.7, ups=0.98, wpb=19154.1, bsz=669.7, num_updates=12200, lr=0.000128037, gnorm=0.439, clip=0, loss_scale=1, train_wall=102, gb_free=13.2, wall=12324
2023-09-06 19:58:33 | INFO | train_inner | epoch 011:    401 / 1191 loss=2.093, trans_loss=3.781, nll_loss=2.005, w2v_ctc_loss=0.876, task_loss=1.343, task_loss_gen=1.743, contrastive_loss=0, total=6570.15, n_correct=2950.53, ppl=4.01, accuracy=44.908, wps=18660, ups=0.98, wpb=19044.1, bsz=652.3, num_updates=12300, lr=0.000127515, gnorm=0.454, clip=0, loss_scale=1, train_wall=101, gb_free=14.2, wall=12426
2023-09-06 20:00:16 | INFO | train_inner | epoch 011:    501 / 1191 loss=2.101, trans_loss=3.789, nll_loss=2.014, w2v_ctc_loss=0.883, task_loss=1.342, task_loss_gen=1.75, contrastive_loss=0, total=6668.97, n_correct=2983.63, ppl=4.04, accuracy=44.739, wps=18808.3, ups=0.97, wpb=19329.4, bsz=653, num_updates=12400, lr=0.000127, gnorm=0.394, clip=0, loss_scale=1, train_wall=102, gb_free=13.8, wall=12529
2023-09-06 20:01:58 | INFO | train_inner | epoch 011:    601 / 1191 loss=2.096, trans_loss=3.779, nll_loss=2.003, w2v_ctc_loss=0.887, task_loss=1.241, task_loss_gen=1.666, contrastive_loss=0, total=6655.76, n_correct=2992.81, ppl=4.01, accuracy=44.966, wps=18992.4, ups=0.98, wpb=19305, bsz=668.5, num_updates=12500, lr=0.000126491, gnorm=0.441, clip=0, loss_scale=1, train_wall=101, gb_free=12.1, wall=12631
2023-09-06 20:03:41 | INFO | train_inner | epoch 011:    701 / 1191 loss=2.085, trans_loss=3.772, nll_loss=1.994, w2v_ctc_loss=0.873, task_loss=1.265, task_loss_gen=1.672, contrastive_loss=0, total=6687.54, n_correct=3025.83, ppl=3.98, accuracy=45.246, wps=18848.1, ups=0.97, wpb=19390.9, bsz=669.6, num_updates=12600, lr=0.000125988, gnorm=0.397, clip=0, loss_scale=1, train_wall=102, gb_free=12, wall=12734
2023-09-06 20:05:23 | INFO | train_inner | epoch 011:    801 / 1191 loss=2.095, trans_loss=3.774, nll_loss=1.994, w2v_ctc_loss=0.891, task_loss=1.203, task_loss_gen=1.612, contrastive_loss=0, total=6781.97, n_correct=3076.09, ppl=3.98, accuracy=45.357, wps=19214.7, ups=0.98, wpb=19648.3, bsz=698.2, num_updates=12700, lr=0.000125491, gnorm=0.407, clip=0, loss_scale=1, train_wall=101, gb_free=11, wall=12836
2023-09-06 20:07:05 | INFO | train_inner | epoch 011:    901 / 1191 loss=2.08, trans_loss=3.778, nll_loss=1.996, w2v_ctc_loss=0.867, task_loss=1.208, task_loss_gen=1.608, contrastive_loss=0, total=6793.28, n_correct=3084.94, ppl=3.99, accuracy=45.412, wps=19169.3, ups=0.97, wpb=19665.8, bsz=684.3, num_updates=12800, lr=0.000125, gnorm=0.432, clip=0, loss_scale=1, train_wall=102, gb_free=13.9, wall=12938
2023-09-06 20:08:48 | INFO | train_inner | epoch 011:   1001 / 1191 loss=2.07, trans_loss=3.768, nll_loss=1.984, w2v_ctc_loss=0.86, task_loss=1.137, task_loss_gen=1.514, contrastive_loss=0, total=6790.27, n_correct=3105.98, ppl=3.96, accuracy=45.742, wps=19092.2, ups=0.97, wpb=19657.6, bsz=708.2, num_updates=12900, lr=0.000124515, gnorm=0.413, clip=0, loss_scale=1, train_wall=102, gb_free=14.3, wall=13041
2023-09-06 20:10:30 | INFO | train_inner | epoch 011:   1101 / 1191 loss=2.08, trans_loss=3.767, nll_loss=1.984, w2v_ctc_loss=0.874, task_loss=1.131, task_loss_gen=1.555, contrastive_loss=0, total=6739.87, n_correct=3075.39, ppl=3.96, accuracy=45.63, wps=19165.4, ups=0.98, wpb=19525.5, bsz=695.1, num_updates=13000, lr=0.000124035, gnorm=0.394, clip=0, loss_scale=1, train_wall=101, gb_free=14.2, wall=13143
2023-09-06 20:12:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 20:12:39 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.678 | trans_loss 6.382 | nll_loss 4.01 | w2v_ctc_loss 1.174 | task_loss 6.393 | task_loss_gen 6.88 | contrastive_loss 0 | total 6138.43 | n_correct 2821.71 | ppl 16.12 | accuracy 45.968 | uer 17.621 | wer 19.301 | raw_wer 19.301 | bleu 2.89 | wps 1486.6 | wpb 6138.4 | bsz 201.1 | num_updates 13090 | best_bleu 2.89
2023-09-06 20:12:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 13090 updates
2023-09-06 20:12:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 20:12:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 20:12:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 11 @ 13090 updates, score 2.89) (writing took 13.660122953937389 seconds)
2023-09-06 20:12:53 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-09-06 20:12:53 | INFO | train | epoch 011 | loss 2.088 | trans_loss 3.778 | nll_loss 1.999 | w2v_ctc_loss 0.876 | task_loss 1.244 | task_loss_gen 1.643 | contrastive_loss 0 | total 6703.69 | n_correct 3029.07 | ppl 4 | accuracy 45.185 | wps 17468.9 | ups 0.9 | wpb 19422.7 | bsz 678.2 | num_updates 13090 | lr 0.000123608 | gnorm 0.423 | clip 0 | loss_scale 1 | train_wall 1207 | gb_free 13.3 | wall 13286
2023-09-06 20:12:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 20:12:53 | INFO | fairseq.trainer | begin training epoch 12
2023-09-06 20:12:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 20:13:11 | INFO | train_inner | epoch 012:     10 / 1191 loss=2.075, trans_loss=3.765, nll_loss=1.981, w2v_ctc_loss=0.873, task_loss=1.201, task_loss_gen=1.525, contrastive_loss=0, total=6828.67, n_correct=3135.81, ppl=3.95, accuracy=45.921, wps=12336.8, ups=0.62, wpb=19771.5, bsz=722.5, num_updates=13100, lr=0.00012356, gnorm=0.396, clip=0, loss_scale=1, train_wall=102, gb_free=14, wall=13303
2023-09-06 20:14:53 | INFO | train_inner | epoch 012:    110 / 1191 loss=2.057, trans_loss=3.758, nll_loss=1.972, w2v_ctc_loss=0.843, task_loss=1.272, task_loss_gen=1.655, contrastive_loss=0, total=6730.47, n_correct=3082.03, ppl=3.92, accuracy=45.792, wps=19096.3, ups=0.98, wpb=19497.4, bsz=666.4, num_updates=13200, lr=0.000123091, gnorm=0.458, clip=0, loss_scale=1, train_wall=101, gb_free=14.2, wall=13406
2023-09-06 20:16:34 | INFO | train_inner | epoch 012:    210 / 1191 loss=2.062, trans_loss=3.76, nll_loss=1.975, w2v_ctc_loss=0.851, task_loss=1.245, task_loss_gen=1.638, contrastive_loss=0, total=6727.5, n_correct=3077.34, ppl=3.93, accuracy=45.743, wps=19149, ups=0.98, wpb=19490.8, bsz=667.8, num_updates=13300, lr=0.000122628, gnorm=0.442, clip=0, loss_scale=1, train_wall=101, gb_free=13.9, wall=13507
2023-09-06 20:18:17 | INFO | train_inner | epoch 012:    310 / 1191 loss=2.058, trans_loss=3.753, nll_loss=1.968, w2v_ctc_loss=0.853, task_loss=1.138, task_loss_gen=1.558, contrastive_loss=0, total=6706.08, n_correct=3084.7, ppl=3.91, accuracy=45.999, wps=19030.9, ups=0.98, wpb=19438.3, bsz=697, num_updates=13400, lr=0.000122169, gnorm=0.478, clip=0, loss_scale=1, train_wall=101, gb_free=15.1, wall=13610
2023-09-06 20:19:58 | INFO | train_inner | epoch 012:    410 / 1191 loss=2.045, trans_loss=3.751, nll_loss=1.963, w2v_ctc_loss=0.838, task_loss=1.159, task_loss_gen=1.513, contrastive_loss=0, total=6777.68, n_correct=3125.33, ppl=3.9, accuracy=46.112, wps=19272, ups=0.98, wpb=19633.7, bsz=706.3, num_updates=13500, lr=0.000121716, gnorm=0.456, clip=0, loss_scale=1, train_wall=101, gb_free=13.2, wall=13711
2023-09-06 20:21:40 | INFO | train_inner | epoch 012:    510 / 1191 loss=2.05, trans_loss=3.755, nll_loss=1.968, w2v_ctc_loss=0.839, task_loss=1.176, task_loss_gen=1.586, contrastive_loss=0, total=6749.2, n_correct=3114.17, ppl=3.91, accuracy=46.141, wps=19208.3, ups=0.98, wpb=19551, bsz=688.8, num_updates=13600, lr=0.000121268, gnorm=0.454, clip=0, loss_scale=1, train_wall=101, gb_free=13.1, wall=13813
2023-09-06 20:23:23 | INFO | train_inner | epoch 012:    610 / 1191 loss=2.066, trans_loss=3.754, nll_loss=1.967, w2v_ctc_loss=0.86, task_loss=1.33, task_loss_gen=1.714, contrastive_loss=0, total=6691.64, n_correct=3070.77, ppl=3.91, accuracy=45.89, wps=18883.4, ups=0.97, wpb=19386.6, bsz=669.1, num_updates=13700, lr=0.000120824, gnorm=0.429, clip=0, loss_scale=2, train_wall=102, gb_free=12.5, wall=13916
2023-09-06 20:25:05 | INFO | train_inner | epoch 012:    710 / 1191 loss=2.052, trans_loss=3.741, nll_loss=1.954, w2v_ctc_loss=0.851, task_loss=1.207, task_loss_gen=1.58, contrastive_loss=0, total=6744.24, n_correct=3117.84, ppl=3.88, accuracy=46.23, wps=19104.8, ups=0.98, wpb=19563.4, bsz=692.1, num_updates=13800, lr=0.000120386, gnorm=0.375, clip=0, loss_scale=2, train_wall=102, gb_free=12.3, wall=14018
2023-09-06 20:26:48 | INFO | train_inner | epoch 012:    810 / 1191 loss=2.065, trans_loss=3.759, nll_loss=1.972, w2v_ctc_loss=0.857, task_loss=1.3, task_loss_gen=1.727, contrastive_loss=0, total=6664.44, n_correct=3062.98, ppl=3.92, accuracy=45.96, wps=18875.5, ups=0.98, wpb=19297.1, bsz=664.8, num_updates=13900, lr=0.000119952, gnorm=0.382, clip=0, loss_scale=2, train_wall=101, gb_free=12.8, wall=14121
2023-09-06 20:28:31 | INFO | train_inner | epoch 012:    910 / 1191 loss=2.065, trans_loss=3.759, nll_loss=1.973, w2v_ctc_loss=0.859, task_loss=1.566, task_loss_gen=1.816, contrastive_loss=0, total=6685.6, n_correct=3073.3, ppl=3.93, accuracy=45.969, wps=18668.3, ups=0.96, wpb=19362, bsz=665.1, num_updates=14000, lr=0.000119523, gnorm=0.392, clip=0, loss_scale=2, train_wall=103, gb_free=13.5, wall=14224
2023-09-06 20:28:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 20:29:08 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.663 | trans_loss 6.36 | nll_loss 3.978 | w2v_ctc_loss 1.176 | task_loss 6.136 | task_loss_gen 7.109 | contrastive_loss 0 | total 6138.43 | n_correct 2838.14 | ppl 15.76 | accuracy 46.236 | uer 17.38 | wer 19.085 | raw_wer 19.085 | bleu 2.94 | wps 1451.9 | wpb 6138.4 | bsz 201.1 | num_updates 14000 | best_bleu 2.94
2023-09-06 20:29:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14000 updates
2023-09-06 20:29:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_12_14000.pt
2023-09-06 20:29:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_12_14000.pt
2023-09-06 20:29:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_12_14000.pt (epoch 12 @ 14000 updates, score 2.94) (writing took 15.242762206005864 seconds)
2023-09-06 20:31:05 | INFO | train_inner | epoch 012:   1010 / 1191 loss=2.066, trans_loss=3.751, nll_loss=1.966, w2v_ctc_loss=0.864, task_loss=1.389, task_loss_gen=1.713, contrastive_loss=0, total=6585.72, n_correct=3031.63, ppl=3.91, accuracy=46.033, wps=12393.1, ups=0.65, wpb=19098.1, bsz=658.4, num_updates=14100, lr=0.000119098, gnorm=0.376, clip=0, loss_scale=2, train_wall=101, gb_free=14.9, wall=14378
2023-09-06 20:32:48 | INFO | train_inner | epoch 012:   1110 / 1191 loss=2.056, trans_loss=3.75, nll_loss=1.961, w2v_ctc_loss=0.853, task_loss=1.434, task_loss_gen=1.718, contrastive_loss=0, total=6653.33, n_correct=3080.32, ppl=3.89, accuracy=46.297, wps=18758.8, ups=0.97, wpb=19271.2, bsz=673.9, num_updates=14200, lr=0.000118678, gnorm=0.35, clip=0, loss_scale=2, train_wall=102, gb_free=13.7, wall=14481
2023-09-06 20:34:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 20:34:47 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.658 | trans_loss 6.344 | nll_loss 3.961 | w2v_ctc_loss 1.191 | task_loss 4.986 | task_loss_gen 7.173 | contrastive_loss 0 | total 6138.43 | n_correct 2855.71 | ppl 15.58 | accuracy 46.522 | uer 17.463 | wer 19.305 | raw_wer 19.305 | bleu 3.13 | wps 1490.7 | wpb 6138.4 | bsz 201.1 | num_updates 14281 | best_bleu 3.13
2023-09-06 20:34:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 14281 updates
2023-09-06 20:34:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 20:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 20:35:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 12 @ 14281 updates, score 3.13) (writing took 13.329224682995118 seconds)
2023-09-06 20:35:01 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-09-06 20:35:01 | INFO | train | epoch 012 | loss 2.058 | trans_loss 3.753 | nll_loss 1.966 | w2v_ctc_loss 0.852 | task_loss 1.291 | task_loss_gen 1.651 | contrastive_loss 0 | total 6703.69 | n_correct 3086.62 | ppl 3.91 | accuracy 46.044 | wps 17413.8 | ups 0.9 | wpb 19422.7 | bsz 678.2 | num_updates 14281 | lr 0.000118341 | gnorm 0.411 | clip 0 | loss_scale 2 | train_wall 1208 | gb_free 13.9 | wall 14614
2023-09-06 20:35:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 20:35:01 | INFO | fairseq.trainer | begin training epoch 13
2023-09-06 20:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 20:35:28 | INFO | train_inner | epoch 013:     19 / 1191 loss=2.053, trans_loss=3.747, nll_loss=1.957, w2v_ctc_loss=0.85, task_loss=1.323, task_loss_gen=1.654, contrastive_loss=0, total=6703.92, n_correct=3105.2, ppl=3.88, accuracy=46.319, wps=12108.3, ups=0.62, wpb=19415.3, bsz=671.8, num_updates=14300, lr=0.000118262, gnorm=0.331, clip=0, loss_scale=2, train_wall=102, gb_free=13.1, wall=14641
2023-09-06 20:37:11 | INFO | train_inner | epoch 013:    119 / 1191 loss=2.034, trans_loss=3.733, nll_loss=1.94, w2v_ctc_loss=0.825, task_loss=1.284, task_loss_gen=1.723, contrastive_loss=0, total=6708.36, n_correct=3121.54, ppl=3.84, accuracy=46.532, wps=18894.7, ups=0.97, wpb=19438, bsz=664.1, num_updates=14400, lr=0.000117851, gnorm=0.344, clip=0, loss_scale=2, train_wall=102, gb_free=13.6, wall=14744
2023-09-06 20:38:54 | INFO | train_inner | epoch 013:    219 / 1191 loss=2.029, trans_loss=3.737, nll_loss=1.945, w2v_ctc_loss=0.822, task_loss=1.248, task_loss_gen=1.687, contrastive_loss=0, total=6639.35, n_correct=3095.42, ppl=3.85, accuracy=46.622, wps=18703.2, ups=0.97, wpb=19235.3, bsz=684.7, num_updates=14500, lr=0.000117444, gnorm=0.362, clip=0, loss_scale=2, train_wall=102, gb_free=12.9, wall=14847
2023-09-06 20:40:36 | INFO | train_inner | epoch 013:    319 / 1191 loss=2.015, trans_loss=3.726, nll_loss=1.93, w2v_ctc_loss=0.811, task_loss=1.249, task_loss_gen=1.578, contrastive_loss=0, total=6757.16, n_correct=3176.77, ppl=3.81, accuracy=47.013, wps=19210.2, ups=0.98, wpb=19575.2, bsz=726.3, num_updates=14600, lr=0.000117041, gnorm=0.378, clip=0, loss_scale=2, train_wall=101, gb_free=13.5, wall=14949
2023-09-06 20:42:19 | INFO | train_inner | epoch 013:    419 / 1191 loss=2.041, trans_loss=3.741, nll_loss=1.951, w2v_ctc_loss=0.836, task_loss=1.471, task_loss_gen=1.758, contrastive_loss=0, total=6711.27, n_correct=3111.57, ppl=3.87, accuracy=46.363, wps=18943.2, ups=0.97, wpb=19450.7, bsz=665, num_updates=14700, lr=0.000116642, gnorm=0.478, clip=0, loss_scale=2, train_wall=102, gb_free=13, wall=15052
2023-09-06 20:44:02 | INFO | train_inner | epoch 013:    519 / 1191 loss=2.039, trans_loss=3.739, nll_loss=1.947, w2v_ctc_loss=0.833, task_loss=1.44, task_loss_gen=1.759, contrastive_loss=0, total=6656.85, n_correct=3091.28, ppl=3.86, accuracy=46.438, wps=18740.6, ups=0.97, wpb=19287.2, bsz=661.9, num_updates=14800, lr=0.000116248, gnorm=0.425, clip=0, loss_scale=2, train_wall=102, gb_free=12.8, wall=15155
2023-09-06 20:45:44 | INFO | train_inner | epoch 013:    619 / 1191 loss=2.042, trans_loss=3.74, nll_loss=1.948, w2v_ctc_loss=0.838, task_loss=1.215, task_loss_gen=1.71, contrastive_loss=0, total=6709.17, n_correct=3114.8, ppl=3.86, accuracy=46.426, wps=18984.7, ups=0.98, wpb=19434.6, bsz=655.6, num_updates=14900, lr=0.000115857, gnorm=0.346, clip=0, loss_scale=2, train_wall=101, gb_free=13.1, wall=15257
2023-09-06 20:47:27 | INFO | train_inner | epoch 013:    719 / 1191 loss=2.038, trans_loss=3.739, nll_loss=1.946, w2v_ctc_loss=0.832, task_loss=1.47, task_loss_gen=1.78, contrastive_loss=0, total=6638.08, n_correct=3084.85, ppl=3.85, accuracy=46.472, wps=18643.7, ups=0.97, wpb=19230.7, bsz=659.9, num_updates=15000, lr=0.00011547, gnorm=0.529, clip=0, loss_scale=2, train_wall=102, gb_free=13.5, wall=15360
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:0')
2023-09-06 20:48:40 | INFO | train_inner | epoch 013:    819 / 1191 loss=2.315, trans_loss=5.386, nll_loss=2.8, w2v_ctc_loss=0.598, task_loss=1.957, task_loss_gen=2.444, contrastive_loss=0, total=6768.29, n_correct=3168.13, ppl=6.96, accuracy=46.808, wps=18704.8, ups=1.38, wpb=13597.7, bsz=462.1, num_updates=15100, lr=0.000115087, gnorm=0.567, clip=0, loss_scale=2, train_wall=72, gb_free=12.8, wall=15433
2023-09-06 20:49:52 | INFO | train_inner | epoch 013:    919 / 1191 loss=2.335, trans_loss=5.416, nll_loss=2.821, w2v_ctc_loss=0.615, task_loss=2.212, task_loss_gen=2.777, contrastive_loss=0, total=6548.7, n_correct=3035.05, ppl=7.07, accuracy=46.346, wps=18125, ups=1.38, wpb=13097.4, bsz=419.3, num_updates=15200, lr=0.000114708, gnorm=0.524, clip=0, loss_scale=2, train_wall=71, gb_free=14.3, wall=15505
2023-09-06 20:51:05 | INFO | train_inner | epoch 013:   1019 / 1191 loss=2.312, trans_loss=5.398, nll_loss=2.798, w2v_ctc_loss=0.596, task_loss=2.083, task_loss_gen=2.496, contrastive_loss=0, total=6802.15, n_correct=3200.7, ppl=6.95, accuracy=47.054, wps=18744, ups=1.38, wpb=13604.3, bsz=467.9, num_updates=15300, lr=0.000114332, gnorm=0.601, clip=0, loss_scale=2, train_wall=72, gb_free=12.8, wall=15578
2023-09-06 20:52:17 | INFO | train_inner | epoch 013:   1119 / 1191 loss=2.316, trans_loss=5.399, nll_loss=2.798, w2v_ctc_loss=0.606, task_loss=2.483, task_loss_gen=2.771, contrastive_loss=0, total=6744.53, n_correct=3170.76, ppl=6.95, accuracy=47.012, wps=18699.8, ups=1.39, wpb=13489.1, bsz=465.4, num_updates=15400, lr=0.000113961, gnorm=0.768, clip=0, loss_scale=2, train_wall=71, gb_free=13.1, wall=15650
2023-09-06 20:53:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:5')
2023-09-06 20:53:45 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.631 | trans_loss 6.316 | nll_loss 3.919 | w2v_ctc_loss 1.167 | task_loss 10.045 | task_loss_gen 7.339 | contrastive_loss 0 | total 6138.43 | n_correct 2889.14 | ppl 15.13 | accuracy 47.066 | uer 17.313 | wer 19.137 | raw_wer 19.137 | bleu 3.37 | wps 1501.1 | wpb 6138.4 | bsz 201.1 | num_updates 15472 | best_bleu 3.37
2023-09-06 20:53:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 15472 updates
2023-09-06 20:53:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 20:53:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 20:53:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 13 @ 15472 updates, score 3.37) (writing took 12.37078337999992 seconds)
2023-09-06 20:53:58 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-09-06 20:53:58 | INFO | train | epoch 013 | loss 2.123 | trans_loss 4.257 | nll_loss 2.213 | w2v_ctc_loss 0.757 | task_loss 1.576 | task_loss_gen 1.971 | contrastive_loss 0 | total 6703.69 | n_correct 3128.8 | ppl 4.64 | accuracy 46.673 | wps 17852.8 | ups 1.05 | wpb 17038.6 | bsz 588.3 | num_updates 15472 | lr 0.000113695 | gnorm 0.481 | clip 0 | loss_scale 2 | train_wall 1069 | gb_free 9.6 | wall 15751
2023-09-06 20:53:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 20:53:58 | INFO | fairseq.trainer | begin training epoch 14
2023-09-06 20:53:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 20:54:26 | INFO | train_inner | epoch 014:     28 / 1191 loss=2.314, trans_loss=5.399, nll_loss=2.798, w2v_ctc_loss=0.599, task_loss=1.887, task_loss_gen=2.386, contrastive_loss=0, total=6727.63, n_correct=3160.19, ppl=6.95, accuracy=46.973, wps=10445.6, ups=0.78, wpb=13455.3, bsz=459.6, num_updates=15500, lr=0.000113592, gnorm=0.5, clip=0, loss_scale=2, train_wall=71, gb_free=13.8, wall=15779
2023-09-06 20:55:38 | INFO | train_inner | epoch 014:    128 / 1191 loss=2.303, trans_loss=5.384, nll_loss=2.778, w2v_ctc_loss=0.583, task_loss=1.817, task_loss_gen=2.45, contrastive_loss=0, total=6665.35, n_correct=3147.25, ppl=6.86, accuracy=47.218, wps=18419.5, ups=1.38, wpb=13330.7, bsz=453.9, num_updates=15600, lr=0.000113228, gnorm=0.502, clip=0, loss_scale=2, train_wall=72, gb_free=13.6, wall=15851
2023-09-06 20:56:51 | INFO | train_inner | epoch 014:    228 / 1191 loss=2.312, trans_loss=5.393, nll_loss=2.79, w2v_ctc_loss=0.594, task_loss=2.803, task_loss_gen=3.179, contrastive_loss=0, total=6620.78, n_correct=3105.74, ppl=6.92, accuracy=46.909, wps=18277.9, ups=1.38, wpb=13241.6, bsz=441, num_updates=15700, lr=0.000112867, gnorm=0.99, clip=0, loss_scale=4, train_wall=72, gb_free=14.1, wall=15924
2023-09-06 20:58:03 | INFO | train_inner | epoch 014:    328 / 1191 loss=2.311, trans_loss=5.39, nll_loss=2.787, w2v_ctc_loss=0.592, task_loss=1.908, task_loss_gen=2.536, contrastive_loss=0, total=6738.62, n_correct=3172.57, ppl=6.9, accuracy=47.08, wps=18520.3, ups=1.37, wpb=13477.2, bsz=449.9, num_updates=15800, lr=0.000112509, gnorm=0.381, clip=0, loss_scale=4, train_wall=72, gb_free=8.1, wall=15996
2023-09-06 20:59:16 | INFO | train_inner | epoch 014:    428 / 1191 loss=2.298, trans_loss=5.378, nll_loss=2.77, w2v_ctc_loss=0.583, task_loss=1.728, task_loss_gen=2.392, contrastive_loss=0, total=6817, n_correct=3234.32, ppl=6.82, accuracy=47.445, wps=18728.9, ups=1.37, wpb=13634, bsz=468.8, num_updates=15900, lr=0.000112154, gnorm=0.357, clip=0, loss_scale=4, train_wall=72, gb_free=12.1, wall=16069
2023-09-06 21:00:29 | INFO | train_inner | epoch 014:    528 / 1191 loss=2.301, trans_loss=5.378, nll_loss=2.771, w2v_ctc_loss=0.587, task_loss=1.762, task_loss_gen=2.467, contrastive_loss=0, total=6727.07, n_correct=3184.68, ppl=6.83, accuracy=47.341, wps=18570.2, ups=1.38, wpb=13454.1, bsz=462.2, num_updates=16000, lr=0.000111803, gnorm=0.349, clip=0, loss_scale=4, train_wall=72, gb_free=8.3, wall=16142
2023-09-06 21:00:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 21:01:05 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.626 | trans_loss 6.299 | nll_loss 3.898 | w2v_ctc_loss 1.187 | task_loss 14.526 | task_loss_gen 8.828 | contrastive_loss 0 | total 6138.43 | n_correct 2893.86 | ppl 14.91 | accuracy 47.143 | uer 17.367 | wer 19.163 | raw_wer 19.163 | bleu 3.47 | wps 1471.1 | wpb 6138.4 | bsz 201.1 | num_updates 16000 | best_bleu 3.47
2023-09-06 21:01:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16000 updates
2023-09-06 21:01:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_14_16000.pt
2023-09-06 21:01:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_14_16000.pt
2023-09-06 21:01:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_14_16000.pt (epoch 14 @ 16000 updates, score 3.47) (writing took 14.376884775003418 seconds)
2023-09-06 21:02:32 | INFO | train_inner | epoch 014:    628 / 1191 loss=2.304, trans_loss=5.38, nll_loss=2.773, w2v_ctc_loss=0.596, task_loss=2.371, task_loss_gen=2.694, contrastive_loss=0, total=6799.26, n_correct=3216.53, ppl=6.83, accuracy=47.307, wps=10980.6, ups=0.81, wpb=13598.5, bsz=461.3, num_updates=16100, lr=0.000111456, gnorm=0.474, clip=0, loss_scale=4, train_wall=72, gb_free=11.9, wall=16265
2023-09-06 21:03:45 | INFO | train_inner | epoch 014:    728 / 1191 loss=2.307, trans_loss=5.382, nll_loss=2.775, w2v_ctc_loss=0.595, task_loss=1.972, task_loss_gen=2.526, contrastive_loss=0, total=6683.72, n_correct=3157.53, ppl=6.85, accuracy=47.242, wps=18384.3, ups=1.38, wpb=13367.4, bsz=447.2, num_updates=16200, lr=0.000111111, gnorm=0.353, clip=0, loss_scale=4, train_wall=72, gb_free=13, wall=16338
2023-09-06 21:04:58 | INFO | train_inner | epoch 014:    828 / 1191 loss=2.302, trans_loss=5.381, nll_loss=2.774, w2v_ctc_loss=0.594, task_loss=1.79, task_loss_gen=2.551, contrastive_loss=0, total=6702.31, n_correct=3177.62, ppl=6.84, accuracy=47.411, wps=18314.8, ups=1.37, wpb=13404.6, bsz=460.3, num_updates=16300, lr=0.00011077, gnorm=0.367, clip=0, loss_scale=4, train_wall=72, gb_free=12.9, wall=16411
2023-09-06 21:06:10 | INFO | train_inner | epoch 014:    928 / 1191 loss=2.306, trans_loss=5.382, nll_loss=2.776, w2v_ctc_loss=0.597, task_loss=2.28, task_loss_gen=2.85, contrastive_loss=0, total=6652.36, n_correct=3142.34, ppl=6.85, accuracy=47.236, wps=18449, ups=1.39, wpb=13304.7, bsz=445.8, num_updates=16400, lr=0.000110432, gnorm=0.466, clip=0, loss_scale=4, train_wall=71, gb_free=13.4, wall=16483
2023-09-06 21:07:23 | INFO | train_inner | epoch 014:   1028 / 1191 loss=2.317, trans_loss=5.391, nll_loss=2.787, w2v_ctc_loss=0.608, task_loss=1.868, task_loss_gen=2.762, contrastive_loss=0, total=6576.67, n_correct=3095.58, ppl=6.9, accuracy=47.069, wps=18034.7, ups=1.37, wpb=13153.3, bsz=423.7, num_updates=16500, lr=0.000110096, gnorm=0.359, clip=0, loss_scale=4, train_wall=72, gb_free=15, wall=16556
2023-09-06 21:08:36 | INFO | train_inner | epoch 014:   1128 / 1191 loss=2.298, trans_loss=5.374, nll_loss=2.766, w2v_ctc_loss=0.596, task_loss=1.77, task_loss_gen=2.475, contrastive_loss=0, total=6781.45, n_correct=3231.59, ppl=6.8, accuracy=47.653, wps=18675.7, ups=1.38, wpb=13562.9, bsz=469.4, num_updates=16600, lr=0.000109764, gnorm=0.375, clip=0, loss_scale=4, train_wall=72, gb_free=12.1, wall=16629
2023-09-06 21:09:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 21:09:57 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.616 | trans_loss 6.287 | nll_loss 3.879 | w2v_ctc_loss 1.182 | task_loss 18.651 | task_loss_gen 10.312 | contrastive_loss 0 | total 6138.43 | n_correct 2901.71 | ppl 14.71 | accuracy 47.271 | uer 17.284 | wer 18.873 | raw_wer 18.873 | bleu 3.86 | wps 1521.3 | wpb 6138.4 | bsz 201.1 | num_updates 16663 | best_bleu 3.86
2023-09-06 21:09:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 16663 updates
2023-09-06 21:09:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 21:10:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 21:10:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 14 @ 16663 updates, score 3.86) (writing took 12.628443359979428 seconds)
2023-09-06 21:10:11 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-09-06 21:10:11 | INFO | train | epoch 014 | loss 2.306 | trans_loss 5.383 | nll_loss 2.777 | w2v_ctc_loss 0.593 | task_loss 2.006 | task_loss_gen 2.628 | contrastive_loss 0 | total 6703.69 | n_correct 3168.19 | ppl 6.85 | accuracy 47.26 | wps 16410.6 | ups 1.22 | wpb 13407.4 | bsz 452.1 | num_updates 16663 | lr 0.000109557 | gnorm 0.452 | clip 0 | loss_scale 4 | train_wall 855 | gb_free 14.3 | wall 16724
2023-09-06 21:10:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 21:10:11 | INFO | fairseq.trainer | begin training epoch 15
2023-09-06 21:10:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 21:10:45 | INFO | train_inner | epoch 015:     37 / 1191 loss=2.299, trans_loss=5.372, nll_loss=2.763, w2v_ctc_loss=0.587, task_loss=1.891, task_loss_gen=2.627, contrastive_loss=0, total=6697.93, n_correct=3181.42, ppl=6.79, accuracy=47.499, wps=10375.2, ups=0.77, wpb=13395.9, bsz=450, num_updates=16700, lr=0.000109435, gnorm=0.391, clip=0, loss_scale=4, train_wall=71, gb_free=12.6, wall=16758
2023-09-06 21:11:57 | INFO | train_inner | epoch 015:    137 / 1191 loss=2.288, trans_loss=5.359, nll_loss=2.746, w2v_ctc_loss=0.584, task_loss=1.614, task_loss_gen=2.429, contrastive_loss=0, total=6740.56, n_correct=3225.85, ppl=6.71, accuracy=47.857, wps=18649.8, ups=1.38, wpb=13481.1, bsz=458.6, num_updates=16800, lr=0.000109109, gnorm=0.335, clip=0, loss_scale=4, train_wall=71, gb_free=11.6, wall=16830
2023-09-06 21:13:09 | INFO | train_inner | epoch 015:    237 / 1191 loss=2.292, trans_loss=5.361, nll_loss=2.748, w2v_ctc_loss=0.585, task_loss=2.16, task_loss_gen=2.639, contrastive_loss=0, total=6694.8, n_correct=3198.47, ppl=6.72, accuracy=47.775, wps=18594.5, ups=1.39, wpb=13389.6, bsz=447.5, num_updates=16900, lr=0.000108786, gnorm=0.439, clip=0, loss_scale=4, train_wall=71, gb_free=13.2, wall=16902
2023-09-06 21:14:22 | INFO | train_inner | epoch 015:    337 / 1191 loss=2.289, trans_loss=5.356, nll_loss=2.742, w2v_ctc_loss=0.578, task_loss=1.852, task_loss_gen=2.493, contrastive_loss=0, total=6668.92, n_correct=3188.42, ppl=6.69, accuracy=47.81, wps=18456.9, ups=1.38, wpb=13337.8, bsz=447.4, num_updates=17000, lr=0.000108465, gnorm=0.382, clip=0, loss_scale=4, train_wall=71, gb_free=13.7, wall=16975
2023-09-06 21:15:34 | INFO | train_inner | epoch 015:    437 / 1191 loss=2.295, trans_loss=5.366, nll_loss=2.755, w2v_ctc_loss=0.592, task_loss=1.78, task_loss_gen=2.567, contrastive_loss=0, total=6703.54, n_correct=3194.99, ppl=6.75, accuracy=47.661, wps=18425.3, ups=1.37, wpb=13407.1, bsz=452.5, num_updates=17100, lr=0.000108148, gnorm=0.357, clip=0, loss_scale=4, train_wall=72, gb_free=12.5, wall=17047
2023-09-06 21:16:47 | INFO | train_inner | epoch 015:    537 / 1191 loss=2.289, trans_loss=5.355, nll_loss=2.74, w2v_ctc_loss=0.592, task_loss=1.92, task_loss_gen=2.601, contrastive_loss=0, total=6725.68, n_correct=3220.85, ppl=6.68, accuracy=47.889, wps=18440.9, ups=1.37, wpb=13451.4, bsz=463.3, num_updates=17200, lr=0.000107833, gnorm=0.413, clip=0, loss_scale=4, train_wall=72, gb_free=13.5, wall=17120
2023-09-06 21:17:59 | INFO | train_inner | epoch 015:    637 / 1191 loss=2.312, trans_loss=5.378, nll_loss=2.77, w2v_ctc_loss=0.6, task_loss=2.098, task_loss_gen=2.833, contrastive_loss=0, total=6602.87, n_correct=3110.08, ppl=6.82, accuracy=47.102, wps=18317.9, ups=1.39, wpb=13205.7, bsz=412.5, num_updates=17300, lr=0.000107521, gnorm=0.382, clip=0, loss_scale=4, train_wall=71, gb_free=11.6, wall=17192
2023-09-06 21:19:12 | INFO | train_inner | epoch 015:    737 / 1191 loss=2.29, trans_loss=5.359, nll_loss=2.746, w2v_ctc_loss=0.585, task_loss=1.816, task_loss_gen=2.634, contrastive_loss=0, total=6633.12, n_correct=3166.3, ppl=6.71, accuracy=47.735, wps=18255.5, ups=1.38, wpb=13266.2, bsz=452, num_updates=17400, lr=0.000107211, gnorm=0.386, clip=0, loss_scale=4, train_wall=72, gb_free=14.1, wall=17265
2023-09-06 21:20:25 | INFO | train_inner | epoch 015:    837 / 1191 loss=2.292, trans_loss=5.36, nll_loss=2.747, w2v_ctc_loss=0.587, task_loss=1.685, task_loss_gen=2.56, contrastive_loss=0, total=6716.93, n_correct=3213.29, ppl=6.71, accuracy=47.839, wps=18521.2, ups=1.38, wpb=13433.9, bsz=447.1, num_updates=17500, lr=0.000106904, gnorm=0.357, clip=0, loss_scale=4, train_wall=72, gb_free=14, wall=17338
2023-09-06 21:21:38 | INFO | train_inner | epoch 015:    937 / 1191 loss=2.275, trans_loss=5.346, nll_loss=2.729, w2v_ctc_loss=0.574, task_loss=1.674, task_loss_gen=2.511, contrastive_loss=0, total=6764.28, n_correct=3266.24, ppl=6.63, accuracy=48.287, wps=18481.4, ups=1.37, wpb=13528.6, bsz=476.1, num_updates=17600, lr=0.0001066, gnorm=0.367, clip=0, loss_scale=4, train_wall=72, gb_free=14.1, wall=17411
2023-09-06 21:22:51 | INFO | train_inner | epoch 015:   1037 / 1191 loss=2.288, trans_loss=5.359, nll_loss=2.746, w2v_ctc_loss=0.587, task_loss=2.454, task_loss_gen=3.025, contrastive_loss=0, total=6704.43, n_correct=3213.96, ppl=6.71, accuracy=47.938, wps=18425.1, ups=1.37, wpb=13408.9, bsz=454.6, num_updates=17700, lr=0.000106299, gnorm=0.49, clip=0, loss_scale=4, train_wall=72, gb_free=8.9, wall=17484
2023-09-06 21:24:03 | INFO | train_inner | epoch 015:   1137 / 1191 loss=2.295, trans_loss=5.364, nll_loss=2.752, w2v_ctc_loss=0.591, task_loss=1.638, task_loss_gen=2.583, contrastive_loss=0, total=6748.19, n_correct=3219.31, ppl=6.74, accuracy=47.706, wps=18593.3, ups=1.38, wpb=13496.4, bsz=443.9, num_updates=17800, lr=0.000106, gnorm=0.33, clip=0, loss_scale=8, train_wall=72, gb_free=12.5, wall=17556
2023-09-06 21:24:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 21:25:17 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.597 | trans_loss 6.262 | nll_loss 3.846 | w2v_ctc_loss 1.175 | task_loss 5.892 | task_loss_gen 6.961 | contrastive_loss 0 | total 6138.43 | n_correct 2930.29 | ppl 14.38 | accuracy 47.737 | uer 17.273 | wer 19.003 | raw_wer 19.003 | bleu 3.93 | wps 1623.6 | wpb 6138.4 | bsz 201.1 | num_updates 17854 | best_bleu 3.93
2023-09-06 21:25:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 17854 updates
2023-09-06 21:25:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 21:25:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 21:25:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 15 @ 17854 updates, score 3.93) (writing took 13.60816495202016 seconds)
2023-09-06 21:25:31 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-09-06 21:25:31 | INFO | train | epoch 015 | loss 2.291 | trans_loss 5.36 | nll_loss 2.747 | w2v_ctc_loss 0.586 | task_loss 1.849 | task_loss_gen 2.606 | contrastive_loss 0 | total 6703.69 | n_correct 3204.68 | ppl 6.71 | accuracy 47.805 | wps 17351 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 17854 | lr 0.000105839 | gnorm 0.381 | clip 0 | loss_scale 8 | train_wall 853 | gb_free 11.5 | wall 17644
2023-09-06 21:25:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 21:25:31 | INFO | fairseq.trainer | begin training epoch 16
2023-09-06 21:25:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 21:26:12 | INFO | train_inner | epoch 016:     46 / 1191 loss=2.282, trans_loss=5.351, nll_loss=2.735, w2v_ctc_loss=0.575, task_loss=1.457, task_loss_gen=2.564, contrastive_loss=0, total=6672.67, n_correct=3204.84, ppl=6.66, accuracy=48.029, wps=10382.4, ups=0.78, wpb=13345.3, bsz=454.4, num_updates=17900, lr=0.000105703, gnorm=0.317, clip=0, loss_scale=8, train_wall=71, gb_free=14.6, wall=17685
2023-09-06 21:27:24 | INFO | train_inner | epoch 016:    146 / 1191 loss=2.279, trans_loss=5.342, nll_loss=2.723, w2v_ctc_loss=0.575, task_loss=1.649, task_loss_gen=2.736, contrastive_loss=0, total=6723.53, n_correct=3243.67, ppl=6.6, accuracy=48.244, wps=18502.5, ups=1.38, wpb=13447.1, bsz=445.7, num_updates=18000, lr=0.000105409, gnorm=0.327, clip=0, loss_scale=8, train_wall=72, gb_free=14, wall=17757
2023-09-06 21:27:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 21:28:01 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.591 | trans_loss 6.26 | nll_loss 3.838 | w2v_ctc_loss 1.162 | task_loss 6.148 | task_loss_gen 7.217 | contrastive_loss 0 | total 6138.43 | n_correct 2936.57 | ppl 14.31 | accuracy 47.839 | uer 17.3 | wer 19.234 | raw_wer 19.234 | bleu 3.97 | wps 1483.3 | wpb 6138.4 | bsz 201.1 | num_updates 18000 | best_bleu 3.97
2023-09-06 21:28:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 18000 updates
2023-09-06 21:28:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_16_18000.pt
2023-09-06 21:28:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_16_18000.pt
2023-09-06 21:28:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_16_18000.pt (epoch 16 @ 18000 updates, score 3.97) (writing took 14.061449042987078 seconds)
2023-09-06 21:29:28 | INFO | train_inner | epoch 016:    246 / 1191 loss=2.282, trans_loss=5.344, nll_loss=2.726, w2v_ctc_loss=0.577, task_loss=1.607, task_loss_gen=2.667, contrastive_loss=0, total=6700.51, n_correct=3222.12, ppl=6.62, accuracy=48.088, wps=10850.4, ups=0.81, wpb=13401, bsz=442.1, num_updates=18100, lr=0.000105118, gnorm=0.333, clip=0, loss_scale=8, train_wall=71, gb_free=13.2, wall=17881
2023-09-06 21:30:40 | INFO | train_inner | epoch 016:    346 / 1191 loss=2.273, trans_loss=5.339, nll_loss=2.72, w2v_ctc_loss=0.577, task_loss=1.448, task_loss_gen=2.514, contrastive_loss=0, total=6776.18, n_correct=3277.33, ppl=6.59, accuracy=48.365, wps=18695.6, ups=1.38, wpb=13552.4, bsz=464.7, num_updates=18200, lr=0.000104828, gnorm=0.319, clip=0, loss_scale=8, train_wall=72, gb_free=11.1, wall=17953
2023-09-06 21:31:52 | INFO | train_inner | epoch 016:    446 / 1191 loss=2.278, trans_loss=5.343, nll_loss=2.724, w2v_ctc_loss=0.576, task_loss=1.552, task_loss_gen=2.748, contrastive_loss=0, total=6679.62, n_correct=3220.89, ppl=6.61, accuracy=48.22, wps=18675.5, ups=1.4, wpb=13359.2, bsz=448.1, num_updates=18300, lr=0.000104542, gnorm=0.332, clip=0, loss_scale=8, train_wall=71, gb_free=13.9, wall=18025
2023-09-06 21:33:05 | INFO | train_inner | epoch 016:    546 / 1191 loss=2.278, trans_loss=5.339, nll_loss=2.719, w2v_ctc_loss=0.576, task_loss=1.507, task_loss_gen=2.675, contrastive_loss=0, total=6693.31, n_correct=3224.52, ppl=6.58, accuracy=48.175, wps=18418.1, ups=1.38, wpb=13386.6, bsz=448.2, num_updates=18400, lr=0.000104257, gnorm=0.319, clip=0, loss_scale=8, train_wall=72, gb_free=13.6, wall=18098
2023-09-06 21:34:18 | INFO | train_inner | epoch 016:    646 / 1191 loss=2.275, trans_loss=5.339, nll_loss=2.718, w2v_ctc_loss=0.574, task_loss=1.513, task_loss_gen=2.671, contrastive_loss=0, total=6708.08, n_correct=3245.27, ppl=6.58, accuracy=48.379, wps=18341.1, ups=1.37, wpb=13416.2, bsz=457.7, num_updates=18500, lr=0.000103975, gnorm=0.322, clip=0, loss_scale=8, train_wall=72, gb_free=13.9, wall=18171
2023-09-06 21:35:31 | INFO | train_inner | epoch 016:    746 / 1191 loss=2.278, trans_loss=5.336, nll_loss=2.715, w2v_ctc_loss=0.579, task_loss=1.378, task_loss_gen=2.843, contrastive_loss=0, total=6642.59, n_correct=3206.86, ppl=6.57, accuracy=48.277, wps=18286.2, ups=1.38, wpb=13285.2, bsz=441.6, num_updates=18600, lr=0.000103695, gnorm=0.315, clip=0, loss_scale=8, train_wall=72, gb_free=13.1, wall=18244
2023-09-06 21:36:43 | INFO | train_inner | epoch 016:    846 / 1191 loss=2.283, trans_loss=5.347, nll_loss=2.729, w2v_ctc_loss=0.584, task_loss=2.061, task_loss_gen=3.032, contrastive_loss=0, total=6704.89, n_correct=3229.51, ppl=6.63, accuracy=48.166, wps=18487.5, ups=1.38, wpb=13409.8, bsz=444.3, num_updates=18700, lr=0.000103418, gnorm=0.379, clip=0, loss_scale=8, train_wall=72, gb_free=12.6, wall=18316
2023-09-06 21:37:56 | INFO | train_inner | epoch 016:    946 / 1191 loss=2.271, trans_loss=5.337, nll_loss=2.716, w2v_ctc_loss=0.573, task_loss=1.498, task_loss_gen=2.545, contrastive_loss=0, total=6714.17, n_correct=3252.59, ppl=6.57, accuracy=48.444, wps=18473, ups=1.38, wpb=13428.3, bsz=462.4, num_updates=18800, lr=0.000103142, gnorm=0.319, clip=0, loss_scale=8, train_wall=72, gb_free=13.5, wall=18389
2023-09-06 21:39:09 | INFO | train_inner | epoch 016:   1046 / 1191 loss=2.275, trans_loss=5.333, nll_loss=2.712, w2v_ctc_loss=0.586, task_loss=1.37, task_loss_gen=2.712, contrastive_loss=0, total=6686.6, n_correct=3237.39, ppl=6.55, accuracy=48.416, wps=18354.7, ups=1.37, wpb=13373.2, bsz=457.2, num_updates=18900, lr=0.000102869, gnorm=0.324, clip=0, loss_scale=8, train_wall=72, gb_free=14.4, wall=18462
2023-09-06 21:40:22 | INFO | train_inner | epoch 016:   1146 / 1191 loss=2.267, trans_loss=5.331, nll_loss=2.71, w2v_ctc_loss=0.581, task_loss=1.598, task_loss_gen=2.512, contrastive_loss=0, total=6800.1, n_correct=3309.31, ppl=6.54, accuracy=48.666, wps=18614.2, ups=1.37, wpb=13600.2, bsz=478.8, num_updates=19000, lr=0.000102598, gnorm=0.336, clip=0, loss_scale=8, train_wall=72, gb_free=13.9, wall=18535
2023-09-06 21:40:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 21:41:29 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.569 | trans_loss 6.238 | nll_loss 3.814 | w2v_ctc_loss 1.134 | task_loss 13.438 | task_loss_gen 8.561 | contrastive_loss 0 | total 6138.43 | n_correct 2951.29 | ppl 14.06 | accuracy 48.079 | uer 17.046 | wer 18.713 | raw_wer 18.713 | bleu 4.17 | wps 1565.3 | wpb 6138.4 | bsz 201.1 | num_updates 19045 | best_bleu 4.17
2023-09-06 21:41:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 19045 updates
2023-09-06 21:41:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 21:41:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 21:41:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 16 @ 19045 updates, score 4.17) (writing took 12.78537913504988 seconds)
2023-09-06 21:41:43 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-09-06 21:41:43 | INFO | train | epoch 016 | loss 2.277 | trans_loss 5.339 | nll_loss 2.72 | w2v_ctc_loss 0.577 | task_loss 1.579 | task_loss_gen 2.705 | contrastive_loss 0 | total 6703.69 | n_correct 3237.47 | ppl 6.59 | accuracy 48.294 | wps 16435.5 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 19045 | lr 0.000102477 | gnorm 0.33 | clip 0 | loss_scale 8 | train_wall 854 | gb_free 13.4 | wall 18616
2023-09-06 21:41:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 21:41:43 | INFO | fairseq.trainer | begin training epoch 17
2023-09-06 21:41:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 21:42:31 | INFO | train_inner | epoch 017:     55 / 1191 loss=2.273, trans_loss=5.334, nll_loss=2.712, w2v_ctc_loss=0.57, task_loss=1.806, task_loss_gen=2.901, contrastive_loss=0, total=6603.02, n_correct=3191.93, ppl=6.55, accuracy=48.34, wps=10250.3, ups=0.78, wpb=13206, bsz=437.5, num_updates=19100, lr=0.000102329, gnorm=0.35, clip=0, loss_scale=8, train_wall=71, gb_free=10.1, wall=18664
2023-09-06 21:43:43 | INFO | train_inner | epoch 017:    155 / 1191 loss=2.263, trans_loss=5.321, nll_loss=2.696, w2v_ctc_loss=0.564, task_loss=1.63, task_loss_gen=2.665, contrastive_loss=0, total=6700.4, n_correct=3259.61, ppl=6.48, accuracy=48.648, wps=18553.5, ups=1.38, wpb=13400.8, bsz=452.7, num_updates=19200, lr=0.000102062, gnorm=0.322, clip=0, loss_scale=8, train_wall=71, gb_free=14.2, wall=18736
2023-09-06 21:44:56 | INFO | train_inner | epoch 017:    255 / 1191 loss=2.258, trans_loss=5.31, nll_loss=2.682, w2v_ctc_loss=0.57, task_loss=1.472, task_loss_gen=2.532, contrastive_loss=0, total=6816.25, n_correct=3340.77, ppl=6.42, accuracy=49.012, wps=18654.7, ups=1.37, wpb=13632.5, bsz=472.6, num_updates=19300, lr=0.000101797, gnorm=0.324, clip=0, loss_scale=8, train_wall=72, gb_free=10.4, wall=18809
2023-09-06 21:46:08 | INFO | train_inner | epoch 017:    355 / 1191 loss=2.269, trans_loss=5.327, nll_loss=2.703, w2v_ctc_loss=0.574, task_loss=1.78, task_loss_gen=2.809, contrastive_loss=0, total=6649.09, n_correct=3227.65, ppl=6.51, accuracy=48.543, wps=18493.7, ups=1.39, wpb=13298.2, bsz=444.3, num_updates=19400, lr=0.000101535, gnorm=0.346, clip=0, loss_scale=8, train_wall=71, gb_free=10.9, wall=18881
2023-09-06 21:47:21 | INFO | train_inner | epoch 017:    455 / 1191 loss=2.271, trans_loss=5.327, nll_loss=2.703, w2v_ctc_loss=0.573, task_loss=1.637, task_loss_gen=2.801, contrastive_loss=0, total=6687.8, n_correct=3243.71, ppl=6.51, accuracy=48.502, wps=18371.8, ups=1.37, wpb=13375.6, bsz=441.3, num_updates=19500, lr=0.000101274, gnorm=0.34, clip=0, loss_scale=8, train_wall=72, gb_free=14.4, wall=18954
2023-09-06 21:48:33 | INFO | train_inner | epoch 017:    555 / 1191 loss=2.272, trans_loss=5.333, nll_loss=2.71, w2v_ctc_loss=0.571, task_loss=1.741, task_loss_gen=2.661, contrastive_loss=0, total=6693.58, n_correct=3239.39, ppl=6.55, accuracy=48.395, wps=18450.2, ups=1.38, wpb=13387.2, bsz=444.4, num_updates=19600, lr=0.000101015, gnorm=0.333, clip=0, loss_scale=8, train_wall=71, gb_free=12.9, wall=19026
2023-09-06 21:49:45 | INFO | train_inner | epoch 017:    655 / 1191 loss=2.261, trans_loss=5.317, nll_loss=2.69, w2v_ctc_loss=0.569, task_loss=1.415, task_loss_gen=2.662, contrastive_loss=0, total=6685.1, n_correct=3265.97, ppl=6.45, accuracy=48.854, wps=18630.2, ups=1.39, wpb=13370.2, bsz=457.9, num_updates=19700, lr=0.000100759, gnorm=0.322, clip=0, loss_scale=8, train_wall=71, gb_free=14.4, wall=19098
2023-09-06 21:50:57 | INFO | train_inner | epoch 017:    755 / 1191 loss=2.278, trans_loss=5.337, nll_loss=2.716, w2v_ctc_loss=0.577, task_loss=1.779, task_loss_gen=3.107, contrastive_loss=0, total=6657.34, n_correct=3210.88, ppl=6.57, accuracy=48.231, wps=18347.8, ups=1.38, wpb=13314.7, bsz=430.7, num_updates=19800, lr=0.000100504, gnorm=0.347, clip=0, loss_scale=16, train_wall=72, gb_free=14.4, wall=19170
2023-09-06 21:52:11 | INFO | train_inner | epoch 017:    855 / 1191 loss=2.271, trans_loss=5.326, nll_loss=2.702, w2v_ctc_loss=0.575, task_loss=1.296, task_loss_gen=3.107, contrastive_loss=0, total=6624.99, n_correct=3220, ppl=6.51, accuracy=48.604, wps=18090.2, ups=1.37, wpb=13250, bsz=439.4, num_updates=19900, lr=0.000100251, gnorm=0.313, clip=0, loss_scale=16, train_wall=72, gb_free=10.6, wall=19244
2023-09-06 21:53:23 | INFO | train_inner | epoch 017:    955 / 1191 loss=2.243, trans_loss=5.302, nll_loss=2.672, w2v_ctc_loss=0.556, task_loss=0.984, task_loss_gen=2.794, contrastive_loss=0, total=6791.83, n_correct=3349.87, ppl=6.37, accuracy=49.322, wps=18720.8, ups=1.38, wpb=13583.7, bsz=493.5, num_updates=20000, lr=0.0001, gnorm=0.314, clip=0, loss_scale=16, train_wall=71, gb_free=14.1, wall=19316
2023-09-06 21:53:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 21:53:59 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.578 | trans_loss 6.224 | nll_loss 3.794 | w2v_ctc_loss 1.198 | task_loss 19.615 | task_loss_gen 10.846 | contrastive_loss 0 | total 6138.43 | n_correct 2956.29 | ppl 13.87 | accuracy 48.16 | uer 16.872 | wer 18.769 | raw_wer 18.769 | bleu 4.33 | wps 1537.4 | wpb 6138.4 | bsz 201.1 | num_updates 20000 | best_bleu 4.33
2023-09-06 21:53:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20000 updates
2023-09-06 21:53:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_17_20000.pt
2023-09-06 21:54:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_17_20000.pt
2023-09-06 21:54:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_17_20000.pt (epoch 17 @ 20000 updates, score 4.33) (writing took 11.452090620063245 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:0')
2023-09-06 21:55:23 | INFO | train_inner | epoch 017:   1055 / 1191 loss=2.263, trans_loss=5.316, nll_loss=2.689, w2v_ctc_loss=0.569, task_loss=1.09, task_loss_gen=3.192, contrastive_loss=0, total=6662.74, n_correct=3245.37, ppl=6.45, accuracy=48.709, wps=11112.7, ups=0.83, wpb=13325.5, bsz=442.7, num_updates=20100, lr=9.97509e-05, gnorm=0.314, clip=0, loss_scale=16, train_wall=71, gb_free=12.3, wall=19436
2023-09-06 21:56:36 | INFO | train_inner | epoch 017:   1155 / 1191 loss=2.262, trans_loss=5.315, nll_loss=2.688, w2v_ctc_loss=0.573, task_loss=0.967, task_loss_gen=3.26, contrastive_loss=0, total=6776.47, n_correct=3313.09, ppl=6.44, accuracy=48.891, wps=18671.3, ups=1.38, wpb=13552.9, bsz=456, num_updates=20200, lr=9.95037e-05, gnorm=0.31, clip=0, loss_scale=16, train_wall=72, gb_free=11.7, wall=19509
2023-09-06 21:57:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:4')
2023-09-06 21:57:38 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.558 | trans_loss 6.217 | nll_loss 3.786 | w2v_ctc_loss 1.147 | task_loss 12.604 | task_loss_gen 8.453 | contrastive_loss 0 | total 6138.43 | n_correct 2972.29 | ppl 13.79 | accuracy 48.421 | uer 16.738 | wer 18.672 | raw_wer 18.672 | bleu 4.37 | wps 1550.6 | wpb 6138.4 | bsz 201.1 | num_updates 20236 | best_bleu 4.37
2023-09-06 21:57:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 20236 updates
2023-09-06 21:57:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 21:57:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 21:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 17 @ 20236 updates, score 4.37) (writing took 12.028859582031146 seconds)
2023-09-06 21:57:50 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-09-06 21:57:50 | INFO | train | epoch 017 | loss 2.264 | trans_loss 5.321 | nll_loss 2.696 | w2v_ctc_loss 0.57 | task_loss 1.426 | task_loss_gen 2.869 | contrastive_loss 0 | total 6703.69 | n_correct 3264.66 | ppl 6.48 | accuracy 48.699 | wps 16501.7 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 20236 | lr 9.94152e-05 | gnorm 0.326 | clip 0 | loss_scale 16 | train_wall 852 | gb_free 14.2 | wall 19583
2023-09-06 21:57:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 21:57:50 | INFO | fairseq.trainer | begin training epoch 18
2023-09-06 21:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 21:58:44 | INFO | train_inner | epoch 018:     64 / 1191 loss=2.247, trans_loss=5.3, nll_loss=2.668, w2v_ctc_loss=0.552, task_loss=1.254, task_loss_gen=2.981, contrastive_loss=0, total=6805.63, n_correct=3345.01, ppl=6.36, accuracy=49.151, wps=10590.7, ups=0.78, wpb=13611.3, bsz=465.5, num_updates=20300, lr=9.92583e-05, gnorm=0.324, clip=0, loss_scale=16, train_wall=71, gb_free=13.3, wall=19637
2023-09-06 21:59:57 | INFO | train_inner | epoch 018:    164 / 1191 loss=2.272, trans_loss=5.324, nll_loss=2.699, w2v_ctc_loss=0.571, task_loss=2.175, task_loss_gen=3.114, contrastive_loss=0, total=6620.89, n_correct=3207.17, ppl=6.49, accuracy=48.44, wps=18105.1, ups=1.37, wpb=13241.8, bsz=419, num_updates=20400, lr=9.90148e-05, gnorm=0.332, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=19710
2023-09-06 22:01:10 | INFO | train_inner | epoch 018:    264 / 1191 loss=2.254, trans_loss=5.308, nll_loss=2.678, w2v_ctc_loss=0.56, task_loss=1.519, task_loss_gen=2.794, contrastive_loss=0, total=6622.15, n_correct=3245.73, ppl=6.4, accuracy=49.013, wps=18203.4, ups=1.37, wpb=13244.3, bsz=447.2, num_updates=20500, lr=9.8773e-05, gnorm=0.318, clip=0, loss_scale=16, train_wall=72, gb_free=14.8, wall=19783
2023-09-06 22:02:23 | INFO | train_inner | epoch 018:    364 / 1191 loss=2.249, trans_loss=5.3, nll_loss=2.668, w2v_ctc_loss=0.56, task_loss=1.282, task_loss_gen=2.814, contrastive_loss=0, total=6736.36, n_correct=3312.73, ppl=6.35, accuracy=49.177, wps=18514.9, ups=1.37, wpb=13472.7, bsz=459.4, num_updates=20600, lr=9.85329e-05, gnorm=0.314, clip=0, loss_scale=16, train_wall=72, gb_free=13.1, wall=19856
2023-09-06 22:03:35 | INFO | train_inner | epoch 018:    464 / 1191 loss=2.249, trans_loss=5.304, nll_loss=2.673, w2v_ctc_loss=0.555, task_loss=1.352, task_loss_gen=3.188, contrastive_loss=0, total=6698.43, n_correct=3294.43, ppl=6.38, accuracy=49.182, wps=18527, ups=1.38, wpb=13396.9, bsz=454.4, num_updates=20700, lr=9.82946e-05, gnorm=0.327, clip=0, loss_scale=16, train_wall=71, gb_free=12, wall=19928
2023-09-06 22:04:47 | INFO | train_inner | epoch 018:    564 / 1191 loss=2.241, trans_loss=5.293, nll_loss=2.658, w2v_ctc_loss=0.558, task_loss=1.228, task_loss_gen=2.638, contrastive_loss=0, total=6847.61, n_correct=3387.28, ppl=6.31, accuracy=49.467, wps=19076.6, ups=1.39, wpb=13695.2, bsz=483.1, num_updates=20800, lr=9.80581e-05, gnorm=0.317, clip=0, loss_scale=16, train_wall=71, gb_free=11.7, wall=20000
2023-09-06 22:05:59 | INFO | train_inner | epoch 018:    664 / 1191 loss=2.262, trans_loss=5.311, nll_loss=2.682, w2v_ctc_loss=0.566, task_loss=1.305, task_loss_gen=3.254, contrastive_loss=0, total=6562.52, n_correct=3200.2, ppl=6.42, accuracy=48.765, wps=18185.9, ups=1.39, wpb=13125, bsz=426.3, num_updates=20900, lr=9.78232e-05, gnorm=0.323, clip=0, loss_scale=16, train_wall=71, gb_free=13.2, wall=20072
2023-09-06 22:07:13 | INFO | train_inner | epoch 018:    764 / 1191 loss=2.246, trans_loss=5.301, nll_loss=2.669, w2v_ctc_loss=0.56, task_loss=1.261, task_loss_gen=2.892, contrastive_loss=0, total=6829.65, n_correct=3365.63, ppl=6.36, accuracy=49.28, wps=18627.7, ups=1.36, wpb=13659.3, bsz=472.1, num_updates=21000, lr=9.759e-05, gnorm=0.321, clip=0, loss_scale=16, train_wall=72, gb_free=13.4, wall=20146
2023-09-06 22:08:26 | INFO | train_inner | epoch 018:    864 / 1191 loss=2.259, trans_loss=5.311, nll_loss=2.681, w2v_ctc_loss=0.569, task_loss=1.437, task_loss_gen=3.061, contrastive_loss=0, total=6699.72, n_correct=3279.65, ppl=6.41, accuracy=48.952, wps=18281, ups=1.36, wpb=13399.4, bsz=449, num_updates=21100, lr=9.73585e-05, gnorm=0.322, clip=0, loss_scale=16, train_wall=72, gb_free=13.5, wall=20219
2023-09-06 22:09:38 | INFO | train_inner | epoch 018:    964 / 1191 loss=2.249, trans_loss=5.298, nll_loss=2.665, w2v_ctc_loss=0.565, task_loss=1.429, task_loss_gen=2.697, contrastive_loss=0, total=6735.73, n_correct=3316.87, ppl=6.34, accuracy=49.243, wps=18711.5, ups=1.39, wpb=13471.5, bsz=459.4, num_updates=21200, lr=9.71286e-05, gnorm=0.319, clip=0, loss_scale=16, train_wall=71, gb_free=13.6, wall=20291
2023-09-06 22:10:50 | INFO | train_inner | epoch 018:   1064 / 1191 loss=2.26, trans_loss=5.311, nll_loss=2.682, w2v_ctc_loss=0.567, task_loss=1.356, task_loss_gen=3.148, contrastive_loss=0, total=6578.5, n_correct=3214.85, ppl=6.42, accuracy=48.869, wps=18299, ups=1.39, wpb=13157, bsz=432.2, num_updates=21300, lr=9.69003e-05, gnorm=0.315, clip=0, loss_scale=16, train_wall=71, gb_free=14.1, wall=20363
2023-09-06 22:12:03 | INFO | train_inner | epoch 018:   1164 / 1191 loss=2.251, trans_loss=5.298, nll_loss=2.666, w2v_ctc_loss=0.57, task_loss=1.26, task_loss_gen=2.886, contrastive_loss=0, total=6752.19, n_correct=3327.21, ppl=6.35, accuracy=49.276, wps=18510, ups=1.37, wpb=13504.4, bsz=463.4, num_updates=21400, lr=9.66736e-05, gnorm=0.315, clip=0, loss_scale=16, train_wall=72, gb_free=13.7, wall=20436
2023-09-06 22:12:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 22:12:59 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.566 | trans_loss 6.206 | nll_loss 3.77 | w2v_ctc_loss 1.199 | task_loss 8.787 | task_loss_gen 7.508 | contrastive_loss 0 | total 6138.43 | n_correct 2991.43 | ppl 13.65 | accuracy 48.733 | uer 17.014 | wer 18.851 | raw_wer 18.851 | bleu 4.71 | wps 1489.2 | wpb 6138.4 | bsz 201.1 | num_updates 21427 | best_bleu 4.71
2023-09-06 22:12:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 21427 updates
2023-09-06 22:12:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 22:13:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 22:13:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 18 @ 21427 updates, score 4.71) (writing took 12.998100109049119 seconds)
2023-09-06 22:13:12 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-09-06 22:13:12 | INFO | train | epoch 018 | loss 2.253 | trans_loss 5.304 | nll_loss 2.673 | w2v_ctc_loss 0.562 | task_loss 1.399 | task_loss_gen 2.946 | contrastive_loss 0 | total 6703.69 | n_correct 3290 | ppl 6.38 | accuracy 49.077 | wps 17318.2 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 21427 | lr 9.66127e-05 | gnorm 0.321 | clip 0 | loss_scale 16 | train_wall 852 | gb_free 13.8 | wall 20505
2023-09-06 22:13:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 22:13:12 | INFO | fairseq.trainer | begin training epoch 19
2023-09-06 22:13:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 22:14:14 | INFO | train_inner | epoch 019:     73 / 1191 loss=2.251, trans_loss=5.299, nll_loss=2.666, w2v_ctc_loss=0.554, task_loss=1.228, task_loss_gen=3.186, contrastive_loss=0, total=6605.34, n_correct=3241.15, ppl=6.35, accuracy=49.069, wps=10088, ups=0.76, wpb=13210.7, bsz=428.3, num_updates=21500, lr=9.64486e-05, gnorm=0.32, clip=0, loss_scale=16, train_wall=72, gb_free=12.8, wall=20567
2023-09-06 22:15:26 | INFO | train_inner | epoch 019:    173 / 1191 loss=2.239, trans_loss=5.285, nll_loss=2.647, w2v_ctc_loss=0.549, task_loss=1.703, task_loss_gen=3.103, contrastive_loss=0, total=6678.53, n_correct=3308.4, ppl=6.27, accuracy=49.538, wps=18509.6, ups=1.39, wpb=13357.1, bsz=446.3, num_updates=21600, lr=9.6225e-05, gnorm=0.339, clip=0, loss_scale=16, train_wall=71, gb_free=14.3, wall=20639
2023-09-06 22:16:39 | INFO | train_inner | epoch 019:    273 / 1191 loss=2.236, trans_loss=5.28, nll_loss=2.641, w2v_ctc_loss=0.549, task_loss=1.549, task_loss_gen=2.769, contrastive_loss=0, total=6755.84, n_correct=3351.54, ppl=6.24, accuracy=49.61, wps=18561.1, ups=1.37, wpb=13511.7, bsz=461.2, num_updates=21700, lr=9.60031e-05, gnorm=0.319, clip=0, loss_scale=16, train_wall=72, gb_free=14.2, wall=20712
2023-09-06 22:17:51 | INFO | train_inner | epoch 019:    373 / 1191 loss=2.241, trans_loss=5.291, nll_loss=2.655, w2v_ctc_loss=0.546, task_loss=1.313, task_loss_gen=2.884, contrastive_loss=0, total=6694.87, n_correct=3301.98, ppl=6.3, accuracy=49.321, wps=18638.2, ups=1.39, wpb=13389.7, bsz=445.4, num_updates=21800, lr=9.57826e-05, gnorm=0.315, clip=0, loss_scale=16, train_wall=71, gb_free=11.8, wall=20784
2023-09-06 22:19:03 | INFO | train_inner | epoch 019:    473 / 1191 loss=2.233, trans_loss=5.282, nll_loss=2.644, w2v_ctc_loss=0.551, task_loss=1.282, task_loss_gen=2.758, contrastive_loss=0, total=6790.32, n_correct=3374.31, ppl=6.25, accuracy=49.693, wps=18733.9, ups=1.38, wpb=13580.6, bsz=478.7, num_updates=21900, lr=9.55637e-05, gnorm=0.32, clip=0, loss_scale=32, train_wall=72, gb_free=12, wall=20856
2023-09-06 22:20:17 | INFO | train_inner | epoch 019:    573 / 1191 loss=2.243, trans_loss=5.292, nll_loss=2.656, w2v_ctc_loss=0.566, task_loss=0.959, task_loss_gen=3.411, contrastive_loss=0, total=6753.74, n_correct=3342.97, ppl=6.3, accuracy=49.498, wps=18376.1, ups=1.36, wpb=13507.5, bsz=462.6, num_updates=22000, lr=9.53463e-05, gnorm=0.314, clip=0, loss_scale=32, train_wall=72, gb_free=11.5, wall=20930
2023-09-06 22:20:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 22:20:53 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.546 | trans_loss 6.197 | nll_loss 3.753 | w2v_ctc_loss 1.153 | task_loss 5.137 | task_loss_gen 7.477 | contrastive_loss 0 | total 6138.43 | n_correct 2987.14 | ppl 13.49 | accuracy 48.663 | uer 16.583 | wer 18.494 | raw_wer 18.494 | bleu 4.55 | wps 1501.7 | wpb 6138.4 | bsz 201.1 | num_updates 22000 | best_bleu 4.71
2023-09-06 22:20:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22000 updates
2023-09-06 22:20:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_19_22000.pt
2023-09-06 22:20:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_19_22000.pt
2023-09-06 22:21:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_19_22000.pt (epoch 19 @ 22000 updates, score 4.55) (writing took 7.14419174590148 seconds)
2023-09-06 22:22:13 | INFO | train_inner | epoch 019:    673 / 1191 loss=2.24, trans_loss=5.285, nll_loss=2.648, w2v_ctc_loss=0.55, task_loss=1.129, task_loss_gen=3.589, contrastive_loss=0, total=6649.95, n_correct=3291.58, ppl=6.27, accuracy=49.498, wps=11443.1, ups=0.86, wpb=13299.9, bsz=451.5, num_updates=22100, lr=9.51303e-05, gnorm=0.317, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=21046
2023-09-06 22:23:25 | INFO | train_inner | epoch 019:    773 / 1191 loss=2.241, trans_loss=5.284, nll_loss=2.647, w2v_ctc_loss=0.561, task_loss=1.061, task_loss_gen=3.361, contrastive_loss=0, total=6758.75, n_correct=3348.67, ppl=6.26, accuracy=49.546, wps=18640.2, ups=1.38, wpb=13517.5, bsz=461.1, num_updates=22200, lr=9.49158e-05, gnorm=0.313, clip=0, loss_scale=32, train_wall=72, gb_free=11.7, wall=21118
2023-09-06 22:24:38 | INFO | train_inner | epoch 019:    873 / 1191 loss=2.251, trans_loss=5.295, nll_loss=2.661, w2v_ctc_loss=0.562, task_loss=0.927, task_loss_gen=3.769, contrastive_loss=0, total=6623.8, n_correct=3260.27, ppl=6.33, accuracy=49.221, wps=18278.4, ups=1.38, wpb=13247.6, bsz=440.7, num_updates=22300, lr=9.47027e-05, gnorm=0.312, clip=0, loss_scale=32, train_wall=71, gb_free=14.3, wall=21191
2023-09-06 22:25:50 | INFO | train_inner | epoch 019:    973 / 1191 loss=2.248, trans_loss=5.29, nll_loss=2.654, w2v_ctc_loss=0.561, task_loss=1.48, task_loss_gen=3.296, contrastive_loss=0, total=6611.17, n_correct=3257.13, ppl=6.29, accuracy=49.267, wps=18326.1, ups=1.39, wpb=13222.3, bsz=434.3, num_updates=22400, lr=9.44911e-05, gnorm=0.315, clip=0, loss_scale=32, train_wall=71, gb_free=13.1, wall=21263
2023-09-06 22:27:02 | INFO | train_inner | epoch 019:   1073 / 1191 loss=2.241, trans_loss=5.287, nll_loss=2.651, w2v_ctc_loss=0.552, task_loss=0.951, task_loss_gen=3.283, contrastive_loss=0, total=6738.74, n_correct=3336.33, ppl=6.28, accuracy=49.51, wps=18580.5, ups=1.38, wpb=13477.5, bsz=455.1, num_updates=22500, lr=9.42809e-05, gnorm=0.311, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=21335
2023-09-06 22:28:16 | INFO | train_inner | epoch 019:   1173 / 1191 loss=2.244, trans_loss=5.297, nll_loss=2.663, w2v_ctc_loss=0.555, task_loss=0.947, task_loss_gen=3.675, contrastive_loss=0, total=6789.71, n_correct=3348.97, ppl=6.33, accuracy=49.324, wps=18502.6, ups=1.36, wpb=13579.4, bsz=457.9, num_updates=22600, lr=9.40721e-05, gnorm=0.309, clip=0, loss_scale=32, train_wall=73, gb_free=14.2, wall=21409
2023-09-06 22:28:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 22:29:06 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.566 | trans_loss 6.191 | nll_loss 3.742 | w2v_ctc_loss 1.231 | task_loss 7.748 | task_loss_gen 8.799 | contrastive_loss 0 | total 6138.43 | n_correct 2998.71 | ppl 13.38 | accuracy 48.851 | uer 16.856 | wer 18.617 | raw_wer 18.617 | bleu 4.81 | wps 1451.6 | wpb 6138.4 | bsz 201.1 | num_updates 22618 | best_bleu 4.81
2023-09-06 22:29:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 22618 updates
2023-09-06 22:29:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 22:29:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 22:29:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 19 @ 22618 updates, score 4.81) (writing took 14.166213857010007 seconds)
2023-09-06 22:29:21 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-09-06 22:29:21 | INFO | train | epoch 019 | loss 2.242 | trans_loss 5.289 | nll_loss 2.653 | w2v_ctc_loss 0.555 | task_loss 1.205 | task_loss_gen 3.279 | contrastive_loss 0 | total 6703.69 | n_correct 3314.07 | ppl 6.29 | accuracy 49.436 | wps 16492 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 22618 | lr 9.40346e-05 | gnorm 0.317 | clip 0 | loss_scale 32 | train_wall 855 | gb_free 14.3 | wall 21474
2023-09-06 22:29:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 22:29:21 | INFO | fairseq.trainer | begin training epoch 20
2023-09-06 22:29:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 22:30:28 | INFO | train_inner | epoch 020:     82 / 1191 loss=2.232, trans_loss=5.272, nll_loss=2.631, w2v_ctc_loss=0.547, task_loss=0.83, task_loss_gen=3.974, contrastive_loss=0, total=6693.71, n_correct=3328.49, ppl=6.19, accuracy=49.726, wps=10147.7, ups=0.76, wpb=13387.4, bsz=451.9, num_updates=22700, lr=9.38647e-05, gnorm=0.321, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=21541
2023-09-06 22:31:40 | INFO | train_inner | epoch 020:    182 / 1191 loss=2.236, trans_loss=5.274, nll_loss=2.633, w2v_ctc_loss=0.549, task_loss=0.715, task_loss_gen=4.399, contrastive_loss=0, total=6599.88, n_correct=3274.22, ppl=6.2, accuracy=49.61, wps=18327.3, ups=1.39, wpb=13199.8, bsz=438.3, num_updates=22800, lr=9.36586e-05, gnorm=0.314, clip=0, loss_scale=32, train_wall=71, gb_free=14.9, wall=21613
2023-09-06 22:32:52 | INFO | train_inner | epoch 020:    282 / 1191 loss=2.235, trans_loss=5.279, nll_loss=2.639, w2v_ctc_loss=0.551, task_loss=0.829, task_loss_gen=4.059, contrastive_loss=0, total=6767.67, n_correct=3368.48, ppl=6.23, accuracy=49.773, wps=18686.6, ups=1.38, wpb=13535.3, bsz=457.2, num_updates=22900, lr=9.34539e-05, gnorm=0.322, clip=0, loss_scale=32, train_wall=72, gb_free=12.6, wall=21685
2023-09-06 22:34:05 | INFO | train_inner | epoch 020:    382 / 1191 loss=2.226, trans_loss=5.27, nll_loss=2.627, w2v_ctc_loss=0.547, task_loss=1.059, task_loss_gen=3.198, contrastive_loss=0, total=6794.56, n_correct=3396.88, ppl=6.18, accuracy=49.994, wps=18736, ups=1.38, wpb=13589.1, bsz=468.7, num_updates=23000, lr=9.32505e-05, gnorm=0.317, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=21758
2023-09-06 22:35:17 | INFO | train_inner | epoch 020:    482 / 1191 loss=2.233, trans_loss=5.273, nll_loss=2.632, w2v_ctc_loss=0.546, task_loss=0.686, task_loss_gen=4.191, contrastive_loss=0, total=6694, n_correct=3324.66, ppl=6.2, accuracy=49.666, wps=18476.7, ups=1.38, wpb=13388, bsz=446.1, num_updates=23100, lr=9.30484e-05, gnorm=0.315, clip=0, loss_scale=32, train_wall=72, gb_free=11.6, wall=21830
2023-09-06 22:36:30 | INFO | train_inner | epoch 020:    582 / 1191 loss=2.24, trans_loss=5.281, nll_loss=2.643, w2v_ctc_loss=0.552, task_loss=1.329, task_loss_gen=3.813, contrastive_loss=0, total=6622.52, n_correct=3278.95, ppl=6.25, accuracy=49.512, wps=18160.6, ups=1.37, wpb=13245, bsz=442.4, num_updates=23200, lr=9.28477e-05, gnorm=0.332, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=21903
2023-09-06 22:37:42 | INFO | train_inner | epoch 020:    682 / 1191 loss=2.219, trans_loss=5.264, nll_loss=2.62, w2v_ctc_loss=0.536, task_loss=1.273, task_loss_gen=3.321, contrastive_loss=0, total=6711.24, n_correct=3364.57, ppl=6.15, accuracy=50.133, wps=18727.6, ups=1.4, wpb=13422.5, bsz=470.5, num_updates=23300, lr=9.26482e-05, gnorm=0.321, clip=0, loss_scale=32, train_wall=71, gb_free=13.4, wall=21975
2023-09-06 22:38:54 | INFO | train_inner | epoch 020:    782 / 1191 loss=2.231, trans_loss=5.274, nll_loss=2.633, w2v_ctc_loss=0.549, task_loss=1.041, task_loss_gen=3.474, contrastive_loss=0, total=6749.91, n_correct=3366.99, ppl=6.2, accuracy=49.882, wps=18657.4, ups=1.38, wpb=13499.8, bsz=458.6, num_updates=23400, lr=9.245e-05, gnorm=0.316, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=22047
2023-09-06 22:40:07 | INFO | train_inner | epoch 020:    882 / 1191 loss=2.237, trans_loss=5.278, nll_loss=2.638, w2v_ctc_loss=0.553, task_loss=1.15, task_loss_gen=3.68, contrastive_loss=0, total=6725.15, n_correct=3340.04, ppl=6.23, accuracy=49.665, wps=18525.1, ups=1.38, wpb=13450.3, bsz=447.2, num_updates=23500, lr=9.22531e-05, gnorm=0.32, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=22120
2023-09-06 22:41:21 | INFO | train_inner | epoch 020:    982 / 1191 loss=2.24, trans_loss=5.283, nll_loss=2.645, w2v_ctc_loss=0.548, task_loss=1.074, task_loss_gen=3.868, contrastive_loss=0, total=6666.28, n_correct=3300.19, ppl=6.25, accuracy=49.506, wps=18055.4, ups=1.35, wpb=13332.6, bsz=433.5, num_updates=23600, lr=9.20575e-05, gnorm=0.317, clip=0, loss_scale=32, train_wall=73, gb_free=13.1, wall=22194
2023-09-06 22:42:33 | INFO | train_inner | epoch 020:   1082 / 1191 loss=2.23, trans_loss=5.27, nll_loss=2.628, w2v_ctc_loss=0.555, task_loss=0.883, task_loss_gen=3.905, contrastive_loss=0, total=6748.86, n_correct=3368.69, ppl=6.18, accuracy=49.915, wps=18567.8, ups=1.38, wpb=13497.7, bsz=458, num_updates=23700, lr=9.1863e-05, gnorm=0.316, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=22266
2023-09-06 22:43:47 | INFO | train_inner | epoch 020:   1182 / 1191 loss=2.235, trans_loss=5.28, nll_loss=2.641, w2v_ctc_loss=0.555, task_loss=1.308, task_loss_gen=3.506, contrastive_loss=0, total=6683.47, n_correct=3321.5, ppl=6.24, accuracy=49.697, wps=18262.6, ups=1.37, wpb=13366.9, bsz=452.7, num_updates=23800, lr=9.16698e-05, gnorm=0.325, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=22340
2023-09-06 22:43:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 22:44:33 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.566 | trans_loss 6.177 | nll_loss 3.725 | w2v_ctc_loss 1.264 | task_loss 8.444 | task_loss_gen 8.51 | contrastive_loss 0 | total 6138.43 | n_correct 3009.57 | ppl 13.23 | accuracy 49.028 | uer 16.8 | wer 18.631 | raw_wer 18.631 | bleu 4.75 | wps 1379.6 | wpb 6138.4 | bsz 201.1 | num_updates 23809 | best_bleu 4.81
2023-09-06 22:44:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 23809 updates
2023-09-06 22:44:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_4.7508.pt
2023-09-06 22:44:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_4.7508.pt
2023-09-06 22:44:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_4.7508.pt (epoch 20 @ 23809 updates, score 4.75) (writing took 7.670359301031567 seconds)
2023-09-06 22:44:41 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-09-06 22:44:41 | INFO | train | epoch 020 | loss 2.233 | trans_loss 5.275 | nll_loss 2.634 | w2v_ctc_loss 0.549 | task_loss 1.022 | task_loss_gen 3.766 | contrastive_loss 0 | total 6703.69 | n_correct 3335.68 | ppl 6.21 | accuracy 49.759 | wps 17356 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 23809 | lr 9.16525e-05 | gnorm 0.32 | clip 0 | loss_scale 32 | train_wall 855 | gb_free 15.2 | wall 22394
2023-09-06 22:44:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 22:44:41 | INFO | fairseq.trainer | begin training epoch 21
2023-09-06 22:44:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 22:45:55 | INFO | train_inner | epoch 021:     91 / 1191 loss=2.211, trans_loss=5.251, nll_loss=2.603, w2v_ctc_loss=0.53, task_loss=1.056, task_loss_gen=3.331, contrastive_loss=0, total=6760.63, n_correct=3411.02, ppl=6.07, accuracy=50.454, wps=10551.1, ups=0.78, wpb=13521.3, bsz=474.7, num_updates=23900, lr=9.14779e-05, gnorm=0.313, clip=0, loss_scale=64, train_wall=71, gb_free=12.3, wall=22468
2023-09-06 22:47:07 | INFO | train_inner | epoch 021:    191 / 1191 loss=2.208, trans_loss=5.244, nll_loss=2.594, w2v_ctc_loss=0.532, task_loss=0.841, task_loss_gen=3.568, contrastive_loss=0, total=6783.08, n_correct=3434.1, ppl=6.04, accuracy=50.627, wps=18803.1, ups=1.39, wpb=13566.2, bsz=471.6, num_updates=24000, lr=9.12871e-05, gnorm=0.312, clip=0, loss_scale=64, train_wall=71, gb_free=14, wall=22540
2023-09-06 22:47:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 22:47:42 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.55 | trans_loss 6.181 | nll_loss 3.729 | w2v_ctc_loss 1.203 | task_loss 2.832 | task_loss_gen 10.043 | contrastive_loss 0 | total 6138.43 | n_correct 3010.14 | ppl 13.26 | accuracy 49.038 | uer 16.693 | wer 18.393 | raw_wer 18.393 | bleu 4.89 | wps 1548.8 | wpb 6138.4 | bsz 201.1 | num_updates 24000 | best_bleu 4.89
2023-09-06 22:47:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 24000 updates
2023-09-06 22:47:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_21_24000.pt
2023-09-06 22:47:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_21_24000.pt
2023-09-06 22:47:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_21_24000.pt (epoch 21 @ 24000 updates, score 4.89) (writing took 12.459696164936759 seconds)
2023-09-06 22:49:07 | INFO | train_inner | epoch 021:    291 / 1191 loss=2.226, trans_loss=5.262, nll_loss=2.617, w2v_ctc_loss=0.538, task_loss=0.623, task_loss_gen=5.053, contrastive_loss=0, total=6641.78, n_correct=3320.17, ppl=6.14, accuracy=49.989, wps=11016.6, ups=0.83, wpb=13283.6, bsz=436, num_updates=24100, lr=9.10975e-05, gnorm=0.314, clip=0, loss_scale=64, train_wall=71, gb_free=15.2, wall=22660
2023-09-06 22:50:20 | INFO | train_inner | epoch 021:    391 / 1191 loss=2.22, trans_loss=5.261, nll_loss=2.616, w2v_ctc_loss=0.536, task_loss=0.878, task_loss_gen=4.174, contrastive_loss=0, total=6675.38, n_correct=3345.72, ppl=6.13, accuracy=50.12, wps=18403.4, ups=1.38, wpb=13350.8, bsz=450.4, num_updates=24200, lr=9.09091e-05, gnorm=0.315, clip=0, loss_scale=64, train_wall=72, gb_free=12.4, wall=22733
2023-09-06 22:51:33 | INFO | train_inner | epoch 021:    491 / 1191 loss=2.228, trans_loss=5.263, nll_loss=2.618, w2v_ctc_loss=0.541, task_loss=0.68, task_loss_gen=4.858, contrastive_loss=0, total=6679.69, n_correct=3330.1, ppl=6.14, accuracy=49.854, wps=18307.2, ups=1.37, wpb=13359.4, bsz=437.8, num_updates=24300, lr=9.07218e-05, gnorm=0.319, clip=0, loss_scale=64, train_wall=72, gb_free=13, wall=22806
2023-09-06 22:52:45 | INFO | train_inner | epoch 021:    591 / 1191 loss=2.239, trans_loss=5.275, nll_loss=2.633, w2v_ctc_loss=0.552, task_loss=0.799, task_loss_gen=5.061, contrastive_loss=0, total=6618.89, n_correct=3284.18, ppl=6.2, accuracy=49.618, wps=18363.8, ups=1.39, wpb=13237.8, bsz=424, num_updates=24400, lr=9.05357e-05, gnorm=0.321, clip=0, loss_scale=64, train_wall=71, gb_free=12.8, wall=22878
2023-09-06 22:53:58 | INFO | train_inner | epoch 021:    691 / 1191 loss=2.222, trans_loss=5.26, nll_loss=2.616, w2v_ctc_loss=0.548, task_loss=0.636, task_loss_gen=4.352, contrastive_loss=0, total=6724.83, n_correct=3377.09, ppl=6.13, accuracy=50.218, wps=18407.8, ups=1.37, wpb=13449.7, bsz=465.4, num_updates=24500, lr=9.03508e-05, gnorm=0.321, clip=0, loss_scale=64, train_wall=72, gb_free=7.4, wall=22951
2023-09-06 22:55:11 | INFO | train_inner | epoch 021:    791 / 1191 loss=2.226, trans_loss=5.265, nll_loss=2.621, w2v_ctc_loss=0.542, task_loss=0.625, task_loss_gen=5.358, contrastive_loss=0, total=6629.21, n_correct=3312.79, ppl=6.15, accuracy=49.973, wps=18248.2, ups=1.38, wpb=13258.4, bsz=443.8, num_updates=24600, lr=9.0167e-05, gnorm=0.313, clip=0, loss_scale=64, train_wall=72, gb_free=13.4, wall=23024
2023-09-06 22:56:24 | INFO | train_inner | epoch 021:    891 / 1191 loss=2.226, trans_loss=5.261, nll_loss=2.616, w2v_ctc_loss=0.549, task_loss=0.621, task_loss_gen=5.513, contrastive_loss=0, total=6739.57, n_correct=3369.93, ppl=6.13, accuracy=50.002, wps=18406.3, ups=1.37, wpb=13479.1, bsz=453.1, num_updates=24700, lr=8.99843e-05, gnorm=0.318, clip=0, loss_scale=64, train_wall=72, gb_free=14.3, wall=23097
2023-09-06 22:57:37 | INFO | train_inner | epoch 021:    991 / 1191 loss=2.218, trans_loss=5.26, nll_loss=2.615, w2v_ctc_loss=0.539, task_loss=0.443, task_loss_gen=5.598, contrastive_loss=0, total=6793.05, n_correct=3408.83, ppl=6.13, accuracy=50.181, wps=18593.5, ups=1.37, wpb=13586.1, bsz=464, num_updates=24800, lr=8.98027e-05, gnorm=0.316, clip=0, loss_scale=64, train_wall=72, gb_free=11.9, wall=23170
2023-09-06 22:58:50 | INFO | train_inner | epoch 021:   1091 / 1191 loss=2.226, trans_loss=5.264, nll_loss=2.62, w2v_ctc_loss=0.549, task_loss=0.385, task_loss_gen=6.49, contrastive_loss=0, total=6727.98, n_correct=3366.33, ppl=6.15, accuracy=50.035, wps=18510.7, ups=1.38, wpb=13456, bsz=456.2, num_updates=24900, lr=8.96221e-05, gnorm=0.315, clip=0, loss_scale=64, train_wall=72, gb_free=13.8, wall=23243
2023-09-06 23:00:03 | INFO | train_inner | epoch 021:   1191 / 1191 loss=2.224, trans_loss=5.262, nll_loss=2.617, w2v_ctc_loss=0.546, task_loss=0.656, task_loss_gen=5.991, contrastive_loss=0, total=6662.99, n_correct=3336.76, ppl=6.14, accuracy=50.079, wps=18220.8, ups=1.37, wpb=13326, bsz=453.1, num_updates=25000, lr=8.94427e-05, gnorm=0.319, clip=0, loss_scale=64, train_wall=72, gb_free=13.4, wall=23316
2023-09-06 23:00:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 23:00:38 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.545 | trans_loss 6.164 | nll_loss 3.706 | w2v_ctc_loss 1.223 | task_loss 4.431 | task_loss_gen 12.333 | contrastive_loss 0 | total 6138.43 | n_correct 3025.14 | ppl 13.05 | accuracy 49.282 | uer 16.8 | wer 18.602 | raw_wer 18.602 | bleu 5.03 | wps 1528.9 | wpb 6138.4 | bsz 201.1 | num_updates 25000 | best_bleu 5.03
2023-09-06 23:00:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 25000 updates
2023-09-06 23:00:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 23:00:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 23:00:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 21 @ 25000 updates, score 5.03) (writing took 13.206915527000092 seconds)
2023-09-06 23:00:52 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-09-06 23:00:52 | INFO | train | epoch 021 | loss 2.223 | trans_loss 5.261 | nll_loss 2.615 | w2v_ctc_loss 0.542 | task_loss 0.684 | task_loss_gen 4.951 | contrastive_loss 0 | total 6703.69 | n_correct 3358.32 | ppl 6.13 | accuracy 50.097 | wps 16435.7 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 25000 | lr 8.94427e-05 | gnorm 0.316 | clip 0 | loss_scale 64 | train_wall 856 | gb_free 13.4 | wall 23365
2023-09-06 23:00:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 23:00:52 | INFO | fairseq.trainer | begin training epoch 22
2023-09-06 23:00:52 | INFO | fairseq_cli.train | Start iterating over samples
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:0')
2023-09-06 23:02:12 | INFO | train_inner | epoch 022:    100 / 1191 loss=2.205, trans_loss=5.24, nll_loss=2.588, w2v_ctc_loss=0.523, task_loss=0.967, task_loss_gen=4.389, contrastive_loss=0, total=6760.58, n_correct=3423.1, ppl=6.01, accuracy=50.633, wps=10490, ups=0.78, wpb=13521.2, bsz=458.1, num_updates=25100, lr=8.92644e-05, gnorm=0.317, clip=0, loss_scale=64, train_wall=71, gb_free=11.3, wall=23445
2023-09-06 23:03:25 | INFO | train_inner | epoch 022:    200 / 1191 loss=2.217, trans_loss=5.251, nll_loss=2.602, w2v_ctc_loss=0.534, task_loss=0.592, task_loss_gen=5.31, contrastive_loss=0, total=6653.73, n_correct=3341.95, ppl=6.07, accuracy=50.227, wps=18090.9, ups=1.36, wpb=13307.5, bsz=443.7, num_updates=25200, lr=8.90871e-05, gnorm=0.318, clip=0, loss_scale=64, train_wall=73, gb_free=14.6, wall=23518
2023-09-06 23:04:38 | INFO | train_inner | epoch 022:    300 / 1191 loss=2.207, trans_loss=5.24, nll_loss=2.588, w2v_ctc_loss=0.534, task_loss=0.515, task_loss_gen=5.257, contrastive_loss=0, total=6760.38, n_correct=3422.17, ppl=6.01, accuracy=50.621, wps=18663.3, ups=1.38, wpb=13520.8, bsz=468.9, num_updates=25300, lr=8.89108e-05, gnorm=0.318, clip=0, loss_scale=64, train_wall=72, gb_free=13.2, wall=23591
2023-09-06 23:05:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 23:05:52 | INFO | train_inner | epoch 022:    401 / 1191 loss=2.21, trans_loss=5.244, nll_loss=2.594, w2v_ctc_loss=0.536, task_loss=0.534, task_loss_gen=5.918, contrastive_loss=0, total=6662.4, n_correct=3368.77, ppl=6.04, accuracy=50.564, wps=18062.2, ups=1.36, wpb=13324.8, bsz=456.7, num_updates=25400, lr=8.87357e-05, gnorm=0.322, clip=0, loss_scale=32, train_wall=73, gb_free=15.1, wall=23665
2023-09-06 23:07:04 | INFO | train_inner | epoch 022:    501 / 1191 loss=2.217, trans_loss=5.251, nll_loss=2.602, w2v_ctc_loss=0.546, task_loss=1.099, task_loss_gen=5.109, contrastive_loss=0, total=6720.12, n_correct=3389.57, ppl=6.07, accuracy=50.439, wps=18502.3, ups=1.38, wpb=13440.2, bsz=457.6, num_updates=25500, lr=8.85615e-05, gnorm=0.337, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=23737
2023-09-06 23:08:17 | INFO | train_inner | epoch 022:    601 / 1191 loss=2.216, trans_loss=5.251, nll_loss=2.603, w2v_ctc_loss=0.538, task_loss=1.852, task_loss_gen=4.104, contrastive_loss=0, total=6704.25, n_correct=3376.4, ppl=6.07, accuracy=50.362, wps=18450.7, ups=1.38, wpb=13408.5, bsz=447.4, num_updates=25600, lr=8.83883e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=72, gb_free=10.2, wall=23810
2023-09-06 23:09:30 | INFO | train_inner | epoch 022:    701 / 1191 loss=2.213, trans_loss=5.248, nll_loss=2.599, w2v_ctc_loss=0.531, task_loss=1.16, task_loss_gen=3.802, contrastive_loss=0, total=6710.51, n_correct=3379.91, ppl=6.06, accuracy=50.367, wps=18447.7, ups=1.37, wpb=13421, bsz=454.9, num_updates=25700, lr=8.82162e-05, gnorm=0.323, clip=0, loss_scale=32, train_wall=72, gb_free=15, wall=23883
2023-09-06 23:10:42 | INFO | train_inner | epoch 022:    801 / 1191 loss=2.219, trans_loss=5.252, nll_loss=2.605, w2v_ctc_loss=0.537, task_loss=0.92, task_loss_gen=4.65, contrastive_loss=0, total=6572.69, n_correct=3293.83, ppl=6.08, accuracy=50.114, wps=18305.4, ups=1.39, wpb=13145.4, bsz=434.8, num_updates=25800, lr=8.80451e-05, gnorm=0.325, clip=0, loss_scale=32, train_wall=71, gb_free=11.5, wall=23954
2023-09-06 23:11:56 | INFO | train_inner | epoch 022:    901 / 1191 loss=2.222, trans_loss=5.259, nll_loss=2.612, w2v_ctc_loss=0.545, task_loss=1.067, task_loss_gen=4.742, contrastive_loss=0, total=6701.42, n_correct=3355.71, ppl=6.12, accuracy=50.075, wps=18086.2, ups=1.35, wpb=13402.8, bsz=452.1, num_updates=25900, lr=8.7875e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=73, gb_free=12.5, wall=24029
2023-09-06 23:13:08 | INFO | train_inner | epoch 022:   1001 / 1191 loss=2.211, trans_loss=5.248, nll_loss=2.599, w2v_ctc_loss=0.533, task_loss=1.673, task_loss_gen=3.46, contrastive_loss=0, total=6847.97, n_correct=3453.11, ppl=6.06, accuracy=50.425, wps=18835.3, ups=1.38, wpb=13695.9, bsz=468.2, num_updates=26000, lr=8.77058e-05, gnorm=0.332, clip=0, loss_scale=32, train_wall=72, gb_free=13.1, wall=24101
2023-09-06 23:13:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:5')
2023-09-06 23:13:46 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.536 | trans_loss 6.16 | nll_loss 3.699 | w2v_ctc_loss 1.203 | task_loss 41.413 | task_loss_gen 22.755 | contrastive_loss 0 | total 6138.43 | n_correct 3029.86 | ppl 12.99 | accuracy 49.359 | uer 16.944 | wer 18.758 | raw_wer 18.758 | bleu 5.21 | wps 1477 | wpb 6138.4 | bsz 201.1 | num_updates 26000 | best_bleu 5.21
2023-09-06 23:13:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 26000 updates
2023-09-06 23:13:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_22_26000.pt
2023-09-06 23:13:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_22_26000.pt
2023-09-06 23:14:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_22_26000.pt (epoch 22 @ 26000 updates, score 5.21) (writing took 14.457011874997988 seconds)
2023-09-06 23:15:13 | INFO | train_inner | epoch 022:   1101 / 1191 loss=2.22, trans_loss=5.253, nll_loss=2.606, w2v_ctc_loss=0.544, task_loss=1.433, task_loss_gen=3.679, contrastive_loss=0, total=6699.81, n_correct=3365.99, ppl=6.09, accuracy=50.24, wps=10784.5, ups=0.8, wpb=13399.6, bsz=447.9, num_updates=26100, lr=8.75376e-05, gnorm=0.335, clip=0, loss_scale=32, train_wall=71, gb_free=12.9, wall=24226
2023-09-06 23:16:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 23:16:54 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.555 | trans_loss 6.163 | nll_loss 3.705 | w2v_ctc_loss 1.261 | task_loss 24.298 | task_loss_gen 13.926 | contrastive_loss 0 | total 6138.43 | n_correct 3031 | ppl 13.04 | accuracy 49.377 | uer 16.821 | wer 18.62 | raw_wer 18.62 | bleu 4.99 | wps 1551.3 | wpb 6138.4 | bsz 201.1 | num_updates 26190 | best_bleu 5.21
2023-09-06 23:16:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 26190 updates
2023-09-06 23:16:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_4.9908.pt
2023-09-06 23:16:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_4.9908.pt
2023-09-06 23:17:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_4.9908.pt (epoch 22 @ 26190 updates, score 4.99) (writing took 7.402943314053118 seconds)
2023-09-06 23:17:02 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-09-06 23:17:02 | INFO | train | epoch 022 | loss 2.215 | trans_loss 5.25 | nll_loss 2.601 | w2v_ctc_loss 0.537 | task_loss 1.091 | task_loss_gen 4.513 | contrastive_loss 0 | total 6703.55 | n_correct 3374.98 | ppl 6.07 | accuracy 50.346 | wps 16454.7 | ups 1.23 | wpb 13407.1 | bsz 452.2 | num_updates 26190 | lr 8.73871e-05 | gnorm 0.329 | clip 0 | loss_scale 32 | train_wall 855 | gb_free 13.5 | wall 24335
2023-09-06 23:17:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 23:17:02 | INFO | fairseq.trainer | begin training epoch 23
2023-09-06 23:17:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 23:17:18 | INFO | train_inner | epoch 023:     10 / 1191 loss=2.226, trans_loss=5.26, nll_loss=2.614, w2v_ctc_loss=0.544, task_loss=1.296, task_loss_gen=3.675, contrastive_loss=0, total=6653.96, n_correct=3329.49, ppl=6.12, accuracy=50.038, wps=10652.1, ups=0.8, wpb=13307.9, bsz=432.5, num_updates=26200, lr=8.73704e-05, gnorm=0.324, clip=0, loss_scale=32, train_wall=72, gb_free=13.9, wall=24351
2023-09-06 23:18:30 | INFO | train_inner | epoch 023:    110 / 1191 loss=2.21, trans_loss=5.24, nll_loss=2.588, w2v_ctc_loss=0.528, task_loss=1.772, task_loss_gen=3.931, contrastive_loss=0, total=6649.43, n_correct=3353.62, ppl=6.01, accuracy=50.435, wps=18409.2, ups=1.38, wpb=13298.9, bsz=438.7, num_updates=26300, lr=8.72041e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=71, gb_free=5.3, wall=24423
2023-09-06 23:19:43 | INFO | train_inner | epoch 023:    210 / 1191 loss=2.197, trans_loss=5.228, nll_loss=2.573, w2v_ctc_loss=0.529, task_loss=1.22, task_loss_gen=3.382, contrastive_loss=0, total=6807.79, n_correct=3470.73, ppl=5.95, accuracy=50.982, wps=18678.4, ups=1.37, wpb=13615.6, bsz=473.5, num_updates=26400, lr=8.70388e-05, gnorm=0.321, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=24496
2023-09-06 23:20:55 | INFO | train_inner | epoch 023:    310 / 1191 loss=2.199, trans_loss=5.229, nll_loss=2.574, w2v_ctc_loss=0.523, task_loss=0.861, task_loss_gen=4.079, contrastive_loss=0, total=6819.51, n_correct=3472.29, ppl=5.95, accuracy=50.917, wps=18817.9, ups=1.38, wpb=13639, bsz=464, num_updates=26500, lr=8.68744e-05, gnorm=0.324, clip=0, loss_scale=32, train_wall=72, gb_free=11.2, wall=24568
2023-09-06 23:22:08 | INFO | train_inner | epoch 023:    410 / 1191 loss=2.216, trans_loss=5.25, nll_loss=2.6, w2v_ctc_loss=0.534, task_loss=1.662, task_loss_gen=4.454, contrastive_loss=0, total=6727.48, n_correct=3379.56, ppl=6.06, accuracy=50.235, wps=18454.8, ups=1.37, wpb=13455, bsz=442.9, num_updates=26600, lr=8.6711e-05, gnorm=0.334, clip=0, loss_scale=32, train_wall=72, gb_free=12.2, wall=24641
2023-09-06 23:23:20 | INFO | train_inner | epoch 023:    510 / 1191 loss=2.206, trans_loss=5.238, nll_loss=2.586, w2v_ctc_loss=0.527, task_loss=1.17, task_loss_gen=3.517, contrastive_loss=0, total=6704.27, n_correct=3395.46, ppl=6, accuracy=50.646, wps=18639.2, ups=1.39, wpb=13408.5, bsz=451.1, num_updates=26700, lr=8.65485e-05, gnorm=0.321, clip=0, loss_scale=32, train_wall=71, gb_free=12.2, wall=24713
2023-09-06 23:24:33 | INFO | train_inner | epoch 023:    610 / 1191 loss=2.207, trans_loss=5.239, nll_loss=2.587, w2v_ctc_loss=0.534, task_loss=0.833, task_loss_gen=4.077, contrastive_loss=0, total=6683.43, n_correct=3379.46, ppl=6.01, accuracy=50.565, wps=18409.2, ups=1.38, wpb=13366.9, bsz=456.8, num_updates=26800, lr=8.63868e-05, gnorm=0.332, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=24786
2023-09-06 23:25:45 | INFO | train_inner | epoch 023:    710 / 1191 loss=2.212, trans_loss=5.245, nll_loss=2.594, w2v_ctc_loss=0.53, task_loss=0.959, task_loss_gen=4.341, contrastive_loss=0, total=6643.28, n_correct=3353.84, ppl=6.04, accuracy=50.485, wps=18259.7, ups=1.37, wpb=13286.6, bsz=439.6, num_updates=26900, lr=8.62261e-05, gnorm=0.324, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=24858
2023-09-06 23:26:59 | INFO | train_inner | epoch 023:    810 / 1191 loss=2.209, trans_loss=5.24, nll_loss=2.588, w2v_ctc_loss=0.533, task_loss=0.682, task_loss_gen=4.483, contrastive_loss=0, total=6723.07, n_correct=3403.05, ppl=6.01, accuracy=50.618, wps=18326.8, ups=1.36, wpb=13446.1, bsz=447.4, num_updates=27000, lr=8.60663e-05, gnorm=0.322, clip=0, loss_scale=32, train_wall=73, gb_free=14.2, wall=24932
2023-09-06 23:28:11 | INFO | train_inner | epoch 023:    910 / 1191 loss=2.2, trans_loss=5.226, nll_loss=2.57, w2v_ctc_loss=0.534, task_loss=0.634, task_loss_gen=4.477, contrastive_loss=0, total=6721.05, n_correct=3426.61, ppl=5.94, accuracy=50.983, wps=18723.2, ups=1.39, wpb=13442.1, bsz=465, num_updates=27100, lr=8.59074e-05, gnorm=0.326, clip=0, loss_scale=32, train_wall=71, gb_free=14.1, wall=25004
2023-09-06 23:29:23 | INFO | train_inner | epoch 023:   1010 / 1191 loss=2.2, trans_loss=5.23, nll_loss=2.576, w2v_ctc_loss=0.534, task_loss=0.594, task_loss_gen=4.915, contrastive_loss=0, total=6675.94, n_correct=3399.51, ppl=5.96, accuracy=50.922, wps=18525.3, ups=1.39, wpb=13351.9, bsz=465.9, num_updates=27200, lr=8.57493e-05, gnorm=0.32, clip=0, loss_scale=32, train_wall=71, gb_free=13.3, wall=25076
2023-09-06 23:30:35 | INFO | train_inner | epoch 023:   1110 / 1191 loss=2.214, trans_loss=5.249, nll_loss=2.6, w2v_ctc_loss=0.534, task_loss=0.664, task_loss_gen=5.207, contrastive_loss=0, total=6637.78, n_correct=3347.92, ppl=6.06, accuracy=50.437, wps=18251.3, ups=1.37, wpb=13275.6, bsz=440.1, num_updates=27300, lr=8.55921e-05, gnorm=0.333, clip=0, loss_scale=32, train_wall=72, gb_free=13.3, wall=25148
2023-09-06 23:31:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 23:32:09 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.529 | trans_loss 6.15 | nll_loss 3.687 | w2v_ctc_loss 1.201 | task_loss 28.565 | task_loss_gen 17.391 | contrastive_loss 0 | total 6138.43 | n_correct 3034.29 | ppl 12.88 | accuracy 49.431 | uer 16.562 | wer 18.304 | raw_wer 18.304 | bleu 5.08 | wps 1572.6 | wpb 6138.4 | bsz 201.1 | num_updates 27381 | best_bleu 5.21
2023-09-06 23:32:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 27381 updates
2023-09-06 23:32:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.0800.pt
2023-09-06 23:32:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.0800.pt
2023-09-06 23:32:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.0800.pt (epoch 23 @ 27381 updates, score 5.08) (writing took 7.6763776070438325 seconds)
2023-09-06 23:32:17 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-09-06 23:32:17 | INFO | train | epoch 023 | loss 2.207 | trans_loss 5.238 | nll_loss 2.586 | w2v_ctc_loss 0.531 | task_loss 0.996 | task_loss_gen 4.29 | contrastive_loss 0 | total 6703.69 | n_correct 3393.87 | ppl 6 | accuracy 50.627 | wps 17439.4 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 27381 | lr 8.54654e-05 | gnorm 0.327 | clip 0 | loss_scale 32 | train_wall 853 | gb_free 14.5 | wall 25250
2023-09-06 23:32:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 23:32:18 | INFO | fairseq.trainer | begin training epoch 24
2023-09-06 23:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 23:32:38 | INFO | train_inner | epoch 024:     19 / 1191 loss=2.214, trans_loss=5.247, nll_loss=2.597, w2v_ctc_loss=0.531, task_loss=0.947, task_loss_gen=4.771, contrastive_loss=0, total=6654.8, n_correct=3348.91, ppl=6.05, accuracy=50.323, wps=10813.4, ups=0.81, wpb=13309.6, bsz=439.5, num_updates=27400, lr=8.54358e-05, gnorm=0.326, clip=0, loss_scale=32, train_wall=72, gb_free=11.6, wall=25271
2023-09-06 23:33:51 | INFO | train_inner | epoch 024:    119 / 1191 loss=2.186, trans_loss=5.218, nll_loss=2.559, w2v_ctc_loss=0.516, task_loss=0.778, task_loss_gen=4.322, contrastive_loss=0, total=6770.69, n_correct=3474.12, ppl=5.89, accuracy=51.311, wps=18672.1, ups=1.38, wpb=13541.4, bsz=478, num_updates=27500, lr=8.52803e-05, gnorm=0.318, clip=0, loss_scale=64, train_wall=72, gb_free=13.7, wall=25344
2023-09-06 23:35:03 | INFO | train_inner | epoch 024:    219 / 1191 loss=2.184, trans_loss=5.215, nll_loss=2.555, w2v_ctc_loss=0.512, task_loss=0.583, task_loss_gen=4.682, contrastive_loss=0, total=6808.43, n_correct=3497.12, ppl=5.88, accuracy=51.365, wps=18942.9, ups=1.39, wpb=13616.9, bsz=478.7, num_updates=27600, lr=8.51257e-05, gnorm=0.318, clip=0, loss_scale=64, train_wall=71, gb_free=14.6, wall=25416
2023-09-06 23:36:16 | INFO | train_inner | epoch 024:    319 / 1191 loss=2.202, trans_loss=5.231, nll_loss=2.576, w2v_ctc_loss=0.526, task_loss=0.464, task_loss_gen=5.922, contrastive_loss=0, total=6739.01, n_correct=3419.19, ppl=5.96, accuracy=50.737, wps=18491.4, ups=1.37, wpb=13478, bsz=450.4, num_updates=27700, lr=8.49719e-05, gnorm=0.323, clip=0, loss_scale=64, train_wall=72, gb_free=14.3, wall=25489
2023-09-06 23:37:29 | INFO | train_inner | epoch 024:    419 / 1191 loss=2.206, trans_loss=5.234, nll_loss=2.579, w2v_ctc_loss=0.529, task_loss=0.521, task_loss_gen=6.405, contrastive_loss=0, total=6663.22, n_correct=3376.26, ppl=5.98, accuracy=50.67, wps=18321.3, ups=1.37, wpb=13326.4, bsz=436.9, num_updates=27800, lr=8.48189e-05, gnorm=0.327, clip=0, loss_scale=64, train_wall=72, gb_free=13.6, wall=25561
2023-09-06 23:38:42 | INFO | train_inner | epoch 024:    519 / 1191 loss=2.203, trans_loss=5.231, nll_loss=2.577, w2v_ctc_loss=0.531, task_loss=0.592, task_loss_gen=5.973, contrastive_loss=0, total=6651.11, n_correct=3377.48, ppl=5.97, accuracy=50.781, wps=18196, ups=1.37, wpb=13302.2, bsz=454.4, num_updates=27900, lr=8.46668e-05, gnorm=0.326, clip=0, loss_scale=64, train_wall=72, gb_free=11.6, wall=25635
2023-09-06 23:39:53 | INFO | train_inner | epoch 024:    619 / 1191 loss=2.21, trans_loss=5.237, nll_loss=2.583, w2v_ctc_loss=0.529, task_loss=0.698, task_loss_gen=5.83, contrastive_loss=0, total=6545.91, n_correct=3307.01, ppl=5.99, accuracy=50.52, wps=18277, ups=1.4, wpb=13091.8, bsz=419.5, num_updates=28000, lr=8.45154e-05, gnorm=0.332, clip=0, loss_scale=64, train_wall=71, gb_free=14, wall=25706
2023-09-06 23:39:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 23:40:27 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.536 | trans_loss 6.147 | nll_loss 3.68 | w2v_ctc_loss 1.231 | task_loss 3.068 | task_loss_gen 11.743 | contrastive_loss 0 | total 6138.43 | n_correct 3035 | ppl 12.82 | accuracy 49.443 | uer 16.704 | wer 18.527 | raw_wer 18.527 | bleu 5.12 | wps 1649.4 | wpb 6138.4 | bsz 201.1 | num_updates 28000 | best_bleu 5.21
2023-09-06 23:40:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28000 updates
2023-09-06 23:40:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_24_28000.pt
2023-09-06 23:40:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_24_28000.pt
2023-09-06 23:40:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_24_28000.pt (epoch 24 @ 28000 updates, score 5.12) (writing took 9.839345146901906 seconds)
2023-09-06 23:41:50 | INFO | train_inner | epoch 024:    719 / 1191 loss=2.193, trans_loss=5.219, nll_loss=2.561, w2v_ctc_loss=0.528, task_loss=0.625, task_loss_gen=5.755, contrastive_loss=0, total=6744.37, n_correct=3451.58, ppl=5.9, accuracy=51.177, wps=11539.2, ups=0.86, wpb=13488.7, bsz=468, num_updates=28100, lr=8.43649e-05, gnorm=0.325, clip=0, loss_scale=64, train_wall=72, gb_free=14.1, wall=25823
2023-09-06 23:43:02 | INFO | train_inner | epoch 024:    819 / 1191 loss=2.2, trans_loss=5.223, nll_loss=2.566, w2v_ctc_loss=0.532, task_loss=0.68, task_loss_gen=5.528, contrastive_loss=0, total=6726.26, n_correct=3427.44, ppl=5.92, accuracy=50.956, wps=18643.1, ups=1.39, wpb=13452.5, bsz=450, num_updates=28200, lr=8.42152e-05, gnorm=0.326, clip=0, loss_scale=64, train_wall=71, gb_free=14.1, wall=25895
2023-09-06 23:44:15 | INFO | train_inner | epoch 024:    919 / 1191 loss=2.196, trans_loss=5.226, nll_loss=2.569, w2v_ctc_loss=0.524, task_loss=0.498, task_loss_gen=5.875, contrastive_loss=0, total=6729.03, n_correct=3434.04, ppl=5.94, accuracy=51.033, wps=18411.8, ups=1.37, wpb=13458.1, bsz=457.1, num_updates=28300, lr=8.40663e-05, gnorm=0.328, clip=0, loss_scale=64, train_wall=72, gb_free=14.2, wall=25968
2023-09-06 23:45:29 | INFO | train_inner | epoch 024:   1019 / 1191 loss=2.208, trans_loss=5.236, nll_loss=2.583, w2v_ctc_loss=0.533, task_loss=0.621, task_loss_gen=6.337, contrastive_loss=0, total=6600.79, n_correct=3340.85, ppl=5.99, accuracy=50.613, wps=17888.1, ups=1.35, wpb=13201.6, bsz=442.6, num_updates=28400, lr=8.39181e-05, gnorm=0.333, clip=0, loss_scale=64, train_wall=73, gb_free=8.3, wall=26042
2023-09-06 23:46:43 | INFO | train_inner | epoch 024:   1119 / 1191 loss=2.206, trans_loss=5.234, nll_loss=2.58, w2v_ctc_loss=0.524, task_loss=0.999, task_loss_gen=6.174, contrastive_loss=0, total=6701.65, n_correct=3398.29, ppl=5.98, accuracy=50.708, wps=18202.5, ups=1.36, wpb=13403.3, bsz=434.4, num_updates=28500, lr=8.37708e-05, gnorm=0.326, clip=0, loss_scale=64, train_wall=73, gb_free=10.3, wall=26116
2023-09-06 23:46:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-06 23:47:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-06 23:48:09 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.527 | trans_loss 6.142 | nll_loss 3.674 | w2v_ctc_loss 1.211 | task_loss 14.685 | task_loss_gen 12.668 | contrastive_loss 0 | total 6138.43 | n_correct 3045.71 | ppl 12.76 | accuracy 49.617 | uer 16.367 | wer 18.234 | raw_wer 18.234 | bleu 5.53 | wps 1671.3 | wpb 6138.4 | bsz 201.1 | num_updates 28571 | best_bleu 5.53
2023-09-06 23:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 28571 updates
2023-09-06 23:48:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 23:48:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-06 23:48:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 24 @ 28571 updates, score 5.53) (writing took 12.137388315983117 seconds)
2023-09-06 23:48:22 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-09-06 23:48:22 | INFO | train | epoch 024 | loss 2.2 | trans_loss 5.228 | nll_loss 2.572 | w2v_ctc_loss 0.526 | task_loss 0.663 | task_loss_gen 5.622 | contrastive_loss 0 | total 6702.95 | n_correct 3410.71 | ppl 5.95 | accuracy 50.884 | wps 16544.8 | ups 1.23 | wpb 13405.9 | bsz 451.8 | num_updates 28571 | lr 8.36666e-05 | gnorm 0.326 | clip 0 | loss_scale 32 | train_wall 856 | gb_free 14.9 | wall 26215
2023-09-06 23:48:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-06 23:48:22 | INFO | fairseq.trainer | begin training epoch 25
2023-09-06 23:48:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-06 23:48:51 | INFO | train_inner | epoch 025:     29 / 1191 loss=2.201, trans_loss=5.228, nll_loss=2.572, w2v_ctc_loss=0.525, task_loss=0.942, task_loss_gen=4.823, contrastive_loss=0, total=6701.17, n_correct=3401.15, ppl=5.95, accuracy=50.755, wps=10488.1, ups=0.78, wpb=13402.3, bsz=445, num_updates=28600, lr=8.36242e-05, gnorm=0.329, clip=0, loss_scale=32, train_wall=73, gb_free=13.8, wall=26244
2023-09-06 23:50:03 | INFO | train_inner | epoch 025:    129 / 1191 loss=2.194, trans_loss=5.216, nll_loss=2.557, w2v_ctc_loss=0.513, task_loss=1.277, task_loss_gen=4.266, contrastive_loss=0, total=6583.6, n_correct=3357.62, ppl=5.88, accuracy=51, wps=18180.5, ups=1.38, wpb=13167.2, bsz=436.5, num_updates=28700, lr=8.34784e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=72, gb_free=13.2, wall=26316
2023-09-06 23:51:16 | INFO | train_inner | epoch 025:    229 / 1191 loss=2.18, trans_loss=5.209, nll_loss=2.547, w2v_ctc_loss=0.509, task_loss=1.401, task_loss_gen=3.756, contrastive_loss=0, total=6780.64, n_correct=3494.2, ppl=5.84, accuracy=51.532, wps=18646.8, ups=1.38, wpb=13561.3, bsz=471, num_updates=28800, lr=8.33333e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=72, gb_free=14.1, wall=26389
2023-09-06 23:52:29 | INFO | train_inner | epoch 025:    329 / 1191 loss=2.2, trans_loss=5.223, nll_loss=2.564, w2v_ctc_loss=0.525, task_loss=1.163, task_loss_gen=4.601, contrastive_loss=0, total=6618.73, n_correct=3365.84, ppl=5.91, accuracy=50.853, wps=18067, ups=1.36, wpb=13237.5, bsz=431.7, num_updates=28900, lr=8.3189e-05, gnorm=0.336, clip=0, loss_scale=32, train_wall=73, gb_free=13.5, wall=26462
2023-09-06 23:53:42 | INFO | train_inner | epoch 025:    429 / 1191 loss=2.208, trans_loss=5.233, nll_loss=2.578, w2v_ctc_loss=0.527, task_loss=2.15, task_loss_gen=4.891, contrastive_loss=0, total=6559, n_correct=3318.18, ppl=5.97, accuracy=50.59, wps=18059.2, ups=1.38, wpb=13118, bsz=418.7, num_updates=29000, lr=8.30455e-05, gnorm=0.372, clip=0, loss_scale=32, train_wall=72, gb_free=13.4, wall=26535
2023-09-06 23:54:54 | INFO | train_inner | epoch 025:    529 / 1191 loss=2.179, trans_loss=5.205, nll_loss=2.542, w2v_ctc_loss=0.516, task_loss=1.744, task_loss_gen=3.382, contrastive_loss=0, total=6859.95, n_correct=3538.91, ppl=5.83, accuracy=51.588, wps=18885.6, ups=1.38, wpb=13719.9, bsz=486.8, num_updates=29100, lr=8.29027e-05, gnorm=0.344, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=26607
2023-09-06 23:56:06 | INFO | train_inner | epoch 025:    629 / 1191 loss=2.19, trans_loss=5.215, nll_loss=2.555, w2v_ctc_loss=0.514, task_loss=1.79, task_loss_gen=3.694, contrastive_loss=0, total=6758.81, n_correct=3458.51, ppl=5.87, accuracy=51.17, wps=18856.6, ups=1.39, wpb=13517.6, bsz=450.4, num_updates=29200, lr=8.27606e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=71, gb_free=14.3, wall=26679
2023-09-06 23:57:19 | INFO | train_inner | epoch 025:    729 / 1191 loss=2.195, trans_loss=5.221, nll_loss=2.563, w2v_ctc_loss=0.52, task_loss=1.387, task_loss_gen=3.848, contrastive_loss=0, total=6686.07, n_correct=3407.31, ppl=5.91, accuracy=50.961, wps=18368.2, ups=1.37, wpb=13372.1, bsz=450.8, num_updates=29300, lr=8.26192e-05, gnorm=0.331, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=26752
2023-09-06 23:58:31 | INFO | train_inner | epoch 025:    829 / 1191 loss=2.191, trans_loss=5.216, nll_loss=2.556, w2v_ctc_loss=0.521, task_loss=1.622, task_loss_gen=3.925, contrastive_loss=0, total=6724.86, n_correct=3441.14, ppl=5.88, accuracy=51.17, wps=18614.9, ups=1.38, wpb=13449.7, bsz=454.4, num_updates=29400, lr=8.24786e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=71, gb_free=12.2, wall=26824
2023-09-06 23:59:44 | INFO | train_inner | epoch 025:    929 / 1191 loss=2.182, trans_loss=5.208, nll_loss=2.546, w2v_ctc_loss=0.516, task_loss=1, task_loss_gen=3.792, contrastive_loss=0, total=6787.73, n_correct=3489.49, ppl=5.84, accuracy=51.409, wps=18636.1, ups=1.37, wpb=13575.5, bsz=474.6, num_updates=29500, lr=8.23387e-05, gnorm=0.333, clip=0, loss_scale=32, train_wall=72, gb_free=12.4, wall=26897
2023-09-07 00:00:55 | INFO | train_inner | epoch 025:   1029 / 1191 loss=2.194, trans_loss=5.225, nll_loss=2.568, w2v_ctc_loss=0.521, task_loss=1.45, task_loss_gen=4.116, contrastive_loss=0, total=6654.71, n_correct=3396.38, ppl=5.93, accuracy=51.037, wps=18604.6, ups=1.4, wpb=13309.4, bsz=451.1, num_updates=29600, lr=8.21995e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=71, gb_free=12.5, wall=26968
2023-09-07 00:01:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-07 00:02:09 | INFO | train_inner | epoch 025:   1130 / 1191 loss=2.194, trans_loss=5.217, nll_loss=2.558, w2v_ctc_loss=0.525, task_loss=1.472, task_loss_gen=4.253, contrastive_loss=0, total=6694.57, n_correct=3420.91, ppl=5.89, accuracy=51.1, wps=18191, ups=1.36, wpb=13389.1, bsz=447.9, num_updates=29700, lr=8.2061e-05, gnorm=0.354, clip=0, loss_scale=16, train_wall=73, gb_free=11.9, wall=27042
2023-09-07 00:02:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 00:03:29 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.529 | trans_loss 6.138 | nll_loss 3.67 | w2v_ctc_loss 1.227 | task_loss 37.309 | task_loss_gen 19.916 | contrastive_loss 0 | total 6138.43 | n_correct 3053.14 | ppl 12.73 | accuracy 49.738 | uer 16.348 | wer 18.111 | raw_wer 18.111 | bleu 5.6 | wps 1590.6 | wpb 6138.4 | bsz 201.1 | num_updates 29761 | best_bleu 5.6
2023-09-07 00:03:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 29761 updates
2023-09-07 00:03:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 00:03:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 00:03:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 25 @ 29761 updates, score 5.6) (writing took 12.54840431699995 seconds)
2023-09-07 00:03:42 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-09-07 00:03:42 | INFO | train | epoch 025 | loss 2.192 | trans_loss 5.218 | nll_loss 2.558 | w2v_ctc_loss 0.519 | task_loss 1.479 | task_loss_gen 4.026 | contrastive_loss 0 | total 6704.06 | n_correct 3427.22 | ppl 5.89 | accuracy 51.122 | wps 17342.3 | ups 1.29 | wpb 13408.1 | bsz 452.3 | num_updates 29761 | lr 8.19769e-05 | gnorm 0.344 | clip 0 | loss_scale 16 | train_wall 853 | gb_free 11.5 | wall 27135
2023-09-07 00:03:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 00:03:42 | INFO | fairseq.trainer | begin training epoch 26
2023-09-07 00:03:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 00:04:18 | INFO | train_inner | epoch 026:     39 / 1191 loss=2.191, trans_loss=5.22, nll_loss=2.561, w2v_ctc_loss=0.518, task_loss=1.525, task_loss_gen=3.616, contrastive_loss=0, total=6812.72, n_correct=3483.51, ppl=5.9, accuracy=51.132, wps=10598.3, ups=0.78, wpb=13625.4, bsz=462.2, num_updates=29800, lr=8.19232e-05, gnorm=0.387, clip=0, loss_scale=16, train_wall=72, gb_free=12.3, wall=27171
2023-09-07 00:05:30 | INFO | train_inner | epoch 026:    139 / 1191 loss=2.181, trans_loss=5.206, nll_loss=2.543, w2v_ctc_loss=0.51, task_loss=1.721, task_loss_gen=3.326, contrastive_loss=0, total=6718.44, n_correct=3454.66, ppl=5.83, accuracy=51.421, wps=18480.7, ups=1.38, wpb=13436.9, bsz=456.6, num_updates=29900, lr=8.17861e-05, gnorm=0.374, clip=0, loss_scale=16, train_wall=72, gb_free=13.8, wall=27243
2023-09-07 00:06:43 | INFO | train_inner | epoch 026:    239 / 1191 loss=2.181, trans_loss=5.2, nll_loss=2.535, w2v_ctc_loss=0.511, task_loss=1.389, task_loss_gen=3.284, contrastive_loss=0, total=6678.33, n_correct=3437.06, ppl=5.8, accuracy=51.466, wps=18507.1, ups=1.39, wpb=13356.7, bsz=451.1, num_updates=30000, lr=8.16497e-05, gnorm=0.361, clip=0, loss_scale=16, train_wall=71, gb_free=11.7, wall=27316
2023-09-07 00:06:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 00:07:18 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.529 | trans_loss 6.137 | nll_loss 3.664 | w2v_ctc_loss 1.232 | task_loss 9.534 | task_loss_gen 8.55 | contrastive_loss 0 | total 6138.43 | n_correct 3056.86 | ppl 12.67 | accuracy 49.799 | uer 16.618 | wer 18.401 | raw_wer 18.401 | bleu 5.57 | wps 1570.3 | wpb 6138.4 | bsz 201.1 | num_updates 30000 | best_bleu 5.6
2023-09-07 00:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30000 updates
2023-09-07 00:07:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_26_30000.pt
2023-09-07 00:07:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_26_30000.pt
2023-09-07 00:07:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_26_30000.pt (epoch 26 @ 30000 updates, score 5.57) (writing took 8.746178693021648 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:0')
2023-09-07 00:08:40 | INFO | train_inner | epoch 026:    339 / 1191 loss=2.167, trans_loss=5.191, nll_loss=2.525, w2v_ctc_loss=0.509, task_loss=1.656, task_loss_gen=2.897, contrastive_loss=0, total=6888.24, n_correct=3581.35, ppl=5.75, accuracy=51.992, wps=11762.9, ups=0.85, wpb=13776.5, bsz=498.1, num_updates=30100, lr=8.15139e-05, gnorm=0.373, clip=0, loss_scale=16, train_wall=71, gb_free=12.7, wall=27433
2023-09-07 00:09:52 | INFO | train_inner | epoch 026:    439 / 1191 loss=2.196, trans_loss=5.215, nll_loss=2.553, w2v_ctc_loss=0.522, task_loss=1.64, task_loss_gen=3.699, contrastive_loss=0, total=6569.92, n_correct=3351.46, ppl=5.87, accuracy=51.012, wps=18141.6, ups=1.38, wpb=13139.8, bsz=423, num_updates=30200, lr=8.13788e-05, gnorm=0.374, clip=0, loss_scale=16, train_wall=72, gb_free=10.6, wall=27505
2023-09-07 00:11:05 | INFO | train_inner | epoch 026:    539 / 1191 loss=2.188, trans_loss=5.209, nll_loss=2.546, w2v_ctc_loss=0.518, task_loss=1.85, task_loss_gen=3.361, contrastive_loss=0, total=6684.51, n_correct=3430.74, ppl=5.84, accuracy=51.324, wps=18324.4, ups=1.37, wpb=13369, bsz=453.1, num_updates=30300, lr=8.12444e-05, gnorm=0.384, clip=0, loss_scale=16, train_wall=72, gb_free=14.5, wall=27578
2023-09-07 00:12:17 | INFO | train_inner | epoch 026:    639 / 1191 loss=2.195, trans_loss=5.219, nll_loss=2.559, w2v_ctc_loss=0.514, task_loss=1.342, task_loss_gen=3.65, contrastive_loss=0, total=6606.67, n_correct=3368.62, ppl=5.89, accuracy=50.988, wps=18370.2, ups=1.39, wpb=13213.3, bsz=426.7, num_updates=30400, lr=8.11107e-05, gnorm=0.353, clip=0, loss_scale=16, train_wall=71, gb_free=12.1, wall=27650
2023-09-07 00:13:30 | INFO | train_inner | epoch 026:    739 / 1191 loss=2.19, trans_loss=5.214, nll_loss=2.553, w2v_ctc_loss=0.516, task_loss=1.609, task_loss_gen=3.495, contrastive_loss=0, total=6778.79, n_correct=3464.81, ppl=5.87, accuracy=51.113, wps=18548.6, ups=1.37, wpb=13557.6, bsz=446.5, num_updates=30500, lr=8.09776e-05, gnorm=0.4, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=27723
2023-09-07 00:14:43 | INFO | train_inner | epoch 026:    839 / 1191 loss=2.182, trans_loss=5.204, nll_loss=2.54, w2v_ctc_loss=0.513, task_loss=2.381, task_loss_gen=3.411, contrastive_loss=0, total=6679.03, n_correct=3430.57, ppl=5.81, accuracy=51.363, wps=18406.2, ups=1.38, wpb=13358.1, bsz=455.9, num_updates=30600, lr=8.08452e-05, gnorm=0.405, clip=0, loss_scale=16, train_wall=72, gb_free=13.1, wall=27796
2023-09-07 00:15:55 | INFO | train_inner | epoch 026:    939 / 1191 loss=2.193, trans_loss=5.215, nll_loss=2.555, w2v_ctc_loss=0.524, task_loss=1.543, task_loss_gen=3.224, contrastive_loss=0, total=6677.41, n_correct=3413.9, ppl=5.88, accuracy=51.126, wps=18559.3, ups=1.39, wpb=13354.8, bsz=447.2, num_updates=30700, lr=8.07134e-05, gnorm=0.359, clip=0, loss_scale=16, train_wall=71, gb_free=13.8, wall=27868
2023-09-07 00:17:07 | INFO | train_inner | epoch 026:   1039 / 1191 loss=2.192, trans_loss=5.216, nll_loss=2.556, w2v_ctc_loss=0.523, task_loss=1.553, task_loss_gen=3.172, contrastive_loss=0, total=6701.65, n_correct=3425.49, ppl=5.88, accuracy=51.114, wps=18469.9, ups=1.38, wpb=13403.3, bsz=447.7, num_updates=30800, lr=8.05823e-05, gnorm=0.362, clip=0, loss_scale=16, train_wall=72, gb_free=13.3, wall=27940
2023-09-07 00:18:20 | INFO | train_inner | epoch 026:   1139 / 1191 loss=2.182, trans_loss=5.206, nll_loss=2.544, w2v_ctc_loss=0.522, task_loss=1.211, task_loss_gen=3.188, contrastive_loss=0, total=6787.9, n_correct=3503.54, ppl=5.83, accuracy=51.614, wps=18550.2, ups=1.37, wpb=13575.8, bsz=474.7, num_updates=30900, lr=8.04518e-05, gnorm=0.35, clip=0, loss_scale=16, train_wall=72, gb_free=13.6, wall=28013
2023-09-07 00:18:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:2')
2023-09-07 00:19:33 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.55 | trans_loss 6.132 | nll_loss 3.661 | w2v_ctc_loss 1.311 | task_loss 27.764 | task_loss_gen 14.777 | contrastive_loss 0 | total 6138.43 | n_correct 3053.86 | ppl 12.65 | accuracy 49.75 | uer 16.669 | wer 18.304 | raw_wer 18.304 | bleu 5.38 | wps 1582.8 | wpb 6138.4 | bsz 201.1 | num_updates 30952 | best_bleu 5.6
2023-09-07 00:19:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 30952 updates
2023-09-07 00:19:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.3801.pt
2023-09-07 00:19:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.3801.pt
2023-09-07 00:19:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.3801.pt (epoch 26 @ 30952 updates, score 5.38) (writing took 7.548539993003942 seconds)
2023-09-07 00:19:41 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-09-07 00:19:41 | INFO | train | epoch 026 | loss 2.186 | trans_loss 5.209 | nll_loss 2.547 | w2v_ctc_loss 0.517 | task_loss 1.607 | task_loss_gen 3.357 | contrastive_loss 0 | total 6703.69 | n_correct 3439.78 | ppl 5.84 | accuracy 51.312 | wps 16649 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 30952 | lr 8.03842e-05 | gnorm 0.372 | clip 0 | loss_scale 16 | train_wall 854 | gb_free 12.4 | wall 28094
2023-09-07 00:19:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 00:19:41 | INFO | fairseq.trainer | begin training epoch 27
2023-09-07 00:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 00:20:24 | INFO | train_inner | epoch 027:     48 / 1191 loss=2.187, trans_loss=5.209, nll_loss=2.546, w2v_ctc_loss=0.52, task_loss=1.271, task_loss_gen=3.571, contrastive_loss=0, total=6621.11, n_correct=3397.62, ppl=5.84, accuracy=51.315, wps=10678.9, ups=0.81, wpb=13242.2, bsz=439, num_updates=31000, lr=8.03219e-05, gnorm=0.358, clip=0, loss_scale=16, train_wall=72, gb_free=15.2, wall=28137
2023-09-07 00:21:38 | INFO | train_inner | epoch 027:    148 / 1191 loss=2.177, trans_loss=5.197, nll_loss=2.53, w2v_ctc_loss=0.51, task_loss=1.63, task_loss_gen=3.377, contrastive_loss=0, total=6726.66, n_correct=3472.31, ppl=5.78, accuracy=51.62, wps=18321.6, ups=1.36, wpb=13453.3, bsz=464.7, num_updates=31100, lr=8.01927e-05, gnorm=0.38, clip=0, loss_scale=16, train_wall=72, gb_free=13.8, wall=28211
2023-09-07 00:22:50 | INFO | train_inner | epoch 027:    248 / 1191 loss=2.162, trans_loss=5.184, nll_loss=2.514, w2v_ctc_loss=0.499, task_loss=1.465, task_loss_gen=3.121, contrastive_loss=0, total=6820.93, n_correct=3552.99, ppl=5.71, accuracy=52.09, wps=19007, ups=1.39, wpb=13641.9, bsz=482.9, num_updates=31200, lr=8.00641e-05, gnorm=0.371, clip=0, loss_scale=16, train_wall=71, gb_free=14.4, wall=28283
2023-09-07 00:24:02 | INFO | train_inner | epoch 027:    348 / 1191 loss=2.167, trans_loss=5.188, nll_loss=2.519, w2v_ctc_loss=0.499, task_loss=1.498, task_loss_gen=3.007, contrastive_loss=0, total=6731.11, n_correct=3493.42, ppl=5.73, accuracy=51.9, wps=18566.4, ups=1.38, wpb=13462.2, bsz=466.9, num_updates=31300, lr=7.99361e-05, gnorm=0.366, clip=0, loss_scale=16, train_wall=72, gb_free=12.5, wall=28355
2023-09-07 00:25:15 | INFO | train_inner | epoch 027:    448 / 1191 loss=2.192, trans_loss=5.215, nll_loss=2.553, w2v_ctc_loss=0.523, task_loss=1.281, task_loss_gen=3.601, contrastive_loss=0, total=6617.99, n_correct=3389.12, ppl=5.87, accuracy=51.211, wps=18178.5, ups=1.37, wpb=13236, bsz=437.6, num_updates=31400, lr=7.98087e-05, gnorm=0.356, clip=0, loss_scale=16, train_wall=72, gb_free=6.1, wall=28428
2023-09-07 00:26:27 | INFO | train_inner | epoch 027:    548 / 1191 loss=2.172, trans_loss=5.192, nll_loss=2.524, w2v_ctc_loss=0.507, task_loss=1.562, task_loss_gen=3.044, contrastive_loss=0, total=6786.76, n_correct=3511.1, ppl=5.75, accuracy=51.735, wps=18852.4, ups=1.39, wpb=13573.5, bsz=467.9, num_updates=31500, lr=7.96819e-05, gnorm=0.364, clip=0, loss_scale=16, train_wall=71, gb_free=13.3, wall=28500
2023-09-07 00:27:40 | INFO | train_inner | epoch 027:    648 / 1191 loss=2.185, trans_loss=5.206, nll_loss=2.542, w2v_ctc_loss=0.511, task_loss=1.627, task_loss_gen=3.392, contrastive_loss=0, total=6681.62, n_correct=3428.78, ppl=5.82, accuracy=51.317, wps=18335.1, ups=1.37, wpb=13363.2, bsz=444.4, num_updates=31600, lr=7.95557e-05, gnorm=0.374, clip=0, loss_scale=16, train_wall=72, gb_free=11.8, wall=28573
2023-09-07 00:28:52 | INFO | train_inner | epoch 027:    748 / 1191 loss=2.187, trans_loss=5.206, nll_loss=2.542, w2v_ctc_loss=0.518, task_loss=1.378, task_loss_gen=3.482, contrastive_loss=0, total=6672.74, n_correct=3427.19, ppl=5.83, accuracy=51.361, wps=18473.3, ups=1.38, wpb=13345.5, bsz=442.4, num_updates=31700, lr=7.94301e-05, gnorm=0.356, clip=0, loss_scale=16, train_wall=71, gb_free=12.7, wall=28645
2023-09-07 00:30:04 | INFO | train_inner | epoch 027:    848 / 1191 loss=2.183, trans_loss=5.202, nll_loss=2.538, w2v_ctc_loss=0.513, task_loss=1.159, task_loss_gen=3.727, contrastive_loss=0, total=6644.45, n_correct=3418.95, ppl=5.81, accuracy=51.456, wps=18379.8, ups=1.38, wpb=13288.9, bsz=439.2, num_updates=31800, lr=7.93052e-05, gnorm=0.337, clip=0, loss_scale=32, train_wall=71, gb_free=12.9, wall=28717
2023-09-07 00:31:17 | INFO | train_inner | epoch 027:    948 / 1191 loss=2.195, trans_loss=5.217, nll_loss=2.557, w2v_ctc_loss=0.518, task_loss=1.548, task_loss_gen=3.773, contrastive_loss=0, total=6643.34, n_correct=3387.97, ppl=5.89, accuracy=50.998, wps=18243.5, ups=1.37, wpb=13286.7, bsz=425.1, num_updates=31900, lr=7.91808e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=72, gb_free=10.5, wall=28790
2023-09-07 00:32:29 | INFO | train_inner | epoch 027:   1048 / 1191 loss=2.182, trans_loss=5.205, nll_loss=2.542, w2v_ctc_loss=0.517, task_loss=1.14, task_loss_gen=3.584, contrastive_loss=0, total=6650.56, n_correct=3428.23, ppl=5.82, accuracy=51.548, wps=18408.4, ups=1.38, wpb=13301.1, bsz=450.8, num_updates=32000, lr=7.90569e-05, gnorm=0.334, clip=0, loss_scale=32, train_wall=72, gb_free=13.3, wall=28862
2023-09-07 00:32:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 00:33:05 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.513 | trans_loss 6.119 | nll_loss 3.647 | w2v_ctc_loss 1.219 | task_loss 8.21 | task_loss_gen 8.252 | contrastive_loss 0 | total 6138.43 | n_correct 3069.86 | ppl 12.53 | accuracy 50.01 | uer 16.474 | wer 18.36 | raw_wer 18.36 | bleu 5.61 | wps 1512.2 | wpb 6138.4 | bsz 201.1 | num_updates 32000 | best_bleu 5.61
2023-09-07 00:33:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 32000 updates
2023-09-07 00:33:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_27_32000.pt
2023-09-07 00:33:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_27_32000.pt
2023-09-07 00:33:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_27_32000.pt (epoch 27 @ 32000 updates, score 5.61) (writing took 12.117775694001466 seconds)
2023-09-07 00:34:30 | INFO | train_inner | epoch 027:   1148 / 1191 loss=2.181, trans_loss=5.203, nll_loss=2.539, w2v_ctc_loss=0.511, task_loss=0.88, task_loss_gen=4.017, contrastive_loss=0, total=6756.52, n_correct=3479.71, ppl=5.81, accuracy=51.502, wps=11175.3, ups=0.83, wpb=13513, bsz=452.5, num_updates=32100, lr=7.89337e-05, gnorm=0.329, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=28983
2023-09-07 00:35:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 00:35:36 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.516 | trans_loss 6.114 | nll_loss 3.64 | w2v_ctc_loss 1.239 | task_loss 8.013 | task_loss_gen 8.892 | contrastive_loss 0 | total 6138.43 | n_correct 3071.29 | ppl 12.46 | accuracy 50.034 | uer 16.348 | wer 18.07 | raw_wer 18.07 | bleu 5.6 | wps 1648.8 | wpb 6138.4 | bsz 201.1 | num_updates 32143 | best_bleu 5.61
2023-09-07 00:35:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 32143 updates
2023-09-07 00:35:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.6006.pt
2023-09-07 00:35:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.6006.pt
2023-09-07 00:35:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.6006.pt (epoch 27 @ 32143 updates, score 5.6) (writing took 7.3503555110655725 seconds)
2023-09-07 00:35:43 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-09-07 00:35:43 | INFO | train | epoch 027 | loss 2.18 | trans_loss 5.2 | nll_loss 2.535 | w2v_ctc_loss 0.511 | task_loss 1.361 | task_loss_gen 3.483 | contrastive_loss 0 | total 6703.69 | n_correct 3455.14 | ppl 5.8 | accuracy 51.541 | wps 16586.9 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 32143 | lr 7.88809e-05 | gnorm 0.355 | clip 0 | loss_scale 32 | train_wall 854 | gb_free 13.3 | wall 29056
2023-09-07 00:35:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 00:35:44 | INFO | fairseq.trainer | begin training epoch 28
2023-09-07 00:35:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 00:36:33 | INFO | train_inner | epoch 028:     57 / 1191 loss=2.166, trans_loss=5.183, nll_loss=2.512, w2v_ctc_loss=0.5, task_loss=0.822, task_loss_gen=4.201, contrastive_loss=0, total=6701.35, n_correct=3478.09, ppl=5.71, accuracy=51.901, wps=10942.4, ups=0.82, wpb=13402.7, bsz=455.5, num_updates=32200, lr=7.8811e-05, gnorm=0.324, clip=0, loss_scale=32, train_wall=71, gb_free=6.4, wall=29106
2023-09-07 00:37:45 | INFO | train_inner | epoch 028:    157 / 1191 loss=2.186, trans_loss=5.198, nll_loss=2.532, w2v_ctc_loss=0.522, task_loss=0.913, task_loss_gen=4.15, contrastive_loss=0, total=6662.36, n_correct=3431, ppl=5.78, accuracy=51.498, wps=18463, ups=1.39, wpb=13324.7, bsz=429.7, num_updates=32300, lr=7.86889e-05, gnorm=0.335, clip=0, loss_scale=32, train_wall=71, gb_free=13.4, wall=29178
2023-09-07 00:38:58 | INFO | train_inner | epoch 028:    257 / 1191 loss=2.174, trans_loss=5.193, nll_loss=2.524, w2v_ctc_loss=0.51, task_loss=0.838, task_loss_gen=4.29, contrastive_loss=0, total=6695.94, n_correct=3467.12, ppl=5.75, accuracy=51.779, wps=18439.5, ups=1.38, wpb=13391.9, bsz=454.4, num_updates=32400, lr=7.85674e-05, gnorm=0.336, clip=0, loss_scale=32, train_wall=72, gb_free=13.4, wall=29251
2023-09-07 00:40:10 | INFO | train_inner | epoch 028:    357 / 1191 loss=2.165, trans_loss=5.181, nll_loss=2.51, w2v_ctc_loss=0.502, task_loss=1.229, task_loss_gen=3.867, contrastive_loss=0, total=6727.32, n_correct=3499.89, ppl=5.7, accuracy=52.025, wps=18515.9, ups=1.38, wpb=13454.6, bsz=459.2, num_updates=32500, lr=7.84465e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=72, gb_free=13.4, wall=29323
2023-09-07 00:41:24 | INFO | train_inner | epoch 028:    457 / 1191 loss=2.166, trans_loss=5.185, nll_loss=2.515, w2v_ctc_loss=0.501, task_loss=0.998, task_loss_gen=3.774, contrastive_loss=0, total=6777.32, n_correct=3522.5, ppl=5.72, accuracy=51.975, wps=18432.9, ups=1.36, wpb=13554.6, bsz=471.8, num_updates=32600, lr=7.8326e-05, gnorm=0.331, clip=0, loss_scale=32, train_wall=73, gb_free=12.7, wall=29397
2023-09-07 00:42:36 | INFO | train_inner | epoch 028:    557 / 1191 loss=2.17, trans_loss=5.189, nll_loss=2.52, w2v_ctc_loss=0.504, task_loss=1.109, task_loss_gen=4.658, contrastive_loss=0, total=6695.22, n_correct=3471.69, ppl=5.74, accuracy=51.853, wps=18583.4, ups=1.39, wpb=13390.4, bsz=451.6, num_updates=32700, lr=7.82062e-05, gnorm=0.35, clip=0, loss_scale=32, train_wall=71, gb_free=13.3, wall=29469
2023-09-07 00:43:48 | INFO | train_inner | epoch 028:    657 / 1191 loss=2.172, trans_loss=5.188, nll_loss=2.52, w2v_ctc_loss=0.509, task_loss=1.623, task_loss_gen=4.12, contrastive_loss=0, total=6769.44, n_correct=3510.65, ppl=5.73, accuracy=51.86, wps=18789.7, ups=1.39, wpb=13538.9, bsz=460.3, num_updates=32800, lr=7.80869e-05, gnorm=0.359, clip=0, loss_scale=32, train_wall=71, gb_free=13.4, wall=29541
2023-09-07 00:45:01 | INFO | train_inner | epoch 028:    757 / 1191 loss=2.172, trans_loss=5.189, nll_loss=2.52, w2v_ctc_loss=0.51, task_loss=1.287, task_loss_gen=3.726, contrastive_loss=0, total=6697.15, n_correct=3470.58, ppl=5.74, accuracy=51.822, wps=18447.8, ups=1.38, wpb=13394.3, bsz=455.2, num_updates=32900, lr=7.79681e-05, gnorm=0.341, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=29614
2023-09-07 00:46:13 | INFO | train_inner | epoch 028:    857 / 1191 loss=2.169, trans_loss=5.186, nll_loss=2.517, w2v_ctc_loss=0.504, task_loss=1.364, task_loss_gen=3.509, contrastive_loss=0, total=6642.02, n_correct=3444.46, ppl=5.72, accuracy=51.859, wps=18461.6, ups=1.39, wpb=13284, bsz=451.4, num_updates=33000, lr=7.78499e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=71, gb_free=13, wall=29686
2023-09-07 00:47:25 | INFO | train_inner | epoch 028:    957 / 1191 loss=2.186, trans_loss=5.203, nll_loss=2.538, w2v_ctc_loss=0.519, task_loss=1.401, task_loss_gen=3.845, contrastive_loss=0, total=6645.42, n_correct=3419.89, ppl=5.81, accuracy=51.462, wps=18353.6, ups=1.38, wpb=13290.8, bsz=437.2, num_updates=33100, lr=7.77322e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=71, gb_free=11.2, wall=29758
2023-09-07 00:48:38 | INFO | train_inner | epoch 028:   1057 / 1191 loss=2.183, trans_loss=5.204, nll_loss=2.54, w2v_ctc_loss=0.508, task_loss=1.066, task_loss_gen=3.984, contrastive_loss=0, total=6685.52, n_correct=3432.98, ppl=5.82, accuracy=51.349, wps=18330.9, ups=1.37, wpb=13371, bsz=440.5, num_updates=33200, lr=7.76151e-05, gnorm=0.333, clip=0, loss_scale=32, train_wall=72, gb_free=13.6, wall=29831
2023-09-07 00:49:51 | INFO | train_inner | epoch 028:   1157 / 1191 loss=2.177, trans_loss=5.196, nll_loss=2.53, w2v_ctc_loss=0.504, task_loss=1.108, task_loss_gen=4.002, contrastive_loss=0, total=6679.26, n_correct=3447.25, ppl=5.78, accuracy=51.611, wps=18335, ups=1.37, wpb=13358.5, bsz=444.1, num_updates=33300, lr=7.74984e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=72, gb_free=12.5, wall=29904
2023-09-07 00:50:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 00:50:50 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.526 | trans_loss 6.118 | nll_loss 3.639 | w2v_ctc_loss 1.266 | task_loss 12.525 | task_loss_gen 9.566 | contrastive_loss 0 | total 6138.43 | n_correct 3070.29 | ppl 12.46 | accuracy 50.017 | uer 16.46 | wer 18.323 | raw_wer 18.323 | bleu 5.62 | wps 1583.7 | wpb 6138.4 | bsz 201.1 | num_updates 33334 | best_bleu 5.62
2023-09-07 00:50:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 33334 updates
2023-09-07 00:50:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 00:50:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 00:51:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 28 @ 33334 updates, score 5.62) (writing took 13.28196005395148 seconds)
2023-09-07 00:51:04 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-09-07 00:51:04 | INFO | train | epoch 028 | loss 2.173 | trans_loss 5.19 | nll_loss 2.522 | w2v_ctc_loss 0.508 | task_loss 1.15 | task_loss_gen 3.981 | contrastive_loss 0 | total 6703.69 | n_correct 3471.02 | ppl 5.74 | accuracy 51.778 | wps 17345.3 | ups 1.29 | wpb 13407.4 | bsz 452.1 | num_updates 33334 | lr 7.74589e-05 | gnorm 0.339 | clip 0 | loss_scale 32 | train_wall 853 | gb_free 13 | wall 29977
2023-09-07 00:51:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 00:51:04 | INFO | fairseq.trainer | begin training epoch 29
2023-09-07 00:51:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 00:52:00 | INFO | train_inner | epoch 029:     66 / 1191 loss=2.155, trans_loss=5.166, nll_loss=2.49, w2v_ctc_loss=0.5, task_loss=0.991, task_loss_gen=3.679, contrastive_loss=0, total=6803.37, n_correct=3570.05, ppl=5.62, accuracy=52.475, wps=10512, ups=0.77, wpb=13606.7, bsz=476.6, num_updates=33400, lr=7.73823e-05, gnorm=0.33, clip=0, loss_scale=32, train_wall=72, gb_free=15.2, wall=30033
2023-09-07 00:53:13 | INFO | train_inner | epoch 029:    166 / 1191 loss=2.168, trans_loss=5.182, nll_loss=2.51, w2v_ctc_loss=0.5, task_loss=0.951, task_loss_gen=4.243, contrastive_loss=0, total=6680.35, n_correct=3472.22, ppl=5.7, accuracy=51.977, wps=18488.6, ups=1.38, wpb=13360.7, bsz=438.8, num_updates=33500, lr=7.72667e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=71, gb_free=12.9, wall=30105
2023-09-07 00:54:25 | INFO | train_inner | epoch 029:    266 / 1191 loss=2.166, trans_loss=5.183, nll_loss=2.512, w2v_ctc_loss=0.494, task_loss=1.474, task_loss_gen=3.974, contrastive_loss=0, total=6674.12, n_correct=3463.62, ppl=5.71, accuracy=51.896, wps=18295.6, ups=1.37, wpb=13348.2, bsz=453.7, num_updates=33600, lr=7.71517e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=72, gb_free=13.7, wall=30178
2023-09-07 00:55:39 | INFO | train_inner | epoch 029:    366 / 1191 loss=2.166, trans_loss=5.181, nll_loss=2.511, w2v_ctc_loss=0.503, task_loss=1.163, task_loss_gen=3.873, contrastive_loss=0, total=6735.44, n_correct=3507.68, ppl=5.7, accuracy=52.078, wps=18423.6, ups=1.37, wpb=13470.9, bsz=449.9, num_updates=33700, lr=7.70371e-05, gnorm=0.335, clip=0, loss_scale=32, train_wall=72, gb_free=12.9, wall=30252
2023-09-07 00:56:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-07 00:56:53 | INFO | train_inner | epoch 029:    467 / 1191 loss=2.159, trans_loss=5.176, nll_loss=2.503, w2v_ctc_loss=0.496, task_loss=1.042, task_loss_gen=3.696, contrastive_loss=0, total=6788.86, n_correct=3539.86, ppl=5.67, accuracy=52.142, wps=18305.8, ups=1.35, wpb=13577.7, bsz=467.9, num_updates=33800, lr=7.69231e-05, gnorm=0.334, clip=0, loss_scale=32, train_wall=73, gb_free=13.6, wall=30326
2023-09-07 00:58:05 | INFO | train_inner | epoch 029:    567 / 1191 loss=2.184, trans_loss=5.198, nll_loss=2.531, w2v_ctc_loss=0.515, task_loss=2.034, task_loss_gen=4.363, contrastive_loss=0, total=6577.57, n_correct=3383.29, ppl=5.78, accuracy=51.437, wps=18169.1, ups=1.38, wpb=13155.1, bsz=421.4, num_updates=33900, lr=7.68095e-05, gnorm=0.378, clip=0, loss_scale=32, train_wall=71, gb_free=14.3, wall=30398
2023-09-07 00:59:17 | INFO | train_inner | epoch 029:    667 / 1191 loss=2.158, trans_loss=5.168, nll_loss=2.493, w2v_ctc_loss=0.503, task_loss=1.447, task_loss_gen=3.564, contrastive_loss=0, total=6760.39, n_correct=3537.41, ppl=5.63, accuracy=52.326, wps=18761.4, ups=1.39, wpb=13520.8, bsz=469.3, num_updates=34000, lr=7.66965e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=71, gb_free=11.8, wall=30470
2023-09-07 00:59:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 00:59:52 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.515 | trans_loss 6.113 | nll_loss 3.635 | w2v_ctc_loss 1.24 | task_loss 12.554 | task_loss_gen 10.374 | contrastive_loss 0 | total 6138.43 | n_correct 3071.14 | ppl 12.43 | accuracy 50.031 | uer 16.722 | wer 18.468 | raw_wer 18.468 | bleu 5.65 | wps 1592.4 | wpb 6138.4 | bsz 201.1 | num_updates 34000 | best_bleu 5.65
2023-09-07 00:59:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34000 updates
2023-09-07 00:59:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_29_34000.pt
2023-09-07 00:59:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_29_34000.pt
2023-09-07 01:00:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_29_34000.pt (epoch 29 @ 34000 updates, score 5.65) (writing took 14.360072415904142 seconds)
2023-09-07 01:01:19 | INFO | train_inner | epoch 029:    767 / 1191 loss=2.166, trans_loss=5.179, nll_loss=2.508, w2v_ctc_loss=0.504, task_loss=1.214, task_loss_gen=3.87, contrastive_loss=0, total=6664.13, n_correct=3465.01, ppl=5.69, accuracy=51.995, wps=10956.7, ups=0.82, wpb=13328.3, bsz=450.3, num_updates=34100, lr=7.6584e-05, gnorm=0.34, clip=0, loss_scale=32, train_wall=71, gb_free=7.4, wall=30592
2023-09-07 01:02:32 | INFO | train_inner | epoch 029:    867 / 1191 loss=2.178, trans_loss=5.193, nll_loss=2.526, w2v_ctc_loss=0.512, task_loss=1.073, task_loss_gen=4.101, contrastive_loss=0, total=6659.43, n_correct=3442.59, ppl=5.76, accuracy=51.695, wps=18314.2, ups=1.38, wpb=13318.9, bsz=435.3, num_updates=34200, lr=7.64719e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=71, gb_free=10.8, wall=30665
2023-09-07 01:03:45 | INFO | train_inner | epoch 029:    967 / 1191 loss=2.168, trans_loss=5.181, nll_loss=2.51, w2v_ctc_loss=0.509, task_loss=1.41, task_loss_gen=3.948, contrastive_loss=0, total=6728.65, n_correct=3499.55, ppl=5.7, accuracy=52.01, wps=18433.3, ups=1.37, wpb=13457.3, bsz=461.6, num_updates=34300, lr=7.63604e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=72, gb_free=12.1, wall=30738
2023-09-07 01:04:57 | INFO | train_inner | epoch 029:   1067 / 1191 loss=2.166, trans_loss=5.18, nll_loss=2.509, w2v_ctc_loss=0.502, task_loss=1.294, task_loss_gen=3.794, contrastive_loss=0, total=6711.89, n_correct=3496.6, ppl=5.69, accuracy=52.096, wps=18576.2, ups=1.38, wpb=13423.8, bsz=456.2, num_updates=34400, lr=7.62493e-05, gnorm=0.338, clip=0, loss_scale=32, train_wall=71, gb_free=14.3, wall=30810
2023-09-07 01:06:09 | INFO | train_inner | epoch 029:   1167 / 1191 loss=2.161, trans_loss=5.179, nll_loss=2.508, w2v_ctc_loss=0.494, task_loss=0.805, task_loss_gen=3.964, contrastive_loss=0, total=6748.65, n_correct=3520.91, ppl=5.69, accuracy=52.172, wps=18624.1, ups=1.38, wpb=13497.3, bsz=461.5, num_updates=34500, lr=7.61387e-05, gnorm=0.335, clip=0, loss_scale=32, train_wall=72, gb_free=15.3, wall=30882
2023-09-07 01:06:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 01:07:02 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.513 | trans_loss 6.11 | nll_loss 3.633 | w2v_ctc_loss 1.238 | task_loss 4.225 | task_loss_gen 8.923 | contrastive_loss 0 | total 6138.43 | n_correct 3074.43 | ppl 12.41 | accuracy 50.085 | uer 16.511 | wer 18.375 | raw_wer 18.375 | bleu 5.89 | wps 1604.6 | wpb 6138.4 | bsz 201.1 | num_updates 34524 | best_bleu 5.89
2023-09-07 01:07:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 34524 updates
2023-09-07 01:07:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 01:07:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 01:07:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 29 @ 34524 updates, score 5.89) (writing took 14.773919677943923 seconds)
2023-09-07 01:07:17 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-09-07 01:07:17 | INFO | train | epoch 029 | loss 2.166 | trans_loss 5.181 | nll_loss 2.51 | w2v_ctc_loss 0.502 | task_loss 1.243 | task_loss_gen 3.932 | contrastive_loss 0 | total 6704.62 | n_correct 3487.48 | ppl 5.69 | accuracy 52.016 | wps 16403.5 | ups 1.22 | wpb 13409.2 | bsz 452.3 | num_updates 34524 | lr 7.61122e-05 | gnorm 0.343 | clip 0 | loss_scale 32 | train_wall 853 | gb_free 13.5 | wall 30950
2023-09-07 01:07:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 01:07:17 | INFO | fairseq.trainer | begin training epoch 30
2023-09-07 01:07:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 01:08:19 | INFO | train_inner | epoch 030:     76 / 1191 loss=2.142, trans_loss=5.154, nll_loss=2.475, w2v_ctc_loss=0.488, task_loss=0.685, task_loss_gen=3.979, contrastive_loss=0, total=6849.81, n_correct=3623, ppl=5.56, accuracy=52.892, wps=10553.1, ups=0.77, wpb=13699.6, bsz=486.1, num_updates=34600, lr=7.60286e-05, gnorm=0.332, clip=0, loss_scale=32, train_wall=71, gb_free=13.8, wall=31012
2023-09-07 01:09:31 | INFO | train_inner | epoch 030:    176 / 1191 loss=2.16, trans_loss=5.175, nll_loss=2.5, w2v_ctc_loss=0.49, task_loss=0.811, task_loss_gen=4.723, contrastive_loss=0, total=6657.78, n_correct=3467.56, ppl=5.66, accuracy=52.083, wps=18579.4, ups=1.4, wpb=13315.6, bsz=441, num_updates=34700, lr=7.5919e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=71, gb_free=14.5, wall=31084
2023-09-07 01:10:43 | INFO | train_inner | epoch 030:    276 / 1191 loss=2.152, trans_loss=5.161, nll_loss=2.483, w2v_ctc_loss=0.495, task_loss=1.639, task_loss_gen=4.56, contrastive_loss=0, total=6769.26, n_correct=3554.31, ppl=5.59, accuracy=52.507, wps=18641.3, ups=1.38, wpb=13538.5, bsz=465.3, num_updates=34800, lr=7.58098e-05, gnorm=0.371, clip=0, loss_scale=32, train_wall=72, gb_free=14.3, wall=31156
2023-09-07 01:11:57 | INFO | train_inner | epoch 030:    376 / 1191 loss=2.142, trans_loss=5.155, nll_loss=2.476, w2v_ctc_loss=0.488, task_loss=1.14, task_loss_gen=3.611, contrastive_loss=0, total=6850.27, n_correct=3620.31, ppl=5.56, accuracy=52.849, wps=18654.7, ups=1.36, wpb=13700.5, bsz=485.4, num_updates=34900, lr=7.57011e-05, gnorm=0.33, clip=0, loss_scale=32, train_wall=73, gb_free=13.7, wall=31230
2023-09-07 01:13:09 | INFO | train_inner | epoch 030:    476 / 1191 loss=2.162, trans_loss=5.174, nll_loss=2.5, w2v_ctc_loss=0.498, task_loss=1.184, task_loss_gen=4.026, contrastive_loss=0, total=6641.83, n_correct=3461.25, ppl=5.66, accuracy=52.113, wps=18409.4, ups=1.39, wpb=13283.7, bsz=444.7, num_updates=35000, lr=7.55929e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=71, gb_free=12.9, wall=31302
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:0')
2023-09-07 01:14:22 | INFO | train_inner | epoch 030:    576 / 1191 loss=2.165, trans_loss=5.177, nll_loss=2.504, w2v_ctc_loss=0.503, task_loss=1.005, task_loss_gen=4.003, contrastive_loss=0, total=6679.82, n_correct=3475.69, ppl=5.67, accuracy=52.033, wps=18265.7, ups=1.37, wpb=13359.6, bsz=445.4, num_updates=35100, lr=7.54851e-05, gnorm=0.347, clip=0, loss_scale=32, train_wall=72, gb_free=11.3, wall=31375
2023-09-07 01:15:35 | INFO | train_inner | epoch 030:    676 / 1191 loss=2.174, trans_loss=5.184, nll_loss=2.513, w2v_ctc_loss=0.505, task_loss=1.84, task_loss_gen=4.218, contrastive_loss=0, total=6572.86, n_correct=3400.35, ppl=5.71, accuracy=51.733, wps=18141, ups=1.38, wpb=13145.7, bsz=422.5, num_updates=35200, lr=7.53778e-05, gnorm=0.362, clip=0, loss_scale=32, train_wall=72, gb_free=13.8, wall=31448
2023-09-07 01:16:48 | INFO | train_inner | epoch 030:    776 / 1191 loss=2.172, trans_loss=5.184, nll_loss=2.513, w2v_ctc_loss=0.503, task_loss=1.927, task_loss_gen=4.272, contrastive_loss=0, total=6650.65, n_correct=3443.57, ppl=5.71, accuracy=51.778, wps=18117.7, ups=1.36, wpb=13301.3, bsz=438.1, num_updates=35300, lr=7.5271e-05, gnorm=0.366, clip=0, loss_scale=32, train_wall=73, gb_free=13, wall=31521
2023-09-07 01:18:01 | INFO | train_inner | epoch 030:    876 / 1191 loss=2.162, trans_loss=5.177, nll_loss=2.505, w2v_ctc_loss=0.496, task_loss=1.328, task_loss_gen=3.908, contrastive_loss=0, total=6686.47, n_correct=3486.55, ppl=5.67, accuracy=52.143, wps=18302.3, ups=1.37, wpb=13372.9, bsz=447.2, num_updates=35400, lr=7.51646e-05, gnorm=0.339, clip=0, loss_scale=32, train_wall=72, gb_free=15.7, wall=31594
2023-09-07 01:19:14 | INFO | train_inner | epoch 030:    976 / 1191 loss=2.168, trans_loss=5.177, nll_loss=2.505, w2v_ctc_loss=0.508, task_loss=1.152, task_loss_gen=4.229, contrastive_loss=0, total=6650.45, n_correct=3457.16, ppl=5.68, accuracy=51.984, wps=18319.8, ups=1.38, wpb=13300.9, bsz=445.3, num_updates=35500, lr=7.50587e-05, gnorm=0.346, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=31667
2023-09-07 01:20:27 | INFO | train_inner | epoch 030:   1076 / 1191 loss=2.164, trans_loss=5.178, nll_loss=2.505, w2v_ctc_loss=0.505, task_loss=1.216, task_loss_gen=3.66, contrastive_loss=0, total=6760.55, n_correct=3526.86, ppl=5.68, accuracy=52.168, wps=18597.3, ups=1.38, wpb=13521.1, bsz=455.7, num_updates=35600, lr=7.49532e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=72, gb_free=13, wall=31740
2023-09-07 01:21:40 | INFO | train_inner | epoch 030:   1176 / 1191 loss=2.164, trans_loss=5.181, nll_loss=2.51, w2v_ctc_loss=0.502, task_loss=1.006, task_loss_gen=3.807, contrastive_loss=0, total=6693.2, n_correct=3490.92, ppl=5.7, accuracy=52.156, wps=18331.6, ups=1.37, wpb=13386.4, bsz=453.9, num_updates=35700, lr=7.48481e-05, gnorm=0.337, clip=0, loss_scale=32, train_wall=72, gb_free=14.4, wall=31813
2023-09-07 01:21:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:7')
2023-09-07 01:22:26 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.501 | trans_loss 6.1 | nll_loss 3.619 | w2v_ctc_loss 1.221 | task_loss 8.433 | task_loss_gen 8.402 | contrastive_loss 0 | total 6138.43 | n_correct 3079.14 | ppl 12.29 | accuracy 50.162 | uer 16.543 | wer 18.256 | raw_wer 18.256 | bleu 5.86 | wps 1544.3 | wpb 6138.4 | bsz 201.1 | num_updates 35715 | best_bleu 5.89
2023-09-07 01:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 35715 updates
2023-09-07 01:22:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.8600.pt
2023-09-07 01:22:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.8600.pt
2023-09-07 01:22:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.8600.pt (epoch 30 @ 35715 updates, score 5.86) (writing took 7.627082039020024 seconds)
2023-09-07 01:22:34 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-09-07 01:22:34 | INFO | train | epoch 030 | loss 2.161 | trans_loss 5.173 | nll_loss 2.499 | w2v_ctc_loss 0.498 | task_loss 1.24 | task_loss_gen 4.082 | contrastive_loss 0 | total 6703.69 | n_correct 3499.07 | ppl 5.65 | accuracy 52.196 | wps 17411.8 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 35715 | lr 7.48324e-05 | gnorm 0.347 | clip 0 | loss_scale 32 | train_wall 856 | gb_free 14.3 | wall 31867
2023-09-07 01:22:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 01:22:34 | INFO | fairseq.trainer | begin training epoch 31
2023-09-07 01:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 01:23:44 | INFO | train_inner | epoch 031:     85 / 1191 loss=2.17, trans_loss=5.18, nll_loss=2.507, w2v_ctc_loss=0.5, task_loss=0.771, task_loss_gen=4.782, contrastive_loss=0, total=6595.99, n_correct=3420.7, ppl=5.69, accuracy=51.86, wps=10634.1, ups=0.81, wpb=13192, bsz=419.6, num_updates=35800, lr=7.47435e-05, gnorm=0.342, clip=0, loss_scale=32, train_wall=72, gb_free=6.1, wall=31937
2023-09-07 01:24:57 | INFO | train_inner | epoch 031:    185 / 1191 loss=2.15, trans_loss=5.16, nll_loss=2.482, w2v_ctc_loss=0.489, task_loss=0.953, task_loss_gen=4.149, contrastive_loss=0, total=6732.15, n_correct=3538.8, ppl=5.58, accuracy=52.566, wps=18322.2, ups=1.36, wpb=13464.3, bsz=458.4, num_updates=35900, lr=7.46393e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=73, gb_free=13.4, wall=32010
2023-09-07 01:26:09 | INFO | train_inner | epoch 031:    285 / 1191 loss=2.164, trans_loss=5.17, nll_loss=2.495, w2v_ctc_loss=0.503, task_loss=0.837, task_loss_gen=5.516, contrastive_loss=0, total=6551.33, n_correct=3412.8, ppl=5.64, accuracy=52.093, wps=18208.2, ups=1.39, wpb=13102.7, bsz=431.1, num_updates=36000, lr=7.45356e-05, gnorm=0.345, clip=0, loss_scale=64, train_wall=71, gb_free=12.9, wall=32082
2023-09-07 01:26:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 01:26:43 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.52 | trans_loss 6.097 | nll_loss 3.614 | w2v_ctc_loss 1.29 | task_loss 33.171 | task_loss_gen 19.22 | contrastive_loss 0 | total 6138.43 | n_correct 3090.86 | ppl 12.25 | accuracy 50.353 | uer 16.578 | wer 18.252 | raw_wer 18.252 | bleu 5.83 | wps 1611.5 | wpb 6138.4 | bsz 201.1 | num_updates 36000 | best_bleu 5.89
2023-09-07 01:26:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36000 updates
2023-09-07 01:26:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_31_36000.pt
2023-09-07 01:26:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_31_36000.pt
2023-09-07 01:26:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_31_36000.pt (epoch 31 @ 36000 updates, score 5.83) (writing took 8.269139070995152 seconds)
--Backword ST Loss tensor(2258.9707, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1080.6355, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-07 01:28:05 | INFO | train_inner | epoch 031:    385 / 1191 loss=2.149, trans_loss=5.158, nll_loss=2.479, w2v_ctc_loss=0.49, task_loss=0.646, task_loss_gen=5.432, contrastive_loss=0, total=6755.84, n_correct=3555.28, ppl=5.57, accuracy=52.625, wps=11683.1, ups=0.86, wpb=13511.7, bsz=458.1, num_updates=36100, lr=7.44323e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=72, gb_free=4.3, wall=32198
2023-09-07 01:29:18 | INFO | train_inner | epoch 031:    485 / 1191 loss=2.169, trans_loss=5.182, nll_loss=2.511, w2v_ctc_loss=0.499, task_loss=0.691, task_loss_gen=5.989, contrastive_loss=0, total=6661.44, n_correct=3459.43, ppl=5.7, accuracy=51.932, wps=18287.5, ups=1.37, wpb=13322.9, bsz=427.9, num_updates=36200, lr=7.43294e-05, gnorm=0.343, clip=0, loss_scale=64, train_wall=72, gb_free=11.2, wall=32271
2023-09-07 01:30:31 | INFO | train_inner | epoch 031:    585 / 1191 loss=2.157, trans_loss=5.166, nll_loss=2.489, w2v_ctc_loss=0.496, task_loss=0.645, task_loss_gen=5.538, contrastive_loss=0, total=6682.32, n_correct=3498.7, ppl=5.61, accuracy=52.358, wps=18321.4, ups=1.37, wpb=13364.6, bsz=450.3, num_updates=36300, lr=7.4227e-05, gnorm=0.337, clip=0, loss_scale=64, train_wall=72, gb_free=14.6, wall=32343
2023-09-07 01:31:43 | INFO | train_inner | epoch 031:    685 / 1191 loss=2.146, trans_loss=5.154, nll_loss=2.474, w2v_ctc_loss=0.493, task_loss=0.643, task_loss_gen=4.606, contrastive_loss=0, total=6823.18, n_correct=3599.12, ppl=5.56, accuracy=52.748, wps=18793.6, ups=1.38, wpb=13646.4, bsz=476.3, num_updates=36400, lr=7.41249e-05, gnorm=0.338, clip=0, loss_scale=64, train_wall=72, gb_free=14.3, wall=32416
2023-09-07 01:32:56 | INFO | train_inner | epoch 031:    785 / 1191 loss=2.145, trans_loss=5.154, nll_loss=2.475, w2v_ctc_loss=0.493, task_loss=0.683, task_loss_gen=5.009, contrastive_loss=0, total=6798.08, n_correct=3584.88, ppl=5.56, accuracy=52.734, wps=18637, ups=1.37, wpb=13596.2, bsz=476.7, num_updates=36500, lr=7.40233e-05, gnorm=0.34, clip=0, loss_scale=64, train_wall=72, gb_free=6.1, wall=32489
2023-09-07 01:33:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-09-07 01:34:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-07 01:34:10 | INFO | train_inner | epoch 031:    887 / 1191 loss=2.158, trans_loss=5.169, nll_loss=2.494, w2v_ctc_loss=0.497, task_loss=0.621, task_loss_gen=5.84, contrastive_loss=0, total=6609.24, n_correct=3456.59, ppl=5.63, accuracy=52.299, wps=17854.1, ups=1.35, wpb=13218.5, bsz=443.5, num_updates=36600, lr=7.39221e-05, gnorm=0.341, clip=0, loss_scale=16, train_wall=73, gb_free=13.8, wall=32563
2023-09-07 01:35:23 | INFO | train_inner | epoch 031:    987 / 1191 loss=2.157, trans_loss=5.166, nll_loss=2.489, w2v_ctc_loss=0.498, task_loss=1.488, task_loss_gen=4.019, contrastive_loss=0, total=6712.51, n_correct=3513.72, ppl=5.61, accuracy=52.346, wps=18477.7, ups=1.38, wpb=13425, bsz=455.1, num_updates=36700, lr=7.38213e-05, gnorm=0.405, clip=0, loss_scale=16, train_wall=72, gb_free=14.2, wall=32636
2023-09-07 01:36:35 | INFO | train_inner | epoch 031:   1087 / 1191 loss=2.141, trans_loss=5.155, nll_loss=2.476, w2v_ctc_loss=0.488, task_loss=1.202, task_loss_gen=3.388, contrastive_loss=0, total=6884.21, n_correct=3640.2, ppl=5.56, accuracy=52.878, wps=19080.8, ups=1.39, wpb=13768.4, bsz=489.3, num_updates=36800, lr=7.3721e-05, gnorm=0.386, clip=0, loss_scale=16, train_wall=72, gb_free=12, wall=32708
2023-09-07 01:37:48 | INFO | train_inner | epoch 031:   1187 / 1191 loss=2.161, trans_loss=5.174, nll_loss=2.501, w2v_ctc_loss=0.498, task_loss=1.615, task_loss_gen=3.87, contrastive_loss=0, total=6656.88, n_correct=3467.38, ppl=5.66, accuracy=52.087, wps=18334, ups=1.38, wpb=13313.8, bsz=445.6, num_updates=36900, lr=7.3621e-05, gnorm=0.4, clip=0, loss_scale=16, train_wall=72, gb_free=13.8, wall=32781
2023-09-07 01:37:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2804.1831, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1383.3679, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(3304.0090, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1876.3541, device='cuda:7', grad_fn=<MulBackward0>)
Traceback (most recent call last):
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
--Backword ST Loss tensor(2053.5815, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1043.9663, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2567.4431, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1230.9956, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2510.1753, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1162.7876, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2824.1311, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1295.1917, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(3350.7915, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1570.1519, device='cuda:4', grad_fn=<MulBackward0>)
2023-09-07 01:38:27 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.504 | trans_loss 6.105 | nll_loss 3.623 | w2v_ctc_loss 1.218 | task_loss 8.166 | task_loss_gen 9.027 | contrastive_loss 0 | total 6138.43 | n_correct 3082.43 | ppl 12.32 | accuracy 50.215 | uer 16.375 | wer 18.245 | raw_wer 18.245 | bleu 5.96 | wps 1514.2 | wpb 6138.4 | bsz 201.1 | num_updates 36904 | best_bleu 5.96
2023-09-07 01:38:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 36904 updates
2023-09-07 01:38:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 01:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 01:38:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 31 @ 36904 updates, score 5.96) (writing took 13.870663087000139 seconds)
2023-09-07 01:38:41 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-09-07 01:38:41 | INFO | train | epoch 031 | loss 2.156 | trans_loss 5.166 | nll_loss 2.489 | w2v_ctc_loss 0.495 | task_loss 0.908 | task_loss_gen 4.841 | contrastive_loss 0 | total 6703 | n_correct 3510.69 | ppl 5.61 | accuracy 52.375 | wps 16482 | ups 1.23 | wpb 13406 | bsz 452 | num_updates 36904 | lr 7.3617e-05 | gnorm 0.355 | clip 0 | loss_scale 16 | train_wall 856 | gb_free 10 | wall 32834
2023-09-07 01:38:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 01:38:41 | INFO | fairseq.trainer | begin training epoch 32
2023-09-07 01:38:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 01:39:58 | INFO | train_inner | epoch 032:     96 / 1191 loss=2.146, trans_loss=5.151, nll_loss=2.47, w2v_ctc_loss=0.485, task_loss=1.61, task_loss_gen=3.582, contrastive_loss=0, total=6689.32, n_correct=3524.8, ppl=5.54, accuracy=52.693, wps=10268.3, ups=0.77, wpb=13378.6, bsz=452.4, num_updates=37000, lr=7.35215e-05, gnorm=0.394, clip=0, loss_scale=16, train_wall=71, gb_free=12, wall=32911
2023-09-07 01:41:10 | INFO | train_inner | epoch 032:    196 / 1191 loss=2.146, trans_loss=5.157, nll_loss=2.477, w2v_ctc_loss=0.487, task_loss=1.577, task_loss_gen=3.552, contrastive_loss=0, total=6806.67, n_correct=3583.2, ppl=5.57, accuracy=52.642, wps=18766.1, ups=1.38, wpb=13613.3, bsz=466.5, num_updates=37100, lr=7.34223e-05, gnorm=0.406, clip=0, loss_scale=16, train_wall=72, gb_free=10.5, wall=32983
2023-09-07 01:42:23 | INFO | train_inner | epoch 032:    296 / 1191 loss=2.153, trans_loss=5.163, nll_loss=2.485, w2v_ctc_loss=0.492, task_loss=1.498, task_loss_gen=3.49, contrastive_loss=0, total=6678.58, n_correct=3503.08, ppl=5.6, accuracy=52.452, wps=18322.5, ups=1.37, wpb=13357.2, bsz=446.2, num_updates=37200, lr=7.33236e-05, gnorm=0.384, clip=0, loss_scale=16, train_wall=72, gb_free=13.7, wall=33056
2023-09-07 01:43:36 | INFO | train_inner | epoch 032:    396 / 1191 loss=2.144, trans_loss=5.15, nll_loss=2.469, w2v_ctc_loss=0.482, task_loss=1.284, task_loss_gen=3.264, contrastive_loss=0, total=6758.65, n_correct=3561.27, ppl=5.53, accuracy=52.692, wps=18644, ups=1.38, wpb=13517.3, bsz=458.9, num_updates=37300, lr=7.32252e-05, gnorm=0.365, clip=0, loss_scale=16, train_wall=72, gb_free=7.7, wall=33129
2023-09-07 01:44:49 | INFO | train_inner | epoch 032:    496 / 1191 loss=2.148, trans_loss=5.158, nll_loss=2.479, w2v_ctc_loss=0.488, task_loss=1.962, task_loss_gen=3.953, contrastive_loss=0, total=6744.1, n_correct=3550.39, ppl=5.58, accuracy=52.644, wps=18502.4, ups=1.37, wpb=13488.2, bsz=454.9, num_updates=37400, lr=7.31272e-05, gnorm=0.44, clip=0, loss_scale=16, train_wall=72, gb_free=14, wall=33202
2023-09-07 01:46:01 | INFO | train_inner | epoch 032:    596 / 1191 loss=2.153, trans_loss=5.163, nll_loss=2.485, w2v_ctc_loss=0.493, task_loss=2.314, task_loss_gen=3.729, contrastive_loss=0, total=6688.42, n_correct=3513.76, ppl=5.6, accuracy=52.535, wps=18380.6, ups=1.37, wpb=13376.8, bsz=444.7, num_updates=37500, lr=7.30297e-05, gnorm=0.45, clip=0, loss_scale=16, train_wall=72, gb_free=11.9, wall=33274
2023-09-07 01:47:15 | INFO | train_inner | epoch 032:    696 / 1191 loss=2.157, trans_loss=5.164, nll_loss=2.486, w2v_ctc_loss=0.491, task_loss=1.605, task_loss_gen=3.613, contrastive_loss=0, total=6670, n_correct=3489.64, ppl=5.6, accuracy=52.318, wps=18179.2, ups=1.36, wpb=13340, bsz=436.6, num_updates=37600, lr=7.29325e-05, gnorm=0.388, clip=0, loss_scale=16, train_wall=72, gb_free=14.1, wall=33348
2023-09-07 01:48:28 | INFO | train_inner | epoch 032:    796 / 1191 loss=2.151, trans_loss=5.159, nll_loss=2.48, w2v_ctc_loss=0.494, task_loss=1.48, task_loss_gen=3.248, contrastive_loss=0, total=6761.99, n_correct=3552.98, ppl=5.58, accuracy=52.543, wps=18605.5, ups=1.38, wpb=13524, bsz=465.5, num_updates=37700, lr=7.28357e-05, gnorm=0.383, clip=0, loss_scale=16, train_wall=72, gb_free=14.1, wall=33421
2023-09-07 01:49:41 | INFO | train_inner | epoch 032:    896 / 1191 loss=2.16, trans_loss=5.17, nll_loss=2.495, w2v_ctc_loss=0.496, task_loss=1.665, task_loss_gen=3.578, contrastive_loss=0, total=6694.46, n_correct=3493.58, ppl=5.64, accuracy=52.186, wps=18354.2, ups=1.37, wpb=13388.9, bsz=444.9, num_updates=37800, lr=7.27393e-05, gnorm=0.413, clip=0, loss_scale=16, train_wall=72, gb_free=14.1, wall=33494
2023-09-07 01:50:52 | INFO | train_inner | epoch 032:    996 / 1191 loss=2.153, trans_loss=5.161, nll_loss=2.482, w2v_ctc_loss=0.494, task_loss=1.927, task_loss_gen=3.677, contrastive_loss=0, total=6610.12, n_correct=3471.37, ppl=5.59, accuracy=52.516, wps=18408.8, ups=1.39, wpb=13220.2, bsz=440.7, num_updates=37900, lr=7.26433e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=71, gb_free=13, wall=33565
2023-09-07 01:52:05 | INFO | train_inner | epoch 032:   1096 / 1191 loss=2.162, trans_loss=5.172, nll_loss=2.497, w2v_ctc_loss=0.497, task_loss=1.559, task_loss_gen=3.998, contrastive_loss=0, total=6609.06, n_correct=3446.35, ppl=5.64, accuracy=52.146, wps=18181.8, ups=1.38, wpb=13218.1, bsz=431, num_updates=38000, lr=7.25476e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=72, gb_free=15, wall=33638
2023-09-07 01:52:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 01:52:41 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.516 | trans_loss 6.096 | nll_loss 3.611 | w2v_ctc_loss 1.281 | task_loss 70.389 | task_loss_gen 35.621 | contrastive_loss 0 | total 6138.43 | n_correct 3102 | ppl 12.21 | accuracy 50.534 | uer 16.597 | wer 18.208 | raw_wer 18.208 | bleu 5.98 | wps 1479.4 | wpb 6138.4 | bsz 201.1 | num_updates 38000 | best_bleu 5.98
2023-09-07 01:52:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 38000 updates
2023-09-07 01:52:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_32_38000.pt
2023-09-07 01:52:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_32_38000.pt
2023-09-07 01:52:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_32_38000.pt (epoch 32 @ 38000 updates, score 5.98) (writing took 14.159520934917964 seconds)
--Backword ST Loss tensor(2819.2424, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1344.4739, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-07 01:54:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2671.9792, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1256.1661, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1800.3184, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(856.0719, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1814.2186, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(857.8821, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2201.6685, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1091.4019, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2400.2471, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1126.9294, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(3036.0278, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1518.5276, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2615.2695, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1358.1704, device='cuda:4', grad_fn=<MulBackward0>)
2023-09-07 01:54:38 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.534 | trans_loss 6.103 | nll_loss 3.62 | w2v_ctc_loss 1.323 | task_loss 22.373 | task_loss_gen 13.598 | contrastive_loss 0 | total 6138.43 | n_correct 3091.29 | ppl 12.29 | accuracy 50.36 | uer 16.738 | wer 18.431 | raw_wer 18.431 | bleu 6.04 | wps 1635.7 | wpb 6138.4 | bsz 201.1 | num_updates 38095 | best_bleu 6.04
2023-09-07 01:54:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 38095 updates
2023-09-07 01:54:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 01:54:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 01:54:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 32 @ 38095 updates, score 6.04) (writing took 13.518603691016324 seconds)
2023-09-07 01:54:52 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-09-07 01:54:52 | INFO | train | epoch 032 | loss 2.151 | trans_loss 5.16 | nll_loss 2.482 | w2v_ctc_loss 0.491 | task_loss 1.684 | task_loss_gen 3.586 | contrastive_loss 0 | total 6703.69 | n_correct 3521.16 | ppl 5.59 | accuracy 52.526 | wps 16442 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 38095 | lr 7.24571e-05 | gnorm 0.409 | clip 0 | loss_scale 16 | train_wall 854 | gb_free 11.4 | wall 33805
2023-09-07 01:54:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 01:54:52 | INFO | fairseq.trainer | begin training epoch 33
2023-09-07 01:54:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 01:55:04 | INFO | train_inner | epoch 033:      5 / 1191 loss=2.14, trans_loss=5.156, nll_loss=2.477, w2v_ctc_loss=0.488, task_loss=1.781, task_loss_gen=3.402, contrastive_loss=0, total=6703.57, n_correct=3547.01, ppl=5.57, accuracy=52.912, wps=7500.6, ups=0.56, wpb=13407.1, bsz=482.5, num_updates=38100, lr=7.24524e-05, gnorm=0.445, clip=0, loss_scale=16, train_wall=70, gb_free=14, wall=33817
2023-09-07 01:55:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-07 01:56:17 | INFO | train_inner | epoch 033:    106 / 1191 loss=2.133, trans_loss=5.141, nll_loss=2.457, w2v_ctc_loss=0.474, task_loss=1.897, task_loss_gen=3.21, contrastive_loss=0, total=6802.5, n_correct=3612.32, ppl=5.49, accuracy=53.103, wps=18520.6, ups=1.36, wpb=13605, bsz=467.3, num_updates=38200, lr=7.23575e-05, gnorm=0.49, clip=0, loss_scale=8, train_wall=73, gb_free=13.3, wall=33890
2023-09-07 01:57:29 | INFO | train_inner | epoch 033:    206 / 1191 loss=2.136, trans_loss=5.141, nll_loss=2.457, w2v_ctc_loss=0.478, task_loss=1.909, task_loss_gen=3.043, contrastive_loss=0, total=6769.39, n_correct=3580.61, ppl=5.49, accuracy=52.894, wps=18750.7, ups=1.38, wpb=13538.8, bsz=459.3, num_updates=38300, lr=7.22629e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=71, gb_free=14.1, wall=33962
2023-09-07 01:58:42 | INFO | train_inner | epoch 033:    306 / 1191 loss=2.154, trans_loss=5.162, nll_loss=2.483, w2v_ctc_loss=0.487, task_loss=2.326, task_loss_gen=3.503, contrastive_loss=0, total=6593.73, n_correct=3450.58, ppl=5.59, accuracy=52.331, wps=18103.2, ups=1.37, wpb=13187.5, bsz=430.7, num_updates=38400, lr=7.21688e-05, gnorm=0.623, clip=0, loss_scale=8, train_wall=72, gb_free=10.6, wall=34035
2023-09-07 01:59:54 | INFO | train_inner | epoch 033:    406 / 1191 loss=2.153, trans_loss=5.161, nll_loss=2.481, w2v_ctc_loss=0.489, task_loss=2.647, task_loss_gen=3.495, contrastive_loss=0, total=6588.62, n_correct=3458.26, ppl=5.58, accuracy=52.488, wps=18292.3, ups=1.39, wpb=13177.2, bsz=432.4, num_updates=38500, lr=7.2075e-05, gnorm=0.677, clip=0, loss_scale=8, train_wall=71, gb_free=14.3, wall=34107
2023-09-07 02:01:06 | INFO | train_inner | epoch 033:    506 / 1191 loss=2.142, trans_loss=5.148, nll_loss=2.466, w2v_ctc_loss=0.482, task_loss=2.121, task_loss_gen=2.926, contrastive_loss=0, total=6687.16, n_correct=3539.08, ppl=5.53, accuracy=52.924, wps=18679.5, ups=1.4, wpb=13374.3, bsz=455.4, num_updates=38600, lr=7.19816e-05, gnorm=0.498, clip=0, loss_scale=8, train_wall=71, gb_free=10.5, wall=34179
2023-09-07 02:02:19 | INFO | train_inner | epoch 033:    606 / 1191 loss=2.148, trans_loss=5.151, nll_loss=2.469, w2v_ctc_loss=0.492, task_loss=1.936, task_loss_gen=3.115, contrastive_loss=0, total=6681.27, n_correct=3518.39, ppl=5.54, accuracy=52.66, wps=18365.2, ups=1.37, wpb=13362.5, bsz=449.6, num_updates=38700, lr=7.18885e-05, gnorm=0.526, clip=0, loss_scale=8, train_wall=72, gb_free=13.1, wall=34252
2023-09-07 02:03:32 | INFO | train_inner | epoch 033:    706 / 1191 loss=2.15, trans_loss=5.156, nll_loss=2.476, w2v_ctc_loss=0.49, task_loss=1.873, task_loss_gen=3.132, contrastive_loss=0, total=6692.25, n_correct=3518.87, ppl=5.57, accuracy=52.581, wps=18294.3, ups=1.37, wpb=13384.5, bsz=443.1, num_updates=38800, lr=7.17958e-05, gnorm=0.527, clip=0, loss_scale=8, train_wall=72, gb_free=13.3, wall=34325
2023-09-07 02:04:44 | INFO | train_inner | epoch 033:    806 / 1191 loss=2.139, trans_loss=5.148, nll_loss=2.466, w2v_ctc_loss=0.479, task_loss=1.593, task_loss_gen=2.801, contrastive_loss=0, total=6777.99, n_correct=3578.41, ppl=5.52, accuracy=52.795, wps=18725.2, ups=1.38, wpb=13556, bsz=465, num_updates=38900, lr=7.17035e-05, gnorm=0.449, clip=0, loss_scale=8, train_wall=71, gb_free=13.8, wall=34397
2023-09-07 02:05:57 | INFO | train_inner | epoch 033:    906 / 1191 loss=2.146, trans_loss=5.153, nll_loss=2.472, w2v_ctc_loss=0.491, task_loss=1.82, task_loss_gen=3.204, contrastive_loss=0, total=6752.91, n_correct=3564.2, ppl=5.55, accuracy=52.78, wps=18531.6, ups=1.37, wpb=13505.8, bsz=462.9, num_updates=39000, lr=7.16115e-05, gnorm=0.617, clip=0, loss_scale=8, train_wall=72, gb_free=5.1, wall=34470
2023-09-07 02:07:11 | INFO | train_inner | epoch 033:   1006 / 1191 loss=2.157, trans_loss=5.168, nll_loss=2.492, w2v_ctc_loss=0.495, task_loss=1.806, task_loss_gen=3.132, contrastive_loss=0, total=6696.09, n_correct=3506.07, ppl=5.63, accuracy=52.36, wps=18186.9, ups=1.36, wpb=13392.2, bsz=444.1, num_updates=39100, lr=7.15199e-05, gnorm=0.528, clip=0, loss_scale=8, train_wall=73, gb_free=12.2, wall=34544
2023-09-07 02:08:23 | INFO | train_inner | epoch 033:   1106 / 1191 loss=2.15, trans_loss=5.158, nll_loss=2.479, w2v_ctc_loss=0.496, task_loss=1.628, task_loss_gen=2.924, contrastive_loss=0, total=6736.67, n_correct=3545.65, ppl=5.58, accuracy=52.632, wps=18543.2, ups=1.38, wpb=13473.3, bsz=460.7, num_updates=39200, lr=7.14286e-05, gnorm=0.463, clip=0, loss_scale=8, train_wall=72, gb_free=12.9, wall=34616
2023-09-07 02:09:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 02:10:04 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.501 | trans_loss 6.09 | nll_loss 3.6 | w2v_ctc_loss 1.245 | task_loss 10.306 | task_loss_gen 8.218 | contrastive_loss 0 | total 6138.43 | n_correct 3099.14 | ppl 12.13 | accuracy 50.488 | uer 16.236 | wer 18.014 | raw_wer 18.014 | bleu 6.27 | wps 1455.5 | wpb 6138.4 | bsz 201.1 | num_updates 39285 | best_bleu 6.27
2023-09-07 02:10:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 39285 updates
2023-09-07 02:10:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 02:10:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 02:10:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 33 @ 39285 updates, score 6.27) (writing took 15.471237635007128 seconds)
2023-09-07 02:10:19 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-09-07 02:10:19 | INFO | train | epoch 033 | loss 2.146 | trans_loss 5.153 | nll_loss 2.472 | w2v_ctc_loss 0.487 | task_loss 1.915 | task_loss_gen 3.121 | contrastive_loss 0 | total 6703.4 | n_correct 3532.45 | ppl 5.55 | accuracy 52.696 | wps 17206.9 | ups 1.28 | wpb 13406.8 | bsz 452.2 | num_updates 39285 | lr 7.13513e-05 | gnorm 0.532 | clip 0 | loss_scale 8 | train_wall 855 | gb_free 10.6 | wall 34732
2023-09-07 02:10:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 02:10:20 | INFO | fairseq.trainer | begin training epoch 34
2023-09-07 02:10:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 02:10:38 | INFO | train_inner | epoch 034:     15 / 1191 loss=2.136, trans_loss=5.144, nll_loss=2.461, w2v_ctc_loss=0.484, task_loss=1.395, task_loss_gen=2.831, contrastive_loss=0, total=6725.75, n_correct=3568.57, ppl=5.51, accuracy=53.058, wps=9990.2, ups=0.74, wpb=13451.5, bsz=470.8, num_updates=39300, lr=7.13376e-05, gnorm=0.446, clip=0, loss_scale=8, train_wall=72, gb_free=13.3, wall=34751
2023-09-07 02:11:50 | INFO | train_inner | epoch 034:    115 / 1191 loss=2.128, trans_loss=5.136, nll_loss=2.45, w2v_ctc_loss=0.47, task_loss=1.428, task_loss_gen=2.783, contrastive_loss=0, total=6791.28, n_correct=3614.79, ppl=5.47, accuracy=53.227, wps=18781.9, ups=1.38, wpb=13582.6, bsz=475.8, num_updates=39400, lr=7.1247e-05, gnorm=0.442, clip=0, loss_scale=8, train_wall=72, gb_free=14.2, wall=34823
2023-09-07 02:13:03 | INFO | train_inner | epoch 034:    215 / 1191 loss=2.143, trans_loss=5.148, nll_loss=2.465, w2v_ctc_loss=0.487, task_loss=1.981, task_loss_gen=3.272, contrastive_loss=0, total=6678.61, n_correct=3529.63, ppl=5.52, accuracy=52.85, wps=18365.1, ups=1.37, wpb=13357.2, bsz=450.2, num_updates=39500, lr=7.11568e-05, gnorm=0.668, clip=0, loss_scale=8, train_wall=72, gb_free=13.5, wall=34896
2023-09-07 02:14:16 | INFO | train_inner | epoch 034:    315 / 1191 loss=2.148, trans_loss=5.151, nll_loss=2.468, w2v_ctc_loss=0.49, task_loss=1.878, task_loss_gen=3.348, contrastive_loss=0, total=6608.68, n_correct=3482.05, ppl=5.53, accuracy=52.689, wps=18132, ups=1.37, wpb=13217.4, bsz=433.2, num_updates=39600, lr=7.10669e-05, gnorm=0.487, clip=0, loss_scale=8, train_wall=72, gb_free=11.6, wall=34969
2023-09-07 02:15:29 | INFO | train_inner | epoch 034:    415 / 1191 loss=2.149, trans_loss=5.155, nll_loss=2.474, w2v_ctc_loss=0.483, task_loss=1.692, task_loss_gen=3.012, contrastive_loss=0, total=6649.36, n_correct=3493.53, ppl=5.56, accuracy=52.539, wps=18206.6, ups=1.37, wpb=13298.7, bsz=430.9, num_updates=39700, lr=7.09773e-05, gnorm=0.45, clip=0, loss_scale=8, train_wall=72, gb_free=14.4, wall=35042
2023-09-07 02:16:42 | INFO | train_inner | epoch 034:    515 / 1191 loss=2.145, trans_loss=5.15, nll_loss=2.468, w2v_ctc_loss=0.484, task_loss=1.748, task_loss_gen=3.044, contrastive_loss=0, total=6704.45, n_correct=3532.23, ppl=5.53, accuracy=52.685, wps=18285.8, ups=1.36, wpb=13408.9, bsz=443.4, num_updates=39800, lr=7.08881e-05, gnorm=0.465, clip=0, loss_scale=8, train_wall=73, gb_free=13.8, wall=35115
2023-09-07 02:17:55 | INFO | train_inner | epoch 034:    615 / 1191 loss=2.135, trans_loss=5.14, nll_loss=2.455, w2v_ctc_loss=0.484, task_loss=1.552, task_loss_gen=2.843, contrastive_loss=0, total=6737.48, n_correct=3574.04, ppl=5.48, accuracy=53.047, wps=18558.4, ups=1.38, wpb=13475, bsz=465.8, num_updates=39900, lr=7.07992e-05, gnorm=0.443, clip=0, loss_scale=8, train_wall=72, gb_free=14.1, wall=35188
2023-09-07 02:19:07 | INFO | train_inner | epoch 034:    715 / 1191 loss=2.148, trans_loss=5.153, nll_loss=2.472, w2v_ctc_loss=0.487, task_loss=1.617, task_loss_gen=3.117, contrastive_loss=0, total=6608.91, n_correct=3479, ppl=5.55, accuracy=52.641, wps=18413.9, ups=1.39, wpb=13217.8, bsz=435.2, num_updates=40000, lr=7.07107e-05, gnorm=0.452, clip=0, loss_scale=8, train_wall=71, gb_free=12.5, wall=35260
2023-09-07 02:19:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 02:19:42 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.507 | trans_loss 6.089 | nll_loss 3.6 | w2v_ctc_loss 1.266 | task_loss 10.451 | task_loss_gen 7.999 | contrastive_loss 0 | total 6138.43 | n_correct 3091.57 | ppl 12.12 | accuracy 50.364 | uer 16.273 | wer 17.984 | raw_wer 17.984 | bleu 6.07 | wps 1585.8 | wpb 6138.4 | bsz 201.1 | num_updates 40000 | best_bleu 6.27
2023-09-07 02:19:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40000 updates
2023-09-07 02:19:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_34_40000.pt
2023-09-07 02:19:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_34_40000.pt
2023-09-07 02:19:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_34_40000.pt (epoch 34 @ 40000 updates, score 6.07) (writing took 9.184789165039547 seconds)
--Backword ST Loss tensor(1584.6936, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(705.0510, device='cuda:0', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:0')
2023-09-07 02:21:04 | INFO | train_inner | epoch 034:    815 / 1191 loss=2.141, trans_loss=5.144, nll_loss=2.46, w2v_ctc_loss=0.49, task_loss=1.705, task_loss_gen=3.054, contrastive_loss=0, total=6668.41, n_correct=3534.81, ppl=5.5, accuracy=53.008, wps=11343.6, ups=0.85, wpb=13336.8, bsz=455.6, num_updates=40100, lr=7.06225e-05, gnorm=0.503, clip=0, loss_scale=8, train_wall=72, gb_free=13.3, wall=35377
2023-09-07 02:22:17 | INFO | train_inner | epoch 034:    915 / 1191 loss=2.152, trans_loss=5.153, nll_loss=2.471, w2v_ctc_loss=0.492, task_loss=1.783, task_loss_gen=3.105, contrastive_loss=0, total=6650.22, n_correct=3490.76, ppl=5.54, accuracy=52.491, wps=18349, ups=1.38, wpb=13300.4, bsz=427.8, num_updates=40200, lr=7.05346e-05, gnorm=0.468, clip=0, loss_scale=16, train_wall=72, gb_free=13.1, wall=35450
2023-09-07 02:23:29 | INFO | train_inner | epoch 034:   1015 / 1191 loss=2.145, trans_loss=5.152, nll_loss=2.47, w2v_ctc_loss=0.488, task_loss=1.459, task_loss_gen=2.993, contrastive_loss=0, total=6680.01, n_correct=3530.91, ppl=5.54, accuracy=52.858, wps=18462.2, ups=1.38, wpb=13360, bsz=442.6, num_updates=40300, lr=7.0447e-05, gnorm=0.368, clip=0, loss_scale=16, train_wall=71, gb_free=13.3, wall=35522
2023-09-07 02:24:42 | INFO | train_inner | epoch 034:   1115 / 1191 loss=2.13, trans_loss=5.136, nll_loss=2.45, w2v_ctc_loss=0.48, task_loss=1.171, task_loss_gen=2.953, contrastive_loss=0, total=6848.4, n_correct=3646.37, ppl=5.47, accuracy=53.244, wps=18873.5, ups=1.38, wpb=13696.8, bsz=477.6, num_updates=40400, lr=7.03598e-05, gnorm=0.354, clip=0, loss_scale=16, train_wall=72, gb_free=14, wall=35595
2023-09-07 02:25:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2521.3958, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1224.6927, device='cuda:2', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:2')
--Backword ST Loss tensor(2845.0354, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1435.4482, device='cuda:5', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:5')
--Backword ST Loss tensor(2820.6843, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1405.1318, device='cuda:3', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:3')
--Backword ST Loss tensor(2611.5171, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1318.4340, device='cuda:4', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:4')
--Backword ST Loss tensor(2581.5669, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1408.1256, device='cuda:1', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:1')
--Backword ST Loss tensor(2982.5449, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1416.5471, device='cuda:7', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:7')
--Backword ST Loss tensor(4134.4351, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(2319.4619, device='cuda:6', grad_fn=<MulBackward0>)
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:6')
2023-09-07 02:26:13 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.517 | trans_loss 6.087 | nll_loss 3.598 | w2v_ctc_loss 1.306 | task_loss 24.311 | task_loss_gen 13.411 | contrastive_loss 0 | total 6138.43 | n_correct 3102.86 | ppl 12.11 | accuracy 50.548 | uer 16.543 | wer 18.185 | raw_wer 18.185 | bleu 5.89 | wps 1522.7 | wpb 6138.4 | bsz 201.1 | num_updates 40476 | best_bleu 6.27
2023-09-07 02:26:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 40476 updates
2023-09-07 02:26:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.8907.pt
2023-09-07 02:26:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.8907.pt
2023-09-07 02:26:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_5.8907.pt (epoch 34 @ 40476 updates, score 5.89) (writing took 7.479007272981107 seconds)
2023-09-07 02:26:21 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-09-07 02:26:21 | INFO | train | epoch 034 | loss 2.141 | trans_loss 5.146 | nll_loss 2.462 | w2v_ctc_loss 0.485 | task_loss 1.614 | task_loss_gen 3.024 | contrastive_loss 0 | total 6703.69 | n_correct 3545.55 | ppl 5.51 | accuracy 52.89 | wps 16601.9 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 40476 | lr 7.02937e-05 | gnorm 0.458 | clip 0 | loss_scale 16 | train_wall 855 | gb_free 13.8 | wall 35694
2023-09-07 02:26:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 02:26:21 | INFO | fairseq.trainer | begin training epoch 35
2023-09-07 02:26:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 02:26:47 | INFO | train_inner | epoch 035:     24 / 1191 loss=2.134, trans_loss=5.138, nll_loss=2.454, w2v_ctc_loss=0.485, task_loss=1.44, task_loss_gen=3.014, contrastive_loss=0, total=6771.92, n_correct=3596.7, ppl=5.48, accuracy=53.112, wps=10846.7, ups=0.8, wpb=13543.8, bsz=471.7, num_updates=40500, lr=7.02728e-05, gnorm=0.376, clip=0, loss_scale=16, train_wall=72, gb_free=13.3, wall=35720
2023-09-07 02:27:59 | INFO | train_inner | epoch 035:    124 / 1191 loss=2.136, trans_loss=5.137, nll_loss=2.452, w2v_ctc_loss=0.483, task_loss=1.495, task_loss_gen=3.267, contrastive_loss=0, total=6711.06, n_correct=3566.49, ppl=5.47, accuracy=53.143, wps=18555.3, ups=1.38, wpb=13422.1, bsz=452.8, num_updates=40600, lr=7.01862e-05, gnorm=0.384, clip=0, loss_scale=16, train_wall=72, gb_free=11.5, wall=35792
2023-09-07 02:29:11 | INFO | train_inner | epoch 035:    224 / 1191 loss=2.136, trans_loss=5.139, nll_loss=2.453, w2v_ctc_loss=0.476, task_loss=1.492, task_loss_gen=3.822, contrastive_loss=0, total=6627.11, n_correct=3514.09, ppl=5.47, accuracy=53.026, wps=18334.3, ups=1.38, wpb=13254.2, bsz=444, num_updates=40700, lr=7.01e-05, gnorm=0.381, clip=0, loss_scale=16, train_wall=71, gb_free=14.9, wall=35864
2023-09-07 02:30:24 | INFO | train_inner | epoch 035:    324 / 1191 loss=2.127, trans_loss=5.129, nll_loss=2.44, w2v_ctc_loss=0.472, task_loss=1.223, task_loss_gen=3.401, contrastive_loss=0, total=6768.12, n_correct=3609.72, ppl=5.43, accuracy=53.334, wps=18698.4, ups=1.38, wpb=13536.2, bsz=463.6, num_updates=40800, lr=7.0014e-05, gnorm=0.36, clip=0, loss_scale=16, train_wall=72, gb_free=13.4, wall=35937
2023-09-07 02:31:37 | INFO | train_inner | epoch 035:    424 / 1191 loss=2.147, trans_loss=5.152, nll_loss=2.469, w2v_ctc_loss=0.481, task_loss=1.521, task_loss_gen=3.769, contrastive_loss=0, total=6573.32, n_correct=3461.32, ppl=5.54, accuracy=52.657, wps=18060.6, ups=1.37, wpb=13146.6, bsz=420.1, num_updates=40900, lr=6.99284e-05, gnorm=0.393, clip=0, loss_scale=16, train_wall=72, gb_free=13.5, wall=36010
2023-09-07 02:32:49 | INFO | train_inner | epoch 035:    524 / 1191 loss=2.133, trans_loss=5.133, nll_loss=2.446, w2v_ctc_loss=0.481, task_loss=1.609, task_loss_gen=3.866, contrastive_loss=0, total=6718.03, n_correct=3574.65, ppl=5.45, accuracy=53.21, wps=18428, ups=1.37, wpb=13436.1, bsz=456.1, num_updates=41000, lr=6.9843e-05, gnorm=0.411, clip=0, loss_scale=16, train_wall=72, gb_free=12.3, wall=36082
2023-09-07 02:34:02 | INFO | train_inner | epoch 035:    624 / 1191 loss=2.137, trans_loss=5.138, nll_loss=2.453, w2v_ctc_loss=0.481, task_loss=1.633, task_loss_gen=3.464, contrastive_loss=0, total=6702.8, n_correct=3551.19, ppl=5.47, accuracy=52.981, wps=18380.2, ups=1.37, wpb=13405.6, bsz=446.4, num_updates=41100, lr=6.9758e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=9.3, wall=36155
2023-09-07 02:35:15 | INFO | train_inner | epoch 035:    724 / 1191 loss=2.139, trans_loss=5.144, nll_loss=2.46, w2v_ctc_loss=0.485, task_loss=1.529, task_loss_gen=3.467, contrastive_loss=0, total=6709.59, n_correct=3552.19, ppl=5.5, accuracy=52.942, wps=18435.5, ups=1.37, wpb=13419.2, bsz=453.6, num_updates=41200, lr=6.96733e-05, gnorm=0.381, clip=0, loss_scale=16, train_wall=72, gb_free=12.9, wall=36228
2023-09-07 02:36:28 | INFO | train_inner | epoch 035:    824 / 1191 loss=2.135, trans_loss=5.142, nll_loss=2.457, w2v_ctc_loss=0.481, task_loss=1.438, task_loss_gen=3.149, contrastive_loss=0, total=6756.65, n_correct=3583.73, ppl=5.49, accuracy=53.04, wps=18573.3, ups=1.37, wpb=13513.3, bsz=459.7, num_updates=41300, lr=6.95889e-05, gnorm=0.38, clip=0, loss_scale=16, train_wall=72, gb_free=14.1, wall=36301
2023-09-07 02:37:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-07 02:37:41 | INFO | train_inner | epoch 035:    925 / 1191 loss=2.124, trans_loss=5.13, nll_loss=2.442, w2v_ctc_loss=0.473, task_loss=1.918, task_loss_gen=3.234, contrastive_loss=0, total=6794.67, n_correct=3625.07, ppl=5.43, accuracy=53.352, wps=18692.1, ups=1.38, wpb=13589.3, bsz=476.1, num_updates=41400, lr=6.95048e-05, gnorm=0.477, clip=0, loss_scale=8, train_wall=72, gb_free=14.1, wall=36374
2023-09-07 02:38:53 | INFO | train_inner | epoch 035:   1025 / 1191 loss=2.142, trans_loss=5.141, nll_loss=2.456, w2v_ctc_loss=0.486, task_loss=2.268, task_loss_gen=3.146, contrastive_loss=0, total=6732.07, n_correct=3558.49, ppl=5.49, accuracy=52.859, wps=18579.1, ups=1.38, wpb=13464.1, bsz=445.3, num_updates=41500, lr=6.9421e-05, gnorm=0.512, clip=0, loss_scale=8, train_wall=72, gb_free=14.5, wall=36446
2023-09-07 02:40:06 | INFO | train_inner | epoch 035:   1125 / 1191 loss=2.143, trans_loss=5.147, nll_loss=2.465, w2v_ctc_loss=0.489, task_loss=2.186, task_loss_gen=3.218, contrastive_loss=0, total=6620.76, n_correct=3501.94, ppl=5.52, accuracy=52.893, wps=18110.2, ups=1.37, wpb=13241.5, bsz=440.4, num_updates=41600, lr=6.93375e-05, gnorm=0.549, clip=0, loss_scale=8, train_wall=72, gb_free=11.5, wall=36519
2023-09-07 02:40:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 02:41:28 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 4.52 | trans_loss 6.088 | nll_loss 3.6 | w2v_ctc_loss 1.313 | task_loss 15.947 | task_loss_gen 9.766 | contrastive_loss 0 | total 6138.43 | n_correct 3105.57 | ppl 12.12 | accuracy 50.592 | uer 16.639 | wer 18.386 | raw_wer 18.386 | bleu 6.27 | wps 1668 | wpb 6138.4 | bsz 201.1 | num_updates 41666 | best_bleu 6.27
2023-09-07 02:41:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 41666 updates
2023-09-07 02:41:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 02:41:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 02:41:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 35 @ 41666 updates, score 6.27) (writing took 12.35971792798955 seconds)
2023-09-07 02:41:41 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-09-07 02:41:41 | INFO | train | epoch 035 | loss 2.136 | trans_loss 5.139 | nll_loss 2.453 | w2v_ctc_loss 0.48 | task_loss 1.658 | task_loss_gen 3.387 | contrastive_loss 0 | total 6704.74 | n_correct 3557.57 | ppl 5.48 | accuracy 53.061 | wps 17347.2 | ups 1.29 | wpb 13409.5 | bsz 452.3 | num_updates 41666 | lr 6.92826e-05 | gnorm 0.42 | clip 0 | loss_scale 8 | train_wall 856 | gb_free 14.1 | wall 36614
2023-09-07 02:41:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 02:41:41 | INFO | fairseq.trainer | begin training epoch 36
2023-09-07 02:41:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 02:42:14 | INFO | train_inner | epoch 036:     34 / 1191 loss=2.127, trans_loss=5.131, nll_loss=2.444, w2v_ctc_loss=0.472, task_loss=1.818, task_loss_gen=2.858, contrastive_loss=0, total=6723.46, n_correct=3582.68, ppl=5.44, accuracy=53.286, wps=10544.2, ups=0.78, wpb=13446.9, bsz=466.6, num_updates=41700, lr=6.92543e-05, gnorm=0.471, clip=0, loss_scale=8, train_wall=72, gb_free=12.4, wall=36647
2023-09-07 02:43:26 | INFO | train_inner | epoch 036:    134 / 1191 loss=2.135, trans_loss=5.132, nll_loss=2.444, w2v_ctc_loss=0.478, task_loss=2.139, task_loss_gen=3.329, contrastive_loss=0, total=6615.18, n_correct=3509.5, ppl=5.44, accuracy=53.052, wps=18459.7, ups=1.4, wpb=13230.4, bsz=439.7, num_updates=41800, lr=6.91714e-05, gnorm=0.567, clip=0, loss_scale=8, train_wall=71, gb_free=13.3, wall=36719
2023-09-07 02:44:38 | INFO | train_inner | epoch 036:    234 / 1191 loss=2.113, trans_loss=5.11, nll_loss=2.415, w2v_ctc_loss=0.464, task_loss=1.644, task_loss_gen=2.885, contrastive_loss=0, total=6741.47, n_correct=3631.16, ppl=5.33, accuracy=53.863, wps=18739, ups=1.39, wpb=13482.9, bsz=470.3, num_updates=41900, lr=6.90889e-05, gnorm=0.452, clip=0, loss_scale=8, train_wall=71, gb_free=8.4, wall=36790
2023-09-07 02:45:50 | INFO | train_inner | epoch 036:    334 / 1191 loss=2.123, trans_loss=5.126, nll_loss=2.436, w2v_ctc_loss=0.473, task_loss=1.73, task_loss_gen=2.982, contrastive_loss=0, total=6788.68, n_correct=3634.02, ppl=5.41, accuracy=53.531, wps=18817.6, ups=1.39, wpb=13577.4, bsz=468.7, num_updates=42000, lr=6.90066e-05, gnorm=0.482, clip=0, loss_scale=8, train_wall=71, gb_free=13.9, wall=36863
2023-09-07 02:45:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 02:46:23 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 4.517 | trans_loss 6.096 | nll_loss 3.602 | w2v_ctc_loss 1.285 | task_loss 18.417 | task_loss_gen 11.084 | contrastive_loss 0 | total 6138.43 | n_correct 3104.71 | ppl 12.14 | accuracy 50.578 | uer 16.594 | wer 18.248 | raw_wer 18.248 | bleu 6.46 | wps 1715.2 | wpb 6138.4 | bsz 201.1 | num_updates 42000 | best_bleu 6.46
2023-09-07 02:46:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42000 updates
2023-09-07 02:46:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_36_42000.pt
2023-09-07 02:46:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_36_42000.pt
2023-09-07 02:46:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_36_42000.pt (epoch 36 @ 42000 updates, score 6.46) (writing took 12.165665345964953 seconds)
--Backword ST Loss tensor(2411.0818, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1129.3062, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-07 02:47:49 | INFO | train_inner | epoch 036:    434 / 1191 loss=2.121, trans_loss=5.122, nll_loss=2.431, w2v_ctc_loss=0.471, task_loss=1.592, task_loss_gen=2.774, contrastive_loss=0, total=6801.05, n_correct=3644.34, ppl=5.39, accuracy=53.585, wps=11390.1, ups=0.84, wpb=13602.1, bsz=473.4, num_updates=42100, lr=6.89246e-05, gnorm=0.439, clip=0, loss_scale=8, train_wall=72, gb_free=13.3, wall=36982
2023-09-07 02:49:02 | INFO | train_inner | epoch 036:    534 / 1191 loss=2.126, trans_loss=5.133, nll_loss=2.445, w2v_ctc_loss=0.471, task_loss=1.343, task_loss_gen=2.82, contrastive_loss=0, total=6792.76, n_correct=3624, ppl=5.45, accuracy=53.351, wps=18735.9, ups=1.38, wpb=13585.5, bsz=472.4, num_updates=42200, lr=6.88428e-05, gnorm=0.422, clip=0, loss_scale=8, train_wall=72, gb_free=12.6, wall=37055
2023-09-07 02:50:14 | INFO | train_inner | epoch 036:    634 / 1191 loss=2.135, trans_loss=5.134, nll_loss=2.446, w2v_ctc_loss=0.484, task_loss=1.634, task_loss_gen=3.113, contrastive_loss=0, total=6667.35, n_correct=3542.49, ppl=5.45, accuracy=53.132, wps=18502.3, ups=1.39, wpb=13334.7, bsz=440.8, num_updates=42300, lr=6.87614e-05, gnorm=0.469, clip=0, loss_scale=8, train_wall=71, gb_free=14.5, wall=37127
2023-09-07 02:51:26 | INFO | train_inner | epoch 036:    734 / 1191 loss=2.136, trans_loss=5.138, nll_loss=2.452, w2v_ctc_loss=0.478, task_loss=1.792, task_loss_gen=3.152, contrastive_loss=0, total=6721.83, n_correct=3564.1, ppl=5.47, accuracy=53.023, wps=18569.6, ups=1.38, wpb=13443.7, bsz=450.1, num_updates=42400, lr=6.86803e-05, gnorm=0.511, clip=0, loss_scale=8, train_wall=72, gb_free=13.8, wall=37199
2023-09-07 02:52:40 | INFO | train_inner | epoch 036:    834 / 1191 loss=2.135, trans_loss=5.141, nll_loss=2.456, w2v_ctc_loss=0.481, task_loss=1.848, task_loss_gen=3.061, contrastive_loss=0, total=6678.35, n_correct=3550.54, ppl=5.49, accuracy=53.165, wps=18158.4, ups=1.36, wpb=13356.7, bsz=447.4, num_updates=42500, lr=6.85994e-05, gnorm=0.468, clip=0, loss_scale=8, train_wall=73, gb_free=13.9, wall=37273
2023-09-07 02:53:53 | INFO | train_inner | epoch 036:    934 / 1191 loss=2.149, trans_loss=5.15, nll_loss=2.468, w2v_ctc_loss=0.488, task_loss=1.876, task_loss_gen=3.367, contrastive_loss=0, total=6679.59, n_correct=3516.93, ppl=5.53, accuracy=52.652, wps=18260.7, ups=1.37, wpb=13359.2, bsz=429.9, num_updates=42600, lr=6.85189e-05, gnorm=0.444, clip=0, loss_scale=8, train_wall=72, gb_free=13.2, wall=37346
2023-09-07 02:55:04 | INFO | train_inner | epoch 036:   1034 / 1191 loss=2.128, trans_loss=5.133, nll_loss=2.446, w2v_ctc_loss=0.48, task_loss=1.657, task_loss_gen=2.993, contrastive_loss=0, total=6715.41, n_correct=3586.39, ppl=5.45, accuracy=53.405, wps=18759, ups=1.4, wpb=13430.8, bsz=465.8, num_updates=42700, lr=6.84386e-05, gnorm=0.452, clip=0, loss_scale=8, train_wall=71, gb_free=14.8, wall=37417
2023-09-07 02:56:17 | INFO | train_inner | epoch 036:   1134 / 1191 loss=2.144, trans_loss=5.142, nll_loss=2.457, w2v_ctc_loss=0.489, task_loss=1.765, task_loss_gen=3.062, contrastive_loss=0, total=6605.28, n_correct=3486.95, ppl=5.49, accuracy=52.79, wps=18152.1, ups=1.37, wpb=13210.6, bsz=432.4, num_updates=42800, lr=6.83586e-05, gnorm=0.455, clip=0, loss_scale=8, train_wall=72, gb_free=13.6, wall=37490
2023-09-07 02:56:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(3040.3406, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1542.1039, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2857.9441, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1348.4434, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1820.0104, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(852.9042, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2339.1555, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1162.7072, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2441.1892, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1165.0220, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2600.5085, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1173.5737, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2509.8167, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1268.4825, device='cuda:6', grad_fn=<MulBackward0>)
2023-09-07 02:57:33 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 4.506 | trans_loss 6.081 | nll_loss 3.587 | w2v_ctc_loss 1.283 | task_loss 22.44 | task_loss_gen 12.052 | contrastive_loss 0 | total 6138.43 | n_correct 3112.14 | ppl 12.02 | accuracy 50.699 | uer 16.332 | wer 18.01 | raw_wer 18.01 | bleu 6.46 | wps 1655.1 | wpb 6138.4 | bsz 201.1 | num_updates 42857 | best_bleu 6.46
2023-09-07 02:57:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 42857 updates
2023-09-07 02:57:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 02:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 02:57:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 36 @ 42857 updates, score 6.46) (writing took 13.583256750949658 seconds)
2023-09-07 02:57:47 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-09-07 02:57:47 | INFO | train | epoch 036 | loss 2.132 | trans_loss 5.134 | nll_loss 2.446 | w2v_ctc_loss 0.478 | task_loss 1.732 | task_loss_gen 3.053 | contrastive_loss 0 | total 6703.69 | n_correct 3565.9 | ppl 5.45 | accuracy 53.193 | wps 16533.7 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 42857 | lr 6.83131e-05 | gnorm 0.469 | clip 0 | loss_scale 8 | train_wall 854 | gb_free 12.7 | wall 37580
2023-09-07 02:57:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 02:57:47 | INFO | fairseq.trainer | begin training epoch 37
2023-09-07 02:57:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 02:58:26 | INFO | train_inner | epoch 037:     43 / 1191 loss=2.136, trans_loss=5.137, nll_loss=2.45, w2v_ctc_loss=0.479, task_loss=1.569, task_loss_gen=3.087, contrastive_loss=0, total=6672.81, n_correct=3537.34, ppl=5.47, accuracy=53.011, wps=10362.8, ups=0.78, wpb=13345.6, bsz=440.3, num_updates=42900, lr=6.82789e-05, gnorm=0.42, clip=0, loss_scale=8, train_wall=72, gb_free=15.1, wall=37619
2023-09-07 02:59:39 | INFO | train_inner | epoch 037:    143 / 1191 loss=2.122, trans_loss=5.121, nll_loss=2.43, w2v_ctc_loss=0.474, task_loss=1.475, task_loss_gen=2.946, contrastive_loss=0, total=6762.6, n_correct=3621.5, ppl=5.39, accuracy=53.552, wps=18522.9, ups=1.37, wpb=13525.2, bsz=464, num_updates=43000, lr=6.81994e-05, gnorm=0.447, clip=0, loss_scale=8, train_wall=72, gb_free=12.7, wall=37692
2023-09-07 03:00:51 | INFO | train_inner | epoch 037:    243 / 1191 loss=2.126, trans_loss=5.124, nll_loss=2.434, w2v_ctc_loss=0.473, task_loss=1.875, task_loss_gen=3.207, contrastive_loss=0, total=6696.92, n_correct=3578.13, ppl=5.4, accuracy=53.429, wps=18579.1, ups=1.39, wpb=13393.8, bsz=449.2, num_updates=43100, lr=6.81203e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=71, gb_free=11.6, wall=37764
2023-09-07 03:02:03 | INFO | train_inner | epoch 037:    343 / 1191 loss=2.13, trans_loss=5.131, nll_loss=2.443, w2v_ctc_loss=0.476, task_loss=1.992, task_loss_gen=3.321, contrastive_loss=0, total=6637.72, n_correct=3541.31, ppl=5.44, accuracy=53.351, wps=18469.9, ups=1.39, wpb=13275.4, bsz=440.5, num_updates=43200, lr=6.80414e-05, gnorm=0.492, clip=0, loss_scale=8, train_wall=71, gb_free=13.5, wall=37836
2023-09-07 03:03:16 | INFO | train_inner | epoch 037:    443 / 1191 loss=2.129, trans_loss=5.128, nll_loss=2.438, w2v_ctc_loss=0.475, task_loss=1.791, task_loss_gen=3.053, contrastive_loss=0, total=6703.75, n_correct=3573.18, ppl=5.42, accuracy=53.301, wps=18446.6, ups=1.38, wpb=13407.5, bsz=446.8, num_updates=43300, lr=6.79628e-05, gnorm=0.471, clip=0, loss_scale=8, train_wall=72, gb_free=14.4, wall=37909
2023-09-07 03:04:28 | INFO | train_inner | epoch 037:    543 / 1191 loss=2.128, trans_loss=5.127, nll_loss=2.437, w2v_ctc_loss=0.477, task_loss=1.837, task_loss_gen=3.039, contrastive_loss=0, total=6639.95, n_correct=3543.67, ppl=5.41, accuracy=53.369, wps=18285.8, ups=1.38, wpb=13279.9, bsz=449.3, num_updates=43400, lr=6.78844e-05, gnorm=0.518, clip=0, loss_scale=8, train_wall=72, gb_free=13.4, wall=37981
2023-09-07 03:05:41 | INFO | train_inner | epoch 037:    643 / 1191 loss=2.135, trans_loss=5.137, nll_loss=2.451, w2v_ctc_loss=0.472, task_loss=1.708, task_loss_gen=3.174, contrastive_loss=0, total=6631.82, n_correct=3518.57, ppl=5.47, accuracy=53.056, wps=18300.9, ups=1.38, wpb=13263.6, bsz=428.1, num_updates=43500, lr=6.78064e-05, gnorm=0.374, clip=0, loss_scale=16, train_wall=72, gb_free=12.2, wall=38054
2023-09-07 03:06:54 | INFO | train_inner | epoch 037:    743 / 1191 loss=2.126, trans_loss=5.122, nll_loss=2.431, w2v_ctc_loss=0.474, task_loss=1.515, task_loss_gen=3.134, contrastive_loss=0, total=6719.07, n_correct=3587.91, ppl=5.39, accuracy=53.399, wps=18448.4, ups=1.37, wpb=13438.1, bsz=451.8, num_updates=43600, lr=6.77285e-05, gnorm=0.368, clip=0, loss_scale=16, train_wall=72, gb_free=13.3, wall=38127
2023-09-07 03:08:07 | INFO | train_inner | epoch 037:    843 / 1191 loss=2.123, trans_loss=5.126, nll_loss=2.437, w2v_ctc_loss=0.473, task_loss=1.18, task_loss_gen=3.316, contrastive_loss=0, total=6808.88, n_correct=3644.43, ppl=5.41, accuracy=53.525, wps=18617.7, ups=1.37, wpb=13617.8, bsz=466.8, num_updates=43700, lr=6.7651e-05, gnorm=0.363, clip=0, loss_scale=16, train_wall=72, gb_free=14.2, wall=38200
2023-09-07 03:09:20 | INFO | train_inner | epoch 037:    943 / 1191 loss=2.106, trans_loss=5.105, nll_loss=2.409, w2v_ctc_loss=0.47, task_loss=1.202, task_loss_gen=2.862, contrastive_loss=0, total=6855.49, n_correct=3713.25, ppl=5.31, accuracy=54.165, wps=18681.7, ups=1.36, wpb=13711, bsz=499.9, num_updates=43800, lr=6.75737e-05, gnorm=0.364, clip=0, loss_scale=16, train_wall=73, gb_free=13, wall=38273
2023-09-07 03:10:33 | INFO | train_inner | epoch 037:   1043 / 1191 loss=2.132, trans_loss=5.129, nll_loss=2.441, w2v_ctc_loss=0.479, task_loss=1.34, task_loss_gen=3.392, contrastive_loss=0, total=6689.96, n_correct=3564.65, ppl=5.43, accuracy=53.284, wps=18396.7, ups=1.37, wpb=13379.9, bsz=441.4, num_updates=43900, lr=6.74967e-05, gnorm=0.366, clip=0, loss_scale=16, train_wall=72, gb_free=13.7, wall=38346
2023-09-07 03:11:45 | INFO | train_inner | epoch 037:   1143 / 1191 loss=2.138, trans_loss=5.139, nll_loss=2.453, w2v_ctc_loss=0.488, task_loss=1.196, task_loss_gen=3.587, contrastive_loss=0, total=6631.9, n_correct=3524.03, ppl=5.48, accuracy=53.138, wps=18350.8, ups=1.38, wpb=13263.8, bsz=443.6, num_updates=44000, lr=6.742e-05, gnorm=0.366, clip=0, loss_scale=16, train_wall=71, gb_free=14.4, wall=38418
2023-09-07 03:11:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 03:12:19 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.499 | trans_loss 6.073 | nll_loss 3.575 | w2v_ctc_loss 1.274 | task_loss 25.035 | task_loss_gen 13.766 | contrastive_loss 0 | total 6138.43 | n_correct 3117.14 | ppl 11.92 | accuracy 50.781 | uer 16.474 | wer 18.297 | raw_wer 18.297 | bleu 6.51 | wps 1625.9 | wpb 6138.4 | bsz 201.1 | num_updates 44000 | best_bleu 6.51
2023-09-07 03:12:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 44000 updates
2023-09-07 03:12:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_37_44000.pt
2023-09-07 03:12:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_37_44000.pt
2023-09-07 03:12:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_37_44000.pt (epoch 37 @ 44000 updates, score 6.51) (writing took 11.70014494692441 seconds)
--Backword ST Loss tensor(3191.7993, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1694.9061, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-07 03:13:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2973.0691, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1403.7412, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2192.0547, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1093.8243, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1811.4327, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(913.4902, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1457.0233, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(643.2842, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2537.9944, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1282.4138, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1730.1353, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(825.3832, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2889.7336, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1368.4429, device='cuda:4', grad_fn=<MulBackward0>)
2023-09-07 03:13:41 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.483 | trans_loss 6.068 | nll_loss 3.574 | w2v_ctc_loss 1.234 | task_loss 22.645 | task_loss_gen 12.612 | contrastive_loss 0 | total 6138.43 | n_correct 3122 | ppl 11.91 | accuracy 50.86 | uer 16.278 | wer 18.103 | raw_wer 18.103 | bleu 6.49 | wps 1598.2 | wpb 6138.4 | bsz 201.1 | num_updates 44048 | best_bleu 6.51
2023-09-07 03:13:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 44048 updates
2023-09-07 03:13:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.4909.pt
2023-09-07 03:13:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.4909.pt
2023-09-07 03:13:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.4909.pt (epoch 37 @ 44048 updates, score 6.49) (writing took 9.842601974960417 seconds)
2023-09-07 03:13:51 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-09-07 03:13:51 | INFO | train | epoch 037 | loss 2.127 | trans_loss 5.127 | nll_loss 2.437 | w2v_ctc_loss 0.475 | task_loss 1.538 | task_loss_gen 3.188 | contrastive_loss 0 | total 6703.69 | n_correct 3580.33 | ppl 5.41 | accuracy 53.408 | wps 16557.3 | ups 1.23 | wpb 13407.4 | bsz 452.1 | num_updates 44048 | lr 6.73832e-05 | gnorm 0.422 | clip 0 | loss_scale 16 | train_wall 855 | gb_free 13.5 | wall 38544
2023-09-07 03:13:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 03:13:52 | INFO | fairseq.trainer | begin training epoch 38
2023-09-07 03:13:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 03:14:36 | INFO | train_inner | epoch 038:     52 / 1191 loss=2.133, trans_loss=5.134, nll_loss=2.446, w2v_ctc_loss=0.48, task_loss=1.229, task_loss_gen=3.638, contrastive_loss=0, total=6590.11, n_correct=3505.85, ppl=5.45, accuracy=53.199, wps=7693, ups=0.58, wpb=13180.2, bsz=432.1, num_updates=44100, lr=6.73435e-05, gnorm=0.371, clip=0, loss_scale=16, train_wall=71, gb_free=11.7, wall=38589
2023-09-07 03:15:49 | INFO | train_inner | epoch 038:    152 / 1191 loss=2.117, trans_loss=5.111, nll_loss=2.416, w2v_ctc_loss=0.467, task_loss=1.34, task_loss_gen=3.309, contrastive_loss=0, total=6707.39, n_correct=3606.74, ppl=5.34, accuracy=53.773, wps=18564.6, ups=1.38, wpb=13414.8, bsz=449.4, num_updates=44200, lr=6.72673e-05, gnorm=0.393, clip=0, loss_scale=16, train_wall=72, gb_free=8, wall=38662
2023-09-07 03:17:02 | INFO | train_inner | epoch 038:    252 / 1191 loss=2.122, trans_loss=5.119, nll_loss=2.427, w2v_ctc_loss=0.47, task_loss=1.183, task_loss_gen=3.581, contrastive_loss=0, total=6683.44, n_correct=3577.97, ppl=5.38, accuracy=53.535, wps=18368, ups=1.37, wpb=13366.9, bsz=456.5, num_updates=44300, lr=6.71913e-05, gnorm=0.372, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=38735
2023-09-07 03:18:15 | INFO | train_inner | epoch 038:    352 / 1191 loss=2.125, trans_loss=5.116, nll_loss=2.423, w2v_ctc_loss=0.478, task_loss=1.144, task_loss_gen=3.567, contrastive_loss=0, total=6695.6, n_correct=3579.25, ppl=5.36, accuracy=53.457, wps=18316.9, ups=1.37, wpb=13391.2, bsz=443, num_updates=44400, lr=6.71156e-05, gnorm=0.368, clip=0, loss_scale=16, train_wall=72, gb_free=13, wall=38808
2023-09-07 03:19:27 | INFO | train_inner | epoch 038:    452 / 1191 loss=2.114, trans_loss=5.113, nll_loss=2.419, w2v_ctc_loss=0.472, task_loss=0.95, task_loss_gen=3.752, contrastive_loss=0, total=6755.69, n_correct=3637, ppl=5.35, accuracy=53.836, wps=18554.8, ups=1.37, wpb=13511.4, bsz=476.3, num_updates=44500, lr=6.70402e-05, gnorm=0.368, clip=0, loss_scale=16, train_wall=72, gb_free=13, wall=38880
2023-09-07 03:20:40 | INFO | train_inner | epoch 038:    552 / 1191 loss=2.116, trans_loss=5.113, nll_loss=2.42, w2v_ctc_loss=0.469, task_loss=1.352, task_loss_gen=3.445, contrastive_loss=0, total=6799.96, n_correct=3656.24, ppl=5.35, accuracy=53.769, wps=18655.5, ups=1.37, wpb=13599.9, bsz=463.7, num_updates=44600, lr=6.6965e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=72, gb_free=11.7, wall=38953
2023-09-07 03:21:53 | INFO | train_inner | epoch 038:    652 / 1191 loss=2.115, trans_loss=5.118, nll_loss=2.426, w2v_ctc_loss=0.471, task_loss=1.293, task_loss_gen=3.13, contrastive_loss=0, total=6826.7, n_correct=3672.55, ppl=5.37, accuracy=53.797, wps=18757.5, ups=1.37, wpb=13653.4, bsz=474.6, num_updates=44700, lr=6.689e-05, gnorm=0.379, clip=0, loss_scale=16, train_wall=72, gb_free=11.9, wall=39026
2023-09-07 03:23:06 | INFO | train_inner | epoch 038:    752 / 1191 loss=2.119, trans_loss=5.119, nll_loss=2.428, w2v_ctc_loss=0.472, task_loss=1.443, task_loss_gen=3.431, contrastive_loss=0, total=6730.12, n_correct=3612.13, ppl=5.38, accuracy=53.671, wps=18531, ups=1.38, wpb=13460.2, bsz=464.2, num_updates=44800, lr=6.68153e-05, gnorm=0.39, clip=0, loss_scale=16, train_wall=72, gb_free=13.2, wall=39099
2023-09-07 03:24:19 | INFO | train_inner | epoch 038:    852 / 1191 loss=2.131, trans_loss=5.129, nll_loss=2.439, w2v_ctc_loss=0.477, task_loss=1.471, task_loss_gen=3.495, contrastive_loss=0, total=6687.39, n_correct=3561.05, ppl=5.42, accuracy=53.25, wps=18370.6, ups=1.37, wpb=13374.8, bsz=435.4, num_updates=44900, lr=6.67409e-05, gnorm=0.377, clip=0, loss_scale=16, train_wall=72, gb_free=11.5, wall=39172
2023-09-07 03:25:32 | INFO | train_inner | epoch 038:    952 / 1191 loss=2.127, trans_loss=5.125, nll_loss=2.435, w2v_ctc_loss=0.477, task_loss=1.308, task_loss_gen=3.431, contrastive_loss=0, total=6685.88, n_correct=3574.66, ppl=5.41, accuracy=53.466, wps=18334.2, ups=1.37, wpb=13371.8, bsz=446, num_updates=45000, lr=6.66667e-05, gnorm=0.377, clip=0, loss_scale=16, train_wall=72, gb_free=10.6, wall=39245
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:0')
2023-09-07 03:26:44 | INFO | train_inner | epoch 038:   1052 / 1191 loss=2.128, trans_loss=5.124, nll_loss=2.433, w2v_ctc_loss=0.478, task_loss=1.256, task_loss_gen=3.648, contrastive_loss=0, total=6622.97, n_correct=3538.78, ppl=5.4, accuracy=53.432, wps=18336.9, ups=1.38, wpb=13245.9, bsz=440.1, num_updates=45100, lr=6.65927e-05, gnorm=0.361, clip=0, loss_scale=16, train_wall=71, gb_free=12.2, wall=39317
2023-09-07 03:27:56 | INFO | train_inner | epoch 038:   1152 / 1191 loss=2.125, trans_loss=5.126, nll_loss=2.436, w2v_ctc_loss=0.475, task_loss=1.715, task_loss_gen=3.468, contrastive_loss=0, total=6688.64, n_correct=3574.18, ppl=5.41, accuracy=53.437, wps=18485.5, ups=1.38, wpb=13377.3, bsz=448.4, num_updates=45200, lr=6.6519e-05, gnorm=0.394, clip=0, loss_scale=16, train_wall=72, gb_free=12.9, wall=39389
2023-09-07 03:28:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.1574, device='cuda:2')
2023-09-07 03:29:00 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 4.506 | trans_loss 6.075 | nll_loss 3.576 | w2v_ctc_loss 1.296 | task_loss 27.654 | task_loss_gen 14.653 | contrastive_loss 0 | total 6138.43 | n_correct 3121.86 | ppl 11.93 | accuracy 50.858 | uer 16.26 | wer 17.981 | raw_wer 17.981 | bleu 6.39 | wps 1550.8 | wpb 6138.4 | bsz 201.1 | num_updates 45239 | best_bleu 6.51
2023-09-07 03:29:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 45239 updates
2023-09-07 03:29:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.3901.pt
2023-09-07 03:29:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.3901.pt
2023-09-07 03:29:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.3901.pt (epoch 38 @ 45239 updates, score 6.39) (writing took 8.681705882074311 seconds)
2023-09-07 03:29:09 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-09-07 03:29:09 | INFO | train | epoch 038 | loss 2.122 | trans_loss 5.12 | nll_loss 2.428 | w2v_ctc_loss 0.473 | task_loss 1.321 | task_loss_gen 3.5 | contrastive_loss 0 | total 6703.69 | n_correct 3590.6 | ppl 5.38 | accuracy 53.562 | wps 17406.8 | ups 1.3 | wpb 13407.4 | bsz 452.1 | num_updates 45239 | lr 6.64903e-05 | gnorm 0.379 | clip 0 | loss_scale 16 | train_wall 855 | gb_free 13.8 | wall 39462
2023-09-07 03:29:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 03:29:09 | INFO | fairseq.trainer | begin training epoch 39
2023-09-07 03:29:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 03:30:01 | INFO | train_inner | epoch 039:     61 / 1191 loss=2.131, trans_loss=5.131, nll_loss=2.441, w2v_ctc_loss=0.473, task_loss=1.739, task_loss_gen=3.731, contrastive_loss=0, total=6527.07, n_correct=3474.93, ppl=5.43, accuracy=53.239, wps=10467.6, ups=0.8, wpb=13054.1, bsz=420.4, num_updates=45300, lr=6.64455e-05, gnorm=0.385, clip=0, loss_scale=16, train_wall=72, gb_free=10, wall=39514
2023-09-07 03:31:14 | INFO | train_inner | epoch 039:    161 / 1191 loss=2.116, trans_loss=5.108, nll_loss=2.412, w2v_ctc_loss=0.464, task_loss=1.287, task_loss_gen=3.536, contrastive_loss=0, total=6683.06, n_correct=3590.8, ppl=5.32, accuracy=53.73, wps=18395.3, ups=1.38, wpb=13366.1, bsz=440.5, num_updates=45400, lr=6.63723e-05, gnorm=0.369, clip=0, loss_scale=16, train_wall=72, gb_free=12.8, wall=39587
2023-09-07 03:32:26 | INFO | train_inner | epoch 039:    261 / 1191 loss=2.12, trans_loss=5.118, nll_loss=2.426, w2v_ctc_loss=0.471, task_loss=1.628, task_loss_gen=3.795, contrastive_loss=0, total=6673.47, n_correct=3582.33, ppl=5.37, accuracy=53.68, wps=18338.2, ups=1.37, wpb=13346.9, bsz=445, num_updates=45500, lr=6.62994e-05, gnorm=0.37, clip=0, loss_scale=32, train_wall=72, gb_free=13.5, wall=39659
2023-09-07 03:33:39 | INFO | train_inner | epoch 039:    361 / 1191 loss=2.129, trans_loss=5.122, nll_loss=2.43, w2v_ctc_loss=0.478, task_loss=1.395, task_loss_gen=4.011, contrastive_loss=0, total=6602.39, n_correct=3528.97, ppl=5.39, accuracy=53.45, wps=18081.3, ups=1.37, wpb=13204.8, bsz=427.5, num_updates=45600, lr=6.62266e-05, gnorm=0.353, clip=0, loss_scale=32, train_wall=72, gb_free=12.5, wall=39732
2023-09-07 03:34:52 | INFO | train_inner | epoch 039:    461 / 1191 loss=2.109, trans_loss=5.104, nll_loss=2.408, w2v_ctc_loss=0.459, task_loss=0.893, task_loss_gen=3.987, contrastive_loss=0, total=6752.25, n_correct=3642.91, ppl=5.31, accuracy=53.951, wps=18611.4, ups=1.38, wpb=13504.5, bsz=462.8, num_updates=45700, lr=6.61541e-05, gnorm=0.345, clip=0, loss_scale=32, train_wall=72, gb_free=14.2, wall=39805
2023-09-07 03:36:05 | INFO | train_inner | epoch 039:    561 / 1191 loss=2.115, trans_loss=5.108, nll_loss=2.413, w2v_ctc_loss=0.464, task_loss=0.945, task_loss_gen=4.173, contrastive_loss=0, total=6699.88, n_correct=3601.2, ppl=5.33, accuracy=53.75, wps=18380.6, ups=1.37, wpb=13399.8, bsz=450.3, num_updates=45800, lr=6.60819e-05, gnorm=0.348, clip=0, loss_scale=32, train_wall=72, gb_free=14, wall=39878
2023-09-07 03:37:18 | INFO | train_inner | epoch 039:    661 / 1191 loss=2.115, trans_loss=5.111, nll_loss=2.416, w2v_ctc_loss=0.474, task_loss=1.558, task_loss_gen=4.296, contrastive_loss=0, total=6727.42, n_correct=3628.32, ppl=5.34, accuracy=53.933, wps=18463.1, ups=1.37, wpb=13454.8, bsz=465.6, num_updates=45900, lr=6.60098e-05, gnorm=0.387, clip=0, loss_scale=32, train_wall=72, gb_free=14.5, wall=39951
2023-09-07 03:37:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-07 03:38:31 | INFO | train_inner | epoch 039:    762 / 1191 loss=2.118, trans_loss=5.115, nll_loss=2.422, w2v_ctc_loss=0.47, task_loss=1.776, task_loss_gen=3.657, contrastive_loss=0, total=6723.48, n_correct=3610.21, ppl=5.36, accuracy=53.696, wps=18295.9, ups=1.36, wpb=13447, bsz=453.9, num_updates=46000, lr=6.5938e-05, gnorm=0.392, clip=0, loss_scale=16, train_wall=73, gb_free=12.7, wall=40024
2023-09-07 03:38:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 03:39:06 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.495 | trans_loss 6.064 | nll_loss 3.565 | w2v_ctc_loss 1.283 | task_loss 42.842 | task_loss_gen 22.107 | contrastive_loss 0 | total 6138.43 | n_correct 3123.86 | ppl 11.84 | accuracy 50.89 | uer 16.393 | wer 18.133 | raw_wer 18.133 | bleu 6.35 | wps 1603.5 | wpb 6138.4 | bsz 201.1 | num_updates 46000 | best_bleu 6.51
2023-09-07 03:39:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46000 updates
2023-09-07 03:39:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_39_46000.pt
2023-09-07 03:39:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_39_46000.pt
2023-09-07 03:39:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_39_46000.pt (epoch 39 @ 46000 updates, score 6.35) (writing took 8.2305428290274 seconds)
--Backword ST Loss tensor(3272.4028, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(1589.0579, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-07 03:40:27 | INFO | train_inner | epoch 039:    862 / 1191 loss=2.114, trans_loss=5.112, nll_loss=2.418, w2v_ctc_loss=0.469, task_loss=1.47, task_loss_gen=3.15, contrastive_loss=0, total=6798.2, n_correct=3661.53, ppl=5.34, accuracy=53.86, wps=11752.6, ups=0.86, wpb=13596.4, bsz=472.1, num_updates=46100, lr=6.58665e-05, gnorm=0.374, clip=0, loss_scale=16, train_wall=72, gb_free=13.5, wall=40140
2023-09-07 03:41:40 | INFO | train_inner | epoch 039:    962 / 1191 loss=2.104, trans_loss=5.097, nll_loss=2.399, w2v_ctc_loss=0.464, task_loss=1.569, task_loss_gen=3.072, contrastive_loss=0, total=6835.31, n_correct=3700.04, ppl=5.27, accuracy=54.131, wps=18635.4, ups=1.36, wpb=13670.6, bsz=480.9, num_updates=46200, lr=6.57952e-05, gnorm=0.382, clip=0, loss_scale=16, train_wall=73, gb_free=13.6, wall=40213
2023-09-07 03:42:52 | INFO | train_inner | epoch 039:   1062 / 1191 loss=2.115, trans_loss=5.11, nll_loss=2.416, w2v_ctc_loss=0.466, task_loss=1.558, task_loss_gen=3.326, contrastive_loss=0, total=6757.98, n_correct=3635.99, ppl=5.34, accuracy=53.803, wps=18755.2, ups=1.39, wpb=13516, bsz=459.7, num_updates=46300, lr=6.57241e-05, gnorm=0.387, clip=0, loss_scale=16, train_wall=71, gb_free=14.3, wall=40285
2023-09-07 03:44:04 | INFO | train_inner | epoch 039:   1162 / 1191 loss=2.128, trans_loss=5.123, nll_loss=2.432, w2v_ctc_loss=0.475, task_loss=1.61, task_loss_gen=3.49, contrastive_loss=0, total=6582.59, n_correct=3516.13, ppl=5.4, accuracy=53.416, wps=18271, ups=1.39, wpb=13165.2, bsz=428.8, num_updates=46400, lr=6.56532e-05, gnorm=0.389, clip=0, loss_scale=16, train_wall=71, gb_free=14.1, wall=40357
2023-09-07 03:44:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2771.2178, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1416.5792, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2779.4580, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1431.2826, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2421.9360, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1175.5583, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2360.0740, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(1063.9946, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2957.6667, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(1557.2463, device='cuda:7', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2441.3196, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1300.8801, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2972.4536, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1455.1793, device='cuda:1', grad_fn=<MulBackward0>)
2023-09-07 03:44:59 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.49 | trans_loss 6.065 | nll_loss 3.569 | w2v_ctc_loss 1.263 | task_loss 34.816 | task_loss_gen 18.432 | contrastive_loss 0 | total 6138.43 | n_correct 3119.86 | ppl 11.87 | accuracy 50.825 | uer 16.268 | wer 18.144 | raw_wer 18.144 | bleu 6.37 | wps 1662.3 | wpb 6138.4 | bsz 201.1 | num_updates 46429 | best_bleu 6.51
2023-09-07 03:44:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 46429 updates
2023-09-07 03:44:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.3704.pt
2023-09-07 03:45:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.3704.pt
2023-09-07 03:45:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.3704.pt (epoch 39 @ 46429 updates, score 6.37) (writing took 7.195166031946428 seconds)
2023-09-07 03:45:07 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-09-07 03:45:07 | INFO | train | epoch 039 | loss 2.117 | trans_loss 5.112 | nll_loss 2.418 | w2v_ctc_loss 0.469 | task_loss 1.442 | task_loss_gen 3.652 | contrastive_loss 0 | total 6703.84 | n_correct 3603.76 | ppl 5.34 | accuracy 53.757 | wps 16650.7 | ups 1.24 | wpb 13407.7 | bsz 452.2 | num_updates 46429 | lr 6.56327e-05 | gnorm 0.373 | clip 0 | loss_scale 16 | train_wall 856 | gb_free 13.1 | wall 40420
2023-09-07 03:45:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 03:45:07 | INFO | fairseq.trainer | begin training epoch 40
2023-09-07 03:45:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 03:46:07 | INFO | train_inner | epoch 040:     71 / 1191 loss=2.103, trans_loss=5.094, nll_loss=2.394, w2v_ctc_loss=0.46, task_loss=1.392, task_loss_gen=3.196, contrastive_loss=0, total=6767.38, n_correct=3667.61, ppl=5.26, accuracy=54.195, wps=11042, ups=0.82, wpb=13534.8, bsz=468.9, num_updates=46500, lr=6.55826e-05, gnorm=0.371, clip=0, loss_scale=16, train_wall=72, gb_free=13.1, wall=40480
2023-09-07 03:47:19 | INFO | train_inner | epoch 040:    171 / 1191 loss=2.109, trans_loss=5.101, nll_loss=2.403, w2v_ctc_loss=0.461, task_loss=1.386, task_loss_gen=3.601, contrastive_loss=0, total=6723.92, n_correct=3635.14, ppl=5.29, accuracy=54.063, wps=18668.6, ups=1.39, wpb=13447.8, bsz=450.2, num_updates=46600, lr=6.55122e-05, gnorm=0.379, clip=0, loss_scale=16, train_wall=71, gb_free=13.9, wall=40552
2023-09-07 03:48:31 | INFO | train_inner | epoch 040:    271 / 1191 loss=2.101, trans_loss=5.093, nll_loss=2.392, w2v_ctc_loss=0.458, task_loss=1.382, task_loss_gen=3.485, contrastive_loss=0, total=6753.31, n_correct=3663.49, ppl=5.25, accuracy=54.247, wps=18635.1, ups=1.38, wpb=13506.6, bsz=465.8, num_updates=46700, lr=6.5442e-05, gnorm=0.381, clip=0, loss_scale=16, train_wall=72, gb_free=14.8, wall=40624
2023-09-07 03:49:44 | INFO | train_inner | epoch 040:    371 / 1191 loss=2.119, trans_loss=5.111, nll_loss=2.416, w2v_ctc_loss=0.467, task_loss=1.326, task_loss_gen=3.945, contrastive_loss=0, total=6618.47, n_correct=3547.02, ppl=5.34, accuracy=53.593, wps=18131.4, ups=1.37, wpb=13236.9, bsz=438.2, num_updates=46800, lr=6.5372e-05, gnorm=0.377, clip=0, loss_scale=16, train_wall=72, gb_free=14.2, wall=40697
2023-09-07 03:50:57 | INFO | train_inner | epoch 040:    471 / 1191 loss=2.108, trans_loss=5.101, nll_loss=2.403, w2v_ctc_loss=0.462, task_loss=1.289, task_loss_gen=3.757, contrastive_loss=0, total=6719.05, n_correct=3635.58, ppl=5.29, accuracy=54.109, wps=18604.6, ups=1.38, wpb=13438.1, bsz=454.8, num_updates=46900, lr=6.53023e-05, gnorm=0.378, clip=0, loss_scale=16, train_wall=72, gb_free=13.8, wall=40770
2023-09-07 03:52:09 | INFO | train_inner | epoch 040:    571 / 1191 loss=2.111, trans_loss=5.105, nll_loss=2.408, w2v_ctc_loss=0.463, task_loss=1.65, task_loss_gen=3.446, contrastive_loss=0, total=6684.61, n_correct=3607.64, ppl=5.31, accuracy=53.969, wps=18498.6, ups=1.38, wpb=13369.2, bsz=455.8, num_updates=47000, lr=6.52328e-05, gnorm=0.404, clip=0, loss_scale=16, train_wall=71, gb_free=12, wall=40842
2023-09-07 03:53:22 | INFO | train_inner | epoch 040:    671 / 1191 loss=2.118, trans_loss=5.111, nll_loss=2.415, w2v_ctc_loss=0.471, task_loss=1.289, task_loss_gen=3.565, contrastive_loss=0, total=6699.46, n_correct=3603.23, ppl=5.33, accuracy=53.784, wps=18411.7, ups=1.37, wpb=13398.9, bsz=447.6, num_updates=47100, lr=6.51635e-05, gnorm=0.38, clip=0, loss_scale=16, train_wall=72, gb_free=7.6, wall=40915
2023-09-07 03:53:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-07 03:54:35 | INFO | train_inner | epoch 040:    772 / 1191 loss=2.119, trans_loss=5.112, nll_loss=2.418, w2v_ctc_loss=0.473, task_loss=1.654, task_loss_gen=3.52, contrastive_loss=0, total=6663.89, n_correct=3580.19, ppl=5.34, accuracy=53.725, wps=18159.1, ups=1.36, wpb=13327.8, bsz=443.6, num_updates=47200, lr=6.50945e-05, gnorm=0.476, clip=0, loss_scale=8, train_wall=73, gb_free=13.1, wall=40988
2023-09-07 03:55:48 | INFO | train_inner | epoch 040:    872 / 1191 loss=2.126, trans_loss=5.12, nll_loss=2.428, w2v_ctc_loss=0.476, task_loss=2.182, task_loss_gen=3.463, contrastive_loss=0, total=6695.84, n_correct=3581.69, ppl=5.38, accuracy=53.491, wps=18283.5, ups=1.37, wpb=13391.7, bsz=442.3, num_updates=47300, lr=6.50256e-05, gnorm=0.612, clip=0, loss_scale=8, train_wall=73, gb_free=13.3, wall=41061
2023-09-07 03:57:00 | INFO | train_inner | epoch 040:    972 / 1191 loss=2.116, trans_loss=5.113, nll_loss=2.42, w2v_ctc_loss=0.469, task_loss=1.946, task_loss_gen=3.351, contrastive_loss=0, total=6689.77, n_correct=3600.05, ppl=5.35, accuracy=53.814, wps=18674.6, ups=1.4, wpb=13379.5, bsz=454, num_updates=47400, lr=6.4957e-05, gnorm=0.606, clip=0, loss_scale=8, train_wall=71, gb_free=13.2, wall=41133
2023-09-07 03:58:13 | INFO | train_inner | epoch 040:   1072 / 1191 loss=2.113, trans_loss=5.106, nll_loss=2.41, w2v_ctc_loss=0.47, task_loss=1.969, task_loss_gen=3.145, contrastive_loss=0, total=6761.55, n_correct=3647.83, ppl=5.31, accuracy=53.95, wps=18466.1, ups=1.37, wpb=13523.1, bsz=459.1, num_updates=47500, lr=6.48886e-05, gnorm=0.599, clip=0, loss_scale=8, train_wall=72, gb_free=14.1, wall=41206
2023-09-07 03:59:26 | INFO | train_inner | epoch 040:   1172 / 1191 loss=2.11, trans_loss=5.107, nll_loss=2.411, w2v_ctc_loss=0.461, task_loss=2.077, task_loss_gen=3.236, contrastive_loss=0, total=6688.64, n_correct=3607.75, ppl=5.32, accuracy=53.938, wps=18429.7, ups=1.38, wpb=13377.3, bsz=458.8, num_updates=47600, lr=6.48204e-05, gnorm=0.622, clip=0, loss_scale=8, train_wall=72, gb_free=12.6, wall=41279
2023-09-07 03:59:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 04:00:14 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 4.495 | trans_loss 6.06 | nll_loss 3.561 | w2v_ctc_loss 1.291 | task_loss 62.06 | task_loss_gen 31.209 | contrastive_loss 0 | total 6138.43 | n_correct 3135.57 | ppl 11.81 | accuracy 51.081 | uer 16.252 | wer 18.066 | raw_wer 18.066 | bleu 6.75 | wps 1613.2 | wpb 6138.4 | bsz 201.1 | num_updates 47619 | best_bleu 6.75
2023-09-07 04:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 47619 updates
2023-09-07 04:00:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 04:00:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 04:00:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 40 @ 47619 updates, score 6.75) (writing took 12.701422263984568 seconds)
2023-09-07 04:00:27 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-09-07 04:00:27 | INFO | train | epoch 040 | loss 2.113 | trans_loss 5.107 | nll_loss 2.411 | w2v_ctc_loss 0.466 | task_loss 1.634 | task_loss_gen 3.491 | contrastive_loss 0 | total 6704.04 | n_correct 3612.5 | ppl 5.32 | accuracy 53.885 | wps 17342.1 | ups 1.29 | wpb 13408.1 | bsz 452.2 | num_updates 47619 | lr 6.48074e-05 | gnorm 0.469 | clip 0 | loss_scale 8 | train_wall 855 | gb_free 12.1 | wall 41340
2023-09-07 04:00:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 04:00:27 | INFO | fairseq.trainer | begin training epoch 41
2023-09-07 04:00:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 04:01:34 | INFO | train_inner | epoch 041:     81 / 1191 loss=2.104, trans_loss=5.097, nll_loss=2.398, w2v_ctc_loss=0.461, task_loss=1.79, task_loss_gen=3.196, contrastive_loss=0, total=6722.93, n_correct=3647.27, ppl=5.27, accuracy=54.251, wps=10455.7, ups=0.78, wpb=13445.9, bsz=464.5, num_updates=47700, lr=6.47524e-05, gnorm=0.563, clip=0, loss_scale=8, train_wall=72, gb_free=14, wall=41407
2023-09-07 04:02:47 | INFO | train_inner | epoch 041:    181 / 1191 loss=2.114, trans_loss=5.103, nll_loss=2.405, w2v_ctc_loss=0.465, task_loss=1.778, task_loss_gen=3.125, contrastive_loss=0, total=6672.05, n_correct=3587.05, ppl=5.3, accuracy=53.762, wps=18434.7, ups=1.38, wpb=13344.1, bsz=445, num_updates=47800, lr=6.46846e-05, gnorm=0.534, clip=0, loss_scale=8, train_wall=72, gb_free=11.5, wall=41480
2023-09-07 04:04:00 | INFO | train_inner | epoch 041:    281 / 1191 loss=2.096, trans_loss=5.09, nll_loss=2.389, w2v_ctc_loss=0.454, task_loss=1.841, task_loss_gen=2.916, contrastive_loss=0, total=6804.18, n_correct=3701.81, ppl=5.24, accuracy=54.405, wps=18648.9, ups=1.37, wpb=13608.4, bsz=478.8, num_updates=47900, lr=6.46171e-05, gnorm=0.542, clip=0, loss_scale=8, train_wall=72, gb_free=12.9, wall=41553
2023-09-07 04:05:13 | INFO | train_inner | epoch 041:    381 / 1191 loss=2.104, trans_loss=5.095, nll_loss=2.395, w2v_ctc_loss=0.464, task_loss=2.202, task_loss_gen=3.302, contrastive_loss=0, total=6779.91, n_correct=3677.54, ppl=5.26, accuracy=54.242, wps=18649, ups=1.38, wpb=13559.8, bsz=459.7, num_updates=48000, lr=6.45497e-05, gnorm=0.568, clip=0, loss_scale=8, train_wall=72, gb_free=13.7, wall=41626
2023-09-07 04:05:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 04:05:49 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 4.5 | trans_loss 6.066 | nll_loss 3.565 | w2v_ctc_loss 1.295 | task_loss 66.718 | task_loss_gen 33.397 | contrastive_loss 0 | total 6138.43 | n_correct 3136.14 | ppl 11.83 | accuracy 51.09 | uer 16.458 | wer 18.185 | raw_wer 18.185 | bleu 6.38 | wps 1459.4 | wpb 6138.4 | bsz 201.1 | num_updates 48000 | best_bleu 6.75
2023-09-07 04:05:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48000 updates
2023-09-07 04:05:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_41_48000.pt
2023-09-07 04:05:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_41_48000.pt
2023-09-07 04:05:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_41_48000.pt (epoch 41 @ 48000 updates, score 6.38) (writing took 7.923602839000523 seconds)
--Backword ST Loss tensor(1542.5613, device='cuda:0', grad_fn=<AddBackward0>) 	MT Loss tensor(746.2013, device='cuda:0', grad_fn=<MulBackward0>)
2023-09-07 04:07:10 | INFO | train_inner | epoch 041:    481 / 1191 loss=2.104, trans_loss=5.095, nll_loss=2.395, w2v_ctc_loss=0.462, task_loss=2.067, task_loss_gen=2.965, contrastive_loss=0, total=6790.05, n_correct=3682.99, ppl=5.26, accuracy=54.241, wps=11584.4, ups=0.85, wpb=13580.1, bsz=461.9, num_updates=48100, lr=6.44826e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=71, gb_free=12.3, wall=41743
2023-09-07 04:08:22 | INFO | train_inner | epoch 041:    581 / 1191 loss=2.101, trans_loss=5.093, nll_loss=2.392, w2v_ctc_loss=0.45, task_loss=1.787, task_loss_gen=2.966, contrastive_loss=0, total=6773.53, n_correct=3672.47, ppl=5.25, accuracy=54.218, wps=18725.3, ups=1.38, wpb=13547.1, bsz=458, num_updates=48200, lr=6.44157e-05, gnorm=0.469, clip=0, loss_scale=8, train_wall=72, gb_free=10.9, wall=41815
2023-09-07 04:09:35 | INFO | train_inner | epoch 041:    681 / 1191 loss=2.112, trans_loss=5.102, nll_loss=2.405, w2v_ctc_loss=0.469, task_loss=2.356, task_loss_gen=3.202, contrastive_loss=0, total=6677.75, n_correct=3602.94, ppl=5.3, accuracy=53.954, wps=18451.6, ups=1.38, wpb=13355.5, bsz=448.7, num_updates=48300, lr=6.43489e-05, gnorm=0.589, clip=0, loss_scale=8, train_wall=72, gb_free=10.3, wall=41888
2023-09-07 04:10:47 | INFO | train_inner | epoch 041:    781 / 1191 loss=2.121, trans_loss=5.109, nll_loss=2.413, w2v_ctc_loss=0.472, task_loss=1.901, task_loss_gen=3.212, contrastive_loss=0, total=6547.43, n_correct=3509.48, ppl=5.32, accuracy=53.601, wps=17958.2, ups=1.37, wpb=13094.9, bsz=422.4, num_updates=48400, lr=6.42824e-05, gnorm=0.478, clip=0, loss_scale=8, train_wall=72, gb_free=12.8, wall=41960
2023-09-07 04:12:00 | INFO | train_inner | epoch 041:    881 / 1191 loss=2.12, trans_loss=5.107, nll_loss=2.41, w2v_ctc_loss=0.471, task_loss=2.395, task_loss_gen=3.199, contrastive_loss=0, total=6581.95, n_correct=3534.37, ppl=5.32, accuracy=53.698, wps=18064, ups=1.37, wpb=13163.9, bsz=427.6, num_updates=48500, lr=6.42161e-05, gnorm=0.565, clip=0, loss_scale=8, train_wall=72, gb_free=10.4, wall=42033
2023-09-07 04:13:13 | INFO | train_inner | epoch 041:    981 / 1191 loss=2.118, trans_loss=5.112, nll_loss=2.417, w2v_ctc_loss=0.469, task_loss=1.968, task_loss_gen=3.241, contrastive_loss=0, total=6677.96, n_correct=3587.11, ppl=5.34, accuracy=53.716, wps=18376.5, ups=1.38, wpb=13355.9, bsz=444.6, num_updates=48600, lr=6.415e-05, gnorm=0.529, clip=0, loss_scale=8, train_wall=72, gb_free=13.8, wall=42106
2023-09-07 04:14:26 | INFO | train_inner | epoch 041:   1081 / 1191 loss=2.101, trans_loss=5.095, nll_loss=2.396, w2v_ctc_loss=0.462, task_loss=1.625, task_loss_gen=2.796, contrastive_loss=0, total=6841.34, n_correct=3722.17, ppl=5.26, accuracy=54.407, wps=18711.9, ups=1.37, wpb=13682.7, bsz=478.7, num_updates=48700, lr=6.40841e-05, gnorm=0.478, clip=0, loss_scale=8, train_wall=72, gb_free=14.2, wall=42179
2023-09-07 04:15:38 | INFO | train_inner | epoch 041:   1181 / 1191 loss=2.118, trans_loss=5.112, nll_loss=2.418, w2v_ctc_loss=0.466, task_loss=1.702, task_loss_gen=3.219, contrastive_loss=0, total=6589.42, n_correct=3533.85, ppl=5.34, accuracy=53.629, wps=18233.1, ups=1.38, wpb=13178.8, bsz=431.4, num_updates=48800, lr=6.40184e-05, gnorm=0.468, clip=0, loss_scale=8, train_wall=72, gb_free=13.1, wall=42251
2023-09-07 04:15:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
--Backword ST Loss tensor(2327.1135, device='cuda:2', grad_fn=<AddBackward0>) 	MT Loss tensor(1119.3293, device='cuda:2', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2919.7661, device='cuda:1', grad_fn=<AddBackward0>) 	MT Loss tensor(1510.9874, device='cuda:1', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2817.4163, device='cuda:6', grad_fn=<AddBackward0>) 	MT Loss tensor(1426.0063, device='cuda:6', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2181.0991, device='cuda:3', grad_fn=<AddBackward0>) 	MT Loss tensor(1047.4017, device='cuda:3', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1787.6172, device='cuda:5', grad_fn=<AddBackward0>) 	MT Loss tensor(843.4924, device='cuda:5', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(2858.0520, device='cuda:4', grad_fn=<AddBackward0>) 	MT Loss tensor(1446.0365, device='cuda:4', grad_fn=<MulBackward0>)
--Backword ST Loss tensor(1711.7107, device='cuda:7', grad_fn=<AddBackward0>) 	MT Loss tensor(800.9772, device='cuda:7', grad_fn=<MulBackward0>)
2023-09-07 04:16:21 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 4.495 | trans_loss 6.063 | nll_loss 3.559 | w2v_ctc_loss 1.285 | task_loss 48.171 | task_loss_gen 24.228 | contrastive_loss 0 | total 6138.43 | n_correct 3139.29 | ppl 11.79 | accuracy 51.142 | uer 16.583 | wer 18.245 | raw_wer 18.245 | bleu 6.63 | wps 1510.5 | wpb 6138.4 | bsz 201.1 | num_updates 48810 | best_bleu 6.75
2023-09-07 04:16:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 48810 updates
2023-09-07 04:16:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.6301.pt
2023-09-07 04:16:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.6301.pt
2023-09-07 04:16:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint.best_bleu_6.6301.pt (epoch 41 @ 48810 updates, score 6.63) (writing took 7.769641082035378 seconds)
2023-09-07 04:16:29 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-09-07 04:16:29 | INFO | train | epoch 041 | loss 2.109 | trans_loss 5.1 | nll_loss 2.402 | w2v_ctc_loss 0.464 | task_loss 1.952 | task_loss_gen 3.099 | contrastive_loss 0 | total 6703.69 | n_correct 3622.01 | ppl 5.29 | accuracy 54.03 | wps 16592.5 | ups 1.24 | wpb 13407.4 | bsz 452.1 | num_updates 48810 | lr 6.40119e-05 | gnorm 0.526 | clip 0 | loss_scale 8 | train_wall 856 | gb_free 11.3 | wall 42302
2023-09-07 04:16:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-09-07 04:16:30 | INFO | fairseq.trainer | begin training epoch 42
2023-09-07 04:16:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-07 04:17:42 | INFO | train_inner | epoch 042:     90 / 1191 loss=2.086, trans_loss=5.076, nll_loss=2.37, w2v_ctc_loss=0.448, task_loss=1.653, task_loss_gen=2.872, contrastive_loss=0, total=6824.86, n_correct=3738.87, ppl=5.17, accuracy=54.783, wps=11003.8, ups=0.81, wpb=13649.7, bsz=483.3, num_updates=48900, lr=6.39529e-05, gnorm=0.511, clip=0, loss_scale=8, train_wall=71, gb_free=13.6, wall=42375
2023-09-07 04:18:55 | INFO | train_inner | epoch 042:    190 / 1191 loss=2.114, trans_loss=5.103, nll_loss=2.406, w2v_ctc_loss=0.464, task_loss=2.043, task_loss_gen=3.245, contrastive_loss=0, total=6671.53, n_correct=3590.27, ppl=5.3, accuracy=53.815, wps=18427.8, ups=1.38, wpb=13343.1, bsz=441.1, num_updates=49000, lr=6.38877e-05, gnorm=0.537, clip=0, loss_scale=8, train_wall=72, gb_free=13.5, wall=42448
2023-09-07 04:20:08 | INFO | train_inner | epoch 042:    290 / 1191 loss=2.108, trans_loss=5.093, nll_loss=2.392, w2v_ctc_loss=0.466, task_loss=1.932, task_loss_gen=3.283, contrastive_loss=0, total=6650.86, n_correct=3598.38, ppl=5.25, accuracy=54.104, wps=18271.9, ups=1.37, wpb=13301.7, bsz=445.5, num_updates=49100, lr=6.38226e-05, gnorm=0.575, clip=0, loss_scale=8, train_wall=72, gb_free=14.3, wall=42521
2023-09-07 04:21:20 | INFO | train_inner | epoch 042:    390 / 1191 loss=2.104, trans_loss=5.093, nll_loss=2.393, w2v_ctc_loss=0.462, task_loss=1.587, task_loss_gen=3.372, contrastive_loss=0, total=6626.36, n_correct=3593.19, ppl=5.25, accuracy=54.226, wps=18255.7, ups=1.38, wpb=13252.7, bsz=447.3, num_updates=49200, lr=6.37577e-05, gnorm=0.443, clip=0, loss_scale=16, train_wall=72, gb_free=13.9, wall=42593
2023-09-07 04:22:34 | INFO | train_inner | epoch 042:    490 / 1191 loss=2.119, trans_loss=5.112, nll_loss=2.416, w2v_ctc_loss=0.464, task_loss=1.832, task_loss_gen=3.644, contrastive_loss=0, total=6622.87, n_correct=3552.71, ppl=5.34, accuracy=53.643, wps=18003.1, ups=1.36, wpb=13245.7, bsz=418.4, num_updates=49300, lr=6.3693e-05, gnorm=0.401, clip=0, loss_scale=16, train_wall=73, gb_free=14.1, wall=42667
2023-09-07 04:23:46 | INFO | train_inner | epoch 042:    590 / 1191 loss=2.116, trans_loss=5.105, nll_loss=2.407, w2v_ctc_loss=0.469, task_loss=1.739, task_loss_gen=3.531, contrastive_loss=0, total=6598.24, n_correct=3551.5, ppl=5.3, accuracy=53.825, wps=18250.7, ups=1.38, wpb=13196.5, bsz=431.9, num_updates=49400, lr=6.36285e-05, gnorm=0.404, clip=0, loss_scale=16, train_wall=71, gb_free=12, wall=42739
2023-09-07 04:24:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-07 04:24:59 | INFO | train_inner | epoch 042:    691 / 1191 loss=2.092, trans_loss=5.083, nll_loss=2.379, w2v_ctc_loss=0.456, task_loss=1.666, task_loss_gen=2.878, contrastive_loss=0, total=6832.93, n_correct=3734.28, ppl=5.2, accuracy=54.651, wps=18658.7, ups=1.37, wpb=13665.9, bsz=481.4, num_updates=49500, lr=6.35642e-05, gnorm=0.464, clip=0, loss_scale=8, train_wall=72, gb_free=13.7, wall=42812
2023-09-07 04:26:12 | INFO | train_inner | epoch 042:    791 / 1191 loss=2.097, trans_loss=5.092, nll_loss=2.391, w2v_ctc_loss=0.457, task_loss=1.599, task_loss_gen=2.91, contrastive_loss=0, total=6740.78, n_correct=3670.95, ppl=5.25, accuracy=54.459, wps=18531.2, ups=1.37, wpb=13481.6, bsz=470.6, num_updates=49600, lr=6.35001e-05, gnorm=0.471, clip=0, loss_scale=8, train_wall=72, gb_free=14.1, wall=42885
2023-09-07 04:27:24 | INFO | train_inner | epoch 042:    891 / 1191 loss=2.111, trans_loss=5.099, nll_loss=2.399, w2v_ctc_loss=0.465, task_loss=1.923, task_loss_gen=3.364, contrastive_loss=0, total=6539.07, n_correct=3532.62, ppl=5.28, accuracy=54.023, wps=18106.2, ups=1.38, wpb=13078.1, bsz=432.2, num_updates=49700, lr=6.34361e-05, gnorm=0.565, clip=0, loss_scale=8, train_wall=71, gb_free=10.2, wall=42957
2023-09-07 04:28:37 | INFO | train_inner | epoch 042:    991 / 1191 loss=2.091, trans_loss=5.084, nll_loss=2.381, w2v_ctc_loss=0.454, task_loss=1.682, task_loss_gen=2.906, contrastive_loss=0, total=6832.32, n_correct=3731.21, ppl=5.21, accuracy=54.611, wps=18923, ups=1.38, wpb=13664.6, bsz=486.3, num_updates=49800, lr=6.33724e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=71, gb_free=13.4, wall=43030
2023-09-07 04:29:49 | INFO | train_inner | epoch 042:   1091 / 1191 loss=2.125, trans_loss=5.118, nll_loss=2.424, w2v_ctc_loss=0.467, task_loss=1.88, task_loss_gen=3.546, contrastive_loss=0, total=6659.37, n_correct=3560.34, ppl=5.36, accuracy=53.464, wps=18471.4, ups=1.39, wpb=13318.7, bsz=420.2, num_updates=49900, lr=6.33089e-05, gnorm=0.507, clip=0, loss_scale=8, train_wall=71, gb_free=14.8, wall=43102
2023-09-07 04:31:02 | INFO | train_inner | epoch 042:   1191 / 1191 loss=2.103, trans_loss=5.094, nll_loss=2.393, w2v_ctc_loss=0.461, task_loss=1.392, task_loss_gen=3.156, contrastive_loss=0, total=6806.95, n_correct=3695.86, ppl=5.25, accuracy=54.295, wps=18514.6, ups=1.36, wpb=13613.9, bsz=463.1, num_updates=50000, lr=6.32456e-05, gnorm=0.441, clip=0, loss_scale=8, train_wall=73, gb_free=10.8, wall=43175
2023-09-07 04:31:02 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-09-07 04:31:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-09-07 04:31:37 | INFO | dev_st | epoch 042 | valid on 'dev_st' subset | loss 4.48 | trans_loss 6.052 | nll_loss 3.55 | w2v_ctc_loss 1.26 | task_loss 19.807 | task_loss_gen 11.359 | contrastive_loss 0 | total 6138.43 | n_correct 3141.57 | ppl 11.71 | accuracy 51.179 | uer 16.225 | wer 17.988 | raw_wer 17.988 | bleu 6.8 | wps 1606.8 | wpb 6138.4 | bsz 201.1 | num_updates 50000 | best_bleu 6.8
2023-09-07 04:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 50000 updates
2023-09-07 04:31:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 04:31:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt
2023-09-07 04:31:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_v4_merge_wmt_0906_shrink_soft_noCL_AT_sentence_mixup_changeid_scale2_alpha0_mt0.5/checkpoint_best.pt (epoch 42 @ 50000 updates, score 6.8) (writing took 11.833251061034389 seconds)
2023-09-07 04:31:49 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-09-07 04:31:49 | INFO | train | epoch 042 | loss 2.105 | trans_loss 5.096 | nll_loss 2.396 | w2v_ctc_loss 0.461 | task_loss 1.735 | task_loss_gen 3.21 | contrastive_loss 0 | total 6704.24 | n_correct 3631.38 | ppl 5.26 | accuracy 54.165 | wps 17347.8 | ups 1.29 | wpb 13408.5 | bsz 452.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.487 | clip 0 | loss_scale 8 | train_wall 854 | gb_free 10.8 | wall 43222
2023-09-07 04:31:49 | INFO | fairseq_cli.train | done training in 43167.1 seconds
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1728 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
