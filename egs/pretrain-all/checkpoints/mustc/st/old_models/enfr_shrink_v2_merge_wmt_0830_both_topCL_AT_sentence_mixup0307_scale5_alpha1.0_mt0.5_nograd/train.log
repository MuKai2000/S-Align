2023-08-30 15:16:30 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13061
2023-08-30 15:16:30 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13061
2023-08-30 15:16:30 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13061
2023-08-30 15:16:30 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13061
2023-08-30 15:16:30 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13061
2023-08-30 15:16:30 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13061
2023-08-30 15:16:30 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13061
2023-08-30 15:16:30 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13061
2023-08-30 15:16:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-30 15:16:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 15:16:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 15:16:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 15:16:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 15:16:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 15:16:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 15:16:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 15:16:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-30 15:16:31 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 15:16:31 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-30 15:16:34 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13061', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=5.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=5.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=5.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-30 15:16:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,999
2023-08-30 15:16:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,999
2023-08-30 15:16:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-30 15:16:34 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-30 15:16:34 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-08-30 15:16:39 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-30 15:16:39 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-30 15:16:39 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-30 15:16:41 | INFO | root | load pretrained hubert
2023-08-30 15:16:48 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enfr_baseline
2023-08-30 15:16:52 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-08-30 15:16:58 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2fr/enfr-baseline/last5.ensemble.pt
2023-08-30 15:16:58 | INFO | root | share the sematic adapter and textual encoder
2023-08-30 15:16:58 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=9999, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(9999, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=9999, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-30 15:16:58 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-30 15:16:58 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-30 15:16:58 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-30 15:16:58 | INFO | fairseq_cli.train | num. shared model params: 147,043,968 (num. trained: 147,043,968)
2023-08-30 15:16:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-30 15:16:58 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-30 15:16:58 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-30 15:16:58 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-30 15:16:58 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1408, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-30 15:17:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-30 15:17:14 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-30 15:17:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-30 15:17:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-30 15:17:15 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 15:17:15 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 15:17:15 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 15:17:15 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 15:17:15 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 15:17:15 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 15:17:15 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 15:17:15 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-30 15:17:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-30 15:17:15 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-30 15:17:15 | INFO | fairseq_cli.train | max tokens per device = 11000 and max sentences per device = None
2023-08-30 15:17:15 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_last.pt
2023-08-30 15:17:15 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_last.pt
2023-08-30 15:17:15 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-30 15:17:15 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-30 15:17:15 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-30 15:17:15 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_enfr_lcrm/sentencepiece.bpe.model'}
2023-08-30 15:17:17 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-30 15:17:20 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=269255, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-30 15:18:11 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-30 15:18:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-30 15:18:11 | INFO | fairseq.trainer | begin training epoch 1
2023-08-30 15:18:11 | INFO | fairseq_cli.train | Start iterating over samples
True False
None None None
2023-08-30 15:18:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-30 15:18:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
True False
None None None
True False
None None None
True False
None None None
2023-08-30 15:19:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
True False
None None None
2023-08-30 15:20:06 | INFO | train_inner | epoch 001:    103 / 1191 loss=19.025, trans_loss=6.389, nll_loss=5.162, w2v_ctc_loss=21.391, task_loss=5.945, contrastive_loss=3.613, total=6741.87, n_correct=203.57, ppl=35.8, accuracy=3.019, wps=20360.8, ups=1.04, wpb=19523.2, bsz=683.5, num_updates=100, lr=4.098e-06, gnorm=1.644, clip=0, loss_scale=16, train_wall=105, gb_free=17.9, wall=170
2023-08-30 15:21:46 | INFO | train_inner | epoch 001:    203 / 1191 loss=15.284, trans_loss=6.188, nll_loss=4.981, w2v_ctc_loss=15.857, task_loss=5.689, contrastive_loss=3.626, total=6694.99, n_correct=168.23, ppl=31.58, accuracy=2.513, wps=19438.8, ups=1, wpb=19404.5, bsz=683.1, num_updates=200, lr=8.096e-06, gnorm=6.147, clip=4, loss_scale=16, train_wall=99, gb_free=17.6, wall=271
2023-08-30 15:23:26 | INFO | train_inner | epoch 001:    303 / 1191 loss=10.27, trans_loss=6.165, nll_loss=5.029, w2v_ctc_loss=8.13, task_loss=4.786, contrastive_loss=3.656, total=6849.79, n_correct=128.97, ppl=32.66, accuracy=1.883, wps=19833.7, ups=1, wpb=19850.1, bsz=713.5, num_updates=300, lr=1.2094e-05, gnorm=1.62, clip=0, loss_scale=16, train_wall=99, gb_free=18, wall=371
2023-08-30 15:25:00 | INFO | train_inner | epoch 001:    403 / 1191 loss=9.822, trans_loss=6.278, nll_loss=5.203, w2v_ctc_loss=7.387, task_loss=5.061, contrastive_loss=3.538, total=6661.33, n_correct=67.31, ppl=36.83, accuracy=1.01, wps=20499.4, ups=1.06, wpb=19315.8, bsz=657.1, num_updates=400, lr=1.6092e-05, gnorm=0.844, clip=0, loss_scale=16, train_wall=75, gb_free=18.1, wall=465
2023-08-30 15:26:39 | INFO | train_inner | epoch 001:    503 / 1191 loss=9.694, trans_loss=6.402, nll_loss=5.365, w2v_ctc_loss=7.035, task_loss=4.467, contrastive_loss=3.59, total=6737.22, n_correct=38.15, ppl=41.22, accuracy=0.566, wps=19766.1, ups=1.01, wpb=19517.9, bsz=686.6, num_updates=500, lr=2.009e-05, gnorm=0.719, clip=0, loss_scale=16, train_wall=97, gb_free=18.4, wall=564
2023-08-30 15:28:17 | INFO | train_inner | epoch 001:    603 / 1191 loss=9.634, trans_loss=6.438, nll_loss=5.415, w2v_ctc_loss=6.899, task_loss=4.34, contrastive_loss=3.559, total=6775.38, n_correct=31.04, ppl=42.65, accuracy=0.458, wps=19933.7, ups=1.02, wpb=19631.7, bsz=689.3, num_updates=600, lr=2.4088e-05, gnorm=0.851, clip=0, loss_scale=16, train_wall=98, gb_free=18, wall=663
2023-08-30 15:29:47 | INFO | train_inner | epoch 001:    703 / 1191 loss=9.589, trans_loss=6.5, nll_loss=5.493, w2v_ctc_loss=6.788, task_loss=4.452, contrastive_loss=3.577, total=6625.64, n_correct=20.1, ppl=45.03, accuracy=0.303, wps=21274.5, ups=1.11, wpb=19188.7, bsz=672.7, num_updates=700, lr=2.8086e-05, gnorm=0.879, clip=0, loss_scale=16, train_wall=81, gb_free=18.1, wall=753
2023-08-30 15:31:28 | INFO | train_inner | epoch 001:    803 / 1191 loss=9.541, trans_loss=6.466, nll_loss=5.447, w2v_ctc_loss=6.751, task_loss=4.203, contrastive_loss=3.543, total=6750.05, n_correct=16.48, ppl=43.63, accuracy=0.244, wps=19345.5, ups=0.99, wpb=19548.7, bsz=688.8, num_updates=800, lr=3.2084e-05, gnorm=0.904, clip=0, loss_scale=16, train_wall=101, gb_free=18.3, wall=854
2023-08-30 15:33:08 | INFO | train_inner | epoch 001:    903 / 1191 loss=9.369, trans_loss=6.327, nll_loss=5.27, w2v_ctc_loss=6.711, task_loss=4.43, contrastive_loss=3.487, total=6706.37, n_correct=19.25, ppl=38.58, accuracy=0.287, wps=19542, ups=1.01, wpb=19433.6, bsz=675.8, num_updates=900, lr=3.6082e-05, gnorm=1.293, clip=0, loss_scale=16, train_wall=99, gb_free=17.6, wall=953
2023-08-30 15:34:42 | INFO | train_inner | epoch 001:   1003 / 1191 loss=9.313, trans_loss=6.29, nll_loss=5.219, w2v_ctc_loss=6.725, task_loss=4.595, contrastive_loss=3.417, total=6668.9, n_correct=25.92, ppl=37.24, accuracy=0.389, wps=20477.6, ups=1.06, wpb=19321.9, bsz=662.2, num_updates=1000, lr=4.008e-05, gnorm=1.381, clip=0, loss_scale=16, train_wall=94, gb_free=18.6, wall=1048
2023-08-30 15:36:15 | INFO | train_inner | epoch 001:   1103 / 1191 loss=9.228, trans_loss=6.28, nll_loss=5.199, w2v_ctc_loss=6.637, task_loss=4.576, contrastive_loss=3.347, total=6578.13, n_correct=33.18, ppl=36.72, accuracy=0.504, wps=20568.1, ups=1.08, wpb=19050.5, bsz=647.4, num_updates=1100, lr=4.4078e-05, gnorm=1.628, clip=0, loss_scale=16, train_wall=92, gb_free=17.6, wall=1140
2023-08-30 15:37:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
True False
None None None
True False
None None None
True False
None None None
True False
None None None
True False
None None None
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-08-30 15:38:23 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 13.249 | trans_loss 13.805 | nll_loss 13.501 | w2v_ctc_loss 9.308 | task_loss 28.032 | contrastive_loss 4.915 | total 6138.43 | n_correct 18.1429 | ppl 11592.9 | accuracy 0.296 | uer 91.656 | wer 98.899 | raw_wer 98.899 | bleu 0 | wps 1066.8 | wpb 6138.4 | bsz 201.1 | num_updates 1188
2023-08-30 15:38:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1188 updates
2023-08-30 15:38:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 15:38:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 15:38:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt (epoch 1 @ 1188 updates, score 0.0) (writing took 4.124467560999619 seconds)
2023-08-30 15:38:27 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-30 15:38:27 | INFO | train | epoch 001 | loss 10.853 | trans_loss 6.333 | nll_loss 5.247 | w2v_ctc_loss 8.942 | task_loss 4.748 | contrastive_loss 3.532 | total 6703.11 | n_correct 65.7332 | ppl 37.99 | accuracy 0.981 | wps 19257.9 | ups 0.99 | wpb 19420.9 | bsz 678 | num_updates 1188 | lr 4.75962e-05 | gnorm 1.609 | clip 0.3 | loss_scale 16 | train_wall 1110 | gb_free 18.5 | wall 1272
2023-08-30 15:38:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-30 15:38:27 | INFO | fairseq.trainer | begin training epoch 2
2023-08-30 15:38:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 15:38:42 | INFO | train_inner | epoch 002:     12 / 1191 loss=9.185, trans_loss=6.266, nll_loss=5.181, w2v_ctc_loss=6.597, task_loss=4.35, contrastive_loss=3.409, total=6631.26, n_correct=32.48, ppl=36.27, accuracy=0.49, wps=13046.7, ups=0.68, wpb=19218.6, bsz=679.5, num_updates=1200, lr=4.8076e-05, gnorm=1.423, clip=0, loss_scale=16, train_wall=78, gb_free=17.5, wall=1288
2023-08-30 15:39:50 | INFO | train_inner | epoch 002:    112 / 1191 loss=9.119, trans_loss=6.251, nll_loss=5.16, w2v_ctc_loss=6.595, task_loss=4.517, contrastive_loss=3.293, total=6617.43, n_correct=33.2, ppl=35.74, accuracy=0.502, wps=28411.6, ups=1.48, wpb=19164.1, bsz=662.2, num_updates=1300, lr=5.2074e-05, gnorm=1.739, clip=0, loss_scale=16, train_wall=67, gb_free=17.6, wall=1355
2023-08-30 15:40:57 | INFO | train_inner | epoch 002:    212 / 1191 loss=8.901, trans_loss=6.233, nll_loss=5.138, w2v_ctc_loss=6.298, task_loss=4.46, contrastive_loss=3.242, total=6716.9, n_correct=36.05, ppl=35.22, accuracy=0.537, wps=28940.1, ups=1.49, wpb=19456.2, bsz=672.8, num_updates=1400, lr=5.6072e-05, gnorm=1.742, clip=0, loss_scale=16, train_wall=67, gb_free=17.5, wall=1422
2023-08-30 15:42:04 | INFO | train_inner | epoch 002:    312 / 1191 loss=8.051, trans_loss=6.219, nll_loss=5.12, w2v_ctc_loss=5.014, task_loss=4.212, contrastive_loss=3.211, total=6776.25, n_correct=41.86, ppl=34.77, accuracy=0.618, wps=29273.7, ups=1.49, wpb=19634.6, bsz=690.8, num_updates=1500, lr=6.007e-05, gnorm=1.18, clip=0, loss_scale=16, train_wall=66, gb_free=18, wall=1489
2023-08-30 15:43:11 | INFO | train_inner | epoch 002:    412 / 1191 loss=7.75, trans_loss=6.204, nll_loss=5.1, w2v_ctc_loss=4.607, task_loss=4.301, contrastive_loss=3.21, total=6718.15, n_correct=43.13, ppl=34.3, accuracy=0.642, wps=29012.1, ups=1.49, wpb=19472.2, bsz=690.8, num_updates=1600, lr=6.4068e-05, gnorm=1.138, clip=0, loss_scale=16, train_wall=66, gb_free=17.8, wall=1556
2023-08-30 15:44:18 | INFO | train_inner | epoch 002:    512 / 1191 loss=7.467, trans_loss=6.17, nll_loss=5.058, w2v_ctc_loss=4.25, task_loss=4.467, contrastive_loss=3.181, total=6696.54, n_correct=47.92, ppl=33.31, accuracy=0.716, wps=29108.9, ups=1.5, wpb=19408.7, bsz=678.7, num_updates=1700, lr=6.8066e-05, gnorm=1.205, clip=0, loss_scale=16, train_wall=66, gb_free=18.1, wall=1623
2023-08-30 15:45:24 | INFO | train_inner | epoch 002:    612 / 1191 loss=7.227, trans_loss=6.168, nll_loss=5.052, w2v_ctc_loss=3.939, task_loss=4.539, contrastive_loss=3.097, total=6640.77, n_correct=49.95, ppl=33.18, accuracy=0.752, wps=28815, ups=1.5, wpb=19228.2, bsz=659.1, num_updates=1800, lr=7.2064e-05, gnorm=1.279, clip=0, loss_scale=16, train_wall=66, gb_free=17.8, wall=1690
2023-08-30 15:46:31 | INFO | train_inner | epoch 002:    712 / 1191 loss=7.082, trans_loss=6.171, nll_loss=5.057, w2v_ctc_loss=3.687, task_loss=4.198, contrastive_loss=3.115, total=6799.78, n_correct=53.45, ppl=33.29, accuracy=0.786, wps=29466.5, ups=1.5, wpb=19685.9, bsz=701.6, num_updates=1900, lr=7.6062e-05, gnorm=1.34, clip=0, loss_scale=16, train_wall=66, gb_free=17.9, wall=1757
2023-08-30 15:47:39 | INFO | train_inner | epoch 002:    812 / 1191 loss=6.941, trans_loss=6.171, nll_loss=5.054, w2v_ctc_loss=3.509, task_loss=4.283, contrastive_loss=2.998, total=6729.15, n_correct=54.57, ppl=33.22, accuracy=0.811, wps=28974.9, ups=1.49, wpb=19495.9, bsz=677.7, num_updates=2000, lr=8.006e-05, gnorm=1.473, clip=0, loss_scale=16, train_wall=67, gb_free=17.8, wall=1824
2023-08-30 15:47:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 15:48:22 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.752 | trans_loss 13.852 | nll_loss 13.481 | w2v_ctc_loss 4.51 | task_loss 28.03 | contrastive_loss 4.527 | total 6138.43 | n_correct 48.4286 | ppl 11430.2 | accuracy 0.789 | uer 64.301 | wer 61.74 | raw_wer 61.74 | bleu 0 | wps 1220.4 | wpb 6138.4 | bsz 201.1 | num_updates 2000 | best_bleu 0
2023-08-30 15:48:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-30 15:48:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_2_2000.pt
2023-08-30 15:48:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_2_2000.pt
2023-08-30 15:48:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 10.908611249000387 seconds)
2023-08-30 15:49:39 | INFO | train_inner | epoch 002:    912 / 1191 loss=6.811, trans_loss=6.168, nll_loss=5.054, w2v_ctc_loss=3.347, task_loss=4.214, contrastive_loss=3.062, total=6738.95, n_correct=59.1, ppl=33.23, accuracy=0.877, wps=16232.9, ups=0.83, wpb=19533.2, bsz=703.8, num_updates=2100, lr=8.4058e-05, gnorm=1.386, clip=0, loss_scale=16, train_wall=65, gb_free=17.9, wall=1944
2023-08-30 15:50:46 | INFO | train_inner | epoch 002:   1012 / 1191 loss=6.699, trans_loss=6.18, nll_loss=5.067, w2v_ctc_loss=3.237, task_loss=4.351, contrastive_loss=2.911, total=6774.79, n_correct=58.78, ppl=33.51, accuracy=0.868, wps=29365.3, ups=1.5, wpb=19640.8, bsz=687.3, num_updates=2200, lr=8.8056e-05, gnorm=1.407, clip=0, loss_scale=32, train_wall=66, gb_free=18.1, wall=2011
2023-08-30 15:51:52 | INFO | train_inner | epoch 002:   1112 / 1191 loss=6.581, trans_loss=6.178, nll_loss=5.064, w2v_ctc_loss=3.129, task_loss=4.565, contrastive_loss=2.809, total=6659.17, n_correct=58.83, ppl=33.46, accuracy=0.883, wps=29022.2, ups=1.5, wpb=19287, bsz=656.7, num_updates=2300, lr=9.2054e-05, gnorm=1.556, clip=0, loss_scale=32, train_wall=66, gb_free=18.4, wall=2078
2023-08-30 15:52:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 15:53:28 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.464 | trans_loss 13.866 | nll_loss 13.411 | w2v_ctc_loss 3.856 | task_loss 28.03 | contrastive_loss 4.094 | total 6138.43 | n_correct 65.7143 | ppl 10893.5 | accuracy 1.071 | uer 57.556 | wer 55.805 | raw_wer 55.805 | bleu 0 | wps 1217.1 | wpb 6138.4 | bsz 201.1 | num_updates 2379 | best_bleu 0
2023-08-30 15:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2379 updates
2023-08-30 15:53:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 15:53:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 15:53:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt (epoch 2 @ 2379 updates, score 0.0) (writing took 10.49688155900003 seconds)
2023-08-30 15:53:39 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-30 15:53:39 | INFO | train | epoch 002 | loss 7.461 | trans_loss 6.192 | nll_loss 5.084 | w2v_ctc_loss 4.265 | task_loss 4.388 | contrastive_loss 3.089 | total 6703.69 | n_correct 49.3157 | ppl 33.91 | accuracy 0.736 | wps 25365.6 | ups 1.31 | wpb 19422.7 | bsz 678.2 | num_updates 2379 | lr 9.52124e-05 | gnorm 1.425 | clip 0 | loss_scale 32 | train_wall 789 | gb_free 17.7 | wall 2184
2023-08-30 15:53:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-30 15:53:39 | INFO | fairseq.trainer | begin training epoch 3
2023-08-30 15:53:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 15:54:00 | INFO | train_inner | epoch 003:     21 / 1191 loss=6.504, trans_loss=6.174, nll_loss=5.063, w2v_ctc_loss=3.053, task_loss=4.66, contrastive_loss=2.825, total=6599.17, n_correct=59.38, ppl=33.44, accuracy=0.9, wps=14960, ups=0.78, wpb=19129.9, bsz=657.1, num_updates=2400, lr=9.6052e-05, gnorm=1.549, clip=0, loss_scale=32, train_wall=66, gb_free=18.1, wall=2205
2023-08-30 15:55:08 | INFO | train_inner | epoch 003:    121 / 1191 loss=6.425, trans_loss=6.155, nll_loss=5.044, w2v_ctc_loss=2.959, task_loss=4.338, contrastive_loss=2.799, total=6686.57, n_correct=60.78, ppl=32.98, accuracy=0.909, wps=28541.5, ups=1.47, wpb=19387.8, bsz=684.3, num_updates=2500, lr=0.00010005, gnorm=1.685, clip=0, loss_scale=32, train_wall=67, gb_free=18.7, wall=2273
2023-08-30 15:55:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-30 15:56:16 | INFO | train_inner | epoch 003:    222 / 1191 loss=6.329, trans_loss=6.159, nll_loss=5.047, w2v_ctc_loss=2.862, task_loss=4.237, contrastive_loss=2.726, total=6722.33, n_correct=63.83, ppl=33.07, accuracy=0.95, wps=28882, ups=1.48, wpb=19482.5, bsz=687.4, num_updates=2600, lr=0.000104048, gnorm=1.501, clip=0, loss_scale=16, train_wall=67, gb_free=17.7, wall=2341
2023-08-30 15:57:22 | INFO | train_inner | epoch 003:    322 / 1191 loss=6.238, trans_loss=6.159, nll_loss=5.047, w2v_ctc_loss=2.832, task_loss=5.013, contrastive_loss=2.549, total=6578.84, n_correct=62.69, ppl=33.07, accuracy=0.953, wps=28612.9, ups=1.5, wpb=19052.5, bsz=625.2, num_updates=2700, lr=0.000108046, gnorm=1.555, clip=0, loss_scale=16, train_wall=66, gb_free=18.5, wall=2407
2023-08-30 15:58:28 | INFO | train_inner | epoch 003:    422 / 1191 loss=6.197, trans_loss=6.155, nll_loss=5.046, w2v_ctc_loss=2.738, task_loss=4.292, contrastive_loss=2.678, total=6697.81, n_correct=66.84, ppl=33.03, accuracy=0.998, wps=29362, ups=1.51, wpb=19404.2, bsz=690.4, num_updates=2800, lr=0.000112044, gnorm=1.474, clip=0, loss_scale=16, train_wall=65, gb_free=18.9, wall=2474
2023-08-30 15:59:35 | INFO | train_inner | epoch 003:    522 / 1191 loss=6.155, trans_loss=6.158, nll_loss=5.053, w2v_ctc_loss=2.714, task_loss=4.371, contrastive_loss=2.518, total=6747.27, n_correct=67.81, ppl=33.19, accuracy=1.005, wps=29249.2, ups=1.5, wpb=19551.8, bsz=674.2, num_updates=2900, lr=0.000116042, gnorm=1.623, clip=0, loss_scale=16, train_wall=66, gb_free=18.2, wall=2540
2023-08-30 16:00:42 | INFO | train_inner | epoch 003:    622 / 1191 loss=6.095, trans_loss=6.148, nll_loss=5.038, w2v_ctc_loss=2.665, task_loss=4.443, contrastive_loss=2.478, total=6746.29, n_correct=70.34, ppl=32.86, accuracy=1.043, wps=29228.2, ups=1.49, wpb=19552.3, bsz=665.2, num_updates=3000, lr=0.00012004, gnorm=1.501, clip=0, loss_scale=16, train_wall=66, gb_free=18.6, wall=2607
2023-08-30 16:00:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-30 16:00:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-30 16:02:30 | INFO | train_inner | epoch 003:    724 / 1191 loss=5.487, trans_loss=5.401, nll_loss=4.126, w2v_ctc_loss=2.425, task_loss=3.04, contrastive_loss=2.671, total=6748.22, n_correct=263.54, ppl=17.46, accuracy=3.905, wps=18127.3, ups=0.93, wpb=19558, bsz=703.4, num_updates=3100, lr=0.000124038, gnorm=2.819, clip=2, loss_scale=4, train_wall=107, gb_free=14.3, wall=2715
2023-08-30 16:04:14 | INFO | train_inner | epoch 003:    824 / 1191 loss=4.917, trans_loss=5.149, nll_loss=3.803, w2v_ctc_loss=2.111, task_loss=2.903, contrastive_loss=2.265, total=6767.26, n_correct=511.41, ppl=13.96, accuracy=7.557, wps=18920.6, ups=0.96, wpb=19615.8, bsz=703.5, num_updates=3200, lr=0.000128036, gnorm=1.769, clip=0, loss_scale=4, train_wall=103, gb_free=13.5, wall=2819
2023-08-30 16:05:57 | INFO | train_inner | epoch 003:    924 / 1191 loss=4.412, trans_loss=4.627, nll_loss=3.101, w2v_ctc_loss=1.974, task_loss=2.805, contrastive_loss=2.161, total=6810.72, n_correct=1402.88, ppl=8.58, accuracy=20.598, wps=19116.6, ups=0.97, wpb=19727.4, bsz=717.9, num_updates=3300, lr=0.000132034, gnorm=1.922, clip=0, loss_scale=4, train_wall=102, gb_free=12.9, wall=2922
2023-08-30 16:06:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-30 16:07:43 | INFO | train_inner | epoch 003:   1025 / 1191 loss=3.929, trans_loss=4.143, nll_loss=2.468, w2v_ctc_loss=1.929, task_loss=3.609, contrastive_loss=1.913, total=6540.79, n_correct=2185.2, ppl=5.53, accuracy=33.409, wps=17818, ups=0.94, wpb=18956.7, bsz=616.2, num_updates=3400, lr=0.000136032, gnorm=1.806, clip=0, loss_scale=2, train_wall=106, gb_free=13.9, wall=3028
2023-08-30 16:09:29 | INFO | train_inner | epoch 003:   1125 / 1191 loss=3.789, trans_loss=4.06, nll_loss=2.36, w2v_ctc_loss=1.811, task_loss=2.949, contrastive_loss=1.929, total=6780.28, n_correct=2475.26, ppl=5.13, accuracy=36.507, wps=18598.2, ups=0.95, wpb=19627.7, bsz=710.5, num_updates=3500, lr=0.00014003, gnorm=1.546, clip=0, loss_scale=2, train_wall=104, gb_free=9.1, wall=3134
2023-08-30 16:10:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 16:11:13 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.894 | trans_loss 6.93 | nll_loss 4.73 | w2v_ctc_loss 2.086 | task_loss 15.249 | contrastive_loss 2.639 | total 6138.43 | n_correct 2383.57 | ppl 26.53 | accuracy 38.83 | uer 34.309 | wer 33.86 | raw_wer 33.86 | bleu 0.56 | wps 1491.1 | wpb 6138.4 | bsz 201.1 | num_updates 3566 | best_bleu 0.56
2023-08-30 16:11:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3566 updates
2023-08-30 16:11:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 16:11:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 16:11:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt (epoch 3 @ 3566 updates, score 0.56) (writing took 13.637442820001525 seconds)
2023-08-30 16:11:26 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-30 16:11:26 | INFO | train | epoch 003 | loss 5.373 | trans_loss 5.416 | nll_loss 4.107 | w2v_ctc_loss 2.427 | task_loss 3.774 | contrastive_loss 2.401 | total 6705.99 | n_correct 746.208 | ppl 17.24 | accuracy 11.127 | wps 21603.4 | ups 1.11 | wpb 19429.5 | bsz 679 | num_updates 3566 | lr 0.000142669 | gnorm 1.723 | clip 0.2 | loss_scale 2 | train_wall 1002 | gb_free 15 | wall 3252
2023-08-30 16:11:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-30 16:11:27 | INFO | fairseq.trainer | begin training epoch 4
2023-08-30 16:11:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 16:12:10 | INFO | train_inner | epoch 004:     34 / 1191 loss=3.657, trans_loss=4.036, nll_loss=2.33, w2v_ctc_loss=1.754, task_loss=3.277, contrastive_loss=1.734, total=6564.78, n_correct=2437.39, ppl=5.03, accuracy=37.128, wps=11795.3, ups=0.62, wpb=19000.8, bsz=644.2, num_updates=3600, lr=0.000144028, gnorm=1.5, clip=0, loss_scale=2, train_wall=104, gb_free=11.7, wall=3295
2023-08-30 16:13:55 | INFO | train_inner | epoch 004:    134 / 1191 loss=3.558, trans_loss=4.007, nll_loss=2.295, w2v_ctc_loss=1.682, task_loss=3.182, contrastive_loss=1.626, total=6736.4, n_correct=2555.86, ppl=4.91, accuracy=37.941, wps=18574.6, ups=0.95, wpb=19512.8, bsz=658, num_updates=3700, lr=0.000148026, gnorm=1.398, clip=0, loss_scale=2, train_wall=104, gb_free=11.5, wall=3400
2023-08-30 16:15:39 | INFO | train_inner | epoch 004:    234 / 1191 loss=3.512, trans_loss=3.996, nll_loss=2.282, w2v_ctc_loss=1.635, task_loss=3, contrastive_loss=1.727, total=6741.46, n_correct=2597.16, ppl=4.86, accuracy=38.525, wps=18783.5, ups=0.96, wpb=19536.2, bsz=701.1, num_updates=3800, lr=0.000152024, gnorm=1.415, clip=0, loss_scale=2, train_wall=103, gb_free=14.3, wall=3504
2023-08-30 16:17:22 | INFO | train_inner | epoch 004:    334 / 1191 loss=3.417, trans_loss=3.989, nll_loss=2.273, w2v_ctc_loss=1.597, task_loss=3.113, contrastive_loss=1.487, total=6665.94, n_correct=2587.87, ppl=4.83, accuracy=38.822, wps=18732.9, ups=0.97, wpb=19316.7, bsz=662.4, num_updates=3900, lr=0.000156022, gnorm=1.208, clip=0, loss_scale=2, train_wall=102, gb_free=12.8, wall=3607
2023-08-30 16:19:06 | INFO | train_inner | epoch 004:    434 / 1191 loss=3.392, trans_loss=3.976, nll_loss=2.256, w2v_ctc_loss=1.578, task_loss=3.125, contrastive_loss=1.581, total=6709.87, n_correct=2633.13, ppl=4.78, accuracy=39.243, wps=18607.3, ups=0.96, wpb=19443.9, bsz=683.5, num_updates=4000, lr=0.00016002, gnorm=1.294, clip=0, loss_scale=2, train_wall=104, gb_free=13.2, wall=3712
2023-08-30 16:19:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 16:19:40 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.6 | trans_loss 6.799 | nll_loss 4.568 | w2v_ctc_loss 1.813 | task_loss 15.472 | contrastive_loss 2.086 | total 6138.43 | n_correct 2507.29 | ppl 23.72 | accuracy 40.846 | uer 30.23 | wer 30.755 | raw_wer 30.755 | bleu 1.11 | wps 1646.7 | wpb 6138.4 | bsz 201.1 | num_updates 4000 | best_bleu 1.11
2023-08-30 16:19:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4000 updates
2023-08-30 16:19:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_4_4000.pt
2023-08-30 16:19:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_4_4000.pt
2023-08-30 16:19:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_4_4000.pt (epoch 4 @ 4000 updates, score 1.11) (writing took 12.719751198001177 seconds)
2023-08-30 16:21:38 | INFO | train_inner | epoch 004:    534 / 1191 loss=3.309, trans_loss=3.959, nll_loss=2.235, w2v_ctc_loss=1.537, task_loss=3.142, contrastive_loss=1.381, total=6689.54, n_correct=2655.14, ppl=4.71, accuracy=39.691, wps=12812.1, ups=0.66, wpb=19381.9, bsz=671.5, num_updates=4100, lr=0.000164018, gnorm=1.165, clip=0, loss_scale=2, train_wall=104, gb_free=13.7, wall=3863
2023-08-30 16:23:23 | INFO | train_inner | epoch 004:    634 / 1191 loss=3.278, trans_loss=3.95, nll_loss=2.224, w2v_ctc_loss=1.511, task_loss=2.984, contrastive_loss=1.43, total=6812.13, n_correct=2742.13, ppl=4.67, accuracy=40.254, wps=18735.6, ups=0.95, wpb=19744.8, bsz=706.1, num_updates=4200, lr=0.000168016, gnorm=1.143, clip=0, loss_scale=2, train_wall=105, gb_free=10.9, wall=3968
2023-08-30 16:25:06 | INFO | train_inner | epoch 004:    734 / 1191 loss=3.217, trans_loss=3.943, nll_loss=2.213, w2v_ctc_loss=1.477, task_loss=3.046, contrastive_loss=1.376, total=6701.57, n_correct=2728.14, ppl=4.64, accuracy=40.709, wps=18849.3, ups=0.97, wpb=19412.3, bsz=686.4, num_updates=4300, lr=0.000172014, gnorm=1.122, clip=0, loss_scale=2, train_wall=102, gb_free=13.6, wall=4071
2023-08-30 16:26:51 | INFO | train_inner | epoch 004:    834 / 1191 loss=3.17, trans_loss=3.934, nll_loss=2.201, w2v_ctc_loss=1.452, task_loss=2.895, contrastive_loss=1.327, total=6852.4, n_correct=2830.45, ppl=4.6, accuracy=41.306, wps=18861.2, ups=0.95, wpb=19846.6, bsz=720.7, num_updates=4400, lr=0.000176012, gnorm=1.044, clip=0, loss_scale=2, train_wall=104, gb_free=14.5, wall=4177
2023-08-30 16:28:36 | INFO | train_inner | epoch 004:    934 / 1191 loss=3.121, trans_loss=3.914, nll_loss=2.175, w2v_ctc_loss=1.436, task_loss=2.929, contrastive_loss=1.258, total=6741.87, n_correct=2843.55, ppl=4.52, accuracy=42.177, wps=18705.5, ups=0.96, wpb=19519.8, bsz=706.3, num_updates=4500, lr=0.00018001, gnorm=1.073, clip=0, loss_scale=2, train_wall=104, gb_free=13.9, wall=4281
2023-08-30 16:30:22 | INFO | train_inner | epoch 004:   1034 / 1191 loss=3.086, trans_loss=3.904, nll_loss=2.163, w2v_ctc_loss=1.444, task_loss=3.324, contrastive_loss=1.174, total=6629.56, n_correct=2825.98, ppl=4.48, accuracy=42.627, wps=18049.4, ups=0.94, wpb=19201.2, bsz=657.7, num_updates=4600, lr=0.000184008, gnorm=1.085, clip=0, loss_scale=2, train_wall=106, gb_free=14.2, wall=4387
2023-08-30 16:32:06 | INFO | train_inner | epoch 004:   1134 / 1191 loss=3.021, trans_loss=3.879, nll_loss=2.132, w2v_ctc_loss=1.426, task_loss=3.32, contrastive_loss=1.029, total=6577.33, n_correct=2869.13, ppl=4.38, accuracy=43.621, wps=18369.5, ups=0.96, wpb=19069.3, bsz=633.2, num_updates=4700, lr=0.000188006, gnorm=1.142, clip=0, loss_scale=2, train_wall=103, gb_free=12, wall=4491
2023-08-30 16:33:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 16:33:39 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 5.083 | trans_loss 6.35 | nll_loss 3.971 | w2v_ctc_loss 1.594 | task_loss 16.08 | contrastive_loss 1.414 | total 6138.43 | n_correct 2956.71 | ppl 15.68 | accuracy 48.167 | uer 26.08 | wer 26.835 | raw_wer 26.835 | bleu 6.39 | wps 1589.8 | wpb 6138.4 | bsz 201.1 | num_updates 4757 | best_bleu 6.39
2023-08-30 16:33:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4757 updates
2023-08-30 16:33:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 16:33:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 16:33:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt (epoch 4 @ 4757 updates, score 6.39) (writing took 11.380708341999707 seconds)
2023-08-30 16:33:51 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-30 16:33:51 | INFO | train | epoch 004 | loss 3.276 | trans_loss 3.948 | nll_loss 2.219 | w2v_ctc_loss 1.526 | task_loss 3.11 | contrastive_loss 1.391 | total 6703.69 | n_correct 2718.98 | ppl 4.66 | accuracy 40.559 | wps 17207.8 | ups 0.89 | wpb 19422.7 | bsz 678.2 | num_updates 4757 | lr 0.000190285 | gnorm 1.188 | clip 0 | loss_scale 2 | train_wall 1236 | gb_free 13.1 | wall 4596
2023-08-30 16:33:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-30 16:33:51 | INFO | fairseq.trainer | begin training epoch 5
2023-08-30 16:33:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 16:34:42 | INFO | train_inner | epoch 005:     43 / 1191 loss=2.966, trans_loss=3.834, nll_loss=2.073, w2v_ctc_loss=1.391, task_loss=2.914, contrastive_loss=1.097, total=6757.75, n_correct=3072.99, ppl=4.21, accuracy=45.474, wps=12533.1, ups=0.64, wpb=19584.7, bsz=709.8, num_updates=4800, lr=0.000192004, gnorm=1.066, clip=0, loss_scale=2, train_wall=103, gb_free=14.2, wall=4648
2023-08-30 16:36:27 | INFO | train_inner | epoch 005:    143 / 1191 loss=2.912, trans_loss=3.815, nll_loss=2.047, w2v_ctc_loss=1.371, task_loss=3.101, contrastive_loss=1.051, total=6724.83, n_correct=3127.14, ppl=4.13, accuracy=46.501, wps=18579.2, ups=0.95, wpb=19483, bsz=681.8, num_updates=4900, lr=0.000196002, gnorm=1.053, clip=0, loss_scale=2, train_wall=104, gb_free=13.1, wall=4752
2023-08-30 16:38:11 | INFO | train_inner | epoch 005:    243 / 1191 loss=2.86, trans_loss=3.782, nll_loss=2.003, w2v_ctc_loss=1.352, task_loss=2.842, contrastive_loss=1.007, total=6862.8, n_correct=3305.47, ppl=4.01, accuracy=48.165, wps=19043.3, ups=0.96, wpb=19880.1, bsz=727.9, num_updates=5000, lr=0.0002, gnorm=1.042, clip=0, loss_scale=2, train_wall=104, gb_free=11, wall=4857
mt_weight tensor(0.5000)
asr_weight tensor(0.5961, device='cuda:0')
2023-08-30 16:39:57 | INFO | train_inner | epoch 005:    343 / 1191 loss=2.829, trans_loss=3.762, nll_loss=1.978, w2v_ctc_loss=1.364, task_loss=3.236, contrastive_loss=0.961, total=6612.86, n_correct=3238.32, ppl=3.94, accuracy=48.97, wps=18217, ups=0.95, wpb=19159.2, bsz=660.7, num_updates=5100, lr=0.00019803, gnorm=0.947, clip=0, loss_scale=2, train_wall=105, gb_free=13, wall=4962
2023-08-30 16:41:41 | INFO | train_inner | epoch 005:    443 / 1191 loss=2.81, trans_loss=3.737, nll_loss=1.946, w2v_ctc_loss=1.368, task_loss=3.119, contrastive_loss=0.978, total=6682.75, n_correct=3340.74, ppl=3.85, accuracy=49.99, wps=18593.2, ups=0.96, wpb=19374.4, bsz=677.7, num_updates=5200, lr=0.000196116, gnorm=0.881, clip=0, loss_scale=2, train_wall=104, gb_free=13.3, wall=5066
2023-08-30 16:43:25 | INFO | train_inner | epoch 005:    543 / 1191 loss=2.767, trans_loss=3.715, nll_loss=1.916, w2v_ctc_loss=1.342, task_loss=3.131, contrastive_loss=0.985, total=6679.73, n_correct=3409.1, ppl=3.77, accuracy=51.036, wps=18516.6, ups=0.96, wpb=19347.8, bsz=678.8, num_updates=5300, lr=0.000194257, gnorm=0.822, clip=0, loss_scale=2, train_wall=104, gb_free=14, wall=5171
2023-08-30 16:45:09 | INFO | train_inner | epoch 005:    643 / 1191 loss=2.723, trans_loss=3.697, nll_loss=1.89, w2v_ctc_loss=1.337, task_loss=3.166, contrastive_loss=0.828, total=6696.14, n_correct=3490.82, ppl=3.71, accuracy=52.132, wps=18739.6, ups=0.97, wpb=19387.6, bsz=665.4, num_updates=5400, lr=0.00019245, gnorm=0.814, clip=0, loss_scale=4, train_wall=103, gb_free=13.5, wall=5274
2023-08-30 16:46:55 | INFO | train_inner | epoch 005:    743 / 1191 loss=2.697, trans_loss=3.667, nll_loss=1.854, w2v_ctc_loss=1.324, task_loss=3.082, contrastive_loss=0.91, total=6727.55, n_correct=3581, ppl=3.62, accuracy=53.229, wps=18398.2, ups=0.94, wpb=19498.5, bsz=687.8, num_updates=5500, lr=0.000190693, gnorm=0.734, clip=0, loss_scale=4, train_wall=105, gb_free=14, wall=5380
2023-08-30 16:48:39 | INFO | train_inner | epoch 005:    843 / 1191 loss=2.658, trans_loss=3.647, nll_loss=1.827, w2v_ctc_loss=1.312, task_loss=3.026, contrastive_loss=0.859, total=6763.54, n_correct=3662.84, ppl=3.55, accuracy=54.156, wps=18770.8, ups=0.96, wpb=19590.6, bsz=686.9, num_updates=5600, lr=0.000188982, gnorm=0.747, clip=0, loss_scale=4, train_wall=104, gb_free=13.7, wall=5484
2023-08-30 16:50:24 | INFO | train_inner | epoch 005:    943 / 1191 loss=2.63, trans_loss=3.636, nll_loss=1.815, w2v_ctc_loss=1.306, task_loss=3.276, contrastive_loss=0.822, total=6598.45, n_correct=3613.64, ppl=3.52, accuracy=54.765, wps=18180.2, ups=0.95, wpb=19124, bsz=655, num_updates=5700, lr=0.000187317, gnorm=0.682, clip=0, loss_scale=4, train_wall=104, gb_free=14.2, wall=5590
2023-08-30 16:52:09 | INFO | train_inner | epoch 005:   1043 / 1191 loss=2.598, trans_loss=3.623, nll_loss=1.796, w2v_ctc_loss=1.292, task_loss=3.298, contrastive_loss=0.774, total=6643.21, n_correct=3676.83, ppl=3.47, accuracy=55.347, wps=18379.4, ups=0.96, wpb=19245.1, bsz=648.6, num_updates=5800, lr=0.000185695, gnorm=0.661, clip=0, loss_scale=4, train_wall=104, gb_free=14.5, wall=5694
2023-08-30 16:53:53 | INFO | train_inner | epoch 005:   1143 / 1191 loss=2.594, trans_loss=3.609, nll_loss=1.779, w2v_ctc_loss=1.293, task_loss=3.168, contrastive_loss=0.8, total=6704.92, n_correct=3749.33, ppl=3.43, accuracy=55.919, wps=18766, ups=0.97, wpb=19427.4, bsz=670.9, num_updates=5900, lr=0.000184115, gnorm=0.678, clip=0, loss_scale=4, train_wall=103, gb_free=13.7, wall=5798
2023-08-30 16:54:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5961, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.5961, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5961, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5961, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5961, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5961, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5961, device='cuda:1')
2023-08-30 16:55:15 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.39 | trans_loss 5.541 | nll_loss 2.915 | w2v_ctc_loss 1.426 | task_loss 16.445 | contrastive_loss 1.002 | total 6138.43 | n_correct 3738.43 | ppl 7.54 | accuracy 60.902 | uer 22.98 | wer 23.931 | raw_wer 23.931 | bleu 19.07 | wps 1710.9 | wpb 6138.4 | bsz 201.1 | num_updates 5948 | best_bleu 19.07
2023-08-30 16:55:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5948 updates
2023-08-30 16:55:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 16:55:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 16:55:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt (epoch 5 @ 5948 updates, score 19.07) (writing took 15.294464668000728 seconds)
2023-08-30 16:55:31 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-30 16:55:31 | INFO | train | epoch 005 | loss 2.735 | trans_loss 3.699 | nll_loss 1.896 | w2v_ctc_loss 1.331 | task_loss 3.113 | contrastive_loss 0.913 | total 6703.69 | n_correct 3472.81 | ppl 3.72 | accuracy 51.804 | wps 17797.4 | ups 0.92 | wpb 19422.7 | bsz 678.2 | num_updates 5948 | lr 0.000183371 | gnorm 0.828 | clip 0 | loss_scale 4 | train_wall 1236 | gb_free 11.1 | wall 5896
2023-08-30 16:55:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-30 16:55:31 | INFO | fairseq.trainer | begin training epoch 6
2023-08-30 16:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 16:56:31 | INFO | train_inner | epoch 006:     52 / 1191 loss=2.535, trans_loss=3.578, nll_loss=1.74, w2v_ctc_loss=1.242, task_loss=3.149, contrastive_loss=0.807, total=6663.58, n_correct=3797.88, ppl=3.34, accuracy=56.995, wps=12192.1, ups=0.63, wpb=19308.8, bsz=664.4, num_updates=6000, lr=0.000182574, gnorm=0.638, clip=0, loss_scale=4, train_wall=102, gb_free=11.8, wall=5956
2023-08-30 16:56:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 16:57:05 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.376 | trans_loss 5.521 | nll_loss 2.894 | w2v_ctc_loss 1.44 | task_loss 16.474 | contrastive_loss 0.976 | total 6138.43 | n_correct 3757.29 | ppl 7.44 | accuracy 61.209 | uer 23.034 | wer 24.321 | raw_wer 24.321 | bleu 18.85 | wps 1565.2 | wpb 6138.4 | bsz 201.1 | num_updates 6000 | best_bleu 19.07
2023-08-30 16:57:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6000 updates
2023-08-30 16:57:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_6_6000.pt
2023-08-30 16:57:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_6_6000.pt
2023-08-30 16:57:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_6_6000.pt (epoch 6 @ 6000 updates, score 18.85) (writing took 7.776327200999731 seconds)
2023-08-30 16:58:58 | INFO | train_inner | epoch 006:    152 / 1191 loss=2.495, trans_loss=3.571, nll_loss=1.728, w2v_ctc_loss=1.221, task_loss=3.167, contrastive_loss=0.74, total=6710.71, n_correct=3857.22, ppl=3.31, accuracy=57.479, wps=13212.9, ups=0.68, wpb=19428.5, bsz=674.5, num_updates=6100, lr=0.000181071, gnorm=0.623, clip=0, loss_scale=4, train_wall=104, gb_free=13.2, wall=6103
2023-08-30 17:00:43 | INFO | train_inner | epoch 006:    252 / 1191 loss=2.493, trans_loss=3.552, nll_loss=1.707, w2v_ctc_loss=1.215, task_loss=2.894, contrastive_loss=0.801, total=6837.1, n_correct=3971.79, ppl=3.26, accuracy=58.092, wps=18904.3, ups=0.95, wpb=19809.8, bsz=717.6, num_updates=6200, lr=0.000179605, gnorm=0.628, clip=0, loss_scale=4, train_wall=104, gb_free=13.5, wall=6208
2023-08-30 17:02:29 | INFO | train_inner | epoch 006:    352 / 1191 loss=2.471, trans_loss=3.552, nll_loss=1.705, w2v_ctc_loss=1.218, task_loss=3.138, contrastive_loss=0.691, total=6732.22, n_correct=3924.27, ppl=3.26, accuracy=58.291, wps=18414.2, ups=0.94, wpb=19495.9, bsz=678.5, num_updates=6300, lr=0.000178174, gnorm=0.62, clip=0, loss_scale=4, train_wall=105, gb_free=12.4, wall=6314
2023-08-30 17:04:12 | INFO | train_inner | epoch 006:    452 / 1191 loss=2.47, trans_loss=3.547, nll_loss=1.7, w2v_ctc_loss=1.227, task_loss=3.294, contrastive_loss=0.728, total=6555.97, n_correct=3828.52, ppl=3.25, accuracy=58.397, wps=18376.2, ups=0.97, wpb=18999.7, bsz=643.9, num_updates=6400, lr=0.000176777, gnorm=0.63, clip=0, loss_scale=4, train_wall=103, gb_free=11.9, wall=6417
2023-08-30 17:05:57 | INFO | train_inner | epoch 006:    552 / 1191 loss=2.439, trans_loss=3.532, nll_loss=1.682, w2v_ctc_loss=1.203, task_loss=3.167, contrastive_loss=0.666, total=6707.81, n_correct=3957.61, ppl=3.21, accuracy=59, wps=18515, ups=0.95, wpb=19445.6, bsz=669.8, num_updates=6500, lr=0.000175412, gnorm=0.622, clip=0, loss_scale=4, train_wall=104, gb_free=13.6, wall=6522
2023-08-30 17:07:42 | INFO | train_inner | epoch 006:    652 / 1191 loss=2.423, trans_loss=3.531, nll_loss=1.679, w2v_ctc_loss=1.19, task_loss=3.299, contrastive_loss=0.696, total=6667.25, n_correct=3950.78, ppl=3.2, accuracy=59.257, wps=18346.2, ups=0.95, wpb=19310.6, bsz=652.9, num_updates=6600, lr=0.000174078, gnorm=0.597, clip=0, loss_scale=4, train_wall=105, gb_free=14, wall=6628
2023-08-30 17:09:27 | INFO | train_inner | epoch 006:    752 / 1191 loss=2.433, trans_loss=3.517, nll_loss=1.662, w2v_ctc_loss=1.189, task_loss=2.9, contrastive_loss=0.787, total=6842.62, n_correct=4090.13, ppl=3.16, accuracy=59.774, wps=18894.1, ups=0.95, wpb=19824, bsz=722.5, num_updates=6700, lr=0.000172774, gnorm=0.584, clip=0, loss_scale=4, train_wall=104, gb_free=14.2, wall=6733
2023-08-30 17:11:12 | INFO | train_inner | epoch 006:    852 / 1191 loss=2.422, trans_loss=3.512, nll_loss=1.659, w2v_ctc_loss=1.194, task_loss=3.185, contrastive_loss=0.749, total=6631.09, n_correct=3965.15, ppl=3.16, accuracy=59.796, wps=18368.4, ups=0.96, wpb=19229.5, bsz=681.3, num_updates=6800, lr=0.000171499, gnorm=0.588, clip=0, loss_scale=4, train_wall=104, gb_free=13.1, wall=6837
2023-08-30 17:12:57 | INFO | train_inner | epoch 006:    952 / 1191 loss=2.409, trans_loss=3.518, nll_loss=1.663, w2v_ctc_loss=1.197, task_loss=3.46, contrastive_loss=0.664, total=6626, n_correct=3960.44, ppl=3.17, accuracy=59.771, wps=18237.8, ups=0.95, wpb=19192.3, bsz=634.2, num_updates=6900, lr=0.000170251, gnorm=0.592, clip=0, loss_scale=4, train_wall=104, gb_free=10.6, wall=6943
2023-08-30 17:14:42 | INFO | train_inner | epoch 006:   1052 / 1191 loss=2.381, trans_loss=3.5, nll_loss=1.642, w2v_ctc_loss=1.163, task_loss=3.146, contrastive_loss=0.722, total=6673.87, n_correct=4030.56, ppl=3.12, accuracy=60.393, wps=18530.2, ups=0.96, wpb=19342.2, bsz=669.1, num_updates=7000, lr=0.000169031, gnorm=0.583, clip=0, loss_scale=4, train_wall=104, gb_free=14.2, wall=7047
2023-08-30 17:16:25 | INFO | train_inner | epoch 006:   1152 / 1191 loss=2.354, trans_loss=3.49, nll_loss=1.629, w2v_ctc_loss=1.155, task_loss=2.857, contrastive_loss=0.608, total=6762.05, n_correct=4117.52, ppl=3.09, accuracy=60.892, wps=18913.1, ups=0.97, wpb=19598.4, bsz=712.9, num_updates=7100, lr=0.000167836, gnorm=0.565, clip=0, loss_scale=4, train_wall=103, gb_free=12.4, wall=7151
2023-08-30 17:17:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 17:17:39 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.17 | trans_loss 5.313 | nll_loss 2.634 | w2v_ctc_loss 1.329 | task_loss 16.804 | contrastive_loss 0.837 | total 6138.43 | n_correct 3957 | ppl 6.21 | accuracy 64.463 | uer 22.106 | wer 23.455 | raw_wer 23.455 | bleu 22.48 | wps 1667.2 | wpb 6138.4 | bsz 201.1 | num_updates 7139 | best_bleu 22.48
2023-08-30 17:17:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 7139 updates
2023-08-30 17:17:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 17:17:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 17:17:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt (epoch 6 @ 7139 updates, score 22.48) (writing took 12.968165480000607 seconds)
2023-08-30 17:17:52 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-30 17:17:52 | INFO | train | epoch 006 | loss 2.436 | trans_loss 3.53 | nll_loss 1.678 | w2v_ctc_loss 1.197 | task_loss 3.121 | contrastive_loss 0.716 | total 6703.69 | n_correct 3966.72 | ppl 3.2 | accuracy 59.172 | wps 17241.3 | ups 0.89 | wpb 19422.7 | bsz 678.2 | num_updates 7139 | lr 0.000167377 | gnorm 0.603 | clip 0 | loss_scale 4 | train_wall 1237 | gb_free 13.5 | wall 7238
2023-08-30 17:17:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-30 17:17:52 | INFO | fairseq.trainer | begin training epoch 7
2023-08-30 17:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 17:19:03 | INFO | train_inner | epoch 007:     61 / 1191 loss=2.347, trans_loss=3.485, nll_loss=1.62, w2v_ctc_loss=1.14, task_loss=3.011, contrastive_loss=0.701, total=6728.8, n_correct=4106.7, ppl=3.07, accuracy=61.032, wps=12360.6, ups=0.63, wpb=19481.1, bsz=693.5, num_updates=7200, lr=0.000166667, gnorm=0.557, clip=0, loss_scale=4, train_wall=103, gb_free=12.3, wall=7308
2023-08-30 17:20:48 | INFO | train_inner | epoch 007:    161 / 1191 loss=2.319, trans_loss=3.469, nll_loss=1.604, w2v_ctc_loss=1.124, task_loss=3.232, contrastive_loss=0.673, total=6657.18, n_correct=4085.72, ppl=3.04, accuracy=61.373, wps=18339.2, ups=0.95, wpb=19310.2, bsz=668.2, num_updates=7300, lr=0.000165521, gnorm=0.558, clip=0, loss_scale=4, train_wall=105, gb_free=13.2, wall=7413
2023-08-30 17:22:32 | INFO | train_inner | epoch 007:    261 / 1191 loss=2.305, trans_loss=3.464, nll_loss=1.596, w2v_ctc_loss=1.124, task_loss=3.107, contrastive_loss=0.586, total=6692.05, n_correct=4131.45, ppl=3.02, accuracy=61.737, wps=18655.1, ups=0.96, wpb=19388.9, bsz=676.3, num_updates=7400, lr=0.000164399, gnorm=0.544, clip=0, loss_scale=8, train_wall=103, gb_free=14.6, wall=7517
2023-08-30 17:24:14 | INFO | train_inner | epoch 007:    361 / 1191 loss=2.272, trans_loss=3.451, nll_loss=1.579, w2v_ctc_loss=1.098, task_loss=2.998, contrastive_loss=0.56, total=6739.19, n_correct=4200.79, ppl=2.99, accuracy=62.334, wps=19114.8, ups=0.98, wpb=19532.5, bsz=691.6, num_updates=7500, lr=0.000163299, gnorm=0.541, clip=0, loss_scale=8, train_wall=102, gb_free=14, wall=7620
2023-08-30 17:25:57 | INFO | train_inner | epoch 007:    461 / 1191 loss=2.287, trans_loss=3.458, nll_loss=1.588, w2v_ctc_loss=1.103, task_loss=2.916, contrastive_loss=0.647, total=6791.88, n_correct=4216.01, ppl=3.01, accuracy=62.074, wps=19078.1, ups=0.97, wpb=19680.7, bsz=711.2, num_updates=7600, lr=0.000162221, gnorm=0.544, clip=0, loss_scale=8, train_wall=103, gb_free=12.5, wall=7723
2023-08-30 17:27:43 | INFO | train_inner | epoch 007:    561 / 1191 loss=2.279, trans_loss=3.454, nll_loss=1.583, w2v_ctc_loss=1.112, task_loss=3.209, contrastive_loss=0.573, total=6695.38, n_correct=4172.46, ppl=3, accuracy=62.318, wps=18420, ups=0.95, wpb=19395.2, bsz=669.3, num_updates=7700, lr=0.000161165, gnorm=0.559, clip=0, loss_scale=8, train_wall=105, gb_free=14.1, wall=7828
2023-08-30 17:29:28 | INFO | train_inner | epoch 007:    661 / 1191 loss=2.277, trans_loss=3.454, nll_loss=1.583, w2v_ctc_loss=1.098, task_loss=3.064, contrastive_loss=0.647, total=6755.96, n_correct=4203.81, ppl=3, accuracy=62.224, wps=18600.8, ups=0.95, wpb=19573.7, bsz=691.6, num_updates=7800, lr=0.000160128, gnorm=0.542, clip=0, loss_scale=8, train_wall=104, gb_free=12.9, wall=7933
2023-08-30 17:31:12 | INFO | train_inner | epoch 007:    761 / 1191 loss=2.251, trans_loss=3.445, nll_loss=1.571, w2v_ctc_loss=1.096, task_loss=3.181, contrastive_loss=0.543, total=6684.34, n_correct=4187.84, ppl=2.97, accuracy=62.652, wps=18557.4, ups=0.96, wpb=19359, bsz=672.8, num_updates=7900, lr=0.000159111, gnorm=0.525, clip=0, loss_scale=8, train_wall=104, gb_free=13.6, wall=8038
2023-08-30 17:32:57 | INFO | train_inner | epoch 007:    861 / 1191 loss=2.255, trans_loss=3.445, nll_loss=1.571, w2v_ctc_loss=1.088, task_loss=3.244, contrastive_loss=0.642, total=6664.42, n_correct=4174.34, ppl=2.97, accuracy=62.636, wps=18503.9, ups=0.96, wpb=19300.9, bsz=658.9, num_updates=8000, lr=0.000158114, gnorm=0.545, clip=0, loss_scale=8, train_wall=104, gb_free=12.8, wall=8142
2023-08-30 17:32:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 17:33:29 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.081 | trans_loss 5.201 | nll_loss 2.492 | w2v_ctc_loss 1.35 | task_loss 16.754 | contrastive_loss 0.751 | total 6138.43 | n_correct 4059.43 | ppl 5.63 | accuracy 66.131 | uer 21.196 | wer 22.64 | raw_wer 22.64 | bleu 24.07 | wps 1727.8 | wpb 6138.4 | bsz 201.1 | num_updates 8000 | best_bleu 24.07
2023-08-30 17:33:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8000 updates
2023-08-30 17:33:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_7_8000.pt
2023-08-30 17:33:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_7_8000.pt
2023-08-30 17:33:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_7_8000.pt (epoch 7 @ 8000 updates, score 24.07) (writing took 13.112648940999861 seconds)
2023-08-30 17:35:28 | INFO | train_inner | epoch 007:    961 / 1191 loss=2.232, trans_loss=3.434, nll_loss=1.558, w2v_ctc_loss=1.09, task_loss=3.353, contrastive_loss=0.528, total=6616.88, n_correct=4167.53, ppl=2.94, accuracy=62.983, wps=12695.9, ups=0.66, wpb=19171.8, bsz=639.8, num_updates=8100, lr=0.000157135, gnorm=0.527, clip=0, loss_scale=8, train_wall=104, gb_free=11, wall=8293
2023-08-30 17:37:13 | INFO | train_inner | epoch 007:   1061 / 1191 loss=2.247, trans_loss=3.431, nll_loss=1.552, w2v_ctc_loss=1.089, task_loss=3.044, contrastive_loss=0.646, total=6683.03, n_correct=4223.13, ppl=2.93, accuracy=63.192, wps=18378.1, ups=0.95, wpb=19348.3, bsz=694.2, num_updates=8200, lr=0.000156174, gnorm=0.526, clip=0, loss_scale=8, train_wall=105, gb_free=13.5, wall=8398
2023-08-30 17:38:58 | INFO | train_inner | epoch 007:   1161 / 1191 loss=2.237, trans_loss=3.431, nll_loss=1.556, w2v_ctc_loss=1.086, task_loss=3.145, contrastive_loss=0.611, total=6730.91, n_correct=4246.67, ppl=2.94, accuracy=63.092, wps=18643.7, ups=0.96, wpb=19511.5, bsz=682.6, num_updates=8300, lr=0.00015523, gnorm=0.517, clip=0, loss_scale=8, train_wall=104, gb_free=13.2, wall=8503
2023-08-30 17:39:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 17:40:01 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.038 | trans_loss 5.176 | nll_loss 2.465 | w2v_ctc_loss 1.287 | task_loss 16.63 | contrastive_loss 0.717 | total 6138.43 | n_correct 4081.71 | ppl 5.52 | accuracy 66.494 | uer 21.047 | wer 22.462 | raw_wer 22.462 | bleu 24.52 | wps 1763.7 | wpb 6138.4 | bsz 201.1 | num_updates 8330 | best_bleu 24.52
2023-08-30 17:40:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 8330 updates
2023-08-30 17:40:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 17:40:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 17:40:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt (epoch 7 @ 8330 updates, score 24.52) (writing took 12.556328968999878 seconds)
2023-08-30 17:40:14 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-30 17:40:14 | INFO | train | epoch 007 | loss 2.272 | trans_loss 3.45 | nll_loss 1.578 | w2v_ctc_loss 1.102 | task_loss 3.129 | contrastive_loss 0.611 | total 6703.69 | n_correct 4181.74 | ppl 2.98 | accuracy 62.38 | wps 17241.3 | ups 0.89 | wpb 19422.7 | bsz 678.2 | num_updates 8330 | lr 0.00015495 | gnorm 0.539 | clip 0 | loss_scale 8 | train_wall 1235 | gb_free 12.7 | wall 8579
2023-08-30 17:40:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-30 17:40:14 | INFO | fairseq.trainer | begin training epoch 8
2023-08-30 17:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 17:41:34 | INFO | train_inner | epoch 008:     70 / 1191 loss=2.187, trans_loss=3.413, nll_loss=1.53, w2v_ctc_loss=1.052, task_loss=3.139, contrastive_loss=0.492, total=6730.54, n_correct=4297.92, ppl=2.89, accuracy=63.857, wps=12422.4, ups=0.64, wpb=19489.8, bsz=668, num_updates=8400, lr=0.000154303, gnorm=0.514, clip=0, loss_scale=8, train_wall=104, gb_free=12.7, wall=8660
2023-08-30 17:43:19 | INFO | train_inner | epoch 008:    170 / 1191 loss=2.191, trans_loss=3.402, nll_loss=1.52, w2v_ctc_loss=1.039, task_loss=2.999, contrastive_loss=0.638, total=6744.24, n_correct=4318, ppl=2.87, accuracy=64.025, wps=18712.9, ups=0.96, wpb=19557.6, bsz=714.2, num_updates=8500, lr=0.000153393, gnorm=0.511, clip=0, loss_scale=8, train_wall=104, gb_free=14.3, wall=8764
2023-08-30 17:45:05 | INFO | train_inner | epoch 008:    270 / 1191 loss=2.179, trans_loss=3.405, nll_loss=1.521, w2v_ctc_loss=1.044, task_loss=3.103, contrastive_loss=0.555, total=6744.09, n_correct=4322.19, ppl=2.87, accuracy=64.089, wps=18508.4, ups=0.95, wpb=19538.4, bsz=691.2, num_updates=8600, lr=0.000152499, gnorm=0.503, clip=0, loss_scale=8, train_wall=105, gb_free=14.1, wall=8870
2023-08-30 17:46:51 | INFO | train_inner | epoch 008:    370 / 1191 loss=2.167, trans_loss=3.409, nll_loss=1.527, w2v_ctc_loss=1.052, task_loss=3.401, contrastive_loss=0.467, total=6638.8, n_correct=4242.32, ppl=2.88, accuracy=63.902, wps=18037.4, ups=0.94, wpb=19244.1, bsz=639.1, num_updates=8700, lr=0.00015162, gnorm=0.512, clip=0, loss_scale=8, train_wall=106, gb_free=14, wall=8977
2023-08-30 17:48:36 | INFO | train_inner | epoch 008:    470 / 1191 loss=2.169, trans_loss=3.4, nll_loss=1.516, w2v_ctc_loss=1.044, task_loss=3.181, contrastive_loss=0.535, total=6672.44, n_correct=4285.85, ppl=2.86, accuracy=64.232, wps=18453.5, ups=0.95, wpb=19339.8, bsz=667.9, num_updates=8800, lr=0.000150756, gnorm=0.505, clip=0, loss_scale=8, train_wall=104, gb_free=11.9, wall=9081
2023-08-30 17:50:20 | INFO | train_inner | epoch 008:    570 / 1191 loss=2.147, trans_loss=3.397, nll_loss=1.511, w2v_ctc_loss=1.026, task_loss=3.23, contrastive_loss=0.53, total=6676.91, n_correct=4295.55, ppl=2.85, accuracy=64.334, wps=18565.7, ups=0.96, wpb=19346.2, bsz=671.5, num_updates=8900, lr=0.000149906, gnorm=0.5, clip=0, loss_scale=8, train_wall=104, gb_free=13.6, wall=9186
2023-08-30 17:52:03 | INFO | train_inner | epoch 008:    670 / 1191 loss=2.143, trans_loss=3.398, nll_loss=1.512, w2v_ctc_loss=1.031, task_loss=3.08, contrastive_loss=0.462, total=6735.41, n_correct=4342.76, ppl=2.85, accuracy=64.477, wps=18913.8, ups=0.97, wpb=19514.6, bsz=679.1, num_updates=9000, lr=0.000149071, gnorm=0.499, clip=0, loss_scale=8, train_wall=102, gb_free=14.4, wall=9289
2023-08-30 17:53:48 | INFO | train_inner | epoch 008:    770 / 1191 loss=2.152, trans_loss=3.395, nll_loss=1.51, w2v_ctc_loss=1.038, task_loss=3.217, contrastive_loss=0.537, total=6676.21, n_correct=4302.2, ppl=2.85, accuracy=64.441, wps=18555.4, ups=0.96, wpb=19347.4, bsz=667.7, num_updates=9100, lr=0.00014825, gnorm=0.509, clip=0, loss_scale=8, train_wall=104, gb_free=11.5, wall=9393
2023-08-30 17:55:32 | INFO | train_inner | epoch 008:    870 / 1191 loss=2.143, trans_loss=3.386, nll_loss=1.498, w2v_ctc_loss=1.036, task_loss=2.919, contrastive_loss=0.486, total=6793.29, n_correct=4409.52, ppl=2.82, accuracy=64.91, wps=18885.1, ups=0.96, wpb=19684.1, bsz=704.6, num_updates=9200, lr=0.000147442, gnorm=0.497, clip=0, loss_scale=8, train_wall=104, gb_free=12, wall=9497
2023-08-30 17:57:17 | INFO | train_inner | epoch 008:    970 / 1191 loss=2.148, trans_loss=3.396, nll_loss=1.509, w2v_ctc_loss=1.03, task_loss=3.231, contrastive_loss=0.566, total=6661.73, n_correct=4295.05, ppl=2.85, accuracy=64.473, wps=18428.3, ups=0.96, wpb=19290.2, bsz=660.9, num_updates=9300, lr=0.000146647, gnorm=0.499, clip=0, loss_scale=8, train_wall=104, gb_free=13.5, wall=9602
2023-08-30 17:59:00 | INFO | train_inner | epoch 008:   1070 / 1191 loss=2.123, trans_loss=3.387, nll_loss=1.495, w2v_ctc_loss=1.028, task_loss=3.213, contrastive_loss=0.432, total=6683.31, n_correct=4337.49, ppl=2.82, accuracy=64.9, wps=18638.5, ups=0.96, wpb=19336.8, bsz=662.3, num_updates=9400, lr=0.000145865, gnorm=0.495, clip=0, loss_scale=8, train_wall=103, gb_free=14, wall=9706
2023-08-30 18:00:44 | INFO | train_inner | epoch 008:   1170 / 1191 loss=2.139, trans_loss=3.376, nll_loss=1.487, w2v_ctc_loss=1.013, task_loss=2.886, contrastive_loss=0.625, total=6727.93, n_correct=4381.78, ppl=2.8, accuracy=65.128, wps=18799.1, ups=0.96, wpb=19499.6, bsz=718.4, num_updates=9500, lr=0.000145095, gnorm=0.511, clip=0, loss_scale=16, train_wall=103, gb_free=12, wall=9809
2023-08-30 18:01:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 18:01:38 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 3.959 | trans_loss 5.089 | nll_loss 2.364 | w2v_ctc_loss 1.281 | task_loss 16.783 | contrastive_loss 0.639 | total 6138.43 | n_correct 4157 | ppl 5.15 | accuracy 67.721 | uer 19.592 | wer 21.16 | raw_wer 21.16 | bleu 25.95 | wps 1749.6 | wpb 6138.4 | bsz 201.1 | num_updates 9521 | best_bleu 25.95
2023-08-30 18:01:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 9521 updates
2023-08-30 18:01:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 18:01:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt
2023-08-30 18:01:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_best.pt (epoch 8 @ 9521 updates, score 25.95) (writing took 10.640450244998647 seconds)
2023-08-30 18:01:49 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-30 18:01:49 | INFO | train | epoch 008 | loss 2.156 | trans_loss 3.396 | nll_loss 1.51 | w2v_ctc_loss 1.035 | task_loss 3.132 | contrastive_loss 0.531 | total 6703.69 | n_correct 4319.49 | ppl 2.85 | accuracy 64.434 | wps 17864.8 | ups 0.92 | wpb 19422.7 | bsz 678.2 | num_updates 9521 | lr 0.000144935 | gnorm 0.504 | clip 0 | loss_scale 16 | train_wall 1236 | gb_free 14 | wall 9874
2023-08-30 18:01:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1191
2023-08-30 18:01:49 | INFO | fairseq.trainer | begin training epoch 9
2023-08-30 18:01:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-30 18:03:18 | INFO | train_inner | epoch 009:     79 / 1191 loss=2.094, trans_loss=3.364, nll_loss=1.469, w2v_ctc_loss=0.989, task_loss=3.141, contrastive_loss=0.518, total=6681.43, n_correct=4375.28, ppl=2.77, accuracy=65.484, wps=12607.6, ups=0.65, wpb=19356.2, bsz=676, num_updates=9600, lr=0.000144338, gnorm=0.489, clip=0, loss_scale=16, train_wall=102, gb_free=11.6, wall=9963
2023-08-30 18:05:03 | INFO | train_inner | epoch 009:    179 / 1191 loss=2.078, trans_loss=3.354, nll_loss=1.459, w2v_ctc_loss=0.98, task_loss=3.064, contrastive_loss=0.495, total=6757.86, n_correct=4443.79, ppl=2.75, accuracy=65.757, wps=18610.9, ups=0.95, wpb=19588.1, bsz=692.6, num_updates=9700, lr=0.000143592, gnorm=0.481, clip=0, loss_scale=16, train_wall=105, gb_free=14.5, wall=10068
2023-08-30 18:06:46 | INFO | train_inner | epoch 009:    279 / 1191 loss=2.089, trans_loss=3.366, nll_loss=1.471, w2v_ctc_loss=1.001, task_loss=2.983, contrastive_loss=0.44, total=6797.76, n_correct=4459.37, ppl=2.77, accuracy=65.601, wps=19039.5, ups=0.97, wpb=19677.4, bsz=701.1, num_updates=9800, lr=0.000142857, gnorm=0.486, clip=0, loss_scale=16, train_wall=103, gb_free=9.4, wall=10172
2023-08-30 18:08:32 | INFO | train_inner | epoch 009:    379 / 1191 loss=2.081, trans_loss=3.361, nll_loss=1.466, w2v_ctc_loss=0.984, task_loss=3.073, contrastive_loss=0.492, total=6775.76, n_correct=4451.65, ppl=2.76, accuracy=65.7, wps=18491.4, ups=0.94, wpb=19634.3, bsz=694.7, num_updates=9900, lr=0.000142134, gnorm=0.48, clip=0, loss_scale=16, train_wall=106, gb_free=12.9, wall=10278
2023-08-30 18:10:18 | INFO | train_inner | epoch 009:    479 / 1191 loss=2.091, trans_loss=3.359, nll_loss=1.466, w2v_ctc_loss=0.999, task_loss=3.122, contrastive_loss=0.48, total=6696.55, n_correct=4407.24, ppl=2.76, accuracy=65.814, wps=18423.4, ups=0.95, wpb=19408.4, bsz=685.4, num_updates=10000, lr=0.000141421, gnorm=0.485, clip=0, loss_scale=16, train_wall=105, gb_free=13.9, wall=10383
2023-08-30 18:10:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-30 18:10:50 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.927 | trans_loss 5.064 | nll_loss 2.334 | w2v_ctc_loss 1.249 | task_loss 16.836 | contrastive_loss 0.611 | total 6138.43 | n_correct 4177.29 | ppl 5.04 | accuracy 68.051 | uer 19.137 | wer 20.409 | raw_wer 20.409 | bleu 26.09 | wps 1761.3 | wpb 6138.4 | bsz 201.1 | num_updates 10000 | best_bleu 26.09
2023-08-30 18:10:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 10000 updates
2023-08-30 18:10:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_9_10000.pt
2023-08-30 18:10:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_9_10000.pt
2023-08-30 18:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd/checkpoint_9_10000.pt (epoch 9 @ 10000 updates, score 26.09) (writing took 14.356428322000284 seconds)
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 1 terminated with signal SIGKILL
/mnt/zhangyh/miniconda3/envs/at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 473 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-08-30 22:09:22 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12142
2023-08-30 22:09:22 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12142
2023-08-30 22:09:22 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12142
2023-08-30 22:09:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-30 22:09:22 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12142
2023-08-30 22:09:22 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12142
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12142
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12142
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12142
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 0
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 7
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 1
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 3
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 4
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 2
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 5
2023-08-30 22:09:23 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-30 22:09:23 | INFO | fairseq.distributed.utils | initialized host localhost.localdomain as rank 6
2023-08-30 22:09:27 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12142', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 11000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 11000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_low_pos=False, at_nomute=False, at_nopad=True, at_scale=3.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_enfr_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=11000, max_tokens_valid=11000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2es/enes-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/enfr_shrink_v2_merge_wmt_0830_both_topCL_AT_sentence_mixup0307_scale5_alpha1.0_mt0.5_nograd', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=True, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-30 22:09:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 9,999
2023-08-30 22:09:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 9,999
2023-08-30 22:09:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-30 22:09:27 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-30 22:09:27 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
2023-08-30 22:09:31 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-30 22:09:31 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_enfr_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-30 22:09:31 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-30 22:09:33 | INFO | root | load pretrained hubert
2023-08-30 22:09:41 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_enes_baseline
