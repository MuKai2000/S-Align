2023-08-16 11:23:46 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11285
2023-08-16 11:23:46 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11285
2023-08-16 11:23:46 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11285
2023-08-16 11:23:47 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11285
2023-08-16 11:23:47 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11285
2023-08-16 11:23:47 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11285
2023-08-16 11:23:47 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11285
2023-08-16 11:23:47 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11285
2023-08-16 11:23:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-16 11:23:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-16 11:23:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-16 11:23:47 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 11:23:48 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-16 11:23:48 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 11:23:48 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 11:23:48 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-16 11:23:48 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-16 11:23:48 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 11:23:48 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-16 11:23:48 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-16 11:23:48 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-16 11:23:52 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11285', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-16 11:23:52 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-16 11:23:52 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-16 11:23:52 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-16 11:23:52 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-16 11:23:52 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-16 11:23:56 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-16 11:23:56 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-16 11:23:56 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-16 11:23:58 | INFO | root | load pretrained hubert
2023-08-16 11:23:59 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-16 11:24:01 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-16 11:24:02 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-16 11:24:02 | INFO | root | share the sematic adapter and textual encoder
2023-08-16 11:24:02 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-16 11:24:02 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-16 11:24:02 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-16 11:24:02 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-16 11:24:02 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-16 11:24:02 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-16 11:24:02 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-16 11:24:02 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-16 11:24:02 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-16 11:24:02 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-16 11:24:06 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-16 11:24:10 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-16 11:24:10 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-16 11:24:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-16 11:24:11 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 11:24:11 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 11:24:11 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 11:24:11 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 11:24:11 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 11:24:11 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 11:24:11 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 11:24:11 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-16 11:24:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-16 11:24:11 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-16 11:24:11 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-16 11:24:11 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-16 11:24:11 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-16 11:24:11 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-16 11:24:11 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-16 11:24:11 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-16 11:24:11 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-16 11:24:12 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-16 11:24:14 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-16 11:25:03 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-16 11:25:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 11:25:03 | INFO | fairseq.trainer | begin training epoch 1
2023-08-16 11:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 11:25:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-16 11:25:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-16 11:25:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-16 11:25:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-16 11:26:22 | INFO | train_inner | epoch 001:    104 / 1474 loss=20.537, trans_loss=5.87, nll_loss=4.678, w2v_ctc_loss=22.862, task_loss=0, contrastive_loss=3.275, total=4224.43, n_correct=123.64, ppl=25.6, accuracy=2.927, wps=19444.2, ups=1.55, wpb=12604.5, bsz=477.7, num_updates=100, lr=4.098e-06, gnorm=2.951, clip=0, loss_scale=8, train_wall=71, gb_free=18.6, wall=131
2023-08-16 11:26:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-16 11:27:26 | INFO | train_inner | epoch 001:    205 / 1474 loss=17.019, trans_loss=5.845, nll_loss=4.671, w2v_ctc_loss=17.55, task_loss=0, contrastive_loss=3.23, total=4111.17, n_correct=116.02, ppl=25.48, accuracy=2.822, wps=19287.1, ups=1.57, wpb=12275.4, bsz=456.2, num_updates=200, lr=8.096e-06, gnorm=7.401, clip=20, loss_scale=4, train_wall=63, gb_free=19.4, wall=195
2023-08-16 11:28:28 | INFO | train_inner | epoch 001:    305 / 1474 loss=10.162, trans_loss=5.846, nll_loss=4.713, w2v_ctc_loss=7.06, task_loss=0, contrastive_loss=3.174, total=4080.91, n_correct=112.4, ppl=26.23, accuracy=2.754, wps=19566.5, ups=1.61, wpb=12190.4, bsz=439.4, num_updates=300, lr=1.2094e-05, gnorm=2.268, clip=0, loss_scale=4, train_wall=62, gb_free=18.6, wall=257
2023-08-16 11:28:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-16 11:29:31 | INFO | train_inner | epoch 001:    406 / 1474 loss=9.631, trans_loss=5.792, nll_loss=4.677, w2v_ctc_loss=6.257, task_loss=0, contrastive_loss=3.203, total=4175.17, n_correct=102.25, ppl=25.57, accuracy=2.449, wps=19798.3, ups=1.59, wpb=12465.7, bsz=460.1, num_updates=400, lr=1.6092e-05, gnorm=1.484, clip=1, loss_scale=2, train_wall=62, gb_free=18.6, wall=320
2023-08-16 11:30:34 | INFO | train_inner | epoch 001:    506 / 1474 loss=9.44, trans_loss=5.725, nll_loss=4.611, w2v_ctc_loss=5.963, task_loss=0, contrastive_loss=3.301, total=4181.66, n_correct=102.04, ppl=24.45, accuracy=2.44, wps=19966.1, ups=1.6, wpb=12495.1, bsz=487, num_updates=500, lr=2.009e-05, gnorm=1.36, clip=0, loss_scale=2, train_wall=62, gb_free=19.2, wall=383
2023-08-16 11:31:37 | INFO | train_inner | epoch 001:    606 / 1474 loss=9.357, trans_loss=5.814, nll_loss=4.727, w2v_ctc_loss=5.797, task_loss=0, contrastive_loss=3.254, total=4137.35, n_correct=86.36, ppl=26.48, accuracy=2.087, wps=19461, ups=1.58, wpb=12337.2, bsz=474.5, num_updates=600, lr=2.4088e-05, gnorm=1.054, clip=0, loss_scale=2, train_wall=63, gb_free=18.7, wall=446
2023-08-16 11:32:39 | INFO | train_inner | epoch 001:    706 / 1474 loss=9.235, trans_loss=5.797, nll_loss=4.703, w2v_ctc_loss=5.719, task_loss=0, contrastive_loss=3.127, total=4145.85, n_correct=88.58, ppl=26.05, accuracy=2.137, wps=20048.9, ups=1.62, wpb=12381.9, bsz=454.4, num_updates=700, lr=2.8086e-05, gnorm=1.408, clip=0, loss_scale=2, train_wall=61, gb_free=19.5, wall=508
2023-08-16 11:33:41 | INFO | train_inner | epoch 001:    806 / 1474 loss=9.243, trans_loss=6.049, nll_loss=5.024, w2v_ctc_loss=5.516, task_loss=0, contrastive_loss=3.139, total=4129.2, n_correct=67.58, ppl=32.55, accuracy=1.637, wps=19807.2, ups=1.61, wpb=12318.4, bsz=463.3, num_updates=800, lr=3.2084e-05, gnorm=1.157, clip=0, loss_scale=2, train_wall=62, gb_free=19.2, wall=570
2023-08-16 11:34:43 | INFO | train_inner | epoch 001:    906 / 1474 loss=9.056, trans_loss=6.076, nll_loss=5.053, w2v_ctc_loss=5.276, task_loss=0, contrastive_loss=3.046, total=4167.97, n_correct=52.29, ppl=33.2, accuracy=1.255, wps=20080.5, ups=1.61, wpb=12446.3, bsz=458.8, num_updates=900, lr=3.6082e-05, gnorm=1.526, clip=0, loss_scale=2, train_wall=62, gb_free=18.6, wall=632
2023-08-16 11:35:46 | INFO | train_inner | epoch 001:   1006 / 1474 loss=8.88, trans_loss=6.121, nll_loss=5.104, w2v_ctc_loss=4.998, task_loss=0, contrastive_loss=3.036, total=4137.5, n_correct=48.38, ppl=34.39, accuracy=1.169, wps=19669, ups=1.59, wpb=12361.1, bsz=459.1, num_updates=1000, lr=4.008e-05, gnorm=2, clip=0, loss_scale=2, train_wall=62, gb_free=19.3, wall=695
2023-08-16 11:36:48 | INFO | train_inner | epoch 001:   1106 / 1474 loss=8.656, trans_loss=6.15, nll_loss=5.13, w2v_ctc_loss=4.767, task_loss=0, contrastive_loss=2.933, total=4151.84, n_correct=50.32, ppl=35.02, accuracy=1.212, wps=19914.8, ups=1.61, wpb=12382.4, bsz=452.7, num_updates=1100, lr=4.4078e-05, gnorm=2.005, clip=0, loss_scale=2, train_wall=62, gb_free=18.8, wall=757
2023-08-16 11:37:50 | INFO | train_inner | epoch 001:   1206 / 1474 loss=8.471, trans_loss=6.151, nll_loss=5.133, w2v_ctc_loss=4.594, task_loss=0, contrastive_loss=2.831, total=4123.25, n_correct=52.47, ppl=35.08, accuracy=1.273, wps=19787.3, ups=1.61, wpb=12316.7, bsz=437.7, num_updates=1200, lr=4.8076e-05, gnorm=2.395, clip=0, loss_scale=2, train_wall=62, gb_free=19.6, wall=820
2023-08-16 11:38:52 | INFO | train_inner | epoch 001:   1306 / 1474 loss=8.366, trans_loss=6.199, nll_loss=5.194, w2v_ctc_loss=4.422, task_loss=0, contrastive_loss=2.783, total=4066.16, n_correct=43.99, ppl=36.62, accuracy=1.082, wps=19736.4, ups=1.63, wpb=12138.7, bsz=445.8, num_updates=1300, lr=5.2074e-05, gnorm=2.331, clip=0, loss_scale=2, train_wall=61, gb_free=18.8, wall=881
2023-08-16 11:39:54 | INFO | train_inner | epoch 001:   1406 / 1474 loss=8.218, trans_loss=6.179, nll_loss=5.174, w2v_ctc_loss=4.266, task_loss=0, contrastive_loss=2.864, total=4119.98, n_correct=47.29, ppl=36.09, accuracy=1.148, wps=19903.6, ups=1.62, wpb=12311.1, bsz=449.5, num_updates=1400, lr=5.6072e-05, gnorm=2.353, clip=0, loss_scale=2, train_wall=61, gb_free=18.6, wall=943
2023-08-16 11:40:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 11:41:15 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 12.91 | trans_loss 13.902 | nll_loss 13.763 | w2v_ctc_loss 5.578 | task_loss 0 | contrastive_loss 4.065 | total 4003.4 | n_correct 25.2 | ppl 13905.9 | accuracy 0.629 | uer 69.238 | wer 67.391 | raw_wer 67.391 | bleu 0 | wps 1201.1 | wpb 4003.4 | bsz 141.8 | num_updates 1468
2023-08-16 11:41:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1468 updates
2023-08-16 11:41:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 11:41:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 11:41:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1468 updates, score 0.0) (writing took 6.263728678226471 seconds)
2023-08-16 11:41:21 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-16 11:41:21 | INFO | train | epoch 001 | loss 10.354 | trans_loss 5.982 | nll_loss 4.912 | w2v_ctc_loss 7.367 | task_loss 0 | contrastive_loss 3.077 | total 4139.21 | n_correct 76.7091 | ppl 30.1 | accuracy 1.853 | wps 18815.8 | ups 1.52 | wpb 12357.5 | bsz 458.7 | num_updates 1468 | lr 5.87906e-05 | gnorm 2.29 | clip 1.4 | loss_scale 2 | train_wall 918 | gb_free 18.9 | wall 1031
2023-08-16 11:41:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 11:41:22 | INFO | fairseq.trainer | begin training epoch 2
2023-08-16 11:41:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 11:41:50 | INFO | train_inner | epoch 002:     32 / 1474 loss=8.117, trans_loss=6.186, nll_loss=5.18, w2v_ctc_loss=4.118, task_loss=0, contrastive_loss=2.835, total=4165.61, n_correct=49.28, ppl=36.25, accuracy=1.183, wps=10682.6, ups=0.86, wpb=12422.6, bsz=470.4, num_updates=1500, lr=6.007e-05, gnorm=2.94, clip=0, loss_scale=2, train_wall=62, gb_free=18.7, wall=1059
2023-08-16 11:42:52 | INFO | train_inner | epoch 002:    132 / 1474 loss=7.977, trans_loss=6.191, nll_loss=5.187, w2v_ctc_loss=4.027, task_loss=0, contrastive_loss=2.684, total=4153.7, n_correct=45.18, ppl=36.44, accuracy=1.088, wps=20040.6, ups=1.62, wpb=12391.2, bsz=453.7, num_updates=1600, lr=6.4068e-05, gnorm=2.418, clip=0, loss_scale=2, train_wall=61, gb_free=19.2, wall=1121
2023-08-16 11:43:53 | INFO | train_inner | epoch 002:    232 / 1474 loss=7.891, trans_loss=6.164, nll_loss=5.158, w2v_ctc_loss=3.881, task_loss=0, contrastive_loss=2.753, total=4201.44, n_correct=54.31, ppl=35.7, accuracy=1.293, wps=20386.9, ups=1.62, wpb=12547.2, bsz=493.6, num_updates=1700, lr=6.8066e-05, gnorm=2.653, clip=0, loss_scale=2, train_wall=61, gb_free=18.9, wall=1183
2023-08-16 11:44:55 | INFO | train_inner | epoch 002:    332 / 1474 loss=7.697, trans_loss=6.152, nll_loss=5.143, w2v_ctc_loss=3.825, task_loss=0, contrastive_loss=2.527, total=4130.13, n_correct=56.22, ppl=35.35, accuracy=1.361, wps=19924.2, ups=1.62, wpb=12330.1, bsz=445.5, num_updates=1800, lr=7.2064e-05, gnorm=2.92, clip=0, loss_scale=2, train_wall=61, gb_free=18.7, wall=1245
2023-08-16 11:45:57 | INFO | train_inner | epoch 002:    432 / 1474 loss=7.539, trans_loss=6.131, nll_loss=5.12, w2v_ctc_loss=3.765, task_loss=0, contrastive_loss=2.341, total=4035.12, n_correct=53.77, ppl=34.77, accuracy=1.333, wps=19393.4, ups=1.61, wpb=12062.7, bsz=413.5, num_updates=1900, lr=7.6062e-05, gnorm=2.623, clip=0, loss_scale=2, train_wall=62, gb_free=19, wall=1307
2023-08-16 11:47:00 | INFO | train_inner | epoch 002:    532 / 1474 loss=7.466, trans_loss=6.08, nll_loss=5.05, w2v_ctc_loss=3.636, task_loss=0, contrastive_loss=2.49, total=4183.09, n_correct=67.33, ppl=33.12, accuracy=1.61, wps=19910.5, ups=1.6, wpb=12479, bsz=468.4, num_updates=2000, lr=8.006e-05, gnorm=2.806, clip=0, loss_scale=2, train_wall=62, gb_free=18.5, wall=1369
2023-08-16 11:47:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 11:47:39 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 12.211 | trans_loss 13.527 | nll_loss 13.272 | w2v_ctc_loss 4.821 | task_loss 0 | contrastive_loss 3.55 | total 4003.4 | n_correct 54.3 | ppl 9889.85 | accuracy 1.356 | uer 62.583 | wer 60.378 | raw_wer 60.378 | bleu 0 | wps 1209.4 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-16 11:47:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-16 11:47:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-16 11:47:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-16 11:48:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 30.921268107369542 seconds)
2023-08-16 11:49:11 | INFO | train_inner | epoch 002:    632 / 1474 loss=7.337, trans_loss=6.099, nll_loss=5.073, w2v_ctc_loss=3.546, task_loss=0, contrastive_loss=2.309, total=4123.85, n_correct=60.69, ppl=33.65, accuracy=1.472, wps=9406.3, ups=0.76, wpb=12306.4, bsz=448.7, num_updates=2100, lr=8.4058e-05, gnorm=2.644, clip=0, loss_scale=2, train_wall=61, gb_free=18.7, wall=1500
2023-08-16 11:50:13 | INFO | train_inner | epoch 002:    732 / 1474 loss=7.254, trans_loss=6.07, nll_loss=5.037, w2v_ctc_loss=3.486, task_loss=0, contrastive_loss=2.376, total=4148.13, n_correct=69.07, ppl=32.84, accuracy=1.665, wps=20108, ups=1.62, wpb=12381, bsz=462.1, num_updates=2200, lr=8.8056e-05, gnorm=2.695, clip=0, loss_scale=2, train_wall=61, gb_free=18.6, wall=1562
2023-08-16 11:51:14 | INFO | train_inner | epoch 002:    832 / 1474 loss=7.167, trans_loss=6.065, nll_loss=5.033, w2v_ctc_loss=3.431, task_loss=0, contrastive_loss=2.331, total=4172.27, n_correct=70.85, ppl=32.74, accuracy=1.698, wps=20141.8, ups=1.62, wpb=12465.7, bsz=464.5, num_updates=2300, lr=9.2054e-05, gnorm=2.539, clip=0, loss_scale=2, train_wall=61, gb_free=18.8, wall=1624
2023-08-16 11:52:17 | INFO | train_inner | epoch 002:    932 / 1474 loss=7.003, trans_loss=6.027, nll_loss=4.983, w2v_ctc_loss=3.346, task_loss=0, contrastive_loss=2.25, total=4101.67, n_correct=71.5, ppl=31.62, accuracy=1.743, wps=19513.2, ups=1.59, wpb=12242.5, bsz=441.6, num_updates=2400, lr=9.6052e-05, gnorm=2.486, clip=0, loss_scale=4, train_wall=62, gb_free=19, wall=1686
2023-08-16 11:53:19 | INFO | train_inner | epoch 002:   1032 / 1474 loss=6.946, trans_loss=6.059, nll_loss=5.022, w2v_ctc_loss=3.286, task_loss=0, contrastive_loss=2.143, total=4091.09, n_correct=67.39, ppl=32.48, accuracy=1.647, wps=19742.5, ups=1.62, wpb=12214.8, bsz=451.5, num_updates=2500, lr=0.00010005, gnorm=2.255, clip=0, loss_scale=4, train_wall=61, gb_free=19.2, wall=1748
2023-08-16 11:54:22 | INFO | train_inner | epoch 002:   1132 / 1474 loss=6.92, trans_loss=6.041, nll_loss=4.998, w2v_ctc_loss=3.192, task_loss=0, contrastive_loss=2.361, total=4219.19, n_correct=74.09, ppl=31.97, accuracy=1.756, wps=20157.4, ups=1.6, wpb=12595.1, bsz=500.6, num_updates=2600, lr=0.000104048, gnorm=2.204, clip=0, loss_scale=4, train_wall=62, gb_free=19, wall=1811
2023-08-16 11:55:23 | INFO | train_inner | epoch 002:   1232 / 1474 loss=6.818, trans_loss=6.039, nll_loss=4.995, w2v_ctc_loss=3.158, task_loss=0, contrastive_loss=2.174, total=4212.91, n_correct=72.98, ppl=31.9, accuracy=1.732, wps=20338.3, ups=1.62, wpb=12571.7, bsz=486.8, num_updates=2700, lr=0.000108046, gnorm=2.146, clip=0, loss_scale=4, train_wall=61, gb_free=19.1, wall=1873
2023-08-16 11:56:25 | INFO | train_inner | epoch 002:   1332 / 1474 loss=6.694, trans_loss=6.029, nll_loss=4.986, w2v_ctc_loss=3.117, task_loss=0, contrastive_loss=1.951, total=4142.48, n_correct=77, ppl=31.7, accuracy=1.859, wps=19979.6, ups=1.61, wpb=12381.2, bsz=456.3, num_updates=2800, lr=0.000112044, gnorm=2.086, clip=0, loss_scale=4, train_wall=62, gb_free=18.9, wall=1935
2023-08-16 11:57:28 | INFO | train_inner | epoch 002:   1432 / 1474 loss=6.599, trans_loss=6.024, nll_loss=4.978, w2v_ctc_loss=3.069, task_loss=0, contrastive_loss=2.009, total=4063.28, n_correct=72.09, ppl=31.51, accuracy=1.774, wps=19410, ups=1.6, wpb=12131.5, bsz=444.3, num_updates=2900, lr=0.000116042, gnorm=2.036, clip=0, loss_scale=4, train_wall=62, gb_free=19.6, wall=1997
2023-08-16 11:57:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 11:58:32 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.327 | trans_loss 13.147 | nll_loss 12.757 | w2v_ctc_loss 3.928 | task_loss 0 | contrastive_loss 2.695 | total 4003.4 | n_correct 80.8 | ppl 6921.7 | accuracy 2.018 | uer 53.065 | wer 52.258 | raw_wer 52.258 | bleu 0 | wps 1215.8 | wpb 4003.4 | bsz 141.8 | num_updates 2942 | best_bleu 0
2023-08-16 11:58:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2942 updates
2023-08-16 11:58:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 11:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 11:59:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2942 updates, score 0.0) (writing took 29.53356439061463 seconds)
2023-08-16 11:59:02 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-16 11:59:02 | INFO | train | epoch 002 | loss 7.236 | trans_loss 6.084 | nll_loss 5.055 | w2v_ctc_loss 3.484 | task_loss 0 | contrastive_loss 2.335 | total 4138.65 | n_correct 65.1581 | ppl 33.24 | accuracy 1.574 | wps 17181.3 | ups 1.39 | wpb 12355.8 | bsz 458.5 | num_updates 2942 | lr 0.000117721 | gnorm 2.466 | clip 0 | loss_scale 4 | train_wall 907 | gb_free 19 | wall 2091
2023-08-16 11:59:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 11:59:02 | INFO | fairseq.trainer | begin training epoch 3
2023-08-16 11:59:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 11:59:46 | INFO | train_inner | epoch 003:     58 / 1474 loss=6.493, trans_loss=6.005, nll_loss=4.954, w2v_ctc_loss=3.012, task_loss=0, contrastive_loss=1.864, total=4048.67, n_correct=74.29, ppl=30.99, accuracy=1.835, wps=8740.6, ups=0.72, wpb=12085.6, bsz=433.9, num_updates=3000, lr=0.00012004, gnorm=1.877, clip=0, loss_scale=4, train_wall=61, gb_free=18.8, wall=2135
2023-08-16 12:01:06 | INFO | train_inner | epoch 003:    158 / 1474 loss=5.801, trans_loss=5.227, nll_loss=3.964, w2v_ctc_loss=2.795, task_loss=0, contrastive_loss=1.84, total=4148.1, n_correct=335.87, ppl=15.6, accuracy=8.097, wps=15557.2, ups=1.26, wpb=12386.6, bsz=459, num_updates=3100, lr=0.000124038, gnorm=4.465, clip=5, loss_scale=4, train_wall=79, gb_free=16.5, wall=2215
2023-08-16 12:02:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-16 12:02:28 | INFO | train_inner | epoch 003:    259 / 1474 loss=4.803, trans_loss=4.424, nll_loss=2.898, w2v_ctc_loss=2.476, task_loss=0, contrastive_loss=1.647, total=4165.4, n_correct=991.74, ppl=7.45, accuracy=23.809, wps=15220.3, ups=1.22, wpb=12444.8, bsz=468.2, num_updates=3200, lr=0.000128036, gnorm=2.509, clip=0, loss_scale=2, train_wall=81, gb_free=17.5, wall=2297
2023-08-16 12:03:48 | INFO | train_inner | epoch 003:    359 / 1474 loss=4.464, trans_loss=4.25, nll_loss=2.672, w2v_ctc_loss=2.334, task_loss=0, contrastive_loss=1.543, total=4154.07, n_correct=1217.19, ppl=6.37, accuracy=29.301, wps=15322.6, ups=1.24, wpb=12396.6, bsz=464.9, num_updates=3300, lr=0.000132034, gnorm=2.175, clip=0, loss_scale=2, train_wall=80, gb_free=15.7, wall=2378
2023-08-16 12:05:09 | INFO | train_inner | epoch 003:    459 / 1474 loss=4.22, trans_loss=4.184, nll_loss=2.589, w2v_ctc_loss=2.214, task_loss=0, contrastive_loss=1.338, total=4212.17, n_correct=1331.19, ppl=6.02, accuracy=31.603, wps=15569.7, ups=1.24, wpb=12572.6, bsz=473.8, num_updates=3400, lr=0.000136032, gnorm=1.95, clip=0, loss_scale=2, train_wall=80, gb_free=15.8, wall=2458
2023-08-16 12:06:29 | INFO | train_inner | epoch 003:    559 / 1474 loss=4.023, trans_loss=4.153, nll_loss=2.553, w2v_ctc_loss=2.122, task_loss=0, contrastive_loss=1.201, total=4081.04, n_correct=1335.27, ppl=5.87, accuracy=32.719, wps=15261.3, ups=1.25, wpb=12190.8, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.935, clip=0, loss_scale=2, train_wall=79, gb_free=16.4, wall=2538
2023-08-16 12:07:51 | INFO | train_inner | epoch 003:    659 / 1474 loss=3.924, trans_loss=4.126, nll_loss=2.513, w2v_ctc_loss=2.03, task_loss=0, contrastive_loss=1.255, total=4231.09, n_correct=1435.88, ppl=5.71, accuracy=33.936, wps=15468.5, ups=1.23, wpb=12615.6, bsz=484.4, num_updates=3600, lr=0.000144028, gnorm=1.654, clip=0, loss_scale=2, train_wall=81, gb_free=15.9, wall=2620
2023-08-16 12:09:11 | INFO | train_inner | epoch 003:    759 / 1474 loss=3.781, trans_loss=4.095, nll_loss=2.479, w2v_ctc_loss=1.999, task_loss=0, contrastive_loss=0.972, total=4160.74, n_correct=1450.79, ppl=5.57, accuracy=34.869, wps=15432.6, ups=1.24, wpb=12428.5, bsz=469.2, num_updates=3700, lr=0.000148026, gnorm=1.706, clip=0, loss_scale=2, train_wall=80, gb_free=16.7, wall=2700
2023-08-16 12:10:32 | INFO | train_inner | epoch 003:    859 / 1474 loss=3.671, trans_loss=4.079, nll_loss=2.457, w2v_ctc_loss=1.945, task_loss=0, contrastive_loss=0.896, total=4160.47, n_correct=1483.78, ppl=5.49, accuracy=35.664, wps=15432, ups=1.24, wpb=12423.6, bsz=455.4, num_updates=3800, lr=0.000152024, gnorm=1.61, clip=0, loss_scale=2, train_wall=80, gb_free=16.3, wall=2781
2023-08-16 12:11:52 | INFO | train_inner | epoch 003:    959 / 1474 loss=3.596, trans_loss=4.058, nll_loss=2.427, w2v_ctc_loss=1.91, task_loss=0, contrastive_loss=0.876, total=4162.26, n_correct=1532.29, ppl=5.38, accuracy=36.814, wps=15480.8, ups=1.25, wpb=12416.1, bsz=467.9, num_updates=3900, lr=0.000156022, gnorm=1.62, clip=0, loss_scale=2, train_wall=80, gb_free=17.7, wall=2861
2023-08-16 12:13:12 | INFO | train_inner | epoch 003:   1059 / 1474 loss=3.504, trans_loss=4.027, nll_loss=2.388, w2v_ctc_loss=1.897, task_loss=0, contrastive_loss=0.785, total=4062.67, n_correct=1533.98, ppl=5.23, accuracy=37.758, wps=15208.9, ups=1.25, wpb=12131.7, bsz=443.2, num_updates=4000, lr=0.00016002, gnorm=1.536, clip=0, loss_scale=2, train_wall=79, gb_free=15.6, wall=2941
2023-08-16 12:13:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 12:13:40 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.846 | trans_loss 6.868 | nll_loss 4.61 | w2v_ctc_loss 2.305 | task_loss 0 | contrastive_loss 1.057 | total 4003.4 | n_correct 1663.6 | ppl 24.42 | accuracy 41.555 | uer 31.951 | wer 32.489 | raw_wer 32.489 | bleu 3.68 | wps 1685.6 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 3.68
2023-08-16 12:13:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-16 12:13:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-16 12:13:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-16 12:14:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 3.68) (writing took 47.42169879004359 seconds)
2023-08-16 12:15:47 | INFO | train_inner | epoch 003:   1159 / 1474 loss=3.411, trans_loss=4.009, nll_loss=2.364, w2v_ctc_loss=1.852, task_loss=0, contrastive_loss=0.717, total=4046.76, n_correct=1567.2, ppl=5.15, accuracy=38.727, wps=7773.4, ups=0.64, wpb=12078.6, bsz=433.9, num_updates=4100, lr=0.000164018, gnorm=1.49, clip=0, loss_scale=2, train_wall=79, gb_free=16.2, wall=3096
2023-08-16 12:17:06 | INFO | train_inner | epoch 003:   1259 / 1474 loss=3.328, trans_loss=3.976, nll_loss=2.322, w2v_ctc_loss=1.814, task_loss=0, contrastive_loss=0.662, total=4064.26, n_correct=1616.72, ppl=5, accuracy=39.779, wps=15300.2, ups=1.26, wpb=12137.6, bsz=434, num_updates=4200, lr=0.000168016, gnorm=1.472, clip=0, loss_scale=2, train_wall=79, gb_free=16.6, wall=3176
2023-08-16 12:18:27 | INFO | train_inner | epoch 003:   1359 / 1474 loss=3.299, trans_loss=3.953, nll_loss=2.291, w2v_ctc_loss=1.779, task_loss=0, contrastive_loss=0.747, total=4137.36, n_correct=1687.61, ppl=4.9, accuracy=40.79, wps=15341.8, ups=1.24, wpb=12352.2, bsz=461.5, num_updates=4300, lr=0.000172014, gnorm=1.411, clip=0, loss_scale=2, train_wall=80, gb_free=16.2, wall=3256
2023-08-16 12:19:48 | INFO | train_inner | epoch 003:   1459 / 1474 loss=3.256, trans_loss=3.932, nll_loss=2.265, w2v_ctc_loss=1.765, task_loss=0, contrastive_loss=0.713, total=4207.75, n_correct=1760.38, ppl=4.81, accuracy=41.837, wps=15455.2, ups=1.23, wpb=12567.9, bsz=476.7, num_updates=4400, lr=0.000176012, gnorm=1.53, clip=0, loss_scale=2, train_wall=81, gb_free=17.3, wall=3338
2023-08-16 12:20:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 12:20:28 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.434 | trans_loss 6.481 | nll_loss 4.102 | w2v_ctc_loss 2.111 | task_loss 0 | contrastive_loss 0.838 | total 4003.4 | n_correct 1884 | ppl 17.17 | accuracy 47.06 | uer 30.653 | wer 30.912 | raw_wer 30.912 | bleu 7.54 | wps 1697.1 | wpb 4003.4 | bsz 141.8 | num_updates 4415 | best_bleu 7.54
2023-08-16 12:20:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4415 updates
2023-08-16 12:20:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 12:20:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 12:20:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 3 @ 4415 updates, score 7.54) (writing took 30.635638972744346 seconds)
2023-08-16 12:20:59 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-16 12:20:59 | INFO | train | epoch 003 | loss 4.028 | trans_loss 4.247 | nll_loss 2.674 | w2v_ctc_loss 2.1 | task_loss 0 | contrastive_loss 1.117 | total 4138.82 | n_correct 1328.79 | ppl 6.38 | accuracy 32.105 | wps 13815.8 | ups 1.12 | wpb 12356.3 | bsz 458.5 | num_updates 4415 | lr 0.000176612 | gnorm 1.924 | clip 0.3 | loss_scale 2 | train_wall 1168 | gb_free 16.4 | wall 3408
2023-08-16 12:20:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 12:20:59 | INFO | fairseq.trainer | begin training epoch 4
2023-08-16 12:20:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 12:22:14 | INFO | train_inner | epoch 004:     85 / 1474 loss=3.125, trans_loss=3.901, nll_loss=2.222, w2v_ctc_loss=1.72, task_loss=0, contrastive_loss=0.529, total=4095.18, n_correct=1757.31, ppl=4.67, accuracy=42.912, wps=8356.8, ups=0.68, wpb=12222.9, bsz=437.8, num_updates=4500, lr=0.00018001, gnorm=1.468, clip=1, loss_scale=2, train_wall=79, gb_free=12.7, wall=3484
2023-08-16 12:23:34 | INFO | train_inner | epoch 004:    185 / 1474 loss=3.085, trans_loss=3.866, nll_loss=2.179, w2v_ctc_loss=1.693, task_loss=0, contrastive_loss=0.544, total=4178.83, n_correct=1850.22, ppl=4.53, accuracy=44.276, wps=15717.8, ups=1.26, wpb=12476.1, bsz=469.5, num_updates=4600, lr=0.000184008, gnorm=1.3, clip=0, loss_scale=2, train_wall=79, gb_free=14.7, wall=3563
2023-08-16 12:24:54 | INFO | train_inner | epoch 004:    285 / 1474 loss=3.083, trans_loss=3.863, nll_loss=2.175, w2v_ctc_loss=1.689, task_loss=0, contrastive_loss=0.645, total=4142.3, n_correct=1840.66, ppl=4.52, accuracy=44.436, wps=15417.6, ups=1.25, wpb=12373.8, bsz=460.7, num_updates=4700, lr=0.000188006, gnorm=1.306, clip=0, loss_scale=2, train_wall=80, gb_free=13.4, wall=3643
2023-08-16 12:26:14 | INFO | train_inner | epoch 004:    385 / 1474 loss=3.016, trans_loss=3.846, nll_loss=2.15, w2v_ctc_loss=1.676, task_loss=0, contrastive_loss=0.478, total=4124.92, n_correct=1863.8, ppl=4.44, accuracy=45.184, wps=15343.3, ups=1.25, wpb=12307.7, bsz=444.2, num_updates=4800, lr=0.000192004, gnorm=1.369, clip=0, loss_scale=2, train_wall=80, gb_free=12.5, wall=3724
2023-08-16 12:27:36 | INFO | train_inner | epoch 004:    485 / 1474 loss=3.057, trans_loss=3.821, nll_loss=2.12, w2v_ctc_loss=1.635, task_loss=0, contrastive_loss=0.868, total=4216.09, n_correct=1948.32, ppl=4.35, accuracy=46.212, wps=15496.7, ups=1.23, wpb=12585.8, bsz=497.6, num_updates=4900, lr=0.000196002, gnorm=1.284, clip=0, loss_scale=2, train_wall=81, gb_free=16.7, wall=3805
2023-08-16 12:28:56 | INFO | train_inner | epoch 004:    585 / 1474 loss=2.98, trans_loss=3.801, nll_loss=2.095, w2v_ctc_loss=1.656, task_loss=0, contrastive_loss=0.543, total=4231.12, n_correct=1994.24, ppl=4.27, accuracy=47.133, wps=15797.6, ups=1.25, wpb=12629.4, bsz=490.1, num_updates=5000, lr=0.0002, gnorm=1.28, clip=0, loss_scale=2, train_wall=79, gb_free=16.1, wall=3885
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:0')
2023-08-16 12:30:17 | INFO | train_inner | epoch 004:    685 / 1474 loss=2.945, trans_loss=3.799, nll_loss=2.087, w2v_ctc_loss=1.64, task_loss=0, contrastive_loss=0.565, total=4176.95, n_correct=1978.35, ppl=4.25, accuracy=47.364, wps=15303.6, ups=1.23, wpb=12451, bsz=455.2, num_updates=5100, lr=0.00019803, gnorm=1.001, clip=0, loss_scale=2, train_wall=81, gb_free=15, wall=3966
2023-08-16 12:31:37 | INFO | train_inner | epoch 004:    785 / 1474 loss=2.898, trans_loss=3.779, nll_loss=2.067, w2v_ctc_loss=1.648, task_loss=0, contrastive_loss=0.426, total=4016.91, n_correct=1927.18, ppl=4.19, accuracy=47.977, wps=14902, ups=1.24, wpb=11995.1, bsz=418.7, num_updates=5200, lr=0.000196116, gnorm=0.95, clip=0, loss_scale=2, train_wall=80, gb_free=16.1, wall=4047
2023-08-16 12:32:58 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.921, trans_loss=3.756, nll_loss=2.038, w2v_ctc_loss=1.63, task_loss=0, contrastive_loss=0.604, total=4183.4, n_correct=2039.12, ppl=4.11, accuracy=48.743, wps=15472.3, ups=1.24, wpb=12493.2, bsz=465.4, num_updates=5300, lr=0.000194257, gnorm=0.861, clip=0, loss_scale=4, train_wall=80, gb_free=15.4, wall=4127
2023-08-16 12:34:19 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.866, trans_loss=3.741, nll_loss=2.019, w2v_ctc_loss=1.618, task_loss=0, contrastive_loss=0.469, total=4128.78, n_correct=2038.74, ppl=4.05, accuracy=49.379, wps=15303.4, ups=1.24, wpb=12332, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.875, clip=0, loss_scale=4, train_wall=80, gb_free=15.9, wall=4208
2023-08-16 12:35:39 | INFO | train_inner | epoch 004:   1085 / 1474 loss=2.838, trans_loss=3.737, nll_loss=2.012, w2v_ctc_loss=1.613, task_loss=0, contrastive_loss=0.431, total=4080.2, n_correct=2032.99, ppl=4.03, accuracy=49.826, wps=15175, ups=1.25, wpb=12179.1, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=0.822, clip=0, loss_scale=4, train_wall=80, gb_free=16.2, wall=4288
2023-08-16 12:37:00 | INFO | train_inner | epoch 004:   1185 / 1474 loss=2.855, trans_loss=3.721, nll_loss=1.994, w2v_ctc_loss=1.6, task_loss=0, contrastive_loss=0.547, total=4163.45, n_correct=2103.15, ppl=3.98, accuracy=50.515, wps=15386.5, ups=1.24, wpb=12436, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=0.828, clip=0, loss_scale=4, train_wall=80, gb_free=15.2, wall=4369
2023-08-16 12:38:20 | INFO | train_inner | epoch 004:   1285 / 1474 loss=2.813, trans_loss=3.704, nll_loss=1.971, w2v_ctc_loss=1.584, task_loss=0, contrastive_loss=0.494, total=4152.41, n_correct=2119.25, ppl=3.92, accuracy=51.037, wps=15555.8, ups=1.25, wpb=12401.3, bsz=471.4, num_updates=5700, lr=0.000187317, gnorm=0.773, clip=0, loss_scale=4, train_wall=79, gb_free=12.9, wall=4449
2023-08-16 12:39:38 | INFO | train_inner | epoch 004:   1385 / 1474 loss=2.748, trans_loss=3.691, nll_loss=1.954, w2v_ctc_loss=1.568, task_loss=0, contrastive_loss=0.36, total=4103.57, n_correct=2115.75, ppl=3.87, accuracy=51.559, wps=15544.2, ups=1.27, wpb=12255.2, bsz=437.9, num_updates=5800, lr=0.000185695, gnorm=0.731, clip=0, loss_scale=4, train_wall=78, gb_free=16.7, wall=4528
2023-08-16 12:40:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4720, device='cuda:1')
2023-08-16 12:41:13 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.737 | trans_loss 5.756 | nll_loss 3.17 | w2v_ctc_loss 1.815 | task_loss 0 | contrastive_loss 0.543 | total 4003.4 | n_correct 2291.3 | ppl 9 | accuracy 57.234 | uer 25.995 | wer 27.363 | raw_wer 27.363 | bleu 15.2 | wps 2164.7 | wpb 4003.4 | bsz 141.8 | num_updates 5889 | best_bleu 15.2
2023-08-16 12:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5889 updates
2023-08-16 12:41:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 12:41:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 12:41:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 4 @ 5889 updates, score 15.2) (writing took 33.34891830012202 seconds)
2023-08-16 12:41:46 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-16 12:41:46 | INFO | train | epoch 004 | loss 2.931 | trans_loss 3.78 | nll_loss 2.068 | w2v_ctc_loss 1.634 | task_loss 0 | contrastive_loss 0.531 | total 4138.65 | n_correct 1982.68 | ppl 4.19 | accuracy 47.907 | wps 14602.6 | ups 1.18 | wpb 12355.8 | bsz 458.5 | num_updates 5889 | lr 0.000184287 | gnorm 1.037 | clip 0.1 | loss_scale 4 | train_wall 1175 | gb_free 14.8 | wall 4655
2023-08-16 12:41:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 12:41:46 | INFO | fairseq.trainer | begin training epoch 5
2023-08-16 12:41:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 12:42:03 | INFO | train_inner | epoch 005:     11 / 1474 loss=2.728, trans_loss=3.682, nll_loss=1.942, w2v_ctc_loss=1.544, task_loss=0, contrastive_loss=0.377, total=4031.51, n_correct=2093.16, ppl=3.84, accuracy=51.92, wps=8349.2, ups=0.69, wpb=12037.5, bsz=436.7, num_updates=5900, lr=0.000184115, gnorm=0.732, clip=0, loss_scale=4, train_wall=79, gb_free=14.3, wall=4672
2023-08-16 12:43:24 | INFO | train_inner | epoch 005:    111 / 1474 loss=2.664, trans_loss=3.641, nll_loss=1.889, w2v_ctc_loss=1.468, task_loss=0, contrastive_loss=0.396, total=4256.63, n_correct=2271.6, ppl=3.7, accuracy=53.366, wps=15567.1, ups=1.22, wpb=12710, bsz=500.1, num_updates=6000, lr=0.000182574, gnorm=0.678, clip=0, loss_scale=4, train_wall=81, gb_free=16.2, wall=4754
2023-08-16 12:43:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 12:43:47 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.708 | trans_loss 5.74 | nll_loss 3.146 | w2v_ctc_loss 1.755 | task_loss 0 | contrastive_loss 0.541 | total 4003.4 | n_correct 2304.9 | ppl 8.85 | accuracy 57.574 | uer 25.684 | wer 27.02 | raw_wer 27.02 | bleu 15.39 | wps 2277.4 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 15.39
2023-08-16 12:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-16 12:43:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-16 12:43:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-16 12:44:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 15.39) (writing took 55.152303187176585 seconds)
2023-08-16 12:46:02 | INFO | train_inner | epoch 005:    211 / 1474 loss=2.7, trans_loss=3.645, nll_loss=1.893, w2v_ctc_loss=1.484, task_loss=0, contrastive_loss=0.585, total=4186.83, n_correct=2236.73, ppl=3.71, accuracy=53.423, wps=7918.3, ups=0.63, wpb=12492.2, bsz=485.3, num_updates=6100, lr=0.000181071, gnorm=0.697, clip=0, loss_scale=4, train_wall=79, gb_free=16, wall=4911
2023-08-16 12:47:22 | INFO | train_inner | epoch 005:    311 / 1474 loss=2.662, trans_loss=3.63, nll_loss=1.88, w2v_ctc_loss=1.494, task_loss=0, contrastive_loss=0.435, total=4094.07, n_correct=2188.62, ppl=3.68, accuracy=53.458, wps=15336.8, ups=1.25, wpb=12241.2, bsz=446, num_updates=6200, lr=0.000179605, gnorm=0.678, clip=0, loss_scale=4, train_wall=79, gb_free=16.1, wall=4991
2023-08-16 12:48:42 | INFO | train_inner | epoch 005:    411 / 1474 loss=2.65, trans_loss=3.617, nll_loss=1.862, w2v_ctc_loss=1.457, task_loss=0, contrastive_loss=0.507, total=4140.39, n_correct=2241.13, ppl=3.64, accuracy=54.128, wps=15481.5, ups=1.25, wpb=12372.8, bsz=467.9, num_updates=6300, lr=0.000178174, gnorm=0.662, clip=0, loss_scale=4, train_wall=79, gb_free=16, wall=5071
2023-08-16 12:50:03 | INFO | train_inner | epoch 005:    511 / 1474 loss=2.591, trans_loss=3.62, nll_loss=1.864, w2v_ctc_loss=1.462, task_loss=0, contrastive_loss=0.298, total=4026.21, n_correct=2181.99, ppl=3.64, accuracy=54.195, wps=14852.9, ups=1.23, wpb=12028.8, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=0.663, clip=0, loss_scale=4, train_wall=81, gb_free=16.9, wall=5152
2023-08-16 12:51:23 | INFO | train_inner | epoch 005:    611 / 1474 loss=2.62, trans_loss=3.622, nll_loss=1.864, w2v_ctc_loss=1.446, task_loss=0, contrastive_loss=0.475, total=4109.94, n_correct=2234.85, ppl=3.64, accuracy=54.377, wps=15267.9, ups=1.25, wpb=12260.2, bsz=449.8, num_updates=6500, lr=0.000175412, gnorm=0.667, clip=0, loss_scale=4, train_wall=80, gb_free=15.4, wall=5232
2023-08-16 12:52:43 | INFO | train_inner | epoch 005:    711 / 1474 loss=2.616, trans_loss=3.614, nll_loss=1.855, w2v_ctc_loss=1.442, task_loss=0, contrastive_loss=0.45, total=4176.83, n_correct=2286.28, ppl=3.62, accuracy=54.737, wps=15544.4, ups=1.25, wpb=12467.5, bsz=483.6, num_updates=6600, lr=0.000174078, gnorm=0.634, clip=0, loss_scale=4, train_wall=80, gb_free=16.9, wall=5313
2023-08-16 12:54:04 | INFO | train_inner | epoch 005:    811 / 1474 loss=2.574, trans_loss=3.603, nll_loss=1.84, w2v_ctc_loss=1.435, task_loss=0, contrastive_loss=0.364, total=4127.9, n_correct=2270.78, ppl=3.58, accuracy=55.011, wps=15309.1, ups=1.24, wpb=12321.2, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=0.638, clip=0, loss_scale=4, train_wall=80, gb_free=15.7, wall=5393
2023-08-16 12:55:24 | INFO | train_inner | epoch 005:    911 / 1474 loss=2.545, trans_loss=3.592, nll_loss=1.828, w2v_ctc_loss=1.423, task_loss=0, contrastive_loss=0.326, total=4101.19, n_correct=2271.27, ppl=3.55, accuracy=55.381, wps=15186, ups=1.24, wpb=12245.9, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=0.637, clip=0, loss_scale=4, train_wall=80, gb_free=17.1, wall=5474
2023-08-16 12:56:44 | INFO | train_inner | epoch 005:   1011 / 1474 loss=2.555, trans_loss=3.595, nll_loss=1.831, w2v_ctc_loss=1.42, task_loss=0, contrastive_loss=0.398, total=4164.27, n_correct=2309.8, ppl=3.56, accuracy=55.467, wps=15631.2, ups=1.26, wpb=12430.2, bsz=462, num_updates=6900, lr=0.000170251, gnorm=0.627, clip=0, loss_scale=4, train_wall=79, gb_free=14.9, wall=5553
2023-08-16 12:58:04 | INFO | train_inner | epoch 005:   1111 / 1474 loss=2.569, trans_loss=3.588, nll_loss=1.821, w2v_ctc_loss=1.43, task_loss=0, contrastive_loss=0.404, total=4168.94, n_correct=2323.23, ppl=3.53, accuracy=55.727, wps=15451.2, ups=1.24, wpb=12436.1, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=0.632, clip=0, loss_scale=4, train_wall=80, gb_free=16.5, wall=5634
2023-08-16 12:59:24 | INFO | train_inner | epoch 005:   1211 / 1474 loss=2.513, trans_loss=3.583, nll_loss=1.815, w2v_ctc_loss=1.399, task_loss=0, contrastive_loss=0.306, total=4171.16, n_correct=2333.55, ppl=3.52, accuracy=55.945, wps=15609, ups=1.25, wpb=12443.2, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=0.609, clip=0, loss_scale=4, train_wall=79, gb_free=15.8, wall=5713
2023-08-16 13:00:45 | INFO | train_inner | epoch 005:   1311 / 1474 loss=2.484, trans_loss=3.574, nll_loss=1.804, w2v_ctc_loss=1.386, task_loss=0, contrastive_loss=0.262, total=4126.97, n_correct=2318.93, ppl=3.49, accuracy=56.19, wps=15277.5, ups=1.24, wpb=12317.9, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=0.603, clip=0, loss_scale=4, train_wall=80, gb_free=15.4, wall=5794
2023-08-16 13:02:05 | INFO | train_inner | epoch 005:   1411 / 1474 loss=2.496, trans_loss=3.572, nll_loss=1.804, w2v_ctc_loss=1.382, task_loss=0, contrastive_loss=0.326, total=4138.54, n_correct=2332.24, ppl=3.49, accuracy=56.354, wps=15490.1, ups=1.25, wpb=12359.3, bsz=459, num_updates=7300, lr=0.000165521, gnorm=0.607, clip=0, loss_scale=8, train_wall=79, gb_free=16.7, wall=5874
2023-08-16 13:02:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 13:03:16 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.487 | trans_loss 5.524 | nll_loss 2.885 | w2v_ctc_loss 1.609 | task_loss 0 | contrastive_loss 0.469 | total 4003.4 | n_correct 2440.8 | ppl 7.38 | accuracy 60.968 | uer 24.222 | wer 25.804 | raw_wer 25.804 | bleu 17.72 | wps 2471.3 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 17.72
2023-08-16 13:03:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-08-16 13:03:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 13:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 13:03:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7363 updates, score 17.72) (writing took 32.62722252123058 seconds)
2023-08-16 13:03:49 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-16 13:03:49 | INFO | train | epoch 005 | loss 2.586 | trans_loss 3.606 | nll_loss 1.845 | w2v_ctc_loss 1.436 | task_loss 0 | contrastive_loss 0.395 | total 4138.65 | n_correct 2271.74 | ppl 3.59 | accuracy 54.891 | wps 13766.7 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 7363 | lr 0.000164812 | gnorm 0.644 | clip 0 | loss_scale 8 | train_wall 1176 | gb_free 16.2 | wall 5978
2023-08-16 13:03:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 13:03:49 | INFO | fairseq.trainer | begin training epoch 6
2023-08-16 13:03:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 13:04:27 | INFO | train_inner | epoch 006:     37 / 1474 loss=2.478, trans_loss=3.557, nll_loss=1.782, w2v_ctc_loss=1.375, task_loss=0, contrastive_loss=0.319, total=4113.87, n_correct=2334.03, ppl=3.44, accuracy=56.736, wps=8622.4, ups=0.7, wpb=12276.7, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=0.601, clip=0, loss_scale=8, train_wall=80, gb_free=17.7, wall=6016
2023-08-16 13:05:47 | INFO | train_inner | epoch 006:    137 / 1474 loss=2.43, trans_loss=3.528, nll_loss=1.746, w2v_ctc_loss=1.32, task_loss=0, contrastive_loss=0.355, total=4161.2, n_correct=2393.4, ppl=3.35, accuracy=57.517, wps=15565.6, ups=1.25, wpb=12428.5, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=0.592, clip=0, loss_scale=8, train_wall=79, gb_free=16.8, wall=6096
2023-08-16 13:07:07 | INFO | train_inner | epoch 006:    237 / 1474 loss=2.432, trans_loss=3.538, nll_loss=1.76, w2v_ctc_loss=1.356, task_loss=0, contrastive_loss=0.265, total=4110.12, n_correct=2352.98, ppl=3.39, accuracy=57.248, wps=15266.5, ups=1.24, wpb=12279.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.583, clip=0, loss_scale=8, train_wall=80, gb_free=17, wall=6177
2023-08-16 13:08:29 | INFO | train_inner | epoch 006:    337 / 1474 loss=2.471, trans_loss=3.525, nll_loss=1.743, w2v_ctc_loss=1.306, task_loss=0, contrastive_loss=0.573, total=4170.52, n_correct=2408.26, ppl=3.35, accuracy=57.745, wps=15311.2, ups=1.23, wpb=12453.1, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=0.608, clip=0, loss_scale=8, train_wall=81, gb_free=15.6, wall=6258
2023-08-16 13:09:48 | INFO | train_inner | epoch 006:    437 / 1474 loss=2.397, trans_loss=3.523, nll_loss=1.74, w2v_ctc_loss=1.311, task_loss=0, contrastive_loss=0.275, total=4154.89, n_correct=2410.4, ppl=3.34, accuracy=58.014, wps=15619.4, ups=1.26, wpb=12405.6, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.576, clip=0, loss_scale=8, train_wall=79, gb_free=16.3, wall=6337
2023-08-16 13:11:08 | INFO | train_inner | epoch 006:    537 / 1474 loss=2.397, trans_loss=3.523, nll_loss=1.739, w2v_ctc_loss=1.322, task_loss=0, contrastive_loss=0.264, total=4174.46, n_correct=2426.11, ppl=3.34, accuracy=58.118, wps=15660.1, ups=1.26, wpb=12460.1, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.579, clip=0, loss_scale=8, train_wall=79, gb_free=17.1, wall=6417
2023-08-16 13:12:28 | INFO | train_inner | epoch 006:    637 / 1474 loss=2.401, trans_loss=3.525, nll_loss=1.742, w2v_ctc_loss=1.306, task_loss=0, contrastive_loss=0.314, total=4145.19, n_correct=2406.65, ppl=3.34, accuracy=58.059, wps=15446.3, ups=1.25, wpb=12372.7, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.583, clip=0, loss_scale=8, train_wall=80, gb_free=15.7, wall=6497
2023-08-16 13:12:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 13:12:51 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.411 | trans_loss 5.444 | nll_loss 2.781 | w2v_ctc_loss 1.605 | task_loss 0 | contrastive_loss 0.417 | total 4003.4 | n_correct 2481.2 | ppl 6.87 | accuracy 61.977 | uer 23.261 | wer 24.928 | raw_wer 24.928 | bleu 18.69 | wps 2323.8 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 18.69
2023-08-16 13:12:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-16 13:12:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-16 13:12:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-16 13:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 18.69) (writing took 53.44534905999899 seconds)
2023-08-16 13:15:06 | INFO | train_inner | epoch 006:    737 / 1474 loss=2.391, trans_loss=3.523, nll_loss=1.74, w2v_ctc_loss=1.318, task_loss=0, contrastive_loss=0.266, total=4151.01, n_correct=2413.89, ppl=3.34, accuracy=58.152, wps=7825.4, ups=0.63, wpb=12393.7, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.57, clip=0, loss_scale=8, train_wall=81, gb_free=13, wall=6655
2023-08-16 13:16:27 | INFO | train_inner | epoch 006:    837 / 1474 loss=2.379, trans_loss=3.524, nll_loss=1.741, w2v_ctc_loss=1.312, task_loss=0, contrastive_loss=0.245, total=4108.83, n_correct=2388.15, ppl=3.34, accuracy=58.122, wps=15141.2, ups=1.23, wpb=12267.1, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.569, clip=0, loss_scale=8, train_wall=80, gb_free=17, wall=6736
2023-08-16 13:17:48 | INFO | train_inner | epoch 006:    937 / 1474 loss=2.402, trans_loss=3.525, nll_loss=1.742, w2v_ctc_loss=1.312, task_loss=0, contrastive_loss=0.343, total=4076.46, n_correct=2369.02, ppl=3.34, accuracy=58.115, wps=15084.3, ups=1.24, wpb=12166, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.575, clip=0, loss_scale=8, train_wall=80, gb_free=12.7, wall=6817
2023-08-16 13:19:09 | INFO | train_inner | epoch 006:   1037 / 1474 loss=2.4, trans_loss=3.51, nll_loss=1.724, w2v_ctc_loss=1.291, task_loss=0, contrastive_loss=0.414, total=4175.9, n_correct=2445.03, ppl=3.3, accuracy=58.551, wps=15402.5, ups=1.24, wpb=12465, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.586, clip=0, loss_scale=8, train_wall=80, gb_free=14.2, wall=6898
2023-08-16 13:20:28 | INFO | train_inner | epoch 006:   1137 / 1474 loss=2.362, trans_loss=3.51, nll_loss=1.724, w2v_ctc_loss=1.3, task_loss=0, contrastive_loss=0.246, total=4077.2, n_correct=2384.42, ppl=3.3, accuracy=58.482, wps=15279.6, ups=1.26, wpb=12172.7, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.562, clip=0, loss_scale=8, train_wall=79, gb_free=16.2, wall=6978
2023-08-16 13:21:49 | INFO | train_inner | epoch 006:   1237 / 1474 loss=2.417, trans_loss=3.501, nll_loss=1.714, w2v_ctc_loss=1.281, task_loss=0, contrastive_loss=0.569, total=4133.46, n_correct=2427.35, ppl=3.28, accuracy=58.724, wps=15319, ups=1.24, wpb=12346.4, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.568, clip=0, loss_scale=8, train_wall=80, gb_free=12.4, wall=7058
2023-08-16 13:23:09 | INFO | train_inner | epoch 006:   1337 / 1474 loss=2.336, trans_loss=3.504, nll_loss=1.714, w2v_ctc_loss=1.282, task_loss=0, contrastive_loss=0.226, total=4127.77, n_correct=2433.24, ppl=3.28, accuracy=58.948, wps=15376, ups=1.25, wpb=12312.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.553, clip=0, loss_scale=8, train_wall=80, gb_free=16.9, wall=7138
2023-08-16 13:24:30 | INFO | train_inner | epoch 006:   1437 / 1474 loss=2.333, trans_loss=3.498, nll_loss=1.708, w2v_ctc_loss=1.277, task_loss=0, contrastive_loss=0.231, total=4190.32, n_correct=2476.84, ppl=3.27, accuracy=59.109, wps=15534.8, ups=1.24, wpb=12507.6, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.552, clip=0, loss_scale=8, train_wall=80, gb_free=16.8, wall=7219
2023-08-16 13:24:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 13:25:22 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.337 | trans_loss 5.385 | nll_loss 2.71 | w2v_ctc_loss 1.521 | task_loss 0 | contrastive_loss 0.396 | total 4003.4 | n_correct 2512.9 | ppl 6.54 | accuracy 62.769 | uer 22.13 | wer 23.936 | raw_wer 23.936 | bleu 19.43 | wps 2178.1 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 19.43
2023-08-16 13:25:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-08-16 13:25:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 13:25:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 13:25:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 6 @ 8837 updates, score 19.43) (writing took 33.15414777211845 seconds)
2023-08-16 13:25:55 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-16 13:25:55 | INFO | train | epoch 006 | loss 2.395 | trans_loss 3.518 | nll_loss 1.734 | w2v_ctc_loss 1.306 | task_loss 0 | contrastive_loss 0.327 | total 4138.65 | n_correct 2409.27 | ppl 3.33 | accuracy 58.214 | wps 13735.4 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 8837 | lr 0.00015044 | gnorm 0.575 | clip 0 | loss_scale 8 | train_wall 1177 | gb_free 15.1 | wall 7304
2023-08-16 13:25:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 13:25:55 | INFO | fairseq.trainer | begin training epoch 7
2023-08-16 13:25:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 13:26:54 | INFO | train_inner | epoch 007:     63 / 1474 loss=2.3, trans_loss=3.482, nll_loss=1.689, w2v_ctc_loss=1.244, task_loss=0, contrastive_loss=0.244, total=4110.43, n_correct=2447.19, ppl=3.22, accuracy=59.536, wps=8514.9, ups=0.69, wpb=12272.9, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.553, clip=0, loss_scale=8, train_wall=79, gb_free=17.2, wall=7363
2023-08-16 13:28:13 | INFO | train_inner | epoch 007:    163 / 1474 loss=2.306, trans_loss=3.475, nll_loss=1.678, w2v_ctc_loss=1.236, task_loss=0, contrastive_loss=0.315, total=4109.53, n_correct=2457.17, ppl=3.2, accuracy=59.792, wps=15403.1, ups=1.26, wpb=12269.6, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.551, clip=0, loss_scale=8, train_wall=79, gb_free=13.6, wall=7443
2023-08-16 13:29:34 | INFO | train_inner | epoch 007:    263 / 1474 loss=2.28, trans_loss=3.469, nll_loss=1.67, w2v_ctc_loss=1.235, task_loss=0, contrastive_loss=0.221, total=4133.29, n_correct=2477.69, ppl=3.18, accuracy=59.945, wps=15200.3, ups=1.23, wpb=12335.8, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.553, clip=0, loss_scale=8, train_wall=81, gb_free=15.3, wall=7524
2023-08-16 13:30:55 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.334, trans_loss=3.476, nll_loss=1.679, w2v_ctc_loss=1.227, task_loss=0, contrastive_loss=0.485, total=4194.76, n_correct=2506.34, ppl=3.2, accuracy=59.749, wps=15581.7, ups=1.24, wpb=12518.2, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.553, clip=0, loss_scale=8, train_wall=80, gb_free=13.1, wall=7604
2023-08-16 13:32:15 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.309, trans_loss=3.472, nll_loss=1.676, w2v_ctc_loss=1.221, task_loss=0, contrastive_loss=0.399, total=4153.22, n_correct=2487.3, ppl=3.2, accuracy=59.888, wps=15489.6, ups=1.25, wpb=12403.3, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.549, clip=0, loss_scale=8, train_wall=80, gb_free=16.8, wall=7684
2023-08-16 13:33:34 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.27, trans_loss=3.468, nll_loss=1.668, w2v_ctc_loss=1.222, task_loss=0, contrastive_loss=0.227, total=4168.14, n_correct=2510.08, ppl=3.18, accuracy=60.221, wps=15721.1, ups=1.26, wpb=12434.7, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.545, clip=0, loss_scale=16, train_wall=79, gb_free=16.8, wall=7763
2023-08-16 13:34:55 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.258, trans_loss=3.466, nll_loss=1.666, w2v_ctc_loss=1.217, task_loss=0, contrastive_loss=0.211, total=4157.82, n_correct=2508.45, ppl=3.17, accuracy=60.331, wps=15336.4, ups=1.24, wpb=12406.4, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.541, clip=0, loss_scale=16, train_wall=80, gb_free=15.6, wall=7844
2023-08-16 13:36:16 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.255, trans_loss=3.46, nll_loss=1.66, w2v_ctc_loss=1.216, task_loss=0, contrastive_loss=0.205, total=4122.1, n_correct=2481.81, ppl=3.16, accuracy=60.207, wps=15257.2, ups=1.24, wpb=12308.4, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.54, clip=0, loss_scale=16, train_wall=80, gb_free=15.5, wall=7925
2023-08-16 13:37:36 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.26, trans_loss=3.467, nll_loss=1.668, w2v_ctc_loss=1.216, task_loss=0, contrastive_loss=0.226, total=4147.23, n_correct=2495.69, ppl=3.18, accuracy=60.177, wps=15346.1, ups=1.24, wpb=12377.6, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.54, clip=0, loss_scale=16, train_wall=80, gb_free=17.4, wall=8006
2023-08-16 13:38:56 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.273, trans_loss=3.459, nll_loss=1.659, w2v_ctc_loss=1.203, task_loss=0, contrastive_loss=0.32, total=4140.14, n_correct=2497.77, ppl=3.16, accuracy=60.331, wps=15469.8, ups=1.25, wpb=12359.1, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.547, clip=0, loss_scale=16, train_wall=79, gb_free=15.9, wall=8085
2023-08-16 13:40:16 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.247, trans_loss=3.468, nll_loss=1.67, w2v_ctc_loss=1.217, task_loss=0, contrastive_loss=0.189, total=4103.51, n_correct=2469.94, ppl=3.18, accuracy=60.191, wps=15311.9, ups=1.25, wpb=12251.1, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.538, clip=0, loss_scale=16, train_wall=80, gb_free=16.8, wall=8165
2023-08-16 13:41:36 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.3, trans_loss=3.452, nll_loss=1.653, w2v_ctc_loss=1.203, task_loss=0, contrastive_loss=0.445, total=4137.04, n_correct=2502.7, ppl=3.15, accuracy=60.495, wps=15391.7, ups=1.25, wpb=12361.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.545, clip=0, loss_scale=16, train_wall=80, gb_free=16, wall=8246
2023-08-16 13:41:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 13:42:01 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.27 | trans_loss 5.323 | nll_loss 2.634 | w2v_ctc_loss 1.466 | task_loss 0 | contrastive_loss 0.376 | total 4003.4 | n_correct 2552 | ppl 6.21 | accuracy 63.746 | uer 20.861 | wer 22.717 | raw_wer 22.717 | bleu 20 | wps 2233.6 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 20
2023-08-16 13:42:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-16 13:42:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-16 13:42:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-16 13:42:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 20.0) (writing took 57.462173745036125 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:0')
2023-08-16 13:44:18 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.234, trans_loss=3.455, nll_loss=1.655, w2v_ctc_loss=1.198, task_loss=0, contrastive_loss=0.215, total=4129.52, n_correct=2498.92, ppl=3.15, accuracy=60.514, wps=7654.9, ups=0.62, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.448, clip=0, loss_scale=16, train_wall=79, gb_free=16.7, wall=8407
2023-08-16 13:45:37 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.256, trans_loss=3.45, nll_loss=1.647, w2v_ctc_loss=1.211, task_loss=0, contrastive_loss=0.25, total=4172.87, n_correct=2537.09, ppl=3.13, accuracy=60.8, wps=15675.2, ups=1.26, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.456, clip=0, loss_scale=16, train_wall=79, gb_free=17.1, wall=8486
2023-08-16 13:46:59 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.261, trans_loss=3.453, nll_loss=1.654, w2v_ctc_loss=1.206, task_loss=0, contrastive_loss=0.314, total=4109.42, n_correct=2486.51, ppl=3.15, accuracy=60.508, wps=15064.6, ups=1.23, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.451, clip=0, loss_scale=16, train_wall=81, gb_free=16.4, wall=8568
2023-08-16 13:47:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:4')
2023-08-16 13:47:29 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.263 | trans_loss 5.311 | nll_loss 2.617 | w2v_ctc_loss 1.483 | task_loss 0 | contrastive_loss 0.366 | total 4003.4 | n_correct 2557.8 | ppl 6.13 | accuracy 63.891 | uer 21.121 | wer 23.023 | raw_wer 23.023 | bleu 20.04 | wps 2207.3 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 20.04
2023-08-16 13:47:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-08-16 13:47:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 13:47:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 13:48:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 7 @ 10311 updates, score 20.04) (writing took 33.15706842392683 seconds)
2023-08-16 13:48:02 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-16 13:48:02 | INFO | train | epoch 007 | loss 2.275 | trans_loss 3.464 | nll_loss 1.665 | w2v_ctc_loss 1.217 | task_loss 0 | contrastive_loss 0.286 | total 4138.65 | n_correct 2491.78 | ppl 3.17 | accuracy 60.208 | wps 13722.3 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 10311 | lr 0.000139272 | gnorm 0.526 | clip 0 | loss_scale 16 | train_wall 1175 | gb_free 13.3 | wall 8632
2023-08-16 13:48:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 13:48:03 | INFO | fairseq.trainer | begin training epoch 8
2023-08-16 13:48:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 13:49:22 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.201, trans_loss=3.442, nll_loss=1.633, w2v_ctc_loss=1.167, task_loss=0, contrastive_loss=0.207, total=4116.25, n_correct=2518.58, ppl=3.1, accuracy=61.186, wps=8541.9, ups=0.7, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.453, clip=0, loss_scale=16, train_wall=79, gb_free=16.9, wall=8712
2023-08-16 13:50:41 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.2, trans_loss=3.433, nll_loss=1.622, w2v_ctc_loss=1.165, task_loss=0, contrastive_loss=0.227, total=4037.23, n_correct=2475.81, ppl=3.08, accuracy=61.324, wps=15200.3, ups=1.26, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.464, clip=0, loss_scale=16, train_wall=79, gb_free=12.8, wall=8791
2023-08-16 13:52:01 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.198, trans_loss=3.426, nll_loss=1.616, w2v_ctc_loss=1.163, task_loss=0, contrastive_loss=0.221, total=4207.78, n_correct=2589.57, ppl=3.06, accuracy=61.542, wps=15712.2, ups=1.25, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.446, clip=0, loss_scale=16, train_wall=79, gb_free=13.1, wall=8871
2023-08-16 13:53:23 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.211, trans_loss=3.432, nll_loss=1.622, w2v_ctc_loss=1.176, task_loss=0, contrastive_loss=0.246, total=4127.24, n_correct=2528.65, ppl=3.08, accuracy=61.267, wps=15146.6, ups=1.23, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.453, clip=0, loss_scale=16, train_wall=81, gb_free=11.9, wall=8952
2023-08-16 13:54:44 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.268, trans_loss=3.429, nll_loss=1.62, w2v_ctc_loss=1.155, task_loss=0, contrastive_loss=0.503, total=4203.76, n_correct=2582.36, ppl=3.07, accuracy=61.43, wps=15471.2, ups=1.23, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.449, clip=0, loss_scale=16, train_wall=81, gb_free=14.5, wall=9033
2023-08-16 13:56:04 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.193, trans_loss=3.427, nll_loss=1.621, w2v_ctc_loss=1.175, task_loss=0, contrastive_loss=0.181, total=4062.5, n_correct=2490.2, ppl=3.08, accuracy=61.297, wps=15194.1, ups=1.25, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.448, clip=0, loss_scale=16, train_wall=79, gb_free=11.5, wall=9113
2023-08-16 13:57:24 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.187, trans_loss=3.422, nll_loss=1.611, w2v_ctc_loss=1.169, task_loss=0, contrastive_loss=0.19, total=4142.78, n_correct=2554.94, ppl=3.06, accuracy=61.672, wps=15417.7, ups=1.25, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.446, clip=0, loss_scale=16, train_wall=80, gb_free=15.7, wall=9193
2023-08-16 13:58:45 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.198, trans_loss=3.418, nll_loss=1.61, w2v_ctc_loss=1.16, task_loss=0, contrastive_loss=0.274, total=4118.9, n_correct=2539.86, ppl=3.05, accuracy=61.664, wps=15244, ups=1.24, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.447, clip=0, loss_scale=16, train_wall=80, gb_free=15.1, wall=9274
2023-08-16 14:00:05 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.199, trans_loss=3.422, nll_loss=1.613, w2v_ctc_loss=1.15, task_loss=0, contrastive_loss=0.284, total=4169.01, n_correct=2572.86, ppl=3.06, accuracy=61.714, wps=15478.1, ups=1.24, wpb=12452.5, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.457, clip=0, loss_scale=16, train_wall=80, gb_free=16.1, wall=9354
2023-08-16 14:01:25 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.169, trans_loss=3.42, nll_loss=1.61, w2v_ctc_loss=1.149, task_loss=0, contrastive_loss=0.183, total=4154.69, n_correct=2569.83, ppl=3.05, accuracy=61.854, wps=15567.5, ups=1.26, wpb=12403.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.443, clip=0, loss_scale=16, train_wall=79, gb_free=17.6, wall=9434
2023-08-16 14:02:46 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.216, trans_loss=3.424, nll_loss=1.614, w2v_ctc_loss=1.149, task_loss=0, contrastive_loss=0.407, total=4199.1, n_correct=2585.92, ppl=3.06, accuracy=61.583, wps=15497.7, ups=1.24, wpb=12534.3, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.443, clip=0, loss_scale=32, train_wall=80, gb_free=12.7, wall=9515
2023-08-16 14:04:06 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.173, trans_loss=3.414, nll_loss=1.603, w2v_ctc_loss=1.15, task_loss=0, contrastive_loss=0.192, total=4177.31, n_correct=2585.72, ppl=3.04, accuracy=61.899, wps=15597.2, ups=1.25, wpb=12476.3, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.441, clip=0, loss_scale=32, train_wall=80, gb_free=14.9, wall=9595
2023-08-16 14:05:25 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.184, trans_loss=3.418, nll_loss=1.608, w2v_ctc_loss=1.164, task_loss=0, contrastive_loss=0.217, total=4063.85, n_correct=2505.25, ppl=3.05, accuracy=61.647, wps=15280.1, ups=1.26, wpb=12140.6, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.451, clip=0, loss_scale=32, train_wall=79, gb_free=16.8, wall=9674
2023-08-16 14:06:45 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.19, trans_loss=3.422, nll_loss=1.613, w2v_ctc_loss=1.15, task_loss=0, contrastive_loss=0.262, total=4141.5, n_correct=2558.58, ppl=3.06, accuracy=61.779, wps=15566.8, ups=1.26, wpb=12367.2, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.442, clip=0, loss_scale=32, train_wall=79, gb_free=16.4, wall=9754
2023-08-16 14:07:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 14:08:15 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.203 | trans_loss 5.26 | nll_loss 2.55 | w2v_ctc_loss 1.417 | task_loss 0 | contrastive_loss 0.354 | total 4003.4 | n_correct 2591.9 | ppl 5.86 | accuracy 64.742 | uer 20.174 | wer 22.028 | raw_wer 22.028 | bleu 20.48 | wps 2366.9 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 20.48
2023-08-16 14:08:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-08-16 14:08:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 14:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 14:08:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 11785 updates, score 20.48) (writing took 35.27103481814265 seconds)
2023-08-16 14:08:50 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-16 14:08:50 | INFO | train | epoch 008 | loss 2.199 | trans_loss 3.425 | nll_loss 1.615 | w2v_ctc_loss 1.159 | task_loss 0 | contrastive_loss 0.263 | total 4138.65 | n_correct 2548.91 | ppl 3.06 | accuracy 61.588 | wps 14592 | ups 1.18 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.448 | clip 0 | loss_scale 32 | train_wall 1174 | gb_free 16.9 | wall 9880
2023-08-16 14:08:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 14:08:51 | INFO | fairseq.trainer | begin training epoch 9
2023-08-16 14:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 14:09:11 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.196, trans_loss=3.416, nll_loss=1.603, w2v_ctc_loss=1.132, task_loss=0, contrastive_loss=0.394, total=4139.35, n_correct=2569.16, ppl=3.04, accuracy=62.067, wps=8424.9, ups=0.68, wpb=12350.9, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.439, clip=0, loss_scale=32, train_wall=80, gb_free=15.5, wall=9901
2023-08-16 14:10:31 | INFO | train_inner | epoch 009:    115 / 1474 loss=2.131, trans_loss=3.39, nll_loss=1.571, w2v_ctc_loss=1.108, task_loss=0, contrastive_loss=0.207, total=4181.9, n_correct=2625.63, ppl=2.97, accuracy=62.786, wps=15572, ups=1.25, wpb=12488.1, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.438, clip=0, loss_scale=32, train_wall=80, gb_free=16.1, wall=9981
2023-08-16 14:11:52 | INFO | train_inner | epoch 009:    215 / 1474 loss=2.121, trans_loss=3.395, nll_loss=1.577, w2v_ctc_loss=1.111, task_loss=0, contrastive_loss=0.165, total=4062.07, n_correct=2541.94, ppl=2.98, accuracy=62.577, wps=15117, ups=1.25, wpb=12129.1, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.44, clip=0, loss_scale=32, train_wall=80, gb_free=15.5, wall=10061
2023-08-16 14:11:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 14:12:13 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.201 | trans_loss 5.27 | nll_loss 2.564 | w2v_ctc_loss 1.384 | task_loss 0 | contrastive_loss 0.354 | total 4003.4 | n_correct 2587.2 | ppl 5.91 | accuracy 64.625 | uer 20.418 | wer 22.412 | raw_wer 22.412 | bleu 20.46 | wps 2391.8 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 20.48
2023-08-16 14:12:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-16 14:12:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-16 14:12:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-16 14:12:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 20.46) (writing took 26.78237786144018 seconds)
2023-08-16 14:14:01 | INFO | train_inner | epoch 009:    315 / 1474 loss=2.12, trans_loss=3.382, nll_loss=1.563, w2v_ctc_loss=1.095, task_loss=0, contrastive_loss=0.214, total=4152.1, n_correct=2612, ppl=2.96, accuracy=62.908, wps=9627.5, ups=0.78, wpb=12407.3, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.438, clip=0, loss_scale=32, train_wall=79, gb_free=16.3, wall=10190
2023-08-16 14:15:22 | INFO | train_inner | epoch 009:    415 / 1474 loss=2.122, trans_loss=3.397, nll_loss=1.58, w2v_ctc_loss=1.104, task_loss=0, contrastive_loss=0.181, total=4203.78, n_correct=2630.16, ppl=2.99, accuracy=62.567, wps=15483.2, ups=1.23, wpb=12551.8, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.435, clip=0, loss_scale=32, train_wall=81, gb_free=17, wall=10271
2023-08-16 14:16:42 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.151, trans_loss=3.397, nll_loss=1.579, w2v_ctc_loss=1.129, task_loss=0, contrastive_loss=0.232, total=4112.78, n_correct=2569, ppl=2.99, accuracy=62.464, wps=15314.2, ups=1.25, wpb=12275.6, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.439, clip=0, loss_scale=32, train_wall=80, gb_free=16.1, wall=10351
2023-08-16 14:18:02 | INFO | train_inner | epoch 009:    615 / 1474 loss=2.114, trans_loss=3.389, nll_loss=1.573, w2v_ctc_loss=1.097, task_loss=0, contrastive_loss=0.191, total=4131.32, n_correct=2591.18, ppl=2.98, accuracy=62.72, wps=15458.5, ups=1.25, wpb=12347.4, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.44, clip=0, loss_scale=32, train_wall=79, gb_free=17.6, wall=10431
2023-08-16 14:19:21 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.153, trans_loss=3.398, nll_loss=1.582, w2v_ctc_loss=1.125, task_loss=0, contrastive_loss=0.272, total=4082.11, n_correct=2549.29, ppl=2.99, accuracy=62.45, wps=15404, ups=1.26, wpb=12194.8, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.444, clip=0, loss_scale=32, train_wall=79, gb_free=16.9, wall=10510
2023-08-16 14:19:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-16 14:20:43 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.153, trans_loss=3.389, nll_loss=1.573, w2v_ctc_loss=1.118, task_loss=0, contrastive_loss=0.271, total=4197.6, n_correct=2630.27, ppl=2.97, accuracy=62.661, wps=15346, ups=1.22, wpb=12543.8, bsz=489.3, num_updates=12600, lr=0.000125988, gnorm=0.444, clip=0, loss_scale=16, train_wall=81, gb_free=14.3, wall=10592
2023-08-16 14:22:03 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.162, trans_loss=3.395, nll_loss=1.576, w2v_ctc_loss=1.111, task_loss=0, contrastive_loss=0.395, total=4146.05, n_correct=2596.1, ppl=2.98, accuracy=62.616, wps=15336.7, ups=1.24, wpb=12371.5, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.437, clip=0, loss_scale=16, train_wall=80, gb_free=17.7, wall=10673
2023-08-16 14:23:23 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.123, trans_loss=3.401, nll_loss=1.584, w2v_ctc_loss=1.114, task_loss=0, contrastive_loss=0.177, total=4101.48, n_correct=2562.35, ppl=3, accuracy=62.474, wps=15306.6, ups=1.25, wpb=12241.7, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.436, clip=0, loss_scale=16, train_wall=79, gb_free=15.9, wall=10753
2023-08-16 14:24:43 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.129, trans_loss=3.399, nll_loss=1.578, w2v_ctc_loss=1.11, task_loss=0, contrastive_loss=0.2, total=4179.09, n_correct=2621.72, ppl=2.99, accuracy=62.734, wps=15655.6, ups=1.26, wpb=12457.7, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.443, clip=0, loss_scale=16, train_wall=79, gb_free=15.2, wall=10832
2023-08-16 14:26:04 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.13, trans_loss=3.395, nll_loss=1.578, w2v_ctc_loss=1.121, task_loss=0, contrastive_loss=0.184, total=4140.66, n_correct=2587.46, ppl=2.99, accuracy=62.489, wps=15313, ups=1.24, wpb=12363.4, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.436, clip=0, loss_scale=16, train_wall=80, gb_free=17, wall=10913
2023-08-16 14:27:24 | INFO | train_inner | epoch 009:   1316 / 1474 loss=2.162, trans_loss=3.391, nll_loss=1.571, w2v_ctc_loss=1.1, task_loss=0, contrastive_loss=0.384, total=4204.43, n_correct=2641.54, ppl=2.97, accuracy=62.828, wps=15598.8, ups=1.24, wpb=12544.9, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.441, clip=0, loss_scale=16, train_wall=80, gb_free=17.6, wall=10993
2023-08-16 14:28:44 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.121, trans_loss=3.402, nll_loss=1.586, w2v_ctc_loss=1.117, task_loss=0, contrastive_loss=0.16, total=4069.19, n_correct=2544.52, ppl=3, accuracy=62.531, wps=15266.6, ups=1.26, wpb=12143.2, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.435, clip=0, loss_scale=16, train_wall=79, gb_free=16.5, wall=11073
2023-08-16 14:29:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 14:29:53 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.181 | trans_loss 5.24 | nll_loss 2.53 | w2v_ctc_loss 1.402 | task_loss 0 | contrastive_loss 0.345 | total 4003.4 | n_correct 2600.1 | ppl 5.78 | accuracy 64.947 | uer 19.767 | wer 21.733 | raw_wer 21.733 | bleu 20.73 | wps 2128 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 20.73
2023-08-16 14:29:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-08-16 14:29:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 14:30:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 14:30:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 9 @ 13258 updates, score 20.73) (writing took 30.164633395150304 seconds)
2023-08-16 14:30:24 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-16 14:30:24 | INFO | train | epoch 009 | loss 2.136 | trans_loss 3.394 | nll_loss 1.576 | w2v_ctc_loss 1.111 | task_loss 0 | contrastive_loss 0.236 | total 4137.17 | n_correct 2591.5 | ppl 2.98 | accuracy 62.64 | wps 14068.8 | ups 1.14 | wpb 12351.5 | bsz 457.7 | num_updates 13258 | lr 0.000122822 | gnorm 0.439 | clip 0 | loss_scale 16 | train_wall 1173 | gb_free 11.7 | wall 11173
2023-08-16 14:30:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 14:30:24 | INFO | fairseq.trainer | begin training epoch 10
2023-08-16 14:30:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 14:31:06 | INFO | train_inner | epoch 010:     42 / 1474 loss=2.119, trans_loss=3.384, nll_loss=1.563, w2v_ctc_loss=1.089, task_loss=0, contrastive_loss=0.254, total=4100.8, n_correct=2588.32, ppl=2.96, accuracy=63.117, wps=8589.6, ups=0.7, wpb=12238.2, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.44, clip=0, loss_scale=16, train_wall=79, gb_free=16.2, wall=11215
2023-08-16 14:32:27 | INFO | train_inner | epoch 010:    142 / 1474 loss=2.069, trans_loss=3.366, nll_loss=1.541, w2v_ctc_loss=1.057, task_loss=0, contrastive_loss=0.177, total=4247.35, n_correct=2701.52, ppl=2.91, accuracy=63.605, wps=15689.4, ups=1.24, wpb=12684.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.421, clip=0, loss_scale=16, train_wall=80, gb_free=11.9, wall=11296
2023-08-16 14:33:47 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.102, trans_loss=3.364, nll_loss=1.537, w2v_ctc_loss=1.07, task_loss=0, contrastive_loss=0.299, total=4122.82, n_correct=2625.63, ppl=2.9, accuracy=63.685, wps=15371.2, ups=1.25, wpb=12303.3, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.434, clip=0, loss_scale=16, train_wall=80, gb_free=16.2, wall=11376
2023-08-16 14:35:07 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.076, trans_loss=3.364, nll_loss=1.541, w2v_ctc_loss=1.063, task_loss=0, contrastive_loss=0.209, total=4138.27, n_correct=2630.82, ppl=2.91, accuracy=63.573, wps=15464.6, ups=1.25, wpb=12371, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.431, clip=0, loss_scale=16, train_wall=80, gb_free=16.3, wall=11456
2023-08-16 14:36:28 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.104, trans_loss=3.368, nll_loss=1.543, w2v_ctc_loss=1.05, task_loss=0, contrastive_loss=0.382, total=4196.37, n_correct=2667.36, ppl=2.91, accuracy=63.564, wps=15513.8, ups=1.24, wpb=12528, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.427, clip=0, loss_scale=16, train_wall=80, gb_free=16, wall=11537
2023-08-16 14:37:48 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.087, trans_loss=3.38, nll_loss=1.555, w2v_ctc_loss=1.087, task_loss=0, contrastive_loss=0.164, total=4102.8, n_correct=2595.72, ppl=2.94, accuracy=63.267, wps=15282.7, ups=1.25, wpb=12234.1, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.432, clip=0, loss_scale=16, train_wall=80, gb_free=16.9, wall=11617
2023-08-16 14:39:08 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.11, trans_loss=3.375, nll_loss=1.551, w2v_ctc_loss=1.077, task_loss=0, contrastive_loss=0.28, total=4176.56, n_correct=2646.39, ppl=2.93, accuracy=63.363, wps=15524, ups=1.25, wpb=12464, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.442, clip=0, loss_scale=16, train_wall=80, gb_free=16.2, wall=11697
2023-08-16 14:40:27 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.091, trans_loss=3.373, nll_loss=1.55, w2v_ctc_loss=1.092, task_loss=0, contrastive_loss=0.163, total=4125.87, n_correct=2612.83, ppl=2.93, accuracy=63.328, wps=15537.5, ups=1.26, wpb=12315.3, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.438, clip=0, loss_scale=16, train_wall=79, gb_free=14.5, wall=11777
2023-08-16 14:40:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 14:40:49 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.184 | trans_loss 5.224 | nll_loss 2.503 | w2v_ctc_loss 1.454 | task_loss 0 | contrastive_loss 0.345 | total 4003.4 | n_correct 2615.4 | ppl 5.67 | accuracy 65.329 | uer 19.675 | wer 21.45 | raw_wer 21.45 | bleu 21.04 | wps 2395.7 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 21.04
2023-08-16 14:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-16 14:40:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-16 14:40:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-16 14:41:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 21.04) (writing took 49.806391682475805 seconds)
2023-08-16 14:43:00 | INFO | train_inner | epoch 010:    842 / 1474 loss=2.065, trans_loss=3.37, nll_loss=1.546, w2v_ctc_loss=1.062, task_loss=0, contrastive_loss=0.163, total=4128.44, n_correct=2622.18, ppl=2.92, accuracy=63.515, wps=8072.2, ups=0.65, wpb=12327.8, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.428, clip=0, loss_scale=16, train_wall=79, gb_free=14.7, wall=11929
2023-08-16 14:44:20 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.087, trans_loss=3.369, nll_loss=1.542, w2v_ctc_loss=1.074, task_loss=0, contrastive_loss=0.202, total=4160.94, n_correct=2645.32, ppl=2.91, accuracy=63.575, wps=15488.1, ups=1.25, wpb=12411.1, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.433, clip=0, loss_scale=16, train_wall=80, gb_free=15.4, wall=12009
2023-08-16 14:45:40 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.079, trans_loss=3.37, nll_loss=1.546, w2v_ctc_loss=1.077, task_loss=0, contrastive_loss=0.175, total=4067.53, n_correct=2577.03, ppl=2.92, accuracy=63.356, wps=15136.4, ups=1.25, wpb=12145, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.442, clip=0, loss_scale=16, train_wall=80, gb_free=16.8, wall=12090
2023-08-16 14:46:59 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.086, trans_loss=3.378, nll_loss=1.555, w2v_ctc_loss=1.09, task_loss=0, contrastive_loss=0.16, total=4044.03, n_correct=2552.67, ppl=2.94, accuracy=63.122, wps=15298.7, ups=1.27, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.438, clip=0, loss_scale=16, train_wall=78, gb_free=17.1, wall=12169
2023-08-16 14:48:19 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.076, trans_loss=3.363, nll_loss=1.541, w2v_ctc_loss=1.084, task_loss=0, contrastive_loss=0.153, total=4110.41, n_correct=2606.29, ppl=2.91, accuracy=63.407, wps=15383.4, ups=1.25, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.439, clip=0, loss_scale=16, train_wall=79, gb_free=16.4, wall=12248
2023-08-16 14:49:40 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.075, trans_loss=3.37, nll_loss=1.547, w2v_ctc_loss=1.078, task_loss=0, contrastive_loss=0.163, total=4121.38, n_correct=2617.66, ppl=2.92, accuracy=63.514, wps=15229.8, ups=1.24, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.435, clip=0, loss_scale=32, train_wall=80, gb_free=14.1, wall=12329
2023-08-16 14:50:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-16 14:51:01 | INFO | train_inner | epoch 010:   1443 / 1474 loss=2.12, trans_loss=3.378, nll_loss=1.554, w2v_ctc_loss=1.06, task_loss=0, contrastive_loss=0.363, total=4186.84, n_correct=2653.67, ppl=2.94, accuracy=63.381, wps=15360.1, ups=1.23, wpb=12489.1, bsz=477.7, num_updates=14700, lr=0.000116642, gnorm=0.441, clip=0, loss_scale=16, train_wall=81, gb_free=16.3, wall=12411
2023-08-16 14:51:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 14:51:49 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.149 | trans_loss 5.216 | nll_loss 2.497 | w2v_ctc_loss 1.368 | task_loss 0 | contrastive_loss 0.335 | total 4003.4 | n_correct 2623.7 | ppl 5.65 | accuracy 65.537 | uer 18.852 | wer 20.708 | raw_wer 20.708 | bleu 20.9 | wps 2160.1 | wpb 4003.4 | bsz 141.8 | num_updates 14731 | best_bleu 21.04
2023-08-16 14:51:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14731 updates
2023-08-16 14:51:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_20.9002.pt
2023-08-16 14:51:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_20.9002.pt
2023-08-16 14:52:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_20.9002.pt (epoch 10 @ 14731 updates, score 20.9) (writing took 26.90255726315081 seconds)
2023-08-16 14:52:17 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-16 14:52:17 | INFO | train | epoch 010 | loss 2.089 | trans_loss 3.37 | nll_loss 1.546 | w2v_ctc_loss 1.072 | task_loss 0 | contrastive_loss 0.229 | total 4137.97 | n_correct 2625.78 | ppl 2.92 | accuracy 63.456 | wps 13857.8 | ups 1.12 | wpb 12353.8 | bsz 458.1 | num_updates 14731 | lr 0.00011652 | gnorm 0.434 | clip 0 | loss_scale 16 | train_wall 1173 | gb_free 17.1 | wall 12486
2023-08-16 14:52:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 14:52:17 | INFO | fairseq.trainer | begin training epoch 11
2023-08-16 14:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 14:53:19 | INFO | train_inner | epoch 011:     69 / 1474 loss=2.058, trans_loss=3.349, nll_loss=1.518, w2v_ctc_loss=1.043, task_loss=0, contrastive_loss=0.24, total=4166, n_correct=2675.49, ppl=2.86, accuracy=64.222, wps=9010.9, ups=0.72, wpb=12436.1, bsz=475.7, num_updates=14800, lr=0.000116248, gnorm=0.424, clip=0, loss_scale=16, train_wall=79, gb_free=17.7, wall=12549
2023-08-16 14:54:39 | INFO | train_inner | epoch 011:    169 / 1474 loss=2.041, trans_loss=3.351, nll_loss=1.522, w2v_ctc_loss=1.044, task_loss=0, contrastive_loss=0.161, total=4100.74, n_correct=2629.09, ppl=2.87, accuracy=64.113, wps=15352.8, ups=1.25, wpb=12251.1, bsz=450.6, num_updates=14900, lr=0.000115857, gnorm=0.428, clip=0, loss_scale=16, train_wall=79, gb_free=14.4, wall=12628
2023-08-16 14:55:59 | INFO | train_inner | epoch 011:    269 / 1474 loss=2.027, trans_loss=3.347, nll_loss=1.517, w2v_ctc_loss=1.035, task_loss=0, contrastive_loss=0.147, total=4115.58, n_correct=2638.5, ppl=2.86, accuracy=64.11, wps=15335.4, ups=1.25, wpb=12290.6, bsz=444.2, num_updates=15000, lr=0.00011547, gnorm=0.428, clip=0, loss_scale=16, train_wall=80, gb_free=16, wall=12709
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:0')
2023-08-16 14:56:56 | INFO | train_inner | epoch 011:    369 / 1474 loss=2.132, trans_loss=4.979, nll_loss=2.261, w2v_ctc_loss=0.785, task_loss=0, contrastive_loss=0.118, total=4094.16, n_correct=2622.56, ppl=4.79, accuracy=64.056, wps=14480.6, ups=1.76, wpb=8227.1, bsz=296.5, num_updates=15100, lr=0.000115087, gnorm=0.558, clip=0, loss_scale=16, train_wall=56, gb_free=13, wall=12765
2023-08-16 14:57:54 | INFO | train_inner | epoch 011:    469 / 1474 loss=2.155, trans_loss=5.012, nll_loss=2.283, w2v_ctc_loss=0.787, task_loss=0, contrastive_loss=0.242, total=4112.8, n_correct=2623.56, ppl=4.87, accuracy=63.79, wps=14307.1, ups=1.74, wpb=8225.6, bsz=302.2, num_updates=15200, lr=0.000114708, gnorm=0.558, clip=0, loss_scale=16, train_wall=57, gb_free=17.2, wall=12823
2023-08-16 14:58:52 | INFO | train_inner | epoch 011:    569 / 1474 loss=2.153, trans_loss=5.009, nll_loss=2.28, w2v_ctc_loss=0.795, task_loss=0, contrastive_loss=0.237, total=4071.06, n_correct=2598.52, ppl=4.86, accuracy=63.829, wps=14064.1, ups=1.73, wpb=8142.1, bsz=292.6, num_updates=15300, lr=0.000114332, gnorm=0.564, clip=0, loss_scale=16, train_wall=57, gb_free=16.4, wall=12881
2023-08-16 14:59:50 | INFO | train_inner | epoch 011:    669 / 1474 loss=2.154, trans_loss=5, nll_loss=2.268, w2v_ctc_loss=0.788, task_loss=0, contrastive_loss=0.296, total=4156.4, n_correct=2659.51, ppl=4.81, accuracy=63.986, wps=14108.4, ups=1.7, wpb=8312.8, bsz=310.2, num_updates=15400, lr=0.000113961, gnorm=0.554, clip=0, loss_scale=16, train_wall=58, gb_free=16.2, wall=12940
2023-08-16 15:00:49 | INFO | train_inner | epoch 011:    769 / 1474 loss=2.144, trans_loss=5.011, nll_loss=2.283, w2v_ctc_loss=0.801, task_loss=0, contrastive_loss=0.118, total=4169.17, n_correct=2667.95, ppl=4.87, accuracy=63.992, wps=14325.5, ups=1.72, wpb=8338.3, bsz=304.8, num_updates=15500, lr=0.000113592, gnorm=0.553, clip=0, loss_scale=16, train_wall=58, gb_free=12.4, wall=12998
2023-08-16 15:01:46 | INFO | train_inner | epoch 011:    869 / 1474 loss=2.14, trans_loss=5.011, nll_loss=2.282, w2v_ctc_loss=0.795, task_loss=0, contrastive_loss=0.108, total=4120.01, n_correct=2629.89, ppl=4.86, accuracy=63.832, wps=14395, ups=1.75, wpb=8240, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.556, clip=0, loss_scale=16, train_wall=57, gb_free=13.7, wall=13055
2023-08-16 15:02:44 | INFO | train_inner | epoch 011:    969 / 1474 loss=2.141, trans_loss=5.009, nll_loss=2.28, w2v_ctc_loss=0.796, task_loss=0, contrastive_loss=0.121, total=4145.45, n_correct=2650.17, ppl=4.86, accuracy=63.93, wps=14365.8, ups=1.73, wpb=8290.9, bsz=303.7, num_updates=15700, lr=0.000112867, gnorm=0.555, clip=0, loss_scale=16, train_wall=57, gb_free=17, wall=13113
2023-08-16 15:03:42 | INFO | train_inner | epoch 011:   1069 / 1474 loss=2.144, trans_loss=5.008, nll_loss=2.279, w2v_ctc_loss=0.799, task_loss=0, contrastive_loss=0.138, total=4141.18, n_correct=2648.98, ppl=4.85, accuracy=63.967, wps=14261.5, ups=1.72, wpb=8282.4, bsz=309.4, num_updates=15800, lr=0.000112509, gnorm=0.554, clip=0, loss_scale=16, train_wall=58, gb_free=16.6, wall=13171
2023-08-16 15:04:39 | INFO | train_inner | epoch 011:   1169 / 1474 loss=2.143, trans_loss=5.011, nll_loss=2.283, w2v_ctc_loss=0.802, task_loss=0, contrastive_loss=0.123, total=4173.93, n_correct=2666.67, ppl=4.87, accuracy=63.889, wps=14547.2, ups=1.74, wpb=8347.9, bsz=307.2, num_updates=15900, lr=0.000112154, gnorm=0.548, clip=0, loss_scale=16, train_wall=57, gb_free=16.9, wall=13228
2023-08-16 15:05:36 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.153, trans_loss=5.006, nll_loss=2.277, w2v_ctc_loss=0.802, task_loss=0, contrastive_loss=0.194, total=4174.26, n_correct=2666.77, ppl=4.85, accuracy=63.886, wps=14547.1, ups=1.74, wpb=8348.5, bsz=314.4, num_updates=16000, lr=0.000111803, gnorm=0.563, clip=0, loss_scale=16, train_wall=57, gb_free=17.5, wall=13286
2023-08-16 15:05:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:4')
2023-08-16 15:06:00 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.159 | trans_loss 5.21 | nll_loss 2.49 | w2v_ctc_loss 1.42 | task_loss 0 | contrastive_loss 0.33 | total 4003.4 | n_correct 2632.6 | ppl 5.62 | accuracy 65.759 | uer 18.714 | wer 20.629 | raw_wer 20.629 | bleu 21.12 | wps 2213.7 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 21.12
2023-08-16 15:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-16 15:06:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-16 15:06:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-16 15:06:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 21.12) (writing took 55.98588071204722 seconds)
2023-08-16 15:07:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-16 15:07:55 | INFO | train_inner | epoch 011:   1370 / 1474 loss=2.154, trans_loss=5.003, nll_loss=2.274, w2v_ctc_loss=0.787, task_loss=0, contrastive_loss=0.299, total=4165.99, n_correct=2664.1, ppl=4.84, accuracy=63.949, wps=5998.5, ups=0.72, wpb=8332, bsz=321, num_updates=16100, lr=0.000111456, gnorm=0.56, clip=0, loss_scale=8, train_wall=58, gb_free=17, wall=13425
2023-08-16 15:08:53 | INFO | train_inner | epoch 011:   1470 / 1474 loss=2.138, trans_loss=5.007, nll_loss=2.278, w2v_ctc_loss=0.792, task_loss=0, contrastive_loss=0.128, total=4162.97, n_correct=2665.99, ppl=4.85, accuracy=64.041, wps=14393.2, ups=1.73, wpb=8325.9, bsz=313, num_updates=16200, lr=0.000111111, gnorm=0.557, clip=0, loss_scale=8, train_wall=57, gb_free=15, wall=13483
2023-08-16 15:08:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 15:09:17 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.139 | trans_loss 5.21 | nll_loss 2.487 | w2v_ctc_loss 1.344 | task_loss 0 | contrastive_loss 0.336 | total 4003.4 | n_correct 2631.7 | ppl 5.6 | accuracy 65.737 | uer 18.796 | wer 20.655 | raw_wer 20.655 | bleu 21.17 | wps 2462.7 | wpb 4003.4 | bsz 141.8 | num_updates 16204 | best_bleu 21.17
2023-08-16 15:09:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16204 updates
2023-08-16 15:09:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 15:09:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 15:09:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 11 @ 16204 updates, score 21.17) (writing took 31.930820321664214 seconds)
2023-08-16 15:09:50 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-16 15:09:50 | INFO | train | epoch 011 | loss 2.118 | trans_loss 4.591 | nll_loss 2.088 | w2v_ctc_loss 0.856 | task_loss 0 | contrastive_loss 0.171 | total 4137.21 | n_correct 2646.75 | ppl 4.25 | accuracy 63.974 | wps 12622.9 | ups 1.4 | wpb 9021.3 | bsz 333.1 | num_updates 16204 | lr 0.000111097 | gnorm 0.533 | clip 0 | loss_scale 8 | train_wall 903 | gb_free 17.3 | wall 13539
2023-08-16 15:09:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 15:09:50 | INFO | fairseq.trainer | begin training epoch 12
2023-08-16 15:09:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 15:10:52 | INFO | train_inner | epoch 012:     96 / 1474 loss=2.122, trans_loss=4.969, nll_loss=2.228, w2v_ctc_loss=0.778, task_loss=0, contrastive_loss=0.158, total=4145.21, n_correct=2680.08, ppl=4.68, accuracy=64.655, wps=6958, ups=0.84, wpb=8290.4, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.547, clip=0, loss_scale=8, train_wall=56, gb_free=16.9, wall=13602
2023-08-16 15:11:49 | INFO | train_inner | epoch 012:    196 / 1474 loss=2.118, trans_loss=4.973, nll_loss=2.232, w2v_ctc_loss=0.779, task_loss=0, contrastive_loss=0.108, total=4124.1, n_correct=2661.04, ppl=4.7, accuracy=64.524, wps=14517.5, ups=1.76, wpb=8248.2, bsz=296.1, num_updates=16400, lr=0.000110432, gnorm=0.544, clip=0, loss_scale=8, train_wall=56, gb_free=15.5, wall=13658
2023-08-16 15:12:47 | INFO | train_inner | epoch 012:    296 / 1474 loss=2.119, trans_loss=4.974, nll_loss=2.234, w2v_ctc_loss=0.77, task_loss=0, contrastive_loss=0.139, total=4208.07, n_correct=2722.33, ppl=4.71, accuracy=64.693, wps=14528.7, ups=1.73, wpb=8416.1, bsz=321.7, num_updates=16500, lr=0.000110096, gnorm=0.549, clip=0, loss_scale=8, train_wall=57, gb_free=12.6, wall=13716
2023-08-16 15:13:45 | INFO | train_inner | epoch 012:    396 / 1474 loss=2.119, trans_loss=4.977, nll_loss=2.239, w2v_ctc_loss=0.776, task_loss=0, contrastive_loss=0.123, total=4144.42, n_correct=2674.8, ppl=4.72, accuracy=64.54, wps=14418.5, ups=1.74, wpb=8288.8, bsz=305.3, num_updates=16600, lr=0.000109764, gnorm=0.556, clip=0, loss_scale=8, train_wall=57, gb_free=16.4, wall=13774
2023-08-16 15:14:42 | INFO | train_inner | epoch 012:    496 / 1474 loss=2.13, trans_loss=4.99, nll_loss=2.256, w2v_ctc_loss=0.789, task_loss=0, contrastive_loss=0.131, total=4095.26, n_correct=2639.43, ppl=4.78, accuracy=64.451, wps=14324.1, ups=1.75, wpb=8190.5, bsz=299.8, num_updates=16700, lr=0.000109435, gnorm=0.556, clip=0, loss_scale=8, train_wall=57, gb_free=17.7, wall=13831
2023-08-16 15:15:39 | INFO | train_inner | epoch 012:    596 / 1474 loss=2.129, trans_loss=4.976, nll_loss=2.238, w2v_ctc_loss=0.778, task_loss=0, contrastive_loss=0.195, total=4204.6, n_correct=2715.53, ppl=4.72, accuracy=64.585, wps=14583.2, ups=1.73, wpb=8409.2, bsz=319.2, num_updates=16800, lr=0.000109109, gnorm=0.558, clip=0, loss_scale=8, train_wall=57, gb_free=16.5, wall=13889
2023-08-16 15:16:37 | INFO | train_inner | epoch 012:    696 / 1474 loss=2.129, trans_loss=4.972, nll_loss=2.233, w2v_ctc_loss=0.767, task_loss=0, contrastive_loss=0.282, total=4197.19, n_correct=2717.32, ppl=4.7, accuracy=64.741, wps=14503.3, ups=1.73, wpb=8394.4, bsz=323.2, num_updates=16900, lr=0.000108786, gnorm=0.542, clip=0, loss_scale=8, train_wall=57, gb_free=16.7, wall=13947
2023-08-16 15:17:35 | INFO | train_inner | epoch 012:    796 / 1474 loss=2.118, trans_loss=4.973, nll_loss=2.233, w2v_ctc_loss=0.779, task_loss=0, contrastive_loss=0.121, total=4094.06, n_correct=2648.82, ppl=4.7, accuracy=64.699, wps=14217.2, ups=1.74, wpb=8188.1, bsz=298.2, num_updates=17000, lr=0.000108465, gnorm=0.567, clip=0, loss_scale=8, train_wall=57, gb_free=14.9, wall=14004
2023-08-16 15:18:32 | INFO | train_inner | epoch 012:    896 / 1474 loss=2.13, trans_loss=4.98, nll_loss=2.244, w2v_ctc_loss=0.783, task_loss=0, contrastive_loss=0.172, total=4163.5, n_correct=2686.82, ppl=4.74, accuracy=64.533, wps=14580.9, ups=1.75, wpb=8327, bsz=305.1, num_updates=17100, lr=0.000108148, gnorm=0.553, clip=0, loss_scale=8, train_wall=56, gb_free=13, wall=14061
2023-08-16 15:19:30 | INFO | train_inner | epoch 012:    996 / 1474 loss=2.13, trans_loss=4.982, nll_loss=2.246, w2v_ctc_loss=0.786, task_loss=0, contrastive_loss=0.182, total=4124.99, n_correct=2660.74, ppl=4.74, accuracy=64.503, wps=14373.4, ups=1.74, wpb=8250, bsz=302.7, num_updates=17200, lr=0.000107833, gnorm=0.551, clip=0, loss_scale=8, train_wall=57, gb_free=11.5, wall=14119
2023-08-16 15:20:27 | INFO | train_inner | epoch 012:   1096 / 1474 loss=2.138, trans_loss=4.986, nll_loss=2.251, w2v_ctc_loss=0.789, task_loss=0, contrastive_loss=0.224, total=4046.6, n_correct=2605.42, ppl=4.76, accuracy=64.385, wps=14104.5, ups=1.74, wpb=8093.2, bsz=289.8, num_updates=17300, lr=0.000107521, gnorm=0.557, clip=0, loss_scale=8, train_wall=57, gb_free=16.5, wall=14176
2023-08-16 15:21:25 | INFO | train_inner | epoch 012:   1196 / 1474 loss=2.146, trans_loss=5.002, nll_loss=2.272, w2v_ctc_loss=0.799, task_loss=0, contrastive_loss=0.193, total=4196.85, n_correct=2690.9, ppl=4.83, accuracy=64.117, wps=14528, ups=1.73, wpb=8393.7, bsz=319, num_updates=17400, lr=0.000107211, gnorm=0.552, clip=0, loss_scale=8, train_wall=57, gb_free=16.5, wall=14234
2023-08-16 15:22:22 | INFO | train_inner | epoch 012:   1296 / 1474 loss=2.128, trans_loss=4.985, nll_loss=2.25, w2v_ctc_loss=0.799, task_loss=0, contrastive_loss=0.105, total=4067.78, n_correct=2616.03, ppl=4.76, accuracy=64.311, wps=14313.2, ups=1.76, wpb=8135.6, bsz=285.5, num_updates=17500, lr=0.000106904, gnorm=0.559, clip=0, loss_scale=8, train_wall=56, gb_free=15.3, wall=14291
2023-08-16 15:23:19 | INFO | train_inner | epoch 012:   1396 / 1474 loss=2.136, trans_loss=4.994, nll_loss=2.262, w2v_ctc_loss=0.784, task_loss=0, contrastive_loss=0.21, total=4142.88, n_correct=2660.24, ppl=4.8, accuracy=64.212, wps=14489.4, ups=1.75, wpb=8285.8, bsz=306.2, num_updates=17600, lr=0.0001066, gnorm=0.548, clip=0, loss_scale=8, train_wall=57, gb_free=15.7, wall=14348
2023-08-16 15:24:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 15:24:26 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.143 | trans_loss 5.195 | nll_loss 2.471 | w2v_ctc_loss 1.405 | task_loss 0 | contrastive_loss 0.324 | total 4003.4 | n_correct 2635.7 | ppl 5.54 | accuracy 65.837 | uer 18.844 | wer 20.861 | raw_wer 20.861 | bleu 21.53 | wps 2312.8 | wpb 4003.4 | bsz 141.8 | num_updates 17678 | best_bleu 21.53
2023-08-16 15:24:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17678 updates
2023-08-16 15:24:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 15:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 15:25:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 12 @ 17678 updates, score 21.53) (writing took 35.047842936590314 seconds)
2023-08-16 15:25:02 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-16 15:25:02 | INFO | train | epoch 012 | loss 2.128 | trans_loss 4.981 | nll_loss 2.245 | w2v_ctc_loss 0.783 | task_loss 0 | contrastive_loss 0.165 | total 4138.65 | n_correct 2669.05 | ppl 4.74 | accuracy 64.491 | wps 13378.2 | ups 1.62 | wpb 8277.3 | bsz 305.7 | num_updates 17678 | lr 0.000106365 | gnorm 0.553 | clip 0 | loss_scale 8 | train_wall 837 | gb_free 13.1 | wall 14451
2023-08-16 15:25:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 15:25:02 | INFO | fairseq.trainer | begin training epoch 13
2023-08-16 15:25:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 15:25:25 | INFO | train_inner | epoch 013:     22 / 1474 loss=2.126, trans_loss=4.987, nll_loss=2.252, w2v_ctc_loss=0.793, task_loss=0, contrastive_loss=0.114, total=4097.08, n_correct=2638.92, ppl=4.76, accuracy=64.41, wps=6591.3, ups=0.8, wpb=8194.2, bsz=296.6, num_updates=17700, lr=0.000106299, gnorm=0.559, clip=0, loss_scale=8, train_wall=57, gb_free=16.5, wall=14472
2023-08-16 15:26:22 | INFO | train_inner | epoch 013:    122 / 1474 loss=2.107, trans_loss=4.957, nll_loss=2.213, w2v_ctc_loss=0.765, task_loss=0, contrastive_loss=0.127, total=4164.24, n_correct=2706.05, ppl=4.64, accuracy=64.983, wps=14445.1, ups=1.73, wpb=8328.5, bsz=301.9, num_updates=17800, lr=0.000106, gnorm=0.545, clip=0, loss_scale=8, train_wall=57, gb_free=17, wall=14532
2023-08-16 15:27:20 | INFO | train_inner | epoch 013:    222 / 1474 loss=2.132, trans_loss=4.963, nll_loss=2.222, w2v_ctc_loss=0.765, task_loss=0, contrastive_loss=0.341, total=4201.52, n_correct=2724, ppl=4.66, accuracy=64.834, wps=14628.9, ups=1.74, wpb=8403, bsz=328.5, num_updates=17900, lr=0.000105703, gnorm=0.55, clip=0, loss_scale=8, train_wall=57, gb_free=13.3, wall=14589
2023-08-16 15:28:17 | INFO | train_inner | epoch 013:    322 / 1474 loss=2.099, trans_loss=4.948, nll_loss=2.201, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.109, total=4102.53, n_correct=2673.05, ppl=4.6, accuracy=65.156, wps=14268.9, ups=1.74, wpb=8205.1, bsz=293.9, num_updates=18000, lr=0.000105409, gnorm=0.555, clip=0, loss_scale=8, train_wall=57, gb_free=16.2, wall=14646
2023-08-16 15:28:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 15:28:41 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.14 | trans_loss 5.203 | nll_loss 2.478 | w2v_ctc_loss 1.376 | task_loss 0 | contrastive_loss 0.327 | total 4003.4 | n_correct 2628.9 | ppl 5.57 | accuracy 65.667 | uer 19.274 | wer 21.185 | raw_wer 21.185 | bleu 21.58 | wps 2049.6 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 21.58
2023-08-16 15:28:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-16 15:28:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-16 15:28:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-16 15:29:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 21.58) (writing took 57.144496662542224 seconds)
2023-08-16 15:30:37 | INFO | train_inner | epoch 013:    422 / 1474 loss=2.108, trans_loss=4.953, nll_loss=2.207, w2v_ctc_loss=0.765, task_loss=0, contrastive_loss=0.157, total=4190.45, n_correct=2729.37, ppl=4.62, accuracy=65.133, wps=5984.3, ups=0.71, wpb=8380.9, bsz=320.3, num_updates=18100, lr=0.000105118, gnorm=0.547, clip=0, loss_scale=8, train_wall=57, gb_free=15.9, wall=14787
2023-08-16 15:31:35 | INFO | train_inner | epoch 013:    522 / 1474 loss=2.117, trans_loss=4.961, nll_loss=2.219, w2v_ctc_loss=0.773, task_loss=0, contrastive_loss=0.192, total=4194.45, n_correct=2722.16, ppl=4.65, accuracy=64.899, wps=14619.8, ups=1.74, wpb=8388.9, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.549, clip=0, loss_scale=16, train_wall=57, gb_free=17.3, wall=14844
2023-08-16 15:32:32 | INFO | train_inner | epoch 013:    622 / 1474 loss=2.1, trans_loss=4.956, nll_loss=2.212, w2v_ctc_loss=0.764, task_loss=0, contrastive_loss=0.106, total=4158.04, n_correct=2708.25, ppl=4.63, accuracy=65.133, wps=14597.4, ups=1.76, wpb=8316.1, bsz=306.7, num_updates=18300, lr=0.000104542, gnorm=0.559, clip=0, loss_scale=16, train_wall=56, gb_free=13.7, wall=14901
2023-08-16 15:33:29 | INFO | train_inner | epoch 013:    722 / 1474 loss=2.114, trans_loss=4.964, nll_loss=2.222, w2v_ctc_loss=0.788, task_loss=0, contrastive_loss=0.106, total=4099.91, n_correct=2654.73, ppl=4.66, accuracy=64.751, wps=14263.8, ups=1.74, wpb=8199.8, bsz=285.5, num_updates=18400, lr=0.000104257, gnorm=0.556, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=14958
2023-08-16 15:34:27 | INFO | train_inner | epoch 013:    822 / 1474 loss=2.115, trans_loss=4.965, nll_loss=2.224, w2v_ctc_loss=0.77, task_loss=0, contrastive_loss=0.153, total=4122.78, n_correct=2669.85, ppl=4.67, accuracy=64.758, wps=14154, ups=1.72, wpb=8245.6, bsz=306, num_updates=18500, lr=0.000103975, gnorm=0.568, clip=0, loss_scale=16, train_wall=58, gb_free=15, wall=15017
2023-08-16 15:35:24 | INFO | train_inner | epoch 013:    922 / 1474 loss=2.105, trans_loss=4.959, nll_loss=2.216, w2v_ctc_loss=0.769, task_loss=0, contrastive_loss=0.114, total=4102.59, n_correct=2668.51, ppl=4.65, accuracy=65.045, wps=14394.8, ups=1.75, wpb=8205.2, bsz=296.6, num_updates=18600, lr=0.000103695, gnorm=0.555, clip=0, loss_scale=16, train_wall=56, gb_free=17.3, wall=15074
2023-08-16 15:36:22 | INFO | train_inner | epoch 013:   1022 / 1474 loss=2.121, trans_loss=4.966, nll_loss=2.225, w2v_ctc_loss=0.784, task_loss=0, contrastive_loss=0.167, total=4087.8, n_correct=2644.52, ppl=4.68, accuracy=64.693, wps=14285.9, ups=1.75, wpb=8175.6, bsz=293.7, num_updates=18700, lr=0.000103418, gnorm=0.554, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=15131
2023-08-16 15:37:19 | INFO | train_inner | epoch 013:   1122 / 1474 loss=2.104, trans_loss=4.953, nll_loss=2.207, w2v_ctc_loss=0.764, task_loss=0, contrastive_loss=0.147, total=4098.77, n_correct=2669.84, ppl=4.62, accuracy=65.138, wps=14252.4, ups=1.74, wpb=8197.5, bsz=304.8, num_updates=18800, lr=0.000103142, gnorm=0.55, clip=0, loss_scale=16, train_wall=57, gb_free=13.8, wall=15188
2023-08-16 15:38:17 | INFO | train_inner | epoch 013:   1222 / 1474 loss=2.112, trans_loss=4.965, nll_loss=2.224, w2v_ctc_loss=0.78, task_loss=0, contrastive_loss=0.109, total=4115.57, n_correct=2670.91, ppl=4.67, accuracy=64.898, wps=14182.5, ups=1.72, wpb=8231.1, bsz=295.9, num_updates=18900, lr=0.000102869, gnorm=0.566, clip=0, loss_scale=16, train_wall=58, gb_free=15.2, wall=15246
2023-08-16 15:39:15 | INFO | train_inner | epoch 013:   1322 / 1474 loss=2.116, trans_loss=4.955, nll_loss=2.212, w2v_ctc_loss=0.774, task_loss=0, contrastive_loss=0.204, total=4111.02, n_correct=2675.94, ppl=4.63, accuracy=65.092, wps=14309.3, ups=1.74, wpb=8222, bsz=307.8, num_updates=19000, lr=0.000102598, gnorm=0.553, clip=0, loss_scale=16, train_wall=57, gb_free=17.9, wall=15304
2023-08-16 15:40:12 | INFO | train_inner | epoch 013:   1422 / 1474 loss=2.119, trans_loss=4.964, nll_loss=2.223, w2v_ctc_loss=0.767, task_loss=0, contrastive_loss=0.213, total=4179.06, n_correct=2712.13, ppl=4.67, accuracy=64.898, wps=14533.9, ups=1.74, wpb=8358.1, bsz=311.9, num_updates=19100, lr=0.000102329, gnorm=0.553, clip=0, loss_scale=16, train_wall=57, gb_free=16.1, wall=15361
2023-08-16 15:40:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 15:41:06 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.132 | trans_loss 5.189 | nll_loss 2.457 | w2v_ctc_loss 1.389 | task_loss 0 | contrastive_loss 0.325 | total 4003.4 | n_correct 2638.2 | ppl 5.49 | accuracy 65.899 | uer 18.687 | wer 20.544 | raw_wer 20.544 | bleu 21.39 | wps 2118.5 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 21.58
2023-08-16 15:41:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-08-16 15:41:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_21.3902.pt
2023-08-16 15:41:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_21.3902.pt
2023-08-16 15:41:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_21.3902.pt (epoch 13 @ 19152 updates, score 21.39) (writing took 23.372688015922904 seconds)
2023-08-16 15:41:29 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-16 15:41:29 | INFO | train | epoch 013 | loss 2.112 | trans_loss 4.959 | nll_loss 2.215 | w2v_ctc_loss 0.771 | task_loss 0 | contrastive_loss 0.161 | total 4138.65 | n_correct 2688.81 | ppl 4.64 | accuracy 64.968 | wps 12353.7 | ups 1.49 | wpb 8277.3 | bsz 305.7 | num_updates 19152 | lr 0.00010219 | gnorm 0.554 | clip 0 | loss_scale 16 | train_wall 840 | gb_free 17.7 | wall 15439
2023-08-16 15:41:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 15:41:29 | INFO | fairseq.trainer | begin training epoch 14
2023-08-16 15:41:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 15:42:05 | INFO | train_inner | epoch 014:     48 / 1474 loss=2.094, trans_loss=4.933, nll_loss=2.184, w2v_ctc_loss=0.761, task_loss=0, contrastive_loss=0.119, total=4179.66, n_correct=2736.74, ppl=4.54, accuracy=65.478, wps=7375.3, ups=0.88, wpb=8359.3, bsz=322, num_updates=19200, lr=0.000102062, gnorm=0.559, clip=0, loss_scale=16, train_wall=57, gb_free=10.9, wall=15475
2023-08-16 15:43:03 | INFO | train_inner | epoch 014:    148 / 1474 loss=2.081, trans_loss=4.921, nll_loss=2.167, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.1, total=4081.01, n_correct=2683.39, ppl=4.49, accuracy=65.753, wps=14224.5, ups=1.74, wpb=8162, bsz=300.6, num_updates=19300, lr=0.000101797, gnorm=0.543, clip=0, loss_scale=16, train_wall=57, gb_free=16, wall=15532
2023-08-16 15:44:00 | INFO | train_inner | epoch 014:    248 / 1474 loss=2.1, trans_loss=4.938, nll_loss=2.189, w2v_ctc_loss=0.759, task_loss=0, contrastive_loss=0.2, total=4109.83, n_correct=2688.37, ppl=4.56, accuracy=65.413, wps=14396.1, ups=1.75, wpb=8219.7, bsz=295.2, num_updates=19400, lr=0.000101535, gnorm=0.551, clip=0, loss_scale=16, train_wall=57, gb_free=15.7, wall=15589
2023-08-16 15:44:57 | INFO | train_inner | epoch 014:    348 / 1474 loss=2.091, trans_loss=4.936, nll_loss=2.187, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.135, total=4171.83, n_correct=2736.1, ppl=4.55, accuracy=65.585, wps=14603.3, ups=1.75, wpb=8343.7, bsz=319.7, num_updates=19500, lr=0.000101274, gnorm=0.551, clip=0, loss_scale=16, train_wall=57, gb_free=16.8, wall=15646
2023-08-16 15:45:55 | INFO | train_inner | epoch 014:    448 / 1474 loss=2.089, trans_loss=4.941, nll_loss=2.193, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.11, total=4142.75, n_correct=2708.83, ppl=4.57, accuracy=65.387, wps=14382.3, ups=1.74, wpb=8285.5, bsz=302.2, num_updates=19600, lr=0.000101015, gnorm=0.547, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=15704
2023-08-16 15:46:53 | INFO | train_inner | epoch 014:    548 / 1474 loss=2.103, trans_loss=4.943, nll_loss=2.195, w2v_ctc_loss=0.777, task_loss=0, contrastive_loss=0.121, total=4073.76, n_correct=2655.84, ppl=4.58, accuracy=65.194, wps=14067.6, ups=1.73, wpb=8147.5, bsz=290.9, num_updates=19700, lr=0.000100759, gnorm=0.564, clip=0, loss_scale=16, train_wall=57, gb_free=15.6, wall=15762
2023-08-16 15:47:51 | INFO | train_inner | epoch 014:    648 / 1474 loss=2.103, trans_loss=4.943, nll_loss=2.194, w2v_ctc_loss=0.763, task_loss=0, contrastive_loss=0.176, total=4158.79, n_correct=2715.85, ppl=4.58, accuracy=65.304, wps=14353.1, ups=1.73, wpb=8317.6, bsz=306.8, num_updates=19800, lr=0.000100504, gnorm=0.557, clip=0, loss_scale=16, train_wall=57, gb_free=17.3, wall=15820
2023-08-16 15:48:48 | INFO | train_inner | epoch 014:    748 / 1474 loss=2.092, trans_loss=4.932, nll_loss=2.181, w2v_ctc_loss=0.762, task_loss=0, contrastive_loss=0.109, total=4145.47, n_correct=2715.87, ppl=4.53, accuracy=65.514, wps=14490.9, ups=1.75, wpb=8290.9, bsz=309.6, num_updates=19900, lr=0.000100251, gnorm=0.547, clip=0, loss_scale=16, train_wall=57, gb_free=16.3, wall=15877
2023-08-16 15:49:45 | INFO | train_inner | epoch 014:    848 / 1474 loss=2.103, trans_loss=4.931, nll_loss=2.181, w2v_ctc_loss=0.755, task_loss=0, contrastive_loss=0.218, total=4171.1, n_correct=2730.66, ppl=4.53, accuracy=65.466, wps=14462.3, ups=1.73, wpb=8342.2, bsz=319.7, num_updates=20000, lr=0.0001, gnorm=0.553, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=15935
2023-08-16 15:49:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 15:50:10 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.136 | trans_loss 5.182 | nll_loss 2.45 | w2v_ctc_loss 1.424 | task_loss 0 | contrastive_loss 0.316 | total 4003.4 | n_correct 2642.4 | ppl 5.46 | accuracy 66.004 | uer 18.642 | wer 20.588 | raw_wer 20.588 | bleu 21.45 | wps 2050.4 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21.58
2023-08-16 15:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-16 15:50:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-16 15:50:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-16 15:50:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.45) (writing took 43.6371114179492 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:0')
2023-08-16 15:51:55 | INFO | train_inner | epoch 014:    948 / 1474 loss=2.096, trans_loss=4.939, nll_loss=2.189, w2v_ctc_loss=0.757, task_loss=0, contrastive_loss=0.151, total=4167.75, n_correct=2723.33, ppl=4.56, accuracy=65.343, wps=6428.6, ups=0.77, wpb=8335.5, bsz=310.1, num_updates=20100, lr=9.97509e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=57, gb_free=16.3, wall=16064
2023-08-16 15:52:53 | INFO | train_inner | epoch 014:   1048 / 1474 loss=2.097, trans_loss=4.943, nll_loss=2.196, w2v_ctc_loss=0.761, task_loss=0, contrastive_loss=0.133, total=4143.92, n_correct=2712.34, ppl=4.58, accuracy=65.453, wps=14296.1, ups=1.72, wpb=8287.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=16.1, wall=16122
2023-08-16 15:53:51 | INFO | train_inner | epoch 014:   1148 / 1474 loss=2.129, trans_loss=4.943, nll_loss=2.196, w2v_ctc_loss=0.768, task_loss=0, contrastive_loss=0.402, total=4228.69, n_correct=2760.46, ppl=4.58, accuracy=65.279, wps=14545.9, ups=1.72, wpb=8457.4, bsz=327.2, num_updates=20300, lr=9.92583e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=58, gb_free=15.8, wall=16181
2023-08-16 15:54:49 | INFO | train_inner | epoch 014:   1248 / 1474 loss=2.1, trans_loss=4.949, nll_loss=2.203, w2v_ctc_loss=0.777, task_loss=0, contrastive_loss=0.092, total=4021.19, n_correct=2619.81, ppl=4.6, accuracy=65.15, wps=14028.4, ups=1.74, wpb=8042.4, bsz=271.7, num_updates=20400, lr=9.90148e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=16238
2023-08-16 15:55:46 | INFO | train_inner | epoch 014:   1348 / 1474 loss=2.091, trans_loss=4.941, nll_loss=2.194, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.108, total=4213.9, n_correct=2756.12, ppl=4.57, accuracy=65.405, wps=14687.1, ups=1.74, wpb=8427.8, bsz=319.4, num_updates=20500, lr=9.8773e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=16295
2023-08-16 15:56:44 | INFO | train_inner | epoch 014:   1448 / 1474 loss=2.098, trans_loss=4.946, nll_loss=2.199, w2v_ctc_loss=0.756, task_loss=0, contrastive_loss=0.148, total=4130.28, n_correct=2697.75, ppl=4.59, accuracy=65.316, wps=14365.5, ups=1.74, wpb=8260.6, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=57, gb_free=15.4, wall=16353
2023-08-16 15:56:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:1')
2023-08-16 15:57:22 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.12 | trans_loss 5.172 | nll_loss 2.44 | w2v_ctc_loss 1.391 | task_loss 0 | contrastive_loss 0.32 | total 4003.4 | n_correct 2655.4 | ppl 5.43 | accuracy 66.329 | uer 18.528 | wer 20.417 | raw_wer 20.417 | bleu 22.01 | wps 2094 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 22.01
2023-08-16 15:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-08-16 15:57:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 15:57:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 15:57:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 14 @ 20626 updates, score 22.01) (writing took 32.90542324818671 seconds)
2023-08-16 15:57:56 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-16 15:57:56 | INFO | train | epoch 014 | loss 2.098 | trans_loss 4.939 | nll_loss 2.19 | w2v_ctc_loss 0.76 | task_loss 0 | contrastive_loss 0.157 | total 4138.65 | n_correct 2706.56 | ppl 4.56 | accuracy 65.397 | wps 12364.9 | ups 1.49 | wpb 8277.3 | bsz 305.7 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.551 | clip 0 | loss_scale 32 | train_wall 842 | gb_free 16.4 | wall 16425
2023-08-16 15:57:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 15:57:56 | INFO | fairseq.trainer | begin training epoch 15
2023-08-16 15:57:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 15:58:45 | INFO | train_inner | epoch 015:     74 / 1474 loss=2.09, trans_loss=4.926, nll_loss=2.174, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.195, total=4083.88, n_correct=2683.66, ppl=4.51, accuracy=65.713, wps=6699.2, ups=0.82, wpb=8167.8, bsz=300.2, num_updates=20700, lr=9.82946e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=15.9, wall=16475
2023-08-16 15:59:43 | INFO | train_inner | epoch 015:    174 / 1474 loss=2.08, trans_loss=4.917, nll_loss=2.161, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.106, total=4115.73, n_correct=2713.37, ppl=4.47, accuracy=65.927, wps=14417, ups=1.75, wpb=8231.5, bsz=297.8, num_updates=20800, lr=9.80581e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=16532
2023-08-16 16:00:40 | INFO | train_inner | epoch 015:    274 / 1474 loss=2.074, trans_loss=4.918, nll_loss=2.163, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.097, total=4193.15, n_correct=2768.27, ppl=4.48, accuracy=66.019, wps=14670.1, ups=1.75, wpb=8386.3, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=13, wall=16589
2023-08-16 16:01:37 | INFO | train_inner | epoch 015:    374 / 1474 loss=2.078, trans_loss=4.913, nll_loss=2.157, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.119, total=4167.66, n_correct=2746.76, ppl=4.46, accuracy=65.907, wps=14539.6, ups=1.74, wpb=8335.3, bsz=306, num_updates=21000, lr=9.759e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=16646
2023-08-16 16:02:34 | INFO | train_inner | epoch 015:    474 / 1474 loss=2.085, trans_loss=4.918, nll_loss=2.162, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.209, total=4074.53, n_correct=2681.31, ppl=4.48, accuracy=65.807, wps=14298.6, ups=1.75, wpb=8149.1, bsz=294.2, num_updates=21100, lr=9.73585e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=15.8, wall=16703
2023-08-16 16:03:31 | INFO | train_inner | epoch 015:    574 / 1474 loss=2.079, trans_loss=4.918, nll_loss=2.163, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.104, total=4140.59, n_correct=2727.15, ppl=4.48, accuracy=65.864, wps=14463.6, ups=1.75, wpb=8281.2, bsz=298.8, num_updates=21200, lr=9.71286e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=12.5, wall=16761
2023-08-16 16:04:29 | INFO | train_inner | epoch 015:    674 / 1474 loss=2.091, trans_loss=4.917, nll_loss=2.162, w2v_ctc_loss=0.751, task_loss=0, contrastive_loss=0.187, total=4134.99, n_correct=2720.26, ppl=4.48, accuracy=65.786, wps=14416.7, ups=1.74, wpb=8270, bsz=307.1, num_updates=21300, lr=9.69003e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=11, wall=16818
2023-08-16 16:05:26 | INFO | train_inner | epoch 015:    774 / 1474 loss=2.083, trans_loss=4.924, nll_loss=2.171, w2v_ctc_loss=0.756, task_loss=0, contrastive_loss=0.105, total=4173.66, n_correct=2739.97, ppl=4.5, accuracy=65.649, wps=14476.9, ups=1.73, wpb=8347.3, bsz=305, num_updates=21400, lr=9.66736e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=16876
2023-08-16 16:06:23 | INFO | train_inner | epoch 015:    874 / 1474 loss=2.082, trans_loss=4.925, nll_loss=2.173, w2v_ctc_loss=0.754, task_loss=0, contrastive_loss=0.1, total=4059.35, n_correct=2663.62, ppl=4.51, accuracy=65.617, wps=14238.7, ups=1.75, wpb=8118.7, bsz=288.3, num_updates=21500, lr=9.64486e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=15.5, wall=16933
2023-08-16 16:07:21 | INFO | train_inner | epoch 015:    974 / 1474 loss=2.086, trans_loss=4.92, nll_loss=2.166, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.19, total=4122.87, n_correct=2717.29, ppl=4.49, accuracy=65.908, wps=14359.1, ups=1.74, wpb=8245.7, bsz=301.7, num_updates=21600, lr=9.6225e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=17.6, wall=16990
2023-08-16 16:08:19 | INFO | train_inner | epoch 015:   1074 / 1474 loss=2.108, trans_loss=4.929, nll_loss=2.178, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.341, total=4192.24, n_correct=2749.97, ppl=4.52, accuracy=65.597, wps=14399.3, ups=1.72, wpb=8384.5, bsz=325.2, num_updates=21700, lr=9.60031e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=58, gb_free=17.2, wall=17048
2023-08-16 16:09:16 | INFO | train_inner | epoch 015:   1174 / 1474 loss=2.077, trans_loss=4.917, nll_loss=2.163, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.146, total=4185, n_correct=2763.33, ppl=4.48, accuracy=66.029, wps=14661.2, ups=1.75, wpb=8370, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=17105
2023-08-16 16:10:14 | INFO | train_inner | epoch 015:   1274 / 1474 loss=2.084, trans_loss=4.918, nll_loss=2.164, w2v_ctc_loss=0.761, task_loss=0, contrastive_loss=0.105, total=4152.04, n_correct=2729.57, ppl=4.48, accuracy=65.74, wps=14472, ups=1.74, wpb=8304.1, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=17163
2023-08-16 16:11:11 | INFO | train_inner | epoch 015:   1374 / 1474 loss=2.075, trans_loss=4.919, nll_loss=2.164, w2v_ctc_loss=0.748, task_loss=0, contrastive_loss=0.092, total=4100.21, n_correct=2699.48, ppl=4.48, accuracy=65.838, wps=14250.2, ups=1.74, wpb=8200.4, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=17.6, wall=17220
2023-08-16 16:11:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 16:11:36 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.098 | trans_loss 5.171 | nll_loss 2.434 | w2v_ctc_loss 1.325 | task_loss 0 | contrastive_loss 0.314 | total 4003.4 | n_correct 2654.3 | ppl 5.41 | accuracy 66.301 | uer 18.464 | wer 20.585 | raw_wer 20.585 | bleu 21.87 | wps 2022.1 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 22.01
2023-08-16 16:11:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-16 16:11:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-16 16:11:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-16 16:12:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 21.87) (writing took 41.63059054128826 seconds)
2023-08-16 16:13:17 | INFO | train_inner | epoch 015:   1474 / 1474 loss=2.091, trans_loss=4.928, nll_loss=2.177, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.179, total=4141.17, n_correct=2720.36, ppl=4.52, accuracy=65.691, wps=6579.7, ups=0.79, wpb=8282.3, bsz=314.3, num_updates=22100, lr=9.51303e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=58, gb_free=16.9, wall=17346
2023-08-16 16:13:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 16:13:40 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.11 | trans_loss 5.17 | nll_loss 2.436 | w2v_ctc_loss 1.371 | task_loss 0 | contrastive_loss 0.313 | total 4003.4 | n_correct 2659 | ppl 5.41 | accuracy 66.419 | uer 18.098 | wer 19.966 | raw_wer 19.966 | bleu 21.77 | wps 2241.7 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 22.01
2023-08-16 16:13:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-08-16 16:13:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_21.7708.pt
2023-08-16 16:13:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_21.7708.pt
2023-08-16 16:14:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_21.7708.pt (epoch 15 @ 22100 updates, score 21.77) (writing took 23.934174239635468 seconds)
2023-08-16 16:14:04 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-16 16:14:04 | INFO | train | epoch 015 | loss 2.084 | trans_loss 4.92 | nll_loss 2.166 | w2v_ctc_loss 0.748 | task_loss 0 | contrastive_loss 0.153 | total 4138.65 | n_correct 2724.11 | ppl 4.49 | accuracy 65.821 | wps 12603.3 | ups 1.52 | wpb 8277.3 | bsz 305.7 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.549 | clip 0 | loss_scale 32 | train_wall 838 | gb_free 16.9 | wall 17393
2023-08-16 16:14:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 16:14:04 | INFO | fairseq.trainer | begin training epoch 16
2023-08-16 16:14:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 16:15:10 | INFO | train_inner | epoch 016:    100 / 1474 loss=2.066, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.734, task_loss=0, contrastive_loss=0.119, total=4126.22, n_correct=2734.68, ppl=4.41, accuracy=66.276, wps=7325.3, ups=0.89, wpb=8252.4, bsz=315.6, num_updates=22200, lr=9.49158e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=17459
2023-08-16 16:16:07 | INFO | train_inner | epoch 016:    200 / 1474 loss=2.059, trans_loss=4.892, nll_loss=2.129, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.097, total=4100.6, n_correct=2721.84, ppl=4.37, accuracy=66.377, wps=14268.5, ups=1.74, wpb=8201.2, bsz=296.8, num_updates=22300, lr=9.47027e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=57, gb_free=12.9, wall=17516
2023-08-16 16:17:05 | INFO | train_inner | epoch 016:    300 / 1474 loss=2.076, trans_loss=4.903, nll_loss=2.144, w2v_ctc_loss=0.741, task_loss=0, contrastive_loss=0.168, total=4166.94, n_correct=2754.8, ppl=4.42, accuracy=66.111, wps=14500.9, ups=1.74, wpb=8333.9, bsz=308.9, num_updates=22400, lr=9.44911e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=17.2, wall=17574
2023-08-16 16:18:02 | INFO | train_inner | epoch 016:    400 / 1474 loss=2.075, trans_loss=4.9, nll_loss=2.14, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.186, total=4073.3, n_correct=2695.08, ppl=4.41, accuracy=66.165, wps=14116.5, ups=1.73, wpb=8146.6, bsz=288.1, num_updates=22500, lr=9.42809e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=57, gb_free=17, wall=17632
2023-08-16 16:19:00 | INFO | train_inner | epoch 016:    500 / 1474 loss=2.07, trans_loss=4.903, nll_loss=2.144, w2v_ctc_loss=0.736, task_loss=0, contrastive_loss=0.128, total=4174.67, n_correct=2767.21, ppl=4.42, accuracy=66.286, wps=14572.3, ups=1.75, wpb=8349.3, bsz=319.1, num_updates=22600, lr=9.40721e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=57, gb_free=16.1, wall=17689
2023-08-16 16:19:57 | INFO | train_inner | epoch 016:    600 / 1474 loss=2.07, trans_loss=4.908, nll_loss=2.15, w2v_ctc_loss=0.745, task_loss=0, contrastive_loss=0.093, total=4124.65, n_correct=2725.54, ppl=4.44, accuracy=66.079, wps=14377.9, ups=1.74, wpb=8249.3, bsz=297.6, num_updates=22700, lr=9.38647e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=57, gb_free=16.3, wall=17746
2023-08-16 16:20:54 | INFO | train_inner | epoch 016:    700 / 1474 loss=2.067, trans_loss=4.904, nll_loss=2.145, w2v_ctc_loss=0.743, task_loss=0, contrastive_loss=0.094, total=4095.49, n_correct=2708.89, ppl=4.42, accuracy=66.143, wps=14394, ups=1.76, wpb=8191, bsz=296.3, num_updates=22800, lr=9.36586e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=56, gb_free=16.2, wall=17803
2023-08-16 16:21:51 | INFO | train_inner | epoch 016:    800 / 1474 loss=2.07, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.732, task_loss=0, contrastive_loss=0.156, total=4174.94, n_correct=2763.61, ppl=4.41, accuracy=66.195, wps=14487.4, ups=1.74, wpb=8349.9, bsz=310.9, num_updates=22900, lr=9.34539e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=57, gb_free=16.5, wall=17861
2023-08-16 16:22:49 | INFO | train_inner | epoch 016:    900 / 1474 loss=2.07, trans_loss=4.901, nll_loss=2.142, w2v_ctc_loss=0.735, task_loss=0, contrastive_loss=0.145, total=4163.19, n_correct=2756.56, ppl=4.42, accuracy=66.213, wps=14503.6, ups=1.74, wpb=8326.4, bsz=310.6, num_updates=23000, lr=9.32505e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=57, gb_free=16.8, wall=17918
2023-08-16 16:23:46 | INFO | train_inner | epoch 016:   1000 / 1474 loss=2.079, trans_loss=4.909, nll_loss=2.152, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.146, total=4103.45, n_correct=2707, ppl=4.44, accuracy=65.969, wps=14264.7, ups=1.74, wpb=8206.9, bsz=298.1, num_updates=23100, lr=9.30484e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=15, wall=17976
2023-08-16 16:24:44 | INFO | train_inner | epoch 016:   1100 / 1474 loss=2.078, trans_loss=4.915, nll_loss=2.159, w2v_ctc_loss=0.75, task_loss=0, contrastive_loss=0.12, total=4119.27, n_correct=2714.63, ppl=4.47, accuracy=65.901, wps=14371.7, ups=1.74, wpb=8238.5, bsz=295.3, num_updates=23200, lr=9.28477e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=57, gb_free=17.8, wall=18033
2023-08-16 16:25:42 | INFO | train_inner | epoch 016:   1200 / 1474 loss=2.08, trans_loss=4.911, nll_loss=2.155, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.213, total=4165.11, n_correct=2748.32, ppl=4.45, accuracy=65.984, wps=14328.4, ups=1.72, wpb=8330.2, bsz=308.7, num_updates=23300, lr=9.26482e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=58, gb_free=16.7, wall=18091
2023-08-16 16:26:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-16 16:26:40 | INFO | train_inner | epoch 016:   1301 / 1474 loss=2.072, trans_loss=4.906, nll_loss=2.148, w2v_ctc_loss=0.749, task_loss=0, contrastive_loss=0.103, total=4125.8, n_correct=2730.42, ppl=4.43, accuracy=66.179, wps=14306.3, ups=1.73, wpb=8251.6, bsz=306, num_updates=23400, lr=9.245e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16, wall=18149
2023-08-16 16:27:38 | INFO | train_inner | epoch 016:   1401 / 1474 loss=2.07, trans_loss=4.904, nll_loss=2.146, w2v_ctc_loss=0.741, task_loss=0, contrastive_loss=0.122, total=4201.47, n_correct=2783.39, ppl=4.43, accuracy=66.248, wps=14507.7, ups=1.73, wpb=8402.9, bsz=320.7, num_updates=23500, lr=9.22531e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=16, wall=18207
2023-08-16 16:28:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 16:28:42 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.099 | trans_loss 5.167 | nll_loss 2.43 | w2v_ctc_loss 1.346 | task_loss 0 | contrastive_loss 0.31 | total 4003.4 | n_correct 2660.3 | ppl 5.39 | accuracy 66.451 | uer 18.066 | wer 19.981 | raw_wer 19.981 | bleu 22.1 | wps 2147.8 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 22.1
2023-08-16 16:28:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-08-16 16:28:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 16:28:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 16:29:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 16 @ 23573 updates, score 22.1) (writing took 32.429502602666616 seconds)
2023-08-16 16:29:15 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-16 16:29:15 | INFO | train | epoch 016 | loss 2.072 | trans_loss 4.904 | nll_loss 2.145 | w2v_ctc_loss 0.739 | task_loss 0 | contrastive_loss 0.144 | total 4137.51 | n_correct 2736.87 | ppl 4.42 | accuracy 66.148 | wps 13376.2 | ups 1.62 | wpb 8275 | bsz 305.2 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.549 | clip 0 | loss_scale 32 | train_wall 840 | gb_free 15.6 | wall 18305
2023-08-16 16:29:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 16:29:16 | INFO | fairseq.trainer | begin training epoch 17
2023-08-16 16:29:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 16:29:38 | INFO | train_inner | epoch 017:     27 / 1474 loss=2.074, trans_loss=4.894, nll_loss=2.133, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.26, total=4145.04, n_correct=2745.72, ppl=4.39, accuracy=66.241, wps=6856.7, ups=0.83, wpb=8290.1, bsz=302.4, num_updates=23600, lr=9.20575e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=18328
2023-08-16 16:30:36 | INFO | train_inner | epoch 017:    127 / 1474 loss=2.052, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.727, task_loss=0, contrastive_loss=0.095, total=4117.27, n_correct=2743.16, ppl=4.33, accuracy=66.626, wps=14353.1, ups=1.74, wpb=8234.5, bsz=296.2, num_updates=23700, lr=9.1863e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=18385
2023-08-16 16:31:33 | INFO | train_inner | epoch 017:    227 / 1474 loss=2.073, trans_loss=4.882, nll_loss=2.117, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.264, total=4159.6, n_correct=2768.95, ppl=4.34, accuracy=66.568, wps=14512.1, ups=1.74, wpb=8319.2, bsz=317.6, num_updates=23800, lr=9.16698e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=18442
2023-08-16 16:32:31 | INFO | train_inner | epoch 017:    327 / 1474 loss=2.069, trans_loss=4.887, nll_loss=2.124, w2v_ctc_loss=0.723, task_loss=0, contrastive_loss=0.264, total=4156.91, n_correct=2762.28, ppl=4.36, accuracy=66.45, wps=14478.4, ups=1.74, wpb=8313.8, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=18500
2023-08-16 16:33:28 | INFO | train_inner | epoch 017:    427 / 1474 loss=2.055, trans_loss=4.886, nll_loss=2.122, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.094, total=4146.43, n_correct=2763.38, ppl=4.35, accuracy=66.645, wps=14428.8, ups=1.74, wpb=8292.9, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=18557
2023-08-16 16:33:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 16:33:52 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.109 | trans_loss 5.168 | nll_loss 2.43 | w2v_ctc_loss 1.379 | task_loss 0 | contrastive_loss 0.307 | total 4003.4 | n_correct 2657.9 | ppl 5.39 | accuracy 66.391 | uer 18.193 | wer 19.94 | raw_wer 19.94 | bleu 21.84 | wps 2105.6 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 22.1
2023-08-16 16:33:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-16 16:33:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-16 16:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-16 16:34:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 21.84) (writing took 40.43008357845247 seconds)
2023-08-16 16:35:31 | INFO | train_inner | epoch 017:    527 / 1474 loss=2.062, trans_loss=4.891, nll_loss=2.128, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.139, total=4182.1, n_correct=2775.53, ppl=4.37, accuracy=66.367, wps=6789.1, ups=0.81, wpb=8364.2, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=58, gb_free=16.8, wall=18681
2023-08-16 16:36:29 | INFO | train_inner | epoch 017:    627 / 1474 loss=2.051, trans_loss=4.888, nll_loss=2.125, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.089, total=4167.27, n_correct=2776.1, ppl=4.36, accuracy=66.617, wps=14535.6, ups=1.74, wpb=8334.5, bsz=302.2, num_updates=24200, lr=9.09091e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=57, gb_free=11.1, wall=18738
2023-08-16 16:37:26 | INFO | train_inner | epoch 017:    727 / 1474 loss=2.071, trans_loss=4.894, nll_loss=2.133, w2v_ctc_loss=0.747, task_loss=0, contrastive_loss=0.137, total=4166.12, n_correct=2763.26, ppl=4.39, accuracy=66.327, wps=14535, ups=1.74, wpb=8332.2, bsz=308.1, num_updates=24300, lr=9.07218e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=18795
2023-08-16 16:38:23 | INFO | train_inner | epoch 017:    827 / 1474 loss=2.056, trans_loss=4.889, nll_loss=2.126, w2v_ctc_loss=0.731, task_loss=0, contrastive_loss=0.102, total=4091.64, n_correct=2721.6, ppl=4.36, accuracy=66.516, wps=14345.4, ups=1.75, wpb=8183.3, bsz=295.3, num_updates=24400, lr=9.05357e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=18852
2023-08-16 16:39:20 | INFO | train_inner | epoch 017:    927 / 1474 loss=2.057, trans_loss=4.892, nll_loss=2.13, w2v_ctc_loss=0.729, task_loss=0, contrastive_loss=0.099, total=4106.83, n_correct=2724.87, ppl=4.38, accuracy=66.35, wps=14385.6, ups=1.75, wpb=8213.7, bsz=304.6, num_updates=24500, lr=9.03508e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=15.9, wall=18909
2023-08-16 16:40:18 | INFO | train_inner | epoch 017:   1027 / 1474 loss=2.057, trans_loss=4.889, nll_loss=2.126, w2v_ctc_loss=0.733, task_loss=0, contrastive_loss=0.102, total=4115.49, n_correct=2735.05, ppl=4.37, accuracy=66.457, wps=14332.1, ups=1.74, wpb=8231, bsz=305.8, num_updates=24600, lr=9.0167e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=18967
2023-08-16 16:41:15 | INFO | train_inner | epoch 017:   1127 / 1474 loss=2.051, trans_loss=4.886, nll_loss=2.122, w2v_ctc_loss=0.722, task_loss=0, contrastive_loss=0.09, total=4078.39, n_correct=2714.81, ppl=4.35, accuracy=66.566, wps=14286.9, ups=1.75, wpb=8156.8, bsz=293.7, num_updates=24700, lr=8.99843e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=19024
2023-08-16 16:42:13 | INFO | train_inner | epoch 017:   1227 / 1474 loss=2.086, trans_loss=4.896, nll_loss=2.135, w2v_ctc_loss=0.726, task_loss=0, contrastive_loss=0.333, total=4173.49, n_correct=2765.17, ppl=4.39, accuracy=66.256, wps=14391.3, ups=1.72, wpb=8347, bsz=323.7, num_updates=24800, lr=8.98027e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=19082
2023-08-16 16:43:10 | INFO | train_inner | epoch 017:   1327 / 1474 loss=2.062, trans_loss=4.891, nll_loss=2.13, w2v_ctc_loss=0.719, task_loss=0, contrastive_loss=0.173, total=4156.28, n_correct=2761.5, ppl=4.38, accuracy=66.442, wps=14502.6, ups=1.74, wpb=8312.6, bsz=308, num_updates=24900, lr=8.96221e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=19139
2023-08-16 16:44:07 | INFO | train_inner | epoch 017:   1427 / 1474 loss=2.055, trans_loss=4.892, nll_loss=2.13, w2v_ctc_loss=0.727, task_loss=0, contrastive_loss=0.095, total=4112.95, n_correct=2733.73, ppl=4.38, accuracy=66.466, wps=14328.2, ups=1.74, wpb=8225.9, bsz=303.2, num_updates=25000, lr=8.94427e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=19197
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:0')
2023-08-16 16:44:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:2')
2023-08-16 16:44:57 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.103 | trans_loss 5.169 | nll_loss 2.433 | w2v_ctc_loss 1.357 | task_loss 0 | contrastive_loss 0.31 | total 4003.4 | n_correct 2658 | ppl 5.4 | accuracy 66.394 | uer 18.063 | wer 20.01 | raw_wer 20.01 | bleu 22.14 | wps 2206.1 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 22.14
2023-08-16 16:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-08-16 16:44:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 16:45:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 16:45:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 17 @ 25047 updates, score 22.14) (writing took 31.47287428751588 seconds)
2023-08-16 16:45:29 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-16 16:45:29 | INFO | train | epoch 017 | loss 2.061 | trans_loss 4.889 | nll_loss 2.125 | w2v_ctc_loss 0.728 | task_loss 0 | contrastive_loss 0.147 | total 4138.65 | n_correct 2751.39 | ppl 4.36 | accuracy 66.48 | wps 12526.3 | ups 1.51 | wpb 8277.3 | bsz 305.7 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.545 | clip 0 | loss_scale 32 | train_wall 839 | gb_free 16.4 | wall 19279
2023-08-16 16:45:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 16:45:30 | INFO | fairseq.trainer | begin training epoch 18
2023-08-16 16:45:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 16:46:08 | INFO | train_inner | epoch 018:     53 / 1474 loss=2.052, trans_loss=4.881, nll_loss=2.116, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.103, total=4139.04, n_correct=2761.76, ppl=4.33, accuracy=66.725, wps=6849.4, ups=0.83, wpb=8278.1, bsz=303.3, num_updates=25100, lr=8.92644e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=19317
2023-08-16 16:47:06 | INFO | train_inner | epoch 018:    153 / 1474 loss=2.049, trans_loss=4.861, nll_loss=2.09, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.226, total=4154.85, n_correct=2785.14, ppl=4.26, accuracy=67.033, wps=14470.3, ups=1.74, wpb=8309.7, bsz=312.7, num_updates=25200, lr=8.90871e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=19375
2023-08-16 16:48:03 | INFO | train_inner | epoch 018:    253 / 1474 loss=2.039, trans_loss=4.864, nll_loss=2.093, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.094, total=4162.72, n_correct=2792.2, ppl=4.27, accuracy=67.076, wps=14507.3, ups=1.74, wpb=8325.4, bsz=312.9, num_updates=25300, lr=8.89108e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=19432
2023-08-16 16:49:01 | INFO | train_inner | epoch 018:    353 / 1474 loss=2.042, trans_loss=4.869, nll_loss=2.099, w2v_ctc_loss=0.712, task_loss=0, contrastive_loss=0.107, total=4161.22, n_correct=2780.23, ppl=4.28, accuracy=66.813, wps=14380, ups=1.73, wpb=8322.4, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=57, gb_free=14.5, wall=19490
2023-08-16 16:49:59 | INFO | train_inner | epoch 018:    453 / 1474 loss=2.055, trans_loss=4.876, nll_loss=2.108, w2v_ctc_loss=0.715, task_loss=0, contrastive_loss=0.2, total=4092.36, n_correct=2729.97, ppl=4.31, accuracy=66.709, wps=14133.2, ups=1.73, wpb=8184.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=16.6, wall=19548
2023-08-16 16:50:56 | INFO | train_inner | epoch 018:    553 / 1474 loss=2.036, trans_loss=4.859, nll_loss=2.088, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.106, total=4206.45, n_correct=2827.06, ppl=4.25, accuracy=67.208, wps=14633.8, ups=1.74, wpb=8412.9, bsz=328.9, num_updates=25600, lr=8.83883e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=17.8, wall=19606
2023-08-16 16:51:54 | INFO | train_inner | epoch 018:    653 / 1474 loss=2.06, trans_loss=4.88, nll_loss=2.115, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.178, total=4097.96, n_correct=2731.58, ppl=4.33, accuracy=66.657, wps=14291.8, ups=1.74, wpb=8195.9, bsz=298.6, num_updates=25700, lr=8.82162e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=57, gb_free=12.4, wall=19663
2023-08-16 16:52:52 | INFO | train_inner | epoch 018:    753 / 1474 loss=2.07, trans_loss=4.881, nll_loss=2.116, w2v_ctc_loss=0.728, task_loss=0, contrastive_loss=0.266, total=4208.5, n_correct=2806.93, ppl=4.34, accuracy=66.697, wps=14541.2, ups=1.73, wpb=8417, bsz=322.6, num_updates=25800, lr=8.80451e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=16.3, wall=19721
2023-08-16 16:53:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-16 16:53:49 | INFO | train_inner | epoch 018:    854 / 1474 loss=2.043, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.718, task_loss=0, contrastive_loss=0.085, total=4158.87, n_correct=2781.65, ppl=4.3, accuracy=66.885, wps=14424.5, ups=1.73, wpb=8317.7, bsz=300.5, num_updates=25900, lr=8.7875e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=12.9, wall=19779
2023-08-16 16:54:47 | INFO | train_inner | epoch 018:    954 / 1474 loss=2.039, trans_loss=4.867, nll_loss=2.098, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.107, total=4142.65, n_correct=2776.37, ppl=4.28, accuracy=67.019, wps=14443.7, ups=1.74, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=14.9, wall=19836
2023-08-16 16:54:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 16:55:12 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.094 | trans_loss 5.16 | nll_loss 2.42 | w2v_ctc_loss 1.351 | task_loss 0 | contrastive_loss 0.307 | total 4003.4 | n_correct 2663.3 | ppl 5.35 | accuracy 66.526 | uer 18.106 | wer 19.984 | raw_wer 19.984 | bleu 22.02 | wps 1972.4 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 22.14
2023-08-16 16:55:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-16 16:55:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-16 16:55:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-16 16:55:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 22.02) (writing took 44.70731337927282 seconds)
2023-08-16 16:56:55 | INFO | train_inner | epoch 018:   1054 / 1474 loss=2.042, trans_loss=4.873, nll_loss=2.106, w2v_ctc_loss=0.71, task_loss=0, contrastive_loss=0.094, total=4137.77, n_correct=2763.45, ppl=4.31, accuracy=66.786, wps=6432.5, ups=0.78, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=19965
2023-08-16 16:57:53 | INFO | train_inner | epoch 018:   1154 / 1474 loss=2.053, trans_loss=4.865, nll_loss=2.096, w2v_ctc_loss=0.717, task_loss=0, contrastive_loss=0.2, total=4153.69, n_correct=2779.44, ppl=4.27, accuracy=66.915, wps=14418.3, ups=1.74, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=15.2, wall=20022
2023-08-16 16:58:50 | INFO | train_inner | epoch 018:   1254 / 1474 loss=2.045, trans_loss=4.883, nll_loss=2.118, w2v_ctc_loss=0.716, task_loss=0, contrastive_loss=0.088, total=4087.62, n_correct=2725.48, ppl=4.34, accuracy=66.676, wps=14332.6, ups=1.75, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=20079
2023-08-16 16:59:47 | INFO | train_inner | epoch 018:   1354 / 1474 loss=2.06, trans_loss=4.885, nll_loss=2.122, w2v_ctc_loss=0.738, task_loss=0, contrastive_loss=0.115, total=4070.69, n_correct=2705.84, ppl=4.35, accuracy=66.471, wps=14210.3, ups=1.75, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=20136
2023-08-16 17:00:44 | INFO | train_inner | epoch 018:   1454 / 1474 loss=2.052, trans_loss=4.881, nll_loss=2.115, w2v_ctc_loss=0.73, task_loss=0, contrastive_loss=0.1, total=4113.2, n_correct=2741.03, ppl=4.33, accuracy=66.64, wps=14373.8, ups=1.75, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=20194
2023-08-16 17:00:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 17:01:19 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.104 | trans_loss 5.159 | nll_loss 2.422 | w2v_ctc_loss 1.388 | task_loss 0 | contrastive_loss 0.302 | total 4003.4 | n_correct 2665.1 | ppl 5.36 | accuracy 66.571 | uer 17.843 | wer 19.91 | raw_wer 19.91 | bleu 22.26 | wps 2146.2 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 22.26
2023-08-16 17:01:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-08-16 17:01:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 17:01:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 17:01:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 18 @ 26520 updates, score 22.26) (writing took 31.04120202921331 seconds)
2023-08-16 17:01:51 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-16 17:01:51 | INFO | train | epoch 018 | loss 2.049 | trans_loss 4.873 | nll_loss 2.105 | w2v_ctc_loss 0.717 | task_loss 0 | contrastive_loss 0.144 | total 4138.41 | n_correct 2765.64 | ppl 4.3 | accuracy 66.829 | wps 12420.5 | ups 1.5 | wpb 8276.8 | bsz 305.6 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.546 | clip 0 | loss_scale 32 | train_wall 840 | gb_free 16 | wall 20260
2023-08-16 17:01:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 17:01:51 | INFO | fairseq.trainer | begin training epoch 19
2023-08-16 17:01:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 17:02:45 | INFO | train_inner | epoch 019:     80 / 1474 loss=2.04, trans_loss=4.857, nll_loss=2.084, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.151, total=4102.06, n_correct=2753.54, ppl=4.24, accuracy=67.126, wps=6790.6, ups=0.83, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=20315
2023-08-16 17:03:43 | INFO | train_inner | epoch 019:    180 / 1474 loss=2.045, trans_loss=4.856, nll_loss=2.083, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.141, total=4227.7, n_correct=2838.55, ppl=4.24, accuracy=67.142, wps=14559.7, ups=1.72, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=58, gb_free=17, wall=20373
2023-08-16 17:04:41 | INFO | train_inner | epoch 019:    280 / 1474 loss=2.027, trans_loss=4.847, nll_loss=2.072, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.085, total=4187.34, n_correct=2821.29, ppl=4.2, accuracy=67.377, wps=14650.6, ups=1.75, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=57, gb_free=16, wall=20430
2023-08-16 17:05:38 | INFO | train_inner | epoch 019:    380 / 1474 loss=2.043, trans_loss=4.854, nll_loss=2.081, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.191, total=4170.52, n_correct=2800.24, ppl=4.23, accuracy=67.144, wps=14454, ups=1.73, wpb=8341, bsz=311, num_updates=26900, lr=8.62261e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=20488
2023-08-16 17:06:36 | INFO | train_inner | epoch 019:    480 / 1474 loss=2.041, trans_loss=4.861, nll_loss=2.09, w2v_ctc_loss=0.721, task_loss=0, contrastive_loss=0.1, total=4113.89, n_correct=2760.34, ppl=4.26, accuracy=67.098, wps=14309.4, ups=1.74, wpb=8227.8, bsz=301.5, num_updates=27000, lr=8.60663e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=17.2, wall=20545
2023-08-16 17:07:33 | INFO | train_inner | epoch 019:    580 / 1474 loss=2.038, trans_loss=4.855, nll_loss=2.082, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.165, total=4128.58, n_correct=2771.69, ppl=4.23, accuracy=67.134, wps=14353.8, ups=1.74, wpb=8257.2, bsz=306.2, num_updates=27100, lr=8.59074e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=20603
2023-08-16 17:08:31 | INFO | train_inner | epoch 019:    680 / 1474 loss=2.028, trans_loss=4.86, nll_loss=2.089, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.091, total=4201.56, n_correct=2824.56, ppl=4.25, accuracy=67.226, wps=14669.6, ups=1.75, wpb=8403.1, bsz=321.5, num_updates=27200, lr=8.57493e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=20660
2023-08-16 17:09:28 | INFO | train_inner | epoch 019:    780 / 1474 loss=2.035, trans_loss=4.857, nll_loss=2.083, w2v_ctc_loss=0.712, task_loss=0, contrastive_loss=0.096, total=4124.03, n_correct=2769.11, ppl=4.24, accuracy=67.146, wps=14303.2, ups=1.73, wpb=8248.1, bsz=299, num_updates=27300, lr=8.55921e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=20717
2023-08-16 17:10:26 | INFO | train_inner | epoch 019:    880 / 1474 loss=2.039, trans_loss=4.866, nll_loss=2.096, w2v_ctc_loss=0.713, task_loss=0, contrastive_loss=0.095, total=4177.8, n_correct=2797.28, ppl=4.28, accuracy=66.956, wps=14497, ups=1.74, wpb=8355.6, bsz=309.6, num_updates=27400, lr=8.54358e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=57, gb_free=15, wall=20775
2023-08-16 17:11:24 | INFO | train_inner | epoch 019:    980 / 1474 loss=2.063, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.709, task_loss=0, contrastive_loss=0.324, total=4084.26, n_correct=2729.76, ppl=4.3, accuracy=66.836, wps=14008.9, ups=1.71, wpb=8168.5, bsz=305.8, num_updates=27500, lr=8.52803e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=58, gb_free=16.1, wall=20833
2023-08-16 17:12:21 | INFO | train_inner | epoch 019:   1080 / 1474 loss=2.039, trans_loss=4.867, nll_loss=2.097, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.13, total=4042.73, n_correct=2706.46, ppl=4.28, accuracy=66.946, wps=14109.2, ups=1.75, wpb=8085.5, bsz=294, num_updates=27600, lr=8.51257e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=20891
2023-08-16 17:13:19 | INFO | train_inner | epoch 019:   1180 / 1474 loss=2.059, trans_loss=4.87, nll_loss=2.101, w2v_ctc_loss=0.72, task_loss=0, contrastive_loss=0.214, total=4140.95, n_correct=2763.92, ppl=4.29, accuracy=66.746, wps=14293, ups=1.73, wpb=8281.9, bsz=307.9, num_updates=27700, lr=8.49719e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=58, gb_free=13, wall=20949
2023-08-16 17:14:16 | INFO | train_inner | epoch 019:   1280 / 1474 loss=2.039, trans_loss=4.867, nll_loss=2.098, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.111, total=4135.79, n_correct=2767.64, ppl=4.28, accuracy=66.919, wps=14551.7, ups=1.76, wpb=8271.6, bsz=299.5, num_updates=27800, lr=8.48189e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=56, gb_free=17.9, wall=21006
2023-08-16 17:15:14 | INFO | train_inner | epoch 019:   1380 / 1474 loss=2.039, trans_loss=4.865, nll_loss=2.095, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.098, total=4138.67, n_correct=2773.4, ppl=4.27, accuracy=67.012, wps=14380.9, ups=1.74, wpb=8277.3, bsz=301.6, num_updates=27900, lr=8.46668e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=57, gb_free=16.6, wall=21063
2023-08-16 17:16:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 17:16:30 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.117 | trans_loss 5.158 | nll_loss 2.418 | w2v_ctc_loss 1.436 | task_loss 0 | contrastive_loss 0.3 | total 4003.4 | n_correct 2669.8 | ppl 5.34 | accuracy 66.688 | uer 18.528 | wer 20.704 | raw_wer 20.704 | bleu 22 | wps 2215.5 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 22.26
2023-08-16 17:16:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-08-16 17:16:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.0005.pt
2023-08-16 17:16:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.0005.pt
2023-08-16 17:17:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.0005.pt (epoch 19 @ 27994 updates, score 22.0) (writing took 39.86944496259093 seconds)
2023-08-16 17:17:10 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-16 17:17:10 | INFO | train | epoch 019 | loss 2.041 | trans_loss 4.86 | nll_loss 2.089 | w2v_ctc_loss 0.71 | task_loss 0 | contrastive_loss 0.141 | total 4138.65 | n_correct 2775.66 | ppl 4.25 | accuracy 67.067 | wps 13274.7 | ups 1.6 | wpb 8277.3 | bsz 305.7 | num_updates 27994 | lr 8.45245e-05 | gnorm 0.544 | clip 0 | loss_scale 64 | train_wall 841 | gb_free 17.4 | wall 21179
2023-08-16 17:17:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 17:17:10 | INFO | fairseq.trainer | begin training epoch 20
2023-08-16 17:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 17:17:21 | INFO | train_inner | epoch 020:      6 / 1474 loss=2.04, trans_loss=4.856, nll_loss=2.084, w2v_ctc_loss=0.704, task_loss=0, contrastive_loss=0.179, total=4117.61, n_correct=2763.54, ppl=4.24, accuracy=67.115, wps=6464.7, ups=0.79, wpb=8235.2, bsz=303, num_updates=28000, lr=8.45154e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=16.5, wall=21191
2023-08-16 17:17:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 17:17:45 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.097 | trans_loss 5.158 | nll_loss 2.417 | w2v_ctc_loss 1.37 | task_loss 0 | contrastive_loss 0.302 | total 4003.4 | n_correct 2669.9 | ppl 5.34 | accuracy 66.691 | uer 18.257 | wer 20.361 | raw_wer 20.361 | bleu 22.39 | wps 2220.2 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 22.39
2023-08-16 17:17:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-16 17:17:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-16 17:17:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-16 17:18:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 22.39) (writing took 39.706508377566934 seconds)
2023-08-16 17:19:26 | INFO | train_inner | epoch 020:    106 / 1474 loss=2.017, trans_loss=4.835, nll_loss=2.056, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.101, total=4192.82, n_correct=2838.66, ppl=4.16, accuracy=67.703, wps=6715.7, ups=0.8, wpb=8385.6, bsz=312.8, num_updates=28100, lr=8.43649e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=58, gb_free=16.3, wall=21315
2023-08-16 17:20:23 | INFO | train_inner | epoch 020:    206 / 1474 loss=2.029, trans_loss=4.843, nll_loss=2.066, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.158, total=4155.9, n_correct=2804.08, ppl=4.19, accuracy=67.472, wps=14510.6, ups=1.75, wpb=8311.8, bsz=302.3, num_updates=28200, lr=8.42152e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=57, gb_free=12, wall=21373
2023-08-16 17:21:21 | INFO | train_inner | epoch 020:    306 / 1474 loss=2.02, trans_loss=4.838, nll_loss=2.06, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.092, total=4192.69, n_correct=2835.62, ppl=4.17, accuracy=67.632, wps=14651.5, ups=1.75, wpb=8385.4, bsz=327.6, num_updates=28300, lr=8.40663e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=57, gb_free=17.1, wall=21430
2023-08-16 17:22:19 | INFO | train_inner | epoch 020:    406 / 1474 loss=2.018, trans_loss=4.836, nll_loss=2.057, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.091, total=4116.96, n_correct=2781.16, ppl=4.16, accuracy=67.554, wps=14209, ups=1.73, wpb=8233.9, bsz=296.8, num_updates=28400, lr=8.39181e-05, gnorm=0.539, clip=0, loss_scale=64, train_wall=57, gb_free=12.9, wall=21488
2023-08-16 17:23:16 | INFO | train_inner | epoch 020:    506 / 1474 loss=2.033, trans_loss=4.851, nll_loss=2.076, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.179, total=4100.73, n_correct=2761.05, ppl=4.22, accuracy=67.331, wps=14265.4, ups=1.74, wpb=8201.5, bsz=298.4, num_updates=28500, lr=8.37708e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=57, gb_free=16.3, wall=21545
2023-08-16 17:24:14 | INFO | train_inner | epoch 020:    606 / 1474 loss=2.036, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.181, total=4101.99, n_correct=2761.98, ppl=4.2, accuracy=67.333, wps=14283.4, ups=1.74, wpb=8204, bsz=298.3, num_updates=28600, lr=8.36242e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=57, gb_free=13.8, wall=21603
2023-08-16 17:25:11 | INFO | train_inner | epoch 020:    706 / 1474 loss=2.03, trans_loss=4.853, nll_loss=2.079, w2v_ctc_loss=0.707, task_loss=0, contrastive_loss=0.085, total=4124.25, n_correct=2768.68, ppl=4.23, accuracy=67.132, wps=14350.5, ups=1.74, wpb=8248.5, bsz=297.2, num_updates=28700, lr=8.34784e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=57, gb_free=16.8, wall=21660
2023-08-16 17:26:09 | INFO | train_inner | epoch 020:    806 / 1474 loss=2.027, trans_loss=4.849, nll_loss=2.075, w2v_ctc_loss=0.706, task_loss=0, contrastive_loss=0.089, total=4153.23, n_correct=2797.74, ppl=4.21, accuracy=67.363, wps=14405.5, ups=1.73, wpb=8306.5, bsz=308.5, num_updates=28800, lr=8.33333e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=57, gb_free=17.7, wall=21718
2023-08-16 17:27:07 | INFO | train_inner | epoch 020:    906 / 1474 loss=2.066, trans_loss=4.86, nll_loss=2.089, w2v_ctc_loss=0.705, task_loss=0, contrastive_loss=0.379, total=4153.72, n_correct=2780.87, ppl=4.26, accuracy=66.949, wps=14271.2, ups=1.72, wpb=8307.4, bsz=320.7, num_updates=28900, lr=8.3189e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=58, gb_free=16.1, wall=21776
2023-08-16 17:28:04 | INFO | train_inner | epoch 020:   1006 / 1474 loss=2.023, trans_loss=4.85, nll_loss=2.075, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.093, total=4156.05, n_correct=2796.14, ppl=4.21, accuracy=67.279, wps=14445.1, ups=1.74, wpb=8312.1, bsz=305.3, num_updates=29000, lr=8.30455e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=57, gb_free=15.2, wall=21834
2023-08-16 17:29:02 | INFO | train_inner | epoch 020:   1106 / 1474 loss=2.046, trans_loss=4.852, nll_loss=2.079, w2v_ctc_loss=0.701, task_loss=0, contrastive_loss=0.231, total=4181.53, n_correct=2808.87, ppl=4.22, accuracy=67.173, wps=14514.7, ups=1.74, wpb=8363.1, bsz=320.2, num_updates=29100, lr=8.29027e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=57, gb_free=17.2, wall=21891
2023-08-16 17:29:59 | INFO | train_inner | epoch 020:   1206 / 1474 loss=2.027, trans_loss=4.842, nll_loss=2.066, w2v_ctc_loss=0.712, task_loss=0, contrastive_loss=0.079, total=4029.26, n_correct=2709.74, ppl=4.19, accuracy=67.252, wps=14079.2, ups=1.75, wpb=8058.5, bsz=282.4, num_updates=29200, lr=8.27606e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=57, gb_free=16.7, wall=21949
2023-08-16 17:30:57 | INFO | train_inner | epoch 020:   1306 / 1474 loss=2.026, trans_loss=4.853, nll_loss=2.079, w2v_ctc_loss=0.699, task_loss=0, contrastive_loss=0.091, total=4127.21, n_correct=2777.13, ppl=4.23, accuracy=67.288, wps=14308.9, ups=1.73, wpb=8254.4, bsz=299.9, num_updates=29300, lr=8.26192e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=57, gb_free=14.9, wall=22006
2023-08-16 17:31:54 | INFO | train_inner | epoch 020:   1406 / 1474 loss=2.032, trans_loss=4.856, nll_loss=2.083, w2v_ctc_loss=0.708, task_loss=0, contrastive_loss=0.086, total=4110.89, n_correct=2758.45, ppl=4.24, accuracy=67.101, wps=14354.9, ups=1.75, wpb=8221.8, bsz=291.6, num_updates=29400, lr=8.24786e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=57, gb_free=13.5, wall=22064
2023-08-16 17:32:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 17:32:56 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.084 | trans_loss 5.153 | nll_loss 2.41 | w2v_ctc_loss 1.345 | task_loss 0 | contrastive_loss 0.293 | total 4003.4 | n_correct 2670.7 | ppl 5.31 | accuracy 66.711 | uer 17.586 | wer 19.511 | raw_wer 19.511 | bleu 22.56 | wps 2231.5 | wpb 4003.4 | bsz 141.8 | num_updates 29468 | best_bleu 22.56
2023-08-16 17:32:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29468 updates
2023-08-16 17:32:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 17:33:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 17:33:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 20 @ 29468 updates, score 22.56) (writing took 32.15992841310799 seconds)
2023-08-16 17:33:29 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-16 17:33:29 | INFO | train | epoch 020 | loss 2.031 | trans_loss 4.848 | nll_loss 2.073 | w2v_ctc_loss 0.7 | task_loss 0 | contrastive_loss 0.139 | total 4138.65 | n_correct 2786.49 | ppl 4.21 | accuracy 67.329 | wps 12465.9 | ups 1.51 | wpb 8277.3 | bsz 305.7 | num_updates 29468 | lr 8.23834e-05 | gnorm 0.546 | clip 0 | loss_scale 64 | train_wall 841 | gb_free 16.2 | wall 22158
2023-08-16 17:33:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 17:33:29 | INFO | fairseq.trainer | begin training epoch 21
2023-08-16 17:33:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 17:33:56 | INFO | train_inner | epoch 021:     32 / 1474 loss=2.036, trans_loss=4.848, nll_loss=2.073, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.206, total=4166.35, n_correct=2806.88, ppl=4.21, accuracy=67.37, wps=6870, ups=0.82, wpb=8332.7, bsz=319.4, num_updates=29500, lr=8.23387e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=11.5, wall=22185
2023-08-16 17:34:54 | INFO | train_inner | epoch 021:    132 / 1474 loss=2.024, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.198, total=4181.45, n_correct=2833.57, ppl=4.12, accuracy=67.765, wps=14372.7, ups=1.72, wpb=8362.9, bsz=317.6, num_updates=29600, lr=8.21995e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=58, gb_free=15.2, wall=22243
2023-08-16 17:35:51 | INFO | train_inner | epoch 021:    232 / 1474 loss=2.017, trans_loss=4.831, nll_loss=2.051, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.153, total=4167.12, n_correct=2824.55, ppl=4.14, accuracy=67.782, wps=14506.4, ups=1.74, wpb=8334.2, bsz=315.1, num_updates=29700, lr=8.2061e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=57, gb_free=12.1, wall=22300
2023-08-16 17:36:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-16 17:36:49 | INFO | train_inner | epoch 021:    333 / 1474 loss=2.026, trans_loss=4.835, nll_loss=2.055, w2v_ctc_loss=0.698, task_loss=0, contrastive_loss=0.152, total=4132.51, n_correct=2791.02, ppl=4.16, accuracy=67.538, wps=14217.1, ups=1.72, wpb=8265, bsz=304.3, num_updates=29800, lr=8.19232e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=58, gb_free=16.7, wall=22359
2023-08-16 17:37:47 | INFO | train_inner | epoch 021:    433 / 1474 loss=2.011, trans_loss=4.83, nll_loss=2.049, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.084, total=4195.53, n_correct=2847.13, ppl=4.14, accuracy=67.861, wps=14626.8, ups=1.74, wpb=8391.1, bsz=311.6, num_updates=29900, lr=8.17861e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=22416
2023-08-16 17:38:44 | INFO | train_inner | epoch 021:    533 / 1474 loss=2.01, trans_loss=4.823, nll_loss=2.04, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.079, total=4085.05, n_correct=2774.38, ppl=4.11, accuracy=67.915, wps=14243.2, ups=1.74, wpb=8170.1, bsz=296.1, num_updates=30000, lr=8.16497e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=22473
2023-08-16 17:38:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 17:39:07 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.109 | trans_loss 5.161 | nll_loss 2.419 | w2v_ctc_loss 1.409 | task_loss 0 | contrastive_loss 0.292 | total 4003.4 | n_correct 2668.2 | ppl 5.35 | accuracy 66.648 | uer 17.923 | wer 19.753 | raw_wer 19.753 | bleu 22.2 | wps 2318.1 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 22.56
2023-08-16 17:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-16 17:39:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-16 17:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-16 17:39:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 22.2) (writing took 40.284850154072046 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:0')
2023-08-16 17:40:45 | INFO | train_inner | epoch 021:    633 / 1474 loss=2.029, trans_loss=4.829, nll_loss=2.048, w2v_ctc_loss=0.687, task_loss=0, contrastive_loss=0.25, total=4220.3, n_correct=2861, ppl=4.14, accuracy=67.791, wps=6967.9, ups=0.83, wpb=8440.6, bsz=315.8, num_updates=30100, lr=8.15139e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=15.8, wall=22594
2023-08-16 17:41:43 | INFO | train_inner | epoch 021:    733 / 1474 loss=2.022, trans_loss=4.841, nll_loss=2.064, w2v_ctc_loss=0.69, task_loss=0, contrastive_loss=0.111, total=4148.18, n_correct=2801.43, ppl=4.18, accuracy=67.534, wps=14381.2, ups=1.73, wpb=8296.4, bsz=308.3, num_updates=30200, lr=8.13788e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=12.2, wall=22652
2023-08-16 17:42:41 | INFO | train_inner | epoch 021:    833 / 1474 loss=2.027, trans_loss=4.845, nll_loss=2.069, w2v_ctc_loss=0.696, task_loss=0, contrastive_loss=0.125, total=4062.56, n_correct=2737.41, ppl=4.19, accuracy=67.381, wps=14101.2, ups=1.74, wpb=8125.1, bsz=293, num_updates=30300, lr=8.12444e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=22710
2023-08-16 17:43:38 | INFO | train_inner | epoch 021:    933 / 1474 loss=2.016, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.691, task_loss=0, contrastive_loss=0.096, total=4103.66, n_correct=2778.11, ppl=4.15, accuracy=67.698, wps=14314.4, ups=1.74, wpb=8207.3, bsz=301.5, num_updates=30400, lr=8.11107e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=17.2, wall=22767
2023-08-16 17:44:35 | INFO | train_inner | epoch 021:   1033 / 1474 loss=2.021, trans_loss=4.845, nll_loss=2.069, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.094, total=4100.54, n_correct=2766.45, ppl=4.19, accuracy=67.466, wps=14379.8, ups=1.75, wpb=8201.1, bsz=298.2, num_updates=30500, lr=8.09776e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=17.9, wall=22824
2023-08-16 17:45:32 | INFO | train_inner | epoch 021:   1133 / 1474 loss=2.018, trans_loss=4.834, nll_loss=2.054, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.097, total=4119.98, n_correct=2786.03, ppl=4.15, accuracy=67.622, wps=14427.3, ups=1.75, wpb=8240, bsz=294, num_updates=30600, lr=8.08452e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=17.9, wall=22881
2023-08-16 17:46:29 | INFO | train_inner | epoch 021:   1233 / 1474 loss=2.026, trans_loss=4.837, nll_loss=2.06, w2v_ctc_loss=0.693, task_loss=0, contrastive_loss=0.149, total=4161.49, n_correct=2813.76, ppl=4.17, accuracy=67.614, wps=14541.8, ups=1.75, wpb=8323, bsz=313, num_updates=30700, lr=8.07134e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=22939
2023-08-16 17:47:27 | INFO | train_inner | epoch 021:   1333 / 1474 loss=2.02, trans_loss=4.837, nll_loss=2.06, w2v_ctc_loss=0.691, task_loss=0, contrastive_loss=0.11, total=4141.76, n_correct=2802.49, ppl=4.17, accuracy=67.664, wps=14407.9, ups=1.74, wpb=8283.5, bsz=311.7, num_updates=30800, lr=8.05823e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=22996
2023-08-16 17:48:24 | INFO | train_inner | epoch 021:   1433 / 1474 loss=2.039, trans_loss=4.846, nll_loss=2.071, w2v_ctc_loss=0.714, task_loss=0, contrastive_loss=0.159, total=4127.02, n_correct=2776.6, ppl=4.2, accuracy=67.279, wps=14298.3, ups=1.73, wpb=8254, bsz=302.1, num_updates=30900, lr=8.04518e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=23054
2023-08-16 17:48:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:2')
2023-08-16 17:49:10 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.09 | trans_loss 5.162 | nll_loss 2.421 | w2v_ctc_loss 1.333 | task_loss 0 | contrastive_loss 0.31 | total 4003.4 | n_correct 2666.5 | ppl 5.36 | accuracy 66.606 | uer 17.859 | wer 19.846 | raw_wer 19.846 | bleu 22.3 | wps 2297.7 | wpb 4003.4 | bsz 141.8 | num_updates 30941 | best_bleu 22.56
2023-08-16 17:49:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30941 updates
2023-08-16 17:49:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.3008.pt
2023-08-16 17:49:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.3008.pt
2023-08-16 17:49:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.3008.pt (epoch 21 @ 30941 updates, score 22.3) (writing took 24.03209413960576 seconds)
2023-08-16 17:49:35 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-16 17:49:35 | INFO | train | epoch 021 | loss 2.022 | trans_loss 4.835 | nll_loss 2.056 | w2v_ctc_loss 0.692 | task_loss 0 | contrastive_loss 0.137 | total 4138.9 | n_correct 2799.42 | ppl 4.16 | accuracy 67.637 | wps 12621.9 | ups 1.52 | wpb 8277.8 | bsz 305.7 | num_updates 30941 | lr 8.03985e-05 | gnorm 0.548 | clip 0 | loss_scale 32 | train_wall 841 | gb_free 15.5 | wall 23124
2023-08-16 17:49:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 17:49:35 | INFO | fairseq.trainer | begin training epoch 22
2023-08-16 17:49:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 17:50:17 | INFO | train_inner | epoch 022:     59 / 1474 loss=2.01, trans_loss=4.823, nll_loss=2.041, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.08, total=4140.16, n_correct=2812.66, ppl=4.12, accuracy=67.936, wps=7372, ups=0.89, wpb=8280.3, bsz=300.1, num_updates=31000, lr=8.03219e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=17.7, wall=23166
2023-08-16 17:51:14 | INFO | train_inner | epoch 022:    159 / 1474 loss=2.018, trans_loss=4.82, nll_loss=2.036, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.159, total=4115.86, n_correct=2795.87, ppl=4.1, accuracy=67.929, wps=14332.4, ups=1.74, wpb=8231.7, bsz=309.4, num_updates=31100, lr=8.01927e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=23224
2023-08-16 17:52:12 | INFO | train_inner | epoch 022:    259 / 1474 loss=2.003, trans_loss=4.815, nll_loss=2.031, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.091, total=4247.73, n_correct=2894.58, ppl=4.09, accuracy=68.144, wps=14700, ups=1.73, wpb=8495.5, bsz=323.2, num_updates=31200, lr=8.00641e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=57, gb_free=14.1, wall=23281
2023-08-16 17:52:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-16 17:53:11 | INFO | train_inner | epoch 022:    360 / 1474 loss=2.027, trans_loss=4.826, nll_loss=2.045, w2v_ctc_loss=0.69, task_loss=0, contrastive_loss=0.207, total=4186, n_correct=2836.04, ppl=4.13, accuracy=67.751, wps=14268.7, ups=1.7, wpb=8372, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=58, gb_free=17.6, wall=23340
2023-08-16 17:54:08 | INFO | train_inner | epoch 022:    460 / 1474 loss=2.02, trans_loss=4.827, nll_loss=2.044, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.144, total=4132.62, n_correct=2800.79, ppl=4.13, accuracy=67.773, wps=14358.9, ups=1.74, wpb=8265.2, bsz=297.2, num_updates=31400, lr=7.98087e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=57, gb_free=16.6, wall=23398
2023-08-16 17:55:06 | INFO | train_inner | epoch 022:    560 / 1474 loss=2.007, trans_loss=4.819, nll_loss=2.035, w2v_ctc_loss=0.683, task_loss=0, contrastive_loss=0.089, total=4155.5, n_correct=2825.5, ppl=4.1, accuracy=67.994, wps=14402.1, ups=1.73, wpb=8311, bsz=307.3, num_updates=31500, lr=7.96819e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=57, gb_free=16.5, wall=23455
2023-08-16 17:56:03 | INFO | train_inner | epoch 022:    660 / 1474 loss=2.009, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.172, total=4147.84, n_correct=2824.86, ppl=4.08, accuracy=68.104, wps=14450, ups=1.74, wpb=8295.7, bsz=313.1, num_updates=31600, lr=7.95557e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=57, gb_free=13.3, wall=23513
2023-08-16 17:57:01 | INFO | train_inner | epoch 022:    760 / 1474 loss=2.008, trans_loss=4.818, nll_loss=2.034, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.091, total=4166.89, n_correct=2831.99, ppl=4.09, accuracy=67.964, wps=14488.3, ups=1.74, wpb=8333.8, bsz=304.3, num_updates=31700, lr=7.94301e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=57, gb_free=16, wall=23570
2023-08-16 17:57:59 | INFO | train_inner | epoch 022:    860 / 1474 loss=2.015, trans_loss=4.833, nll_loss=2.053, w2v_ctc_loss=0.692, task_loss=0, contrastive_loss=0.079, total=4074.75, n_correct=2751.4, ppl=4.15, accuracy=67.523, wps=14151.6, ups=1.74, wpb=8149.5, bsz=288.4, num_updates=31800, lr=7.93052e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=57, gb_free=17.6, wall=23628
2023-08-16 17:58:56 | INFO | train_inner | epoch 022:    960 / 1474 loss=2.005, trans_loss=4.821, nll_loss=2.038, w2v_ctc_loss=0.68, task_loss=0, contrastive_loss=0.08, total=4136.34, n_correct=2809.05, ppl=4.11, accuracy=67.911, wps=14503.3, ups=1.75, wpb=8272.7, bsz=303.7, num_updates=31900, lr=7.91808e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=23685
2023-08-16 17:59:53 | INFO | train_inner | epoch 022:   1060 / 1474 loss=2.019, trans_loss=4.819, nll_loss=2.035, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.249, total=4157.21, n_correct=2825.18, ppl=4.1, accuracy=67.959, wps=14570.6, ups=1.75, wpb=8314.4, bsz=315.4, num_updates=32000, lr=7.90569e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=57, gb_free=12.4, wall=23742
2023-08-16 17:59:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 18:00:14 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.09 | trans_loss 5.157 | nll_loss 2.417 | w2v_ctc_loss 1.352 | task_loss 0 | contrastive_loss 0.3 | total 4003.4 | n_correct 2671.4 | ppl 5.34 | accuracy 66.728 | uer 17.747 | wer 19.895 | raw_wer 19.895 | bleu 22.07 | wps 2366.4 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 22.56
2023-08-16 18:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-16 18:00:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-16 18:00:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-16 18:00:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 22.07) (writing took 43.775348618626595 seconds)
2023-08-16 18:01:56 | INFO | train_inner | epoch 022:   1160 / 1474 loss=2.024, trans_loss=4.841, nll_loss=2.064, w2v_ctc_loss=0.694, task_loss=0, contrastive_loss=0.131, total=4092.91, n_correct=2764.5, ppl=4.18, accuracy=67.544, wps=6648.8, ups=0.81, wpb=8185.8, bsz=294.3, num_updates=32100, lr=7.89337e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=56, gb_free=16.1, wall=23865
2023-08-16 18:02:53 | INFO | train_inner | epoch 022:   1260 / 1474 loss=2.025, trans_loss=4.84, nll_loss=2.063, w2v_ctc_loss=0.695, task_loss=0, contrastive_loss=0.125, total=4182.65, n_correct=2825.57, ppl=4.18, accuracy=67.555, wps=14549.9, ups=1.74, wpb=8365.3, bsz=323.6, num_updates=32200, lr=7.8811e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=57, gb_free=16.3, wall=23923
2023-08-16 18:03:50 | INFO | train_inner | epoch 022:   1360 / 1474 loss=2.013, trans_loss=4.824, nll_loss=2.043, w2v_ctc_loss=0.681, task_loss=0, contrastive_loss=0.15, total=4071.58, n_correct=2762.93, ppl=4.12, accuracy=67.859, wps=14268.4, ups=1.75, wpb=8143.2, bsz=300.6, num_updates=32300, lr=7.86889e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=23980
2023-08-16 18:04:47 | INFO | train_inner | epoch 022:   1460 / 1474 loss=2.017, trans_loss=4.835, nll_loss=2.056, w2v_ctc_loss=0.697, task_loss=0, contrastive_loss=0.095, total=4077.83, n_correct=2757.25, ppl=4.16, accuracy=67.616, wps=14274.1, ups=1.75, wpb=8155.7, bsz=288, num_updates=32400, lr=7.85674e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=57, gb_free=16.2, wall=24037
2023-08-16 18:04:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 18:05:20 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.081 | trans_loss 5.152 | nll_loss 2.409 | w2v_ctc_loss 1.331 | task_loss 0 | contrastive_loss 0.307 | total 4003.4 | n_correct 2672 | ppl 5.31 | accuracy 66.743 | uer 17.745 | wer 19.72 | raw_wer 19.72 | bleu 22.24 | wps 2220 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 22.56
2023-08-16 18:05:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-08-16 18:05:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.2401.pt
2023-08-16 18:05:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.2401.pt
2023-08-16 18:05:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.2401.pt (epoch 22 @ 32414 updates, score 22.24) (writing took 24.35378909483552 seconds)
2023-08-16 18:05:45 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-16 18:05:45 | INFO | train | epoch 022 | loss 2.015 | trans_loss 4.825 | nll_loss 2.043 | w2v_ctc_loss 0.686 | task_loss 0 | contrastive_loss 0.131 | total 4137.49 | n_correct 2806.81 | ppl 4.12 | accuracy 67.839 | wps 12564.4 | ups 1.52 | wpb 8275 | bsz 305.2 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.549 | clip 0 | loss_scale 16 | train_wall 839 | gb_free 12 | wall 24094
2023-08-16 18:05:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 18:05:45 | INFO | fairseq.trainer | begin training epoch 23
2023-08-16 18:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 18:06:43 | INFO | train_inner | epoch 023:     86 / 1474 loss=2.004, trans_loss=4.809, nll_loss=2.023, w2v_ctc_loss=0.688, task_loss=0, contrastive_loss=0.085, total=4089.8, n_correct=2787.15, ppl=4.06, accuracy=68.149, wps=7108.6, ups=0.87, wpb=8179.6, bsz=299.5, num_updates=32500, lr=7.84465e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=24152
2023-08-16 18:07:40 | INFO | train_inner | epoch 023:    186 / 1474 loss=1.995, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.083, total=4117.76, n_correct=2812.23, ppl=4.03, accuracy=68.295, wps=14364.7, ups=1.74, wpb=8235.5, bsz=296, num_updates=32600, lr=7.8326e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=57, gb_free=15.5, wall=24209
2023-08-16 18:08:38 | INFO | train_inner | epoch 023:    286 / 1474 loss=2.009, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.161, total=4144.73, n_correct=2824.15, ppl=4.08, accuracy=68.138, wps=14371.1, ups=1.73, wpb=8289.5, bsz=304, num_updates=32700, lr=7.82062e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=57, gb_free=17.6, wall=24267
2023-08-16 18:09:35 | INFO | train_inner | epoch 023:    386 / 1474 loss=1.994, trans_loss=4.803, nll_loss=2.014, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.075, total=4126.79, n_correct=2819.42, ppl=4.04, accuracy=68.32, wps=14342.4, ups=1.74, wpb=8253.6, bsz=296.4, num_updates=32800, lr=7.80869e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=57, gb_free=17.1, wall=24324
2023-08-16 18:10:32 | INFO | train_inner | epoch 023:    486 / 1474 loss=2.006, trans_loss=4.813, nll_loss=2.027, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.132, total=4150.15, n_correct=2827.27, ppl=4.08, accuracy=68.125, wps=14581.9, ups=1.76, wpb=8300.3, bsz=312.1, num_updates=32900, lr=7.79681e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=56, gb_free=16.3, wall=24381
2023-08-16 18:11:29 | INFO | train_inner | epoch 023:    586 / 1474 loss=1.995, trans_loss=4.803, nll_loss=2.015, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.08, total=4174.6, n_correct=2852.62, ppl=4.04, accuracy=68.333, wps=14583.9, ups=1.75, wpb=8349.2, bsz=316.3, num_updates=33000, lr=7.78499e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=57, gb_free=16.4, wall=24439
2023-08-16 18:12:27 | INFO | train_inner | epoch 023:    686 / 1474 loss=2.006, trans_loss=4.814, nll_loss=2.029, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.12, total=4136.6, n_correct=2818.3, ppl=4.08, accuracy=68.131, wps=14425.2, ups=1.74, wpb=8273.2, bsz=301.2, num_updates=33100, lr=7.77322e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=57, gb_free=17.7, wall=24496
2023-08-16 18:13:24 | INFO | train_inner | epoch 023:    786 / 1474 loss=2.007, trans_loss=4.817, nll_loss=2.033, w2v_ctc_loss=0.684, task_loss=0, contrastive_loss=0.099, total=4147.22, n_correct=2820.35, ppl=4.09, accuracy=68.006, wps=14466.1, ups=1.74, wpb=8294.4, bsz=305.1, num_updates=33200, lr=7.76151e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=57, gb_free=17.3, wall=24553
2023-08-16 18:14:21 | INFO | train_inner | epoch 023:    886 / 1474 loss=2.008, trans_loss=4.806, nll_loss=2.019, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.179, total=4193.16, n_correct=2864.21, ppl=4.05, accuracy=68.307, wps=14614.8, ups=1.74, wpb=8386.3, bsz=327.3, num_updates=33300, lr=7.74984e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=57, gb_free=16, wall=24611
2023-08-16 18:15:19 | INFO | train_inner | epoch 023:    986 / 1474 loss=2.023, trans_loss=4.813, nll_loss=2.028, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.334, total=4164.33, n_correct=2835.16, ppl=4.08, accuracy=68.082, wps=14391, ups=1.73, wpb=8328.7, bsz=310.1, num_updates=33400, lr=7.73823e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=17.7, wall=24669
2023-08-16 18:16:16 | INFO | train_inner | epoch 023:   1086 / 1474 loss=2.008, trans_loss=4.819, nll_loss=2.036, w2v_ctc_loss=0.689, task_loss=0, contrastive_loss=0.087, total=4088.37, n_correct=2776.89, ppl=4.1, accuracy=67.922, wps=14304.7, ups=1.75, wpb=8176.7, bsz=289.6, num_updates=33500, lr=7.72667e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=15.6, wall=24726
2023-08-16 18:17:14 | INFO | train_inner | epoch 023:   1186 / 1474 loss=2.005, trans_loss=4.82, nll_loss=2.037, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.079, total=4162.3, n_correct=2827.82, ppl=4.1, accuracy=67.939, wps=14369.4, ups=1.73, wpb=8324.6, bsz=309, num_updates=33600, lr=7.71517e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=24784
2023-08-16 18:18:12 | INFO | train_inner | epoch 023:   1286 / 1474 loss=2.001, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.091, total=4131.74, n_correct=2814.23, ppl=4.08, accuracy=68.112, wps=14418, ups=1.74, wpb=8263.5, bsz=308.7, num_updates=33700, lr=7.70371e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=24841
2023-08-16 18:19:10 | INFO | train_inner | epoch 023:   1386 / 1474 loss=2.016, trans_loss=4.827, nll_loss=2.046, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.147, total=4141.25, n_correct=2809.19, ppl=4.13, accuracy=67.834, wps=14265.3, ups=1.72, wpb=8282.5, bsz=304.7, num_updates=33800, lr=7.69231e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=58, gb_free=16.8, wall=24899
2023-08-16 18:20:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 18:20:24 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.091 | trans_loss 5.156 | nll_loss 2.413 | w2v_ctc_loss 1.366 | task_loss 0 | contrastive_loss 0.293 | total 4003.4 | n_correct 2677.6 | ppl 5.32 | accuracy 66.883 | uer 17.591 | wer 19.455 | raw_wer 19.455 | bleu 22.22 | wps 2113.8 | wpb 4003.4 | bsz 141.8 | num_updates 33888 | best_bleu 22.56
2023-08-16 18:20:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33888 updates
2023-08-16 18:20:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.2201.pt
2023-08-16 18:20:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.2201.pt
2023-08-16 18:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.2201.pt (epoch 23 @ 33888 updates, score 22.22) (writing took 17.365923581644893 seconds)
2023-08-16 18:20:42 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-16 18:20:42 | INFO | train | epoch 023 | loss 2.007 | trans_loss 4.813 | nll_loss 2.028 | w2v_ctc_loss 0.678 | task_loss 0 | contrastive_loss 0.133 | total 4138.65 | n_correct 2818.54 | ppl 4.08 | accuracy 68.103 | wps 13596.2 | ups 1.64 | wpb 8277.3 | bsz 305.7 | num_updates 33888 | lr 7.68231e-05 | gnorm 0.548 | clip 0 | loss_scale 32 | train_wall 840 | gb_free 13.9 | wall 24992
2023-08-16 18:20:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 18:20:43 | INFO | fairseq.trainer | begin training epoch 24
2023-08-16 18:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 18:20:58 | INFO | train_inner | epoch 024:     12 / 1474 loss=2.023, trans_loss=4.825, nll_loss=2.044, w2v_ctc_loss=0.675, task_loss=0, contrastive_loss=0.224, total=4095.53, n_correct=2777.09, ppl=4.13, accuracy=67.808, wps=7572.9, ups=0.92, wpb=8191.1, bsz=306.3, num_updates=33900, lr=7.68095e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=25007
2023-08-16 18:21:56 | INFO | train_inner | epoch 024:    112 / 1474 loss=2.007, trans_loss=4.793, nll_loss=2.001, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.248, total=4167.42, n_correct=2853.37, ppl=4, accuracy=68.469, wps=14447.6, ups=1.73, wpb=8334.8, bsz=323, num_updates=34000, lr=7.66965e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=25065
2023-08-16 18:21:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 18:22:19 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.093 | trans_loss 5.162 | nll_loss 2.417 | w2v_ctc_loss 1.356 | task_loss 0 | contrastive_loss 0.296 | total 4003.4 | n_correct 2671.6 | ppl 5.34 | accuracy 66.733 | uer 17.49 | wer 19.429 | raw_wer 19.429 | bleu 22.45 | wps 2257.4 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.56
2023-08-16 18:22:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-16 18:22:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-16 18:22:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-16 18:23:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 22.45) (writing took 45.638751635327935 seconds)
2023-08-16 18:24:03 | INFO | train_inner | epoch 024:    212 / 1474 loss=2.011, trans_loss=4.8, nll_loss=2.011, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.299, total=4247.08, n_correct=2908.9, ppl=4.03, accuracy=68.492, wps=6660.1, ups=0.78, wpb=8494.2, bsz=339.5, num_updates=34100, lr=7.6584e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=58, gb_free=16.4, wall=25192
2023-08-16 18:25:00 | INFO | train_inner | epoch 024:    312 / 1474 loss=1.991, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.076, total=4139.31, n_correct=2834.47, ppl=4.02, accuracy=68.477, wps=14488.4, ups=1.75, wpb=8278.6, bsz=308.4, num_updates=34200, lr=7.64719e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=25250
2023-08-16 18:25:58 | INFO | train_inner | epoch 024:    412 / 1474 loss=2.015, trans_loss=4.802, nll_loss=2.012, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.22, total=4157.07, n_correct=2836.08, ppl=4.03, accuracy=68.223, wps=14394.6, ups=1.73, wpb=8314.1, bsz=299.9, num_updates=34300, lr=7.63604e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=25307
2023-08-16 18:26:56 | INFO | train_inner | epoch 024:    512 / 1474 loss=2.001, trans_loss=4.801, nll_loss=2.011, w2v_ctc_loss=0.676, task_loss=0, contrastive_loss=0.148, total=4138.82, n_correct=2827.13, ppl=4.03, accuracy=68.308, wps=14292.2, ups=1.73, wpb=8277.6, bsz=301.6, num_updates=34400, lr=7.62493e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=25365
2023-08-16 18:27:54 | INFO | train_inner | epoch 024:    612 / 1474 loss=1.991, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.107, total=4164.75, n_correct=2849.73, ppl=4.02, accuracy=68.425, wps=14479.3, ups=1.74, wpb=8329.5, bsz=309.1, num_updates=34500, lr=7.61387e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=25423
2023-08-16 18:28:51 | INFO | train_inner | epoch 024:    712 / 1474 loss=2.001, trans_loss=4.81, nll_loss=2.022, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.122, total=4103.92, n_correct=2796.91, ppl=4.06, accuracy=68.152, wps=14324.3, ups=1.75, wpb=8207.8, bsz=294, num_updates=34600, lr=7.60286e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=12.4, wall=25480
2023-08-16 18:29:48 | INFO | train_inner | epoch 024:    812 / 1474 loss=1.999, trans_loss=4.81, nll_loss=2.025, w2v_ctc_loss=0.674, task_loss=0, contrastive_loss=0.096, total=4109.8, n_correct=2803.06, ppl=4.07, accuracy=68.204, wps=14330.7, ups=1.74, wpb=8219.6, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=17.2, wall=25537
2023-08-16 18:30:45 | INFO | train_inner | epoch 024:    912 / 1474 loss=1.998, trans_loss=4.808, nll_loss=2.02, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.072, total=4042.08, n_correct=2752.67, ppl=4.06, accuracy=68.1, wps=14137.8, ups=1.75, wpb=8084.2, bsz=280.6, num_updates=34800, lr=7.58098e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=25595
2023-08-16 18:31:43 | INFO | train_inner | epoch 024:   1012 / 1474 loss=1.996, trans_loss=4.809, nll_loss=2.023, w2v_ctc_loss=0.672, task_loss=0, contrastive_loss=0.077, total=4140.44, n_correct=2824.07, ppl=4.06, accuracy=68.207, wps=14398, ups=1.74, wpb=8280.9, bsz=298.7, num_updates=34900, lr=7.57011e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=12.1, wall=25652
2023-08-16 18:32:40 | INFO | train_inner | epoch 024:   1112 / 1474 loss=1.994, trans_loss=4.793, nll_loss=2.001, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.118, total=4134.93, n_correct=2834.8, ppl=4, accuracy=68.557, wps=14472.5, ups=1.75, wpb=8269.9, bsz=309.4, num_updates=35000, lr=7.55929e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=25709
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:0')
2023-08-16 18:33:38 | INFO | train_inner | epoch 024:   1212 / 1474 loss=2, trans_loss=4.806, nll_loss=2.019, w2v_ctc_loss=0.673, task_loss=0, contrastive_loss=0.107, total=4144.49, n_correct=2829.83, ppl=4.05, accuracy=68.279, wps=14341.6, ups=1.73, wpb=8289, bsz=309.8, num_updates=35100, lr=7.54851e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=25767
2023-08-16 18:34:35 | INFO | train_inner | epoch 024:   1312 / 1474 loss=1.998, trans_loss=4.807, nll_loss=2.02, w2v_ctc_loss=0.682, task_loss=0, contrastive_loss=0.077, total=4110.93, n_correct=2804.68, ppl=4.05, accuracy=68.225, wps=14273, ups=1.74, wpb=8221.9, bsz=293, num_updates=35200, lr=7.53778e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=13.8, wall=25825
2023-08-16 18:35:33 | INFO | train_inner | epoch 024:   1412 / 1474 loss=2.003, trans_loss=4.812, nll_loss=2.028, w2v_ctc_loss=0.685, task_loss=0, contrastive_loss=0.084, total=4088.73, n_correct=2785.68, ppl=4.08, accuracy=68.131, wps=14189.9, ups=1.74, wpb=8177.5, bsz=294.1, num_updates=35300, lr=7.5271e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=17.7, wall=25882
2023-08-16 18:36:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:7')
2023-08-16 18:36:30 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.081 | trans_loss 5.156 | nll_loss 2.413 | w2v_ctc_loss 1.33 | task_loss 0 | contrastive_loss 0.294 | total 4003.4 | n_correct 2682 | ppl 5.33 | accuracy 66.993 | uer 17.53 | wer 19.384 | raw_wer 19.384 | bleu 22.87 | wps 2411.5 | wpb 4003.4 | bsz 141.8 | num_updates 35362 | best_bleu 22.87
2023-08-16 18:36:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35362 updates
2023-08-16 18:36:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 18:36:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-16 18:37:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_best.pt (epoch 24 @ 35362 updates, score 22.87) (writing took 31.06606381945312 seconds)
2023-08-16 18:37:02 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-16 18:37:02 | INFO | train | epoch 024 | loss 2 | trans_loss 4.803 | nll_loss 2.015 | w2v_ctc_loss 0.671 | task_loss 0 | contrastive_loss 0.132 | total 4138.65 | n_correct 2827.17 | ppl 4.04 | accuracy 68.311 | wps 12454.9 | ups 1.5 | wpb 8277.3 | bsz 305.7 | num_updates 35362 | lr 7.5205e-05 | gnorm 0.549 | clip 0 | loss_scale 64 | train_wall 841 | gb_free 16.2 | wall 25971
2023-08-16 18:37:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 18:37:02 | INFO | fairseq.trainer | begin training epoch 25
2023-08-16 18:37:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 18:37:32 | INFO | train_inner | epoch 025:     38 / 1474 loss=1.988, trans_loss=4.798, nll_loss=2.009, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.086, total=4170.36, n_correct=2859.76, ppl=4.02, accuracy=68.573, wps=7022.4, ups=0.84, wpb=8340.7, bsz=313, num_updates=35400, lr=7.51646e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=57, gb_free=16.3, wall=26001
2023-08-16 18:38:30 | INFO | train_inner | epoch 025:    138 / 1474 loss=1.979, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.083, total=4133.56, n_correct=2845.08, ppl=3.96, accuracy=68.829, wps=14326.7, ups=1.73, wpb=8267.1, bsz=306.4, num_updates=35500, lr=7.50587e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=57, gb_free=17.1, wall=26059
2023-08-16 18:39:27 | INFO | train_inner | epoch 025:    238 / 1474 loss=1.987, trans_loss=4.789, nll_loss=1.996, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.087, total=4112.46, n_correct=2823.13, ppl=3.99, accuracy=68.648, wps=14339.3, ups=1.74, wpb=8224.9, bsz=303.4, num_updates=35600, lr=7.49532e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=57, gb_free=17, wall=26116
2023-08-16 18:40:25 | INFO | train_inner | epoch 025:    338 / 1474 loss=1.987, trans_loss=4.787, nll_loss=1.993, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.117, total=4139.11, n_correct=2836.29, ppl=3.98, accuracy=68.524, wps=14245.3, ups=1.72, wpb=8278.2, bsz=291.7, num_updates=35700, lr=7.48481e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=58, gb_free=15.1, wall=26174
2023-08-16 18:41:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-16 18:41:23 | INFO | train_inner | epoch 025:    439 / 1474 loss=1.989, trans_loss=4.786, nll_loss=1.992, w2v_ctc_loss=0.677, task_loss=0, contrastive_loss=0.078, total=4158.38, n_correct=2854.52, ppl=3.98, accuracy=68.645, wps=14310.1, ups=1.72, wpb=8316.8, bsz=293.8, num_updates=35800, lr=7.47435e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=58, gb_free=12.6, wall=26232
2023-08-16 18:42:21 | INFO | train_inner | epoch 025:    539 / 1474 loss=1.993, trans_loss=4.801, nll_loss=2.011, w2v_ctc_loss=0.668, task_loss=0, contrastive_loss=0.088, total=4156.93, n_correct=2844.81, ppl=4.03, accuracy=68.435, wps=14284, ups=1.72, wpb=8313.9, bsz=312.8, num_updates=35900, lr=7.46393e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=58, gb_free=17, wall=26291
2023-08-16 18:43:19 | INFO | train_inner | epoch 025:    639 / 1474 loss=1.995, trans_loss=4.787, nll_loss=1.995, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.155, total=4153.23, n_correct=2847.83, ppl=3.99, accuracy=68.569, wps=14505, ups=1.75, wpb=8306.5, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=15, wall=26348
2023-08-16 18:43:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 18:43:42 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.097 | trans_loss 5.157 | nll_loss 2.412 | w2v_ctc_loss 1.387 | task_loss 0 | contrastive_loss 0.287 | total 4003.4 | n_correct 2674.3 | ppl 5.32 | accuracy 66.801 | uer 17.524 | wer 19.291 | raw_wer 19.291 | bleu 22.41 | wps 2280.4 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.87
2023-08-16 18:43:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-16 18:43:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-16 18:43:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-16 18:44:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.41) (writing took 43.81712128221989 seconds)
2023-08-16 18:45:24 | INFO | train_inner | epoch 025:    739 / 1474 loss=1.995, trans_loss=4.789, nll_loss=1.996, w2v_ctc_loss=0.667, task_loss=0, contrastive_loss=0.149, total=4123.21, n_correct=2825.91, ppl=3.99, accuracy=68.537, wps=6570.5, ups=0.8, wpb=8246.4, bsz=300.7, num_updates=36100, lr=7.44323e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=14.9, wall=26473
2023-08-16 18:46:21 | INFO | train_inner | epoch 025:    839 / 1474 loss=1.99, trans_loss=4.794, nll_loss=2.003, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.096, total=4197.27, n_correct=2879.26, ppl=4.01, accuracy=68.598, wps=14696.3, ups=1.75, wpb=8394.5, bsz=328.2, num_updates=36200, lr=7.43294e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=26531
2023-08-16 18:47:19 | INFO | train_inner | epoch 025:    939 / 1474 loss=1.996, trans_loss=4.795, nll_loss=2.004, w2v_ctc_loss=0.665, task_loss=0, contrastive_loss=0.152, total=4137.23, n_correct=2833.95, ppl=4.01, accuracy=68.499, wps=14245.5, ups=1.72, wpb=8274.5, bsz=313.3, num_updates=36300, lr=7.4227e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=58, gb_free=16.6, wall=26589
2023-08-16 18:48:17 | INFO | train_inner | epoch 025:   1039 / 1474 loss=2.007, trans_loss=4.803, nll_loss=2.015, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.264, total=4183.45, n_correct=2856.68, ppl=4.04, accuracy=68.285, wps=14600.8, ups=1.75, wpb=8366.9, bsz=311, num_updates=36400, lr=7.41249e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=26646
2023-08-16 18:49:14 | INFO | train_inner | epoch 025:   1139 / 1474 loss=1.984, trans_loss=4.794, nll_loss=2.002, w2v_ctc_loss=0.66, task_loss=0, contrastive_loss=0.072, total=4045.24, n_correct=2771.08, ppl=4.01, accuracy=68.502, wps=14119, ups=1.75, wpb=8090.5, bsz=287, num_updates=36500, lr=7.40233e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=26703
2023-08-16 18:50:11 | INFO | train_inner | epoch 025:   1239 / 1474 loss=1.988, trans_loss=4.8, nll_loss=2.01, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.075, total=4079.17, n_correct=2792.12, ppl=4.03, accuracy=68.448, wps=14386.6, ups=1.76, wpb=8158.3, bsz=292.3, num_updates=36600, lr=7.39221e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=56, gb_free=17, wall=26760
2023-08-16 18:51:08 | INFO | train_inner | epoch 025:   1339 / 1474 loss=1.996, trans_loss=4.794, nll_loss=2.003, w2v_ctc_loss=0.662, task_loss=0, contrastive_loss=0.177, total=4173.55, n_correct=2861.76, ppl=4.01, accuracy=68.569, wps=14531.3, ups=1.74, wpb=8347.1, bsz=312.7, num_updates=36700, lr=7.38213e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=26817
2023-08-16 18:52:06 | INFO | train_inner | epoch 025:   1439 / 1474 loss=2.002, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.671, task_loss=0, contrastive_loss=0.124, total=4102.27, n_correct=2793.97, ppl=4.06, accuracy=68.108, wps=14263.7, ups=1.74, wpb=8204.5, bsz=299.9, num_updates=36800, lr=7.3721e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=15.9, wall=26875
2023-08-16 18:52:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 18:52:49 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.084 | trans_loss 5.152 | nll_loss 2.407 | w2v_ctc_loss 1.355 | task_loss 0 | contrastive_loss 0.289 | total 4003.4 | n_correct 2679.9 | ppl 5.3 | accuracy 66.941 | uer 17.596 | wer 19.488 | raw_wer 19.488 | bleu 22.52 | wps 2288.5 | wpb 4003.4 | bsz 141.8 | num_updates 36835 | best_bleu 22.87
2023-08-16 18:52:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36835 updates
2023-08-16 18:52:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.5209.pt
2023-08-16 18:52:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.5209.pt
2023-08-16 18:53:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.5209.pt (epoch 25 @ 36835 updates, score 22.52) (writing took 24.708349438384175 seconds)
2023-08-16 18:53:14 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-16 18:53:14 | INFO | train | epoch 025 | loss 1.992 | trans_loss 4.794 | nll_loss 2.002 | w2v_ctc_loss 0.665 | task_loss 0 | contrastive_loss 0.122 | total 4137.25 | n_correct 2834.5 | ppl 4.01 | accuracy 68.512 | wps 12542.8 | ups 1.52 | wpb 8274.5 | bsz 305.1 | num_updates 36835 | lr 7.36859e-05 | gnorm 0.548 | clip 0 | loss_scale 32 | train_wall 841 | gb_free 14.5 | wall 26943
2023-08-16 18:53:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 18:53:14 | INFO | fairseq.trainer | begin training epoch 26
2023-08-16 18:53:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 18:53:59 | INFO | train_inner | epoch 026:     65 / 1474 loss=1.98, trans_loss=4.779, nll_loss=1.983, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.11, total=4178.19, n_correct=2874.09, ppl=3.95, accuracy=68.788, wps=7377.2, ups=0.88, wpb=8356.4, bsz=317.5, num_updates=36900, lr=7.3621e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=14.5, wall=26988
2023-08-16 18:54:57 | INFO | train_inner | epoch 026:    165 / 1474 loss=1.998, trans_loss=4.78, nll_loss=1.986, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.291, total=4269.55, n_correct=2940.69, ppl=3.96, accuracy=68.876, wps=14780.2, ups=1.73, wpb=8539.1, bsz=341.4, num_updates=37000, lr=7.35215e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=57, gb_free=15.5, wall=27046
2023-08-16 18:55:54 | INFO | train_inner | epoch 026:    265 / 1474 loss=1.991, trans_loss=4.778, nll_loss=1.982, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.171, total=4128.39, n_correct=2839.3, ppl=3.95, accuracy=68.775, wps=14349.5, ups=1.74, wpb=8256.8, bsz=306.8, num_updates=37100, lr=7.34223e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=10.4, wall=27104
2023-08-16 18:56:51 | INFO | train_inner | epoch 026:    365 / 1474 loss=1.987, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.659, task_loss=0, contrastive_loss=0.127, total=4166.22, n_correct=2865.77, ppl=3.96, accuracy=68.786, wps=14570.6, ups=1.75, wpb=8332.4, bsz=315, num_updates=37200, lr=7.33236e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=57, gb_free=16.7, wall=27161
2023-08-16 18:57:49 | INFO | train_inner | epoch 026:    465 / 1474 loss=1.987, trans_loss=4.772, nll_loss=1.975, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.173, total=4171.18, n_correct=2878.02, ppl=3.93, accuracy=68.998, wps=14526.5, ups=1.74, wpb=8342.4, bsz=315.5, num_updates=37300, lr=7.32252e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=27218
2023-08-16 18:58:46 | INFO | train_inner | epoch 026:    565 / 1474 loss=1.986, trans_loss=4.784, nll_loss=1.99, w2v_ctc_loss=0.67, task_loss=0, contrastive_loss=0.091, total=4139.82, n_correct=2844.45, ppl=3.97, accuracy=68.71, wps=14397.7, ups=1.74, wpb=8279.6, bsz=300, num_updates=37400, lr=7.31272e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=15.2, wall=27276
2023-08-16 18:59:44 | INFO | train_inner | epoch 026:    665 / 1474 loss=1.976, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.078, total=4146.72, n_correct=2850, ppl=3.96, accuracy=68.729, wps=14361.6, ups=1.73, wpb=8293.4, bsz=302.7, num_updates=37500, lr=7.30297e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=27333
2023-08-16 19:00:41 | INFO | train_inner | epoch 026:    765 / 1474 loss=1.995, trans_loss=4.788, nll_loss=1.994, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.192, total=4084.89, n_correct=2801.9, ppl=3.98, accuracy=68.592, wps=14357, ups=1.76, wpb=8169.8, bsz=297.2, num_updates=37600, lr=7.29325e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=56, gb_free=17.3, wall=27390
2023-08-16 19:01:38 | INFO | train_inner | epoch 026:    865 / 1474 loss=1.985, trans_loss=4.783, nll_loss=1.989, w2v_ctc_loss=0.664, task_loss=0, contrastive_loss=0.091, total=4180.78, n_correct=2870.3, ppl=3.97, accuracy=68.655, wps=14563.8, ups=1.74, wpb=8361.6, bsz=309.6, num_updates=37700, lr=7.28357e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=16, wall=27448
2023-08-16 19:02:36 | INFO | train_inner | epoch 026:    965 / 1474 loss=1.986, trans_loss=4.789, nll_loss=1.996, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.143, total=4147.79, n_correct=2845.87, ppl=3.99, accuracy=68.612, wps=14432.2, ups=1.74, wpb=8295.6, bsz=299.5, num_updates=37800, lr=7.27393e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=12.8, wall=27505
2023-08-16 19:02:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-16 19:03:34 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.979, trans_loss=4.783, nll_loss=1.988, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.074, total=4107.66, n_correct=2824.78, ppl=3.97, accuracy=68.769, wps=14101.9, ups=1.72, wpb=8215.3, bsz=291.9, num_updates=37900, lr=7.26433e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=58, gb_free=16.7, wall=27564
2023-08-16 19:04:32 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.987, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.116, total=4113.86, n_correct=2820.91, ppl=4, accuracy=68.571, wps=14339.2, ups=1.74, wpb=8227.7, bsz=298.5, num_updates=38000, lr=7.25476e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=27621
2023-08-16 19:04:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 19:04:54 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.094 | trans_loss 5.162 | nll_loss 2.418 | w2v_ctc_loss 1.366 | task_loss 0 | contrastive_loss 0.289 | total 4003.4 | n_correct 2674.9 | ppl 5.35 | accuracy 66.816 | uer 17.702 | wer 19.645 | raw_wer 19.645 | bleu 22.73 | wps 2412.4 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.87
2023-08-16 19:04:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-16 19:04:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-16 19:04:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-16 19:05:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 22.73) (writing took 44.97998879477382 seconds)
2023-08-16 19:06:40 | INFO | train_inner | epoch 026:   1266 / 1474 loss=1.993, trans_loss=4.801, nll_loss=2.011, w2v_ctc_loss=0.678, task_loss=0, contrastive_loss=0.079, total=3996.19, n_correct=2731.76, ppl=4.03, accuracy=68.359, wps=6243.5, ups=0.78, wpb=7992.4, bsz=279.3, num_updates=38100, lr=7.24524e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=27749
2023-08-16 19:07:37 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.983, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.653, task_loss=0, contrastive_loss=0.09, total=4159.74, n_correct=2857.57, ppl=4, accuracy=68.696, wps=14391.4, ups=1.73, wpb=8319.5, bsz=311.4, num_updates=38200, lr=7.23575e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=27807
2023-08-16 19:08:35 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.978, trans_loss=4.784, nll_loss=1.991, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.084, total=4165.66, n_correct=2867.44, ppl=3.98, accuracy=68.835, wps=14477.3, ups=1.74, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=27864
2023-08-16 19:08:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 19:09:04 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.079 | trans_loss 5.157 | nll_loss 2.413 | w2v_ctc_loss 1.329 | task_loss 0 | contrastive_loss 0.286 | total 4003.4 | n_correct 2680.2 | ppl 5.33 | accuracy 66.948 | uer 17.434 | wer 19.306 | raw_wer 19.306 | bleu 22.49 | wps 2070.9 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 22.87
2023-08-16 19:09:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-08-16 19:09:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.4907.pt
2023-08-16 19:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.4907.pt
2023-08-16 19:09:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.4907.pt (epoch 26 @ 38308 updates, score 22.49) (writing took 18.100431306287646 seconds)
2023-08-16 19:09:22 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-16 19:09:22 | INFO | train | epoch 026 | loss 1.986 | trans_loss 4.784 | nll_loss 1.99 | w2v_ctc_loss 0.658 | task_loss 0 | contrastive_loss 0.129 | total 4138.21 | n_correct 2844.19 | ppl 3.97 | accuracy 68.73 | wps 12590.4 | ups 1.52 | wpb 8276.4 | bsz 305.6 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.548 | clip 0 | loss_scale 32 | train_wall 840 | gb_free 16 | wall 27911
2023-08-16 19:09:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 19:09:22 | INFO | fairseq.trainer | begin training epoch 27
2023-08-16 19:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 19:10:23 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.959, trans_loss=4.752, nll_loss=1.947, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.066, total=4054.57, n_correct=2815.16, ppl=3.86, accuracy=69.432, wps=7501, ups=0.93, wpb=8109.1, bsz=282.4, num_updates=38400, lr=7.21688e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=27972
2023-08-16 19:11:20 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.969, trans_loss=4.763, nll_loss=1.963, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.093, total=4195.2, n_correct=2901.43, ppl=3.9, accuracy=69.161, wps=14714, ups=1.75, wpb=8390.4, bsz=323.2, num_updates=38500, lr=7.2075e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=57, gb_free=17.2, wall=28029
2023-08-16 19:12:18 | INFO | train_inner | epoch 027:    292 / 1474 loss=1.972, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.077, total=4162.23, n_correct=2877.4, ppl=3.92, accuracy=69.131, wps=14409.7, ups=1.73, wpb=8324.5, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=17.2, wall=28087
2023-08-16 19:13:16 | INFO | train_inner | epoch 027:    392 / 1474 loss=1.997, trans_loss=4.779, nll_loss=1.983, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.262, total=4079.05, n_correct=2799.53, ppl=3.95, accuracy=68.632, wps=14136.2, ups=1.73, wpb=8158.1, bsz=297.1, num_updates=38700, lr=7.18885e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=28145
2023-08-16 19:14:14 | INFO | train_inner | epoch 027:    492 / 1474 loss=1.991, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.195, total=4243.25, n_correct=2921.26, ppl=3.96, accuracy=68.845, wps=14586.6, ups=1.72, wpb=8486.5, bsz=331, num_updates=38800, lr=7.17958e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=58, gb_free=15.8, wall=28203
2023-08-16 19:15:11 | INFO | train_inner | epoch 027:    592 / 1474 loss=1.983, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.658, task_loss=0, contrastive_loss=0.135, total=4137.92, n_correct=2853.71, ppl=3.93, accuracy=68.965, wps=14449.2, ups=1.75, wpb=8275.8, bsz=313.5, num_updates=38900, lr=7.17035e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16, wall=28260
2023-08-16 19:16:09 | INFO | train_inner | epoch 027:    692 / 1474 loss=1.981, trans_loss=4.778, nll_loss=1.981, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.114, total=4158.48, n_correct=2860.5, ppl=3.95, accuracy=68.787, wps=14410.4, ups=1.73, wpb=8317, bsz=304.1, num_updates=39000, lr=7.16115e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=28318
2023-08-16 19:17:06 | INFO | train_inner | epoch 027:    792 / 1474 loss=1.978, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.661, task_loss=0, contrastive_loss=0.078, total=4100.88, n_correct=2823.33, ppl=3.94, accuracy=68.847, wps=14421.4, ups=1.76, wpb=8201.8, bsz=292.2, num_updates=39100, lr=7.15199e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=56, gb_free=15.8, wall=28375
2023-08-16 19:18:03 | INFO | train_inner | epoch 027:    892 / 1474 loss=1.973, trans_loss=4.781, nll_loss=1.985, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.071, total=4111.94, n_correct=2832.24, ppl=3.96, accuracy=68.878, wps=14380.8, ups=1.75, wpb=8223.9, bsz=294.9, num_updates=39200, lr=7.14286e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=16, wall=28432
2023-08-16 19:19:01 | INFO | train_inner | epoch 027:    992 / 1474 loss=1.994, trans_loss=4.779, nll_loss=1.983, w2v_ctc_loss=0.652, task_loss=0, contrastive_loss=0.256, total=4189.27, n_correct=2883.84, ppl=3.95, accuracy=68.839, wps=14525.9, ups=1.73, wpb=8378.5, bsz=314.9, num_updates=39300, lr=7.13376e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=57, gb_free=14.5, wall=28490
2023-08-16 19:19:58 | INFO | train_inner | epoch 027:   1092 / 1474 loss=1.973, trans_loss=4.774, nll_loss=1.978, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.087, total=4160.42, n_correct=2867.75, ppl=3.94, accuracy=68.929, wps=14503.5, ups=1.74, wpb=8320.8, bsz=307.3, num_updates=39400, lr=7.1247e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=28547
2023-08-16 19:20:55 | INFO | train_inner | epoch 027:   1192 / 1474 loss=1.982, trans_loss=4.781, nll_loss=1.985, w2v_ctc_loss=0.663, task_loss=0, contrastive_loss=0.091, total=4103.72, n_correct=2820.2, ppl=3.96, accuracy=68.723, wps=14322.5, ups=1.75, wpb=8207.4, bsz=297.1, num_updates=39500, lr=7.11568e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=17.7, wall=28605
2023-08-16 19:21:53 | INFO | train_inner | epoch 027:   1292 / 1474 loss=1.988, trans_loss=4.783, nll_loss=1.989, w2v_ctc_loss=0.657, task_loss=0, contrastive_loss=0.143, total=4065.94, n_correct=2791.2, ppl=3.97, accuracy=68.648, wps=14098.9, ups=1.73, wpb=8131.9, bsz=292.4, num_updates=39600, lr=7.10669e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=28662
2023-08-16 19:22:50 | INFO | train_inner | epoch 027:   1392 / 1474 loss=1.978, trans_loss=4.778, nll_loss=1.982, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.124, total=4149.21, n_correct=2860.7, ppl=3.95, accuracy=68.946, wps=14607, ups=1.76, wpb=8298.4, bsz=312.6, num_updates=39700, lr=7.09773e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=28719
2023-08-16 19:23:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 19:23:59 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.088 | trans_loss 5.159 | nll_loss 2.418 | w2v_ctc_loss 1.35 | task_loss 0 | contrastive_loss 0.294 | total 4003.4 | n_correct 2677.3 | ppl 5.34 | accuracy 66.876 | uer 17.66 | wer 19.619 | raw_wer 19.619 | bleu 22.37 | wps 2296.8 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 22.87
2023-08-16 19:23:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-08-16 19:23:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.3701.pt
2023-08-16 19:24:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.3701.pt
2023-08-16 19:24:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.3701.pt (epoch 27 @ 39782 updates, score 22.37) (writing took 31.347562689334154 seconds)
2023-08-16 19:24:31 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-16 19:24:31 | INFO | train | epoch 027 | loss 1.979 | trans_loss 4.775 | nll_loss 1.978 | w2v_ctc_loss 0.652 | task_loss 0 | contrastive_loss 0.126 | total 4138.65 | n_correct 2852.35 | ppl 3.94 | accuracy 68.92 | wps 13424.1 | ups 1.62 | wpb 8277.3 | bsz 305.7 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.549 | clip 0 | loss_scale 32 | train_wall 839 | gb_free 17.8 | wall 28820
2023-08-16 19:24:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 19:24:31 | INFO | fairseq.trainer | begin training epoch 28
2023-08-16 19:24:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 19:24:49 | INFO | train_inner | epoch 028:     18 / 1474 loss=1.97, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.078, total=4106.72, n_correct=2837.47, ppl=3.93, accuracy=69.093, wps=6866.4, ups=0.84, wpb=8213.4, bsz=305, num_updates=39800, lr=7.08881e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=57, gb_free=16.1, wall=28839
2023-08-16 19:25:46 | INFO | train_inner | epoch 028:    118 / 1474 loss=1.961, trans_loss=4.75, nll_loss=1.946, w2v_ctc_loss=0.646, task_loss=0, contrastive_loss=0.072, total=4103.42, n_correct=2848.97, ppl=3.85, accuracy=69.429, wps=14379.4, ups=1.75, wpb=8206.8, bsz=292, num_updates=39900, lr=7.07992e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=57, gb_free=16.2, wall=28896
2023-08-16 19:26:44 | INFO | train_inner | epoch 028:    218 / 1474 loss=1.964, trans_loss=4.76, nll_loss=1.959, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.08, total=4200.12, n_correct=2909.06, ppl=3.89, accuracy=69.261, wps=14633.7, ups=1.74, wpb=8400.2, bsz=317.8, num_updates=40000, lr=7.07107e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=57, gb_free=11.4, wall=28953
2023-08-16 19:26:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 19:27:06 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.1 | trans_loss 5.162 | nll_loss 2.42 | w2v_ctc_loss 1.383 | task_loss 0 | contrastive_loss 0.29 | total 4003.4 | n_correct 2677.6 | ppl 5.35 | accuracy 66.883 | uer 17.684 | wer 19.649 | raw_wer 19.649 | bleu 22.6 | wps 2356.1 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.87
2023-08-16 19:27:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-16 19:27:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-16 19:27:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-16 19:27:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.6) (writing took 41.59087781608105 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:0')
2023-08-16 19:28:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-16 19:28:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-16 19:28:48 | INFO | train_inner | epoch 028:    320 / 1474 loss=1.989, trans_loss=4.767, nll_loss=1.968, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.308, total=4124.52, n_correct=2844.28, ppl=3.91, accuracy=68.96, wps=6654.2, ups=0.81, wpb=8249, bsz=308.3, num_updates=40100, lr=7.06225e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=59, gb_free=13.5, wall=29077
2023-08-16 19:29:45 | INFO | train_inner | epoch 028:    420 / 1474 loss=1.968, trans_loss=4.762, nll_loss=1.961, w2v_ctc_loss=0.65, task_loss=0, contrastive_loss=0.07, total=4089.84, n_correct=2829.93, ppl=3.89, accuracy=69.194, wps=14283.3, ups=1.75, wpb=8179.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=57, gb_free=16.6, wall=29134
2023-08-16 19:30:42 | INFO | train_inner | epoch 028:    520 / 1474 loss=1.966, trans_loss=4.762, nll_loss=1.961, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.081, total=4098.92, n_correct=2834.6, ppl=3.89, accuracy=69.155, wps=14353.1, ups=1.75, wpb=8197.8, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=57, gb_free=17, wall=29191
2023-08-16 19:31:39 | INFO | train_inner | epoch 028:    620 / 1474 loss=1.971, trans_loss=4.773, nll_loss=1.975, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.081, total=4180.1, n_correct=2886.89, ppl=3.93, accuracy=69.063, wps=14592.5, ups=1.75, wpb=8360.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=57, gb_free=16.6, wall=29249
2023-08-16 19:32:37 | INFO | train_inner | epoch 028:    720 / 1474 loss=1.982, trans_loss=4.772, nll_loss=1.975, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.188, total=4191.62, n_correct=2894.91, ppl=3.93, accuracy=69.064, wps=14546.3, ups=1.74, wpb=8383.2, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=57, gb_free=17.1, wall=29306
2023-08-16 19:33:35 | INFO | train_inner | epoch 028:    820 / 1474 loss=1.964, trans_loss=4.765, nll_loss=1.965, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.071, total=4088.91, n_correct=2830.41, ppl=3.9, accuracy=69.222, wps=14227.2, ups=1.74, wpb=8177.8, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=57, gb_free=17.1, wall=29364
2023-08-16 19:34:32 | INFO | train_inner | epoch 028:    920 / 1474 loss=1.98, trans_loss=4.773, nll_loss=1.975, w2v_ctc_loss=0.651, task_loss=0, contrastive_loss=0.135, total=4117.01, n_correct=2835.69, ppl=3.93, accuracy=68.877, wps=14286.3, ups=1.74, wpb=8234, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=57, gb_free=15.4, wall=29422
2023-08-16 19:35:30 | INFO | train_inner | epoch 028:   1020 / 1474 loss=1.988, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.655, task_loss=0, contrastive_loss=0.187, total=4182.85, n_correct=2883.21, ppl=3.93, accuracy=68.929, wps=14528.9, ups=1.74, wpb=8365.7, bsz=312, num_updates=40800, lr=7.0014e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=57, gb_free=16.4, wall=29479
2023-08-16 19:36:27 | INFO | train_inner | epoch 028:   1120 / 1474 loss=1.969, trans_loss=4.764, nll_loss=1.965, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.093, total=4220.16, n_correct=2916.49, ppl=3.9, accuracy=69.109, wps=14748.3, ups=1.75, wpb=8440.3, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=57, gb_free=16, wall=29536
2023-08-16 19:37:25 | INFO | train_inner | epoch 028:   1220 / 1474 loss=1.967, trans_loss=4.77, nll_loss=1.972, w2v_ctc_loss=0.64, task_loss=0, contrastive_loss=0.079, total=4092.46, n_correct=2826.3, ppl=3.92, accuracy=69.061, wps=14159.7, ups=1.73, wpb=8184.9, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=57, gb_free=17.7, wall=29594
2023-08-16 19:38:22 | INFO | train_inner | epoch 028:   1320 / 1474 loss=1.975, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.656, task_loss=0, contrastive_loss=0.095, total=4084.55, n_correct=2816.37, ppl=3.92, accuracy=68.952, wps=14191.7, ups=1.74, wpb=8169.1, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=57, gb_free=15.8, wall=29652
2023-08-16 19:39:20 | INFO | train_inner | epoch 028:   1420 / 1474 loss=1.973, trans_loss=4.769, nll_loss=1.969, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.117, total=4154.09, n_correct=2867.45, ppl=3.92, accuracy=69.027, wps=14467.8, ups=1.74, wpb=8308.2, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=57, gb_free=16.1, wall=29709
2023-08-16 19:39:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:7')
2023-08-16 19:40:15 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.076 | trans_loss 5.158 | nll_loss 2.415 | w2v_ctc_loss 1.317 | task_loss 0 | contrastive_loss 0.29 | total 4003.4 | n_correct 2677.5 | ppl 5.33 | accuracy 66.881 | uer 17.283 | wer 19.086 | raw_wer 19.086 | bleu 22.67 | wps 2049.5 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 22.87
2023-08-16 19:40:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-08-16 19:40:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.6707.pt
2023-08-16 19:40:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.6707.pt
2023-08-16 19:40:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.6707.pt (epoch 28 @ 41254 updates, score 22.67) (writing took 21.190946456044912 seconds)
2023-08-16 19:40:37 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-16 19:40:37 | INFO | train | epoch 028 | loss 1.972 | trans_loss 4.766 | nll_loss 1.967 | w2v_ctc_loss 0.646 | task_loss 0 | contrastive_loss 0.117 | total 4137.4 | n_correct 2858.92 | ppl 3.91 | accuracy 69.099 | wps 12613.4 | ups 1.52 | wpb 8274.8 | bsz 305.2 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.548 | clip 0 | loss_scale 16 | train_wall 839 | gb_free 16.5 | wall 29786
2023-08-16 19:40:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 19:40:37 | INFO | fairseq.trainer | begin training epoch 29
2023-08-16 19:40:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 19:41:10 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.967, trans_loss=4.757, nll_loss=1.956, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.09, total=4169.12, n_correct=2890.68, ppl=3.88, accuracy=69.335, wps=7539.9, ups=0.9, wpb=8338.2, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=57, gb_free=16.4, wall=29820
2023-08-16 19:42:08 | INFO | train_inner | epoch 029:    146 / 1474 loss=1.969, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.107, total=4105.72, n_correct=2844.54, ppl=3.88, accuracy=69.282, wps=14266.2, ups=1.74, wpb=8211.4, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=57, gb_free=16, wall=29877
2023-08-16 19:43:06 | INFO | train_inner | epoch 029:    246 / 1474 loss=1.97, trans_loss=4.749, nll_loss=1.945, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.193, total=4199.67, n_correct=2919.1, ppl=3.85, accuracy=69.508, wps=14552.5, ups=1.73, wpb=8399.3, bsz=330.5, num_updates=41500, lr=6.9421e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=57, gb_free=15.7, wall=29935
2023-08-16 19:44:03 | INFO | train_inner | epoch 029:    346 / 1474 loss=1.971, trans_loss=4.767, nll_loss=1.967, w2v_ctc_loss=0.654, task_loss=0, contrastive_loss=0.075, total=4095.17, n_correct=2831.04, ppl=3.91, accuracy=69.131, wps=14289, ups=1.74, wpb=8190.3, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.555, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=29992
2023-08-16 19:45:00 | INFO | train_inner | epoch 029:    446 / 1474 loss=1.949, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.068, total=4157.44, n_correct=2898.32, ppl=3.81, accuracy=69.714, wps=14562.6, ups=1.75, wpb=8314.9, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=57, gb_free=16.5, wall=30049
2023-08-16 19:45:58 | INFO | train_inner | epoch 029:    546 / 1474 loss=1.977, trans_loss=4.765, nll_loss=1.964, w2v_ctc_loss=0.643, task_loss=0, contrastive_loss=0.165, total=4150.87, n_correct=2866.69, ppl=3.9, accuracy=69.062, wps=14352.9, ups=1.73, wpb=8301.7, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=57, gb_free=15.8, wall=30107
2023-08-16 19:46:55 | INFO | train_inner | epoch 029:    646 / 1474 loss=1.975, trans_loss=4.755, nll_loss=1.953, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.233, total=4143.02, n_correct=2872.86, ppl=3.87, accuracy=69.342, wps=14440.7, ups=1.74, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=57, gb_free=17.1, wall=30165
2023-08-16 19:47:53 | INFO | train_inner | epoch 029:    746 / 1474 loss=1.968, trans_loss=4.753, nll_loss=1.95, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.15, total=4249.79, n_correct=2947.46, ppl=3.86, accuracy=69.355, wps=14693.4, ups=1.73, wpb=8499.6, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=57, gb_free=16.7, wall=30223
2023-08-16 19:47:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 19:48:15 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.098 | trans_loss 5.163 | nll_loss 2.42 | w2v_ctc_loss 1.381 | task_loss 0 | contrastive_loss 0.285 | total 4003.4 | n_correct 2676.5 | ppl 5.35 | accuracy 66.856 | uer 17.601 | wer 19.481 | raw_wer 19.481 | bleu 22.38 | wps 2318.2 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.87
2023-08-16 19:48:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-16 19:48:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-16 19:48:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-16 19:48:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.38) (writing took 22.355619683861732 seconds)
2023-08-16 19:49:35 | INFO | train_inner | epoch 029:    846 / 1474 loss=1.964, trans_loss=4.768, nll_loss=1.968, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.069, total=4027.19, n_correct=2781.75, ppl=3.91, accuracy=69.074, wps=7894.2, ups=0.98, wpb=8054.4, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.55, clip=0, loss_scale=16, train_wall=57, gb_free=17.3, wall=30325
2023-08-16 19:50:33 | INFO | train_inner | epoch 029:    946 / 1474 loss=1.967, trans_loss=4.764, nll_loss=1.963, w2v_ctc_loss=0.648, task_loss=0, contrastive_loss=0.08, total=4082.14, n_correct=2824.82, ppl=3.9, accuracy=69.199, wps=14217.2, ups=1.74, wpb=8164.3, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=57, gb_free=15.5, wall=30382
2023-08-16 19:51:30 | INFO | train_inner | epoch 029:   1046 / 1474 loss=1.967, trans_loss=4.756, nll_loss=1.953, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.153, total=4148.18, n_correct=2875.79, ppl=3.87, accuracy=69.327, wps=14517.5, ups=1.75, wpb=8296.4, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=16.1, wall=30439
2023-08-16 19:52:27 | INFO | train_inner | epoch 029:   1146 / 1474 loss=1.968, trans_loss=4.769, nll_loss=1.969, w2v_ctc_loss=0.649, task_loss=0, contrastive_loss=0.067, total=4063.95, n_correct=2804.48, ppl=3.92, accuracy=69.009, wps=14264.6, ups=1.76, wpb=8127.9, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=13.5, wall=30496
2023-08-16 19:53:24 | INFO | train_inner | epoch 029:   1246 / 1474 loss=1.966, trans_loss=4.767, nll_loss=1.968, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.073, total=4158.81, n_correct=2874, ppl=3.91, accuracy=69.106, wps=14510.6, ups=1.74, wpb=8317.6, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=30553
2023-08-16 19:54:22 | INFO | train_inner | epoch 029:   1346 / 1474 loss=1.964, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.135, total=4166.34, n_correct=2890.84, ppl=3.86, accuracy=69.386, wps=14366, ups=1.72, wpb=8332.7, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=17.9, wall=30611
2023-08-16 19:55:19 | INFO | train_inner | epoch 029:   1446 / 1474 loss=1.974, trans_loss=4.759, nll_loss=1.958, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.166, total=4162.2, n_correct=2883.12, ppl=3.89, accuracy=69.269, wps=14551.5, ups=1.75, wpb=8324.4, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=30669
2023-08-16 19:55:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 19:55:58 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.092 | trans_loss 5.154 | nll_loss 2.407 | w2v_ctc_loss 1.38 | task_loss 0 | contrastive_loss 0.289 | total 4003.4 | n_correct 2681.9 | ppl 5.3 | accuracy 66.991 | uer 17.004 | wer 18.978 | raw_wer 18.978 | bleu 22.44 | wps 2259.4 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 22.87
2023-08-16 19:55:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-08-16 19:55:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.4402.pt
2023-08-16 19:56:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.4402.pt
2023-08-16 19:56:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.4402.pt (epoch 29 @ 42728 updates, score 22.44) (writing took 22.051223365589976 seconds)
2023-08-16 19:56:21 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-16 19:56:21 | INFO | train | epoch 029 | loss 1.967 | trans_loss 4.758 | nll_loss 1.956 | w2v_ctc_loss 0.64 | task_loss 0 | contrastive_loss 0.124 | total 4138.65 | n_correct 2867.45 | ppl 3.88 | accuracy 69.285 | wps 12923.2 | ups 1.56 | wpb 8277.3 | bsz 305.7 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.549 | clip 0 | loss_scale 32 | train_wall 839 | gb_free 16.1 | wall 30730
2023-08-16 19:56:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 19:56:21 | INFO | fairseq.trainer | begin training epoch 30
2023-08-16 19:56:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 19:57:11 | INFO | train_inner | epoch 030:     72 / 1474 loss=1.964, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.184, total=4182.65, n_correct=2909.27, ppl=3.84, accuracy=69.556, wps=7517.1, ups=0.9, wpb=8365.3, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=13.7, wall=30780
2023-08-16 19:58:08 | INFO | train_inner | epoch 030:    172 / 1474 loss=1.956, trans_loss=4.734, nll_loss=1.925, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.114, total=4203.05, n_correct=2933.61, ppl=3.8, accuracy=69.797, wps=14665, ups=1.74, wpb=8406.1, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=30837
2023-08-16 19:59:05 | INFO | train_inner | epoch 030:    272 / 1474 loss=1.959, trans_loss=4.752, nll_loss=1.947, w2v_ctc_loss=0.642, task_loss=0, contrastive_loss=0.069, total=4116.93, n_correct=2861.65, ppl=3.86, accuracy=69.509, wps=14403.6, ups=1.75, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=30894
2023-08-16 20:00:03 | INFO | train_inner | epoch 030:    372 / 1474 loss=1.95, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.07, total=4173.13, n_correct=2910.14, ppl=3.81, accuracy=69.735, wps=14384.4, ups=1.72, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=57, gb_free=12.1, wall=30952
2023-08-16 20:01:00 | INFO | train_inner | epoch 030:    472 / 1474 loss=1.957, trans_loss=4.744, nll_loss=1.938, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.133, total=4135.2, n_correct=2877.61, ppl=3.83, accuracy=69.588, wps=14496.9, ups=1.75, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=31010
2023-08-16 20:01:57 | INFO | train_inner | epoch 030:    572 / 1474 loss=1.962, trans_loss=4.75, nll_loss=1.946, w2v_ctc_loss=0.639, task_loss=0, contrastive_loss=0.095, total=4168.65, n_correct=2893.56, ppl=3.85, accuracy=69.412, wps=14584.8, ups=1.75, wpb=8337.3, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=16, wall=31067
2023-08-16 20:02:55 | INFO | train_inner | epoch 030:    672 / 1474 loss=1.966, trans_loss=4.751, nll_loss=1.946, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.108, total=4183.65, n_correct=2897.96, ppl=3.85, accuracy=69.269, wps=14496.9, ups=1.73, wpb=8367.3, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=57, gb_free=16.9, wall=31124
2023-08-16 20:03:53 | INFO | train_inner | epoch 030:    772 / 1474 loss=1.977, trans_loss=4.756, nll_loss=1.952, w2v_ctc_loss=0.647, task_loss=0, contrastive_loss=0.189, total=4106.9, n_correct=2845.9, ppl=3.87, accuracy=69.296, wps=14206.6, ups=1.73, wpb=8213.8, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=57, gb_free=12.2, wall=31182
2023-08-16 20:04:50 | INFO | train_inner | epoch 030:    872 / 1474 loss=1.961, trans_loss=4.756, nll_loss=1.952, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.074, total=4089.18, n_correct=2836.03, ppl=3.87, accuracy=69.354, wps=14360.9, ups=1.76, wpb=8178.4, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=56, gb_free=16.5, wall=31239
2023-08-16 20:05:47 | INFO | train_inner | epoch 030:    972 / 1474 loss=1.965, trans_loss=4.758, nll_loss=1.955, w2v_ctc_loss=0.644, task_loss=0, contrastive_loss=0.091, total=4140.03, n_correct=2869.42, ppl=3.88, accuracy=69.309, wps=14412.3, ups=1.74, wpb=8280.1, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=14.1, wall=31297
2023-08-16 20:06:45 | INFO | train_inner | epoch 030:   1072 / 1474 loss=1.971, trans_loss=4.762, nll_loss=1.96, w2v_ctc_loss=0.638, task_loss=0, contrastive_loss=0.162, total=4101.12, n_correct=2835.54, ppl=3.89, accuracy=69.141, wps=14191.1, ups=1.73, wpb=8202.2, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=31354
2023-08-16 20:07:43 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.959, trans_loss=4.747, nll_loss=1.943, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.14, total=4168.22, n_correct=2899.08, ppl=3.84, accuracy=69.552, wps=14453.5, ups=1.73, wpb=8336.4, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=31412
2023-08-16 20:08:40 | INFO | train_inner | epoch 030:   1272 / 1474 loss=1.963, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.645, task_loss=0, contrastive_loss=0.075, total=4032.74, n_correct=2793.13, ppl=3.88, accuracy=69.261, wps=13994.3, ups=1.74, wpb=8065.5, bsz=281.8, num_updates=44000, lr=6.742e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=31470
2023-08-16 20:08:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 20:09:03 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.09 | trans_loss 5.157 | nll_loss 2.41 | w2v_ctc_loss 1.368 | task_loss 0 | contrastive_loss 0.291 | total 4003.4 | n_correct 2683.2 | ppl 5.32 | accuracy 67.023 | uer 17.209 | wer 19.06 | raw_wer 19.06 | bleu 22.79 | wps 2377.4 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.87
2023-08-16 20:09:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-16 20:09:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-16 20:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-16 20:09:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.79) (writing took 45.5178708601743 seconds)
2023-08-16 20:10:47 | INFO | train_inner | epoch 030:   1372 / 1474 loss=1.957, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.632, task_loss=0, contrastive_loss=0.085, total=4166.96, n_correct=2893.47, ppl=3.86, accuracy=69.438, wps=6603.1, ups=0.79, wpb=8333.9, bsz=322.3, num_updates=44100, lr=6.73435e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=15.3, wall=31596
2023-08-16 20:11:44 | INFO | train_inner | epoch 030:   1472 / 1474 loss=1.967, trans_loss=4.752, nll_loss=1.949, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.233, total=4125.17, n_correct=2865.51, ppl=3.86, accuracy=69.464, wps=14396.5, ups=1.74, wpb=8250.3, bsz=310, num_updates=44200, lr=6.72673e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=57, gb_free=17, wall=31653
2023-08-16 20:11:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 20:12:06 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.08 | trans_loss 5.158 | nll_loss 2.413 | w2v_ctc_loss 1.329 | task_loss 0 | contrastive_loss 0.291 | total 4003.4 | n_correct 2689.1 | ppl 5.33 | accuracy 67.17 | uer 17.363 | wer 19.276 | raw_wer 19.276 | bleu 22.52 | wps 2440.1 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 22.87
2023-08-16 20:12:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-08-16 20:12:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.5203.pt
2023-08-16 20:12:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.5203.pt
2023-08-16 20:12:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.5203.pt (epoch 30 @ 44202 updates, score 22.52) (writing took 40.422528099268675 seconds)
2023-08-16 20:12:48 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-16 20:12:48 | INFO | train | epoch 030 | loss 1.962 | trans_loss 4.75 | nll_loss 1.946 | w2v_ctc_loss 0.635 | task_loss 0 | contrastive_loss 0.123 | total 4138.65 | n_correct 2874.07 | ppl 3.85 | accuracy 69.445 | wps 12356 | ups 1.49 | wpb 8277.3 | bsz 305.7 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.551 | clip 0 | loss_scale 64 | train_wall 840 | gb_free 17.2 | wall 31718
2023-08-16 20:12:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 20:12:49 | INFO | fairseq.trainer | begin training epoch 31
2023-08-16 20:12:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 20:13:52 | INFO | train_inner | epoch 031:     98 / 1474 loss=1.95, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.073, total=4081.34, n_correct=2846.14, ppl=3.81, accuracy=69.735, wps=6381.6, ups=0.78, wpb=8162.7, bsz=294.7, num_updates=44300, lr=6.71913e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=57, gb_free=16.5, wall=31781
2023-08-16 20:13:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-16 20:14:50 | INFO | train_inner | epoch 031:    199 / 1474 loss=1.954, trans_loss=4.741, nll_loss=1.933, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.098, total=4142.87, n_correct=2887.52, ppl=3.82, accuracy=69.699, wps=14279, ups=1.72, wpb=8285.7, bsz=301.8, num_updates=44400, lr=6.71156e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=31839
2023-08-16 20:15:48 | INFO | train_inner | epoch 031:    299 / 1474 loss=1.956, trans_loss=4.735, nll_loss=1.925, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.136, total=4149.21, n_correct=2890.58, ppl=3.8, accuracy=69.666, wps=14389.9, ups=1.73, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=31897
2023-08-16 20:16:45 | INFO | train_inner | epoch 031:    399 / 1474 loss=1.953, trans_loss=4.747, nll_loss=1.942, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.074, total=4092.62, n_correct=2848.19, ppl=3.84, accuracy=69.593, wps=14150.6, ups=1.73, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=57, gb_free=17.2, wall=31955
2023-08-16 20:17:43 | INFO | train_inner | epoch 031:    499 / 1474 loss=1.954, trans_loss=4.74, nll_loss=1.932, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.081, total=4111.85, n_correct=2863.39, ppl=3.82, accuracy=69.638, wps=14309.5, ups=1.74, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=11.4, wall=32012
2023-08-16 20:18:40 | INFO | train_inner | epoch 031:    599 / 1474 loss=1.95, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.071, total=4083.44, n_correct=2846.35, ppl=3.81, accuracy=69.705, wps=14264.2, ups=1.75, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=32070
2023-08-16 20:19:38 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.948, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.074, total=4213.98, n_correct=2939.55, ppl=3.81, accuracy=69.757, wps=14701.4, ups=1.74, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=57, gb_free=16.3, wall=32127
2023-08-16 20:20:35 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.964, trans_loss=4.749, nll_loss=1.943, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.143, total=4097.37, n_correct=2844.15, ppl=3.85, accuracy=69.414, wps=14188.8, ups=1.73, wpb=8194.7, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=13.2, wall=32185
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:0')
2023-08-16 20:21:33 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.949, trans_loss=4.732, nll_loss=1.922, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.088, total=4096.72, n_correct=2856.79, ppl=3.79, accuracy=69.734, wps=14280.1, ups=1.74, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=32242
2023-08-16 20:22:30 | INFO | train_inner | epoch 031:    999 / 1474 loss=1.963, trans_loss=4.748, nll_loss=1.944, w2v_ctc_loss=0.628, task_loss=0, contrastive_loss=0.17, total=4187.84, n_correct=2914.7, ppl=3.85, accuracy=69.599, wps=14624.2, ups=1.75, wpb=8375.7, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=17.3, wall=32299
2023-08-16 20:23:27 | INFO | train_inner | epoch 031:   1099 / 1474 loss=1.96, trans_loss=4.746, nll_loss=1.941, w2v_ctc_loss=0.631, task_loss=0, contrastive_loss=0.117, total=4149.44, n_correct=2886.95, ppl=3.84, accuracy=69.574, wps=14447.2, ups=1.74, wpb=8298.9, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=57, gb_free=17.6, wall=32357
2023-08-16 20:24:25 | INFO | train_inner | epoch 031:   1199 / 1474 loss=1.964, trans_loss=4.743, nll_loss=1.937, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.235, total=4189.76, n_correct=2917.93, ppl=3.83, accuracy=69.644, wps=14609, ups=1.74, wpb=8379.5, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=13.5, wall=32414
2023-08-16 20:25:22 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.957, trans_loss=4.75, nll_loss=1.946, w2v_ctc_loss=0.635, task_loss=0, contrastive_loss=0.079, total=4227.44, n_correct=2940.74, ppl=3.85, accuracy=69.563, wps=14739.3, ups=1.74, wpb=8454.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=57, gb_free=16.4, wall=32471
2023-08-16 20:26:20 | INFO | train_inner | epoch 031:   1399 / 1474 loss=1.979, trans_loss=4.746, nll_loss=1.942, w2v_ctc_loss=0.63, task_loss=0, contrastive_loss=0.284, total=4186.05, n_correct=2910.13, ppl=3.84, accuracy=69.52, wps=14534, ups=1.74, wpb=8372.1, bsz=326.6, num_updates=45600, lr=6.62266e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=32529
2023-08-16 20:27:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2761, device='cuda:1')
2023-08-16 20:27:25 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.078 | trans_loss 5.156 | nll_loss 2.409 | w2v_ctc_loss 1.33 | task_loss 0 | contrastive_loss 0.29 | total 4003.4 | n_correct 2685 | ppl 5.31 | accuracy 67.068 | uer 17.233 | wer 19.168 | raw_wer 19.168 | bleu 22.6 | wps 2377 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 22.87
2023-08-16 20:27:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-08-16 20:27:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.6005.pt
2023-08-16 20:27:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.6005.pt
2023-08-16 20:28:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.6005.pt (epoch 31 @ 45675 updates, score 22.6) (writing took 41.954124219715595 seconds)
2023-08-16 20:28:07 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-16 20:28:07 | INFO | train | epoch 031 | loss 1.957 | trans_loss 4.743 | nll_loss 1.936 | w2v_ctc_loss 0.63 | task_loss 0 | contrastive_loss 0.122 | total 4138.87 | n_correct 2881.77 | ppl 3.83 | accuracy 69.627 | wps 13275.5 | ups 1.6 | wpb 8277.7 | bsz 305.7 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.551 | clip 0 | loss_scale 32 | train_wall 839 | gb_free 12.4 | wall 32636
2023-08-16 20:28:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 20:28:07 | INFO | fairseq.trainer | begin training epoch 32
2023-08-16 20:28:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 20:28:29 | INFO | train_inner | epoch 032:     25 / 1474 loss=1.951, trans_loss=4.74, nll_loss=1.933, w2v_ctc_loss=0.636, task_loss=0, contrastive_loss=0.069, total=4042.6, n_correct=2818.58, ppl=3.82, accuracy=69.722, wps=6247.5, ups=0.77, wpb=8085.2, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=56, gb_free=16.4, wall=32658
2023-08-16 20:29:26 | INFO | train_inner | epoch 032:    125 / 1474 loss=1.935, trans_loss=4.717, nll_loss=1.903, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.078, total=4227.68, n_correct=2967.83, ppl=3.74, accuracy=70.2, wps=14826.2, ups=1.75, wpb=8455.4, bsz=323.3, num_updates=45800, lr=6.60819e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=57, gb_free=16.1, wall=32715
2023-08-16 20:30:24 | INFO | train_inner | epoch 032:    225 / 1474 loss=1.947, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.086, total=4157.32, n_correct=2904.66, ppl=3.8, accuracy=69.869, wps=14310.9, ups=1.72, wpb=8314.6, bsz=320.6, num_updates=45900, lr=6.60098e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=58, gb_free=17.3, wall=32774
2023-08-16 20:31:22 | INFO | train_inner | epoch 032:    325 / 1474 loss=1.941, trans_loss=4.723, nll_loss=1.91, w2v_ctc_loss=0.617, task_loss=0, contrastive_loss=0.083, total=4183.45, n_correct=2931, ppl=3.76, accuracy=70.062, wps=14538.3, ups=1.74, wpb=8366.9, bsz=314.4, num_updates=46000, lr=6.5938e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=57, gb_free=17.6, wall=32831
2023-08-16 20:31:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 20:31:44 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.094 | trans_loss 5.169 | nll_loss 2.426 | w2v_ctc_loss 1.353 | task_loss 0 | contrastive_loss 0.29 | total 4003.4 | n_correct 2680.3 | ppl 5.37 | accuracy 66.951 | uer 17.246 | wer 19.186 | raw_wer 19.186 | bleu 22.46 | wps 2383.3 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.87
2023-08-16 20:31:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-16 20:31:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-16 20:31:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-16 20:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.46) (writing took 22.8382972124964 seconds)
2023-08-16 20:33:05 | INFO | train_inner | epoch 032:    425 / 1474 loss=1.945, trans_loss=4.727, nll_loss=1.916, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.077, total=4157.28, n_correct=2906.59, ppl=3.77, accuracy=69.916, wps=8025.2, ups=0.97, wpb=8314.6, bsz=305.9, num_updates=46100, lr=6.58665e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=15, wall=32935
2023-08-16 20:34:03 | INFO | train_inner | epoch 032:    525 / 1474 loss=1.96, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.161, total=4198.93, n_correct=2926.93, ppl=3.81, accuracy=69.707, wps=14582.5, ups=1.74, wpb=8397.9, bsz=317.6, num_updates=46200, lr=6.57952e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=32992
2023-08-16 20:35:01 | INFO | train_inner | epoch 032:    625 / 1474 loss=1.948, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.085, total=4142.69, n_correct=2887.1, ppl=3.8, accuracy=69.691, wps=14317.4, ups=1.73, wpb=8285.4, bsz=301.6, num_updates=46300, lr=6.57241e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=33050
2023-08-16 20:35:59 | INFO | train_inner | epoch 032:    725 / 1474 loss=1.949, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.633, task_loss=0, contrastive_loss=0.07, total=4154.59, n_correct=2900.18, ppl=3.81, accuracy=69.807, wps=14301.6, ups=1.72, wpb=8309.2, bsz=301.8, num_updates=46400, lr=6.56532e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=57, gb_free=15.9, wall=33108
2023-08-16 20:36:56 | INFO | train_inner | epoch 032:    825 / 1474 loss=1.942, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.62, task_loss=0, contrastive_loss=0.067, total=4114.54, n_correct=2873.77, ppl=3.79, accuracy=69.844, wps=14348.8, ups=1.74, wpb=8229.1, bsz=294.9, num_updates=46500, lr=6.55826e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=57, gb_free=17.2, wall=33166
2023-08-16 20:37:54 | INFO | train_inner | epoch 032:    925 / 1474 loss=1.944, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.066, total=4139.67, n_correct=2888.78, ppl=3.8, accuracy=69.783, wps=14388.7, ups=1.74, wpb=8279.3, bsz=298.3, num_updates=46600, lr=6.55122e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=57, gb_free=17, wall=33223
2023-08-16 20:38:52 | INFO | train_inner | epoch 032:   1025 / 1474 loss=1.958, trans_loss=4.74, nll_loss=1.932, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.16, total=4119.15, n_correct=2871.74, ppl=3.81, accuracy=69.717, wps=14276.8, ups=1.73, wpb=8238.3, bsz=304.5, num_updates=46700, lr=6.5442e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=57, gb_free=16.5, wall=33281
2023-08-16 20:39:49 | INFO | train_inner | epoch 032:   1125 / 1474 loss=1.95, trans_loss=4.738, nll_loss=1.928, w2v_ctc_loss=0.624, task_loss=0, contrastive_loss=0.104, total=4019.61, n_correct=2798.8, ppl=3.81, accuracy=69.629, wps=13933.9, ups=1.73, wpb=8039.2, bsz=271.4, num_updates=46800, lr=6.5372e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=57, gb_free=17.7, wall=33339
2023-08-16 20:40:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-16 20:40:47 | INFO | train_inner | epoch 032:   1226 / 1474 loss=1.954, trans_loss=4.745, nll_loss=1.938, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.099, total=4125.85, n_correct=2873.53, ppl=3.83, accuracy=69.647, wps=14210.1, ups=1.72, wpb=8251.7, bsz=302.2, num_updates=46900, lr=6.53023e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=58, gb_free=16.3, wall=33397
2023-08-16 20:41:44 | INFO | train_inner | epoch 032:   1326 / 1474 loss=1.948, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.066, total=4075.86, n_correct=2839.65, ppl=3.81, accuracy=69.67, wps=14394.3, ups=1.77, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=33453
2023-08-16 20:42:41 | INFO | train_inner | epoch 032:   1426 / 1474 loss=1.978, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.641, task_loss=0, contrastive_loss=0.302, total=4116.4, n_correct=2863.52, ppl=3.82, accuracy=69.564, wps=14359.2, ups=1.74, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=33511
2023-08-16 20:43:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 20:43:31 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.09 | trans_loss 5.16 | nll_loss 2.415 | w2v_ctc_loss 1.361 | task_loss 0 | contrastive_loss 0.291 | total 4003.4 | n_correct 2683.5 | ppl 5.33 | accuracy 67.031 | uer 17.554 | wer 19.518 | raw_wer 19.518 | bleu 22.77 | wps 2287.4 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 22.87
2023-08-16 20:43:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-08-16 20:43:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.7705.pt
2023-08-16 20:43:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.7705.pt
2023-08-16 20:43:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint.best_bleu_22.7705.pt (epoch 32 @ 47148 updates, score 22.77) (writing took 25.270395502448082 seconds)
2023-08-16 20:43:57 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-16 20:43:57 | INFO | train | epoch 032 | loss 1.95 | trans_loss 4.735 | nll_loss 1.925 | w2v_ctc_loss 0.625 | task_loss 0 | contrastive_loss 0.113 | total 4137.03 | n_correct 2887.56 | ppl 3.8 | accuracy 69.798 | wps 12823.9 | ups 1.55 | wpb 8274.1 | bsz 305.1 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.552 | clip 0 | loss_scale 32 | train_wall 840 | gb_free 16.5 | wall 33587
2023-08-16 20:43:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 20:43:58 | INFO | fairseq.trainer | begin training epoch 33
2023-08-16 20:43:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 20:44:35 | INFO | train_inner | epoch 033:     52 / 1474 loss=1.956, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.619, task_loss=0, contrastive_loss=0.168, total=4149.21, n_correct=2896.04, ppl=3.79, accuracy=69.797, wps=7300.2, ups=0.88, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=57, gb_free=17.1, wall=33624
2023-08-16 20:45:33 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.929, trans_loss=4.716, nll_loss=1.901, w2v_ctc_loss=0.605, task_loss=0, contrastive_loss=0.059, total=4073.9, n_correct=2859.86, ppl=3.73, accuracy=70.2, wps=14174.3, ups=1.74, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=15.4, wall=33682
2023-08-16 20:46:31 | INFO | train_inner | epoch 033:    252 / 1474 loss=1.961, trans_loss=4.722, nll_loss=1.91, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.231, total=4280.14, n_correct=2996.86, ppl=3.76, accuracy=70.018, wps=14738.9, ups=1.72, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=58, gb_free=16.5, wall=33740
2023-08-16 20:47:28 | INFO | train_inner | epoch 033:    352 / 1474 loss=1.944, trans_loss=4.727, nll_loss=1.916, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.085, total=4120.27, n_correct=2884.14, ppl=3.77, accuracy=69.999, wps=14292.3, ups=1.73, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=57, gb_free=17.4, wall=33798
2023-08-16 20:48:26 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.93, trans_loss=4.715, nll_loss=1.9, w2v_ctc_loss=0.609, task_loss=0, contrastive_loss=0.065, total=4141.22, n_correct=2907.88, ppl=3.73, accuracy=70.218, wps=14433.5, ups=1.74, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=33855
2023-08-16 20:49:23 | INFO | train_inner | epoch 033:    552 / 1474 loss=1.947, trans_loss=4.729, nll_loss=1.918, w2v_ctc_loss=0.627, task_loss=0, contrastive_loss=0.087, total=4133.59, n_correct=2887.57, ppl=3.78, accuracy=69.856, wps=14334.8, ups=1.73, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=57, gb_free=15.3, wall=33913
2023-08-16 20:50:21 | INFO | train_inner | epoch 033:    652 / 1474 loss=1.952, trans_loss=4.74, nll_loss=1.931, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.12, total=4157.63, n_correct=2897.74, ppl=3.81, accuracy=69.697, wps=14393, ups=1.73, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=33970
2023-08-16 20:51:19 | INFO | train_inner | epoch 033:    752 / 1474 loss=1.95, trans_loss=4.734, nll_loss=1.924, w2v_ctc_loss=0.637, task_loss=0, contrastive_loss=0.068, total=4070.75, n_correct=2841.47, ppl=3.79, accuracy=69.802, wps=14152, ups=1.74, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=16.5, wall=34028
2023-08-16 20:52:17 | INFO | train_inner | epoch 033:    852 / 1474 loss=1.939, trans_loss=4.722, nll_loss=1.909, w2v_ctc_loss=0.605, task_loss=0, contrastive_loss=0.137, total=4130.24, n_correct=2901.27, ppl=3.76, accuracy=70.245, wps=14214.1, ups=1.72, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=58, gb_free=16.7, wall=34086
2023-08-16 20:52:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 20:52:39 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.097 | trans_loss 5.164 | nll_loss 2.418 | w2v_ctc_loss 1.381 | task_loss 0 | contrastive_loss 0.286 | total 4003.4 | n_correct 2677.4 | ppl 5.34 | accuracy 66.878 | uer 17.081 | wer 19.011 | raw_wer 19.011 | bleu 22.54 | wps 2413.6 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.87
2023-08-16 20:52:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-16 20:52:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-16 20:52:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-16 20:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.54) (writing took 43.37680180370808 seconds)
2023-08-16 20:54:20 | INFO | train_inner | epoch 033:    952 / 1474 loss=1.947, trans_loss=4.73, nll_loss=1.919, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.078, total=4151.18, n_correct=2901.7, ppl=3.78, accuracy=69.901, wps=6730.7, ups=0.81, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=57, gb_free=11.6, wall=34209
2023-08-16 20:55:18 | INFO | train_inner | epoch 033:   1052 / 1474 loss=1.956, trans_loss=4.727, nll_loss=1.916, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.181, total=4140.1, n_correct=2890.92, ppl=3.77, accuracy=69.827, wps=14332.5, ups=1.73, wpb=8280.2, bsz=307.6, num_updates=48200, lr=6.44157e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=57, gb_free=12, wall=34267
2023-08-16 20:56:16 | INFO | train_inner | epoch 033:   1152 / 1474 loss=1.955, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.172, total=4182.67, n_correct=2915.54, ppl=3.81, accuracy=69.705, wps=14423.8, ups=1.72, wpb=8365.3, bsz=309.5, num_updates=48300, lr=6.43489e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=57, gb_free=17.6, wall=34325
2023-08-16 20:57:13 | INFO | train_inner | epoch 033:   1252 / 1474 loss=1.942, trans_loss=4.727, nll_loss=1.915, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.071, total=4110.02, n_correct=2874.51, ppl=3.77, accuracy=69.939, wps=14325.9, ups=1.74, wpb=8220, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=16.8, wall=34383
2023-08-16 20:58:11 | INFO | train_inner | epoch 033:   1352 / 1474 loss=1.945, trans_loss=4.731, nll_loss=1.921, w2v_ctc_loss=0.621, task_loss=0, contrastive_loss=0.089, total=4128.82, n_correct=2886.43, ppl=3.79, accuracy=69.909, wps=14300.2, ups=1.73, wpb=8257.6, bsz=312.4, num_updates=48500, lr=6.42161e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=57, gb_free=16.2, wall=34440
2023-08-16 20:59:09 | INFO | train_inner | epoch 033:   1452 / 1474 loss=1.958, trans_loss=4.73, nll_loss=1.92, w2v_ctc_loss=0.618, task_loss=0, contrastive_loss=0.24, total=4123.47, n_correct=2878.44, ppl=3.79, accuracy=69.806, wps=14334.1, ups=1.74, wpb=8246.9, bsz=308.9, num_updates=48600, lr=6.415e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=57, gb_free=16.6, wall=34498
2023-08-16 20:59:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 20:59:44 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.089 | trans_loss 5.162 | nll_loss 2.416 | w2v_ctc_loss 1.349 | task_loss 0 | contrastive_loss 0.299 | total 4003.4 | n_correct 2678.9 | ppl 5.34 | accuracy 66.916 | uer 17.471 | wer 19.351 | raw_wer 19.351 | bleu 22.45 | wps 2319.5 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 22.87
2023-08-16 20:59:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-08-16 20:59:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-16 21:00:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-16 21:00:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_last.pt (epoch 33 @ 48622 updates, score 22.45) (writing took 17.024158047512174 seconds)
2023-08-16 21:00:01 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-16 21:00:01 | INFO | train | epoch 033 | loss 1.946 | trans_loss 4.727 | nll_loss 1.916 | w2v_ctc_loss 0.62 | task_loss 0 | contrastive_loss 0.12 | total 4138.65 | n_correct 2894.52 | ppl 3.77 | accuracy 69.939 | wps 12664.2 | ups 1.53 | wpb 8277.3 | bsz 305.7 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.553 | clip 0 | loss_scale 32 | train_wall 842 | gb_free 17.9 | wall 34550
2023-08-16 21:00:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-16 21:00:01 | INFO | fairseq.trainer | begin training epoch 34
2023-08-16 21:00:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-16 21:00:54 | INFO | train_inner | epoch 034:     78 / 1474 loss=1.934, trans_loss=4.716, nll_loss=1.901, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.071, total=4128.94, n_correct=2896.73, ppl=3.73, accuracy=70.157, wps=7863.6, ups=0.95, wpb=8257.9, bsz=302.1, num_updates=48700, lr=6.40841e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=15.4, wall=34603
2023-08-16 21:01:51 | INFO | train_inner | epoch 034:    178 / 1474 loss=1.931, trans_loss=4.706, nll_loss=1.888, w2v_ctc_loss=0.614, task_loss=0, contrastive_loss=0.073, total=4071.22, n_correct=2864.96, ppl=3.7, accuracy=70.371, wps=14165.4, ups=1.74, wpb=8142.4, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=34660
2023-08-16 21:02:49 | INFO | train_inner | epoch 034:    278 / 1474 loss=1.965, trans_loss=4.726, nll_loss=1.914, w2v_ctc_loss=0.613, task_loss=0, contrastive_loss=0.289, total=4237.89, n_correct=2963.9, ppl=3.77, accuracy=69.938, wps=14623.9, ups=1.73, wpb=8475.8, bsz=326.9, num_updates=48900, lr=6.39529e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=57, gb_free=10.9, wall=34718
2023-08-16 21:03:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-16 21:03:47 | INFO | train_inner | epoch 034:    379 / 1474 loss=1.935, trans_loss=4.708, nll_loss=1.891, w2v_ctc_loss=0.606, task_loss=0, contrastive_loss=0.138, total=4147.46, n_correct=2915.09, ppl=3.71, accuracy=70.286, wps=14308.7, ups=1.72, wpb=8294.9, bsz=313.9, num_updates=49000, lr=6.38877e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=57, gb_free=17.8, wall=34776
2023-08-16 21:04:45 | INFO | train_inner | epoch 034:    479 / 1474 loss=1.94, trans_loss=4.722, nll_loss=1.908, w2v_ctc_loss=0.626, task_loss=0, contrastive_loss=0.066, total=4070.55, n_correct=2847.81, ppl=3.75, accuracy=69.961, wps=14163, ups=1.74, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=57, gb_free=17.5, wall=34834
2023-08-16 21:05:41 | INFO | train_inner | epoch 034:    579 / 1474 loss=1.931, trans_loss=4.71, nll_loss=1.894, w2v_ctc_loss=0.611, task_loss=0, contrastive_loss=0.069, total=4119.38, n_correct=2895.99, ppl=3.72, accuracy=70.302, wps=14482.2, ups=1.76, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=56, gb_free=13.4, wall=34891
2023-08-16 21:06:39 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.93, trans_loss=4.716, nll_loss=1.902, w2v_ctc_loss=0.609, task_loss=0, contrastive_loss=0.063, total=4124.83, n_correct=2894.99, ppl=3.74, accuracy=70.184, wps=14446.5, ups=1.75, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=14.4, wall=34948
2023-08-16 21:07:36 | INFO | train_inner | epoch 034:    779 / 1474 loss=1.949, trans_loss=4.738, nll_loss=1.93, w2v_ctc_loss=0.614, task_loss=0, contrastive_loss=0.134, total=4082.07, n_correct=2848.6, ppl=3.81, accuracy=69.783, wps=14281.5, ups=1.75, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=57, gb_free=15.7, wall=35005
2023-08-16 21:08:33 | INFO | train_inner | epoch 034:    879 / 1474 loss=1.945, trans_loss=4.728, nll_loss=1.916, w2v_ctc_loss=0.622, task_loss=0, contrastive_loss=0.091, total=4100.9, n_correct=2868.23, ppl=3.77, accuracy=69.941, wps=14287.5, ups=1.74, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=57, gb_free=12.5, wall=35062
2023-08-16 21:09:31 | INFO | train_inner | epoch 034:    979 / 1474 loss=1.945, trans_loss=4.725, nll_loss=1.913, w2v_ctc_loss=0.625, task_loss=0, contrastive_loss=0.085, total=4168.39, n_correct=2916.08, ppl=3.77, accuracy=69.957, wps=14520.4, ups=1.74, wpb=8336.8, bsz=311.9, num_updates=49600, lr=6.35001e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=15.9, wall=35120
2023-08-16 21:10:27 | INFO | train_inner | epoch 034:   1079 / 1474 loss=1.939, trans_loss=4.723, nll_loss=1.91, w2v_ctc_loss=0.623, task_loss=0, contrastive_loss=0.069, total=4150.57, n_correct=2911.27, ppl=3.76, accuracy=70.141, wps=14588.5, ups=1.76, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=56, gb_free=16.9, wall=35177
2023-08-16 21:11:25 | INFO | train_inner | epoch 034:   1179 / 1474 loss=1.938, trans_loss=4.724, nll_loss=1.911, w2v_ctc_loss=0.614, task_loss=0, contrastive_loss=0.08, total=4098.77, n_correct=2868.31, ppl=3.76, accuracy=69.98, wps=14371.5, ups=1.75, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=17, wall=35234
2023-08-16 21:12:22 | INFO | train_inner | epoch 034:   1279 / 1474 loss=1.936, trans_loss=4.719, nll_loss=1.906, w2v_ctc_loss=0.616, task_loss=0, contrastive_loss=0.066, total=4150.54, n_correct=2909.77, ppl=3.75, accuracy=70.106, wps=14480.4, ups=1.74, wpb=8301.1, bsz=301, num_updates=49900, lr=6.33089e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=57, gb_free=17.2, wall=35291
2023-08-16 21:13:20 | INFO | train_inner | epoch 034:   1379 / 1474 loss=1.955, trans_loss=4.73, nll_loss=1.92, w2v_ctc_loss=0.629, task_loss=0, contrastive_loss=0.131, total=4196.91, n_correct=2930.16, ppl=3.78, accuracy=69.817, wps=14531.8, ups=1.73, wpb=8393.8, bsz=321.4, num_updates=50000, lr=6.32456e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=57, gb_free=16.1, wall=35349
2023-08-16 21:13:20 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-16 21:13:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-16 21:13:42 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.08 | trans_loss 5.16 | nll_loss 2.412 | w2v_ctc_loss 1.335 | task_loss 0 | contrastive_loss 0.283 | total 4003.4 | n_correct 2688.7 | ppl 5.32 | accuracy 67.16 | uer 16.895 | wer 18.683 | raw_wer 18.683 | bleu 22.37 | wps 2278.1 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.87
2023-08-16 21:13:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-16 21:13:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-16 21:13:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-16 21:14:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0816_baseline_cl_alpha1.5_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.37) (writing took 19.08935124054551 seconds)
2023-08-16 21:14:02 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-16 21:14:02 | INFO | train | epoch 034 | loss 1.941 | trans_loss 4.721 | nll_loss 1.907 | w2v_ctc_loss 0.617 | task_loss 0 | contrastive_loss 0.104 | total 4132.06 | n_correct 2895.16 | ppl 3.75 | accuracy 70.066 | wps 13537.4 | ups 1.64 | wpb 8264.1 | bsz 304 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.554 | clip 0 | loss_scale 32 | train_wall 784 | gb_free 16.1 | wall 35391
2023-08-16 21:14:02 | INFO | fairseq_cli.train | done training in 35339.0 seconds
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
