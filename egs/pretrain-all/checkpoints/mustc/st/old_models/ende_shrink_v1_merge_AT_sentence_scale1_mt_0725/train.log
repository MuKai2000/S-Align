2023-07-25 11:19:41 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:16249
2023-07-25 11:19:41 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:16249
2023-07-25 11:19:41 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16249
2023-07-25 11:19:41 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:16249
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16249
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:16249
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16249
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16249
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-25 11:19:42 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-07-25 11:19:42 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-07-25 11:19:47 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16249', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-07-25 11:19:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-07-25 11:19:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-07-25 11:19:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-25 11:19:47 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 1.0
2023-07-25 11:19:47 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-25 11:19:51 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-07-25 11:19:51 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-25 11:19:51 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-25 11:19:53 | INFO | root | load pretrained hubert
2023-07-25 11:19:56 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-25 11:19:56 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-25 11:19:59 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-25 11:19:59 | INFO | root | share the sematic adapter and textual encoder
2023-07-25 11:19:59 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-25 11:19:59 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-07-25 11:19:59 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-25 11:19:59 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-07-25 11:19:59 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-25 11:19:59 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-25 11:19:59 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-25 11:19:59 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-25 11:19:59 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-25 11:19:59 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-25 11:20:05 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-25 11:20:07 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-25 11:20:07 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-25 11:20:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-25 11:20:08 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-25 11:20:08 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-25 11:20:08 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-25 11:20:08 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-25 11:20:08 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-25 11:20:08 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-25 11:20:08 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-25 11:20:08 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-25 11:20:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-25 11:20:08 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-25 11:20:08 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-25 11:20:08 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_last.pt
2023-07-25 11:20:08 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_last.pt
2023-07-25 11:20:08 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-25 11:20:08 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-25 11:20:08 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-25 11:20:08 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-25 11:20:09 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-25 11:20:11 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-25 11:20:12 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-25 11:21:22 | INFO | fairseq.optim.adam | using FusedAdam
2023-07-25 11:21:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 11:21:22 | INFO | fairseq.trainer | begin training epoch 1
2023-07-25 11:21:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 11:22:46 | INFO | train_inner | epoch 001:    100 / 1474 loss=19.137, trans_loss=5.598, nll_loss=4.163, w2v_ctc_loss=22.485, task_loss=1.749, contrastive_loss=3.325, total=4207.04, n_correct=209.29, ppl=17.91, accuracy=4.975, wps=19091.7, ups=1.52, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.891, clip=0, loss_scale=128, train_wall=75, gb_free=19.5, wall=159
2023-07-25 11:23:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-25 11:23:51 | INFO | train_inner | epoch 001:    201 / 1474 loss=16.99, trans_loss=5.477, nll_loss=4.065, w2v_ctc_loss=19.358, task_loss=1.706, contrastive_loss=3.278, total=4124.14, n_correct=223.63, ppl=16.74, accuracy=5.422, wps=18887.2, ups=1.53, wpb=12313.4, bsz=461, num_updates=200, lr=8.096e-06, gnorm=3.625, clip=0, loss_scale=64, train_wall=65, gb_free=19.2, wall=224
2023-07-25 11:24:55 | INFO | train_inner | epoch 001:    301 / 1474 loss=10.087, trans_loss=5.481, nll_loss=4.124, w2v_ctc_loss=8.784, task_loss=1.706, contrastive_loss=3.203, total=4079.62, n_correct=207.46, ppl=17.43, accuracy=5.085, wps=19095.5, ups=1.57, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.607, clip=0, loss_scale=64, train_wall=63, gb_free=19.9, wall=288
2023-07-25 11:25:59 | INFO | train_inner | epoch 001:    401 / 1474 loss=8.85, trans_loss=5.519, nll_loss=4.193, w2v_ctc_loss=6.815, task_loss=1.496, contrastive_loss=3.237, total=4174.14, n_correct=193.85, ppl=18.29, accuracy=4.644, wps=19535.1, ups=1.57, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=2.947, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=352
2023-07-25 11:27:04 | INFO | train_inner | epoch 001:    501 / 1474 loss=8.415, trans_loss=5.495, nll_loss=4.179, w2v_ctc_loss=6.176, task_loss=1.369, contrastive_loss=3.233, total=4176.18, n_correct=188.76, ppl=18.12, accuracy=4.52, wps=19274.2, ups=1.54, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.416, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=416
2023-07-25 11:28:08 | INFO | train_inner | epoch 001:    601 / 1474 loss=8.165, trans_loss=5.524, nll_loss=4.214, w2v_ctc_loss=5.809, task_loss=1.274, contrastive_loss=3.288, total=4147.79, n_correct=184.25, ppl=18.56, accuracy=4.442, wps=19257.4, ups=1.56, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.727, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=481
2023-07-25 11:29:11 | INFO | train_inner | epoch 001:    701 / 1474 loss=8.009, trans_loss=5.525, nll_loss=4.221, w2v_ctc_loss=5.69, task_loss=1.325, contrastive_loss=3.039, total=4152.1, n_correct=192.42, ppl=18.64, accuracy=4.634, wps=19575.4, ups=1.58, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=63, gb_free=19.5, wall=544
2023-07-25 11:30:15 | INFO | train_inner | epoch 001:    801 / 1474 loss=7.732, trans_loss=5.461, nll_loss=4.152, w2v_ctc_loss=5.464, task_loss=1.281, contrastive_loss=2.948, total=4123.83, n_correct=238.07, ppl=17.78, accuracy=5.773, wps=19344.8, ups=1.57, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.824, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=608
2023-07-25 11:31:20 | INFO | train_inner | epoch 001:    901 / 1474 loss=7.472, trans_loss=5.427, nll_loss=4.122, w2v_ctc_loss=5.281, task_loss=1.302, contrastive_loss=2.707, total=4163.61, n_correct=263.85, ppl=17.41, accuracy=6.337, wps=19258.7, ups=1.55, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.327, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=672
2023-07-25 11:32:24 | INFO | train_inner | epoch 001:   1001 / 1474 loss=7.212, trans_loss=5.403, nll_loss=4.101, w2v_ctc_loss=5.07, task_loss=1.311, contrastive_loss=2.557, total=4135.34, n_correct=286.49, ppl=17.16, accuracy=6.928, wps=19278.8, ups=1.56, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.415, clip=0, loss_scale=64, train_wall=64, gb_free=19, wall=736
2023-07-25 11:33:27 | INFO | train_inner | epoch 001:   1101 / 1474 loss=6.942, trans_loss=5.39, nll_loss=4.088, w2v_ctc_loss=4.871, task_loss=1.322, contrastive_loss=2.334, total=4147.38, n_correct=308.83, ppl=17.01, accuracy=7.446, wps=19539.8, ups=1.58, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.653, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=799
2023-07-25 11:34:30 | INFO | train_inner | epoch 001:   1201 / 1474 loss=6.722, trans_loss=5.37, nll_loss=4.071, w2v_ctc_loss=4.705, task_loss=1.377, contrastive_loss=2.131, total=4139.9, n_correct=316.3, ppl=16.8, accuracy=7.64, wps=19495.5, ups=1.58, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.751, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=863
2023-07-25 11:35:34 | INFO | train_inner | epoch 001:   1301 / 1474 loss=6.5, trans_loss=5.367, nll_loss=4.07, w2v_ctc_loss=4.509, task_loss=1.324, contrastive_loss=1.94, total=4046.58, n_correct=317.98, ppl=16.8, accuracy=7.858, wps=18867.9, ups=1.56, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.737, clip=0, loss_scale=64, train_wall=64, gb_free=19.7, wall=927
2023-07-25 11:36:38 | INFO | train_inner | epoch 001:   1401 / 1474 loss=6.295, trans_loss=5.357, nll_loss=4.06, w2v_ctc_loss=4.309, task_loss=1.308, contrastive_loss=2.009, total=4133.18, n_correct=331.94, ppl=16.68, accuracy=8.031, wps=19351.9, ups=1.57, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.629, clip=0, loss_scale=64, train_wall=63, gb_free=19.9, wall=991
2023-07-25 11:37:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 11:38:05 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.567 | trans_loss 10.918 | nll_loss 9.901 | w2v_ctc_loss 5.605 | task_loss 7.547 | contrastive_loss 2.367 | total 4003.4 | n_correct 384.2 | ppl 956.22 | accuracy 9.597 | uer 71.935 | wer 69.886 | raw_wer 69.886 | bleu 0.03 | wps 1140.5 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-25 11:38:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-25 11:38:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 11:38:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 11:38:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.03) (writing took 5.696978749707341 seconds)
2023-07-25 11:38:10 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-25 11:38:10 | INFO | train | epoch 001 | loss 9.041 | trans_loss 5.452 | nll_loss 4.126 | w2v_ctc_loss 7.643 | task_loss 1.41 | contrastive_loss 2.762 | total 4138.55 | n_correct 251.769 | ppl 17.47 | accuracy 6.084 | wps 18384.4 | ups 1.49 | wpb 12355.5 | bsz 458.4 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.787 | clip 0 | loss_scale 64 | train_wall 947 | gb_free 19.2 | wall 1083
2023-07-25 11:38:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 11:38:11 | INFO | fairseq.trainer | begin training epoch 2
2023-07-25 11:38:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 11:38:38 | INFO | train_inner | epoch 002:     27 / 1474 loss=6.106, trans_loss=5.35, nll_loss=4.047, w2v_ctc_loss=4.116, task_loss=1.246, contrastive_loss=1.855, total=4162.95, n_correct=338.58, ppl=16.53, accuracy=8.133, wps=10366, ups=0.83, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.653, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1111
2023-07-25 11:39:42 | INFO | train_inner | epoch 002:    127 / 1474 loss=5.946, trans_loss=5.346, nll_loss=4.042, w2v_ctc_loss=4, task_loss=1.33, contrastive_loss=1.652, total=4155.98, n_correct=339.4, ppl=16.47, accuracy=8.167, wps=19339.5, ups=1.56, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.718, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=1175
2023-07-25 11:40:47 | INFO | train_inner | epoch 002:    227 / 1474 loss=5.781, trans_loss=5.325, nll_loss=4.021, w2v_ctc_loss=3.804, task_loss=1.153, contrastive_loss=1.682, total=4179.21, n_correct=348.49, ppl=16.23, accuracy=8.339, wps=19366.7, ups=1.55, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.505, clip=0, loss_scale=64, train_wall=64, gb_free=19, wall=1239
2023-07-25 11:41:50 | INFO | train_inner | epoch 002:    327 / 1474 loss=5.621, trans_loss=5.324, nll_loss=4.016, w2v_ctc_loss=3.714, task_loss=1.325, contrastive_loss=1.391, total=4146.1, n_correct=353.02, ppl=16.17, accuracy=8.515, wps=19407.4, ups=1.57, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.393, clip=0, loss_scale=64, train_wall=63, gb_free=18.8, wall=1303
2023-07-25 11:42:54 | INFO | train_inner | epoch 002:    427 / 1474 loss=5.481, trans_loss=5.315, nll_loss=4.009, w2v_ctc_loss=3.617, task_loss=1.456, contrastive_loss=1.214, total=4037.99, n_correct=343.22, ppl=16.1, accuracy=8.5, wps=19053.4, ups=1.58, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.439, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1366
2023-07-25 11:43:57 | INFO | train_inner | epoch 002:    527 / 1474 loss=5.371, trans_loss=5.304, nll_loss=3.991, w2v_ctc_loss=3.456, task_loss=1.266, contrastive_loss=1.31, total=4176.97, n_correct=360.18, ppl=15.9, accuracy=8.623, wps=19729.9, ups=1.58, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.282, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1429
2023-07-25 11:43:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 11:44:37 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.955 | trans_loss 10.759 | nll_loss 9.685 | w2v_ctc_loss 4.514 | task_loss 7.546 | contrastive_loss 1.646 | total 4003.4 | n_correct 414 | ppl 822.88 | accuracy 10.341 | uer 61.415 | wer 59.289 | raw_wer 59.289 | bleu 0.05 | wps 1138.2 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.05
2023-07-25 11:44:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-25 11:44:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_2_2000.pt
2023-07-25 11:44:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_2_2000.pt
2023-07-25 11:45:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.05) (writing took 30.666150307282805 seconds)
2023-07-25 11:46:13 | INFO | train_inner | epoch 002:    627 / 1474 loss=5.239, trans_loss=5.297, nll_loss=3.982, w2v_ctc_loss=3.351, task_loss=1.309, contrastive_loss=1.11, total=4126.49, n_correct=366.01, ppl=15.8, accuracy=8.87, wps=9050.1, ups=0.73, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.172, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=1565
2023-07-25 11:47:17 | INFO | train_inner | epoch 002:    727 / 1474 loss=5.167, trans_loss=5.282, nll_loss=3.967, w2v_ctc_loss=3.267, task_loss=1.283, contrastive_loss=1.212, total=4149.06, n_correct=374.49, ppl=15.64, accuracy=9.026, wps=19471.1, ups=1.57, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.138, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1629
2023-07-25 11:48:20 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.077, trans_loss=5.265, nll_loss=3.948, w2v_ctc_loss=3.197, task_loss=1.317, contrastive_loss=1.161, total=4175.4, n_correct=384.18, ppl=15.43, accuracy=9.201, wps=19650.7, ups=1.58, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.033, clip=0, loss_scale=128, train_wall=63, gb_free=19.8, wall=1693
2023-07-25 11:49:24 | INFO | train_inner | epoch 002:    927 / 1474 loss=4.986, trans_loss=5.253, nll_loss=3.932, w2v_ctc_loss=3.104, task_loss=1.344, contrastive_loss=1.143, total=4104.2, n_correct=380.53, ppl=15.26, accuracy=9.272, wps=19245.9, ups=1.57, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.026, clip=0, loss_scale=128, train_wall=63, gb_free=19, wall=1756
2023-07-25 11:50:29 | INFO | train_inner | epoch 002:   1027 / 1474 loss=4.901, trans_loss=5.247, nll_loss=3.926, w2v_ctc_loss=3.034, task_loss=1.305, contrastive_loss=0.996, total=4102.5, n_correct=385.59, ppl=15.2, accuracy=9.399, wps=18746, ups=1.53, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.895, clip=0, loss_scale=128, train_wall=65, gb_free=19.2, wall=1822
2023-07-25 11:51:33 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.858, trans_loss=5.241, nll_loss=3.917, w2v_ctc_loss=2.943, task_loss=1.187, contrastive_loss=1.207, total=4187.61, n_correct=399.75, ppl=15.11, accuracy=9.546, wps=19602.1, ups=1.57, wpb=12495.7, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.905, clip=0, loss_scale=128, train_wall=63, gb_free=19.5, wall=1885
2023-07-25 11:52:37 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.8, trans_loss=5.229, nll_loss=3.903, w2v_ctc_loss=2.899, task_loss=1.194, contrastive_loss=1.13, total=4221.06, n_correct=416.87, ppl=14.96, accuracy=9.876, wps=19719.4, ups=1.57, wpb=12596.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.816, clip=0, loss_scale=128, train_wall=63, gb_free=19.5, wall=1949
2023-07-25 11:53:40 | INFO | train_inner | epoch 002:   1327 / 1474 loss=4.708, trans_loss=5.22, nll_loss=3.896, w2v_ctc_loss=2.864, task_loss=1.259, contrastive_loss=0.838, total=4157.86, n_correct=415.69, ppl=14.89, accuracy=9.998, wps=19653.9, ups=1.58, wpb=12425.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.779, clip=0, loss_scale=128, train_wall=63, gb_free=19.5, wall=2012
2023-07-25 11:54:45 | INFO | train_inner | epoch 002:   1427 / 1474 loss=4.671, trans_loss=5.226, nll_loss=3.904, w2v_ctc_loss=2.823, task_loss=1.414, contrastive_loss=0.927, total=4054.34, n_correct=400.51, ppl=14.97, accuracy=9.879, wps=18582.2, ups=1.53, wpb=12107, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.731, clip=0, loss_scale=128, train_wall=65, gb_free=19.4, wall=2078
2023-07-25 11:55:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 11:55:53 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.188 | trans_loss 10.247 | nll_loss 9.063 | w2v_ctc_loss 3.614 | task_loss 7.547 | contrastive_loss 0.989 | total 4003.4 | n_correct 501.7 | ppl 534.98 | accuracy 12.532 | uer 51.865 | wer 50.688 | raw_wer 50.688 | bleu 0.12 | wps 1169.2 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.12
2023-07-25 11:55:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-25 11:55:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 11:56:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 11:56:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.12) (writing took 19.892044447362423 seconds)
2023-07-25 11:56:13 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-25 11:56:13 | INFO | train | epoch 002 | loss 5.185 | trans_loss 5.276 | nll_loss 3.96 | w2v_ctc_loss 3.289 | task_loss 1.292 | contrastive_loss 1.214 | total 4138.65 | n_correct 376.565 | ppl 15.56 | accuracy 9.099 | wps 16822 | ups 1.36 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.125 | clip 0 | loss_scale 128 | train_wall 936 | gb_free 19.3 | wall 2166
2023-07-25 11:56:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 11:56:14 | INFO | fairseq.trainer | begin training epoch 3
2023-07-25 11:56:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 11:56:56 | INFO | train_inner | epoch 003:     53 / 1474 loss=4.596, trans_loss=5.198, nll_loss=3.868, w2v_ctc_loss=2.762, task_loss=1.324, contrastive_loss=0.827, total=4071.2, n_correct=416.37, ppl=14.61, accuracy=10.227, wps=9270.6, ups=0.76, wpb=12154.1, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.719, clip=0, loss_scale=128, train_wall=63, gb_free=19.1, wall=2209
2023-07-25 11:56:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-25 11:56:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 11:56:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-25 11:57:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-25 11:57:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-25 11:58:32 | INFO | train_inner | epoch 003:    158 / 1474 loss=3.807, trans_loss=4.398, nll_loss=2.821, w2v_ctc_loss=2.431, task_loss=0.903, contrastive_loss=0.751, total=4144.18, n_correct=1134.85, ppl=7.06, accuracy=27.384, wps=12991.9, ups=1.05, wpb=12374.6, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=1.903, clip=1, loss_scale=4, train_wall=95, gb_free=16.5, wall=2304
2023-07-25 12:00:05 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.386, trans_loss=4.143, nll_loss=2.489, w2v_ctc_loss=2.179, task_loss=0.915, contrastive_loss=0.637, total=4161.13, n_correct=1431.67, ppl=5.61, accuracy=34.406, wps=13273.4, ups=1.07, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.503, clip=0, loss_scale=4, train_wall=93, gb_free=17.1, wall=2398
2023-07-25 12:01:37 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.279, trans_loss=4.091, nll_loss=2.417, w2v_ctc_loss=2.096, task_loss=0.92, contrastive_loss=0.668, total=4150.02, n_correct=1507.74, ppl=5.34, accuracy=36.331, wps=13484.1, ups=1.09, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.539, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=2489
2023-07-25 12:03:09 | INFO | train_inner | epoch 003:    458 / 1474 loss=3.177, trans_loss=4.045, nll_loss=2.357, w2v_ctc_loss=2.031, task_loss=0.892, contrastive_loss=0.534, total=4209.57, n_correct=1599.82, ppl=5.12, accuracy=38.004, wps=13625.8, ups=1.08, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.431, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=2582
2023-07-25 12:04:41 | INFO | train_inner | epoch 003:    558 / 1474 loss=3.066, trans_loss=4.012, nll_loss=2.315, w2v_ctc_loss=1.943, task_loss=0.977, contrastive_loss=0.487, total=4088.48, n_correct=1601.97, ppl=4.98, accuracy=39.183, wps=13276.8, ups=1.09, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.223, clip=0, loss_scale=4, train_wall=91, gb_free=17.7, wall=2674
2023-07-25 12:06:14 | INFO | train_inner | epoch 003:    658 / 1474 loss=3.008, trans_loss=3.978, nll_loss=2.266, w2v_ctc_loss=1.87, task_loss=0.879, contrastive_loss=0.598, total=4221.58, n_correct=1712.18, ppl=4.81, accuracy=40.558, wps=13568.7, ups=1.08, wpb=12587.8, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=1.145, clip=0, loss_scale=4, train_wall=92, gb_free=16.4, wall=2766
2023-07-25 12:07:45 | INFO | train_inner | epoch 003:    758 / 1474 loss=2.939, trans_loss=3.948, nll_loss=2.231, w2v_ctc_loss=1.847, task_loss=0.878, contrastive_loss=0.375, total=4167.41, n_correct=1733.49, ppl=4.7, accuracy=41.596, wps=13607, ups=1.09, wpb=12447.6, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=1.206, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=2858
2023-07-25 12:09:17 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.889, trans_loss=3.937, nll_loss=2.215, w2v_ctc_loss=1.807, task_loss=0.93, contrastive_loss=0.335, total=4165.53, n_correct=1757.09, ppl=4.64, accuracy=42.182, wps=13539.2, ups=1.09, wpb=12437.8, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=1.156, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=2950
2023-07-25 12:10:50 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.849, trans_loss=3.913, nll_loss=2.183, w2v_ctc_loss=1.771, task_loss=0.893, contrastive_loss=0.363, total=4162.3, n_correct=1805.34, ppl=4.54, accuracy=43.374, wps=13413.9, ups=1.08, wpb=12417, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=1.084, clip=0, loss_scale=4, train_wall=92, gb_free=16.8, wall=3042
2023-07-25 12:12:22 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.824, trans_loss=3.897, nll_loss=2.164, w2v_ctc_loss=1.764, task_loss=0.98, contrastive_loss=0.319, total=4069.95, n_correct=1777.68, ppl=4.48, accuracy=43.678, wps=13262.8, ups=1.09, wpb=12153.7, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=1.089, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=3134
2023-07-25 12:12:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 12:12:47 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.06 | trans_loss 6.442 | nll_loss 3.999 | w2v_ctc_loss 2.123 | task_loss 4.339 | contrastive_loss 0.439 | total 4003.4 | n_correct 1949.2 | ppl 15.99 | accuracy 48.689 | uer 30.59 | wer 31.345 | raw_wer 31.345 | bleu 11.03 | wps 2007.5 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 11.03
2023-07-25 12:12:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-25 12:12:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_3_4000.pt
2023-07-25 12:12:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_3_4000.pt
2023-07-25 12:13:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 11.03) (writing took 29.768902311101556 seconds)
2023-07-25 12:14:48 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.782, trans_loss=3.889, nll_loss=2.151, w2v_ctc_loss=1.724, task_loss=0.999, contrastive_loss=0.3, total=4038.49, n_correct=1782.49, ppl=4.44, accuracy=44.138, wps=8237.9, ups=0.68, wpb=12054.8, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=1.079, clip=0, loss_scale=4, train_wall=91, gb_free=16.4, wall=3280
2023-07-25 12:16:20 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.737, trans_loss=3.87, nll_loss=2.128, w2v_ctc_loss=1.689, task_loss=0.976, contrastive_loss=0.277, total=4064.31, n_correct=1825.26, ppl=4.37, accuracy=44.909, wps=13209.2, ups=1.09, wpb=12136.8, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=1.028, clip=0, loss_scale=4, train_wall=91, gb_free=17.3, wall=3372
2023-07-25 12:17:52 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.718, trans_loss=3.849, nll_loss=2.1, w2v_ctc_loss=1.649, task_loss=0.934, contrastive_loss=0.391, total=4134.58, n_correct=1889.6, ppl=4.29, accuracy=45.702, wps=13397.3, ups=1.09, wpb=12343.8, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=1, clip=0, loss_scale=4, train_wall=92, gb_free=17.8, wall=3464
2023-07-25 12:19:24 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.69, trans_loss=3.838, nll_loss=2.088, w2v_ctc_loss=1.629, task_loss=0.878, contrastive_loss=0.371, total=4209.94, n_correct=1945.92, ppl=4.25, accuracy=46.222, wps=13618.9, ups=1.08, wpb=12573.5, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.978, clip=0, loss_scale=4, train_wall=92, gb_free=17, wall=3557
2023-07-25 12:19:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 12:20:04 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.918 | trans_loss 6.314 | nll_loss 3.829 | w2v_ctc_loss 1.949 | task_loss 4.209 | contrastive_loss 0.421 | total 4003.4 | n_correct 2032 | ppl 14.22 | accuracy 50.757 | uer 29.719 | wer 30.193 | raw_wer 30.193 | bleu 12.48 | wps 1978 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 12.48
2023-07-25 12:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-25 12:20:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 12:20:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 12:20:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 3 @ 4416 updates, score 12.48) (writing took 20.206657672300935 seconds)
2023-07-25 12:20:24 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-25 12:20:24 | INFO | train | epoch 003 | loss 3.065 | trans_loss 4.028 | nll_loss 2.336 | w2v_ctc_loss 1.916 | task_loss 0.938 | contrastive_loss 0.474 | total 4140.05 | n_correct 1635.52 | ppl 5.05 | accuracy 39.505 | wps 12515 | ups 1.01 | wpb 12360.1 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 1.218 | clip 0.1 | loss_scale 4 | train_wall 1334 | gb_free 16.4 | wall 3616
2023-07-25 12:20:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 12:20:24 | INFO | fairseq.trainer | begin training epoch 4
2023-07-25 12:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 12:21:49 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.611, trans_loss=3.806, nll_loss=2.043, w2v_ctc_loss=1.581, task_loss=0.955, contrastive_loss=0.223, total=4099.41, n_correct=1930.58, ppl=4.12, accuracy=47.094, wps=8442.8, ups=0.69, wpb=12237, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.923, clip=0, loss_scale=4, train_wall=90, gb_free=16.3, wall=3702
2023-07-25 12:23:20 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.59, trans_loss=3.785, nll_loss=2.015, w2v_ctc_loss=1.56, task_loss=0.883, contrastive_loss=0.247, total=4175.15, n_correct=2003.36, ppl=4.04, accuracy=47.983, wps=13676.4, ups=1.1, wpb=12464.9, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.907, clip=0, loss_scale=4, train_wall=91, gb_free=16.6, wall=3793
2023-07-25 12:24:52 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.601, trans_loss=3.787, nll_loss=2.021, w2v_ctc_loss=1.555, task_loss=0.926, contrastive_loss=0.373, total=4145.23, n_correct=1981.4, ppl=4.06, accuracy=47.8, wps=13483.2, ups=1.09, wpb=12382.4, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.893, clip=0, loss_scale=4, train_wall=91, gb_free=15.9, wall=3885
2023-07-25 12:26:23 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.572, trans_loss=3.793, nll_loss=2.025, w2v_ctc_loss=1.544, task_loss=0.967, contrastive_loss=0.219, total=4127.66, n_correct=1976.1, ppl=4.07, accuracy=47.875, wps=13511.1, ups=1.1, wpb=12314.6, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.92, clip=0, loss_scale=4, train_wall=91, gb_free=17.4, wall=3976
2023-07-25 12:27:56 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.598, trans_loss=3.77, nll_loss=1.998, w2v_ctc_loss=1.51, task_loss=0.839, contrastive_loss=0.616, total=4218.78, n_correct=2053.19, ppl=4, accuracy=48.668, wps=13664.3, ups=1.09, wpb=12592.4, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.968, clip=0, loss_scale=4, train_wall=92, gb_free=16.5, wall=4068
2023-07-25 12:29:28 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.547, trans_loss=3.761, nll_loss=1.987, w2v_ctc_loss=1.518, task_loss=0.872, contrastive_loss=0.289, total=4217.52, n_correct=2074.7, ppl=3.97, accuracy=49.192, wps=13591.4, ups=1.08, wpb=12591.1, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.877, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=4161
mt_weight tensor(1.)
asr_weight tensor(0.4470, device='cuda:0')
2023-07-25 12:31:02 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.521, trans_loss=3.766, nll_loss=1.989, w2v_ctc_loss=1.485, task_loss=0.952, contrastive_loss=0.332, total=4176.39, n_correct=2060.32, ppl=3.97, accuracy=49.333, wps=13220.8, ups=1.06, wpb=12448.9, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.582, clip=0, loss_scale=8, train_wall=94, gb_free=17.1, wall=4255
2023-07-25 12:32:34 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.503, trans_loss=3.756, nll_loss=1.98, w2v_ctc_loss=1.498, task_loss=1.02, contrastive_loss=0.204, total=4026.63, n_correct=1996.81, ppl=3.95, accuracy=49.59, wps=13105.8, ups=1.09, wpb=12025, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.578, clip=0, loss_scale=8, train_wall=91, gb_free=13.1, wall=4347
2023-07-25 12:34:06 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.523, trans_loss=3.742, nll_loss=1.963, w2v_ctc_loss=1.49, task_loss=0.924, contrastive_loss=0.39, total=4186.04, n_correct=2090.04, ppl=3.9, accuracy=49.929, wps=13551.5, ups=1.08, wpb=12501.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.575, clip=0, loss_scale=8, train_wall=92, gb_free=17.7, wall=4439
2023-07-25 12:35:39 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.485, trans_loss=3.733, nll_loss=1.953, w2v_ctc_loss=1.473, task_loss=0.942, contrastive_loss=0.256, total=4125.02, n_correct=2078.31, ppl=3.87, accuracy=50.383, wps=13297.4, ups=1.08, wpb=12321, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.58, clip=0, loss_scale=8, train_wall=92, gb_free=12.7, wall=4531
2023-07-25 12:37:11 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.488, trans_loss=3.742, nll_loss=1.963, w2v_ctc_loss=1.482, task_loss=1.002, contrastive_loss=0.229, total=4075.6, n_correct=2047.3, ppl=3.9, accuracy=50.233, wps=13226.2, ups=1.09, wpb=12163.4, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.577, clip=0, loss_scale=8, train_wall=91, gb_free=16, wall=4623
2023-07-25 12:38:42 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.498, trans_loss=3.731, nll_loss=1.953, w2v_ctc_loss=1.477, task_loss=0.871, contrastive_loss=0.343, total=4161.18, n_correct=2103.66, ppl=3.87, accuracy=50.554, wps=13590.9, ups=1.09, wpb=12431.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.602, clip=0, loss_scale=8, train_wall=91, gb_free=16.8, wall=4715
2023-07-25 12:40:15 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.465, trans_loss=3.718, nll_loss=1.934, w2v_ctc_loss=1.451, task_loss=0.885, contrastive_loss=0.306, total=4156.53, n_correct=2128.89, ppl=3.82, accuracy=51.218, wps=13455.6, ups=1.08, wpb=12411.4, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.558, clip=0, loss_scale=8, train_wall=92, gb_free=15.8, wall=4807
2023-07-25 12:41:45 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.434, trans_loss=3.716, nll_loss=1.931, w2v_ctc_loss=1.446, task_loss=0.953, contrastive_loss=0.181, total=4101.23, n_correct=2107.16, ppl=3.81, accuracy=51.379, wps=13517.4, ups=1.1, wpb=12249, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.539, clip=0, loss_scale=8, train_wall=90, gb_free=15.6, wall=4898
2023-07-25 12:43:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.4470, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.4470, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.4470, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.4470, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.4470, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.4470, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.4470, device='cuda:2')
2023-07-25 12:43:34 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.592 | trans_loss 5.977 | nll_loss 3.373 | w2v_ctc_loss 1.673 | task_loss 4.402 | contrastive_loss 0.338 | total 4003.4 | n_correct 2223.2 | ppl 10.36 | accuracy 55.533 | uer 25.289 | wer 26.804 | raw_wer 26.804 | bleu 16.06 | wps 1742.3 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 16.06
2023-07-25 12:43:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-25 12:43:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 12:43:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 12:43:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 4 @ 5890 updates, score 16.06) (writing took 19.9430693667382 seconds)
2023-07-25 12:43:54 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-25 12:43:54 | INFO | train | epoch 004 | loss 2.524 | trans_loss 3.754 | nll_loss 1.978 | w2v_ctc_loss 1.499 | task_loss 0.927 | contrastive_loss 0.3 | total 4138.65 | n_correct 2049.8 | ppl 3.94 | accuracy 49.528 | wps 12915.8 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.708 | clip 0 | loss_scale 8 | train_wall 1347 | gb_free 14.8 | wall 5027
2023-07-25 12:43:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 12:43:54 | INFO | fairseq.trainer | begin training epoch 5
2023-07-25 12:43:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 12:44:13 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.416, trans_loss=3.707, nll_loss=1.919, w2v_ctc_loss=1.419, task_loss=0.964, contrastive_loss=0.203, total=4037.7, n_correct=2084.78, ppl=3.78, accuracy=51.633, wps=8157.7, ups=0.68, wpb=12055.9, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.546, clip=0, loss_scale=8, train_wall=90, gb_free=16.9, wall=5046
2023-07-25 12:45:45 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.342, trans_loss=3.648, nll_loss=1.843, w2v_ctc_loss=1.342, task_loss=0.839, contrastive_loss=0.211, total=4247.37, n_correct=2266.2, ppl=3.59, accuracy=53.355, wps=13794.5, ups=1.09, wpb=12683.4, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.515, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=5137
2023-07-25 12:45:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 12:46:11 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.555 | trans_loss 5.961 | nll_loss 3.353 | w2v_ctc_loss 1.59 | task_loss 4.443 | contrastive_loss 0.335 | total 4003.4 | n_correct 2224.1 | ppl 10.22 | accuracy 55.555 | uer 24.009 | wer 25.681 | raw_wer 25.681 | bleu 16.04 | wps 1877.6 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.06
2023-07-25 12:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-25 12:46:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_5_6000.pt
2023-07-25 12:46:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_5_6000.pt
2023-07-25 12:46:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.04) (writing took 27.4600490629673 seconds)
2023-07-25 12:48:10 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.384, trans_loss=3.662, nll_loss=1.859, w2v_ctc_loss=1.362, task_loss=0.858, contrastive_loss=0.43, total=4189.85, n_correct=2223.07, ppl=3.63, accuracy=53.058, wps=8599.3, ups=0.69, wpb=12500.5, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.529, clip=0, loss_scale=8, train_wall=91, gb_free=17.8, wall=5283
2023-07-25 12:49:41 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.364, trans_loss=3.654, nll_loss=1.853, w2v_ctc_loss=1.369, task_loss=0.955, contrastive_loss=0.275, total=4090.1, n_correct=2166.67, ppl=3.61, accuracy=52.974, wps=13438.5, ups=1.1, wpb=12228.1, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.521, clip=0, loss_scale=8, train_wall=90, gb_free=16.2, wall=5374
2023-07-25 12:51:13 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.357, trans_loss=3.646, nll_loss=1.844, w2v_ctc_loss=1.34, task_loss=0.897, contrastive_loss=0.371, total=4147.17, n_correct=2215.88, ppl=3.59, accuracy=53.431, wps=13514.7, ups=1.09, wpb=12395.1, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.523, clip=0, loss_scale=8, train_wall=91, gb_free=14.8, wall=5466
2023-07-25 12:52:45 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.327, trans_loss=3.657, nll_loss=1.855, w2v_ctc_loss=1.348, task_loss=1.043, contrastive_loss=0.149, total=4026.81, n_correct=2139.34, ppl=3.62, accuracy=53.127, wps=13082.4, ups=1.09, wpb=12029.7, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.511, clip=0, loss_scale=8, train_wall=91, gb_free=17.4, wall=5558
2023-07-25 12:54:17 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.342, trans_loss=3.66, nll_loss=1.856, w2v_ctc_loss=1.332, task_loss=0.955, contrastive_loss=0.32, total=4107.75, n_correct=2190.1, ppl=3.62, accuracy=53.316, wps=13294.5, ups=1.08, wpb=12253.8, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.513, clip=0, loss_scale=8, train_wall=92, gb_free=16.1, wall=5650
2023-07-25 12:55:49 | INFO | train_inner | epoch 005:    710 / 1474 loss=2.339, trans_loss=3.653, nll_loss=1.85, w2v_ctc_loss=1.33, task_loss=0.882, contrastive_loss=0.302, total=4178.85, n_correct=2242.17, ppl=3.6, accuracy=53.655, wps=13647.5, ups=1.09, wpb=12473.1, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.519, clip=0, loss_scale=8, train_wall=91, gb_free=17.7, wall=5741
2023-07-25 12:57:21 | INFO | train_inner | epoch 005:    810 / 1474 loss=2.327, trans_loss=3.654, nll_loss=1.851, w2v_ctc_loss=1.332, task_loss=0.957, contrastive_loss=0.229, total=4127.73, n_correct=2213.63, ppl=3.61, accuracy=53.628, wps=13340.2, ups=1.08, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.532, clip=0, loss_scale=8, train_wall=92, gb_free=15.1, wall=5834
2023-07-25 12:58:53 | INFO | train_inner | epoch 005:    910 / 1474 loss=2.301, trans_loss=3.643, nll_loss=1.838, w2v_ctc_loss=1.317, task_loss=0.962, contrastive_loss=0.186, total=4095.48, n_correct=2209.97, ppl=3.58, accuracy=53.961, wps=13367.4, ups=1.09, wpb=12229.5, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.513, clip=0, loss_scale=8, train_wall=91, gb_free=15.6, wall=5925
2023-07-25 13:00:25 | INFO | train_inner | epoch 005:   1010 / 1474 loss=2.313, trans_loss=3.647, nll_loss=1.842, w2v_ctc_loss=1.316, task_loss=0.918, contrastive_loss=0.268, total=4165.12, n_correct=2246.17, ppl=3.59, accuracy=53.928, wps=13487.5, ups=1.08, wpb=12433.6, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.504, clip=0, loss_scale=8, train_wall=92, gb_free=15.6, wall=6017
2023-07-25 13:01:59 | INFO | train_inner | epoch 005:   1110 / 1474 loss=2.326, trans_loss=3.647, nll_loss=1.842, w2v_ctc_loss=1.327, task_loss=0.919, contrastive_loss=0.273, total=4176.72, n_correct=2257.59, ppl=3.59, accuracy=54.052, wps=13281.8, ups=1.07, wpb=12459.2, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.525, clip=0, loss_scale=8, train_wall=93, gb_free=16.7, wall=6111
2023-07-25 13:03:32 | INFO | train_inner | epoch 005:   1210 / 1474 loss=2.289, trans_loss=3.643, nll_loss=1.836, w2v_ctc_loss=1.303, task_loss=0.947, contrastive_loss=0.174, total=4164.13, n_correct=2260.36, ppl=3.57, accuracy=54.282, wps=13243, ups=1.07, wpb=12420.9, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.523, clip=0, loss_scale=16, train_wall=93, gb_free=16.9, wall=6205
2023-07-25 13:05:05 | INFO | train_inner | epoch 005:   1310 / 1474 loss=2.276, trans_loss=3.641, nll_loss=1.836, w2v_ctc_loss=1.292, task_loss=0.946, contrastive_loss=0.143, total=4134.91, n_correct=2244.94, ppl=3.57, accuracy=54.292, wps=13265.5, ups=1.07, wpb=12341.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.51, clip=0, loss_scale=16, train_wall=92, gb_free=16.3, wall=6298
2023-07-25 13:06:38 | INFO | train_inner | epoch 005:   1410 / 1474 loss=2.281, trans_loss=3.64, nll_loss=1.837, w2v_ctc_loss=1.287, task_loss=0.938, contrastive_loss=0.21, total=4134.37, n_correct=2247.45, ppl=3.57, accuracy=54.36, wps=13281.9, ups=1.08, wpb=12347.5, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.506, clip=0, loss_scale=16, train_wall=92, gb_free=17.8, wall=6391
2023-07-25 13:07:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 13:08:03 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.462 | trans_loss 5.878 | nll_loss 3.25 | w2v_ctc_loss 1.455 | task_loss 4.42 | contrastive_loss 0.348 | total 4003.4 | n_correct 2281.9 | ppl 9.52 | accuracy 56.999 | uer 22.918 | wer 24.526 | raw_wer 24.526 | bleu 17.04 | wps 2089.6 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 17.04
2023-07-25 13:08:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-25 13:08:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 13:08:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 13:08:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 5 @ 7364 updates, score 17.04) (writing took 22.89541820809245 seconds)
2023-07-25 13:08:26 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-25 13:08:26 | INFO | train | epoch 005 | loss 2.325 | trans_loss 3.649 | nll_loss 1.845 | w2v_ctc_loss 1.328 | task_loss 0.929 | contrastive_loss 0.253 | total 4138.65 | n_correct 2222.45 | ppl 3.59 | accuracy 53.7 | wps 12375.5 | ups 1 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.518 | clip 0 | loss_scale 16 | train_wall 1352 | gb_free 16.2 | wall 6498
2023-07-25 13:08:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 13:08:26 | INFO | fairseq.trainer | begin training epoch 6
2023-07-25 13:08:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 13:09:10 | INFO | train_inner | epoch 006:     36 / 1474 loss=2.268, trans_loss=3.616, nll_loss=1.802, w2v_ctc_loss=1.283, task_loss=0.954, contrastive_loss=0.206, total=4115.45, n_correct=2261.35, ppl=3.49, accuracy=54.948, wps=8094.9, ups=0.66, wpb=12281.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.515, clip=0, loss_scale=16, train_wall=93, gb_free=16.4, wall=6543
2023-07-25 13:10:43 | INFO | train_inner | epoch 006:    136 / 1474 loss=2.225, trans_loss=3.585, nll_loss=1.763, w2v_ctc_loss=1.234, task_loss=0.926, contrastive_loss=0.248, total=4154.25, n_correct=2309.75, ppl=3.39, accuracy=55.6, wps=13360.8, ups=1.08, wpb=12407.4, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.502, clip=0, loss_scale=16, train_wall=92, gb_free=15.5, wall=6635
2023-07-25 13:12:16 | INFO | train_inner | epoch 006:    236 / 1474 loss=2.236, trans_loss=3.595, nll_loss=1.776, w2v_ctc_loss=1.265, task_loss=0.997, contrastive_loss=0.157, total=4112.66, n_correct=2274.8, ppl=3.43, accuracy=55.312, wps=13228.6, ups=1.08, wpb=12287.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.512, clip=0, loss_scale=16, train_wall=92, gb_free=16.1, wall=6728
2023-07-25 13:13:50 | INFO | train_inner | epoch 006:    336 / 1474 loss=2.244, trans_loss=3.581, nll_loss=1.759, w2v_ctc_loss=1.212, task_loss=0.864, contrastive_loss=0.464, total=4177.51, n_correct=2336.25, ppl=3.39, accuracy=55.924, wps=13214.4, ups=1.06, wpb=12473.8, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.508, clip=0, loss_scale=16, train_wall=94, gb_free=16, wall=6823
2023-07-25 13:15:23 | INFO | train_inner | epoch 006:    436 / 1474 loss=2.204, trans_loss=3.586, nll_loss=1.766, w2v_ctc_loss=1.223, task_loss=0.893, contrastive_loss=0.171, total=4154.57, n_correct=2324.74, ppl=3.4, accuracy=55.956, wps=13442.5, ups=1.08, wpb=12405.5, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.497, clip=0, loss_scale=16, train_wall=92, gb_free=16.1, wall=6915
2023-07-25 13:16:55 | INFO | train_inner | epoch 006:    536 / 1474 loss=2.213, trans_loss=3.593, nll_loss=1.773, w2v_ctc_loss=1.238, task_loss=0.936, contrastive_loss=0.159, total=4167.79, n_correct=2328.93, ppl=3.42, accuracy=55.879, wps=13410.5, ups=1.08, wpb=12438.5, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.494, clip=0, loss_scale=16, train_wall=92, gb_free=15.7, wall=7008
2023-07-25 13:18:28 | INFO | train_inner | epoch 006:    636 / 1474 loss=2.209, trans_loss=3.594, nll_loss=1.776, w2v_ctc_loss=1.216, task_loss=0.88, contrastive_loss=0.224, total=4146.17, n_correct=2317.25, ppl=3.43, accuracy=55.889, wps=13366.9, ups=1.08, wpb=12376.6, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.507, clip=0, loss_scale=16, train_wall=92, gb_free=16.3, wall=7100
2023-07-25 13:18:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 13:18:52 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.407 | trans_loss 5.801 | nll_loss 3.144 | w2v_ctc_loss 1.475 | task_loss 4.503 | contrastive_loss 0.308 | total 4003.4 | n_correct 2322.8 | ppl 8.84 | accuracy 58.021 | uer 21.787 | wer 23.351 | raw_wer 23.351 | bleu 17.71 | wps 2112.7 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.71
2023-07-25 13:18:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-25 13:18:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_6_8000.pt
2023-07-25 13:18:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_6_8000.pt
2023-07-25 13:19:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.71) (writing took 22.651569571346045 seconds)
2023-07-25 13:20:48 | INFO | train_inner | epoch 006:    736 / 1474 loss=2.211, trans_loss=3.595, nll_loss=1.778, w2v_ctc_loss=1.233, task_loss=0.951, contrastive_loss=0.169, total=4148.65, n_correct=2315.77, ppl=3.43, accuracy=55.82, wps=8856, ups=0.71, wpb=12388, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.495, clip=0, loss_scale=16, train_wall=92, gb_free=15.5, wall=7240
2023-07-25 13:22:21 | INFO | train_inner | epoch 006:    836 / 1474 loss=2.209, trans_loss=3.604, nll_loss=1.788, w2v_ctc_loss=1.228, task_loss=0.977, contrastive_loss=0.152, total=4114.34, n_correct=2292.79, ppl=3.45, accuracy=55.727, wps=13117.9, ups=1.07, wpb=12282.2, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.499, clip=0, loss_scale=16, train_wall=93, gb_free=15, wall=7334
2023-07-25 13:23:54 | INFO | train_inner | epoch 006:    936 / 1474 loss=2.223, trans_loss=3.602, nll_loss=1.786, w2v_ctc_loss=1.228, task_loss=0.969, contrastive_loss=0.248, total=4081.53, n_correct=2273.95, ppl=3.45, accuracy=55.713, wps=13208.3, ups=1.08, wpb=12181.3, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.498, clip=0, loss_scale=16, train_wall=92, gb_free=17.8, wall=7426
2023-07-25 13:25:25 | INFO | train_inner | epoch 006:   1036 / 1474 loss=2.214, trans_loss=3.588, nll_loss=1.77, w2v_ctc_loss=1.21, task_loss=0.883, contrastive_loss=0.326, total=4165.84, n_correct=2336.1, ppl=3.41, accuracy=56.078, wps=13585.8, ups=1.09, wpb=12435.7, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.511, clip=0, loss_scale=16, train_wall=91, gb_free=16.8, wall=7518
2023-07-25 13:26:57 | INFO | train_inner | epoch 006:   1136 / 1474 loss=2.2, trans_loss=3.595, nll_loss=1.777, w2v_ctc_loss=1.222, task_loss=1.028, contrastive_loss=0.152, total=4072.29, n_correct=2275.44, ppl=3.43, accuracy=55.876, wps=13229, ups=1.09, wpb=12157.6, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.496, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=7610
2023-07-25 13:28:29 | INFO | train_inner | epoch 006:   1236 / 1474 loss=2.23, trans_loss=3.584, nll_loss=1.766, w2v_ctc_loss=1.206, task_loss=0.9, contrastive_loss=0.473, total=4141.55, n_correct=2330.73, ppl=3.4, accuracy=56.277, wps=13417.4, ups=1.08, wpb=12370.9, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.497, clip=0, loss_scale=16, train_wall=92, gb_free=13.1, wall=7702
2023-07-25 13:30:00 | INFO | train_inner | epoch 006:   1336 / 1474 loss=2.179, trans_loss=3.593, nll_loss=1.773, w2v_ctc_loss=1.202, task_loss=0.929, contrastive_loss=0.136, total=4125.31, n_correct=2321.82, ppl=3.42, accuracy=56.282, wps=13598.5, ups=1.11, wpb=12305, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.489, clip=0, loss_scale=16, train_wall=90, gb_free=17.8, wall=7792
2023-07-25 13:31:32 | INFO | train_inner | epoch 006:   1436 / 1474 loss=2.178, trans_loss=3.585, nll_loss=1.766, w2v_ctc_loss=1.203, task_loss=0.929, contrastive_loss=0.144, total=4196.2, n_correct=2369.88, ppl=3.4, accuracy=56.477, wps=13598, ups=1.09, wpb=12525.2, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.486, clip=0, loss_scale=16, train_wall=92, gb_free=11.2, wall=7884
2023-07-25 13:32:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 13:32:30 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.373 | trans_loss 5.773 | nll_loss 3.11 | w2v_ctc_loss 1.43 | task_loss 4.535 | contrastive_loss 0.298 | total 4003.4 | n_correct 2347.6 | ppl 8.63 | accuracy 58.64 | uer 20.585 | wer 22.371 | raw_wer 22.371 | bleu 17.58 | wps 2171.1 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 17.71
2023-07-25 13:32:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-25 13:32:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_17.5808.pt
2023-07-25 13:32:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_17.5808.pt
2023-07-25 13:32:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_17.5808.pt (epoch 6 @ 8838 updates, score 17.58) (writing took 19.12143992818892 seconds)
2023-07-25 13:32:49 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-25 13:32:49 | INFO | train | epoch 006 | loss 2.211 | trans_loss 3.591 | nll_loss 1.772 | w2v_ctc_loss 1.222 | task_loss 0.93 | contrastive_loss 0.23 | total 4138.65 | n_correct 2314.97 | ppl 3.42 | accuracy 55.935 | wps 12449.1 | ups 1.01 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.499 | clip 0 | loss_scale 16 | train_wall 1355 | gb_free 15.1 | wall 7961
2023-07-25 13:32:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 13:32:49 | INFO | fairseq.trainer | begin training epoch 7
2023-07-25 13:32:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 13:33:56 | INFO | train_inner | epoch 007:     62 / 1474 loss=2.149, trans_loss=3.56, nll_loss=1.733, w2v_ctc_loss=1.175, task_loss=0.908, contrastive_loss=0.162, total=4108.19, n_correct=2344.59, ppl=3.32, accuracy=57.071, wps=8494.3, ups=0.69, wpb=12266.6, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.493, clip=0, loss_scale=16, train_wall=91, gb_free=17.1, wall=8029
2023-07-25 13:35:27 | INFO | train_inner | epoch 007:    162 / 1474 loss=2.147, trans_loss=3.549, nll_loss=1.718, w2v_ctc_loss=1.16, task_loss=0.945, contrastive_loss=0.234, total=4106.05, n_correct=2350.56, ppl=3.29, accuracy=57.246, wps=13441.4, ups=1.1, wpb=12258.7, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.497, clip=0, loss_scale=16, train_wall=91, gb_free=16.7, wall=8120
2023-07-25 13:36:59 | INFO | train_inner | epoch 007:    262 / 1474 loss=2.133, trans_loss=3.545, nll_loss=1.711, w2v_ctc_loss=1.164, task_loss=0.944, contrastive_loss=0.139, total=4129.3, n_correct=2377.31, ppl=3.27, accuracy=57.572, wps=13407.4, ups=1.09, wpb=12322.8, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.496, clip=0, loss_scale=16, train_wall=91, gb_free=17.3, wall=8212
2023-07-25 13:38:32 | INFO | train_inner | epoch 007:    362 / 1474 loss=2.162, trans_loss=3.553, nll_loss=1.723, w2v_ctc_loss=1.151, task_loss=0.897, contrastive_loss=0.402, total=4201.67, n_correct=2404.19, ppl=3.3, accuracy=57.22, wps=13577.9, ups=1.08, wpb=12539.8, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.485, clip=0, loss_scale=32, train_wall=92, gb_free=15.4, wall=8304
2023-07-25 13:40:04 | INFO | train_inner | epoch 007:    462 / 1474 loss=2.154, trans_loss=3.554, nll_loss=1.727, w2v_ctc_loss=1.15, task_loss=0.915, contrastive_loss=0.336, total=4155.31, n_correct=2373.74, ppl=3.31, accuracy=57.125, wps=13504.1, ups=1.09, wpb=12410.9, bsz=465.5, num_updates=9300, lr=0.000146647, gnorm=0.498, clip=0, loss_scale=32, train_wall=91, gb_free=16.7, wall=8396
2023-07-25 13:41:35 | INFO | train_inner | epoch 007:    562 / 1474 loss=2.13, trans_loss=3.554, nll_loss=1.722, w2v_ctc_loss=1.154, task_loss=0.912, contrastive_loss=0.149, total=4165.88, n_correct=2388.51, ppl=3.3, accuracy=57.335, wps=13640.9, ups=1.1, wpb=12426.4, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.496, clip=0, loss_scale=32, train_wall=91, gb_free=17.2, wall=8487
2023-07-25 13:43:07 | INFO | train_inner | epoch 007:    662 / 1474 loss=2.119, trans_loss=3.553, nll_loss=1.723, w2v_ctc_loss=1.146, task_loss=0.935, contrastive_loss=0.133, total=4149.29, n_correct=2388.54, ppl=3.3, accuracy=57.565, wps=13443.5, ups=1.09, wpb=12381.3, bsz=451.6, num_updates=9500, lr=0.000145095, gnorm=0.491, clip=0, loss_scale=32, train_wall=92, gb_free=17, wall=8579
2023-07-25 13:44:39 | INFO | train_inner | epoch 007:    762 / 1474 loss=2.122, trans_loss=3.547, nll_loss=1.716, w2v_ctc_loss=1.15, task_loss=0.964, contrastive_loss=0.133, total=4134.54, n_correct=2379.42, ppl=3.28, accuracy=57.55, wps=13379.5, ups=1.08, wpb=12345.4, bsz=449.8, num_updates=9600, lr=0.000144338, gnorm=0.497, clip=0, loss_scale=32, train_wall=92, gb_free=13.8, wall=8672
2023-07-25 13:46:11 | INFO | train_inner | epoch 007:    862 / 1474 loss=2.125, trans_loss=3.556, nll_loss=1.728, w2v_ctc_loss=1.149, task_loss=0.934, contrastive_loss=0.154, total=4151.77, n_correct=2379.63, ppl=3.31, accuracy=57.316, wps=13516.7, ups=1.09, wpb=12391.6, bsz=461.9, num_updates=9700, lr=0.000143592, gnorm=0.487, clip=0, loss_scale=32, train_wall=91, gb_free=14.8, wall=8763
2023-07-25 13:47:43 | INFO | train_inner | epoch 007:    962 / 1474 loss=2.129, trans_loss=3.551, nll_loss=1.724, w2v_ctc_loss=1.136, task_loss=0.894, contrastive_loss=0.249, total=4124.8, n_correct=2373.16, ppl=3.3, accuracy=57.534, wps=13289.4, ups=1.08, wpb=12313.3, bsz=471.2, num_updates=9800, lr=0.000142857, gnorm=0.491, clip=0, loss_scale=32, train_wall=92, gb_free=16.5, wall=8856
2023-07-25 13:49:15 | INFO | train_inner | epoch 007:   1062 / 1474 loss=2.119, trans_loss=3.562, nll_loss=1.737, w2v_ctc_loss=1.148, task_loss=0.973, contrastive_loss=0.115, total=4113.08, n_correct=2355.63, ppl=3.33, accuracy=57.272, wps=13434.8, ups=1.09, wpb=12279.6, bsz=439.4, num_updates=9900, lr=0.000142134, gnorm=0.485, clip=0, loss_scale=32, train_wall=91, gb_free=14.7, wall=8947
2023-07-25 13:50:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-25 13:50:48 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.141, trans_loss=3.547, nll_loss=1.721, w2v_ctc_loss=1.138, task_loss=0.93, contrastive_loss=0.326, total=4112.66, n_correct=2366.27, ppl=3.3, accuracy=57.536, wps=13214, ups=1.08, wpb=12289.5, bsz=460.2, num_updates=10000, lr=0.000141421, gnorm=0.499, clip=0, loss_scale=16, train_wall=92, gb_free=15.9, wall=9040
2023-07-25 13:50:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 13:51:11 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.314 | trans_loss 5.715 | nll_loss 3.041 | w2v_ctc_loss 1.37 | task_loss 4.584 | contrastive_loss 0.284 | total 4003.4 | n_correct 2378.7 | ppl 8.23 | accuracy 59.417 | uer 19.571 | wer 21.252 | raw_wer 21.252 | bleu 18.45 | wps 2193.2 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.45
2023-07-25 13:51:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-25 13:51:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_7_10000.pt
2023-07-25 13:51:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_7_10000.pt
2023-07-25 13:51:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.45) (writing took 36.20196245983243 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:0')
2023-07-25 13:53:19 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.112, trans_loss=3.555, nll_loss=1.729, w2v_ctc_loss=1.135, task_loss=0.943, contrastive_loss=0.145, total=4129.52, n_correct=2373.31, ppl=3.31, accuracy=57.472, wps=8152.9, ups=0.66, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.426, clip=0, loss_scale=16, train_wall=91, gb_free=16.7, wall=9192
2023-07-25 13:54:50 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.124, trans_loss=3.548, nll_loss=1.72, w2v_ctc_loss=1.144, task_loss=0.874, contrastive_loss=0.181, total=4172.87, n_correct=2408.84, ppl=3.29, accuracy=57.726, wps=13748.8, ups=1.1, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.421, clip=0, loss_scale=16, train_wall=90, gb_free=17.2, wall=9282
2023-07-25 13:56:23 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.133, trans_loss=3.554, nll_loss=1.729, w2v_ctc_loss=1.145, task_loss=1.004, contrastive_loss=0.247, total=4109.42, n_correct=2358.81, ppl=3.32, accuracy=57.4, wps=13231.1, ups=1.08, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.429, clip=0, loss_scale=16, train_wall=92, gb_free=16.4, wall=9375
2023-07-25 13:56:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:2')
2023-07-25 13:56:56 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.316 | trans_loss 5.717 | nll_loss 3.04 | w2v_ctc_loss 1.372 | task_loss 4.56 | contrastive_loss 0.286 | total 4003.4 | n_correct 2371.5 | ppl 8.22 | accuracy 59.237 | uer 19.805 | wer 21.547 | raw_wer 21.547 | bleu 18.61 | wps 2115.6 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.61
2023-07-25 13:56:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-25 13:56:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 13:57:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 13:57:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 7 @ 10311 updates, score 18.61) (writing took 19.725259179249406 seconds)
2023-07-25 13:57:16 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-25 13:57:16 | INFO | train | epoch 007 | loss 2.132 | trans_loss 3.552 | nll_loss 1.723 | w2v_ctc_loss 1.148 | task_loss 0.933 | contrastive_loss 0.209 | total 4137.22 | n_correct 2375.61 | ppl 3.3 | accuracy 57.42 | wps 12398 | ups 1 | wpb 12351.6 | bsz 457.8 | num_updates 10311 | lr 0.000139272 | gnorm 0.479 | clip 0 | loss_scale 16 | train_wall 1345 | gb_free 13.1 | wall 9429
2023-07-25 13:57:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 13:57:17 | INFO | fairseq.trainer | begin training epoch 8
2023-07-25 13:57:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 13:58:47 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.079, trans_loss=3.528, nll_loss=1.689, w2v_ctc_loss=1.105, task_loss=0.982, contrastive_loss=0.14, total=4116.25, n_correct=2400.3, ppl=3.22, accuracy=58.313, wps=8495.1, ups=0.69, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.42, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=9520
2023-07-25 14:00:18 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.079, trans_loss=3.52, nll_loss=1.678, w2v_ctc_loss=1.103, task_loss=1.01, contrastive_loss=0.161, total=4037.23, n_correct=2362.38, ppl=3.2, accuracy=58.515, wps=13286.1, ups=1.1, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.43, clip=0, loss_scale=16, train_wall=90, gb_free=12.6, wall=9610
2023-07-25 14:01:49 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.074, trans_loss=3.515, nll_loss=1.675, w2v_ctc_loss=1.099, task_loss=0.876, contrastive_loss=0.163, total=4207.78, n_correct=2470.26, ppl=3.19, accuracy=58.707, wps=13777, ups=1.1, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.418, clip=0, loss_scale=16, train_wall=91, gb_free=12.8, wall=9701
2023-07-25 14:03:22 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.095, trans_loss=3.526, nll_loss=1.688, w2v_ctc_loss=1.12, task_loss=0.994, contrastive_loss=0.182, total=4127.24, n_correct=2405.99, ppl=3.22, accuracy=58.295, wps=13249.3, ups=1.08, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.434, clip=0, loss_scale=16, train_wall=92, gb_free=11.6, wall=9794
2023-07-25 14:04:54 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.12, trans_loss=3.52, nll_loss=1.683, w2v_ctc_loss=1.094, task_loss=0.832, contrastive_loss=0.446, total=4203.76, n_correct=2459.02, ppl=3.21, accuracy=58.496, wps=13622.8, ups=1.09, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.423, clip=0, loss_scale=16, train_wall=92, gb_free=14.5, wall=9886
2023-07-25 14:06:25 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.083, trans_loss=3.523, nll_loss=1.689, w2v_ctc_loss=1.118, task_loss=1.018, contrastive_loss=0.114, total=4062.5, n_correct=2362.33, ppl=3.23, accuracy=58.15, wps=13269, ups=1.09, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.423, clip=0, loss_scale=16, train_wall=91, gb_free=11.1, wall=9978
2023-07-25 14:07:58 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.076, trans_loss=3.518, nll_loss=1.68, w2v_ctc_loss=1.113, task_loss=0.959, contrastive_loss=0.126, total=4142.78, n_correct=2428.44, ppl=3.2, accuracy=58.619, wps=13429, ups=1.09, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.427, clip=0, loss_scale=16, train_wall=91, gb_free=15.8, wall=10070
2023-07-25 14:09:29 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.082, trans_loss=3.518, nll_loss=1.683, w2v_ctc_loss=1.103, task_loss=0.955, contrastive_loss=0.212, total=4118.9, n_correct=2406.21, ppl=3.21, accuracy=58.419, wps=13445.9, ups=1.09, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.423, clip=0, loss_scale=16, train_wall=91, gb_free=15.1, wall=10162
2023-07-25 14:11:00 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.079, trans_loss=3.52, nll_loss=1.686, w2v_ctc_loss=1.093, task_loss=0.895, contrastive_loss=0.223, total=4169.01, n_correct=2445.58, ppl=3.22, accuracy=58.661, wps=13667.9, ups=1.1, wpb=12452.5, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.427, clip=0, loss_scale=16, train_wall=91, gb_free=16, wall=10253
2023-07-25 14:12:31 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.06, trans_loss=3.521, nll_loss=1.685, w2v_ctc_loss=1.09, task_loss=0.891, contrastive_loss=0.123, total=4154.69, n_correct=2439.06, ppl=3.21, accuracy=58.706, wps=13638.6, ups=1.1, wpb=12403.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.416, clip=0, loss_scale=16, train_wall=90, gb_free=17.7, wall=10344
2023-07-25 14:14:03 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.095, trans_loss=3.528, nll_loss=1.695, w2v_ctc_loss=1.093, task_loss=0.927, contrastive_loss=0.346, total=4199.1, n_correct=2447.66, ppl=3.24, accuracy=58.29, wps=13633, ups=1.09, wpb=12534.3, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.427, clip=0, loss_scale=16, train_wall=91, gb_free=12.5, wall=10436
2023-07-25 14:15:34 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.069, trans_loss=3.52, nll_loss=1.687, w2v_ctc_loss=1.097, task_loss=0.882, contrastive_loss=0.133, total=4177.31, n_correct=2448.33, ppl=3.22, accuracy=58.61, wps=13699.3, ups=1.1, wpb=12476.3, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.431, clip=0, loss_scale=16, train_wall=91, gb_free=14.8, wall=10527
2023-07-25 14:17:05 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.078, trans_loss=3.527, nll_loss=1.694, w2v_ctc_loss=1.106, task_loss=0.972, contrastive_loss=0.155, total=4063.85, n_correct=2369.45, ppl=3.24, accuracy=58.306, wps=13407.5, ups=1.1, wpb=12140.6, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.426, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=10617
2023-07-25 14:18:36 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.083, trans_loss=3.528, nll_loss=1.696, w2v_ctc_loss=1.099, task_loss=0.919, contrastive_loss=0.209, total=4141.5, n_correct=2423.79, ppl=3.24, accuracy=58.524, wps=13597.3, ups=1.1, wpb=12367.2, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.426, clip=0, loss_scale=16, train_wall=90, gb_free=16.3, wall=10708
2023-07-25 14:19:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 14:20:16 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.286 | trans_loss 5.685 | nll_loss 2.994 | w2v_ctc_loss 1.35 | task_loss 4.59 | contrastive_loss 0.276 | total 4003.4 | n_correct 2402.7 | ppl 7.97 | accuracy 60.016 | uer 18.865 | wer 20.547 | raw_wer 20.547 | bleu 18.65 | wps 2164.2 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.65
2023-07-25 14:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-25 14:20:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 14:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 14:20:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.65) (writing took 20.073438180610538 seconds)
2023-07-25 14:20:37 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-25 14:20:37 | INFO | train | epoch 008 | loss 2.082 | trans_loss 3.522 | nll_loss 1.687 | w2v_ctc_loss 1.101 | task_loss 0.932 | contrastive_loss 0.202 | total 4138.65 | n_correct 2420.29 | ppl 3.22 | accuracy 58.48 | wps 13001.9 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.425 | clip 0 | loss_scale 16 | train_wall 1340 | gb_free 16.8 | wall 10830
2023-07-25 14:20:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 14:20:37 | INFO | fairseq.trainer | begin training epoch 9
2023-07-25 14:20:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 14:21:00 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.082, trans_loss=3.521, nll_loss=1.685, w2v_ctc_loss=1.082, task_loss=0.898, contrastive_loss=0.337, total=4139.35, n_correct=2427.15, ppl=3.22, accuracy=58.636, wps=8560.7, ups=0.69, wpb=12350.9, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.426, clip=0, loss_scale=16, train_wall=91, gb_free=15.4, wall=10852
2023-07-25 14:22:31 | INFO | train_inner | epoch 009:    115 / 1474 loss=2.027, trans_loss=3.484, nll_loss=1.637, w2v_ctc_loss=1.056, task_loss=0.885, contrastive_loss=0.153, total=4181.9, n_correct=2496.3, ppl=3.11, accuracy=59.693, wps=13693.3, ups=1.1, wpb=12488.1, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.421, clip=0, loss_scale=16, train_wall=91, gb_free=16.2, wall=10944
2023-07-25 14:24:03 | INFO | train_inner | epoch 009:    215 / 1474 loss=2.025, trans_loss=3.491, nll_loss=1.646, w2v_ctc_loss=1.06, task_loss=1.004, contrastive_loss=0.109, total=4062.07, n_correct=2414.88, ppl=3.13, accuracy=59.449, wps=13190.2, ups=1.09, wpb=12129.1, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.429, clip=0, loss_scale=16, train_wall=91, gb_free=15.5, wall=11036
2023-07-25 14:24:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 14:24:28 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.282 | trans_loss 5.696 | nll_loss 3.008 | w2v_ctc_loss 1.31 | task_loss 4.548 | contrastive_loss 0.281 | total 4003.4 | n_correct 2393.4 | ppl 8.05 | accuracy 59.784 | uer 18.862 | wer 20.737 | raw_wer 20.737 | bleu 18.61 | wps 1931.4 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.65
2023-07-25 14:24:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-25 14:24:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_9_12000.pt
2023-07-25 14:24:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_9_12000.pt
2023-07-25 14:24:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.61) (writing took 15.247488247230649 seconds)
2023-07-25 14:26:15 | INFO | train_inner | epoch 009:    315 / 1474 loss=2.02, trans_loss=3.479, nll_loss=1.633, w2v_ctc_loss=1.046, task_loss=0.871, contrastive_loss=0.162, total=4152.1, n_correct=2484.49, ppl=3.1, accuracy=59.837, wps=9416.7, ups=0.76, wpb=12407.3, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.423, clip=0, loss_scale=32, train_wall=90, gb_free=16.3, wall=11167
2023-07-25 14:27:48 | INFO | train_inner | epoch 009:    415 / 1474 loss=2.024, trans_loss=3.495, nll_loss=1.652, w2v_ctc_loss=1.055, task_loss=0.91, contrastive_loss=0.127, total=4203.78, n_correct=2499.29, ppl=3.14, accuracy=59.453, wps=13513.4, ups=1.08, wpb=12551.8, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.412, clip=0, loss_scale=32, train_wall=92, gb_free=17.1, wall=11260
2023-07-25 14:29:19 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.051, trans_loss=3.501, nll_loss=1.658, w2v_ctc_loss=1.078, task_loss=0.98, contrastive_loss=0.177, total=4112.78, n_correct=2434.45, ppl=3.16, accuracy=59.192, wps=13503, ups=1.1, wpb=12275.6, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.422, clip=0, loss_scale=32, train_wall=90, gb_free=16.1, wall=11351
2023-07-25 14:30:50 | INFO | train_inner | epoch 009:    615 / 1474 loss=2.016, trans_loss=3.49, nll_loss=1.648, w2v_ctc_loss=1.046, task_loss=0.947, contrastive_loss=0.138, total=4131.32, n_correct=2460.4, ppl=3.13, accuracy=59.555, wps=13525.2, ups=1.1, wpb=12347.4, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.416, clip=0, loss_scale=32, train_wall=91, gb_free=17.8, wall=11442
2023-07-25 14:32:21 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.052, trans_loss=3.502, nll_loss=1.663, w2v_ctc_loss=1.072, task_loss=0.953, contrastive_loss=0.221, total=4082.11, n_correct=2413.88, ppl=3.17, accuracy=59.133, wps=13369.6, ups=1.1, wpb=12194.8, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.424, clip=0, loss_scale=32, train_wall=91, gb_free=16.9, wall=11534
2023-07-25 14:33:53 | INFO | train_inner | epoch 009:    815 / 1474 loss=2.074, trans_loss=3.495, nll_loss=1.656, w2v_ctc_loss=1.065, task_loss=0.842, contrastive_loss=0.369, total=4221.08, n_correct=2502.45, ppl=3.15, accuracy=59.285, wps=13768, ups=1.09, wpb=12613.9, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.423, clip=0, loss_scale=32, train_wall=91, gb_free=17.6, wall=11625
2023-07-25 14:35:25 | INFO | train_inner | epoch 009:    915 / 1474 loss=2.056, trans_loss=3.501, nll_loss=1.658, w2v_ctc_loss=1.061, task_loss=0.964, contrastive_loss=0.344, total=4142.34, n_correct=2457.07, ppl=3.16, accuracy=59.316, wps=13343.4, ups=1.08, wpb=12359.9, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.415, clip=0, loss_scale=32, train_wall=92, gb_free=17.2, wall=11718
2023-07-25 14:36:57 | INFO | train_inner | epoch 009:   1015 / 1474 loss=2.041, trans_loss=3.51, nll_loss=1.67, w2v_ctc_loss=1.072, task_loss=1.047, contrastive_loss=0.125, total=4097.15, n_correct=2419.96, ppl=3.18, accuracy=59.064, wps=13354.3, ups=1.09, wpb=12228.7, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.425, clip=0, loss_scale=32, train_wall=91, gb_free=16.8, wall=11809
2023-07-25 14:38:28 | INFO | train_inner | epoch 009:   1115 / 1474 loss=2.031, trans_loss=3.504, nll_loss=1.661, w2v_ctc_loss=1.056, task_loss=0.871, contrastive_loss=0.152, total=4182.29, n_correct=2485.54, ppl=3.16, accuracy=59.43, wps=13731.4, ups=1.1, wpb=12467.1, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.42, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=11900
2023-07-25 14:40:00 | INFO | train_inner | epoch 009:   1215 / 1474 loss=2.041, trans_loss=3.506, nll_loss=1.667, w2v_ctc_loss=1.074, task_loss=0.989, contrastive_loss=0.13, total=4141.43, n_correct=2450.69, ppl=3.17, accuracy=59.175, wps=13449.4, ups=1.09, wpb=12364.7, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.419, clip=0, loss_scale=32, train_wall=91, gb_free=17.5, wall=11992
2023-07-25 14:41:31 | INFO | train_inner | epoch 009:   1315 / 1474 loss=2.053, trans_loss=3.5, nll_loss=1.66, w2v_ctc_loss=1.052, task_loss=0.847, contrastive_loss=0.328, total=4203.91, n_correct=2501.96, ppl=3.16, accuracy=59.515, wps=13766.3, ups=1.1, wpb=12545.2, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.42, clip=0, loss_scale=32, train_wall=91, gb_free=17.3, wall=12083
2023-07-25 14:43:03 | INFO | train_inner | epoch 009:   1415 / 1474 loss=2.033, trans_loss=3.511, nll_loss=1.672, w2v_ctc_loss=1.066, task_loss=1.006, contrastive_loss=0.106, total=4077.08, n_correct=2414.04, ppl=3.19, accuracy=59.21, wps=13279, ups=1.09, wpb=12165, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.42, clip=0, loss_scale=32, train_wall=91, gb_free=17.3, wall=12175
2023-07-25 14:43:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 14:44:18 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.268 | trans_loss 5.666 | nll_loss 2.973 | w2v_ctc_loss 1.334 | task_loss 4.563 | contrastive_loss 0.277 | total 4003.4 | n_correct 2402.9 | ppl 7.85 | accuracy 60.021 | uer 18.422 | wer 20.409 | raw_wer 20.409 | bleu 18.79 | wps 2301.6 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 18.79
2023-07-25 14:44:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-07-25 14:44:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 14:44:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 14:44:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 9 @ 13259 updates, score 18.79) (writing took 19.702730432152748 seconds)
2023-07-25 14:44:38 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-25 14:44:38 | INFO | train | epoch 009 | loss 2.04 | trans_loss 3.498 | nll_loss 1.656 | w2v_ctc_loss 1.062 | task_loss 0.932 | contrastive_loss 0.195 | total 4138.65 | n_correct 2457.69 | ppl 3.15 | accuracy 59.384 | wps 12641.2 | ups 1.02 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.421 | clip 0 | loss_scale 32 | train_wall 1341 | gb_free 11.4 | wall 12270
2023-07-25 14:44:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 14:44:38 | INFO | fairseq.trainer | begin training epoch 10
2023-07-25 14:44:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 14:45:24 | INFO | train_inner | epoch 010:     41 / 1474 loss=2.027, trans_loss=3.49, nll_loss=1.647, w2v_ctc_loss=1.044, task_loss=0.889, contrastive_loss=0.21, total=4100.86, n_correct=2452.98, ppl=3.13, accuracy=59.816, wps=8668.9, ups=0.71, wpb=12239.9, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.435, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=12316
2023-07-25 14:46:55 | INFO | train_inner | epoch 010:    141 / 1474 loss=1.981, trans_loss=3.464, nll_loss=1.613, w2v_ctc_loss=1.012, task_loss=0.88, contrastive_loss=0.132, total=4240.18, n_correct=2562.02, ppl=3.06, accuracy=60.422, wps=13908.1, ups=1.1, wpb=12664, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.409, clip=0, loss_scale=32, train_wall=91, gb_free=14.8, wall=12407
2023-07-25 14:48:26 | INFO | train_inner | epoch 010:    241 / 1474 loss=2.008, trans_loss=3.467, nll_loss=1.614, w2v_ctc_loss=1.025, task_loss=0.923, contrastive_loss=0.253, total=4126.3, n_correct=2491.86, ppl=3.06, accuracy=60.39, wps=13486, ups=1.1, wpb=12312.3, bsz=460.9, num_updates=13500, lr=0.000121716, gnorm=0.416, clip=0, loss_scale=32, train_wall=91, gb_free=15.4, wall=12499
2023-07-25 14:49:57 | INFO | train_inner | epoch 010:    341 / 1474 loss=1.989, trans_loss=3.463, nll_loss=1.615, w2v_ctc_loss=1.018, task_loss=0.949, contrastive_loss=0.162, total=4132.25, n_correct=2493.46, ppl=3.06, accuracy=60.341, wps=13529.1, ups=1.1, wpb=12352, bsz=452.8, num_updates=13600, lr=0.000121268, gnorm=0.415, clip=0, loss_scale=32, train_wall=91, gb_free=14.6, wall=12590
2023-07-25 14:51:30 | INFO | train_inner | epoch 010:    441 / 1474 loss=2.005, trans_loss=3.47, nll_loss=1.621, w2v_ctc_loss=1.006, task_loss=0.893, contrastive_loss=0.337, total=4203.14, n_correct=2535.16, ppl=3.08, accuracy=60.316, wps=13559.9, ups=1.08, wpb=12548.6, bsz=481.7, num_updates=13700, lr=0.000120824, gnorm=0.418, clip=0, loss_scale=32, train_wall=92, gb_free=16.3, wall=12682
2023-07-25 14:53:02 | INFO | train_inner | epoch 010:    541 / 1474 loss=2.007, trans_loss=3.486, nll_loss=1.637, w2v_ctc_loss=1.042, task_loss=0.993, contrastive_loss=0.118, total=4106.5, n_correct=2460.24, ppl=3.11, accuracy=59.911, wps=13335.3, ups=1.09, wpb=12244.6, bsz=440, num_updates=13800, lr=0.000120386, gnorm=0.421, clip=0, loss_scale=32, train_wall=91, gb_free=16.3, wall=12774
2023-07-25 14:54:33 | INFO | train_inner | epoch 010:    641 / 1474 loss=2.018, trans_loss=3.48, nll_loss=1.633, w2v_ctc_loss=1.032, task_loss=0.889, contrastive_loss=0.238, total=4170.61, n_correct=2507.15, ppl=3.1, accuracy=60.115, wps=13590.9, ups=1.09, wpb=12448.2, bsz=476.1, num_updates=13900, lr=0.000119952, gnorm=0.42, clip=0, loss_scale=32, train_wall=91, gb_free=10.6, wall=12866
2023-07-25 14:56:04 | INFO | train_inner | epoch 010:    741 / 1474 loss=2.01, trans_loss=3.482, nll_loss=1.636, w2v_ctc_loss=1.048, task_loss=0.938, contrastive_loss=0.116, total=4123.31, n_correct=2471.74, ppl=3.11, accuracy=59.946, wps=13608.5, ups=1.11, wpb=12306.7, bsz=453, num_updates=14000, lr=0.000119523, gnorm=0.425, clip=0, loss_scale=32, train_wall=90, gb_free=17, wall=12956
2023-07-25 14:56:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 14:56:26 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.262 | trans_loss 5.662 | nll_loss 2.965 | w2v_ctc_loss 1.322 | task_loss 4.578 | contrastive_loss 0.281 | total 4003.4 | n_correct 2412.8 | ppl 7.81 | accuracy 60.269 | uer 18.854 | wer 20.573 | raw_wer 20.573 | bleu 18.94 | wps 2271 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 18.94
2023-07-25 14:56:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-25 14:56:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_10_14000.pt
2023-07-25 14:56:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_10_14000.pt
2023-07-25 14:57:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 18.94) (writing took 38.05689152516425 seconds)
2023-07-25 14:58:37 | INFO | train_inner | epoch 010:    841 / 1474 loss=1.985, trans_loss=3.476, nll_loss=1.629, w2v_ctc_loss=1.018, task_loss=0.918, contrastive_loss=0.117, total=4125.69, n_correct=2488.02, ppl=3.09, accuracy=60.306, wps=8060.2, ups=0.65, wpb=12321, bsz=456.1, num_updates=14100, lr=0.000119098, gnorm=0.411, clip=0, loss_scale=64, train_wall=91, gb_free=15.7, wall=13109
2023-07-25 15:00:08 | INFO | train_inner | epoch 010:    941 / 1474 loss=2.002, trans_loss=3.479, nll_loss=1.63, w2v_ctc_loss=1.028, task_loss=0.889, contrastive_loss=0.158, total=4170.41, n_correct=2514.64, ppl=3.1, accuracy=60.297, wps=13670, ups=1.1, wpb=12437.5, bsz=470.8, num_updates=14200, lr=0.000118678, gnorm=0.419, clip=0, loss_scale=64, train_wall=90, gb_free=16, wall=13200
2023-07-25 15:01:39 | INFO | train_inner | epoch 010:   1041 / 1474 loss=2.001, trans_loss=3.482, nll_loss=1.638, w2v_ctc_loss=1.031, task_loss=1.008, contrastive_loss=0.131, total=4072.57, n_correct=2439.09, ppl=3.11, accuracy=59.891, wps=13361.7, ups=1.1, wpb=12161.8, bsz=434.8, num_updates=14300, lr=0.000118262, gnorm=0.426, clip=0, loss_scale=64, train_wall=91, gb_free=16.8, wall=13291
2023-07-25 15:03:10 | INFO | train_inner | epoch 010:   1141 / 1474 loss=2.012, trans_loss=3.491, nll_loss=1.647, w2v_ctc_loss=1.048, task_loss=1.037, contrastive_loss=0.112, total=4041.97, n_correct=2413.43, ppl=3.13, accuracy=59.709, wps=13224.3, ups=1.1, wpb=12067, bsz=421.9, num_updates=14400, lr=0.000117851, gnorm=0.421, clip=0, loss_scale=64, train_wall=91, gb_free=16.4, wall=13382
2023-07-25 15:04:41 | INFO | train_inner | epoch 010:   1241 / 1474 loss=1.999, trans_loss=3.478, nll_loss=1.637, w2v_ctc_loss=1.039, task_loss=0.959, contrastive_loss=0.107, total=4103.65, n_correct=2460.56, ppl=3.11, accuracy=59.96, wps=13438.5, ups=1.1, wpb=12271.8, bsz=443.9, num_updates=14500, lr=0.000117444, gnorm=0.422, clip=0, loss_scale=64, train_wall=91, gb_free=15.5, wall=13474
2023-07-25 15:06:12 | INFO | train_inner | epoch 010:   1341 / 1474 loss=1.998, trans_loss=3.485, nll_loss=1.642, w2v_ctc_loss=1.032, task_loss=0.951, contrastive_loss=0.121, total=4121.93, n_correct=2477.29, ppl=3.12, accuracy=60.1, wps=13564.2, ups=1.1, wpb=12309.4, bsz=451.2, num_updates=14600, lr=0.000117041, gnorm=0.423, clip=0, loss_scale=64, train_wall=90, gb_free=16.7, wall=13564
2023-07-25 15:06:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 15:07:46 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.009, trans_loss=3.489, nll_loss=1.644, w2v_ctc_loss=1.018, task_loss=0.904, contrastive_loss=0.228, total=4172.44, n_correct=2501.67, ppl=3.13, accuracy=59.957, wps=13282.9, ups=1.07, wpb=12446.1, bsz=470, num_updates=14700, lr=0.000116642, gnorm=0.419, clip=0, loss_scale=32, train_wall=93, gb_free=17, wall=13658
2023-07-25 15:08:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 15:08:39 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.256 | trans_loss 5.644 | nll_loss 2.943 | w2v_ctc_loss 1.347 | task_loss 4.561 | contrastive_loss 0.271 | total 4003.4 | n_correct 2424.8 | ppl 7.69 | accuracy 60.569 | uer 18.1 | wer 19.839 | raw_wer 19.839 | bleu 19.44 | wps 2092.4 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.44
2023-07-25 15:08:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-25 15:08:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 15:08:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 15:08:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.44) (writing took 19.856955653056502 seconds)
2023-07-25 15:08:59 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-25 15:08:59 | INFO | train | epoch 010 | loss 2.002 | trans_loss 3.478 | nll_loss 1.631 | w2v_ctc_loss 1.027 | task_loss 0.934 | contrastive_loss 0.178 | total 4137.35 | n_correct 2487.72 | ppl 3.1 | accuracy 60.128 | wps 12451.2 | ups 1.01 | wpb 12351.9 | bsz 457.7 | num_updates 14732 | lr 0.000116516 | gnorm 0.419 | clip 0 | loss_scale 32 | train_wall 1340 | gb_free 17.2 | wall 13732
2023-07-25 15:08:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 15:08:59 | INFO | fairseq.trainer | begin training epoch 11
2023-07-25 15:08:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 15:10:10 | INFO | train_inner | epoch 011:     68 / 1474 loss=1.973, trans_loss=3.453, nll_loss=1.598, w2v_ctc_loss=0.998, task_loss=0.865, contrastive_loss=0.196, total=4175.24, n_correct=2543.21, ppl=3.03, accuracy=60.912, wps=8662.5, ups=0.7, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.415, clip=0, loss_scale=32, train_wall=90, gb_free=16.7, wall=13802
2023-07-25 15:11:40 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.964, trans_loss=3.453, nll_loss=1.601, w2v_ctc_loss=1.002, task_loss=0.96, contrastive_loss=0.114, total=4087.78, n_correct=2487.36, ppl=3.03, accuracy=60.849, wps=13471.1, ups=1.1, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.424, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=13893
2023-07-25 15:13:12 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.955, trans_loss=3.453, nll_loss=1.599, w2v_ctc_loss=0.992, task_loss=0.961, contrastive_loss=0.109, total=4118.77, n_correct=2506.53, ppl=3.03, accuracy=60.856, wps=13468.5, ups=1.1, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.415, clip=0, loss_scale=32, train_wall=91, gb_free=12.2, wall=13984
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:0')
2023-07-25 15:14:19 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.111, trans_loss=5.132, nll_loss=2.38, w2v_ctc_loss=0.746, task_loss=1.428, contrastive_loss=0.087, total=4097.83, n_correct=2493.01, ppl=5.21, accuracy=60.837, wps=12144.6, ups=1.47, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.556, clip=0, loss_scale=32, train_wall=67, gb_free=15.6, wall=14052
2023-07-25 15:15:28 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.13, trans_loss=5.174, nll_loss=2.411, w2v_ctc_loss=0.745, task_loss=1.46, contrastive_loss=0.209, total=4110.64, n_correct=2488.05, ppl=5.32, accuracy=60.527, wps=11967.9, ups=1.46, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=14121
2023-07-25 15:16:37 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.131, trans_loss=5.171, nll_loss=2.409, w2v_ctc_loss=0.754, task_loss=1.498, contrastive_loss=0.205, total=4071.69, n_correct=2463.58, ppl=5.31, accuracy=60.505, wps=11884.2, ups=1.46, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.569, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=14189
2023-07-25 15:17:45 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.132, trans_loss=5.171, nll_loss=2.409, w2v_ctc_loss=0.75, task_loss=1.37, contrastive_loss=0.263, total=4157.2, n_correct=2513.12, ppl=5.31, accuracy=60.452, wps=12159.2, ups=1.46, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.55, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=14257
2023-07-25 15:18:54 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.127, trans_loss=5.181, nll_loss=2.422, w2v_ctc_loss=0.762, task_loss=1.405, contrastive_loss=0.088, total=4174.91, n_correct=2529.33, ppl=5.36, accuracy=60.584, wps=12172.8, ups=1.46, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.553, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=14326
2023-07-25 15:20:02 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.126, trans_loss=5.182, nll_loss=2.423, w2v_ctc_loss=0.756, task_loss=1.464, contrastive_loss=0.075, total=4118.44, n_correct=2484.98, ppl=5.36, accuracy=60.338, wps=12138.7, ups=1.47, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.554, clip=0, loss_scale=32, train_wall=67, gb_free=10.6, wall=14394
2023-07-25 15:21:10 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.126, trans_loss=5.18, nll_loss=2.421, w2v_ctc_loss=0.761, task_loss=1.432, contrastive_loss=0.089, total=4140.92, n_correct=2501.53, ppl=5.35, accuracy=60.41, wps=12164.3, ups=1.47, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=14462
2023-07-25 15:22:18 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.122, trans_loss=5.174, nll_loss=2.415, w2v_ctc_loss=0.757, task_loss=1.377, contrastive_loss=0.108, total=4136.99, n_correct=2508.24, ppl=5.33, accuracy=60.63, wps=12075.4, ups=1.46, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.562, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=14531
2023-07-25 15:23:26 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.125, trans_loss=5.183, nll_loss=2.426, w2v_ctc_loss=0.76, task_loss=1.392, contrastive_loss=0.094, total=4185.65, n_correct=2528.04, ppl=5.37, accuracy=60.398, wps=12281.8, ups=1.47, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.557, clip=0, loss_scale=32, train_wall=68, gb_free=13.9, wall=14599
2023-07-25 15:24:34 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.128, trans_loss=5.176, nll_loss=2.418, w2v_ctc_loss=0.759, task_loss=1.344, contrastive_loss=0.164, total=4171.89, n_correct=2523.51, ppl=5.34, accuracy=60.488, wps=12243.6, ups=1.47, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.561, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=14667
2023-07-25 15:24:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:6')
2023-07-25 15:24:56 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.268 | trans_loss 5.639 | nll_loss 2.94 | w2v_ctc_loss 1.397 | task_loss 4.625 | contrastive_loss 0.272 | total 4003.4 | n_correct 2432.6 | ppl 7.67 | accuracy 60.763 | uer 18.164 | wer 19.958 | raw_wer 19.958 | bleu 19.12 | wps 2392.2 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.44
2023-07-25 15:24:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-25 15:24:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_11_16000.pt
2023-07-25 15:25:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_11_16000.pt
2023-07-25 15:25:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.12) (writing took 18.70959708839655 seconds)
2023-07-25 15:26:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-25 15:26:27 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.135, trans_loss=5.179, nll_loss=2.422, w2v_ctc_loss=0.748, task_loss=1.304, contrastive_loss=0.329, total=4179.61, n_correct=2528.83, ppl=5.36, accuracy=60.504, wps=7446.6, ups=0.89, wpb=8359.2, bsz=325.3, num_updates=16100, lr=0.000111456, gnorm=0.559, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=14779
2023-07-25 15:27:35 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.12, trans_loss=5.181, nll_loss=2.424, w2v_ctc_loss=0.752, task_loss=1.344, contrastive_loss=0.097, total=4161.81, n_correct=2515.39, ppl=5.37, accuracy=60.44, wps=12190.6, ups=1.46, wpb=8323.6, bsz=313.2, num_updates=16200, lr=0.000111111, gnorm=0.568, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=14847
2023-07-25 15:27:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 15:28:02 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.235 | trans_loss 5.634 | nll_loss 2.933 | w2v_ctc_loss 1.296 | task_loss 4.588 | contrastive_loss 0.275 | total 4003.4 | n_correct 2433.2 | ppl 7.64 | accuracy 60.778 | uer 18.294 | wer 20.096 | raw_wer 20.096 | bleu 19.21 | wps 2094.4 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 19.44
2023-07-25 15:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-07-25 15:28:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.2104.pt
2023-07-25 15:28:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.2104.pt
2023-07-25 15:28:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.2104.pt (epoch 11 @ 16205 updates, score 19.21) (writing took 11.998137487098575 seconds)
2023-07-25 15:28:15 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-25 15:28:15 | INFO | train | epoch 011 | loss 2.085 | trans_loss 4.745 | nll_loss 2.211 | w2v_ctc_loss 0.814 | task_loss 1.283 | contrastive_loss 0.141 | total 4138.02 | n_correct 2506.99 | ppl 4.63 | accuracy 60.584 | wps 11497.1 | ups 1.27 | wpb 9020.3 | bsz 333.3 | num_updates 16205 | lr 0.000111094 | gnorm 0.535 | clip 0 | loss_scale 16 | train_wall 1060 | gb_free 17.2 | wall 14887
2023-07-25 15:28:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 15:28:15 | INFO | fairseq.trainer | begin training epoch 12
2023-07-25 15:28:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 15:29:29 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.096, trans_loss=5.121, nll_loss=2.344, w2v_ctc_loss=0.736, task_loss=1.348, contrastive_loss=0.131, total=4139.2, n_correct=2548.12, ppl=5.08, accuracy=61.561, wps=7283.8, ups=0.88, wpb=8278.4, bsz=312.5, num_updates=16300, lr=0.00011077, gnorm=0.554, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=14961
2023-07-25 15:30:37 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.103, trans_loss=5.133, nll_loss=2.359, w2v_ctc_loss=0.746, task_loss=1.438, contrastive_loss=0.081, total=4126.87, n_correct=2527.14, ppl=5.13, accuracy=61.236, wps=12128, ups=1.47, wpb=8253.7, bsz=295.9, num_updates=16400, lr=0.000110432, gnorm=0.57, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=15029
2023-07-25 15:31:45 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.096, trans_loss=5.131, nll_loss=2.358, w2v_ctc_loss=0.732, task_loss=1.31, contrastive_loss=0.113, total=4203.54, n_correct=2580.47, ppl=5.12, accuracy=61.388, wps=12254.6, ups=1.46, wpb=8407.1, bsz=321.1, num_updates=16500, lr=0.000110096, gnorm=0.554, clip=0, loss_scale=16, train_wall=68, gb_free=14.5, wall=15098
2023-07-25 15:32:53 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.105, trans_loss=5.142, nll_loss=2.372, w2v_ctc_loss=0.745, task_loss=1.372, contrastive_loss=0.096, total=4149.28, n_correct=2540.57, ppl=5.18, accuracy=61.229, wps=12229.3, ups=1.47, wpb=8298.6, bsz=307.1, num_updates=16600, lr=0.000109764, gnorm=0.577, clip=0, loss_scale=16, train_wall=67, gb_free=15.1, wall=15166
2023-07-25 15:34:01 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.111, trans_loss=5.152, nll_loss=2.386, w2v_ctc_loss=0.75, task_loss=1.408, contrastive_loss=0.102, total=4106.46, n_correct=2505.62, ppl=5.23, accuracy=61.017, wps=12021, ups=1.46, wpb=8212.9, bsz=301.2, num_updates=16700, lr=0.000109435, gnorm=0.552, clip=0, loss_scale=16, train_wall=68, gb_free=17.8, wall=15234
2023-07-25 15:35:10 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.108, trans_loss=5.144, nll_loss=2.375, w2v_ctc_loss=0.742, task_loss=1.336, contrastive_loss=0.17, total=4190.91, n_correct=2563.54, ppl=5.19, accuracy=61.169, wps=12224, ups=1.46, wpb=8381.8, bsz=316.5, num_updates=16800, lr=0.000109109, gnorm=0.571, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=15303
2023-07-25 15:36:17 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.104, trans_loss=5.142, nll_loss=2.374, w2v_ctc_loss=0.726, task_loss=1.288, contrastive_loss=0.256, total=4203.66, n_correct=2575.67, ppl=5.18, accuracy=61.272, wps=12487.7, ups=1.49, wpb=8407.3, bsz=324.4, num_updates=16900, lr=0.000108786, gnorm=0.549, clip=0, loss_scale=16, train_wall=67, gb_free=17.4, wall=15370
2023-07-25 15:37:26 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.105, trans_loss=5.144, nll_loss=2.376, w2v_ctc_loss=0.745, task_loss=1.415, contrastive_loss=0.09, total=4095.72, n_correct=2506.74, ppl=5.19, accuracy=61.204, wps=11985.8, ups=1.46, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.563, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=15438
2023-07-25 15:38:34 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.112, trans_loss=5.152, nll_loss=2.385, w2v_ctc_loss=0.744, task_loss=1.435, contrastive_loss=0.146, total=4162.82, n_correct=2539.76, ppl=5.22, accuracy=61.011, wps=12181.3, ups=1.46, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.565, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=15507
2023-07-25 15:39:42 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.116, trans_loss=5.16, nll_loss=2.397, w2v_ctc_loss=0.75, task_loss=1.426, contrastive_loss=0.152, total=4117.63, n_correct=2506.41, ppl=5.27, accuracy=60.87, wps=12128.4, ups=1.47, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.567, clip=0, loss_scale=16, train_wall=67, gb_free=16.8, wall=15574
2023-07-25 15:40:50 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.125, trans_loss=5.166, nll_loss=2.404, w2v_ctc_loss=0.753, task_loss=1.475, contrastive_loss=0.195, total=4046.48, n_correct=2461.01, ppl=5.29, accuracy=60.819, wps=11948.7, ups=1.48, wpb=8093, bsz=289.6, num_updates=17300, lr=0.000107521, gnorm=0.578, clip=0, loss_scale=16, train_wall=67, gb_free=15.9, wall=15642
2023-07-25 15:41:58 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.126, trans_loss=5.173, nll_loss=2.415, w2v_ctc_loss=0.759, task_loss=1.363, contrastive_loss=0.168, total=4201.13, n_correct=2546.22, ppl=5.33, accuracy=60.608, wps=12236.9, ups=1.46, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.566, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=15711
2023-07-25 15:43:07 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.122, trans_loss=5.166, nll_loss=2.404, w2v_ctc_loss=0.767, task_loss=1.557, contrastive_loss=0.077, total=4070.27, n_correct=2472.83, ppl=5.29, accuracy=60.753, wps=11905.2, ups=1.46, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.564, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=15779
2023-07-25 15:44:15 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.113, trans_loss=5.164, nll_loss=2.403, w2v_ctc_loss=0.737, task_loss=1.407, contrastive_loss=0.182, total=4139.63, n_correct=2519.6, ppl=5.29, accuracy=60.865, wps=12167.5, ups=1.47, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.555, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=15847
2023-07-25 15:45:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 15:45:34 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.268 | trans_loss 5.629 | nll_loss 2.923 | w2v_ctc_loss 1.422 | task_loss 4.578 | contrastive_loss 0.268 | total 4003.4 | n_correct 2439.8 | ppl 7.59 | accuracy 60.943 | uer 18.557 | wer 20.331 | raw_wer 20.331 | bleu 19.31 | wps 1971.7 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.44
2023-07-25 15:45:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-07-25 15:45:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.3105.pt
2023-07-25 15:45:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.3105.pt
2023-07-25 15:45:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.3105.pt (epoch 12 @ 17679 updates, score 19.31) (writing took 11.99762113392353 seconds)
2023-07-25 15:45:47 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-25 15:45:47 | INFO | train | epoch 012 | loss 2.11 | trans_loss 5.15 | nll_loss 2.384 | w2v_ctc_loss 0.745 | task_loss 1.399 | contrastive_loss 0.138 | total 4138.65 | n_correct 2527.23 | ppl 5.22 | accuracy 61.064 | wps 11600.3 | ups 1.4 | wpb 8277.3 | bsz 305.7 | num_updates 17679 | lr 0.000106362 | gnorm 0.563 | clip 0 | loss_scale 16 | train_wall 998 | gb_free 12.7 | wall 15939
2023-07-25 15:45:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 15:45:47 | INFO | fairseq.trainer | begin training epoch 13
2023-07-25 15:45:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 15:46:09 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.115, trans_loss=5.165, nll_loss=2.403, w2v_ctc_loss=0.754, task_loss=1.457, contrastive_loss=0.088, total=4096.49, n_correct=2494.48, ppl=5.29, accuracy=60.893, wps=7173.5, ups=0.88, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.568, clip=0, loss_scale=16, train_wall=68, gb_free=14.5, wall=15961
2023-07-25 15:47:18 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.089, trans_loss=5.113, nll_loss=2.334, w2v_ctc_loss=0.733, task_loss=1.403, contrastive_loss=0.098, total=4160.97, n_correct=2568.76, ppl=5.04, accuracy=61.735, wps=12146.8, ups=1.46, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.558, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=16030
2023-07-25 15:48:26 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.101, trans_loss=5.122, nll_loss=2.348, w2v_ctc_loss=0.726, task_loss=1.292, contrastive_loss=0.318, total=4212.08, n_correct=2593.74, ppl=5.09, accuracy=61.579, wps=12231.1, ups=1.45, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.554, clip=0, loss_scale=16, train_wall=68, gb_free=14.6, wall=16099
2023-07-25 15:49:35 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.085, trans_loss=5.113, nll_loss=2.334, w2v_ctc_loss=0.726, task_loss=1.452, contrastive_loss=0.082, total=4102.3, n_correct=2538.25, ppl=5.04, accuracy=61.874, wps=11981.5, ups=1.46, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.566, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=16167
2023-07-25 15:49:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 15:49:58 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.252 | trans_loss 5.626 | nll_loss 2.917 | w2v_ctc_loss 1.371 | task_loss 4.595 | contrastive_loss 0.272 | total 4003.4 | n_correct 2445.2 | ppl 7.55 | accuracy 61.078 | uer 18.146 | wer 19.958 | raw_wer 19.958 | bleu 19.32 | wps 2169.2 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.44
2023-07-25 15:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-25 15:49:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_13_18000.pt
2023-07-25 15:50:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_13_18000.pt
2023-07-25 15:50:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.32) (writing took 28.88504741154611 seconds)
2023-07-25 15:51:36 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.092, trans_loss=5.122, nll_loss=2.347, w2v_ctc_loss=0.735, task_loss=1.308, contrastive_loss=0.134, total=4177.29, n_correct=2577.78, ppl=5.09, accuracy=61.709, wps=6909, ups=0.83, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.549, clip=0, loss_scale=16, train_wall=67, gb_free=17.5, wall=16288
2023-07-25 15:52:45 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.098, trans_loss=5.129, nll_loss=2.356, w2v_ctc_loss=0.735, task_loss=1.354, contrastive_loss=0.172, total=4201.22, n_correct=2582.19, ppl=5.12, accuracy=61.463, wps=12130.9, ups=1.44, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.554, clip=0, loss_scale=32, train_wall=69, gb_free=12.8, wall=16358
2023-07-25 15:53:53 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.087, trans_loss=5.124, nll_loss=2.351, w2v_ctc_loss=0.729, task_loss=1.357, contrastive_loss=0.08, total=4161.98, n_correct=2569.26, ppl=5.1, accuracy=61.732, wps=12222.3, ups=1.47, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=16426
2023-07-25 15:55:01 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.107, trans_loss=5.138, nll_loss=2.367, w2v_ctc_loss=0.757, task_loss=1.556, contrastive_loss=0.077, total=4096.76, n_correct=2509.74, ppl=5.16, accuracy=61.262, wps=12040.3, ups=1.47, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.575, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=16494
2023-07-25 15:56:10 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.102, trans_loss=5.137, nll_loss=2.368, w2v_ctc_loss=0.739, task_loss=1.412, contrastive_loss=0.133, total=4121.73, n_correct=2527.06, ppl=5.16, accuracy=61.311, wps=11993.5, ups=1.45, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.578, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=16562
2023-07-25 15:57:18 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.1, trans_loss=5.139, nll_loss=2.37, w2v_ctc_loss=0.74, task_loss=1.429, contrastive_loss=0.091, total=4107.01, n_correct=2518.88, ppl=5.17, accuracy=61.331, wps=12072.4, ups=1.47, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.571, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=16631
2023-07-25 15:58:26 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.105, trans_loss=5.14, nll_loss=2.371, w2v_ctc_loss=0.742, task_loss=1.478, contrastive_loss=0.141, total=4081.02, n_correct=2499.65, ppl=5.17, accuracy=61.251, wps=11959.1, ups=1.47, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.564, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=16699
2023-07-25 15:59:34 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.095, trans_loss=5.132, nll_loss=2.361, w2v_ctc_loss=0.735, task_loss=1.376, contrastive_loss=0.122, total=4105.62, n_correct=2526.34, ppl=5.14, accuracy=61.534, wps=12165.5, ups=1.48, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.565, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=16766
2023-07-25 16:00:42 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.104, trans_loss=5.147, nll_loss=2.381, w2v_ctc_loss=0.745, task_loss=1.484, contrastive_loss=0.081, total=4110.35, n_correct=2516.65, ppl=5.21, accuracy=61.227, wps=12018.9, ups=1.46, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.565, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=16835
2023-07-25 16:01:51 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.096, trans_loss=5.129, nll_loss=2.359, w2v_ctc_loss=0.734, task_loss=1.375, contrastive_loss=0.178, total=4112.2, n_correct=2534.79, ppl=5.13, accuracy=61.641, wps=12031.7, ups=1.46, wpb=8224.4, bsz=308.2, num_updates=19000, lr=0.000102598, gnorm=0.557, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=16903
2023-07-25 16:02:59 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.103, trans_loss=5.144, nll_loss=2.379, w2v_ctc_loss=0.73, task_loss=1.369, contrastive_loss=0.192, total=4180.88, n_correct=2564.13, ppl=5.2, accuracy=61.33, wps=12259.4, ups=1.47, wpb=8361.8, bsz=312.2, num_updates=19100, lr=0.000102329, gnorm=0.552, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=16971
2023-07-25 16:03:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 16:03:59 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.234 | trans_loss 5.614 | nll_loss 2.904 | w2v_ctc_loss 1.343 | task_loss 4.607 | contrastive_loss 0.261 | total 4003.4 | n_correct 2442.3 | ppl 7.48 | accuracy 61.006 | uer 17.931 | wer 19.694 | raw_wer 19.694 | bleu 19.28 | wps 2071.1 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.44
2023-07-25 16:03:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-25 16:03:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.2808.pt
2023-07-25 16:04:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.2808.pt
2023-07-25 16:04:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.2808.pt (epoch 13 @ 19153 updates, score 19.28) (writing took 12.187332911416888 seconds)
2023-07-25 16:04:12 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-25 16:04:12 | INFO | train | epoch 013 | loss 2.097 | trans_loss 5.13 | nll_loss 2.359 | w2v_ctc_loss 0.736 | task_loss 1.397 | contrastive_loss 0.136 | total 4138.65 | n_correct 2545.74 | ppl 5.13 | accuracy 61.511 | wps 11041.7 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 19153 | lr 0.000102187 | gnorm 0.563 | clip 0 | loss_scale 32 | train_wall 998 | gb_free 17.6 | wall 17044
2023-07-25 16:04:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 16:04:12 | INFO | fairseq.trainer | begin training epoch 14
2023-07-25 16:04:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 16:04:53 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.073, trans_loss=5.099, nll_loss=2.32, w2v_ctc_loss=0.724, task_loss=1.277, contrastive_loss=0.097, total=4176.2, n_correct=2602.29, ppl=4.99, accuracy=62.312, wps=7344.6, ups=0.88, wpb=8352.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.561, clip=0, loss_scale=32, train_wall=68, gb_free=10.5, wall=17085
2023-07-25 16:06:00 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.072, trans_loss=5.088, nll_loss=2.303, w2v_ctc_loss=0.726, task_loss=1.41, contrastive_loss=0.077, total=4080.86, n_correct=2550.09, ppl=4.94, accuracy=62.489, wps=12016.8, ups=1.47, wpb=8161.7, bsz=299.6, num_updates=19300, lr=0.000101797, gnorm=0.563, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=17153
2023-07-25 16:07:09 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.089, trans_loss=5.107, nll_loss=2.327, w2v_ctc_loss=0.727, task_loss=1.471, contrastive_loss=0.18, total=4106.97, n_correct=2546, ppl=5.02, accuracy=61.992, wps=12042.3, ups=1.47, wpb=8213.9, bsz=293.3, num_updates=19400, lr=0.000101535, gnorm=0.561, clip=0, loss_scale=32, train_wall=68, gb_free=12.2, wall=17221
2023-07-25 16:08:16 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.073, trans_loss=5.097, nll_loss=2.315, w2v_ctc_loss=0.722, task_loss=1.286, contrastive_loss=0.117, total=4179.8, n_correct=2606.11, ppl=4.98, accuracy=62.35, wps=12328.7, ups=1.47, wpb=8359.6, bsz=322.5, num_updates=19500, lr=0.000101274, gnorm=0.563, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=17289
2023-07-25 16:09:25 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.08, trans_loss=5.113, nll_loss=2.336, w2v_ctc_loss=0.722, task_loss=1.442, contrastive_loss=0.073, total=4120.38, n_correct=2550.86, ppl=5.05, accuracy=61.908, wps=12030.7, ups=1.46, wpb=8240.8, bsz=296.3, num_updates=19600, lr=0.000101015, gnorm=0.562, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=17357
2023-07-25 16:10:34 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.094, trans_loss=5.116, nll_loss=2.338, w2v_ctc_loss=0.746, task_loss=1.48, contrastive_loss=0.111, total=4089.86, n_correct=2524.47, ppl=5.06, accuracy=61.725, wps=11929.2, ups=1.46, wpb=8179.7, bsz=295.5, num_updates=19700, lr=0.000100759, gnorm=0.585, clip=0, loss_scale=32, train_wall=68, gb_free=11.9, wall=17426
2023-07-25 16:11:41 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.087, trans_loss=5.113, nll_loss=2.335, w2v_ctc_loss=0.727, task_loss=1.4, contrastive_loss=0.152, total=4158.94, n_correct=2574.41, ppl=5.05, accuracy=61.901, wps=12244.2, ups=1.47, wpb=8317.9, bsz=306.7, num_updates=19800, lr=0.000100504, gnorm=0.557, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=17494
2023-07-25 16:12:50 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.073, trans_loss=5.102, nll_loss=2.323, w2v_ctc_loss=0.719, task_loss=1.358, contrastive_loss=0.084, total=4150.03, n_correct=2582.72, ppl=5, accuracy=62.234, wps=12135.2, ups=1.46, wpb=8300.1, bsz=310.4, num_updates=19900, lr=0.000100251, gnorm=0.551, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=17562
2023-07-25 16:13:58 | INFO | train_inner | epoch 014:    847 / 1474 loss=2.086, trans_loss=5.108, nll_loss=2.332, w2v_ctc_loss=0.723, task_loss=1.341, contrastive_loss=0.196, total=4162.8, n_correct=2582.5, ppl=5.03, accuracy=62.038, wps=12187.2, ups=1.46, wpb=8325.6, bsz=317.2, num_updates=20000, lr=0.0001, gnorm=0.555, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=17631
2023-07-25 16:13:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 16:14:21 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.231 | trans_loss 5.61 | nll_loss 2.9 | w2v_ctc_loss 1.342 | task_loss 4.616 | contrastive_loss 0.264 | total 4003.4 | n_correct 2451.2 | ppl 7.46 | accuracy 61.228 | uer 17.949 | wer 19.708 | raw_wer 19.708 | bleu 19.3 | wps 2255.9 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.44
2023-07-25 16:14:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-25 16:14:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_14_20000.pt
2023-07-25 16:14:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_14_20000.pt
2023-07-25 16:14:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.3) (writing took 26.624377138912678 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:0')
2023-07-25 16:15:57 | INFO | train_inner | epoch 014:    947 / 1474 loss=2.082, trans_loss=5.115, nll_loss=2.339, w2v_ctc_loss=0.727, task_loss=1.423, contrastive_loss=0.086, total=4159.46, n_correct=2572.05, ppl=5.06, accuracy=61.836, wps=7005.4, ups=0.84, wpb=8318.9, bsz=306.7, num_updates=20100, lr=9.97509e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=17749
2023-07-25 16:17:06 | INFO | train_inner | epoch 014:   1047 / 1474 loss=2.087, trans_loss=5.121, nll_loss=2.348, w2v_ctc_loss=0.719, task_loss=1.391, contrastive_loss=0.15, total=4155.93, n_correct=2566.07, ppl=5.09, accuracy=61.745, wps=12053.8, ups=1.45, wpb=8311.9, bsz=305.9, num_updates=20200, lr=9.95037e-05, gnorm=0.561, clip=0, loss_scale=64, train_wall=68, gb_free=16.3, wall=17818
2023-07-25 16:17:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 16:18:16 | INFO | train_inner | epoch 014:   1148 / 1474 loss=2.106, trans_loss=5.121, nll_loss=2.349, w2v_ctc_loss=0.734, task_loss=1.314, contrastive_loss=0.382, total=4228.22, n_correct=2608.11, ppl=5.09, accuracy=61.683, wps=12104.2, ups=1.43, wpb=8456.4, bsz=327.1, num_updates=20300, lr=9.92583e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=17888
2023-07-25 16:19:24 | INFO | train_inner | epoch 014:   1248 / 1474 loss=2.101, trans_loss=5.138, nll_loss=2.369, w2v_ctc_loss=0.747, task_loss=1.646, contrastive_loss=0.064, total=4021.19, n_correct=2470.72, ppl=5.16, accuracy=61.443, wps=11826.8, ups=1.47, wpb=8042.4, bsz=271.7, num_updates=20400, lr=9.90148e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=17956
2023-07-25 16:20:32 | INFO | train_inner | epoch 014:   1348 / 1474 loss=2.081, trans_loss=5.123, nll_loss=2.351, w2v_ctc_loss=0.721, task_loss=1.318, contrastive_loss=0.085, total=4213.9, n_correct=2607.37, ppl=5.1, accuracy=61.875, wps=12360.6, ups=1.47, wpb=8427.8, bsz=319.4, num_updates=20500, lr=9.8773e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=18024
2023-07-25 16:21:40 | INFO | train_inner | epoch 014:   1448 / 1474 loss=2.09, trans_loss=5.131, nll_loss=2.361, w2v_ctc_loss=0.727, task_loss=1.399, contrastive_loss=0.124, total=4130.28, n_correct=2551.1, ppl=5.14, accuracy=61.766, wps=12125.1, ups=1.47, wpb=8260.6, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=18093
2023-07-25 16:21:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:7')
2023-07-25 16:22:20 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.238 | trans_loss 5.61 | nll_loss 2.902 | w2v_ctc_loss 1.362 | task_loss 4.599 | contrastive_loss 0.27 | total 4003.4 | n_correct 2456.7 | ppl 7.47 | accuracy 61.365 | uer 18.114 | wer 19.869 | raw_wer 19.869 | bleu 19.67 | wps 2302.5 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.67
2023-07-25 16:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-07-25 16:22:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 16:22:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 16:22:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 14 @ 20626 updates, score 19.67) (writing took 20.839888839051127 seconds)
2023-07-25 16:22:42 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-25 16:22:42 | INFO | train | epoch 014 | loss 2.085 | trans_loss 5.113 | nll_loss 2.337 | w2v_ctc_loss 0.728 | task_loss 1.4 | contrastive_loss 0.134 | total 4138.53 | n_correct 2563.21 | ppl 5.05 | accuracy 61.935 | wps 10980.9 | ups 1.33 | wpb 8277.1 | bsz 305.7 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.562 | clip 0 | loss_scale 32 | train_wall 1000 | gb_free 16.4 | wall 18154
2023-07-25 16:22:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 16:22:42 | INFO | fairseq.trainer | begin training epoch 15
2023-07-25 16:22:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 16:23:39 | INFO | train_inner | epoch 015:     74 / 1474 loss=2.079, trans_loss=5.099, nll_loss=2.318, w2v_ctc_loss=0.718, task_loss=1.406, contrastive_loss=0.172, total=4083.88, n_correct=2539.72, ppl=4.99, accuracy=62.189, wps=6846.8, ups=0.84, wpb=8167.8, bsz=300.2, num_updates=20700, lr=9.82946e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=18212
2023-07-25 16:24:48 | INFO | train_inner | epoch 015:    174 / 1474 loss=2.072, trans_loss=5.089, nll_loss=2.305, w2v_ctc_loss=0.725, task_loss=1.457, contrastive_loss=0.082, total=4115.73, n_correct=2567.32, ppl=4.94, accuracy=62.378, wps=11994.6, ups=1.46, wpb=8231.5, bsz=297.8, num_updates=20800, lr=9.80581e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=18280
2023-07-25 16:25:56 | INFO | train_inner | epoch 015:    274 / 1474 loss=2.062, trans_loss=5.087, nll_loss=2.303, w2v_ctc_loss=0.71, task_loss=1.345, contrastive_loss=0.073, total=4193.15, n_correct=2624.99, ppl=4.93, accuracy=62.602, wps=12317.9, ups=1.47, wpb=8386.3, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=18349
2023-07-25 16:27:05 | INFO | train_inner | epoch 015:    374 / 1474 loss=2.068, trans_loss=5.083, nll_loss=2.297, w2v_ctc_loss=0.715, task_loss=1.41, contrastive_loss=0.1, total=4167.66, n_correct=2601.79, ppl=4.91, accuracy=62.428, wps=12163.5, ups=1.46, wpb=8335.3, bsz=306, num_updates=21000, lr=9.759e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=18417
2023-07-25 16:28:13 | INFO | train_inner | epoch 015:    474 / 1474 loss=2.075, trans_loss=5.092, nll_loss=2.31, w2v_ctc_loss=0.706, task_loss=1.461, contrastive_loss=0.188, total=4074.53, n_correct=2536.34, ppl=4.96, accuracy=62.249, wps=12008.3, ups=1.47, wpb=8149.1, bsz=294.2, num_updates=21100, lr=9.73585e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=67, gb_free=15.7, wall=18485
2023-07-25 16:29:21 | INFO | train_inner | epoch 015:    574 / 1474 loss=2.069, trans_loss=5.09, nll_loss=2.307, w2v_ctc_loss=0.719, task_loss=1.448, contrastive_loss=0.081, total=4140.59, n_correct=2582.71, ppl=4.95, accuracy=62.375, wps=12095.3, ups=1.46, wpb=8281.2, bsz=298.8, num_updates=21200, lr=9.71286e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=68, gb_free=12, wall=18553
2023-07-25 16:30:30 | INFO | train_inner | epoch 015:    674 / 1474 loss=2.078, trans_loss=5.093, nll_loss=2.31, w2v_ctc_loss=0.723, task_loss=1.414, contrastive_loss=0.169, total=4134.99, n_correct=2580.15, ppl=4.96, accuracy=62.398, wps=12035.4, ups=1.46, wpb=8270, bsz=307.1, num_updates=21300, lr=9.69003e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=68, gb_free=10.5, wall=18622
2023-07-25 16:31:38 | INFO | train_inner | epoch 015:    774 / 1474 loss=2.075, trans_loss=5.103, nll_loss=2.324, w2v_ctc_loss=0.723, task_loss=1.415, contrastive_loss=0.084, total=4173.66, n_correct=2594.59, ppl=5.01, accuracy=62.166, wps=12193.2, ups=1.46, wpb=8347.3, bsz=305, num_updates=21400, lr=9.66736e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=18691
2023-07-25 16:32:46 | INFO | train_inner | epoch 015:    874 / 1474 loss=2.081, trans_loss=5.108, nll_loss=2.331, w2v_ctc_loss=0.731, task_loss=1.512, contrastive_loss=0.079, total=4059.35, n_correct=2516.59, ppl=5.03, accuracy=61.995, wps=12007.9, ups=1.48, wpb=8118.7, bsz=288.3, num_updates=21500, lr=9.64486e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=18758
2023-07-25 16:33:54 | INFO | train_inner | epoch 015:    974 / 1474 loss=2.076, trans_loss=5.102, nll_loss=2.323, w2v_ctc_loss=0.716, task_loss=1.41, contrastive_loss=0.163, total=4122.87, n_correct=2566.49, ppl=5, accuracy=62.25, wps=12049.2, ups=1.46, wpb=8245.7, bsz=301.7, num_updates=21600, lr=9.6225e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=18827
2023-07-25 16:35:03 | INFO | train_inner | epoch 015:   1074 / 1474 loss=2.091, trans_loss=5.109, nll_loss=2.334, w2v_ctc_loss=0.721, task_loss=1.316, contrastive_loss=0.324, total=4192.24, n_correct=2601.27, ppl=5.04, accuracy=62.05, wps=12111, ups=1.44, wpb=8384.5, bsz=325.2, num_updates=21700, lr=9.60031e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=18896
2023-07-25 16:36:11 | INFO | train_inner | epoch 015:   1174 / 1474 loss=2.06, trans_loss=5.095, nll_loss=2.317, w2v_ctc_loss=0.701, task_loss=1.26, contrastive_loss=0.126, total=4185, n_correct=2619.86, ppl=4.98, accuracy=62.601, wps=12317.3, ups=1.47, wpb=8370, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=18964
2023-07-25 16:37:20 | INFO | train_inner | epoch 015:   1274 / 1474 loss=2.078, trans_loss=5.106, nll_loss=2.329, w2v_ctc_loss=0.728, task_loss=1.426, contrastive_loss=0.083, total=4152.04, n_correct=2579.16, ppl=5.03, accuracy=62.118, wps=12127.5, ups=1.46, wpb=8304.1, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=19032
2023-07-25 16:38:28 | INFO | train_inner | epoch 015:   1374 / 1474 loss=2.071, trans_loss=5.105, nll_loss=2.327, w2v_ctc_loss=0.715, task_loss=1.446, contrastive_loss=0.067, total=4100.21, n_correct=2553.1, ppl=5.02, accuracy=62.268, wps=11977.4, ups=1.46, wpb=8200.4, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=19101
2023-07-25 16:38:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 16:38:52 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.604 | nll_loss 2.888 | w2v_ctc_loss 1.285 | task_loss 4.581 | contrastive_loss 0.27 | total 4003.4 | n_correct 2459.1 | ppl 7.4 | accuracy 61.425 | uer 17.594 | wer 19.425 | raw_wer 19.425 | bleu 19.37 | wps 2068.2 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.67
2023-07-25 16:38:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-25 16:38:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_15_22000.pt
2023-07-25 16:38:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_15_22000.pt
2023-07-25 16:39:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.37) (writing took 15.443318601697683 seconds)
2023-07-25 16:39:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-25 16:40:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 16:40:42 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.224 | trans_loss 5.598 | nll_loss 2.887 | w2v_ctc_loss 1.347 | task_loss 4.605 | contrastive_loss 0.268 | total 4003.4 | n_correct 2459.3 | ppl 7.4 | accuracy 61.43 | uer 17.747 | wer 19.459 | raw_wer 19.459 | bleu 19.84 | wps 2003.5 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 19.84
2023-07-25 16:40:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-07-25 16:40:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 16:40:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 16:41:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 15 @ 22099 updates, score 19.84) (writing took 21.17072920501232 seconds)
2023-07-25 16:41:04 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-25 16:41:04 | INFO | train | epoch 015 | loss 2.074 | trans_loss 5.097 | nll_loss 2.317 | w2v_ctc_loss 0.717 | task_loss 1.401 | contrastive_loss 0.132 | total 4138.38 | n_correct 2578.27 | ppl 4.98 | accuracy 62.301 | wps 11065.7 | ups 1.34 | wpb 8276.8 | bsz 305.6 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.565 | clip 0 | loss_scale 16 | train_wall 1000 | gb_free 16.9 | wall 19256
2023-07-25 16:41:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 16:41:04 | INFO | fairseq.trainer | begin training epoch 16
2023-07-25 16:41:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 16:41:13 | INFO | train_inner | epoch 016:      1 / 1474 loss=2.082, trans_loss=5.112, nll_loss=2.339, w2v_ctc_loss=0.722, task_loss=1.349, contrastive_loss=0.161, total=4139.59, n_correct=2570.91, ppl=5.06, accuracy=62.105, wps=5037.1, ups=0.61, wpb=8279.2, bsz=314.1, num_updates=22100, lr=9.51303e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=19265
2023-07-25 16:42:21 | INFO | train_inner | epoch 016:    101 / 1474 loss=2.053, trans_loss=5.066, nll_loss=2.276, w2v_ctc_loss=0.706, task_loss=1.343, contrastive_loss=0.103, total=4118.73, n_correct=2589.36, ppl=4.84, accuracy=62.868, wps=12080.7, ups=1.47, wpb=8237.5, bsz=314, num_updates=22200, lr=9.49158e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=19333
2023-07-25 16:43:29 | INFO | train_inner | epoch 016:    201 / 1474 loss=2.051, trans_loss=5.065, nll_loss=2.275, w2v_ctc_loss=0.699, task_loss=1.437, contrastive_loss=0.074, total=4106.45, n_correct=2587.22, ppl=4.84, accuracy=63.004, wps=12022, ups=1.46, wpb=8212.9, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=19402
2023-07-25 16:44:37 | INFO | train_inner | epoch 016:    301 / 1474 loss=2.065, trans_loss=5.075, nll_loss=2.288, w2v_ctc_loss=0.712, task_loss=1.382, contrastive_loss=0.15, total=4169.65, n_correct=2614.02, ppl=4.88, accuracy=62.692, wps=12345.3, ups=1.48, wpb=8339.3, bsz=309.9, num_updates=22400, lr=9.44911e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=67, gb_free=10.6, wall=19469
2023-07-25 16:45:45 | INFO | train_inner | epoch 016:    401 / 1474 loss=2.07, trans_loss=5.078, nll_loss=2.29, w2v_ctc_loss=0.716, task_loss=1.503, contrastive_loss=0.163, total=4063.79, n_correct=2544.68, ppl=4.89, accuracy=62.618, wps=11877.1, ups=1.46, wpb=8127.6, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=68, gb_free=12.6, wall=19538
2023-07-25 16:46:54 | INFO | train_inner | epoch 016:    501 / 1474 loss=2.058, trans_loss=5.074, nll_loss=2.289, w2v_ctc_loss=0.709, task_loss=1.343, contrastive_loss=0.109, total=4179.53, n_correct=2629.75, ppl=4.89, accuracy=62.92, wps=12224.8, ups=1.46, wpb=8359.1, bsz=319.5, num_updates=22600, lr=9.40721e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=68, gb_free=17.7, wall=19606
2023-07-25 16:48:01 | INFO | train_inner | epoch 016:    601 / 1474 loss=2.059, trans_loss=5.08, nll_loss=2.295, w2v_ctc_loss=0.707, task_loss=1.408, contrastive_loss=0.069, total=4121.37, n_correct=2582.69, ppl=4.91, accuracy=62.666, wps=12221.2, ups=1.48, wpb=8242.7, bsz=297.5, num_updates=22700, lr=9.38647e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=67, gb_free=17.8, wall=19674
2023-07-25 16:49:09 | INFO | train_inner | epoch 016:    701 / 1474 loss=2.062, trans_loss=5.084, nll_loss=2.299, w2v_ctc_loss=0.713, task_loss=1.428, contrastive_loss=0.071, total=4099.17, n_correct=2567.49, ppl=4.92, accuracy=62.634, wps=12155.8, ups=1.48, wpb=8198.3, bsz=297.5, num_updates=22800, lr=9.36586e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=67, gb_free=16.7, wall=19741
2023-07-25 16:50:17 | INFO | train_inner | epoch 016:    801 / 1474 loss=2.062, trans_loss=5.084, nll_loss=2.301, w2v_ctc_loss=0.702, task_loss=1.334, contrastive_loss=0.136, total=4184.53, n_correct=2621.52, ppl=4.93, accuracy=62.648, wps=12192.5, ups=1.46, wpb=8369.1, bsz=313, num_updates=22900, lr=9.34539e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=68, gb_free=13.3, wall=19810
2023-07-25 16:51:26 | INFO | train_inner | epoch 016:    901 / 1474 loss=2.061, trans_loss=5.081, nll_loss=2.297, w2v_ctc_loss=0.707, task_loss=1.372, contrastive_loss=0.126, total=4151.84, n_correct=2610.13, ppl=4.91, accuracy=62.867, wps=12140.1, ups=1.46, wpb=8303.7, bsz=307, num_updates=23000, lr=9.32505e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=19878
2023-07-25 16:52:34 | INFO | train_inner | epoch 016:   1001 / 1474 loss=2.075, trans_loss=5.096, nll_loss=2.315, w2v_ctc_loss=0.721, task_loss=1.448, contrastive_loss=0.126, total=4112.79, n_correct=2561.88, ppl=4.98, accuracy=62.291, wps=11968.2, ups=1.46, wpb=8225.6, bsz=299.5, num_updates=23100, lr=9.30484e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=19947
2023-07-25 16:53:44 | INFO | train_inner | epoch 016:   1101 / 1474 loss=2.076, trans_loss=5.102, nll_loss=2.324, w2v_ctc_loss=0.724, task_loss=1.485, contrastive_loss=0.101, total=4111.6, n_correct=2557.34, ppl=5.01, accuracy=62.198, wps=11858.7, ups=1.44, wpb=8223.2, bsz=295.6, num_updates=23200, lr=9.28477e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=20016
2023-07-25 16:54:53 | INFO | train_inner | epoch 016:   1201 / 1474 loss=2.07, trans_loss=5.093, nll_loss=2.314, w2v_ctc_loss=0.702, task_loss=1.429, contrastive_loss=0.196, total=4157.51, n_correct=2596.48, ppl=4.97, accuracy=62.453, wps=12069.2, ups=1.45, wpb=8315, bsz=306.6, num_updates=23300, lr=9.26482e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=20085
2023-07-25 16:56:01 | INFO | train_inner | epoch 016:   1301 / 1474 loss=2.071, trans_loss=5.092, nll_loss=2.312, w2v_ctc_loss=0.718, task_loss=1.357, contrastive_loss=0.173, total=4151.03, n_correct=2596.56, ppl=4.96, accuracy=62.552, wps=12158.9, ups=1.46, wpb=8302.1, bsz=314.5, num_updates=23400, lr=9.245e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=20153
2023-07-25 16:57:09 | INFO | train_inner | epoch 016:   1401 / 1474 loss=2.067, trans_loss=5.097, nll_loss=2.318, w2v_ctc_loss=0.717, task_loss=1.337, contrastive_loss=0.107, total=4201.47, n_correct=2625.16, ppl=4.99, accuracy=62.482, wps=12245.7, ups=1.46, wpb=8402.9, bsz=320.7, num_updates=23500, lr=9.22531e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=20222
2023-07-25 16:57:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 16:58:23 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.597 | nll_loss 2.882 | w2v_ctc_loss 1.328 | task_loss 4.585 | contrastive_loss 0.257 | total 4003.4 | n_correct 2463.2 | ppl 7.37 | accuracy 61.528 | uer 17.575 | wer 19.406 | raw_wer 19.406 | bleu 19.49 | wps 2141 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 19.84
2023-07-25 16:58:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-07-25 16:58:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.4902.pt
2023-07-25 16:58:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.4902.pt
2023-07-25 16:58:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.4902.pt (epoch 16 @ 23573 updates, score 19.49) (writing took 11.750061586499214 seconds)
2023-07-25 16:58:35 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-25 16:58:35 | INFO | train | epoch 016 | loss 2.065 | trans_loss 5.084 | nll_loss 2.3 | w2v_ctc_loss 0.711 | task_loss 1.399 | contrastive_loss 0.131 | total 4138.65 | n_correct 2591.82 | ppl 4.93 | accuracy 62.625 | wps 11601.8 | ups 1.4 | wpb 8277.3 | bsz 305.7 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.572 | clip 0 | loss_scale 16 | train_wall 1000 | gb_free 15.4 | wall 20308
2023-07-25 16:58:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 16:58:36 | INFO | fairseq.trainer | begin training epoch 17
2023-07-25 16:58:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 16:59:02 | INFO | train_inner | epoch 017:     27 / 1474 loss=2.068, trans_loss=5.079, nll_loss=2.294, w2v_ctc_loss=0.704, task_loss=1.429, contrastive_loss=0.241, total=4145.04, n_correct=2596.8, ppl=4.9, accuracy=62.648, wps=7350.8, ups=0.89, wpb=8290.1, bsz=302.4, num_updates=23600, lr=9.20575e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=20335
2023-07-25 17:00:10 | INFO | train_inner | epoch 017:    127 / 1474 loss=2.051, trans_loss=5.055, nll_loss=2.262, w2v_ctc_loss=0.709, task_loss=1.437, contrastive_loss=0.075, total=4117.27, n_correct=2603.13, ppl=4.8, accuracy=63.225, wps=12121.3, ups=1.47, wpb=8234.5, bsz=296.2, num_updates=23700, lr=9.1863e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=67, gb_free=17.8, wall=20403
2023-07-25 17:01:18 | INFO | train_inner | epoch 017:    227 / 1474 loss=2.054, trans_loss=5.054, nll_loss=2.262, w2v_ctc_loss=0.691, task_loss=1.327, contrastive_loss=0.246, total=4159.6, n_correct=2625.37, ppl=4.8, accuracy=63.116, wps=12237.8, ups=1.47, wpb=8319.2, bsz=317.6, num_updates=23800, lr=9.16698e-05, gnorm=0.584, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=20471
2023-07-25 17:02:26 | INFO | train_inner | epoch 017:    327 / 1474 loss=2.059, trans_loss=5.063, nll_loss=2.272, w2v_ctc_loss=0.698, task_loss=1.393, contrastive_loss=0.244, total=4156.91, n_correct=2618.09, ppl=4.83, accuracy=62.982, wps=12208.8, ups=1.47, wpb=8313.8, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=20539
2023-07-25 17:03:35 | INFO | train_inner | epoch 017:    427 / 1474 loss=2.046, trans_loss=5.062, nll_loss=2.271, w2v_ctc_loss=0.698, task_loss=1.389, contrastive_loss=0.074, total=4146.43, n_correct=2618.74, ppl=4.83, accuracy=63.156, wps=12126.4, ups=1.46, wpb=8292.9, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=20607
2023-07-25 17:03:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 17:03:59 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.598 | nll_loss 2.883 | w2v_ctc_loss 1.324 | task_loss 4.607 | contrastive_loss 0.256 | total 4003.4 | n_correct 2458.6 | ppl 7.38 | accuracy 61.413 | uer 17.355 | wer 18.996 | raw_wer 18.996 | bleu 19.35 | wps 2074.2 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.84
2023-07-25 17:03:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-25 17:03:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_17_24000.pt
2023-07-25 17:04:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_17_24000.pt
2023-07-25 17:04:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.35) (writing took 11.756348667666316 seconds)
2023-07-25 17:05:20 | INFO | train_inner | epoch 017:    527 / 1474 loss=2.055, trans_loss=5.066, nll_loss=2.278, w2v_ctc_loss=0.705, task_loss=1.455, contrastive_loss=0.121, total=4182.1, n_correct=2631.15, ppl=4.85, accuracy=62.915, wps=7942.6, ups=0.95, wpb=8364.2, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=20712
2023-07-25 17:06:28 | INFO | train_inner | epoch 017:    627 / 1474 loss=2.049, trans_loss=5.069, nll_loss=2.281, w2v_ctc_loss=0.699, task_loss=1.409, contrastive_loss=0.068, total=4167.27, n_correct=2625.23, ppl=4.86, accuracy=62.996, wps=12235, ups=1.47, wpb=8334.5, bsz=302.2, num_updates=24200, lr=9.09091e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=68, gb_free=10.6, wall=20781
2023-07-25 17:07:36 | INFO | train_inner | epoch 017:    727 / 1474 loss=2.062, trans_loss=5.075, nll_loss=2.289, w2v_ctc_loss=0.714, task_loss=1.385, contrastive_loss=0.121, total=4166.12, n_correct=2617.3, ppl=4.89, accuracy=62.823, wps=12269.8, ups=1.47, wpb=8332.2, bsz=308.1, num_updates=24300, lr=9.07218e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=20848
2023-07-25 17:08:43 | INFO | train_inner | epoch 017:    827 / 1474 loss=2.053, trans_loss=5.073, nll_loss=2.286, w2v_ctc_loss=0.704, task_loss=1.419, contrastive_loss=0.081, total=4091.64, n_correct=2574.3, ppl=4.88, accuracy=62.916, wps=12219.8, ups=1.49, wpb=8183.3, bsz=295.3, num_updates=24400, lr=9.05357e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=66, gb_free=17.3, wall=20915
2023-07-25 17:09:50 | INFO | train_inner | epoch 017:    927 / 1474 loss=2.049, trans_loss=5.072, nll_loss=2.286, w2v_ctc_loss=0.696, task_loss=1.382, contrastive_loss=0.08, total=4106.83, n_correct=2585.48, ppl=4.88, accuracy=62.956, wps=12206.8, ups=1.49, wpb=8213.7, bsz=304.6, num_updates=24500, lr=9.03508e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=20983
2023-07-25 17:10:58 | INFO | train_inner | epoch 017:   1027 / 1474 loss=2.053, trans_loss=5.072, nll_loss=2.286, w2v_ctc_loss=0.706, task_loss=1.385, contrastive_loss=0.086, total=4115.49, n_correct=2593.93, ppl=4.88, accuracy=63.028, wps=12088.4, ups=1.47, wpb=8231, bsz=305.8, num_updates=24600, lr=9.0167e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=21051
2023-07-25 17:12:06 | INFO | train_inner | epoch 017:   1127 / 1474 loss=2.051, trans_loss=5.073, nll_loss=2.287, w2v_ctc_loss=0.698, task_loss=1.458, contrastive_loss=0.069, total=4078.39, n_correct=2568.18, ppl=4.88, accuracy=62.97, wps=12094.5, ups=1.48, wpb=8156.8, bsz=293.7, num_updates=24700, lr=8.99843e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=21118
2023-07-25 17:13:15 | INFO | train_inner | epoch 017:   1227 / 1474 loss=2.072, trans_loss=5.084, nll_loss=2.302, w2v_ctc_loss=0.698, task_loss=1.359, contrastive_loss=0.322, total=4173.49, n_correct=2607.93, ppl=4.93, accuracy=62.488, wps=12086.1, ups=1.45, wpb=8347, bsz=323.7, num_updates=24800, lr=8.98027e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=21187
2023-07-25 17:14:23 | INFO | train_inner | epoch 017:   1327 / 1474 loss=2.057, trans_loss=5.08, nll_loss=2.297, w2v_ctc_loss=0.693, task_loss=1.387, contrastive_loss=0.156, total=4156.28, n_correct=2611.26, ppl=4.92, accuracy=62.827, wps=12196.7, ups=1.47, wpb=8312.6, bsz=308, num_updates=24900, lr=8.96221e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=21255
2023-07-25 17:15:32 | INFO | train_inner | epoch 017:   1427 / 1474 loss=2.052, trans_loss=5.079, nll_loss=2.295, w2v_ctc_loss=0.698, task_loss=1.411, contrastive_loss=0.074, total=4112.95, n_correct=2585.17, ppl=4.91, accuracy=62.854, wps=11999.5, ups=1.46, wpb=8225.9, bsz=303.2, num_updates=25000, lr=8.94427e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=21324
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:0')
2023-07-25 17:16:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:1')
2023-07-25 17:16:29 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.207 | trans_loss 5.585 | nll_loss 2.87 | w2v_ctc_loss 1.32 | task_loss 4.616 | contrastive_loss 0.267 | total 4003.4 | n_correct 2462.3 | ppl 7.31 | accuracy 61.505 | uer 17.503 | wer 19.336 | raw_wer 19.336 | bleu 19.94 | wps 1955.5 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 19.94
2023-07-25 17:16:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-07-25 17:16:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 17:16:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 17:16:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 17 @ 25047 updates, score 19.94) (writing took 20.339507462456822 seconds)
2023-07-25 17:16:49 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-25 17:16:50 | INFO | train | epoch 017 | loss 2.055 | trans_loss 5.07 | nll_loss 2.282 | w2v_ctc_loss 0.701 | task_loss 1.4 | contrastive_loss 0.129 | total 4138.65 | n_correct 2605.15 | ppl 4.86 | accuracy 62.947 | wps 11149.9 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.572 | clip 0 | loss_scale 32 | train_wall 996 | gb_free 16.3 | wall 21402
2023-07-25 17:16:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 17:16:50 | INFO | fairseq.trainer | begin training epoch 18
2023-07-25 17:16:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 17:17:35 | INFO | train_inner | epoch 018:     53 / 1474 loss=2.052, trans_loss=5.067, nll_loss=2.28, w2v_ctc_loss=0.706, task_loss=1.426, contrastive_loss=0.084, total=4139.04, n_correct=2608.8, ppl=4.86, accuracy=63.029, wps=6718.4, ups=0.81, wpb=8278.1, bsz=303.3, num_updates=25100, lr=8.92644e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=21447
2023-07-25 17:18:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-25 17:18:44 | INFO | train_inner | epoch 018:    154 / 1474 loss=2.037, trans_loss=5.038, nll_loss=2.239, w2v_ctc_loss=0.679, task_loss=1.349, contrastive_loss=0.166, total=4147.2, n_correct=2637.55, ppl=4.72, accuracy=63.598, wps=12009.6, ups=1.45, wpb=8294.4, bsz=310.1, num_updates=25200, lr=8.90871e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=21516
2023-07-25 17:19:52 | INFO | train_inner | epoch 018:    254 / 1474 loss=2.031, trans_loss=5.04, nll_loss=2.243, w2v_ctc_loss=0.685, task_loss=1.359, contrastive_loss=0.076, total=4164.11, n_correct=2649.51, ppl=4.73, accuracy=63.627, wps=12222.6, ups=1.47, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=21584
2023-07-25 17:21:01 | INFO | train_inner | epoch 018:    354 / 1474 loss=2.041, trans_loss=5.048, nll_loss=2.253, w2v_ctc_loss=0.692, task_loss=1.419, contrastive_loss=0.09, total=4163.13, n_correct=2636.82, ppl=4.77, accuracy=63.337, wps=12150.7, ups=1.46, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=21653
2023-07-25 17:22:09 | INFO | train_inner | epoch 018:    454 / 1474 loss=2.052, trans_loss=5.055, nll_loss=2.263, w2v_ctc_loss=0.694, task_loss=1.496, contrastive_loss=0.181, total=4087.83, n_correct=2581.69, ppl=4.8, accuracy=63.156, wps=11965.7, ups=1.46, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=21721
2023-07-25 17:23:17 | INFO | train_inner | epoch 018:    554 / 1474 loss=2.032, trans_loss=5.043, nll_loss=2.248, w2v_ctc_loss=0.685, task_loss=1.258, contrastive_loss=0.091, total=4204.41, n_correct=2670.97, ppl=4.75, accuracy=63.528, wps=12352, ups=1.47, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=21789
2023-07-25 17:24:25 | INFO | train_inner | epoch 018:    654 / 1474 loss=2.053, trans_loss=5.065, nll_loss=2.275, w2v_ctc_loss=0.698, task_loss=1.447, contrastive_loss=0.16, total=4096.81, n_correct=2585.47, ppl=4.84, accuracy=63.109, wps=12059.8, ups=1.47, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=21857
2023-07-25 17:25:34 | INFO | train_inner | epoch 018:    754 / 1474 loss=2.057, trans_loss=5.062, nll_loss=2.273, w2v_ctc_loss=0.702, task_loss=1.336, contrastive_loss=0.252, total=4208.29, n_correct=2652.68, ppl=4.83, accuracy=63.035, wps=12193.1, ups=1.45, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=68, gb_free=17.8, wall=21926
2023-07-25 17:26:42 | INFO | train_inner | epoch 018:    854 / 1474 loss=2.045, trans_loss=5.063, nll_loss=2.273, w2v_ctc_loss=0.694, task_loss=1.425, contrastive_loss=0.065, total=4166.81, n_correct=2632.07, ppl=4.83, accuracy=63.168, wps=12203.7, ups=1.46, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=68, gb_free=12.5, wall=21995
2023-07-25 17:27:50 | INFO | train_inner | epoch 018:    954 / 1474 loss=2.036, trans_loss=5.054, nll_loss=2.263, w2v_ctc_loss=0.683, task_loss=1.304, contrastive_loss=0.091, total=4142.65, n_correct=2625.2, ppl=4.8, accuracy=63.37, wps=12301.5, ups=1.48, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=67, gb_free=14.8, wall=22062
2023-07-25 17:27:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 17:28:13 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.237 | trans_loss 5.596 | nll_loss 2.878 | w2v_ctc_loss 1.396 | task_loss 4.607 | contrastive_loss 0.266 | total 4003.4 | n_correct 2463.2 | ppl 7.35 | accuracy 61.528 | uer 17.846 | wer 19.578 | raw_wer 19.578 | bleu 19.5 | wps 2116.2 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 19.94
2023-07-25 17:28:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-25 17:28:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_18_26000.pt
2023-07-25 17:28:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_18_26000.pt
2023-07-25 17:28:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.5) (writing took 12.965320222079754 seconds)
2023-07-25 17:29:38 | INFO | train_inner | epoch 018:   1054 / 1474 loss=2.041, trans_loss=5.061, nll_loss=2.272, w2v_ctc_loss=0.684, task_loss=1.457, contrastive_loss=0.077, total=4137.77, n_correct=2615.4, ppl=4.83, accuracy=63.208, wps=7604.1, ups=0.92, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=22171
2023-07-25 17:30:46 | INFO | train_inner | epoch 018:   1154 / 1474 loss=2.044, trans_loss=5.05, nll_loss=2.259, w2v_ctc_loss=0.688, task_loss=1.328, contrastive_loss=0.184, total=4153.69, n_correct=2631.8, ppl=4.79, accuracy=63.361, wps=12217, ups=1.47, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=68, gb_free=15, wall=22239
2023-07-25 17:31:55 | INFO | train_inner | epoch 018:   1254 / 1474 loss=2.049, trans_loss=5.072, nll_loss=2.286, w2v_ctc_loss=0.693, task_loss=1.504, contrastive_loss=0.069, total=4087.62, n_correct=2574.79, ppl=4.88, accuracy=62.99, wps=11967.6, ups=1.46, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=22307
2023-07-25 17:33:03 | INFO | train_inner | epoch 018:   1354 / 1474 loss=2.06, trans_loss=5.079, nll_loss=2.295, w2v_ctc_loss=0.709, task_loss=1.493, contrastive_loss=0.097, total=4070.69, n_correct=2554.35, ppl=4.91, accuracy=62.75, wps=12007.2, ups=1.47, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=67, gb_free=17.3, wall=22375
2023-07-25 17:34:11 | INFO | train_inner | epoch 018:   1454 / 1474 loss=2.053, trans_loss=5.074, nll_loss=2.289, w2v_ctc_loss=0.701, task_loss=1.477, contrastive_loss=0.083, total=4113.2, n_correct=2586.06, ppl=4.89, accuracy=62.872, wps=11983.7, ups=1.46, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.592, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=22444
2023-07-25 17:34:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 17:34:47 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.24 | trans_loss 5.591 | nll_loss 2.876 | w2v_ctc_loss 1.414 | task_loss 4.605 | contrastive_loss 0.268 | total 4003.4 | n_correct 2467.3 | ppl 7.34 | accuracy 61.63 | uer 17.57 | wer 19.384 | raw_wer 19.384 | bleu 19.63 | wps 2289 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 19.94
2023-07-25 17:34:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-07-25 17:34:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.6301.pt
2023-07-25 17:34:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.6301.pt
2023-07-25 17:34:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.6301.pt (epoch 18 @ 26520 updates, score 19.63) (writing took 11.417183915153146 seconds)
2023-07-25 17:34:59 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-25 17:34:59 | INFO | train | epoch 018 | loss 2.045 | trans_loss 5.057 | nll_loss 2.266 | w2v_ctc_loss 0.692 | task_loss 1.401 | contrastive_loss 0.123 | total 4138.11 | n_correct 2616.06 | ppl 4.81 | accuracy 63.219 | wps 11189 | ups 1.35 | wpb 8276.2 | bsz 305.5 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.575 | clip 0 | loss_scale 16 | train_wall 1000 | gb_free 15.9 | wall 22492
2023-07-25 17:34:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 17:34:59 | INFO | fairseq.trainer | begin training epoch 19
2023-07-25 17:34:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 17:36:03 | INFO | train_inner | epoch 019:     80 / 1474 loss=2.037, trans_loss=5.034, nll_loss=2.235, w2v_ctc_loss=0.687, task_loss=1.404, contrastive_loss=0.132, total=4102.06, n_correct=2607.5, ppl=4.71, accuracy=63.566, wps=7345.5, ups=0.9, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=22555
2023-07-25 17:37:12 | INFO | train_inner | epoch 019:    180 / 1474 loss=2.033, trans_loss=5.026, nll_loss=2.225, w2v_ctc_loss=0.693, task_loss=1.304, contrastive_loss=0.129, total=4227.7, n_correct=2696.95, ppl=4.68, accuracy=63.792, wps=12316.3, ups=1.46, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=22624
2023-07-25 17:38:20 | INFO | train_inner | epoch 019:    280 / 1474 loss=2.027, trans_loss=5.028, nll_loss=2.228, w2v_ctc_loss=0.685, task_loss=1.382, contrastive_loss=0.066, total=4187.34, n_correct=2676.2, ppl=4.68, accuracy=63.912, wps=12217.9, ups=1.46, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=22693
2023-07-25 17:39:28 | INFO | train_inner | epoch 019:    380 / 1474 loss=2.035, trans_loss=5.034, nll_loss=2.237, w2v_ctc_loss=0.677, task_loss=1.381, contrastive_loss=0.177, total=4170.52, n_correct=2653.17, ppl=4.71, accuracy=63.617, wps=12275.4, ups=1.47, wpb=8341, bsz=311, num_updates=26900, lr=8.62261e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=22760
2023-07-25 17:40:35 | INFO | train_inner | epoch 019:    480 / 1474 loss=2.037, trans_loss=5.043, nll_loss=2.248, w2v_ctc_loss=0.691, task_loss=1.436, contrastive_loss=0.084, total=4113.89, n_correct=2613.08, ppl=4.75, accuracy=63.518, wps=12223.5, ups=1.49, wpb=8227.8, bsz=301.5, num_updates=27000, lr=8.60663e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=67, gb_free=17.1, wall=22828
2023-07-25 17:41:43 | INFO | train_inner | epoch 019:    580 / 1474 loss=2.033, trans_loss=5.038, nll_loss=2.242, w2v_ctc_loss=0.683, task_loss=1.374, contrastive_loss=0.147, total=4128.58, n_correct=2633.02, ppl=4.73, accuracy=63.775, wps=12162.2, ups=1.47, wpb=8257.2, bsz=306.2, num_updates=27100, lr=8.59074e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=22896
2023-07-25 17:42:51 | INFO | train_inner | epoch 019:    680 / 1474 loss=2.02, trans_loss=5.039, nll_loss=2.243, w2v_ctc_loss=0.665, task_loss=1.271, contrastive_loss=0.075, total=4201.56, n_correct=2678.75, ppl=4.73, accuracy=63.756, wps=12390.5, ups=1.47, wpb=8403.1, bsz=321.5, num_updates=27200, lr=8.57493e-05, gnorm=0.563, clip=0, loss_scale=16, train_wall=67, gb_free=17.8, wall=22964
2023-07-25 17:44:00 | INFO | train_inner | epoch 019:    780 / 1474 loss=2.037, trans_loss=5.043, nll_loss=2.247, w2v_ctc_loss=0.692, task_loss=1.439, contrastive_loss=0.08, total=4124.03, n_correct=2619.68, ppl=4.75, accuracy=63.522, wps=12022.2, ups=1.46, wpb=8248.1, bsz=299, num_updates=27300, lr=8.55921e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=23032
2023-07-25 17:45:08 | INFO | train_inner | epoch 019:    880 / 1474 loss=2.04, trans_loss=5.055, nll_loss=2.264, w2v_ctc_loss=0.692, task_loss=1.396, contrastive_loss=0.077, total=4177.8, n_correct=2643.43, ppl=4.8, accuracy=63.273, wps=12243.5, ups=1.47, wpb=8355.6, bsz=309.6, num_updates=27400, lr=8.54358e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=23100
2023-07-25 17:46:17 | INFO | train_inner | epoch 019:    980 / 1474 loss=2.056, trans_loss=5.063, nll_loss=2.275, w2v_ctc_loss=0.688, task_loss=1.42, contrastive_loss=0.311, total=4084.26, n_correct=2579.24, ppl=4.84, accuracy=63.151, wps=11894.1, ups=1.46, wpb=8168.5, bsz=305.8, num_updates=27500, lr=8.52803e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=23169
2023-07-25 17:47:25 | INFO | train_inner | epoch 019:   1080 / 1474 loss=2.043, trans_loss=5.061, nll_loss=2.273, w2v_ctc_loss=0.686, task_loss=1.47, contrastive_loss=0.115, total=4042.73, n_correct=2558.48, ppl=4.83, accuracy=63.286, wps=11907.2, ups=1.47, wpb=8085.5, bsz=294, num_updates=27600, lr=8.51257e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=23237
2023-07-25 17:48:33 | INFO | train_inner | epoch 019:   1180 / 1474 loss=2.056, trans_loss=5.064, nll_loss=2.276, w2v_ctc_loss=0.697, task_loss=1.428, contrastive_loss=0.201, total=4140.95, n_correct=2610.42, ppl=4.84, accuracy=63.039, wps=12024, ups=1.45, wpb=8281.9, bsz=307.9, num_updates=27700, lr=8.49719e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=68, gb_free=12.7, wall=23306
2023-07-25 17:49:41 | INFO | train_inner | epoch 019:   1280 / 1474 loss=2.04, trans_loss=5.063, nll_loss=2.275, w2v_ctc_loss=0.679, task_loss=1.418, contrastive_loss=0.094, total=4135.79, n_correct=2614.55, ppl=4.84, accuracy=63.218, wps=12168.3, ups=1.47, wpb=8271.6, bsz=299.5, num_updates=27800, lr=8.48189e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=23374
2023-07-25 17:50:50 | INFO | train_inner | epoch 019:   1380 / 1474 loss=2.04, trans_loss=5.057, nll_loss=2.268, w2v_ctc_loss=0.69, task_loss=1.43, contrastive_loss=0.081, total=4138.67, n_correct=2619.41, ppl=4.82, accuracy=63.291, wps=12123.1, ups=1.46, wpb=8277.3, bsz=301.6, num_updates=27900, lr=8.46668e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=23442
2023-07-25 17:51:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 17:52:17 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.224 | trans_loss 5.587 | nll_loss 2.868 | w2v_ctc_loss 1.373 | task_loss 4.656 | contrastive_loss 0.265 | total 4003.4 | n_correct 2471.5 | ppl 7.3 | accuracy 61.735 | uer 17.432 | wer 19.313 | raw_wer 19.313 | bleu 19.8 | wps 2124.8 | wpb 4003.4 | bsz 141.8 | num_updates 27994 | best_bleu 19.94
2023-07-25 17:52:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27994 updates
2023-07-25 17:52:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.8007.pt
2023-07-25 17:52:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.8007.pt
2023-07-25 17:52:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.8007.pt (epoch 19 @ 27994 updates, score 19.8) (writing took 13.714729767292738 seconds)
2023-07-25 17:52:32 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-25 17:52:32 | INFO | train | epoch 019 | loss 2.038 | trans_loss 5.046 | nll_loss 2.253 | w2v_ctc_loss 0.686 | task_loss 1.399 | contrastive_loss 0.126 | total 4138.65 | n_correct 2627.52 | ppl 4.77 | accuracy 63.487 | wps 11586.9 | ups 1.4 | wpb 8277.3 | bsz 305.7 | num_updates 27994 | lr 8.45245e-05 | gnorm 0.572 | clip 0 | loss_scale 32 | train_wall 998 | gb_free 17.3 | wall 23545
2023-07-25 17:52:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 17:52:32 | INFO | fairseq.trainer | begin training epoch 20
2023-07-25 17:52:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 17:52:46 | INFO | train_inner | epoch 020:      6 / 1474 loss=2.039, trans_loss=5.05, nll_loss=2.259, w2v_ctc_loss=0.68, task_loss=1.42, contrastive_loss=0.164, total=4117.61, n_correct=2613.51, ppl=4.79, accuracy=63.472, wps=7078.2, ups=0.86, wpb=8235.2, bsz=303, num_updates=28000, lr=8.45154e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=23558
2023-07-25 17:52:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 17:53:10 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.217 | trans_loss 5.588 | nll_loss 2.867 | w2v_ctc_loss 1.348 | task_loss 4.638 | contrastive_loss 0.267 | total 4003.4 | n_correct 2472.4 | ppl 7.3 | accuracy 61.758 | uer 17.325 | wer 19.112 | raw_wer 19.112 | bleu 20.04 | wps 2146.8 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.04
2023-07-25 17:53:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-25 17:53:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_20_28000.pt
2023-07-25 17:53:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_20_28000.pt
2023-07-25 17:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.04) (writing took 38.39689761959016 seconds)
2023-07-25 17:54:58 | INFO | train_inner | epoch 020:    106 / 1474 loss=2.015, trans_loss=5.011, nll_loss=2.206, w2v_ctc_loss=0.669, task_loss=1.356, contrastive_loss=0.088, total=4192.82, n_correct=2689.8, ppl=4.61, accuracy=64.153, wps=6362.9, ups=0.76, wpb=8385.6, bsz=312.8, num_updates=28100, lr=8.43649e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=23690
2023-07-25 17:56:07 | INFO | train_inner | epoch 020:    206 / 1474 loss=2.027, trans_loss=5.023, nll_loss=2.221, w2v_ctc_loss=0.676, task_loss=1.452, contrastive_loss=0.138, total=4155.9, n_correct=2655.04, ppl=4.66, accuracy=63.886, wps=12001.4, ups=1.44, wpb=8311.8, bsz=302.3, num_updates=28200, lr=8.42152e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=69, gb_free=11.6, wall=23760
2023-07-25 17:57:15 | INFO | train_inner | epoch 020:    306 / 1474 loss=2.016, trans_loss=5.016, nll_loss=2.214, w2v_ctc_loss=0.677, task_loss=1.255, contrastive_loss=0.079, total=4192.69, n_correct=2691.21, ppl=4.64, accuracy=64.188, wps=12362.7, ups=1.47, wpb=8385.4, bsz=327.6, num_updates=28300, lr=8.40663e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=23827
2023-07-25 17:58:23 | INFO | train_inner | epoch 020:    406 / 1474 loss=2.02, trans_loss=5.023, nll_loss=2.221, w2v_ctc_loss=0.67, task_loss=1.422, contrastive_loss=0.075, total=4116.96, n_correct=2635.16, ppl=4.66, accuracy=64.007, wps=12098.8, ups=1.47, wpb=8233.9, bsz=296.8, num_updates=28400, lr=8.39181e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=68, gb_free=12.5, wall=23895
2023-07-25 17:59:31 | INFO | train_inner | epoch 020:    506 / 1474 loss=2.032, trans_loss=5.038, nll_loss=2.241, w2v_ctc_loss=0.673, task_loss=1.443, contrastive_loss=0.162, total=4100.73, n_correct=2611.79, ppl=4.73, accuracy=63.691, wps=12051.4, ups=1.47, wpb=8201.5, bsz=298.4, num_updates=28500, lr=8.37708e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=23963
2023-07-25 18:00:39 | INFO | train_inner | epoch 020:    606 / 1474 loss=2.035, trans_loss=5.033, nll_loss=2.235, w2v_ctc_loss=0.677, task_loss=1.455, contrastive_loss=0.168, total=4101.99, n_correct=2611.82, ppl=4.71, accuracy=63.672, wps=12134.7, ups=1.48, wpb=8204, bsz=298.3, num_updates=28600, lr=8.36242e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=67, gb_free=13.4, wall=24031
2023-07-25 18:01:46 | INFO | train_inner | epoch 020:    706 / 1474 loss=2.03, trans_loss=5.038, nll_loss=2.241, w2v_ctc_loss=0.683, task_loss=1.425, contrastive_loss=0.065, total=4124.25, n_correct=2625.45, ppl=4.73, accuracy=63.659, wps=12167.3, ups=1.48, wpb=8248.5, bsz=297.2, num_updates=28700, lr=8.34784e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=24099
2023-07-25 18:02:54 | INFO | train_inner | epoch 020:    806 / 1474 loss=2.027, trans_loss=5.034, nll_loss=2.237, w2v_ctc_loss=0.684, task_loss=1.373, contrastive_loss=0.072, total=4153.23, n_correct=2647.24, ppl=4.71, accuracy=63.739, wps=12240, ups=1.47, wpb=8306.5, bsz=308.5, num_updates=28800, lr=8.33333e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=24167
2023-07-25 18:04:03 | INFO | train_inner | epoch 020:    906 / 1474 loss=2.053, trans_loss=5.047, nll_loss=2.255, w2v_ctc_loss=0.682, task_loss=1.349, contrastive_loss=0.369, total=4153.72, n_correct=2633.32, ppl=4.77, accuracy=63.397, wps=12040.4, ups=1.45, wpb=8307.4, bsz=320.7, num_updates=28900, lr=8.3189e-05, gnorm=0.59, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=24236
2023-07-25 18:05:12 | INFO | train_inner | epoch 020:   1006 / 1474 loss=2.027, trans_loss=5.039, nll_loss=2.244, w2v_ctc_loss=0.674, task_loss=1.403, contrastive_loss=0.078, total=4156.05, n_correct=2646.77, ppl=4.74, accuracy=63.685, wps=12130.3, ups=1.46, wpb=8312.1, bsz=305.3, num_updates=29000, lr=8.30455e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=24304
2023-07-25 18:05:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-25 18:06:21 | INFO | train_inner | epoch 020:   1107 / 1474 loss=2.032, trans_loss=5.04, nll_loss=2.246, w2v_ctc_loss=0.677, task_loss=1.343, contrastive_loss=0.159, total=4167.99, n_correct=2655.96, ppl=4.74, accuracy=63.723, wps=12110.3, ups=1.45, wpb=8336, bsz=314.6, num_updates=29100, lr=8.29027e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=24373
2023-07-25 18:07:28 | INFO | train_inner | epoch 020:   1207 / 1474 loss=2.033, trans_loss=5.038, nll_loss=2.242, w2v_ctc_loss=0.689, task_loss=1.531, contrastive_loss=0.065, total=4033.74, n_correct=2564.12, ppl=4.73, accuracy=63.567, wps=11917, ups=1.48, wpb=8067.5, bsz=285.2, num_updates=29200, lr=8.27606e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=67, gb_free=17.2, wall=24441
2023-07-25 18:08:37 | INFO | train_inner | epoch 020:   1307 / 1474 loss=2.031, trans_loss=5.048, nll_loss=2.257, w2v_ctc_loss=0.678, task_loss=1.479, contrastive_loss=0.07, total=4124.42, n_correct=2624.36, ppl=4.78, accuracy=63.63, wps=12102.5, ups=1.47, wpb=8248.8, bsz=297, num_updates=29300, lr=8.26192e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=24509
2023-07-25 18:09:45 | INFO | train_inner | epoch 020:   1407 / 1474 loss=2.031, trans_loss=5.044, nll_loss=2.25, w2v_ctc_loss=0.68, task_loss=1.482, contrastive_loss=0.068, total=4114.1, n_correct=2617.15, ppl=4.76, accuracy=63.614, wps=12080.3, ups=1.47, wpb=8228.2, bsz=293.7, num_updates=29400, lr=8.24786e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=68, gb_free=14.4, wall=24577
2023-07-25 18:10:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 18:10:55 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.201 | trans_loss 5.587 | nll_loss 2.867 | w2v_ctc_loss 1.298 | task_loss 4.578 | contrastive_loss 0.267 | total 4003.4 | n_correct 2464.5 | ppl 7.3 | accuracy 61.56 | uer 17.262 | wer 18.963 | raw_wer 18.963 | bleu 19.74 | wps 1991.1 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.04
2023-07-25 18:10:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-07-25 18:10:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.7403.pt
2023-07-25 18:10:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.7403.pt
2023-07-25 18:11:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.7403.pt (epoch 20 @ 29467 updates, score 19.74) (writing took 12.537645379081368 seconds)
2023-07-25 18:11:08 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-25 18:11:08 | INFO | train | epoch 020 | loss 2.029 | trans_loss 5.034 | nll_loss 2.237 | w2v_ctc_loss 0.678 | task_loss 1.401 | contrastive_loss 0.119 | total 4137.83 | n_correct 2638.01 | ppl 4.71 | accuracy 63.754 | wps 10922.8 | ups 1.32 | wpb 8275.7 | bsz 305.4 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.573 | clip 0 | loss_scale 16 | train_wall 998 | gb_free 16.1 | wall 24661
2023-07-25 18:11:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 18:11:08 | INFO | fairseq.trainer | begin training epoch 21
2023-07-25 18:11:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 18:11:38 | INFO | train_inner | epoch 021:     33 / 1474 loss=2.035, trans_loss=5.04, nll_loss=2.247, w2v_ctc_loss=0.678, task_loss=1.32, contrastive_loss=0.193, total=4155.01, n_correct=2643.8, ppl=4.75, accuracy=63.629, wps=7312.8, ups=0.88, wpb=8310, bsz=317.6, num_updates=29500, lr=8.23387e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=24691
2023-07-25 18:12:46 | INFO | train_inner | epoch 021:    133 / 1474 loss=2.017, trans_loss=5.005, nll_loss=2.198, w2v_ctc_loss=0.665, task_loss=1.321, contrastive_loss=0.185, total=4186.67, n_correct=2689.26, ppl=4.59, accuracy=64.234, wps=12405.6, ups=1.48, wpb=8373.3, bsz=317.4, num_updates=29600, lr=8.21995e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=67, gb_free=12.9, wall=24758
2023-07-25 18:13:54 | INFO | train_inner | epoch 021:    233 / 1474 loss=2.009, trans_loss=5.01, nll_loss=2.205, w2v_ctc_loss=0.653, task_loss=1.319, contrastive_loss=0.136, total=4166.37, n_correct=2680.08, ppl=4.61, accuracy=64.327, wps=12170, ups=1.46, wpb=8332.7, bsz=315.2, num_updates=29700, lr=8.2061e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=68, gb_free=14, wall=24827
2023-07-25 18:15:03 | INFO | train_inner | epoch 021:    333 / 1474 loss=2.019, trans_loss=5.013, nll_loss=2.208, w2v_ctc_loss=0.671, task_loss=1.416, contrastive_loss=0.138, total=4132.25, n_correct=2651.68, ppl=4.62, accuracy=64.17, wps=11996, ups=1.45, wpb=8264.5, bsz=305, num_updates=29800, lr=8.19232e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=24896
2023-07-25 18:16:11 | INFO | train_inner | epoch 021:    433 / 1474 loss=2.01, trans_loss=5.013, nll_loss=2.209, w2v_ctc_loss=0.661, task_loss=1.331, contrastive_loss=0.068, total=4195.53, n_correct=2693.24, ppl=4.62, accuracy=64.193, wps=12365.5, ups=1.47, wpb=8391.1, bsz=311.6, num_updates=29900, lr=8.17861e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=24963
2023-07-25 18:17:19 | INFO | train_inner | epoch 021:    533 / 1474 loss=2.012, trans_loss=5.01, nll_loss=2.205, w2v_ctc_loss=0.669, task_loss=1.443, contrastive_loss=0.062, total=4085.05, n_correct=2627.12, ppl=4.61, accuracy=64.311, wps=11944.2, ups=1.46, wpb=8170.1, bsz=296.1, num_updates=30000, lr=8.16497e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=25032
2023-07-25 18:17:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 18:17:45 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.209 | trans_loss 5.587 | nll_loss 2.867 | w2v_ctc_loss 1.325 | task_loss 4.624 | contrastive_loss 0.258 | total 4003.4 | n_correct 2475.6 | ppl 7.3 | accuracy 61.837 | uer 17.219 | wer 18.952 | raw_wer 18.952 | bleu 19.92 | wps 1977.7 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.04
2023-07-25 18:17:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-25 18:17:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_21_30000.pt
2023-07-25 18:17:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_21_30000.pt
2023-07-25 18:18:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.92) (writing took 24.948972214013338 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:0')
2023-07-25 18:19:21 | INFO | train_inner | epoch 021:    633 / 1474 loss=2.024, trans_loss=5.019, nll_loss=2.217, w2v_ctc_loss=0.663, task_loss=1.379, contrastive_loss=0.235, total=4220.3, n_correct=2702.26, ppl=4.65, accuracy=64.03, wps=6952.7, ups=0.82, wpb=8440.6, bsz=315.8, num_updates=30100, lr=8.15139e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=25153
2023-07-25 18:20:29 | INFO | train_inner | epoch 021:    733 / 1474 loss=2.021, trans_loss=5.028, nll_loss=2.229, w2v_ctc_loss=0.67, task_loss=1.399, contrastive_loss=0.098, total=4148.18, n_correct=2651.99, ppl=4.69, accuracy=63.931, wps=12159.8, ups=1.47, wpb=8296.4, bsz=308.3, num_updates=30200, lr=8.13788e-05, gnorm=0.572, clip=0, loss_scale=16, train_wall=68, gb_free=11.8, wall=25222
2023-07-25 18:21:38 | INFO | train_inner | epoch 021:    833 / 1474 loss=2.027, trans_loss=5.035, nll_loss=2.238, w2v_ctc_loss=0.67, task_loss=1.487, contrastive_loss=0.109, total=4062.56, n_correct=2591.65, ppl=4.72, accuracy=63.794, wps=11760.3, ups=1.45, wpb=8125.1, bsz=293, num_updates=30300, lr=8.12444e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=25291
2023-07-25 18:22:46 | INFO | train_inner | epoch 021:    933 / 1474 loss=2.019, trans_loss=5.024, nll_loss=2.224, w2v_ctc_loss=0.67, task_loss=1.397, contrastive_loss=0.082, total=4103.66, n_correct=2624.63, ppl=4.67, accuracy=63.958, wps=12153.1, ups=1.48, wpb=8207.3, bsz=301.5, num_updates=30400, lr=8.11107e-05, gnorm=0.592, clip=0, loss_scale=16, train_wall=67, gb_free=17.1, wall=25358
2023-07-25 18:23:53 | INFO | train_inner | epoch 021:   1033 / 1474 loss=2.028, trans_loss=5.043, nll_loss=2.249, w2v_ctc_loss=0.677, task_loss=1.431, contrastive_loss=0.079, total=4100.54, n_correct=2611.17, ppl=4.75, accuracy=63.679, wps=12147.9, ups=1.48, wpb=8201.1, bsz=298.2, num_updates=30500, lr=8.09776e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=67, gb_free=17.8, wall=25426
2023-07-25 18:24:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-25 18:25:03 | INFO | train_inner | epoch 021:   1134 / 1474 loss=2.023, trans_loss=5.029, nll_loss=2.23, w2v_ctc_loss=0.673, task_loss=1.495, contrastive_loss=0.082, total=4122.74, n_correct=2636.38, ppl=4.69, accuracy=63.947, wps=11881.8, ups=1.44, wpb=8245.5, bsz=295.2, num_updates=30600, lr=8.08452e-05, gnorm=0.567, clip=0, loss_scale=8, train_wall=69, gb_free=15.8, wall=25495
2023-07-25 18:26:10 | INFO | train_inner | epoch 021:   1234 / 1474 loss=2.022, trans_loss=5.03, nll_loss=2.233, w2v_ctc_loss=0.667, task_loss=1.329, contrastive_loss=0.135, total=4154.73, n_correct=2655.24, ppl=4.7, accuracy=63.909, wps=12327.3, ups=1.48, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.566, clip=0, loss_scale=8, train_wall=67, gb_free=12.5, wall=25562
2023-07-25 18:27:18 | INFO | train_inner | epoch 021:   1334 / 1474 loss=2.022, trans_loss=5.031, nll_loss=2.235, w2v_ctc_loss=0.672, task_loss=1.353, contrastive_loss=0.096, total=4147.17, n_correct=2654.42, ppl=4.71, accuracy=64.006, wps=12219.1, ups=1.47, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.565, clip=0, loss_scale=8, train_wall=67, gb_free=16.2, wall=25630
2023-07-25 18:28:26 | INFO | train_inner | epoch 021:   1434 / 1474 loss=2.039, trans_loss=5.043, nll_loss=2.25, w2v_ctc_loss=0.687, task_loss=1.463, contrastive_loss=0.148, total=4133.93, n_correct=2626.31, ppl=4.76, accuracy=63.531, wps=12080.2, ups=1.46, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.582, clip=0, loss_scale=8, train_wall=68, gb_free=15.5, wall=25699
2023-07-25 18:28:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:2')
2023-07-25 18:29:18 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.203 | trans_loss 5.583 | nll_loss 2.865 | w2v_ctc_loss 1.313 | task_loss 4.606 | contrastive_loss 0.265 | total 4003.4 | n_correct 2470.7 | ppl 7.29 | accuracy 61.715 | uer 17.429 | wer 19.097 | raw_wer 19.097 | bleu 19.73 | wps 2094.8 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.04
2023-07-25 18:29:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-25 18:29:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.7304.pt
2023-07-25 18:29:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.7304.pt
2023-07-25 18:29:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.7304.pt (epoch 21 @ 30940 updates, score 19.73) (writing took 27.703118167817593 seconds)
2023-07-25 18:29:46 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-25 18:29:46 | INFO | train | epoch 021 | loss 2.021 | trans_loss 5.024 | nll_loss 2.224 | w2v_ctc_loss 0.669 | task_loss 1.398 | contrastive_loss 0.122 | total 4138.71 | n_correct 2648.43 | ppl 4.67 | accuracy 63.992 | wps 10906.9 | ups 1.32 | wpb 8277.4 | bsz 305.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.576 | clip 0 | loss_scale 8 | train_wall 997 | gb_free 15.4 | wall 25778
2023-07-25 18:29:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 18:29:46 | INFO | fairseq.trainer | begin training epoch 22
2023-07-25 18:29:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 18:30:35 | INFO | train_inner | epoch 022:     60 / 1474 loss=2.014, trans_loss=5.011, nll_loss=2.207, w2v_ctc_loss=0.671, task_loss=1.421, contrastive_loss=0.061, total=4128.84, n_correct=2655.2, ppl=4.62, accuracy=64.309, wps=6419.9, ups=0.78, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.585, clip=0, loss_scale=8, train_wall=68, gb_free=14.1, wall=25827
2023-07-25 18:31:43 | INFO | train_inner | epoch 022:    160 / 1474 loss=2.012, trans_loss=4.999, nll_loss=2.191, w2v_ctc_loss=0.664, task_loss=1.41, contrastive_loss=0.149, total=4123.35, n_correct=2656.36, ppl=4.57, accuracy=64.422, wps=12094.8, ups=1.47, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.576, clip=0, loss_scale=8, train_wall=68, gb_free=14.6, wall=25896
2023-07-25 18:32:51 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.996, trans_loss=4.995, nll_loss=2.187, w2v_ctc_loss=0.649, task_loss=1.234, contrastive_loss=0.088, total=4267.16, n_correct=2759.8, ppl=4.55, accuracy=64.675, wps=12578.7, ups=1.47, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.558, clip=0, loss_scale=8, train_wall=67, gb_free=16.6, wall=25963
2023-07-25 18:34:00 | INFO | train_inner | epoch 022:    360 / 1474 loss=2.024, trans_loss=5.01, nll_loss=2.206, w2v_ctc_loss=0.664, task_loss=1.421, contrastive_loss=0.246, total=4180.09, n_correct=2684.87, ppl=4.61, accuracy=64.23, wps=12045, ups=1.44, wpb=8360.2, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.569, clip=0, loss_scale=8, train_wall=69, gb_free=17.5, wall=26033
2023-07-25 18:35:09 | INFO | train_inner | epoch 022:    460 / 1474 loss=2.02, trans_loss=5.015, nll_loss=2.211, w2v_ctc_loss=0.667, task_loss=1.478, contrastive_loss=0.128, total=4132.62, n_correct=2653.5, ppl=4.63, accuracy=64.209, wps=11996.3, ups=1.45, wpb=8265.2, bsz=297.2, num_updates=31400, lr=7.98087e-05, gnorm=0.585, clip=0, loss_scale=8, train_wall=68, gb_free=16.5, wall=26102
2023-07-25 18:36:17 | INFO | train_inner | epoch 022:    560 / 1474 loss=2.012, trans_loss=5.01, nll_loss=2.205, w2v_ctc_loss=0.667, task_loss=1.407, contrastive_loss=0.075, total=4155.5, n_correct=2670.98, ppl=4.61, accuracy=64.276, wps=12194.6, ups=1.47, wpb=8311, bsz=307.3, num_updates=31500, lr=7.96819e-05, gnorm=0.579, clip=0, loss_scale=8, train_wall=68, gb_free=16.4, wall=26170
2023-07-25 18:37:25 | INFO | train_inner | epoch 022:    660 / 1474 loss=2.006, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.649, task_loss=1.325, contrastive_loss=0.156, total=4147.84, n_correct=2675.09, ppl=4.58, accuracy=64.494, wps=12272.5, ups=1.48, wpb=8295.7, bsz=313.1, num_updates=31600, lr=7.95557e-05, gnorm=0.6, clip=0, loss_scale=8, train_wall=67, gb_free=12.9, wall=26238
2023-07-25 18:38:34 | INFO | train_inner | epoch 022:    760 / 1474 loss=2.012, trans_loss=5.01, nll_loss=2.205, w2v_ctc_loss=0.667, task_loss=1.435, contrastive_loss=0.077, total=4166.89, n_correct=2680.67, ppl=4.61, accuracy=64.333, wps=12176, ups=1.46, wpb=8333.8, bsz=304.3, num_updates=31700, lr=7.94301e-05, gnorm=0.595, clip=0, loss_scale=8, train_wall=68, gb_free=15.9, wall=26306
2023-07-25 18:39:42 | INFO | train_inner | epoch 022:    860 / 1474 loss=2.024, trans_loss=5.028, nll_loss=2.229, w2v_ctc_loss=0.676, task_loss=1.522, contrastive_loss=0.063, total=4074.75, n_correct=2601.31, ppl=4.69, accuracy=63.84, wps=11877, ups=1.46, wpb=8149.5, bsz=288.4, num_updates=31800, lr=7.93052e-05, gnorm=0.66, clip=0, loss_scale=8, train_wall=68, gb_free=17.5, wall=26375
2023-07-25 18:40:51 | INFO | train_inner | epoch 022:    960 / 1474 loss=2.008, trans_loss=5.014, nll_loss=2.213, w2v_ctc_loss=0.657, task_loss=1.405, contrastive_loss=0.062, total=4136.34, n_correct=2659.48, ppl=4.64, accuracy=64.295, wps=12071.6, ups=1.46, wpb=8272.7, bsz=303.7, num_updates=31900, lr=7.91808e-05, gnorm=0.587, clip=0, loss_scale=8, train_wall=68, gb_free=16.6, wall=26443
2023-07-25 18:41:58 | INFO | train_inner | epoch 022:   1060 / 1474 loss=2.017, trans_loss=5.014, nll_loss=2.212, w2v_ctc_loss=0.658, task_loss=1.335, contrastive_loss=0.233, total=4157.21, n_correct=2669.99, ppl=4.63, accuracy=64.226, wps=12288, ups=1.48, wpb=8314.4, bsz=315.4, num_updates=32000, lr=7.90569e-05, gnorm=0.569, clip=0, loss_scale=8, train_wall=67, gb_free=11.9, wall=26511
2023-07-25 18:41:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 18:42:26 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.199 | trans_loss 5.577 | nll_loss 2.858 | w2v_ctc_loss 1.317 | task_loss 4.595 | contrastive_loss 0.258 | total 4003.4 | n_correct 2476.6 | ppl 7.25 | accuracy 61.862 | uer 17.243 | wer 19.075 | raw_wer 19.075 | bleu 19.72 | wps 1728.3 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.04
2023-07-25 18:42:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-25 18:42:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_22_32000.pt
2023-07-25 18:42:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_22_32000.pt
2023-07-25 18:42:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.72) (writing took 23.94355196878314 seconds)
2023-07-25 18:43:58 | INFO | train_inner | epoch 022:   1160 / 1474 loss=2.03, trans_loss=5.038, nll_loss=2.244, w2v_ctc_loss=0.678, task_loss=1.459, contrastive_loss=0.114, total=4092.91, n_correct=2609.11, ppl=4.74, accuracy=63.747, wps=6825.3, ups=0.83, wpb=8185.8, bsz=294.3, num_updates=32100, lr=7.89337e-05, gnorm=0.587, clip=0, loss_scale=8, train_wall=67, gb_free=15.9, wall=26631
2023-07-25 18:45:07 | INFO | train_inner | epoch 022:   1260 / 1474 loss=2.019, trans_loss=5.03, nll_loss=2.235, w2v_ctc_loss=0.667, task_loss=1.298, contrastive_loss=0.114, total=4182.65, n_correct=2673.17, ppl=4.71, accuracy=63.911, wps=12179.6, ups=1.46, wpb=8365.3, bsz=323.6, num_updates=32200, lr=7.8811e-05, gnorm=0.597, clip=0, loss_scale=8, train_wall=68, gb_free=16.3, wall=26699
2023-07-25 18:46:15 | INFO | train_inner | epoch 022:   1360 / 1474 loss=2.013, trans_loss=5.02, nll_loss=2.22, w2v_ctc_loss=0.656, task_loss=1.39, contrastive_loss=0.131, total=4071.58, n_correct=2613.98, ppl=4.66, accuracy=64.201, wps=11971.8, ups=1.47, wpb=8143.2, bsz=300.6, num_updates=32300, lr=7.86889e-05, gnorm=0.575, clip=0, loss_scale=8, train_wall=68, gb_free=16.7, wall=26767
2023-07-25 18:47:23 | INFO | train_inner | epoch 022:   1460 / 1474 loss=2.027, trans_loss=5.037, nll_loss=2.241, w2v_ctc_loss=0.678, task_loss=1.496, contrastive_loss=0.079, total=4077.83, n_correct=2601.38, ppl=4.73, accuracy=63.793, wps=12008.8, ups=1.47, wpb=8155.7, bsz=288, num_updates=32400, lr=7.85674e-05, gnorm=0.592, clip=0, loss_scale=8, train_wall=67, gb_free=16, wall=26835
2023-07-25 18:47:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 18:47:57 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.194 | trans_loss 5.575 | nll_loss 2.853 | w2v_ctc_loss 1.304 | task_loss 4.577 | contrastive_loss 0.259 | total 4003.4 | n_correct 2479 | ppl 7.23 | accuracy 61.922 | uer 17.102 | wer 19.007 | raw_wer 19.007 | bleu 20.14 | wps 2038.2 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 20.14
2023-07-25 18:47:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-07-25 18:47:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 18:48:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 18:48:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 22 @ 32414 updates, score 20.14) (writing took 19.19560712389648 seconds)
2023-07-25 18:48:16 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-25 18:48:16 | INFO | train | epoch 022 | loss 2.015 | trans_loss 5.015 | nll_loss 2.213 | w2v_ctc_loss 0.664 | task_loss 1.401 | contrastive_loss 0.12 | total 4138.65 | n_correct 2657.3 | ppl 4.64 | accuracy 64.207 | wps 10987.1 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.588 | clip 0 | loss_scale 8 | train_wall 999 | gb_free 11.6 | wall 26889
2023-07-25 18:48:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 18:48:17 | INFO | fairseq.trainer | begin training epoch 23
2023-07-25 18:48:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 18:49:24 | INFO | train_inner | epoch 023:     86 / 1474 loss=2.004, trans_loss=4.992, nll_loss=2.183, w2v_ctc_loss=0.666, task_loss=1.447, contrastive_loss=0.07, total=4089.8, n_correct=2644.28, ppl=4.54, accuracy=64.655, wps=6776.6, ups=0.83, wpb=8179.6, bsz=299.5, num_updates=32500, lr=7.84465e-05, gnorm=0.585, clip=0, loss_scale=8, train_wall=68, gb_free=16.6, wall=26956
2023-07-25 18:50:32 | INFO | train_inner | epoch 023:    186 / 1474 loss=1.998, trans_loss=4.986, nll_loss=2.175, w2v_ctc_loss=0.653, task_loss=1.47, contrastive_loss=0.067, total=4117.76, n_correct=2665.64, ppl=4.51, accuracy=64.735, wps=11987.3, ups=1.46, wpb=8235.5, bsz=296, num_updates=32600, lr=7.8326e-05, gnorm=0.566, clip=0, loss_scale=8, train_wall=68, gb_free=15.5, wall=27025
2023-07-25 18:51:42 | INFO | train_inner | epoch 023:    286 / 1474 loss=2.003, trans_loss=4.995, nll_loss=2.186, w2v_ctc_loss=0.646, task_loss=1.42, contrastive_loss=0.146, total=4144.73, n_correct=2678.24, ppl=4.55, accuracy=64.618, wps=11948.2, ups=1.44, wpb=8289.5, bsz=304, num_updates=32700, lr=7.82062e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=27094
2023-07-25 18:52:50 | INFO | train_inner | epoch 023:    386 / 1474 loss=2, trans_loss=4.995, nll_loss=2.185, w2v_ctc_loss=0.653, task_loss=1.437, contrastive_loss=0.058, total=4126.79, n_correct=2670.77, ppl=4.55, accuracy=64.718, wps=12137.1, ups=1.47, wpb=8253.6, bsz=296.4, num_updates=32800, lr=7.80869e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=27162
2023-07-25 18:53:58 | INFO | train_inner | epoch 023:    486 / 1474 loss=2.01, trans_loss=5.005, nll_loss=2.199, w2v_ctc_loss=0.661, task_loss=1.363, contrastive_loss=0.121, total=4150.15, n_correct=2671.55, ppl=4.59, accuracy=64.372, wps=12084.8, ups=1.46, wpb=8300.3, bsz=312.1, num_updates=32900, lr=7.79681e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=27231
2023-07-25 18:55:06 | INFO | train_inner | epoch 023:    586 / 1474 loss=1.99, trans_loss=4.987, nll_loss=2.176, w2v_ctc_loss=0.646, task_loss=1.319, contrastive_loss=0.065, total=4174.6, n_correct=2708.96, ppl=4.52, accuracy=64.891, wps=12271.1, ups=1.47, wpb=8349.2, bsz=316.3, num_updates=33000, lr=7.78499e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=27299
2023-07-25 18:56:14 | INFO | train_inner | epoch 023:    686 / 1474 loss=2.003, trans_loss=4.998, nll_loss=2.191, w2v_ctc_loss=0.652, task_loss=1.406, contrastive_loss=0.103, total=4136.6, n_correct=2672.17, ppl=4.57, accuracy=64.598, wps=12168.4, ups=1.47, wpb=8273.2, bsz=301.2, num_updates=33100, lr=7.77322e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=67, gb_free=17.7, wall=27367
2023-07-25 18:57:23 | INFO | train_inner | epoch 023:    786 / 1474 loss=2.008, trans_loss=5.007, nll_loss=2.202, w2v_ctc_loss=0.66, task_loss=1.411, contrastive_loss=0.086, total=4147.22, n_correct=2671.45, ppl=4.6, accuracy=64.415, wps=12169.9, ups=1.47, wpb=8294.4, bsz=305.1, num_updates=33200, lr=7.76151e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=27435
2023-07-25 18:58:31 | INFO | train_inner | epoch 023:    886 / 1474 loss=2.005, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.651, task_loss=1.269, contrastive_loss=0.167, total=4193.16, n_correct=2706.43, ppl=4.59, accuracy=64.544, wps=12268, ups=1.46, wpb=8386.3, bsz=327.3, num_updates=33300, lr=7.74984e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=27503
2023-07-25 18:59:40 | INFO | train_inner | epoch 023:    986 / 1474 loss=2.016, trans_loss=5.006, nll_loss=2.202, w2v_ctc_loss=0.647, task_loss=1.395, contrastive_loss=0.319, total=4164.33, n_correct=2682.28, ppl=4.6, accuracy=64.411, wps=12090.8, ups=1.45, wpb=8328.7, bsz=310.1, num_updates=33400, lr=7.73823e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=27572
2023-07-25 19:00:48 | INFO | train_inner | epoch 023:   1086 / 1474 loss=2.016, trans_loss=5.013, nll_loss=2.211, w2v_ctc_loss=0.673, task_loss=1.498, contrastive_loss=0.072, total=4088.37, n_correct=2626.45, ppl=4.63, accuracy=64.242, wps=11927.8, ups=1.46, wpb=8176.7, bsz=289.6, num_updates=33500, lr=7.72667e-05, gnorm=0.613, clip=0, loss_scale=16, train_wall=68, gb_free=15.5, wall=27641
2023-07-25 19:01:57 | INFO | train_inner | epoch 023:   1186 / 1474 loss=2.007, trans_loss=5.014, nll_loss=2.212, w2v_ctc_loss=0.661, task_loss=1.39, contrastive_loss=0.063, total=4162.3, n_correct=2675.72, ppl=4.63, accuracy=64.285, wps=12122.4, ups=1.46, wpb=8324.6, bsz=309, num_updates=33600, lr=7.71517e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=27710
2023-07-25 19:03:05 | INFO | train_inner | epoch 023:   1286 / 1474 loss=2.001, trans_loss=5.011, nll_loss=2.209, w2v_ctc_loss=0.649, task_loss=1.361, contrastive_loss=0.077, total=4131.74, n_correct=2661.95, ppl=4.62, accuracy=64.427, wps=12085.6, ups=1.46, wpb=8263.5, bsz=308.7, num_updates=33700, lr=7.70371e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=27778
2023-07-25 19:04:14 | INFO | train_inner | epoch 023:   1386 / 1474 loss=2.021, trans_loss=5.03, nll_loss=2.234, w2v_ctc_loss=0.664, task_loss=1.415, contrastive_loss=0.134, total=4141.25, n_correct=2653.17, ppl=4.7, accuracy=64.067, wps=12088.4, ups=1.46, wpb=8282.5, bsz=304.7, num_updates=33800, lr=7.69231e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=27846
2023-07-25 19:05:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 19:05:40 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.202 | trans_loss 5.572 | nll_loss 2.849 | w2v_ctc_loss 1.336 | task_loss 4.587 | contrastive_loss 0.259 | total 4003.4 | n_correct 2481.9 | ppl 7.2 | accuracy 61.995 | uer 17.02 | wer 18.664 | raw_wer 18.664 | bleu 19.86 | wps 1823.9 | wpb 4003.4 | bsz 141.8 | num_updates 33888 | best_bleu 20.14
2023-07-25 19:05:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33888 updates
2023-07-25 19:05:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.8601.pt
2023-07-25 19:05:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.8601.pt
2023-07-25 19:05:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.8601.pt (epoch 23 @ 33888 updates, score 19.86) (writing took 11.576421210542321 seconds)
2023-07-25 19:05:53 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-25 19:05:53 | INFO | train | epoch 023 | loss 2.007 | trans_loss 5.004 | nll_loss 2.199 | w2v_ctc_loss 0.656 | task_loss 1.399 | contrastive_loss 0.119 | total 4138.65 | n_correct 2668.43 | ppl 4.59 | accuracy 64.476 | wps 11552.5 | ups 1.4 | wpb 8277.3 | bsz 305.7 | num_updates 33888 | lr 7.68231e-05 | gnorm 0.58 | clip 0 | loss_scale 16 | train_wall 1002 | gb_free 13.6 | wall 27945
2023-07-25 19:05:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 19:05:53 | INFO | fairseq.trainer | begin training epoch 24
2023-07-25 19:05:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 19:06:09 | INFO | train_inner | epoch 024:     12 / 1474 loss=2.021, trans_loss=5.022, nll_loss=2.223, w2v_ctc_loss=0.655, task_loss=1.393, contrastive_loss=0.213, total=4095.53, n_correct=2627.41, ppl=4.67, accuracy=64.153, wps=7118.6, ups=0.87, wpb=8191.1, bsz=306.3, num_updates=33900, lr=7.68095e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=27962
2023-07-25 19:07:17 | INFO | train_inner | epoch 024:    112 / 1474 loss=2, trans_loss=4.977, nll_loss=2.164, w2v_ctc_loss=0.646, task_loss=1.306, contrastive_loss=0.231, total=4167.42, n_correct=2705.55, ppl=4.48, accuracy=64.921, wps=12203.8, ups=1.46, wpb=8334.8, bsz=323, num_updates=34000, lr=7.66965e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=68, gb_free=17.7, wall=28030
2023-07-25 19:07:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 19:07:42 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.196 | trans_loss 5.576 | nll_loss 2.852 | w2v_ctc_loss 1.306 | task_loss 4.627 | contrastive_loss 0.261 | total 4003.4 | n_correct 2477.8 | ppl 7.22 | accuracy 61.892 | uer 16.842 | wer 18.541 | raw_wer 18.541 | bleu 20 | wps 1970.5 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.14
2023-07-25 19:07:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-25 19:07:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_24_34000.pt
2023-07-25 19:07:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_24_34000.pt
2023-07-25 19:07:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.0) (writing took 12.369195936247706 seconds)
2023-07-25 19:09:05 | INFO | train_inner | epoch 024:    212 / 1474 loss=2, trans_loss=4.982, nll_loss=2.171, w2v_ctc_loss=0.636, task_loss=1.23, contrastive_loss=0.291, total=4247.08, n_correct=2759.46, ppl=4.5, accuracy=64.973, wps=7902.9, ups=0.93, wpb=8494.2, bsz=339.5, num_updates=34100, lr=7.6584e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=28137
2023-07-25 19:10:13 | INFO | train_inner | epoch 024:    312 / 1474 loss=1.989, trans_loss=4.981, nll_loss=2.168, w2v_ctc_loss=0.647, task_loss=1.353, contrastive_loss=0.061, total=4139.31, n_correct=2689.2, ppl=4.49, accuracy=64.967, wps=12200, ups=1.47, wpb=8278.6, bsz=308.4, num_updates=34200, lr=7.64719e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=28205
2023-07-25 19:11:21 | INFO | train_inner | epoch 024:    412 / 1474 loss=2.015, trans_loss=4.993, nll_loss=2.184, w2v_ctc_loss=0.659, task_loss=1.461, contrastive_loss=0.209, total=4157.07, n_correct=2682.16, ppl=4.54, accuracy=64.52, wps=12138.9, ups=1.46, wpb=8314.1, bsz=299.9, num_updates=34300, lr=7.63604e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=28274
2023-07-25 19:12:29 | INFO | train_inner | epoch 024:    512 / 1474 loss=2.003, trans_loss=4.992, nll_loss=2.182, w2v_ctc_loss=0.656, task_loss=1.435, contrastive_loss=0.13, total=4138.82, n_correct=2677.58, ppl=4.54, accuracy=64.694, wps=12126, ups=1.46, wpb=8277.6, bsz=301.6, num_updates=34400, lr=7.62493e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=28342
2023-07-25 19:13:38 | INFO | train_inner | epoch 024:    612 / 1474 loss=1.992, trans_loss=4.987, nll_loss=2.178, w2v_ctc_loss=0.639, task_loss=1.391, contrastive_loss=0.096, total=4164.75, n_correct=2701.24, ppl=4.52, accuracy=64.86, wps=12177.8, ups=1.46, wpb=8329.5, bsz=309.1, num_updates=34500, lr=7.61387e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=68, gb_free=15.5, wall=28410
2023-07-25 19:14:47 | INFO | train_inner | epoch 024:    712 / 1474 loss=2.006, trans_loss=5.004, nll_loss=2.198, w2v_ctc_loss=0.652, task_loss=1.454, contrastive_loss=0.104, total=4103.92, n_correct=2646.92, ppl=4.59, accuracy=64.497, wps=11943.7, ups=1.46, wpb=8207.8, bsz=294, num_updates=34600, lr=7.60286e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=68, gb_free=11.9, wall=28479
2023-07-25 19:15:55 | INFO | train_inner | epoch 024:    812 / 1474 loss=1.999, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.648, task_loss=1.411, contrastive_loss=0.085, total=4109.8, n_correct=2655.06, ppl=4.58, accuracy=64.603, wps=11990.1, ups=1.46, wpb=8219.6, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=28548
2023-07-25 19:17:03 | INFO | train_inner | epoch 024:    912 / 1474 loss=2.009, trans_loss=5.01, nll_loss=2.205, w2v_ctc_loss=0.66, task_loss=1.55, contrastive_loss=0.054, total=4042.08, n_correct=2602.19, ppl=4.61, accuracy=64.377, wps=11964.4, ups=1.48, wpb=8084.2, bsz=280.6, num_updates=34800, lr=7.58098e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=28615
2023-07-25 19:18:11 | INFO | train_inner | epoch 024:   1012 / 1474 loss=2.003, trans_loss=5.008, nll_loss=2.204, w2v_ctc_loss=0.651, task_loss=1.446, contrastive_loss=0.061, total=4140.44, n_correct=2668.6, ppl=4.61, accuracy=64.452, wps=12123.8, ups=1.46, wpb=8280.9, bsz=298.7, num_updates=34900, lr=7.57011e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=68, gb_free=11.6, wall=28683
2023-07-25 19:19:20 | INFO | train_inner | epoch 024:   1112 / 1474 loss=1.999, trans_loss=4.993, nll_loss=2.186, w2v_ctc_loss=0.653, task_loss=1.342, contrastive_loss=0.106, total=4134.93, n_correct=2676.8, ppl=4.55, accuracy=64.736, wps=11917.5, ups=1.44, wpb=8269.9, bsz=309.4, num_updates=35000, lr=7.55929e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=28753
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:0')
2023-07-25 19:20:29 | INFO | train_inner | epoch 024:   1212 / 1474 loss=2.001, trans_loss=5.003, nll_loss=2.198, w2v_ctc_loss=0.65, task_loss=1.392, contrastive_loss=0.095, total=4144.49, n_correct=2675.96, ppl=4.59, accuracy=64.567, wps=12179.9, ups=1.47, wpb=8289, bsz=309.8, num_updates=35100, lr=7.54851e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=28821
2023-07-25 19:21:37 | INFO | train_inner | epoch 024:   1312 / 1474 loss=2.009, trans_loss=5.011, nll_loss=2.208, w2v_ctc_loss=0.665, task_loss=1.487, contrastive_loss=0.061, total=4110.93, n_correct=2642.08, ppl=4.62, accuracy=64.27, wps=12066.6, ups=1.47, wpb=8221.9, bsz=293, num_updates=35200, lr=7.53778e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=68, gb_free=13.5, wall=28889
2023-07-25 19:22:45 | INFO | train_inner | epoch 024:   1412 / 1474 loss=2.01, trans_loss=5.013, nll_loss=2.211, w2v_ctc_loss=0.664, task_loss=1.456, contrastive_loss=0.069, total=4088.73, n_correct=2629.02, ppl=4.63, accuracy=64.299, wps=11960.6, ups=1.46, wpb=8177.5, bsz=294.1, num_updates=35300, lr=7.5271e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=28957
2023-07-25 19:23:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:1')
2023-07-25 19:23:51 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.188 | trans_loss 5.57 | nll_loss 2.845 | w2v_ctc_loss 1.294 | task_loss 4.621 | contrastive_loss 0.265 | total 4003.4 | n_correct 2484.9 | ppl 7.19 | accuracy 62.07 | uer 16.779 | wer 18.65 | raw_wer 18.65 | bleu 19.75 | wps 1972.7 | wpb 4003.4 | bsz 141.8 | num_updates 35362 | best_bleu 20.14
2023-07-25 19:23:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35362 updates
2023-07-25 19:23:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.7507.pt
2023-07-25 19:23:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.7507.pt
2023-07-25 19:24:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.7507.pt (epoch 24 @ 35362 updates, score 19.75) (writing took 11.571083884686232 seconds)
2023-07-25 19:24:03 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-25 19:24:03 | INFO | train | epoch 024 | loss 2.002 | trans_loss 4.997 | nll_loss 2.189 | w2v_ctc_loss 0.651 | task_loss 1.398 | contrastive_loss 0.118 | total 4138.65 | n_correct 2675.09 | ppl 4.56 | accuracy 64.637 | wps 11190.8 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 35362 | lr 7.5205e-05 | gnorm 0.58 | clip 0 | loss_scale 32 | train_wall 1000 | gb_free 16.1 | wall 29035
2023-07-25 19:24:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 19:24:03 | INFO | fairseq.trainer | begin training epoch 25
2023-07-25 19:24:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 19:24:38 | INFO | train_inner | epoch 025:     38 / 1474 loss=1.99, trans_loss=4.988, nll_loss=2.179, w2v_ctc_loss=0.646, task_loss=1.335, contrastive_loss=0.071, total=4170.36, n_correct=2709.93, ppl=4.53, accuracy=64.981, wps=7369.6, ups=0.88, wpb=8340.7, bsz=313, num_updates=35400, lr=7.51646e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=29071
2023-07-25 19:25:46 | INFO | train_inner | epoch 025:    138 / 1474 loss=1.983, trans_loss=4.968, nll_loss=2.151, w2v_ctc_loss=0.639, task_loss=1.378, contrastive_loss=0.071, total=4133.56, n_correct=2698.77, ppl=4.44, accuracy=65.289, wps=12201.7, ups=1.48, wpb=8267.1, bsz=306.4, num_updates=35500, lr=7.50587e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=67, gb_free=17.1, wall=29138
2023-07-25 19:26:56 | INFO | train_inner | epoch 025:    238 / 1474 loss=1.985, trans_loss=4.971, nll_loss=2.156, w2v_ctc_loss=0.641, task_loss=1.431, contrastive_loss=0.075, total=4112.46, n_correct=2679.06, ppl=4.46, accuracy=65.145, wps=11812.1, ups=1.44, wpb=8224.9, bsz=303.4, num_updates=35600, lr=7.49532e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=29208
2023-07-25 19:28:04 | INFO | train_inner | epoch 025:    338 / 1474 loss=1.996, trans_loss=4.98, nll_loss=2.166, w2v_ctc_loss=0.647, task_loss=1.507, contrastive_loss=0.1, total=4139.11, n_correct=2684.61, ppl=4.49, accuracy=64.86, wps=12049.1, ups=1.46, wpb=8278.2, bsz=291.7, num_updates=35700, lr=7.48481e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=29277
2023-07-25 19:29:13 | INFO | train_inner | epoch 025:    438 / 1474 loss=2.005, trans_loss=4.983, nll_loss=2.171, w2v_ctc_loss=0.656, task_loss=1.424, contrastive_loss=0.179, total=4181.96, n_correct=2711.44, ppl=4.5, accuracy=64.837, wps=12156.2, ups=1.45, wpb=8363.9, bsz=303, num_updates=35800, lr=7.47435e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=29346
2023-07-25 19:30:22 | INFO | train_inner | epoch 025:    538 / 1474 loss=1.995, trans_loss=4.991, nll_loss=2.183, w2v_ctc_loss=0.648, task_loss=1.369, contrastive_loss=0.075, total=4162.59, n_correct=2694.76, ppl=4.54, accuracy=64.738, wps=12155.9, ups=1.46, wpb=8325.2, bsz=312.9, num_updates=35900, lr=7.46393e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=68, gb_free=11.8, wall=29414
2023-07-25 19:31:30 | INFO | train_inner | epoch 025:    638 / 1474 loss=1.998, trans_loss=4.983, nll_loss=2.172, w2v_ctc_loss=0.65, task_loss=1.397, contrastive_loss=0.142, total=4142.58, n_correct=2688.14, ppl=4.51, accuracy=64.89, wps=12027.8, ups=1.45, wpb=8285.2, bsz=308.3, num_updates=36000, lr=7.45356e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=68, gb_free=14.7, wall=29483
2023-07-25 19:31:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 19:31:56 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.189 | trans_loss 5.57 | nll_loss 2.844 | w2v_ctc_loss 1.295 | task_loss 4.625 | contrastive_loss 0.26 | total 4003.4 | n_correct 2487.3 | ppl 7.18 | accuracy 62.13 | uer 16.845 | wer 18.676 | raw_wer 18.676 | bleu 20 | wps 1895.9 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.14
2023-07-25 19:31:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-25 19:31:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_25_36000.pt
2023-07-25 19:32:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_25_36000.pt
2023-07-25 19:32:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.0) (writing took 27.855200013145804 seconds)
2023-07-25 19:33:35 | INFO | train_inner | epoch 025:    738 / 1474 loss=1.999, trans_loss=4.986, nll_loss=2.176, w2v_ctc_loss=0.647, task_loss=1.415, contrastive_loss=0.137, total=4126.89, n_correct=2677.5, ppl=4.52, accuracy=64.879, wps=6604.2, ups=0.8, wpb=8253.8, bsz=300.9, num_updates=36100, lr=7.44323e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=29608
2023-07-25 19:34:43 | INFO | train_inner | epoch 025:    838 / 1474 loss=1.987, trans_loss=4.985, nll_loss=2.176, w2v_ctc_loss=0.641, task_loss=1.277, contrastive_loss=0.085, total=4199.63, n_correct=2728.7, ppl=4.52, accuracy=64.975, wps=12395.9, ups=1.48, wpb=8399.3, bsz=329, num_updates=36200, lr=7.43294e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=67, gb_free=16, wall=29676
2023-07-25 19:35:52 | INFO | train_inner | epoch 025:    938 / 1474 loss=1.999, trans_loss=4.993, nll_loss=2.187, w2v_ctc_loss=0.649, task_loss=1.344, contrastive_loss=0.141, total=4134.29, n_correct=2679.32, ppl=4.55, accuracy=64.807, wps=12030.3, ups=1.45, wpb=8268.6, bsz=312.8, num_updates=36300, lr=7.4227e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=29744
2023-07-25 19:37:00 | INFO | train_inner | epoch 025:   1038 / 1474 loss=2.005, trans_loss=5, nll_loss=2.195, w2v_ctc_loss=0.639, task_loss=1.383, contrastive_loss=0.251, total=4184.54, n_correct=2707.04, ppl=4.58, accuracy=64.691, wps=12267.4, ups=1.47, wpb=8369.1, bsz=311.2, num_updates=36400, lr=7.41249e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=29813
2023-07-25 19:38:08 | INFO | train_inner | epoch 025:   1138 / 1474 loss=1.992, trans_loss=4.994, nll_loss=2.185, w2v_ctc_loss=0.637, task_loss=1.513, contrastive_loss=0.054, total=4042.38, n_correct=2617.98, ppl=4.55, accuracy=64.763, wps=11903.6, ups=1.47, wpb=8084.8, bsz=286.2, num_updates=36500, lr=7.40233e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=29881
2023-07-25 19:39:16 | INFO | train_inner | epoch 025:   1238 / 1474 loss=1.996, trans_loss=4.999, nll_loss=2.193, w2v_ctc_loss=0.645, task_loss=1.437, contrastive_loss=0.058, total=4077.76, n_correct=2637.89, ppl=4.57, accuracy=64.69, wps=12044.1, ups=1.48, wpb=8155.5, bsz=291.8, num_updates=36600, lr=7.39221e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=29948
2023-07-25 19:40:24 | INFO | train_inner | epoch 025:   1338 / 1474 loss=2.001, trans_loss=4.994, nll_loss=2.187, w2v_ctc_loss=0.649, task_loss=1.357, contrastive_loss=0.164, total=4169.44, n_correct=2699.6, ppl=4.55, accuracy=64.747, wps=12197.1, ups=1.46, wpb=8338.9, bsz=311.7, num_updates=36700, lr=7.38213e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=30017
2023-07-25 19:41:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 19:41:34 | INFO | train_inner | epoch 025:   1439 / 1474 loss=2.008, trans_loss=5.012, nll_loss=2.21, w2v_ctc_loss=0.653, task_loss=1.432, contrastive_loss=0.111, total=4110.44, n_correct=2646.28, ppl=4.63, accuracy=64.379, wps=11846.4, ups=1.44, wpb=8220.9, bsz=301.7, num_updates=36800, lr=7.3721e-05, gnorm=0.599, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=30086
2023-07-25 19:41:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 19:42:21 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.182 | trans_loss 5.564 | nll_loss 2.841 | w2v_ctc_loss 1.288 | task_loss 4.621 | contrastive_loss 0.266 | total 4003.4 | n_correct 2488.7 | ppl 7.16 | accuracy 62.165 | uer 16.776 | wer 18.739 | raw_wer 18.739 | bleu 20.21 | wps 2186.3 | wpb 4003.4 | bsz 141.8 | num_updates 36835 | best_bleu 20.21
2023-07-25 19:42:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36835 updates
2023-07-25 19:42:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 19:42:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 19:42:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 25 @ 36835 updates, score 20.21) (writing took 19.889945408329368 seconds)
2023-07-25 19:42:41 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-25 19:42:41 | INFO | train | epoch 025 | loss 1.996 | trans_loss 4.989 | nll_loss 2.179 | w2v_ctc_loss 0.646 | task_loss 1.398 | contrastive_loss 0.117 | total 4138.78 | n_correct 2683.56 | ppl 4.53 | accuracy 64.84 | wps 10899.9 | ups 1.32 | wpb 8277.6 | bsz 305.7 | num_updates 36835 | lr 7.36859e-05 | gnorm 0.58 | clip 0 | loss_scale 32 | train_wall 1001 | gb_free 14.2 | wall 30154
2023-07-25 19:42:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 19:42:42 | INFO | fairseq.trainer | begin training epoch 26
2023-07-25 19:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 19:43:35 | INFO | train_inner | epoch 026:     65 / 1474 loss=1.981, trans_loss=4.969, nll_loss=2.154, w2v_ctc_loss=0.635, task_loss=1.323, contrastive_loss=0.097, total=4178.19, n_correct=2725.27, ppl=4.45, accuracy=65.226, wps=6859.9, ups=0.82, wpb=8356.4, bsz=317.5, num_updates=36900, lr=7.3621e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=68, gb_free=14.2, wall=30208
2023-07-25 19:44:44 | INFO | train_inner | epoch 026:    165 / 1474 loss=1.986, trans_loss=4.964, nll_loss=2.148, w2v_ctc_loss=0.625, task_loss=1.226, contrastive_loss=0.279, total=4269.55, n_correct=2792.43, ppl=4.43, accuracy=65.403, wps=12394.7, ups=1.45, wpb=8539.1, bsz=341.4, num_updates=37000, lr=7.35215e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=30277
2023-07-25 19:45:52 | INFO | train_inner | epoch 026:    265 / 1474 loss=1.991, trans_loss=4.969, nll_loss=2.153, w2v_ctc_loss=0.644, task_loss=1.384, contrastive_loss=0.155, total=4128.39, n_correct=2688.88, ppl=4.45, accuracy=65.131, wps=12114.4, ups=1.47, wpb=8256.8, bsz=306.8, num_updates=37100, lr=7.34223e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=68, gb_free=9.8, wall=30345
2023-07-25 19:47:01 | INFO | train_inner | epoch 026:    365 / 1474 loss=1.986, trans_loss=4.969, nll_loss=2.154, w2v_ctc_loss=0.641, task_loss=1.342, contrastive_loss=0.115, total=4166.22, n_correct=2714.85, ppl=4.45, accuracy=65.163, wps=12180.9, ups=1.46, wpb=8332.4, bsz=315, num_updates=37200, lr=7.33236e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=30413
2023-07-25 19:47:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-25 19:48:10 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.98, trans_loss=4.965, nll_loss=2.147, w2v_ctc_loss=0.638, task_loss=1.377, contrastive_loss=0.065, total=4141.98, n_correct=2706.32, ppl=4.43, accuracy=65.339, wps=12008.7, ups=1.45, wpb=8284, bsz=305.9, num_updates=37300, lr=7.32252e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=69, gb_free=17.7, wall=30482
2023-07-25 19:49:19 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.993, trans_loss=4.98, nll_loss=2.168, w2v_ctc_loss=0.654, task_loss=1.415, contrastive_loss=0.078, total=4155.02, n_correct=2698.09, ppl=4.49, accuracy=64.936, wps=12086.9, ups=1.45, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.593, clip=0, loss_scale=16, train_wall=68, gb_free=17.8, wall=30551
2023-07-25 19:50:27 | INFO | train_inner | epoch 026:    666 / 1474 loss=1.985, trans_loss=4.979, nll_loss=2.166, w2v_ctc_loss=0.635, task_loss=1.43, contrastive_loss=0.063, total=4136.96, n_correct=2690.95, ppl=4.49, accuracy=65.047, wps=12068.2, ups=1.46, wpb=8273.9, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=30620
2023-07-25 19:51:36 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.997, trans_loss=4.984, nll_loss=2.173, w2v_ctc_loss=0.64, task_loss=1.424, contrastive_loss=0.178, total=4086.28, n_correct=2654.14, ppl=4.51, accuracy=64.952, wps=11958.5, ups=1.46, wpb=8172.6, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=68, gb_free=15, wall=30688
2023-07-25 19:52:44 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.991, trans_loss=4.981, nll_loss=2.169, w2v_ctc_loss=0.647, task_loss=1.385, contrastive_loss=0.078, total=4183.26, n_correct=2715.91, ppl=4.5, accuracy=64.923, wps=12269.7, ups=1.47, wpb=8366.5, bsz=308.1, num_updates=37700, lr=7.28357e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=30756
2023-07-25 19:53:52 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.994, trans_loss=4.992, nll_loss=2.183, w2v_ctc_loss=0.634, task_loss=1.45, contrastive_loss=0.132, total=4137.96, n_correct=2679.91, ppl=4.54, accuracy=64.764, wps=12105.2, ups=1.46, wpb=8275.9, bsz=299, num_updates=37800, lr=7.27393e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=30825
2023-07-25 19:55:00 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.989, trans_loss=4.985, nll_loss=2.175, w2v_ctc_loss=0.641, task_loss=1.47, contrastive_loss=0.06, total=4120.53, n_correct=2680.24, ppl=4.52, accuracy=65.046, wps=12111.9, ups=1.47, wpb=8241.1, bsz=294.3, num_updates=37900, lr=7.26433e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=30893
2023-07-25 19:56:09 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.996, trans_loss=4.993, nll_loss=2.184, w2v_ctc_loss=0.643, task_loss=1.463, contrastive_loss=0.101, total=4113.86, n_correct=2663.3, ppl=4.55, accuracy=64.74, wps=12024.1, ups=1.46, wpb=8227.7, bsz=298.5, num_updates=38000, lr=7.25476e-05, gnorm=0.596, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=30961
2023-07-25 19:56:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 19:56:33 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.197 | trans_loss 5.574 | nll_loss 2.849 | w2v_ctc_loss 1.313 | task_loss 4.62 | contrastive_loss 0.26 | total 4003.4 | n_correct 2488.1 | ppl 7.21 | accuracy 62.15 | uer 16.911 | wer 18.724 | raw_wer 18.724 | bleu 19.97 | wps 2013.5 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.21
2023-07-25 19:56:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-25 19:56:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_26_38000.pt
2023-07-25 19:56:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_26_38000.pt
2023-07-25 19:56:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 19.97) (writing took 16.20030841603875 seconds)
2023-07-25 19:58:01 | INFO | train_inner | epoch 026:   1266 / 1474 loss=2.005, trans_loss=5.005, nll_loss=2.2, w2v_ctc_loss=0.659, task_loss=1.564, contrastive_loss=0.064, total=3996.19, n_correct=2576.74, ppl=4.59, accuracy=64.48, wps=7114.5, ups=0.89, wpb=7992.4, bsz=279.3, num_updates=38100, lr=7.24524e-05, gnorm=0.593, clip=0, loss_scale=16, train_wall=68, gb_free=17.7, wall=31073
2023-07-25 19:59:10 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.989, trans_loss=4.993, nll_loss=2.186, w2v_ctc_loss=0.634, task_loss=1.394, contrastive_loss=0.08, total=4159.74, n_correct=2698.99, ppl=4.55, accuracy=64.884, wps=12019.7, ups=1.44, wpb=8319.5, bsz=311.4, num_updates=38200, lr=7.23575e-05, gnorm=0.596, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=31143
2023-07-25 20:00:18 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.984, trans_loss=4.989, nll_loss=2.181, w2v_ctc_loss=0.631, task_loss=1.326, contrastive_loss=0.073, total=4165.66, n_correct=2710.38, ppl=4.54, accuracy=65.065, wps=12225.6, ups=1.47, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=31211
2023-07-25 20:00:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 20:00:47 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.202 | trans_loss 5.575 | nll_loss 2.854 | w2v_ctc_loss 1.329 | task_loss 4.588 | contrastive_loss 0.261 | total 4003.4 | n_correct 2484.2 | ppl 7.23 | accuracy 62.052 | uer 16.935 | wer 18.758 | raw_wer 18.758 | bleu 19.93 | wps 2240 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.21
2023-07-25 20:00:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-07-25 20:00:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.9307.pt
2023-07-25 20:00:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.9307.pt
2023-07-25 20:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_19.9307.pt (epoch 26 @ 38308 updates, score 19.93) (writing took 14.98293468914926 seconds)
2023-07-25 20:01:02 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-25 20:01:02 | INFO | train | epoch 026 | loss 1.99 | trans_loss 4.98 | nll_loss 2.168 | w2v_ctc_loss 0.64 | task_loss 1.403 | contrastive_loss 0.109 | total 4137.07 | n_correct 2689.8 | ppl 4.5 | accuracy 65.017 | wps 11075.2 | ups 1.34 | wpb 8274.1 | bsz 305.1 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.584 | clip 0 | loss_scale 16 | train_wall 1001 | gb_free 15.9 | wall 31254
2023-07-25 20:01:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 20:01:02 | INFO | fairseq.trainer | begin training epoch 27
2023-07-25 20:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 20:02:13 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.971, trans_loss=4.948, nll_loss=2.124, w2v_ctc_loss=0.624, task_loss=1.506, contrastive_loss=0.049, total=4054.57, n_correct=2662.62, ppl=4.36, accuracy=65.67, wps=7089.1, ups=0.87, wpb=8109.1, bsz=282.4, num_updates=38400, lr=7.21688e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=67, gb_free=16.2, wall=31325
2023-07-25 20:03:21 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.971, trans_loss=4.95, nll_loss=2.129, w2v_ctc_loss=0.633, task_loss=1.331, contrastive_loss=0.083, total=4195.2, n_correct=2755.26, ppl=4.37, accuracy=65.676, wps=12283.4, ups=1.46, wpb=8390.4, bsz=323.2, num_updates=38500, lr=7.2075e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=31393
2023-07-25 20:04:30 | INFO | train_inner | epoch 027:    292 / 1474 loss=1.976, trans_loss=4.96, nll_loss=2.141, w2v_ctc_loss=0.633, task_loss=1.401, contrastive_loss=0.063, total=4162.23, n_correct=2727.53, ppl=4.41, accuracy=65.53, wps=12000.3, ups=1.44, wpb=8324.5, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=31463
2023-07-25 20:05:40 | INFO | train_inner | epoch 027:    392 / 1474 loss=1.993, trans_loss=4.97, nll_loss=2.154, w2v_ctc_loss=0.631, task_loss=1.467, contrastive_loss=0.248, total=4079.05, n_correct=2660.85, ppl=4.45, accuracy=65.232, wps=11754, ups=1.44, wpb=8158.1, bsz=297.1, num_updates=38700, lr=7.18885e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=31532
2023-07-25 20:06:48 | INFO | train_inner | epoch 027:    492 / 1474 loss=1.989, trans_loss=4.975, nll_loss=2.163, w2v_ctc_loss=0.633, task_loss=1.286, contrastive_loss=0.189, total=4243.25, n_correct=2762.57, ppl=4.48, accuracy=65.105, wps=12367.1, ups=1.46, wpb=8486.5, bsz=331, num_updates=38800, lr=7.17958e-05, gnorm=0.596, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=31601
2023-07-25 20:07:57 | INFO | train_inner | epoch 027:    592 / 1474 loss=1.985, trans_loss=4.969, nll_loss=2.154, w2v_ctc_loss=0.637, task_loss=1.362, contrastive_loss=0.125, total=4137.92, n_correct=2700.93, ppl=4.45, accuracy=65.273, wps=11994.4, ups=1.45, wpb=8275.8, bsz=313.5, num_updates=38900, lr=7.17035e-05, gnorm=0.593, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=31670
2023-07-25 20:09:06 | INFO | train_inner | epoch 027:    692 / 1474 loss=1.989, trans_loss=4.978, nll_loss=2.166, w2v_ctc_loss=0.641, task_loss=1.406, contrastive_loss=0.101, total=4158.48, n_correct=2706.4, ppl=4.49, accuracy=65.081, wps=12150.6, ups=1.46, wpb=8317, bsz=304.1, num_updates=39000, lr=7.16115e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=31738
2023-07-25 20:10:14 | INFO | train_inner | epoch 027:    792 / 1474 loss=1.987, trans_loss=4.977, nll_loss=2.164, w2v_ctc_loss=0.642, task_loss=1.486, contrastive_loss=0.064, total=4100.88, n_correct=2667.03, ppl=4.48, accuracy=65.036, wps=12068.4, ups=1.47, wpb=8201.8, bsz=292.2, num_updates=39100, lr=7.15199e-05, gnorm=0.603, clip=0, loss_scale=16, train_wall=67, gb_free=15.6, wall=31806
2023-07-25 20:11:22 | INFO | train_inner | epoch 027:    892 / 1474 loss=1.98, trans_loss=4.98, nll_loss=2.167, w2v_ctc_loss=0.627, task_loss=1.447, contrastive_loss=0.055, total=4111.94, n_correct=2685.13, ppl=4.49, accuracy=65.301, wps=12025.1, ups=1.46, wpb=8223.9, bsz=294.9, num_updates=39200, lr=7.14286e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=31875
2023-07-25 20:12:32 | INFO | train_inner | epoch 027:    992 / 1474 loss=1.99, trans_loss=4.974, nll_loss=2.161, w2v_ctc_loss=0.631, task_loss=1.361, contrastive_loss=0.244, total=4189.27, n_correct=2729.49, ppl=4.47, accuracy=65.154, wps=12059.7, ups=1.44, wpb=8378.5, bsz=314.9, num_updates=39300, lr=7.13376e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=69, gb_free=14.2, wall=31944
2023-07-25 20:13:40 | INFO | train_inner | epoch 027:   1092 / 1474 loss=1.977, trans_loss=4.973, nll_loss=2.159, w2v_ctc_loss=0.625, task_loss=1.394, contrastive_loss=0.076, total=4160.42, n_correct=2714.05, ppl=4.47, accuracy=65.235, wps=12119, ups=1.46, wpb=8320.8, bsz=307.3, num_updates=39400, lr=7.1247e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=32013
2023-07-25 20:14:49 | INFO | train_inner | epoch 027:   1192 / 1474 loss=1.992, trans_loss=4.982, nll_loss=2.172, w2v_ctc_loss=0.647, task_loss=1.469, contrastive_loss=0.08, total=4103.72, n_correct=2663.56, ppl=4.51, accuracy=64.906, wps=11937.7, ups=1.45, wpb=8207.4, bsz=297.1, num_updates=39500, lr=7.11568e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=32082
2023-07-25 20:15:57 | INFO | train_inner | epoch 027:   1292 / 1474 loss=1.996, trans_loss=4.989, nll_loss=2.18, w2v_ctc_loss=0.639, task_loss=1.497, contrastive_loss=0.129, total=4065.94, n_correct=2637.21, ppl=4.53, accuracy=64.861, wps=11916.9, ups=1.47, wpb=8131.9, bsz=292.4, num_updates=39600, lr=7.10669e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=32150
2023-07-25 20:17:05 | INFO | train_inner | epoch 027:   1392 / 1474 loss=1.982, trans_loss=4.98, nll_loss=2.169, w2v_ctc_loss=0.628, task_loss=1.322, contrastive_loss=0.113, total=4149.21, n_correct=2705.41, ppl=4.5, accuracy=65.203, wps=12292.8, ups=1.48, wpb=8298.4, bsz=312.6, num_updates=39700, lr=7.09773e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=32217
2023-07-25 20:18:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 20:18:24 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.187 | trans_loss 5.567 | nll_loss 2.842 | w2v_ctc_loss 1.302 | task_loss 4.619 | contrastive_loss 0.255 | total 4003.4 | n_correct 2486.6 | ppl 7.17 | accuracy 62.112 | uer 17.01 | wer 18.884 | raw_wer 18.884 | bleu 20.18 | wps 2203.6 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 20.21
2023-07-25 20:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-07-25 20:18:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_20.1806.pt
2023-07-25 20:18:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_20.1806.pt
2023-07-25 20:18:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_20.1806.pt (epoch 27 @ 39782 updates, score 20.18) (writing took 12.624402772635221 seconds)
2023-07-25 20:18:37 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-25 20:18:37 | INFO | train | epoch 027 | loss 1.984 | trans_loss 4.972 | nll_loss 2.158 | w2v_ctc_loss 0.633 | task_loss 1.401 | contrastive_loss 0.114 | total 4138.65 | n_correct 2699.88 | ppl 4.46 | accuracy 65.236 | wps 11567.1 | ups 1.4 | wpb 8277.3 | bsz 305.7 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.583 | clip 0 | loss_scale 32 | train_wall 1002 | gb_free 17.8 | wall 32309
2023-07-25 20:18:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 20:18:37 | INFO | fairseq.trainer | begin training epoch 28
2023-07-25 20:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 20:18:58 | INFO | train_inner | epoch 028:     18 / 1474 loss=1.976, trans_loss=4.972, nll_loss=2.158, w2v_ctc_loss=0.628, task_loss=1.357, contrastive_loss=0.064, total=4106.72, n_correct=2682.75, ppl=4.46, accuracy=65.326, wps=7271.3, ups=0.89, wpb=8213.4, bsz=305, num_updates=39800, lr=7.08881e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=32330
2023-07-25 20:20:07 | INFO | train_inner | epoch 028:    118 / 1474 loss=1.969, trans_loss=4.943, nll_loss=2.119, w2v_ctc_loss=0.627, task_loss=1.469, contrastive_loss=0.06, total=4103.42, n_correct=2698.96, ppl=4.34, accuracy=65.773, wps=11802.2, ups=1.44, wpb=8206.8, bsz=292, num_updates=39900, lr=7.07992e-05, gnorm=0.601, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=32400
2023-07-25 20:21:16 | INFO | train_inner | epoch 028:    218 / 1474 loss=1.965, trans_loss=4.948, nll_loss=2.126, w2v_ctc_loss=0.621, task_loss=1.312, contrastive_loss=0.069, total=4200.12, n_correct=2763.73, ppl=4.37, accuracy=65.801, wps=12208.2, ups=1.45, wpb=8400.2, bsz=317.8, num_updates=40000, lr=7.07107e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=10.8, wall=32469
2023-07-25 20:21:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 20:21:39 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.212 | trans_loss 5.579 | nll_loss 2.855 | w2v_ctc_loss 1.357 | task_loss 4.595 | contrastive_loss 0.259 | total 4003.4 | n_correct 2481.5 | ppl 7.24 | accuracy 61.985 | uer 17.065 | wer 18.814 | raw_wer 18.814 | bleu 20.16 | wps 2257.7 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.21
2023-07-25 20:21:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-25 20:21:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_28_40000.pt
2023-07-25 20:21:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_28_40000.pt
2023-07-25 20:21:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.16) (writing took 14.470510303974152 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:0')
2023-07-25 20:23:05 | INFO | train_inner | epoch 028:    318 / 1474 loss=1.994, trans_loss=4.96, nll_loss=2.142, w2v_ctc_loss=0.619, task_loss=1.395, contrastive_loss=0.4, total=4147.36, n_correct=2704.42, ppl=4.41, accuracy=65.208, wps=7656.5, ups=0.92, wpb=8294.7, bsz=315.4, num_updates=40100, lr=7.06225e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=32577
2023-07-25 20:24:14 | INFO | train_inner | epoch 028:    418 / 1474 loss=1.976, trans_loss=4.958, nll_loss=2.138, w2v_ctc_loss=0.633, task_loss=1.448, contrastive_loss=0.055, total=4087.34, n_correct=2682.38, ppl=4.4, accuracy=65.627, wps=11850, ups=1.45, wpb=8174.7, bsz=295.1, num_updates=40200, lr=7.05346e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=32646
2023-07-25 20:25:22 | INFO | train_inner | epoch 028:    518 / 1474 loss=1.974, trans_loss=4.96, nll_loss=2.141, w2v_ctc_loss=0.624, task_loss=1.452, contrastive_loss=0.067, total=4099.71, n_correct=2684.65, ppl=4.41, accuracy=65.484, wps=12054.7, ups=1.47, wpb=8199.4, bsz=296.2, num_updates=40300, lr=7.0447e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=32714
2023-07-25 20:26:29 | INFO | train_inner | epoch 028:    618 / 1474 loss=1.98, trans_loss=4.97, nll_loss=2.155, w2v_ctc_loss=0.632, task_loss=1.419, contrastive_loss=0.069, total=4177.06, n_correct=2727.64, ppl=4.45, accuracy=65.3, wps=12316.9, ups=1.47, wpb=8354.1, bsz=304.1, num_updates=40400, lr=7.03598e-05, gnorm=0.592, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=32782
2023-07-25 20:27:38 | INFO | train_inner | epoch 028:    718 / 1474 loss=1.981, trans_loss=4.969, nll_loss=2.155, w2v_ctc_loss=0.625, task_loss=1.26, contrastive_loss=0.18, total=4190.74, n_correct=2740.53, ppl=4.45, accuracy=65.395, wps=12235.4, ups=1.46, wpb=8381.5, bsz=328.5, num_updates=40500, lr=7.02728e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=32850
2023-07-25 20:28:46 | INFO | train_inner | epoch 028:    818 / 1474 loss=1.971, trans_loss=4.966, nll_loss=2.15, w2v_ctc_loss=0.623, task_loss=1.384, contrastive_loss=0.059, total=4091.75, n_correct=2679.88, ppl=4.44, accuracy=65.495, wps=12087.5, ups=1.48, wpb=8183.5, bsz=306, num_updates=40600, lr=7.01862e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=32918
2023-07-25 20:29:54 | INFO | train_inner | epoch 028:    918 / 1474 loss=1.988, trans_loss=4.976, nll_loss=2.163, w2v_ctc_loss=0.635, task_loss=1.442, contrastive_loss=0.123, total=4123.89, n_correct=2685.23, ppl=4.48, accuracy=65.114, wps=12067.5, ups=1.46, wpb=8247.8, bsz=301, num_updates=40700, lr=7.01e-05, gnorm=0.594, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=32986
2023-07-25 20:31:02 | INFO | train_inner | epoch 028:   1018 / 1474 loss=1.993, trans_loss=4.976, nll_loss=2.164, w2v_ctc_loss=0.64, task_loss=1.362, contrastive_loss=0.177, total=4176.06, n_correct=2717.73, ppl=4.48, accuracy=65.079, wps=12235.7, ups=1.46, wpb=8352.1, bsz=311.4, num_updates=40800, lr=7.0014e-05, gnorm=0.601, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=33055
2023-07-25 20:32:11 | INFO | train_inner | epoch 028:   1118 / 1474 loss=1.973, trans_loss=4.964, nll_loss=2.149, w2v_ctc_loss=0.624, task_loss=1.36, contrastive_loss=0.081, total=4206.08, n_correct=2753.51, ppl=4.43, accuracy=65.465, wps=12277.3, ups=1.46, wpb=8412.2, bsz=317.3, num_updates=40900, lr=6.99284e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=33123
2023-07-25 20:33:19 | INFO | train_inner | epoch 028:   1218 / 1474 loss=1.975, trans_loss=4.97, nll_loss=2.157, w2v_ctc_loss=0.624, task_loss=1.378, contrastive_loss=0.069, total=4109.72, n_correct=2686.7, ppl=4.46, accuracy=65.374, wps=12125.5, ups=1.48, wpb=8219.4, bsz=306.9, num_updates=41000, lr=6.9843e-05, gnorm=0.586, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=33191
2023-07-25 20:34:27 | INFO | train_inner | epoch 028:   1318 / 1474 loss=1.991, trans_loss=4.981, nll_loss=2.169, w2v_ctc_loss=0.644, task_loss=1.523, contrastive_loss=0.081, total=4085.44, n_correct=2656.28, ppl=4.5, accuracy=65.018, wps=11908.2, ups=1.46, wpb=8170.9, bsz=285.6, num_updates=41100, lr=6.9758e-05, gnorm=0.587, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=33260
2023-07-25 20:35:36 | INFO | train_inner | epoch 028:   1418 / 1474 loss=1.985, trans_loss=4.979, nll_loss=2.166, w2v_ctc_loss=0.629, task_loss=1.485, contrastive_loss=0.101, total=4137.47, n_correct=2692.02, ppl=4.49, accuracy=65.064, wps=12103.3, ups=1.46, wpb=8274.9, bsz=294.8, num_updates=41200, lr=6.96733e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=33328
2023-07-25 20:36:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:1')
2023-07-25 20:36:36 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.195 | trans_loss 5.574 | nll_loss 2.848 | w2v_ctc_loss 1.31 | task_loss 4.591 | contrastive_loss 0.257 | total 4003.4 | n_correct 2487.2 | ppl 7.2 | accuracy 62.127 | uer 16.938 | wer 18.94 | raw_wer 18.94 | bleu 19.9 | wps 2223.5 | wpb 4003.4 | bsz 141.8 | num_updates 41256 | best_bleu 20.21
2023-07-25 20:36:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41256 updates
2023-07-25 20:36:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_last.pt
2023-07-25 20:36:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_last.pt
2023-07-25 20:36:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_last.pt (epoch 28 @ 41256 updates, score 19.9) (writing took 11.04886545240879 seconds)
2023-07-25 20:36:47 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-25 20:36:47 | INFO | train | epoch 028 | loss 1.979 | trans_loss 4.965 | nll_loss 2.149 | w2v_ctc_loss 0.629 | task_loss 1.399 | contrastive_loss 0.113 | total 4138.65 | n_correct 2705.97 | ppl 4.44 | accuracy 65.383 | wps 11186.2 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 41256 | lr 6.9626e-05 | gnorm 0.587 | clip 0 | loss_scale 32 | train_wall 1001 | gb_free 16.4 | wall 33400
2023-07-25 20:36:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 20:36:48 | INFO | fairseq.trainer | begin training epoch 29
2023-07-25 20:36:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 20:37:26 | INFO | train_inner | epoch 029:     44 / 1474 loss=1.97, trans_loss=4.952, nll_loss=2.132, w2v_ctc_loss=0.631, task_loss=1.344, contrastive_loss=0.074, total=4168.25, n_correct=2740.12, ppl=4.38, accuracy=65.738, wps=7564.8, ups=0.91, wpb=8336.5, bsz=315.7, num_updates=41300, lr=6.95889e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=67, gb_free=17.7, wall=33438
2023-07-25 20:38:34 | INFO | train_inner | epoch 029:    144 / 1474 loss=1.97, trans_loss=4.947, nll_loss=2.125, w2v_ctc_loss=0.624, task_loss=1.37, contrastive_loss=0.107, total=4117.66, n_correct=2707.06, ppl=4.36, accuracy=65.743, wps=12091.8, ups=1.47, wpb=8235.3, bsz=308.4, num_updates=41400, lr=6.95048e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=68, gb_free=17.2, wall=33506
2023-07-25 20:39:43 | INFO | train_inner | epoch 029:    244 / 1474 loss=1.965, trans_loss=4.94, nll_loss=2.118, w2v_ctc_loss=0.609, task_loss=1.273, contrastive_loss=0.182, total=4198.99, n_correct=2763.41, ppl=4.34, accuracy=65.811, wps=12232.2, ups=1.46, wpb=8398, bsz=330.7, num_updates=41500, lr=6.9421e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=68, gb_free=15.2, wall=33575
2023-07-25 20:40:51 | INFO | train_inner | epoch 029:    344 / 1474 loss=1.977, trans_loss=4.96, nll_loss=2.142, w2v_ctc_loss=0.635, task_loss=1.504, contrastive_loss=0.062, total=4091.28, n_correct=2680.7, ppl=4.41, accuracy=65.522, wps=11939.1, ups=1.46, wpb=8182.6, bsz=290.4, num_updates=41600, lr=6.93375e-05, gnorm=0.611, clip=0, loss_scale=64, train_wall=68, gb_free=17.3, wall=33644
2023-07-25 20:41:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-25 20:42:00 | INFO | train_inner | epoch 029:    445 / 1474 loss=1.96, trans_loss=4.937, nll_loss=2.111, w2v_ctc_loss=0.619, task_loss=1.364, contrastive_loss=0.054, total=4156.67, n_correct=2741.33, ppl=4.32, accuracy=65.95, wps=12059.8, ups=1.45, wpb=8313.3, bsz=306.5, num_updates=41700, lr=6.92543e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=33712
2023-07-25 20:43:09 | INFO | train_inner | epoch 029:    545 / 1474 loss=1.981, trans_loss=4.96, nll_loss=2.142, w2v_ctc_loss=0.623, task_loss=1.479, contrastive_loss=0.153, total=4159.68, n_correct=2721.92, ppl=4.41, accuracy=65.436, wps=12089.7, ups=1.45, wpb=8319.4, bsz=296.5, num_updates=41800, lr=6.91714e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=33781
2023-07-25 20:44:17 | INFO | train_inner | epoch 029:    645 / 1474 loss=1.971, trans_loss=4.948, nll_loss=2.129, w2v_ctc_loss=0.616, task_loss=1.324, contrastive_loss=0.22, total=4143.76, n_correct=2725.55, ppl=4.37, accuracy=65.775, wps=12086.4, ups=1.46, wpb=8287.5, bsz=318.8, num_updates=41900, lr=6.90889e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=33850
2023-07-25 20:45:26 | INFO | train_inner | epoch 029:    745 / 1474 loss=1.967, trans_loss=4.949, nll_loss=2.129, w2v_ctc_loss=0.614, task_loss=1.298, contrastive_loss=0.143, total=4234.8, n_correct=2783.82, ppl=4.37, accuracy=65.737, wps=12347.3, ups=1.46, wpb=8469.6, bsz=328.1, num_updates=42000, lr=6.90066e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=33918
2023-07-25 20:45:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 20:45:49 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.573 | nll_loss 2.847 | w2v_ctc_loss 1.345 | task_loss 4.626 | contrastive_loss 0.266 | total 4003.4 | n_correct 2485.3 | ppl 7.2 | accuracy 62.08 | uer 16.975 | wer 18.75 | raw_wer 18.75 | bleu 19.91 | wps 2295.1 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.21
2023-07-25 20:45:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-25 20:45:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_29_42000.pt
2023-07-25 20:45:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_29_42000.pt
2023-07-25 20:46:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 19.91) (writing took 13.55048755928874 seconds)
2023-07-25 20:46:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-25 20:47:12 | INFO | train_inner | epoch 029:    846 / 1474 loss=1.981, trans_loss=4.975, nll_loss=2.16, w2v_ctc_loss=0.628, task_loss=1.554, contrastive_loss=0.054, total=4038.53, n_correct=2634.06, ppl=4.47, accuracy=65.223, wps=7616.2, ups=0.94, wpb=8077.1, bsz=281.8, num_updates=42100, lr=6.89246e-05, gnorm=0.611, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=34025
2023-07-25 20:48:20 | INFO | train_inner | epoch 029:    946 / 1474 loss=1.978, trans_loss=4.971, nll_loss=2.157, w2v_ctc_loss=0.63, task_loss=1.425, contrastive_loss=0.067, total=4082.14, n_correct=2669.54, ppl=4.46, accuracy=65.396, wps=11963.3, ups=1.47, wpb=8164.3, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=34093
2023-07-25 20:49:28 | INFO | train_inner | epoch 029:   1046 / 1474 loss=1.973, trans_loss=4.957, nll_loss=2.139, w2v_ctc_loss=0.619, task_loss=1.393, contrastive_loss=0.141, total=4148.18, n_correct=2720.53, ppl=4.4, accuracy=65.584, wps=12218, ups=1.47, wpb=8296.4, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=67, gb_free=15.9, wall=34161
2023-07-25 20:50:36 | INFO | train_inner | epoch 029:   1146 / 1474 loss=1.98, trans_loss=4.973, nll_loss=2.159, w2v_ctc_loss=0.631, task_loss=1.533, contrastive_loss=0.049, total=4063.95, n_correct=2650.53, ppl=4.47, accuracy=65.221, wps=11946.5, ups=1.47, wpb=8127.9, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=68, gb_free=13.2, wall=34229
2023-07-25 20:51:45 | INFO | train_inner | epoch 029:   1246 / 1474 loss=1.978, trans_loss=4.972, nll_loss=2.159, w2v_ctc_loss=0.631, task_loss=1.419, contrastive_loss=0.059, total=4158.81, n_correct=2720.43, ppl=4.47, accuracy=65.414, wps=12103.2, ups=1.46, wpb=8317.6, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=34297
2023-07-25 20:52:53 | INFO | train_inner | epoch 029:   1346 / 1474 loss=1.977, trans_loss=4.965, nll_loss=2.149, w2v_ctc_loss=0.622, task_loss=1.375, contrastive_loss=0.127, total=4166.34, n_correct=2728.13, ppl=4.44, accuracy=65.48, wps=12180, ups=1.46, wpb=8332.7, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=68, gb_free=17.8, wall=34366
2023-07-25 20:54:01 | INFO | train_inner | epoch 029:   1446 / 1474 loss=1.98, trans_loss=4.965, nll_loss=2.151, w2v_ctc_loss=0.627, task_loss=1.37, contrastive_loss=0.152, total=4162.2, n_correct=2720.75, ppl=4.44, accuracy=65.368, wps=12231.4, ups=1.47, wpb=8324.4, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=34434
2023-07-25 20:54:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 20:54:45 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.196 | trans_loss 5.566 | nll_loss 2.84 | w2v_ctc_loss 1.329 | task_loss 4.603 | contrastive_loss 0.262 | total 4003.4 | n_correct 2491.6 | ppl 7.16 | accuracy 62.237 | uer 16.784 | wer 18.538 | raw_wer 18.538 | bleu 20.28 | wps 2038.9 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 20.28
2023-07-25 20:54:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-07-25 20:54:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 20:54:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 20:55:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 29 @ 42728 updates, score 20.28) (writing took 19.929718863219023 seconds)
2023-07-25 20:55:05 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-25 20:55:05 | INFO | train | epoch 029 | loss 1.974 | trans_loss 4.958 | nll_loss 2.14 | w2v_ctc_loss 0.623 | task_loss 1.399 | contrastive_loss 0.112 | total 4138.71 | n_correct 2713.46 | ppl 4.41 | accuracy 65.563 | wps 11099.5 | ups 1.34 | wpb 8277.4 | bsz 305.7 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.587 | clip 0 | loss_scale 16 | train_wall 1000 | gb_free 16 | wall 34498
2023-07-25 20:55:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 20:55:05 | INFO | fairseq.trainer | begin training epoch 30
2023-07-25 20:55:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 20:56:04 | INFO | train_inner | epoch 030:     72 / 1474 loss=1.965, trans_loss=4.941, nll_loss=2.118, w2v_ctc_loss=0.61, task_loss=1.323, contrastive_loss=0.171, total=4182.65, n_correct=2753.06, ppl=4.34, accuracy=65.821, wps=6837.4, ups=0.82, wpb=8365.3, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=68, gb_free=13.4, wall=34556
2023-07-25 20:57:12 | INFO | train_inner | epoch 030:    172 / 1474 loss=1.958, trans_loss=4.925, nll_loss=2.097, w2v_ctc_loss=0.617, task_loss=1.313, contrastive_loss=0.104, total=4203.05, n_correct=2783.25, ppl=4.28, accuracy=66.22, wps=12304.9, ups=1.46, wpb=8406.1, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.569, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=34625
2023-07-25 20:58:20 | INFO | train_inner | epoch 030:    272 / 1474 loss=1.967, trans_loss=4.944, nll_loss=2.12, w2v_ctc_loss=0.628, task_loss=1.442, contrastive_loss=0.053, total=4116.93, n_correct=2710.45, ppl=4.35, accuracy=65.837, wps=12084.4, ups=1.47, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.591, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=34693
2023-07-25 20:59:29 | INFO | train_inner | epoch 030:    372 / 1474 loss=1.957, trans_loss=4.935, nll_loss=2.109, w2v_ctc_loss=0.613, task_loss=1.405, contrastive_loss=0.058, total=4173.13, n_correct=2757.31, ppl=4.31, accuracy=66.073, wps=12089.9, ups=1.45, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=69, gb_free=11.7, wall=34762
2023-07-25 21:00:37 | INFO | train_inner | epoch 030:    472 / 1474 loss=1.96, trans_loss=4.939, nll_loss=2.116, w2v_ctc_loss=0.608, task_loss=1.334, contrastive_loss=0.124, total=4135.2, n_correct=2728.66, ppl=4.34, accuracy=65.986, wps=12201.8, ups=1.48, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=67, gb_free=16.8, wall=34830
2023-07-25 21:01:45 | INFO | train_inner | epoch 030:    572 / 1474 loss=1.964, trans_loss=4.949, nll_loss=2.128, w2v_ctc_loss=0.616, task_loss=1.364, contrastive_loss=0.085, total=4168.65, n_correct=2745.42, ppl=4.37, accuracy=65.859, wps=12268.7, ups=1.47, wpb=8337.3, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=67, gb_free=15.8, wall=34897
2023-07-25 21:02:54 | INFO | train_inner | epoch 030:    672 / 1474 loss=1.97, trans_loss=4.949, nll_loss=2.129, w2v_ctc_loss=0.627, task_loss=1.38, contrastive_loss=0.101, total=4183.65, n_correct=2750.41, ppl=4.37, accuracy=65.742, wps=12162, ups=1.45, wpb=8367.3, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=34966
2023-07-25 21:04:02 | INFO | train_inner | epoch 030:    772 / 1474 loss=1.987, trans_loss=4.964, nll_loss=2.148, w2v_ctc_loss=0.636, task_loss=1.429, contrastive_loss=0.179, total=4106.9, n_correct=2685.96, ppl=4.43, accuracy=65.401, wps=11996.5, ups=1.46, wpb=8213.8, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.597, clip=0, loss_scale=16, train_wall=68, gb_free=11.8, wall=35035
2023-07-25 21:05:10 | INFO | train_inner | epoch 030:    872 / 1474 loss=1.968, trans_loss=4.955, nll_loss=2.134, w2v_ctc_loss=0.62, task_loss=1.466, contrastive_loss=0.06, total=4089.18, n_correct=2684.96, ppl=4.39, accuracy=65.66, wps=12003.5, ups=1.47, wpb=8178.4, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=35103
2023-07-25 21:06:19 | INFO | train_inner | epoch 030:    972 / 1474 loss=1.973, trans_loss=4.96, nll_loss=2.142, w2v_ctc_loss=0.625, task_loss=1.412, contrastive_loss=0.081, total=4140.03, n_correct=2713.83, ppl=4.41, accuracy=65.551, wps=12097.7, ups=1.46, wpb=8280.1, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.59, clip=0, loss_scale=16, train_wall=68, gb_free=13.8, wall=35171
2023-07-25 21:07:28 | INFO | train_inner | epoch 030:   1072 / 1474 loss=1.985, trans_loss=4.968, nll_loss=2.152, w2v_ctc_loss=0.63, task_loss=1.567, contrastive_loss=0.146, total=4101.12, n_correct=2678.29, ppl=4.44, accuracy=65.306, wps=11869.4, ups=1.45, wpb=8202.2, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.594, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=35240
2023-07-25 21:08:37 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.967, trans_loss=4.956, nll_loss=2.138, w2v_ctc_loss=0.608, task_loss=1.341, contrastive_loss=0.13, total=4168.22, n_correct=2736.48, ppl=4.4, accuracy=65.651, wps=12108.8, ups=1.45, wpb=8336.4, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.592, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=35309
2023-07-25 21:09:46 | INFO | train_inner | epoch 030:   1272 / 1474 loss=1.978, trans_loss=4.967, nll_loss=2.151, w2v_ctc_loss=0.629, task_loss=1.563, contrastive_loss=0.063, total=4032.74, n_correct=2637.86, ppl=4.44, accuracy=65.411, wps=11736.9, ups=1.46, wpb=8065.5, bsz=281.8, num_updates=44000, lr=6.742e-05, gnorm=0.601, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=35378
2023-07-25 21:09:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 21:10:10 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.576 | nll_loss 2.852 | w2v_ctc_loss 1.338 | task_loss 4.59 | contrastive_loss 0.259 | total 4003.4 | n_correct 2483.5 | ppl 7.22 | accuracy 62.035 | uer 16.824 | wer 18.754 | raw_wer 18.754 | bleu 19.88 | wps 2085.6 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.28
2023-07-25 21:10:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-25 21:10:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_30_44000.pt
2023-07-25 21:10:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_30_44000.pt
2023-07-25 21:10:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 19.88) (writing took 13.877481335774064 seconds)
2023-07-25 21:11:32 | INFO | train_inner | epoch 030:   1372 / 1474 loss=1.963, trans_loss=4.956, nll_loss=2.139, w2v_ctc_loss=0.615, task_loss=1.314, contrastive_loss=0.076, total=4166.96, n_correct=2737.6, ppl=4.41, accuracy=65.698, wps=7803.2, ups=0.94, wpb=8333.9, bsz=322.3, num_updates=44100, lr=6.73435e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=35485
2023-07-25 21:12:40 | INFO | train_inner | epoch 030:   1472 / 1474 loss=1.974, trans_loss=4.961, nll_loss=2.146, w2v_ctc_loss=0.611, task_loss=1.34, contrastive_loss=0.218, total=4125.17, n_correct=2703.54, ppl=4.43, accuracy=65.538, wps=12191.6, ups=1.48, wpb=8250.3, bsz=310, num_updates=44200, lr=6.72673e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=35553
2023-07-25 21:12:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 21:13:04 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.184 | trans_loss 5.57 | nll_loss 2.846 | w2v_ctc_loss 1.282 | task_loss 4.612 | contrastive_loss 0.258 | total 4003.4 | n_correct 2484.3 | ppl 7.19 | accuracy 62.055 | uer 16.879 | wer 19 | raw_wer 19 | bleu 20.09 | wps 2237 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 20.28
2023-07-25 21:13:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-07-25 21:13:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_20.0909.pt
2023-07-25 21:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_20.0909.pt
2023-07-25 21:13:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint.best_bleu_20.0909.pt (epoch 30 @ 44202 updates, score 20.09) (writing took 27.828900502994657 seconds)
2023-07-25 21:13:33 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-25 21:13:33 | INFO | train | epoch 030 | loss 1.969 | trans_loss 4.951 | nll_loss 2.131 | w2v_ctc_loss 0.619 | task_loss 1.399 | contrastive_loss 0.111 | total 4138.65 | n_correct 2720.05 | ppl 4.38 | accuracy 65.723 | wps 11016.6 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.586 | clip 0 | loss_scale 32 | train_wall 1001 | gb_free 17.1 | wall 35605
2023-07-25 21:13:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 21:13:33 | INFO | fairseq.trainer | begin training epoch 31
2023-07-25 21:13:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 21:14:48 | INFO | train_inner | epoch 031:     98 / 1474 loss=1.96, trans_loss=4.932, nll_loss=2.105, w2v_ctc_loss=0.62, task_loss=1.456, contrastive_loss=0.06, total=4081.34, n_correct=2698.56, ppl=4.3, accuracy=66.119, wps=6384.9, ups=0.78, wpb=8162.7, bsz=294.7, num_updates=44300, lr=6.71913e-05, gnorm=0.597, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=35680
2023-07-25 21:15:57 | INFO | train_inner | epoch 031:    198 / 1474 loss=1.962, trans_loss=4.935, nll_loss=2.109, w2v_ctc_loss=0.62, task_loss=1.432, contrastive_loss=0.087, total=4146.03, n_correct=2741.72, ppl=4.31, accuracy=66.129, wps=12061.4, ups=1.45, wpb=8292.1, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.598, clip=0, loss_scale=32, train_wall=68, gb_free=13.3, wall=35749
2023-07-25 21:17:06 | INFO | train_inner | epoch 031:    298 / 1474 loss=1.962, trans_loss=4.933, nll_loss=2.106, w2v_ctc_loss=0.614, task_loss=1.437, contrastive_loss=0.124, total=4146.75, n_correct=2739.66, ppl=4.31, accuracy=66.068, wps=12025.9, ups=1.45, wpb=8293.5, bsz=300.7, num_updates=44500, lr=6.70402e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=35818
2023-07-25 21:18:14 | INFO | train_inner | epoch 031:    398 / 1474 loss=1.966, trans_loss=4.946, nll_loss=2.123, w2v_ctc_loss=0.62, task_loss=1.526, contrastive_loss=0.059, total=4089.43, n_correct=2690.41, ppl=4.36, accuracy=65.789, wps=12041.9, ups=1.47, wpb=8178.9, bsz=285.5, num_updates=44600, lr=6.6965e-05, gnorm=0.613, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=35886
2023-07-25 21:19:22 | INFO | train_inner | epoch 031:    498 / 1474 loss=1.965, trans_loss=4.94, nll_loss=2.116, w2v_ctc_loss=0.627, task_loss=1.46, contrastive_loss=0.071, total=4114.41, n_correct=2710.68, ppl=4.33, accuracy=65.883, wps=11977.8, ups=1.46, wpb=8228.8, bsz=300.9, num_updates=44700, lr=6.689e-05, gnorm=0.637, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=35955
2023-07-25 21:20:30 | INFO | train_inner | epoch 031:    598 / 1474 loss=1.957, trans_loss=4.939, nll_loss=2.115, w2v_ctc_loss=0.608, task_loss=1.456, contrastive_loss=0.059, total=4084.36, n_correct=2696.04, ppl=4.33, accuracy=66.009, wps=12013.5, ups=1.47, wpb=8168.7, bsz=295, num_updates=44800, lr=6.68153e-05, gnorm=0.596, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=36023
2023-07-25 21:21:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-25 21:21:39 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.954, trans_loss=4.936, nll_loss=2.111, w2v_ctc_loss=0.607, task_loss=1.349, contrastive_loss=0.06, total=4206.94, n_correct=2777.98, ppl=4.32, accuracy=66.033, wps=12267.4, ups=1.46, wpb=8413.9, bsz=313.2, num_updates=44900, lr=6.67409e-05, gnorm=0.591, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=36091
2023-07-25 21:22:48 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.973, trans_loss=4.954, nll_loss=2.134, w2v_ctc_loss=0.619, task_loss=1.467, contrastive_loss=0.132, total=4097.37, n_correct=2690.06, ppl=4.39, accuracy=65.653, wps=11795.9, ups=1.44, wpb=8194.7, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.595, clip=0, loss_scale=16, train_wall=69, gb_free=12.9, wall=36161
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:0')
2023-07-25 21:23:57 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.963, trans_loss=4.941, nll_loss=2.118, w2v_ctc_loss=0.617, task_loss=1.457, contrastive_loss=0.077, total=4096.72, n_correct=2697.72, ppl=4.34, accuracy=65.851, wps=11915.8, ups=1.45, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.591, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=36230
2023-07-25 21:25:05 | INFO | train_inner | epoch 031:    999 / 1474 loss=1.969, trans_loss=4.954, nll_loss=2.136, w2v_ctc_loss=0.615, task_loss=1.323, contrastive_loss=0.161, total=4187.84, n_correct=2753.38, ppl=4.39, accuracy=65.747, wps=12311.8, ups=1.47, wpb=8375.7, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.623, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=36298
2023-07-25 21:26:13 | INFO | train_inner | epoch 031:   1099 / 1474 loss=1.966, trans_loss=4.949, nll_loss=2.129, w2v_ctc_loss=0.616, task_loss=1.367, contrastive_loss=0.111, total=4149.44, n_correct=2733.07, ppl=4.38, accuracy=65.866, wps=12150, ups=1.46, wpb=8298.9, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.609, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=36366
2023-07-25 21:27:22 | INFO | train_inner | epoch 031:   1199 / 1474 loss=1.971, trans_loss=4.953, nll_loss=2.136, w2v_ctc_loss=0.612, task_loss=1.311, contrastive_loss=0.222, total=4189.76, n_correct=2751.87, ppl=4.39, accuracy=65.681, wps=12206.3, ups=1.46, wpb=8379.5, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.608, clip=0, loss_scale=16, train_wall=68, gb_free=13.1, wall=36435
2023-07-25 21:28:30 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.962, trans_loss=4.954, nll_loss=2.137, w2v_ctc_loss=0.616, task_loss=1.258, contrastive_loss=0.068, total=4227.44, n_correct=2780.96, ppl=4.4, accuracy=65.784, wps=12487.9, ups=1.48, wpb=8454.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.598, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=36502
2023-07-25 21:29:39 | INFO | train_inner | epoch 031:   1399 / 1474 loss=1.979, trans_loss=4.955, nll_loss=2.138, w2v_ctc_loss=0.614, task_loss=1.284, contrastive_loss=0.276, total=4186.05, n_correct=2747.69, ppl=4.4, accuracy=65.639, wps=12182.2, ups=1.46, wpb=8372.1, bsz=326.6, num_updates=45600, lr=6.62266e-05, gnorm=0.593, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=36571
2023-07-25 21:30:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2579, device='cuda:5')
2023-07-25 21:30:54 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.194 | trans_loss 5.565 | nll_loss 2.84 | w2v_ctc_loss 1.329 | task_loss 4.62 | contrastive_loss 0.258 | total 4003.4 | n_correct 2495.8 | ppl 7.16 | accuracy 62.342 | uer 16.755 | wer 18.564 | raw_wer 18.564 | bleu 20.29 | wps 2142.7 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 20.29
2023-07-25 21:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-07-25 21:30:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 21:31:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt
2023-07-25 21:31:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_best.pt (epoch 31 @ 45675 updates, score 20.29) (writing took 19.851835161447525 seconds)
2023-07-25 21:31:14 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-25 21:31:14 | INFO | train | epoch 031 | loss 1.965 | trans_loss 4.945 | nll_loss 2.123 | w2v_ctc_loss 0.616 | task_loss 1.4 | contrastive_loss 0.111 | total 4138.46 | n_correct 2725.56 | ppl 4.36 | accuracy 65.859 | wps 11486 | ups 1.39 | wpb 8276.9 | bsz 305.6 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.604 | clip 0 | loss_scale 16 | train_wall 1002 | gb_free 12 | wall 36667
2023-07-25 21:31:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 21:31:15 | INFO | fairseq.trainer | begin training epoch 32
2023-07-25 21:31:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 21:31:41 | INFO | train_inner | epoch 032:     25 / 1474 loss=1.963, trans_loss=4.947, nll_loss=2.126, w2v_ctc_loss=0.617, task_loss=1.476, contrastive_loss=0.056, total=4042.6, n_correct=2661.69, ppl=4.37, accuracy=65.841, wps=6616.6, ups=0.82, wpb=8085.2, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.626, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=36693
2023-07-25 21:32:49 | INFO | train_inner | epoch 032:    125 / 1474 loss=1.939, trans_loss=4.91, nll_loss=2.078, w2v_ctc_loss=0.596, task_loss=1.294, contrastive_loss=0.067, total=4227.68, n_correct=2811.65, ppl=4.22, accuracy=66.506, wps=12425.6, ups=1.47, wpb=8455.4, bsz=323.3, num_updates=45800, lr=6.60819e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=36761
2023-07-25 21:33:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-25 21:33:58 | INFO | train_inner | epoch 032:    226 / 1474 loss=1.949, trans_loss=4.926, nll_loss=2.099, w2v_ctc_loss=0.605, task_loss=1.331, contrastive_loss=0.08, total=4157.26, n_correct=2752.88, ppl=4.29, accuracy=66.219, wps=12056.6, ups=1.45, wpb=8314.5, bsz=320.6, num_updates=45900, lr=6.60098e-05, gnorm=0.603, clip=0, loss_scale=8, train_wall=68, gb_free=16.2, wall=36830
2023-07-25 21:35:06 | INFO | train_inner | epoch 032:    326 / 1474 loss=1.944, trans_loss=4.917, nll_loss=2.086, w2v_ctc_loss=0.598, task_loss=1.324, contrastive_loss=0.071, total=4179.65, n_correct=2777.84, ppl=4.25, accuracy=66.461, wps=12264.9, ups=1.47, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.607, clip=0, loss_scale=8, train_wall=68, gb_free=16.2, wall=36898
2023-07-25 21:35:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 21:35:30 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.204 | trans_loss 5.575 | nll_loss 2.852 | w2v_ctc_loss 1.34 | task_loss 4.609 | contrastive_loss 0.257 | total 4003.4 | n_correct 2492.2 | ppl 7.22 | accuracy 62.252 | uer 16.707 | wer 18.687 | raw_wer 18.687 | bleu 20.4 | wps 2051.4 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.4
2023-07-25 21:35:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-25 21:35:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_32_46000.pt
2023-07-25 21:35:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_32_46000.pt
2023-07-25 21:35:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.4) (writing took 20.33187249302864 seconds)
2023-07-25 21:37:00 | INFO | train_inner | epoch 032:    426 / 1474 loss=1.951, trans_loss=4.925, nll_loss=2.097, w2v_ctc_loss=0.61, task_loss=1.371, contrastive_loss=0.068, total=4172.34, n_correct=2768.69, ppl=4.28, accuracy=66.358, wps=7342.3, ups=0.88, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.587, clip=0, loss_scale=8, train_wall=68, gb_free=17.1, wall=37012
2023-07-25 21:38:09 | INFO | train_inner | epoch 032:    526 / 1474 loss=1.963, trans_loss=4.936, nll_loss=2.111, w2v_ctc_loss=0.615, task_loss=1.369, contrastive_loss=0.152, total=4191.15, n_correct=2771, ppl=4.32, accuracy=66.116, wps=12146.4, ups=1.45, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.597, clip=0, loss_scale=8, train_wall=69, gb_free=14.9, wall=37081
2023-07-25 21:39:18 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.962, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.615, task_loss=1.464, contrastive_loss=0.075, total=4138.05, n_correct=2727.89, ppl=4.34, accuracy=65.922, wps=11965.7, ups=1.45, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.604, clip=0, loss_scale=8, train_wall=69, gb_free=13.2, wall=37150
2023-07-25 21:40:26 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.961, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.62, task_loss=1.416, contrastive_loss=0.058, total=4156.23, n_correct=2741.21, ppl=4.35, accuracy=65.954, wps=12108.4, ups=1.46, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.605, clip=0, loss_scale=8, train_wall=68, gb_free=16.6, wall=37219
2023-07-25 21:41:34 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.955, trans_loss=4.938, nll_loss=2.114, w2v_ctc_loss=0.607, task_loss=1.452, contrastive_loss=0.054, total=4112.3, n_correct=2717.09, ppl=4.33, accuracy=66.072, wps=12140.8, ups=1.48, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.582, clip=0, loss_scale=8, train_wall=67, gb_free=15.8, wall=37287
2023-07-25 21:42:43 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.956, trans_loss=4.941, nll_loss=2.118, w2v_ctc_loss=0.605, task_loss=1.447, contrastive_loss=0.053, total=4139.37, n_correct=2730.9, ppl=4.34, accuracy=65.974, wps=12081.7, ups=1.46, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.593, clip=0, loss_scale=8, train_wall=68, gb_free=12.7, wall=37355
2023-07-25 21:43:51 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.968, trans_loss=4.949, nll_loss=2.128, w2v_ctc_loss=0.616, task_loss=1.379, contrastive_loss=0.148, total=4121.85, n_correct=2708.65, ppl=4.37, accuracy=65.714, wps=12028.6, ups=1.46, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.587, clip=0, loss_scale=8, train_wall=68, gb_free=16.8, wall=37424
2023-07-25 21:45:00 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.973, trans_loss=4.954, nll_loss=2.133, w2v_ctc_loss=0.618, task_loss=1.657, contrastive_loss=0.09, total=4015.59, n_correct=2633.13, ppl=4.39, accuracy=65.573, wps=11676.6, ups=1.45, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.613, clip=0, loss_scale=8, train_wall=68, gb_free=17.2, wall=37492
2023-07-25 21:46:09 | INFO | train_inner | epoch 032:   1226 / 1474 loss=1.975, trans_loss=4.957, nll_loss=2.14, w2v_ctc_loss=0.613, task_loss=1.379, contrastive_loss=0.201, total=4153.44, n_correct=2726.91, ppl=4.41, accuracy=65.654, wps=12026.2, ups=1.45, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.611, clip=0, loss_scale=8, train_wall=69, gb_free=16.2, wall=37562
2023-07-25 21:47:17 | INFO | train_inner | epoch 032:   1326 / 1474 loss=1.963, trans_loss=4.948, nll_loss=2.128, w2v_ctc_loss=0.616, task_loss=1.441, contrastive_loss=0.053, total=4075.86, n_correct=2685.99, ppl=4.37, accuracy=65.9, wps=11993.7, ups=1.47, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.594, clip=0, loss_scale=8, train_wall=67, gb_free=16.8, wall=37630
2023-07-25 21:48:26 | INFO | train_inner | epoch 032:   1426 / 1474 loss=1.98, trans_loss=4.953, nll_loss=2.134, w2v_ctc_loss=0.621, task_loss=1.394, contrastive_loss=0.287, total=4116.4, n_correct=2704.96, ppl=4.39, accuracy=65.712, wps=11993, ups=1.46, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.592, clip=0, loss_scale=8, train_wall=68, gb_free=16.7, wall=37698
2023-07-25 21:48:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 21:49:23 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.569 | nll_loss 2.844 | w2v_ctc_loss 1.381 | task_loss 4.609 | contrastive_loss 0.261 | total 4003.4 | n_correct 2485.5 | ppl 7.18 | accuracy 62.085 | uer 16.999 | wer 18.903 | raw_wer 18.903 | bleu 19.99 | wps 2133.8 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.4
2023-07-25 21:49:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-07-25 21:49:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_last.pt
2023-07-25 21:49:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_last.pt
2023-07-25 21:49:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_last.pt (epoch 32 @ 47148 updates, score 19.99) (writing took 10.989408103749156 seconds)
2023-07-25 21:49:34 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-25 21:49:34 | INFO | train | epoch 032 | loss 1.96 | trans_loss 4.938 | nll_loss 2.114 | w2v_ctc_loss 0.61 | task_loss 1.399 | contrastive_loss 0.109 | total 4138.67 | n_correct 2732.24 | ppl 4.33 | accuracy 66.017 | wps 11090.2 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.597 | clip 0 | loss_scale 8 | train_wall 1003 | gb_free 16.5 | wall 37766
2023-07-25 21:49:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 21:49:34 | INFO | fairseq.trainer | begin training epoch 33
2023-07-25 21:49:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 21:50:19 | INFO | train_inner | epoch 033:     52 / 1474 loss=1.959, trans_loss=4.934, nll_loss=2.11, w2v_ctc_loss=0.603, task_loss=1.32, contrastive_loss=0.162, total=4149.21, n_correct=2742.71, ppl=4.32, accuracy=66.102, wps=7324.8, ups=0.88, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.59, clip=0, loss_scale=8, train_wall=69, gb_free=17, wall=37811
2023-07-25 21:51:28 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.945, trans_loss=4.916, nll_loss=2.084, w2v_ctc_loss=0.595, task_loss=1.501, contrastive_loss=0.043, total=4073.9, n_correct=2708.4, ppl=4.24, accuracy=66.482, wps=11859.5, ups=1.46, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.599, clip=0, loss_scale=8, train_wall=68, gb_free=15.2, wall=37880
2023-07-25 21:52:36 | INFO | train_inner | epoch 033:    252 / 1474 loss=1.956, trans_loss=4.918, nll_loss=2.089, w2v_ctc_loss=0.6, task_loss=1.195, contrastive_loss=0.23, total=4280.14, n_correct=2843.48, ppl=4.26, accuracy=66.434, wps=12505.4, ups=1.46, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.6, clip=0, loss_scale=8, train_wall=68, gb_free=16.4, wall=37949
2023-07-25 21:53:44 | INFO | train_inner | epoch 033:    352 / 1474 loss=1.954, trans_loss=4.929, nll_loss=2.102, w2v_ctc_loss=0.609, task_loss=1.426, contrastive_loss=0.079, total=4120.27, n_correct=2726.47, ppl=4.29, accuracy=66.172, wps=12071, ups=1.46, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.642, clip=0, loss_scale=8, train_wall=68, gb_free=17.3, wall=38017
2023-07-25 21:54:53 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.94, trans_loss=4.914, nll_loss=2.082, w2v_ctc_loss=0.6, task_loss=1.323, contrastive_loss=0.052, total=4141.22, n_correct=2754.68, ppl=4.24, accuracy=66.519, wps=12164.9, ups=1.47, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.597, clip=0, loss_scale=8, train_wall=68, gb_free=16.4, wall=38085
2023-07-25 21:56:01 | INFO | train_inner | epoch 033:    552 / 1474 loss=1.96, trans_loss=4.936, nll_loss=2.11, w2v_ctc_loss=0.612, task_loss=1.453, contrastive_loss=0.076, total=4133.59, n_correct=2726.54, ppl=4.32, accuracy=65.961, wps=12124.6, ups=1.47, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.596, clip=0, loss_scale=8, train_wall=68, gb_free=15.2, wall=38153
2023-07-25 21:57:09 | INFO | train_inner | epoch 033:    652 / 1474 loss=1.961, trans_loss=4.944, nll_loss=2.122, w2v_ctc_loss=0.607, task_loss=1.43, contrastive_loss=0.11, total=4157.63, n_correct=2738.53, ppl=4.35, accuracy=65.868, wps=12143.8, ups=1.46, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.598, clip=0, loss_scale=8, train_wall=68, gb_free=17.7, wall=38222
2023-07-25 21:58:18 | INFO | train_inner | epoch 033:    752 / 1474 loss=1.965, trans_loss=4.941, nll_loss=2.117, w2v_ctc_loss=0.624, task_loss=1.518, contrastive_loss=0.054, total=4070.75, n_correct=2680.78, ppl=4.34, accuracy=65.855, wps=11805.1, ups=1.45, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.609, clip=0, loss_scale=8, train_wall=68, gb_free=16.4, wall=38291
2023-07-25 21:59:26 | INFO | train_inner | epoch 033:    852 / 1474 loss=1.945, trans_loss=4.928, nll_loss=2.101, w2v_ctc_loss=0.588, task_loss=1.329, contrastive_loss=0.125, total=4130.24, n_correct=2743.58, ppl=4.29, accuracy=66.427, wps=12166.2, ups=1.47, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=67, gb_free=16.7, wall=38359
2023-07-25 21:59:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 21:59:49 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.207 | trans_loss 5.567 | nll_loss 2.84 | w2v_ctc_loss 1.365 | task_loss 4.614 | contrastive_loss 0.256 | total 4003.4 | n_correct 2497.6 | ppl 7.16 | accuracy 62.387 | uer 16.776 | wer 18.463 | raw_wer 18.463 | bleu 20.3 | wps 2173.3 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.4
2023-07-25 21:59:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-25 21:59:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_33_48000.pt
2023-07-25 21:59:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_33_48000.pt
2023-07-25 22:00:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.3) (writing took 17.09992371313274 seconds)
2023-07-25 22:01:15 | INFO | train_inner | epoch 033:    952 / 1474 loss=1.96, trans_loss=4.939, nll_loss=2.115, w2v_ctc_loss=0.619, task_loss=1.395, contrastive_loss=0.068, total=4151.18, n_correct=2739.48, ppl=4.33, accuracy=65.993, wps=7593.1, ups=0.91, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.611, clip=0, loss_scale=16, train_wall=68, gb_free=11.1, wall=38468
2023-07-25 22:02:24 | INFO | train_inner | epoch 033:   1052 / 1474 loss=1.962, trans_loss=4.936, nll_loss=2.112, w2v_ctc_loss=0.607, task_loss=1.399, contrastive_loss=0.171, total=4140.1, n_correct=2736.08, ppl=4.32, accuracy=66.087, wps=12002.7, ups=1.45, wpb=8280.2, bsz=307.6, num_updates=48200, lr=6.44157e-05, gnorm=0.593, clip=0, loss_scale=16, train_wall=68, gb_free=11.6, wall=38537
2023-07-25 22:03:33 | INFO | train_inner | epoch 033:   1152 / 1474 loss=1.961, trans_loss=4.942, nll_loss=2.12, w2v_ctc_loss=0.602, task_loss=1.399, contrastive_loss=0.16, total=4182.67, n_correct=2756.56, ppl=4.35, accuracy=65.904, wps=12153.8, ups=1.45, wpb=8365.3, bsz=309.5, num_updates=48300, lr=6.43489e-05, gnorm=0.605, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=38606
2023-07-25 22:04:42 | INFO | train_inner | epoch 033:   1252 / 1474 loss=1.96, trans_loss=4.938, nll_loss=2.115, w2v_ctc_loss=0.616, task_loss=1.469, contrastive_loss=0.059, total=4110.02, n_correct=2715.22, ppl=4.33, accuracy=66.063, wps=12030.2, ups=1.46, wpb=8220, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.61, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=38674
2023-07-25 22:05:51 | INFO | train_inner | epoch 033:   1352 / 1474 loss=1.956, trans_loss=4.941, nll_loss=2.12, w2v_ctc_loss=0.608, task_loss=1.37, contrastive_loss=0.081, total=4128.82, n_correct=2727.43, ppl=4.35, accuracy=66.058, wps=11961.3, ups=1.45, wpb=8257.6, bsz=312.4, num_updates=48500, lr=6.42161e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=38743
2023-07-25 22:06:59 | INFO | train_inner | epoch 033:   1452 / 1474 loss=1.963, trans_loss=4.938, nll_loss=2.116, w2v_ctc_loss=0.605, task_loss=1.396, contrastive_loss=0.223, total=4123.47, n_correct=2725.12, ppl=4.33, accuracy=66.088, wps=11979.1, ups=1.45, wpb=8246.9, bsz=308.9, num_updates=48600, lr=6.415e-05, gnorm=0.603, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=38812
2023-07-25 22:07:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-25 22:07:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 22:07:39 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.207 | trans_loss 5.57 | nll_loss 2.841 | w2v_ctc_loss 1.362 | task_loss 4.617 | contrastive_loss 0.253 | total 4003.4 | n_correct 2492.9 | ppl 7.17 | accuracy 62.27 | uer 16.941 | wer 18.739 | raw_wer 18.739 | bleu 19.89 | wps 1999.4 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.4
2023-07-25 22:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-07-25 22:07:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_last.pt
2023-07-25 22:07:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_last.pt
2023-07-25 22:07:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_last.pt (epoch 33 @ 48621 updates, score 19.89) (writing took 10.781262513250113 seconds)
2023-07-25 22:07:50 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-25 22:07:50 | INFO | train | epoch 033 | loss 1.956 | trans_loss 4.932 | nll_loss 2.107 | w2v_ctc_loss 0.607 | task_loss 1.397 | contrastive_loss 0.109 | total 4138.51 | n_correct 2737.39 | ppl 4.31 | accuracy 66.144 | wps 11124 | ups 1.34 | wpb 8277 | bsz 305.7 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.602 | clip 0 | loss_scale 8 | train_wall 1003 | gb_free 17.8 | wall 38862
2023-07-25 22:07:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-25 22:07:50 | INFO | fairseq.trainer | begin training epoch 34
2023-07-25 22:07:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-25 22:08:53 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.947, trans_loss=4.914, nll_loss=2.082, w2v_ctc_loss=0.608, task_loss=1.387, contrastive_loss=0.061, total=4128.69, n_correct=2749.03, ppl=4.24, accuracy=66.584, wps=7278.5, ups=0.88, wpb=8257.4, bsz=301.5, num_updates=48700, lr=6.40841e-05, gnorm=0.593, clip=0, loss_scale=8, train_wall=69, gb_free=16.6, wall=38925
2023-07-25 22:10:01 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.942, trans_loss=4.909, nll_loss=2.076, w2v_ctc_loss=0.599, task_loss=1.461, contrastive_loss=0.063, total=4065.88, n_correct=2708.59, ppl=4.21, accuracy=66.618, wps=11917.2, ups=1.47, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.595, clip=0, loss_scale=8, train_wall=68, gb_free=16, wall=38994
2023-07-25 22:11:10 | INFO | train_inner | epoch 034:    279 / 1474 loss=1.963, trans_loss=4.927, nll_loss=2.101, w2v_ctc_loss=0.598, task_loss=1.306, contrastive_loss=0.274, total=4246.3, n_correct=2809.21, ppl=4.29, accuracy=66.157, wps=12284.6, ups=1.45, wpb=8492.6, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.593, clip=0, loss_scale=8, train_wall=69, gb_free=17.8, wall=39063
2023-07-25 22:12:18 | INFO | train_inner | epoch 034:    379 / 1474 loss=1.945, trans_loss=4.91, nll_loss=2.079, w2v_ctc_loss=0.594, task_loss=1.326, contrastive_loss=0.163, total=4156.17, n_correct=2770.86, ppl=4.22, accuracy=66.669, wps=12258.2, ups=1.47, wpb=8312.3, bsz=316.7, num_updates=49000, lr=6.38877e-05, gnorm=0.601, clip=0, loss_scale=8, train_wall=67, gb_free=17.7, wall=39131
2023-07-25 22:13:26 | INFO | train_inner | epoch 034:    479 / 1474 loss=1.955, trans_loss=4.928, nll_loss=2.099, w2v_ctc_loss=0.612, task_loss=1.533, contrastive_loss=0.054, total=4070.55, n_correct=2695.83, ppl=4.28, accuracy=66.228, wps=11916.7, ups=1.46, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.598, clip=0, loss_scale=8, train_wall=68, gb_free=17.4, wall=39199
2023-07-25 22:14:34 | INFO | train_inner | epoch 034:    579 / 1474 loss=1.944, trans_loss=4.916, nll_loss=2.086, w2v_ctc_loss=0.6, task_loss=1.415, contrastive_loss=0.057, total=4119.38, n_correct=2742.91, ppl=4.24, accuracy=66.586, wps=12119, ups=1.47, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.601, clip=0, loss_scale=8, train_wall=67, gb_free=13, wall=39267
2023-07-25 22:15:42 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.946, trans_loss=4.922, nll_loss=2.094, w2v_ctc_loss=0.601, task_loss=1.419, contrastive_loss=0.051, total=4124.83, n_correct=2737.4, ppl=4.27, accuracy=66.364, wps=12125.8, ups=1.47, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.62, clip=0, loss_scale=8, train_wall=68, gb_free=14.2, wall=39335
2023-07-25 22:16:50 | INFO | train_inner | epoch 034:    779 / 1474 loss=1.957, trans_loss=4.941, nll_loss=2.118, w2v_ctc_loss=0.595, task_loss=1.47, contrastive_loss=0.122, total=4082.07, n_correct=2700.61, ppl=4.34, accuracy=66.158, wps=12002.5, ups=1.47, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.605, clip=0, loss_scale=8, train_wall=68, gb_free=15.5, wall=39403
2023-07-25 22:17:59 | INFO | train_inner | epoch 034:    879 / 1474 loss=1.956, trans_loss=4.934, nll_loss=2.109, w2v_ctc_loss=0.607, task_loss=1.476, contrastive_loss=0.083, total=4100.9, n_correct=2712.98, ppl=4.31, accuracy=66.156, wps=11947.6, ups=1.46, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.63, clip=0, loss_scale=8, train_wall=68, gb_free=12.1, wall=39472
2023-07-25 22:19:08 | INFO | train_inner | epoch 034:    979 / 1474 loss=1.955, trans_loss=4.932, nll_loss=2.107, w2v_ctc_loss=0.612, task_loss=1.375, contrastive_loss=0.078, total=4168.39, n_correct=2758.84, ppl=4.31, accuracy=66.185, wps=12153.6, ups=1.46, wpb=8336.8, bsz=311.9, num_updates=49600, lr=6.35001e-05, gnorm=0.595, clip=0, loss_scale=8, train_wall=68, gb_free=15.8, wall=39540
2023-07-25 22:20:15 | INFO | train_inner | epoch 034:   1079 / 1474 loss=1.953, trans_loss=4.936, nll_loss=2.111, w2v_ctc_loss=0.612, task_loss=1.359, contrastive_loss=0.058, total=4150.57, n_correct=2747.01, ppl=4.32, accuracy=66.184, wps=12316, ups=1.48, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.59, clip=0, loss_scale=8, train_wall=67, gb_free=16.8, wall=39608
2023-07-25 22:21:23 | INFO | train_inner | epoch 034:   1179 / 1474 loss=1.953, trans_loss=4.934, nll_loss=2.11, w2v_ctc_loss=0.603, task_loss=1.444, contrastive_loss=0.07, total=4098.77, n_correct=2711.68, ppl=4.32, accuracy=66.158, wps=12041.1, ups=1.47, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.602, clip=0, loss_scale=8, train_wall=68, gb_free=16.9, wall=39676
2023-07-25 22:22:32 | INFO | train_inner | epoch 034:   1279 / 1474 loss=1.951, trans_loss=4.932, nll_loss=2.107, w2v_ctc_loss=0.603, task_loss=1.41, contrastive_loss=0.054, total=4150.54, n_correct=2746.21, ppl=4.31, accuracy=66.165, wps=12143.6, ups=1.46, wpb=8301.1, bsz=301, num_updates=49900, lr=6.33089e-05, gnorm=0.596, clip=0, loss_scale=8, train_wall=68, gb_free=17.1, wall=39744
2023-07-25 22:23:40 | INFO | train_inner | epoch 034:   1379 / 1474 loss=1.963, trans_loss=4.941, nll_loss=2.119, w2v_ctc_loss=0.616, task_loss=1.341, contrastive_loss=0.123, total=4196.91, n_correct=2765.98, ppl=4.35, accuracy=65.905, wps=12227, ups=1.46, wpb=8393.8, bsz=321.4, num_updates=50000, lr=6.32456e-05, gnorm=0.619, clip=0, loss_scale=8, train_wall=68, gb_free=16, wall=39813
2023-07-25 22:23:40 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-07-25 22:23:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-25 22:24:04 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.189 | trans_loss 5.565 | nll_loss 2.837 | w2v_ctc_loss 1.312 | task_loss 4.618 | contrastive_loss 0.251 | total 4003.4 | n_correct 2498.4 | ppl 7.15 | accuracy 62.407 | uer 16.627 | wer 18.556 | raw_wer 18.556 | bleu 20.43 | wps 1956.4 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.43
2023-07-25 22:24:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-25 22:24:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_34_50000.pt
2023-07-25 22:24:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_34_50000.pt
2023-07-25 22:24:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_AT_sentence_scale1_mt_0725/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.43) (writing took 21.45618456415832 seconds)
2023-07-25 22:24:27 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-25 22:24:27 | INFO | train | epoch 034 | loss 1.952 | trans_loss 4.927 | nll_loss 2.1 | w2v_ctc_loss 0.604 | task_loss 1.408 | contrastive_loss 0.096 | total 4133.04 | n_correct 2739.94 | ppl 4.29 | accuracy 66.294 | wps 11432.8 | ups 1.38 | wpb 8266.1 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.603 | clip 0 | loss_scale 8 | train_wall 935 | gb_free 16 | wall 39859
2023-07-25 22:24:27 | INFO | fairseq_cli.train | done training in 39784.9 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
