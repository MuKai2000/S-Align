2023-07-17 12:04:51 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11282
2023-07-17 12:04:51 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11282
2023-07-17 12:04:51 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11282
2023-07-17 12:04:51 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11282
2023-07-17 12:04:51 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11282
2023-07-17 12:04:51 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11282
2023-07-17 12:04:51 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11282
2023-07-17 12:04:51 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11282
2023-07-17 12:04:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-17 12:04:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-17 12:04:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-17 12:04:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-17 12:04:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-17 12:04:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-17 12:04:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-17 12:04:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-17 12:04:52 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-17 12:04:52 | INFO | fairseq.distributed.utils | initialized host test1 as rank 6
2023-07-17 12:04:52 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-17 12:04:52 | INFO | fairseq.distributed.utils | initialized host test1 as rank 7
2023-07-17 12:04:52 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-17 12:04:53 | INFO | fairseq.distributed.utils | initialized host test1 as rank 0
2023-07-17 12:04:53 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-17 12:04:53 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-17 12:04:53 | INFO | fairseq.distributed.utils | initialized host test1 as rank 5
2023-07-17 12:04:53 | INFO | fairseq.distributed.utils | initialized host test1 as rank 2
2023-07-17 12:04:53 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-17 12:04:53 | INFO | fairseq.distributed.utils | initialized host test1 as rank 3
2023-07-17 12:04:53 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-17 12:04:53 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-17 12:04:53 | INFO | fairseq.distributed.utils | initialized host test1 as rank 4
2023-07-17 12:04:53 | INFO | fairseq.distributed.utils | initialized host test1 as rank 1
2023-07-17 12:04:55 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_window_scale1', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11282', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_window_scale1', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='window', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_window_scale1', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_window_scale1', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='window', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_window_scale1', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_window_scale1', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='window', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_window_scale1', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_window_scale1', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-17 12:04:55 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-17 12:04:55 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-17 12:04:55 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-17 12:04:55 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-17 12:04:55 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-17 12:05:00 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-17 12:05:00 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-17 12:05:00 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-17 12:05:01 | INFO | root | load pretrained hubert
2023-07-17 12:05:03 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-17 12:05:05 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-17 12:05:06 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-17 12:05:06 | INFO | root | share the sematic adapter and textual encoder
2023-07-17 12:05:06 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-17 12:05:06 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-17 12:05:06 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-17 12:05:06 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-17 12:05:06 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-17 12:05:06 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-17 12:05:06 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-17 12:05:06 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-17 12:05:06 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-17 12:05:06 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-17 12:05:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-17 12:05:17 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-17 12:05:17 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-17 12:05:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-17 12:05:18 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-17 12:05:18 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-17 12:05:18 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-17 12:05:18 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-17 12:05:18 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-17 12:05:18 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-17 12:05:18 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-17 12:05:18 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-17 12:05:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-17 12:05:18 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-17 12:05:18 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-17 12:05:18 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt
2023-07-17 12:05:18 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt
2023-07-17 12:05:18 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-17 12:05:18 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-17 12:05:18 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-17 12:05:18 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-17 12:05:20 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-17 12:05:21 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-17 12:05:23 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-17 12:06:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 12:06:28 | INFO | fairseq.trainer | begin training epoch 1
2023-07-17 12:06:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 12:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-17 12:07:42 | INFO | train_inner | epoch 001:    101 / 1474 loss=13.905, trans_loss=5.637, nll_loss=4.212, w2v_ctc_loss=15.061, task_loss=1.703, contrastive_loss=3.311, total=4200.41, n_correct=212.99, ppl=18.53, accuracy=5.071, wps=19552.6, ups=1.56, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=0.628, clip=0, loss_scale=64, train_wall=65, gb_free=19, wall=144
2023-07-17 12:08:44 | INFO | train_inner | epoch 001:    201 / 1474 loss=12.427, trans_loss=5.437, nll_loss=4.022, w2v_ctc_loss=12.97, task_loss=1.696, contrastive_loss=3.287, total=4127.38, n_correct=253.76, ppl=16.24, accuracy=6.148, wps=19711.4, ups=1.6, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=2.431, clip=0, loss_scale=64, train_wall=62, gb_free=19.2, wall=206
2023-07-17 12:09:47 | INFO | train_inner | epoch 001:    301 / 1474 loss=7.771, trans_loss=5.385, nll_loss=4.017, w2v_ctc_loss=5.895, task_loss=1.807, contrastive_loss=3.202, total=4079.62, n_correct=255.25, ppl=16.19, accuracy=6.257, wps=19578.2, ups=1.61, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=3.123, clip=0, loss_scale=64, train_wall=62, gb_free=19.9, wall=269
2023-07-17 12:10:49 | INFO | train_inner | epoch 001:    401 / 1474 loss=6.942, trans_loss=5.447, nll_loss=4.114, w2v_ctc_loss=4.567, task_loss=1.556, contrastive_loss=3.237, total=4174.14, n_correct=235.79, ppl=17.32, accuracy=5.649, wps=19928.9, ups=1.6, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=2.017, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=331
2023-07-17 12:11:53 | INFO | train_inner | epoch 001:    501 / 1474 loss=6.649, trans_loss=5.448, nll_loss=4.124, w2v_ctc_loss=4.124, task_loss=1.365, contrastive_loss=3.232, total=4176.18, n_correct=222.89, ppl=17.44, accuracy=5.337, wps=19761.8, ups=1.58, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=0.963, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=395
2023-07-17 12:12:55 | INFO | train_inner | epoch 001:    601 / 1474 loss=6.48, trans_loss=5.483, nll_loss=4.173, w2v_ctc_loss=3.883, task_loss=1.265, contrastive_loss=3.285, total=4147.79, n_correct=214.39, ppl=18.04, accuracy=5.169, wps=19768.9, ups=1.6, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.497, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=457
2023-07-17 12:13:57 | INFO | train_inner | epoch 001:    701 / 1474 loss=6.394, trans_loss=5.475, nll_loss=4.17, w2v_ctc_loss=3.819, task_loss=1.291, contrastive_loss=3.036, total=4152.1, n_correct=224.26, ppl=18, accuracy=5.401, wps=19886.8, ups=1.61, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.394, clip=0, loss_scale=64, train_wall=62, gb_free=19.5, wall=519
2023-07-17 12:15:00 | INFO | train_inner | epoch 001:    801 / 1474 loss=6.208, trans_loss=5.434, nll_loss=4.12, w2v_ctc_loss=3.662, task_loss=1.232, contrastive_loss=2.934, total=4123.83, n_correct=251.88, ppl=17.39, accuracy=6.108, wps=19803.1, ups=1.61, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=62, gb_free=19.1, wall=582
2023-07-17 12:16:02 | INFO | train_inner | epoch 001:    901 / 1474 loss=6.053, trans_loss=5.411, nll_loss=4.108, w2v_ctc_loss=3.557, task_loss=1.242, contrastive_loss=2.687, total=4163.61, n_correct=272.63, ppl=17.25, accuracy=6.548, wps=19964.7, ups=1.61, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=0.898, clip=0, loss_scale=64, train_wall=62, gb_free=18.8, wall=644
2023-07-17 12:17:04 | INFO | train_inner | epoch 001:   1001 / 1474 loss=5.861, trans_loss=5.389, nll_loss=4.084, w2v_ctc_loss=3.397, task_loss=1.247, contrastive_loss=2.543, total=4135.34, n_correct=297.06, ppl=16.96, accuracy=7.183, wps=19718.4, ups=1.59, wpb=12363.9, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=0.962, clip=0, loss_scale=64, train_wall=62, gb_free=19, wall=706
2023-07-17 12:18:06 | INFO | train_inner | epoch 001:   1101 / 1474 loss=5.698, trans_loss=5.386, nll_loss=4.085, w2v_ctc_loss=3.273, task_loss=1.26, contrastive_loss=2.322, total=4147.38, n_correct=311.19, ppl=16.97, accuracy=7.503, wps=19939.9, ups=1.61, wpb=12356.9, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.116, clip=0, loss_scale=64, train_wall=62, gb_free=18.8, wall=768
2023-07-17 12:19:09 | INFO | train_inner | epoch 001:   1201 / 1474 loss=5.537, trans_loss=5.365, nll_loss=4.064, w2v_ctc_loss=3.148, task_loss=1.311, contrastive_loss=2.114, total=4139.9, n_correct=324.35, ppl=16.72, accuracy=7.835, wps=19840.4, ups=1.6, wpb=12386.7, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.166, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=831
2023-07-17 12:20:11 | INFO | train_inner | epoch 001:   1301 / 1474 loss=5.38, trans_loss=5.366, nll_loss=4.066, w2v_ctc_loss=3.014, task_loss=1.26, contrastive_loss=1.928, total=4046.58, n_correct=320.7, ppl=16.75, accuracy=7.925, wps=19591.5, ups=1.62, wpb=12092.5, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.118, clip=0, loss_scale=64, train_wall=61, gb_free=19.7, wall=893
2023-07-17 12:21:12 | INFO | train_inner | epoch 001:   1401 / 1474 loss=5.271, trans_loss=5.358, nll_loss=4.069, w2v_ctc_loss=2.9, task_loss=1.24, contrastive_loss=2.001, total=4133.18, n_correct=331.06, ppl=16.78, accuracy=8.01, wps=19902.2, ups=1.62, wpb=12300.7, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.137, clip=0, loss_scale=64, train_wall=61, gb_free=19.9, wall=954
2023-07-17 12:21:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-17 12:22:32 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 7.779 | trans_loss 10.954 | nll_loss 9.948 | w2v_ctc_loss 4.542 | task_loss 7.241 | contrastive_loss 2.331 | total 4003.4 | n_correct 373.2 | ppl 987.98 | accuracy 9.322 | uer 71.417 | wer 69.457 | raw_wer 69.457 | bleu 0.03 | wps 1421.5 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-17 12:22:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-17 12:22:32 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 12:22:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 12:22:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.03) (writing took 4.9455374700482935 seconds)
2023-07-17 12:22:37 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-17 12:22:37 | INFO | train | epoch 001 | loss 7.091 | trans_loss 5.427 | nll_loss 4.1 | w2v_ctc_loss 5.122 | task_loss 1.382 | contrastive_loss 2.753 | total 4138.32 | n_correct 269.798 | ppl 17.15 | accuracy 6.519 | wps 18965.9 | ups 1.53 | wpb 12354.6 | bsz 458.3 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.208 | clip 0 | loss_scale 64 | train_wall 915 | gb_free 19.2 | wall 1039
2023-07-17 12:22:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 12:22:38 | INFO | fairseq.trainer | begin training epoch 2
2023-07-17 12:22:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 12:23:02 | INFO | train_inner | epoch 002:     27 / 1474 loss=5.14, trans_loss=5.353, nll_loss=4.052, w2v_ctc_loss=2.762, task_loss=1.183, contrastive_loss=1.843, total=4162.95, n_correct=337.87, ppl=16.59, accuracy=8.116, wps=11349.9, ups=0.91, wpb=12414, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.08, clip=0, loss_scale=64, train_wall=61, gb_free=19.6, wall=1064
2023-07-17 12:24:04 | INFO | train_inner | epoch 002:    127 / 1474 loss=5.029, trans_loss=5.355, nll_loss=4.056, w2v_ctc_loss=2.678, task_loss=1.266, contrastive_loss=1.642, total=4155.98, n_correct=340.74, ppl=16.64, accuracy=8.199, wps=19845.8, ups=1.6, wpb=12390, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.093, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=1126
2023-07-17 12:25:07 | INFO | train_inner | epoch 002:    227 / 1474 loss=4.89, trans_loss=5.329, nll_loss=4.027, w2v_ctc_loss=2.534, task_loss=1.093, contrastive_loss=1.675, total=4179.21, n_correct=346.08, ppl=16.3, accuracy=8.281, wps=19796.1, ups=1.59, wpb=12488.1, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.028, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1189
2023-07-17 12:26:10 | INFO | train_inner | epoch 002:    327 / 1474 loss=4.812, trans_loss=5.331, nll_loss=4.026, w2v_ctc_loss=2.484, task_loss=1.257, contrastive_loss=1.389, total=4146.1, n_correct=349.03, ppl=16.29, accuracy=8.418, wps=19757.9, ups=1.6, wpb=12381, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=0.991, clip=0, loss_scale=64, train_wall=62, gb_free=18.8, wall=1252
2023-07-17 12:27:12 | INFO | train_inner | epoch 002:    427 / 1474 loss=4.724, trans_loss=5.32, nll_loss=4.017, w2v_ctc_loss=2.424, task_loss=1.38, contrastive_loss=1.206, total=4037.99, n_correct=335.77, ppl=16.19, accuracy=8.315, wps=19444.2, ups=1.61, wpb=12079.4, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=0.998, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=1314
2023-07-17 12:28:14 | INFO | train_inner | epoch 002:    527 / 1474 loss=4.655, trans_loss=5.31, nll_loss=3.999, w2v_ctc_loss=2.318, task_loss=1.201, contrastive_loss=1.31, total=4176.97, n_correct=360.55, ppl=15.98, accuracy=8.632, wps=20155.1, ups=1.62, wpb=12475.1, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=0.904, clip=0, loss_scale=64, train_wall=61, gb_free=19.6, wall=1376
2023-07-17 12:28:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 12:28:49 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 7.302 | trans_loss 10.811 | nll_loss 9.76 | w2v_ctc_loss 3.675 | task_loss 7.239 | contrastive_loss 1.629 | total 4003.4 | n_correct 393.9 | ppl 866.9 | accuracy 9.839 | uer 62.007 | wer 59.603 | raw_wer 59.603 | bleu 0.04 | wps 1415.7 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-07-17 12:28:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-17 12:28:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_2_2000.pt
2023-07-17 12:28:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_2_2000.pt
2023-07-17 12:28:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 9.111544513027184 seconds)
2023-07-17 12:30:00 | INFO | train_inner | epoch 002:    627 / 1474 loss=4.56, trans_loss=5.299, nll_loss=3.99, w2v_ctc_loss=2.248, task_loss=1.243, contrastive_loss=1.104, total=4126.49, n_correct=363.94, ppl=15.89, accuracy=8.82, wps=11596.4, ups=0.94, wpb=12299.1, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=0.815, clip=0, loss_scale=128, train_wall=62, gb_free=19.2, wall=1482
2023-07-17 12:31:02 | INFO | train_inner | epoch 002:    727 / 1474 loss=4.495, trans_loss=5.28, nll_loss=3.968, w2v_ctc_loss=2.181, task_loss=1.218, contrastive_loss=1.203, total=4149.06, n_correct=374.48, ppl=15.65, accuracy=9.026, wps=19984.9, ups=1.62, wpb=12372.9, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=0.749, clip=0, loss_scale=128, train_wall=61, gb_free=19.2, wall=1544
2023-07-17 12:32:04 | INFO | train_inner | epoch 002:    827 / 1474 loss=4.461, trans_loss=5.273, nll_loss=3.958, w2v_ctc_loss=2.144, task_loss=1.251, contrastive_loss=1.155, total=4175.4, n_correct=377.83, ppl=15.54, accuracy=9.049, wps=20091.9, ups=1.61, wpb=12477.6, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=0.698, clip=0, loss_scale=128, train_wall=62, gb_free=19.8, wall=1606
2023-07-17 12:33:06 | INFO | train_inner | epoch 002:    927 / 1474 loss=4.395, trans_loss=5.263, nll_loss=3.946, w2v_ctc_loss=2.079, task_loss=1.276, contrastive_loss=1.132, total=4104.2, n_correct=377.43, ppl=15.41, accuracy=9.196, wps=19776.1, ups=1.62, wpb=12243.8, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=0.685, clip=0, loss_scale=128, train_wall=61, gb_free=19, wall=1668
2023-07-17 12:34:08 | INFO | train_inner | epoch 002:   1027 / 1474 loss=4.329, trans_loss=5.255, nll_loss=3.936, w2v_ctc_loss=2.024, task_loss=1.237, contrastive_loss=0.989, total=4102.5, n_correct=378, ppl=15.3, accuracy=9.214, wps=19931.1, ups=1.62, wpb=12270.3, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.606, clip=0, loss_scale=128, train_wall=61, gb_free=19.2, wall=1730
2023-07-17 12:35:10 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.311, trans_loss=5.247, nll_loss=3.927, w2v_ctc_loss=1.973, task_loss=1.123, contrastive_loss=1.202, total=4187.61, n_correct=395.71, ppl=15.22, accuracy=9.45, wps=20022.2, ups=1.6, wpb=12484.3, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.575, clip=0, loss_scale=128, train_wall=62, gb_free=19.5, wall=1792
2023-07-17 12:36:13 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.259, trans_loss=5.241, nll_loss=3.919, w2v_ctc_loss=1.936, task_loss=1.135, contrastive_loss=1.123, total=4221.06, n_correct=407.91, ppl=15.13, accuracy=9.664, wps=20099.6, ups=1.6, wpb=12590.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.543, clip=0, loss_scale=128, train_wall=62, gb_free=19.4, wall=1855
2023-07-17 12:37:15 | INFO | train_inner | epoch 002:   1327 / 1474 loss=4.2, trans_loss=5.219, nll_loss=3.897, w2v_ctc_loss=1.914, task_loss=1.193, contrastive_loss=0.834, total=4157.86, n_correct=414.48, ppl=14.9, accuracy=9.969, wps=20024.6, ups=1.61, wpb=12422.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.514, clip=0, loss_scale=128, train_wall=62, gb_free=19.5, wall=1917
2023-07-17 12:38:17 | INFO | train_inner | epoch 002:   1427 / 1474 loss=4.18, trans_loss=5.225, nll_loss=3.899, w2v_ctc_loss=1.883, task_loss=1.345, contrastive_loss=0.926, total=4054.34, n_correct=401.05, ppl=14.92, accuracy=9.892, wps=19375, ups=1.6, wpb=12128.6, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.497, clip=0, loss_scale=128, train_wall=62, gb_free=19.4, wall=1979
2023-07-17 12:38:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 12:39:22 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 6.671 | trans_loss 10.296 | nll_loss 9.109 | w2v_ctc_loss 2.917 | task_loss 7.239 | contrastive_loss 0.993 | total 4003.4 | n_correct 501.3 | ppl 552.09 | accuracy 12.522 | uer 51.628 | wer 50.412 | raw_wer 50.412 | bleu 0.14 | wps 1415.8 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.14
2023-07-17 12:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-17 12:39:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 12:39:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 12:39:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.14) (writing took 8.150742326979525 seconds)
2023-07-17 12:39:30 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-17 12:39:30 | INFO | train | epoch 002 | loss 4.522 | trans_loss 5.281 | nll_loss 3.968 | w2v_ctc_loss 2.201 | task_loss 1.226 | contrastive_loss 1.209 | total 4138.65 | n_correct 373.412 | ppl 15.65 | accuracy 9.023 | wps 17989.9 | ups 1.46 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 0.761 | clip 0 | loss_scale 128 | train_wall 911 | gb_free 19.3 | wall 2052
2023-07-17 12:39:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 12:39:30 | INFO | fairseq.trainer | begin training epoch 3
2023-07-17 12:39:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 12:40:11 | INFO | train_inner | epoch 003:     53 / 1474 loss=4.138, trans_loss=5.203, nll_loss=3.874, w2v_ctc_loss=1.853, task_loss=1.256, contrastive_loss=0.821, total=4071.2, n_correct=413.67, ppl=14.66, accuracy=10.161, wps=10701.5, ups=0.88, wpb=12148.3, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.486, clip=0, loss_scale=128, train_wall=62, gb_free=19.1, wall=2093
2023-07-17 12:40:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-17 12:40:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-17 12:40:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-17 12:40:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-17 12:40:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-17 12:41:44 | INFO | train_inner | epoch 003:    158 / 1474 loss=3.67, trans_loss=4.354, nll_loss=2.763, w2v_ctc_loss=1.684, task_loss=0.841, contrastive_loss=0.773, total=4144.18, n_correct=1161.01, ppl=6.79, accuracy=28.015, wps=13280.6, ups=1.07, wpb=12381.7, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=1.64, clip=2, loss_scale=4, train_wall=93, gb_free=16.7, wall=2186
2023-07-17 12:43:14 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.429, trans_loss=4.15, nll_loss=2.497, w2v_ctc_loss=1.533, task_loss=0.849, contrastive_loss=0.66, total=4161.13, n_correct=1410.75, ppl=5.64, accuracy=33.903, wps=13775.4, ups=1.11, wpb=12444.3, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.205, clip=0, loss_scale=4, train_wall=90, gb_free=17.3, wall=2276
2023-07-17 12:44:44 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.358, trans_loss=4.102, nll_loss=2.433, w2v_ctc_loss=1.479, task_loss=0.855, contrastive_loss=0.686, total=4150.02, n_correct=1484.24, ppl=5.4, accuracy=35.765, wps=13843.1, ups=1.12, wpb=12369, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.086, clip=0, loss_scale=4, train_wall=89, gb_free=17.3, wall=2366
2023-07-17 12:46:14 | INFO | train_inner | epoch 003:    458 / 1474 loss=3.261, trans_loss=4.045, nll_loss=2.36, w2v_ctc_loss=1.408, task_loss=0.826, contrastive_loss=0.534, total=4209.57, n_correct=1588.21, ppl=5.13, accuracy=37.729, wps=13918.2, ups=1.11, wpb=12537.6, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=0.904, clip=0, loss_scale=4, train_wall=90, gb_free=16.2, wall=2456
2023-07-17 12:47:44 | INFO | train_inner | epoch 003:    558 / 1474 loss=3.192, trans_loss=4.018, nll_loss=2.319, w2v_ctc_loss=1.343, task_loss=0.914, contrastive_loss=0.493, total=4088.48, n_correct=1588.66, ppl=4.99, accuracy=38.857, wps=13617.4, ups=1.11, wpb=12237.1, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=0.857, clip=0, loss_scale=4, train_wall=89, gb_free=17.8, wall=2546
2023-07-17 12:49:15 | INFO | train_inner | epoch 003:    658 / 1474 loss=3.14, trans_loss=3.978, nll_loss=2.269, w2v_ctc_loss=1.293, task_loss=0.816, contrastive_loss=0.609, total=4221.58, n_correct=1706.54, ppl=4.82, accuracy=40.424, wps=13792.9, ups=1.1, wpb=12558.6, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=0.8, clip=0, loss_scale=4, train_wall=91, gb_free=16.5, wall=2637
2023-07-17 12:50:43 | INFO | train_inner | epoch 003:    758 / 1474 loss=3.076, trans_loss=3.945, nll_loss=2.225, w2v_ctc_loss=1.259, task_loss=0.812, contrastive_loss=0.364, total=4167.41, n_correct=1736.5, ppl=4.68, accuracy=41.669, wps=14032.5, ups=1.13, wpb=12462.8, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=0.714, clip=0, loss_scale=4, train_wall=88, gb_free=16.5, wall=2725
2023-07-17 12:52:13 | INFO | train_inner | epoch 003:    858 / 1474 loss=3.046, trans_loss=3.925, nll_loss=2.198, w2v_ctc_loss=1.228, task_loss=0.866, contrastive_loss=0.322, total=4165.53, n_correct=1765.96, ppl=4.59, accuracy=42.395, wps=13932.4, ups=1.12, wpb=12445.3, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=0.699, clip=0, loss_scale=4, train_wall=89, gb_free=17.2, wall=2815
2023-07-17 12:53:42 | INFO | train_inner | epoch 003:    958 / 1474 loss=3.019, trans_loss=3.897, nll_loss=2.161, w2v_ctc_loss=1.207, task_loss=0.828, contrastive_loss=0.353, total=4162.3, n_correct=1816.87, ppl=4.47, accuracy=43.651, wps=13853.5, ups=1.12, wpb=12408.5, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=0.668, clip=0, loss_scale=4, train_wall=89, gb_free=16.9, wall=2904
2023-07-17 12:55:11 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.996, trans_loss=3.885, nll_loss=2.145, w2v_ctc_loss=1.191, task_loss=0.907, contrastive_loss=0.304, total=4069.95, n_correct=1801.22, ppl=4.42, accuracy=44.257, wps=13690.2, ups=1.13, wpb=12168.2, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=0.657, clip=0, loss_scale=4, train_wall=88, gb_free=16.5, wall=2993
2023-07-17 12:55:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 12:55:39 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.458 | trans_loss 6.417 | nll_loss 3.962 | w2v_ctc_loss 1.831 | task_loss 4.049 | contrastive_loss 0.429 | total 4003.4 | n_correct 1970.1 | ppl 15.59 | accuracy 49.211 | uer 30.324 | wer 31.155 | raw_wer 31.155 | bleu 10.91 | wps 1775.4 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 10.91
2023-07-17 12:55:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-17 12:55:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_3_4000.pt
2023-07-17 12:55:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_3_4000.pt
2023-07-17 12:55:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 10.91) (writing took 9.424827425042167 seconds)
2023-07-17 12:57:17 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.966, trans_loss=3.875, nll_loss=2.131, w2v_ctc_loss=1.162, task_loss=0.927, contrastive_loss=0.284, total=4038.49, n_correct=1800.78, ppl=4.38, accuracy=44.59, wps=9561.3, ups=0.79, wpb=12064, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=0.652, clip=0, loss_scale=4, train_wall=88, gb_free=16.6, wall=3119
2023-07-17 12:58:46 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.945, trans_loss=3.857, nll_loss=2.108, w2v_ctc_loss=1.137, task_loss=0.906, contrastive_loss=0.266, total=4064.31, n_correct=1850.63, ppl=4.31, accuracy=45.534, wps=13697.7, ups=1.13, wpb=12147.9, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.64, clip=0, loss_scale=4, train_wall=88, gb_free=17.5, wall=3208
2023-07-17 13:00:16 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.925, trans_loss=3.832, nll_loss=2.08, w2v_ctc_loss=1.12, task_loss=0.866, contrastive_loss=0.38, total=4134.58, n_correct=1910.66, ppl=4.23, accuracy=46.212, wps=13732.2, ups=1.11, wpb=12326.9, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.644, clip=0, loss_scale=4, train_wall=89, gb_free=17.9, wall=3298
2023-07-17 13:01:46 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.893, trans_loss=3.816, nll_loss=2.057, w2v_ctc_loss=1.094, task_loss=0.815, contrastive_loss=0.356, total=4209.94, n_correct=1975.91, ppl=4.16, accuracy=46.934, wps=14020.9, ups=1.12, wpb=12573.7, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.622, clip=0, loss_scale=4, train_wall=89, gb_free=17.2, wall=3388
2023-07-17 13:01:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 13:02:25 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.32 | trans_loss 6.266 | nll_loss 3.762 | w2v_ctc_loss 1.65 | task_loss 3.929 | contrastive_loss 0.389 | total 4003.4 | n_correct 2054.2 | ppl 13.56 | accuracy 51.311 | uer 28.575 | wer 29.324 | raw_wer 29.324 | bleu 12.89 | wps 2083.1 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 12.89
2023-07-17 13:02:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-17 13:02:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 13:02:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 13:02:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 3 @ 4416 updates, score 12.89) (writing took 8.343881730921566 seconds)
2023-07-17 13:02:33 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-17 13:02:33 | INFO | train | epoch 003 | loss 3.171 | trans_loss 4.02 | nll_loss 2.323 | w2v_ctc_loss 1.314 | task_loss 0.872 | contrastive_loss 0.472 | total 4140.05 | n_correct 1641.86 | ppl 5.01 | accuracy 39.658 | wps 13125.3 | ups 1.06 | wpb 12360.2 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 0.826 | clip 0.1 | loss_scale 4 | train_wall 1298 | gb_free 16.8 | wall 3435
2023-07-17 13:02:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 13:02:33 | INFO | fairseq.trainer | begin training epoch 4
2023-07-17 13:02:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 13:03:56 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.853, trans_loss=3.789, nll_loss=2.022, w2v_ctc_loss=1.071, task_loss=0.889, contrastive_loss=0.209, total=4099.41, n_correct=1953.22, ppl=4.06, accuracy=47.646, wps=9374.8, ups=0.77, wpb=12215.8, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.592, clip=0, loss_scale=4, train_wall=88, gb_free=16.6, wall=3518
2023-07-17 13:05:25 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.828, trans_loss=3.772, nll_loss=1.998, w2v_ctc_loss=1.051, task_loss=0.816, contrastive_loss=0.237, total=4175.15, n_correct=2019.49, ppl=3.99, accuracy=48.369, wps=13985.8, ups=1.12, wpb=12466.1, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.603, clip=0, loss_scale=4, train_wall=89, gb_free=16.8, wall=3607
2023-07-17 13:06:55 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.839, trans_loss=3.771, nll_loss=1.998, w2v_ctc_loss=1.047, task_loss=0.858, contrastive_loss=0.362, total=4145.23, n_correct=2007.69, ppl=3.99, accuracy=48.434, wps=13747, ups=1.11, wpb=12387.3, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.6, clip=0, loss_scale=4, train_wall=90, gb_free=16.1, wall=3697
2023-07-17 13:08:24 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.821, trans_loss=3.769, nll_loss=1.994, w2v_ctc_loss=1.038, task_loss=0.894, contrastive_loss=0.206, total=4127.66, n_correct=2010.93, ppl=3.98, accuracy=48.718, wps=13862.6, ups=1.13, wpb=12298.8, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.587, clip=0, loss_scale=4, train_wall=88, gb_free=17.6, wall=3786
2023-07-17 13:09:54 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.821, trans_loss=3.749, nll_loss=1.971, w2v_ctc_loss=1.007, task_loss=0.777, contrastive_loss=0.605, total=4218.78, n_correct=2084.72, ppl=3.92, accuracy=49.415, wps=14021.1, ups=1.11, wpb=12578.2, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.583, clip=0, loss_scale=4, train_wall=89, gb_free=16.7, wall=3876
2023-07-17 13:11:23 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.789, trans_loss=3.745, nll_loss=1.966, w2v_ctc_loss=1.022, task_loss=0.813, contrastive_loss=0.279, total=4217.52, n_correct=2091.85, ppl=3.91, accuracy=49.599, wps=14045.5, ups=1.12, wpb=12583.6, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.591, clip=0, loss_scale=4, train_wall=89, gb_free=16.3, wall=3965
mt_weight tensor(0.8335, device='cuda:0')
asr_weight tensor(0.8129, device='cuda:0')
2023-07-17 13:12:54 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.796, trans_loss=3.748, nll_loss=1.965, w2v_ctc_loss=1.007, task_loss=0.885, contrastive_loss=0.325, total=4176.39, n_correct=2085.94, ppl=3.9, accuracy=49.946, wps=13710, ups=1.1, wpb=12440.1, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.508, clip=0, loss_scale=8, train_wall=90, gb_free=17.2, wall=4056
2023-07-17 13:14:23 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.783, trans_loss=3.741, nll_loss=1.957, w2v_ctc_loss=1.008, task_loss=0.951, contrastive_loss=0.194, total=4026.63, n_correct=2016.99, ppl=3.88, accuracy=50.091, wps=13460.1, ups=1.12, wpb=12049.9, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.493, clip=0, loss_scale=8, train_wall=89, gb_free=13.5, wall=4145
2023-07-17 13:15:54 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.773, trans_loss=3.723, nll_loss=1.939, w2v_ctc_loss=0.994, task_loss=0.86, contrastive_loss=0.368, total=4186.04, n_correct=2114.59, ppl=3.84, accuracy=50.515, wps=13827.3, ups=1.11, wpb=12493.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.494, clip=0, loss_scale=8, train_wall=90, gb_free=17.8, wall=4236
2023-07-17 13:17:24 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.751, trans_loss=3.714, nll_loss=1.927, w2v_ctc_loss=0.98, task_loss=0.872, contrastive_loss=0.234, total=4125.02, n_correct=2106.43, ppl=3.8, accuracy=51.065, wps=13651, ups=1.11, wpb=12319.9, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.478, clip=0, loss_scale=8, train_wall=90, gb_free=13.1, wall=4326
2023-07-17 13:18:53 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.764, trans_loss=3.721, nll_loss=1.933, w2v_ctc_loss=0.987, task_loss=0.93, contrastive_loss=0.212, total=4075.6, n_correct=2076.68, ppl=3.82, accuracy=50.954, wps=13614.9, ups=1.12, wpb=12166.1, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.487, clip=0, loss_scale=8, train_wall=89, gb_free=16.2, wall=4415
2023-07-17 13:20:22 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.75, trans_loss=3.711, nll_loss=1.922, w2v_ctc_loss=0.969, task_loss=0.808, contrastive_loss=0.32, total=4161.18, n_correct=2146.42, ppl=3.79, accuracy=51.582, wps=13998.8, ups=1.12, wpb=12451.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.479, clip=0, loss_scale=8, train_wall=89, gb_free=16.9, wall=4504
2023-07-17 13:21:51 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.737, trans_loss=3.702, nll_loss=1.91, w2v_ctc_loss=0.96, task_loss=0.821, contrastive_loss=0.284, total=4156.53, n_correct=2159.3, ppl=3.76, accuracy=51.95, wps=13954.6, ups=1.12, wpb=12424.6, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.476, clip=0, loss_scale=8, train_wall=89, gb_free=16.2, wall=4593
2023-07-17 13:23:20 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.725, trans_loss=3.697, nll_loss=1.905, w2v_ctc_loss=0.962, task_loss=0.886, contrastive_loss=0.163, total=4101.23, n_correct=2131.41, ppl=3.74, accuracy=51.97, wps=13905.6, ups=1.13, wpb=12255, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.463, clip=0, loss_scale=8, train_wall=88, gb_free=15.8, wall=4681
2023-07-17 13:24:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.8335, device='cuda:1')
asr_weight tensor(0.8129, device='cuda:1')
mt_weight tensor(0.8335, device='cuda:2')
asr_weight tensor(0.8129, device='cuda:2')
mt_weight tensor(0.8335, device='cuda:7')
asr_weight tensor(0.8129, device='cuda:7')
mt_weight tensor(0.8335, device='cuda:6')
asr_weight tensor(0.8129, device='cuda:6')
mt_weight tensor(0.8335, device='cuda:4')
asr_weight tensor(0.8129, device='cuda:4')
mt_weight tensor(0.8335, device='cuda:5')
asr_weight tensor(0.8129, device='cuda:5')
mt_weight tensor(0.8335, device='cuda:3')
asr_weight tensor(0.8129, device='cuda:3')
2023-07-17 13:25:03 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.009 | trans_loss 5.936 | nll_loss 3.319 | w2v_ctc_loss 1.396 | task_loss 4.161 | contrastive_loss 0.315 | total 4003.4 | n_correct 2252.8 | ppl 9.98 | accuracy 56.272 | uer 23.558 | wer 25.014 | raw_wer 25.014 | bleu 16 | wps 2347.1 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 16
2023-07-17 13:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-17 13:25:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 13:25:07 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 13:25:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 4 @ 5890 updates, score 16.0) (writing took 8.364888662006706 seconds)
2023-07-17 13:25:11 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-17 13:25:11 | INFO | train | epoch 004 | loss 2.783 | trans_loss 3.736 | nll_loss 1.953 | w2v_ctc_loss 1.003 | task_loss 0.861 | contrastive_loss 0.284 | total 4138.65 | n_correct 2076.77 | ppl 3.87 | accuracy 50.18 | wps 13411.6 | ups 1.09 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.527 | clip 0 | loss_scale 8 | train_wall 1312 | gb_free 15 | wall 4793
2023-07-17 13:25:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 13:25:11 | INFO | fairseq.trainer | begin training epoch 5
2023-07-17 13:25:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 13:25:28 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.716, trans_loss=3.69, nll_loss=1.895, w2v_ctc_loss=0.947, task_loss=0.896, contrastive_loss=0.181, total=4037.7, n_correct=2110.98, ppl=3.72, accuracy=52.282, wps=9410.6, ups=0.78, wpb=12062.8, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.471, clip=0, loss_scale=8, train_wall=88, gb_free=17, wall=4810
2023-07-17 13:26:58 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.642, trans_loss=3.638, nll_loss=1.827, w2v_ctc_loss=0.887, task_loss=0.78, contrastive_loss=0.189, total=4247.37, n_correct=2288.23, ppl=3.55, accuracy=53.874, wps=14093.4, ups=1.11, wpb=12683.8, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.445, clip=0, loss_scale=8, train_wall=90, gb_free=16.8, wall=4900
2023-07-17 13:26:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 13:27:22 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 3.982 | trans_loss 5.925 | nll_loss 3.301 | w2v_ctc_loss 1.345 | task_loss 4.168 | contrastive_loss 0.301 | total 4003.4 | n_correct 2250.7 | ppl 9.85 | accuracy 56.22 | uer 22.671 | wer 24.101 | raw_wer 24.101 | bleu 16.17 | wps 2280.9 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.17
2023-07-17 13:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-17 13:27:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_5_6000.pt
2023-07-17 13:27:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_5_6000.pt
2023-07-17 13:27:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.17) (writing took 9.23851596901659 seconds)
2023-07-17 13:29:00 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.67, trans_loss=3.647, nll_loss=1.838, w2v_ctc_loss=0.899, task_loss=0.798, contrastive_loss=0.411, total=4189.85, n_correct=2248.82, ppl=3.58, accuracy=53.673, wps=10240.8, ups=0.82, wpb=12492.8, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.455, clip=0, loss_scale=8, train_wall=88, gb_free=17.9, wall=5022
2023-07-17 13:30:28 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.676, trans_loss=3.647, nll_loss=1.841, w2v_ctc_loss=0.914, task_loss=0.887, contrastive_loss=0.261, total=4090.1, n_correct=2182.97, ppl=3.58, accuracy=53.372, wps=13834.1, ups=1.13, wpb=12240, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.468, clip=0, loss_scale=8, train_wall=88, gb_free=16.4, wall=5110
2023-07-17 13:31:58 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.657, trans_loss=3.636, nll_loss=1.831, w2v_ctc_loss=0.885, task_loss=0.831, contrastive_loss=0.348, total=4147.17, n_correct=2237.19, ppl=3.56, accuracy=53.945, wps=13801.4, ups=1.11, wpb=12381.8, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.46, clip=0, loss_scale=8, train_wall=89, gb_free=15.1, wall=5200
2023-07-17 13:33:27 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.653, trans_loss=3.65, nll_loss=1.841, w2v_ctc_loss=0.895, task_loss=0.973, contrastive_loss=0.137, total=4026.81, n_correct=2159.48, ppl=3.58, accuracy=53.628, wps=13541.6, ups=1.12, wpb=12047.2, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.464, clip=0, loss_scale=8, train_wall=89, gb_free=17.5, wall=5289
2023-07-17 13:34:57 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.664, trans_loss=3.644, nll_loss=1.835, w2v_ctc_loss=0.886, task_loss=0.886, contrastive_loss=0.312, total=4107.75, n_correct=2207.61, ppl=3.57, accuracy=53.743, wps=13656.3, ups=1.12, wpb=12245.3, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.461, clip=0, loss_scale=8, train_wall=89, gb_free=16.3, wall=5379
2023-07-17 13:36:26 | INFO | train_inner | epoch 005:    710 / 1474 loss=2.642, trans_loss=3.636, nll_loss=1.827, w2v_ctc_loss=0.885, task_loss=0.819, contrastive_loss=0.288, total=4178.85, n_correct=2258.78, ppl=3.55, accuracy=54.053, wps=13911.1, ups=1.12, wpb=12462.3, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.454, clip=0, loss_scale=8, train_wall=89, gb_free=17.8, wall=5468
2023-07-17 13:37:57 | INFO | train_inner | epoch 005:    810 / 1474 loss=2.643, trans_loss=3.641, nll_loss=1.831, w2v_ctc_loss=0.882, task_loss=0.891, contrastive_loss=0.212, total=4127.73, n_correct=2234.17, ppl=3.56, accuracy=54.126, wps=13609.2, ups=1.1, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.448, clip=0, loss_scale=8, train_wall=90, gb_free=15.4, wall=5559
2023-07-17 13:39:26 | INFO | train_inner | epoch 005:    910 / 1474 loss=2.634, trans_loss=3.634, nll_loss=1.823, w2v_ctc_loss=0.875, task_loss=0.895, contrastive_loss=0.173, total=4095.48, n_correct=2226.31, ppl=3.54, accuracy=54.36, wps=13725.9, ups=1.12, wpb=12237.9, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.452, clip=0, loss_scale=8, train_wall=89, gb_free=15.8, wall=5648
2023-07-17 13:40:55 | INFO | train_inner | epoch 005:   1010 / 1474 loss=2.647, trans_loss=3.637, nll_loss=1.829, w2v_ctc_loss=0.879, task_loss=0.852, contrastive_loss=0.253, total=4165.12, n_correct=2270.22, ppl=3.55, accuracy=54.506, wps=13963.9, ups=1.12, wpb=12426.3, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.442, clip=0, loss_scale=8, train_wall=89, gb_free=15.9, wall=5737
2023-07-17 13:42:25 | INFO | train_inner | epoch 005:   1110 / 1474 loss=2.644, trans_loss=3.634, nll_loss=1.821, w2v_ctc_loss=0.876, task_loss=0.854, contrastive_loss=0.252, total=4176.72, n_correct=2283.68, ppl=3.53, accuracy=54.676, wps=13803.4, ups=1.11, wpb=12467.3, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.442, clip=0, loss_scale=8, train_wall=90, gb_free=16.9, wall=5827
2023-07-17 13:43:56 | INFO | train_inner | epoch 005:   1210 / 1474 loss=2.627, trans_loss=3.634, nll_loss=1.822, w2v_ctc_loss=0.868, task_loss=0.879, contrastive_loss=0.158, total=4164.13, n_correct=2276.66, ppl=3.54, accuracy=54.673, wps=13682.1, ups=1.1, wpb=12416.1, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.458, clip=0, loss_scale=16, train_wall=90, gb_free=17.1, wall=5918
2023-07-17 13:45:26 | INFO | train_inner | epoch 005:   1310 / 1474 loss=2.613, trans_loss=3.628, nll_loss=1.814, w2v_ctc_loss=0.857, task_loss=0.881, contrastive_loss=0.127, total=4134.91, n_correct=2264.36, ppl=3.52, accuracy=54.762, wps=13743.3, ups=1.11, wpb=12356.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.443, clip=0, loss_scale=16, train_wall=90, gb_free=16.6, wall=6008
2023-07-17 13:46:55 | INFO | train_inner | epoch 005:   1410 / 1474 loss=2.617, trans_loss=3.622, nll_loss=1.812, w2v_ctc_loss=0.859, task_loss=0.87, contrastive_loss=0.191, total=4134.37, n_correct=2263.74, ppl=3.51, accuracy=54.754, wps=13859.9, ups=1.12, wpb=12339.9, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.443, clip=0, loss_scale=16, train_wall=89, gb_free=17.9, wall=6097
2023-07-17 13:47:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 13:48:16 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 3.9 | trans_loss 5.84 | nll_loss 3.192 | w2v_ctc_loss 1.261 | task_loss 4.224 | contrastive_loss 0.312 | total 4003.4 | n_correct 2311.8 | ppl 9.14 | accuracy 57.746 | uer 21.854 | wer 23.441 | raw_wer 23.441 | bleu 17.27 | wps 2325.6 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 17.27
2023-07-17 13:48:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-17 13:48:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 13:48:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 13:48:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 5 @ 7364 updates, score 17.27) (writing took 8.394778475980274 seconds)
2023-07-17 13:48:24 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-17 13:48:24 | INFO | train | epoch 005 | loss 2.643 | trans_loss 3.637 | nll_loss 1.827 | w2v_ctc_loss 0.881 | task_loss 0.864 | contrastive_loss 0.237 | total 4138.65 | n_correct 2242.72 | ppl 3.55 | accuracy 54.19 | wps 13072 | ups 1.06 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.453 | clip 0 | loss_scale 16 | train_wall 1313 | gb_free 16.4 | wall 6186
2023-07-17 13:48:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 13:48:25 | INFO | fairseq.trainer | begin training epoch 6
2023-07-17 13:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 13:49:05 | INFO | train_inner | epoch 006:     36 / 1474 loss=2.596, trans_loss=3.605, nll_loss=1.785, w2v_ctc_loss=0.845, task_loss=0.888, contrastive_loss=0.186, total=4115.45, n_correct=2284.61, ppl=3.45, accuracy=55.513, wps=9446.6, ups=0.77, wpb=12279.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.455, clip=0, loss_scale=16, train_wall=89, gb_free=16.6, wall=6227
2023-07-17 13:50:34 | INFO | train_inner | epoch 006:    136 / 1474 loss=2.56, trans_loss=3.58, nll_loss=1.754, w2v_ctc_loss=0.809, task_loss=0.865, contrastive_loss=0.232, total=4154.25, n_correct=2330.84, ppl=3.37, accuracy=56.107, wps=13868, ups=1.12, wpb=12409.6, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.436, clip=0, loss_scale=16, train_wall=89, gb_free=15.7, wall=6316
2023-07-17 13:52:04 | INFO | train_inner | epoch 006:    236 / 1474 loss=2.581, trans_loss=3.588, nll_loss=1.767, w2v_ctc_loss=0.839, task_loss=0.927, contrastive_loss=0.14, total=4112.66, n_correct=2290.4, ppl=3.4, accuracy=55.691, wps=13716.8, ups=1.12, wpb=12281.7, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.443, clip=0, loss_scale=16, train_wall=89, gb_free=16.3, wall=6406
2023-07-17 13:53:35 | INFO | train_inner | epoch 006:    336 / 1474 loss=2.578, trans_loss=3.575, nll_loss=1.75, w2v_ctc_loss=0.805, task_loss=0.803, contrastive_loss=0.443, total=4177.51, n_correct=2354.64, ppl=3.36, accuracy=56.365, wps=13645, ups=1.09, wpb=12463.7, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.438, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=6497
2023-07-17 13:55:04 | INFO | train_inner | epoch 006:    436 / 1474 loss=2.554, trans_loss=3.58, nll_loss=1.755, w2v_ctc_loss=0.808, task_loss=0.83, contrastive_loss=0.156, total=4154.57, n_correct=2340.42, ppl=3.37, accuracy=56.334, wps=13934.9, ups=1.12, wpb=12407.2, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.437, clip=0, loss_scale=16, train_wall=89, gb_free=16.3, wall=6586
2023-07-17 13:56:34 | INFO | train_inner | epoch 006:    536 / 1474 loss=2.564, trans_loss=3.582, nll_loss=1.758, w2v_ctc_loss=0.82, task_loss=0.869, contrastive_loss=0.143, total=4167.79, n_correct=2349.18, ppl=3.38, accuracy=56.365, wps=13901, ups=1.12, wpb=12419.2, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.439, clip=0, loss_scale=16, train_wall=89, gb_free=15.9, wall=6676
2023-07-17 13:58:02 | INFO | train_inner | epoch 006:    636 / 1474 loss=2.554, trans_loss=3.584, nll_loss=1.758, w2v_ctc_loss=0.803, task_loss=0.821, contrastive_loss=0.201, total=4146.17, n_correct=2332.33, ppl=3.38, accuracy=56.253, wps=13944.3, ups=1.12, wpb=12395.5, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.443, clip=0, loss_scale=16, train_wall=88, gb_free=16.7, wall=6764
2023-07-17 13:58:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 13:58:27 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 3.865 | trans_loss 5.79 | nll_loss 3.125 | w2v_ctc_loss 1.249 | task_loss 4.231 | contrastive_loss 0.303 | total 4003.4 | n_correct 2338.4 | ppl 8.73 | accuracy 58.41 | uer 20.773 | wer 22.49 | raw_wer 22.49 | bleu 17.5 | wps 2240.2 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.5
2023-07-17 13:58:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-17 13:58:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_6_8000.pt
2023-07-17 13:58:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_6_8000.pt
2023-07-17 13:58:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.5) (writing took 9.637365814996883 seconds)
2023-07-17 14:00:07 | INFO | train_inner | epoch 006:    736 / 1474 loss=2.566, trans_loss=3.585, nll_loss=1.763, w2v_ctc_loss=0.822, task_loss=0.883, contrastive_loss=0.153, total=4148.65, n_correct=2335.52, ppl=3.39, accuracy=56.296, wps=9922.3, ups=0.8, wpb=12378.4, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.442, clip=0, loss_scale=16, train_wall=90, gb_free=15.8, wall=6889
2023-07-17 14:01:37 | INFO | train_inner | epoch 006:    836 / 1474 loss=2.572, trans_loss=3.59, nll_loss=1.766, w2v_ctc_loss=0.814, task_loss=0.907, contrastive_loss=0.135, total=4114.34, n_correct=2310.38, ppl=3.4, accuracy=56.154, wps=13649.1, ups=1.11, wpb=12292.5, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.44, clip=0, loss_scale=16, train_wall=90, gb_free=15.3, wall=6979
2023-07-17 14:03:07 | INFO | train_inner | epoch 006:    936 / 1474 loss=2.572, trans_loss=3.587, nll_loss=1.765, w2v_ctc_loss=0.817, task_loss=0.9, contrastive_loss=0.23, total=4081.53, n_correct=2292.97, ppl=3.4, accuracy=56.179, wps=13527.3, ups=1.11, wpb=12166.1, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.444, clip=0, loss_scale=16, train_wall=90, gb_free=17.9, wall=7069
2023-07-17 14:04:36 | INFO | train_inner | epoch 006:   1036 / 1474 loss=2.568, trans_loss=3.58, nll_loss=1.756, w2v_ctc_loss=0.805, task_loss=0.818, contrastive_loss=0.305, total=4165.84, n_correct=2354.24, ppl=3.38, accuracy=56.513, wps=13963.2, ups=1.12, wpb=12437.3, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.44, clip=0, loss_scale=16, train_wall=89, gb_free=17, wall=7158
2023-07-17 14:06:05 | INFO | train_inner | epoch 006:   1136 / 1474 loss=2.561, trans_loss=3.588, nll_loss=1.765, w2v_ctc_loss=0.809, task_loss=0.959, contrastive_loss=0.135, total=4072.29, n_correct=2291.09, ppl=3.4, accuracy=56.26, wps=13647, ups=1.12, wpb=12165.1, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.438, clip=0, loss_scale=16, train_wall=89, gb_free=17.1, wall=7247
2023-07-17 14:07:35 | INFO | train_inner | epoch 006:   1236 / 1474 loss=2.572, trans_loss=3.577, nll_loss=1.753, w2v_ctc_loss=0.796, task_loss=0.839, contrastive_loss=0.45, total=4141.55, n_correct=2349.59, ppl=3.37, accuracy=56.732, wps=13788.5, ups=1.11, wpb=12385.8, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.435, clip=0, loss_scale=16, train_wall=89, gb_free=13.5, wall=7337
2023-07-17 14:09:04 | INFO | train_inner | epoch 006:   1336 / 1474 loss=2.554, trans_loss=3.584, nll_loss=1.758, w2v_ctc_loss=0.8, task_loss=0.861, contrastive_loss=0.123, total=4125.31, n_correct=2338.17, ppl=3.38, accuracy=56.679, wps=13859.6, ups=1.13, wpb=12316, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.436, clip=0, loss_scale=16, train_wall=88, gb_free=17.8, wall=7426
2023-07-17 14:10:34 | INFO | train_inner | epoch 006:   1436 / 1474 loss=2.544, trans_loss=3.575, nll_loss=1.75, w2v_ctc_loss=0.802, task_loss=0.866, contrastive_loss=0.129, total=4196.2, n_correct=2387.62, ppl=3.36, accuracy=56.9, wps=13868.8, ups=1.11, wpb=12515.5, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.433, clip=0, loss_scale=16, train_wall=90, gb_free=11.8, wall=7516
2023-07-17 14:11:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 14:11:32 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 3.83 | trans_loss 5.757 | nll_loss 3.082 | w2v_ctc_loss 1.209 | task_loss 4.239 | contrastive_loss 0.282 | total 4003.4 | n_correct 2349.2 | ppl 8.47 | accuracy 58.68 | uer 19.659 | wer 21.394 | raw_wer 21.394 | bleu 17.76 | wps 2259.9 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 17.76
2023-07-17 14:11:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-17 14:11:32 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 14:11:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 14:11:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 6 @ 8838 updates, score 17.76) (writing took 8.747216554940678 seconds)
2023-07-17 14:11:41 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-17 14:11:41 | INFO | train | epoch 006 | loss 2.563 | trans_loss 3.582 | nll_loss 1.758 | w2v_ctc_loss 0.81 | task_loss 0.865 | contrastive_loss 0.212 | total 4138.65 | n_correct 2332.6 | ppl 3.38 | accuracy 56.361 | wps 13040.1 | ups 1.06 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.439 | clip 0 | loss_scale 16 | train_wall 1315 | gb_free 15.3 | wall 7583
2023-07-17 14:11:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 14:11:41 | INFO | fairseq.trainer | begin training epoch 7
2023-07-17 14:11:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 14:12:46 | INFO | train_inner | epoch 007:     62 / 1474 loss=2.516, trans_loss=3.55, nll_loss=1.718, w2v_ctc_loss=0.775, task_loss=0.844, contrastive_loss=0.144, total=4108.19, n_correct=2358.17, ppl=3.29, accuracy=57.402, wps=9349.4, ups=0.76, wpb=12269.7, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.435, clip=0, loss_scale=16, train_wall=90, gb_free=17.2, wall=7648
2023-07-17 14:14:15 | INFO | train_inner | epoch 007:    162 / 1474 loss=2.518, trans_loss=3.544, nll_loss=1.709, w2v_ctc_loss=0.765, task_loss=0.877, contrastive_loss=0.219, total=4106.05, n_correct=2363.64, ppl=3.27, accuracy=57.565, wps=13698.9, ups=1.12, wpb=12254.3, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.44, clip=0, loss_scale=16, train_wall=89, gb_free=16.9, wall=7737
2023-07-17 14:15:44 | INFO | train_inner | epoch 007:    262 / 1474 loss=2.498, trans_loss=3.541, nll_loss=1.704, w2v_ctc_loss=0.765, task_loss=0.878, contrastive_loss=0.124, total=4129.3, n_correct=2384.9, ppl=3.26, accuracy=57.756, wps=13818.5, ups=1.12, wpb=12322.9, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.433, clip=0, loss_scale=16, train_wall=89, gb_free=17.4, wall=7826
2023-07-17 14:16:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-17 14:17:15 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.514, trans_loss=3.546, nll_loss=1.712, w2v_ctc_loss=0.756, task_loss=0.845, contrastive_loss=0.369, total=4190.91, n_correct=2407.26, ppl=3.28, accuracy=57.44, wps=13761.3, ups=1.1, wpb=12505.3, bsz=474.7, num_updates=9200, lr=0.000147442, gnorm=0.431, clip=0, loss_scale=16, train_wall=90, gb_free=13.3, wall=7917
2023-07-17 14:18:45 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.521, trans_loss=3.545, nll_loss=1.714, w2v_ctc_loss=0.764, task_loss=0.856, contrastive_loss=0.313, total=4153.22, n_correct=2387.39, ppl=3.28, accuracy=57.483, wps=13789.3, ups=1.11, wpb=12386.6, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.437, clip=0, loss_scale=16, train_wall=89, gb_free=17, wall=8007
2023-07-17 14:20:15 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.501, trans_loss=3.544, nll_loss=1.711, w2v_ctc_loss=0.763, task_loss=0.845, contrastive_loss=0.132, total=4168.14, n_correct=2413.12, ppl=3.27, accuracy=57.894, wps=13862.9, ups=1.12, wpb=12410.5, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.428, clip=0, loss_scale=16, train_wall=89, gb_free=17, wall=8096
2023-07-17 14:21:44 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.502, trans_loss=3.548, nll_loss=1.712, w2v_ctc_loss=0.756, task_loss=0.856, contrastive_loss=0.12, total=4157.82, n_correct=2405.92, ppl=3.28, accuracy=57.865, wps=13840.4, ups=1.11, wpb=12417.8, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.431, clip=0, loss_scale=16, train_wall=89, gb_free=15.8, wall=8186
2023-07-17 14:23:14 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.51, trans_loss=3.547, nll_loss=1.713, w2v_ctc_loss=0.764, task_loss=0.907, contrastive_loss=0.116, total=4122.1, n_correct=2380.46, ppl=3.28, accuracy=57.749, wps=13718, ups=1.11, wpb=12321.9, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.434, clip=0, loss_scale=16, train_wall=89, gb_free=15.8, wall=8276
2023-07-17 14:24:44 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.507, trans_loss=3.545, nll_loss=1.71, w2v_ctc_loss=0.76, task_loss=0.872, contrastive_loss=0.138, total=4147.23, n_correct=2396.32, ppl=3.27, accuracy=57.781, wps=13758, ups=1.11, wpb=12392, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.435, clip=0, loss_scale=16, train_wall=90, gb_free=17.6, wall=8366
2023-07-17 14:26:14 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.508, trans_loss=3.544, nll_loss=1.71, w2v_ctc_loss=0.755, task_loss=0.821, contrastive_loss=0.233, total=4140.14, n_correct=2400.82, ppl=3.27, accuracy=57.989, wps=13791.1, ups=1.12, wpb=12360, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.436, clip=0, loss_scale=16, train_wall=89, gb_free=16.1, wall=8456
2023-07-17 14:27:43 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.502, trans_loss=3.553, nll_loss=1.721, w2v_ctc_loss=0.762, task_loss=0.911, contrastive_loss=0.101, total=4103.51, n_correct=2367.91, ppl=3.3, accuracy=57.705, wps=13690.4, ups=1.12, wpb=12263.4, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.43, clip=0, loss_scale=16, train_wall=89, gb_free=17, wall=8545
2023-07-17 14:29:13 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.514, trans_loss=3.541, nll_loss=1.711, w2v_ctc_loss=0.753, task_loss=0.842, contrastive_loss=0.365, total=4137.04, n_correct=2398.58, ppl=3.27, accuracy=57.978, wps=13750.6, ups=1.11, wpb=12348.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.438, clip=0, loss_scale=16, train_wall=89, gb_free=16.2, wall=8635
2023-07-17 14:29:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 14:29:37 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 3.802 | trans_loss 5.718 | nll_loss 3.035 | w2v_ctc_loss 1.199 | task_loss 4.253 | contrastive_loss 0.288 | total 4003.4 | n_correct 2386.6 | ppl 8.2 | accuracy 59.614 | uer 19.29 | wer 21.297 | raw_wer 21.297 | bleu 18.46 | wps 2281.6 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.46
2023-07-17 14:29:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-17 14:29:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_7_10000.pt
2023-07-17 14:29:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_7_10000.pt
2023-07-17 14:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.46) (writing took 9.487258567940444 seconds)
mt_weight tensor(0.5762, device='cuda:0')
asr_weight tensor(0.5148, device='cuda:0')
2023-07-17 14:31:16 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.491, trans_loss=3.539, nll_loss=1.707, w2v_ctc_loss=0.75, task_loss=0.876, contrastive_loss=0.128, total=4129.52, n_correct=2395.02, ppl=3.26, accuracy=57.998, wps=10003.8, ups=0.81, wpb=12329.2, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.33, clip=0, loss_scale=16, train_wall=89, gb_free=17, wall=8758
2023-07-17 14:32:46 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.499, trans_loss=3.535, nll_loss=1.701, w2v_ctc_loss=0.756, task_loss=0.813, contrastive_loss=0.165, total=4172.87, n_correct=2435.32, ppl=3.25, accuracy=58.361, wps=13907.9, ups=1.12, wpb=12453.5, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.33, clip=0, loss_scale=16, train_wall=89, gb_free=17.3, wall=8848
2023-07-17 14:34:17 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.512, trans_loss=3.546, nll_loss=1.716, w2v_ctc_loss=0.758, task_loss=0.937, contrastive_loss=0.228, total=4109.42, n_correct=2381.63, ppl=3.28, accuracy=57.955, wps=13503.3, ups=1.1, wpb=12285.7, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.337, clip=0, loss_scale=16, train_wall=91, gb_free=16.6, wall=8939
2023-07-17 14:34:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5762, device='cuda:6')
asr_weight tensor(0.5148, device='cuda:6')
mt_weight tensor(0.5762, device='cuda:1')
asr_weight tensor(0.5148, device='cuda:1')
mt_weight tensor(0.5762, device='cuda:7')
asr_weight tensor(0.5148, device='cuda:7')
mt_weight tensor(0.5762, device='cuda:4')
asr_weight tensor(0.5148, device='cuda:4')
mt_weight tensor(0.5762, device='cuda:5')
asr_weight tensor(0.5148, device='cuda:5')
mt_weight tensor(0.5762, device='cuda:2')
asr_weight tensor(0.5148, device='cuda:2')
mt_weight tensor(0.5762, device='cuda:3')
asr_weight tensor(0.5148, device='cuda:3')
2023-07-17 14:34:51 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 3.788 | trans_loss 5.716 | nll_loss 3.034 | w2v_ctc_loss 1.181 | task_loss 4.281 | contrastive_loss 0.265 | total 4003.4 | n_correct 2372.2 | ppl 8.19 | accuracy 59.255 | uer 19.422 | wer 21.207 | raw_wer 21.207 | bleu 18.3 | wps 2310.2 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.46
2023-07-17 14:34:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-17 14:34:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_18.3001.pt
2023-07-17 14:34:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_18.3001.pt
2023-07-17 14:34:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_18.3001.pt (epoch 7 @ 10311 updates, score 18.3) (writing took 5.509933207998984 seconds)
2023-07-17 14:34:56 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-17 14:34:56 | INFO | train | epoch 007 | loss 2.507 | trans_loss 3.544 | nll_loss 1.71 | w2v_ctc_loss 0.759 | task_loss 0.867 | contrastive_loss 0.195 | total 4137.97 | n_correct 2392.43 | ppl 3.27 | accuracy 57.816 | wps 13041.8 | ups 1.06 | wpb 12354.1 | bsz 458.1 | num_updates 10311 | lr 0.000139272 | gnorm 0.413 | clip 0 | loss_scale 16 | train_wall 1317 | gb_free 13.5 | wall 8978
2023-07-17 14:34:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 14:34:56 | INFO | fairseq.trainer | begin training epoch 8
2023-07-17 14:34:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 14:36:25 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.466, trans_loss=3.519, nll_loss=1.674, w2v_ctc_loss=0.727, task_loss=0.917, contrastive_loss=0.122, total=4116.25, n_correct=2418.41, ppl=3.19, accuracy=58.753, wps=9557.4, ups=0.78, wpb=12265.9, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.335, clip=0, loss_scale=16, train_wall=90, gb_free=17.1, wall=9067
2023-07-17 14:37:54 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.478, trans_loss=3.522, nll_loss=1.679, w2v_ctc_loss=0.731, task_loss=0.939, contrastive_loss=0.145, total=4037.23, n_correct=2370.18, ppl=3.2, accuracy=58.708, wps=13512, ups=1.12, wpb=12033.3, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.343, clip=0, loss_scale=16, train_wall=89, gb_free=13.1, wall=9156
2023-07-17 14:39:24 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.446, trans_loss=3.509, nll_loss=1.663, w2v_ctc_loss=0.715, task_loss=0.813, contrastive_loss=0.142, total=4207.78, n_correct=2489.08, ppl=3.17, accuracy=59.154, wps=13957.2, ups=1.11, wpb=12570.1, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.33, clip=0, loss_scale=16, train_wall=90, gb_free=13.3, wall=9246
2023-07-17 14:40:55 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.48, trans_loss=3.518, nll_loss=1.675, w2v_ctc_loss=0.738, task_loss=0.923, contrastive_loss=0.166, total=4127.24, n_correct=2422.52, ppl=3.19, accuracy=58.696, wps=13628.5, ups=1.11, wpb=12318.5, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.337, clip=0, loss_scale=16, train_wall=90, gb_free=12.1, wall=9337
2023-07-17 14:42:25 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.488, trans_loss=3.517, nll_loss=1.675, w2v_ctc_loss=0.719, task_loss=0.776, contrastive_loss=0.424, total=4203.76, n_correct=2475.02, ppl=3.19, accuracy=58.876, wps=13958.7, ups=1.11, wpb=12567.7, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.338, clip=0, loss_scale=16, train_wall=90, gb_free=14.7, wall=9427
2023-07-17 14:43:54 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.468, trans_loss=3.517, nll_loss=1.677, w2v_ctc_loss=0.731, task_loss=0.948, contrastive_loss=0.099, total=4062.5, n_correct=2383.85, ppl=3.2, accuracy=58.679, wps=13593.9, ups=1.12, wpb=12171.9, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.331, clip=0, loss_scale=16, train_wall=89, gb_free=11.7, wall=9516
2023-07-17 14:45:25 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.462, trans_loss=3.513, nll_loss=1.672, w2v_ctc_loss=0.733, task_loss=0.894, contrastive_loss=0.111, total=4142.78, n_correct=2448.17, ppl=3.19, accuracy=59.095, wps=13693, ups=1.11, wpb=12347.9, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.332, clip=0, loss_scale=16, train_wall=90, gb_free=16, wall=9607
2023-07-17 14:46:54 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.465, trans_loss=3.511, nll_loss=1.67, w2v_ctc_loss=0.723, task_loss=0.893, contrastive_loss=0.199, total=4118.9, n_correct=2429.57, ppl=3.18, accuracy=58.986, wps=13722.8, ups=1.11, wpb=12327.8, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.338, clip=0, loss_scale=16, train_wall=89, gb_free=15.3, wall=9696
2023-07-17 14:48:24 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.463, trans_loss=3.512, nll_loss=1.672, w2v_ctc_loss=0.717, task_loss=0.828, contrastive_loss=0.208, total=4169.01, n_correct=2467.33, ppl=3.19, accuracy=59.183, wps=13825.2, ups=1.11, wpb=12455.3, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.333, clip=0, loss_scale=16, train_wall=90, gb_free=16.3, wall=9786
2023-07-17 14:49:54 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.449, trans_loss=3.509, nll_loss=1.666, w2v_ctc_loss=0.713, task_loss=0.827, contrastive_loss=0.106, total=4154.69, n_correct=2461.13, ppl=3.17, accuracy=59.237, wps=13862.8, ups=1.12, wpb=12398.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.336, clip=0, loss_scale=32, train_wall=89, gb_free=17.8, wall=9876
2023-07-17 14:51:24 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.474, trans_loss=3.515, nll_loss=1.676, w2v_ctc_loss=0.719, task_loss=0.864, contrastive_loss=0.333, total=4199.1, n_correct=2471.94, ppl=3.19, accuracy=58.868, wps=13826.3, ups=1.1, wpb=12520.7, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.329, clip=0, loss_scale=32, train_wall=90, gb_free=13, wall=9966
2023-07-17 14:52:54 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.454, trans_loss=3.513, nll_loss=1.674, w2v_ctc_loss=0.718, task_loss=0.817, contrastive_loss=0.116, total=4177.31, n_correct=2470.38, ppl=3.19, accuracy=59.138, wps=13975, ups=1.12, wpb=12476.4, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.327, clip=0, loss_scale=32, train_wall=89, gb_free=15.1, wall=10056
2023-07-17 14:54:23 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.469, trans_loss=3.516, nll_loss=1.677, w2v_ctc_loss=0.729, task_loss=0.904, contrastive_loss=0.138, total=4063.85, n_correct=2390.31, ppl=3.2, accuracy=58.819, wps=13630.8, ups=1.12, wpb=12141.2, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.336, clip=0, loss_scale=32, train_wall=89, gb_free=16.9, wall=10145
2023-07-17 14:55:52 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.468, trans_loss=3.515, nll_loss=1.678, w2v_ctc_loss=0.723, task_loss=0.859, contrastive_loss=0.19, total=4141.5, n_correct=2445.85, ppl=3.2, accuracy=59.057, wps=13801.8, ups=1.12, wpb=12351.9, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.327, clip=0, loss_scale=32, train_wall=89, gb_free=16.7, wall=10234
2023-07-17 14:57:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 14:57:32 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 3.754 | trans_loss 5.672 | nll_loss 2.976 | w2v_ctc_loss 1.171 | task_loss 4.304 | contrastive_loss 0.257 | total 4003.4 | n_correct 2401.3 | ppl 7.87 | accuracy 59.982 | uer 18.515 | wer 20.219 | raw_wer 20.219 | bleu 18.89 | wps 2311.2 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.89
2023-07-17 14:57:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-17 14:57:32 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 14:57:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 14:57:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.89) (writing took 8.511927981977351 seconds)
2023-07-17 14:57:41 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-17 14:57:41 | INFO | train | epoch 008 | loss 2.466 | trans_loss 3.514 | nll_loss 1.673 | w2v_ctc_loss 0.723 | task_loss 0.867 | contrastive_loss 0.185 | total 4138.65 | n_correct 2440.52 | ppl 3.19 | accuracy 58.969 | wps 13349.2 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.333 | clip 0 | loss_scale 32 | train_wall 1316 | gb_free 17.1 | wall 10343
2023-07-17 14:57:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 14:57:41 | INFO | fairseq.trainer | begin training epoch 9
2023-07-17 14:57:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 14:58:03 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.468, trans_loss=3.51, nll_loss=1.669, w2v_ctc_loss=0.711, task_loss=0.835, contrastive_loss=0.316, total=4139.35, n_correct=2455.47, ppl=3.18, accuracy=59.32, wps=9451, ups=0.77, wpb=12332.8, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.33, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=10365
2023-07-17 14:59:32 | INFO | train_inner | epoch 009:    115 / 1474 loss=2.418, trans_loss=3.482, nll_loss=1.631, w2v_ctc_loss=0.684, task_loss=0.818, contrastive_loss=0.135, total=4181.9, n_correct=2517.64, ppl=3.1, accuracy=60.203, wps=13939.9, ups=1.12, wpb=12493.2, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.325, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=10454
2023-07-17 15:01:03 | INFO | train_inner | epoch 009:    215 / 1474 loss=2.426, trans_loss=3.492, nll_loss=1.644, w2v_ctc_loss=0.691, task_loss=0.938, contrastive_loss=0.094, total=4062.07, n_correct=2430.78, ppl=3.13, accuracy=59.841, wps=13469.6, ups=1.11, wpb=12136.5, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.33, clip=0, loss_scale=32, train_wall=90, gb_free=15.8, wall=10545
2023-07-17 15:01:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 15:01:27 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.759 | trans_loss 5.678 | nll_loss 2.98 | w2v_ctc_loss 1.166 | task_loss 4.267 | contrastive_loss 0.264 | total 4003.4 | n_correct 2404.3 | ppl 7.89 | accuracy 60.056 | uer 18.647 | wer 20.335 | raw_wer 20.335 | bleu 18.75 | wps 2211.8 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.89
2023-07-17 15:01:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-17 15:01:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_9_12000.pt
2023-07-17 15:01:29 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_9_12000.pt
2023-07-17 15:01:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.75) (writing took 6.174037454067729 seconds)
2023-07-17 15:03:03 | INFO | train_inner | epoch 009:    315 / 1474 loss=2.418, trans_loss=3.479, nll_loss=1.629, w2v_ctc_loss=0.681, task_loss=0.809, contrastive_loss=0.142, total=4152.1, n_correct=2501.04, ppl=3.09, accuracy=60.236, wps=10314.9, ups=0.83, wpb=12422.8, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.328, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=10665
2023-07-17 15:04:34 | INFO | train_inner | epoch 009:    415 / 1474 loss=2.422, trans_loss=3.487, nll_loss=1.64, w2v_ctc_loss=0.69, task_loss=0.848, contrastive_loss=0.111, total=4203.78, n_correct=2514.33, ppl=3.12, accuracy=59.811, wps=13798.1, ups=1.1, wpb=12545.5, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.326, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=10756
2023-07-17 15:06:03 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.446, trans_loss=3.496, nll_loss=1.65, w2v_ctc_loss=0.708, task_loss=0.91, contrastive_loss=0.161, total=4112.78, n_correct=2454.58, ppl=3.14, accuracy=59.682, wps=13765.3, ups=1.12, wpb=12260.1, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.334, clip=0, loss_scale=32, train_wall=89, gb_free=16.3, wall=10845
2023-07-17 15:07:33 | INFO | train_inner | epoch 009:    615 / 1474 loss=2.422, trans_loss=3.487, nll_loss=1.641, w2v_ctc_loss=0.687, task_loss=0.883, contrastive_loss=0.121, total=4131.32, n_correct=2477.75, ppl=3.12, accuracy=59.975, wps=13730.8, ups=1.11, wpb=12355.3, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.328, clip=0, loss_scale=32, train_wall=89, gb_free=17.9, wall=10935
2023-07-17 15:09:02 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.445, trans_loss=3.495, nll_loss=1.649, w2v_ctc_loss=0.702, task_loss=0.887, contrastive_loss=0.202, total=4082.11, n_correct=2434.26, ppl=3.14, accuracy=59.632, wps=13734.5, ups=1.13, wpb=12206.9, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.335, clip=0, loss_scale=32, train_wall=88, gb_free=17.1, wall=11024
2023-07-17 15:09:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-17 15:10:33 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.439, trans_loss=3.483, nll_loss=1.638, w2v_ctc_loss=0.702, task_loss=0.8, contrastive_loss=0.202, total=4197.6, n_correct=2514.57, ppl=3.11, accuracy=59.905, wps=13769.7, ups=1.1, wpb=12537.8, bsz=489.3, num_updates=12600, lr=0.000125988, gnorm=0.332, clip=0, loss_scale=16, train_wall=91, gb_free=14.6, wall=11115
2023-07-17 15:12:04 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.441, trans_loss=3.494, nll_loss=1.648, w2v_ctc_loss=0.694, task_loss=0.892, contrastive_loss=0.327, total=4146.05, n_correct=2480.78, ppl=3.13, accuracy=59.835, wps=13571.3, ups=1.1, wpb=12355.9, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.329, clip=0, loss_scale=16, train_wall=91, gb_free=17.9, wall=11206
2023-07-17 15:13:34 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.441, trans_loss=3.502, nll_loss=1.657, w2v_ctc_loss=0.7, task_loss=0.969, contrastive_loss=0.107, total=4101.48, n_correct=2442.46, ppl=3.15, accuracy=59.551, wps=13588.9, ups=1.11, wpb=12243.2, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.333, clip=0, loss_scale=16, train_wall=90, gb_free=16.1, wall=11296
2023-07-17 15:15:04 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.43, trans_loss=3.494, nll_loss=1.646, w2v_ctc_loss=0.697, task_loss=0.814, contrastive_loss=0.132, total=4179.09, n_correct=2504.53, ppl=3.13, accuracy=59.93, wps=13894, ups=1.12, wpb=12439.9, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.331, clip=0, loss_scale=16, train_wall=89, gb_free=15.5, wall=11386
2023-07-17 15:16:34 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.438, trans_loss=3.5, nll_loss=1.651, w2v_ctc_loss=0.7, task_loss=0.919, contrastive_loss=0.114, total=4140.66, n_correct=2474.51, ppl=3.14, accuracy=59.761, wps=13701.4, ups=1.1, wpb=12405, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.328, clip=0, loss_scale=16, train_wall=90, gb_free=17.2, wall=11476
2023-07-17 15:18:03 | INFO | train_inner | epoch 009:   1316 / 1474 loss=2.428, trans_loss=3.486, nll_loss=1.638, w2v_ctc_loss=0.679, task_loss=0.788, contrastive_loss=0.303, total=4204.43, n_correct=2533.55, ppl=3.11, accuracy=60.259, wps=14049.2, ups=1.12, wpb=12539.3, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.327, clip=0, loss_scale=16, train_wall=89, gb_free=17.8, wall=11565
2023-07-17 15:19:33 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.439, trans_loss=3.503, nll_loss=1.658, w2v_ctc_loss=0.703, task_loss=0.936, contrastive_loss=0.091, total=4069.19, n_correct=2428.07, ppl=3.16, accuracy=59.67, wps=13594.7, ups=1.12, wpb=12152.5, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.333, clip=0, loss_scale=16, train_wall=89, gb_free=16.8, wall=11655
2023-07-17 15:20:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 15:20:48 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 3.74 | trans_loss 5.652 | nll_loss 2.955 | w2v_ctc_loss 1.152 | task_loss 4.295 | contrastive_loss 0.257 | total 4003.4 | n_correct 2416.1 | ppl 7.75 | accuracy 60.351 | uer 17.997 | wer 19.88 | raw_wer 19.88 | bleu 18.95 | wps 2382.3 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 18.95
2023-07-17 15:20:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-07-17 15:20:48 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 15:20:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 15:20:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 9 @ 13258 updates, score 18.95) (writing took 8.643624971038662 seconds)
2023-07-17 15:20:57 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-17 15:20:57 | INFO | train | epoch 009 | loss 2.432 | trans_loss 3.491 | nll_loss 1.644 | w2v_ctc_loss 0.694 | task_loss 0.868 | contrastive_loss 0.166 | total 4137.17 | n_correct 2477.63 | ppl 3.13 | accuracy 59.887 | wps 13031.8 | ups 1.06 | wpb 12352.1 | bsz 457.7 | num_updates 13258 | lr 0.000122822 | gnorm 0.33 | clip 0 | loss_scale 16 | train_wall 1317 | gb_free 12 | wall 11739
2023-07-17 15:20:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 15:20:57 | INFO | fairseq.trainer | begin training epoch 10
2023-07-17 15:20:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 15:21:42 | INFO | train_inner | epoch 010:     42 / 1474 loss=2.419, trans_loss=3.482, nll_loss=1.633, w2v_ctc_loss=0.68, task_loss=0.824, contrastive_loss=0.189, total=4100.8, n_correct=2474.52, ppl=3.1, accuracy=60.342, wps=9443.9, ups=0.77, wpb=12243.3, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.333, clip=0, loss_scale=16, train_wall=88, gb_free=16.4, wall=11784
2023-07-17 15:23:12 | INFO | train_inner | epoch 010:    142 / 1474 loss=2.39, trans_loss=3.465, nll_loss=1.607, w2v_ctc_loss=0.659, task_loss=0.815, contrastive_loss=0.111, total=4247.35, n_correct=2587.82, ppl=3.05, accuracy=60.928, wps=14167.6, ups=1.11, wpb=12717.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.324, clip=0, loss_scale=16, train_wall=89, gb_free=12.1, wall=11874
2023-07-17 15:24:41 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.398, trans_loss=3.458, nll_loss=1.603, w2v_ctc_loss=0.664, task_loss=0.855, contrastive_loss=0.232, total=4122.82, n_correct=2516.13, ppl=3.04, accuracy=61.029, wps=13782.9, ups=1.12, wpb=12279.5, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.329, clip=0, loss_scale=16, train_wall=89, gb_free=16.4, wall=11963
2023-07-17 15:26:12 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.396, trans_loss=3.463, nll_loss=1.611, w2v_ctc_loss=0.665, task_loss=0.876, contrastive_loss=0.147, total=4138.27, n_correct=2516.91, ppl=3.05, accuracy=60.82, wps=13727.8, ups=1.11, wpb=12378.7, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.333, clip=0, loss_scale=16, train_wall=90, gb_free=16.6, wall=12053
2023-07-17 15:27:42 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.404, trans_loss=3.466, nll_loss=1.613, w2v_ctc_loss=0.656, task_loss=0.832, contrastive_loss=0.323, total=4196.37, n_correct=2546.6, ppl=3.06, accuracy=60.686, wps=13820.4, ups=1.1, wpb=12523.5, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.326, clip=0, loss_scale=16, train_wall=90, gb_free=16.6, wall=12144
2023-07-17 15:29:12 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.414, trans_loss=3.476, nll_loss=1.622, w2v_ctc_loss=0.68, task_loss=0.932, contrastive_loss=0.1, total=4102.8, n_correct=2484.16, ppl=3.08, accuracy=60.548, wps=13609.5, ups=1.11, wpb=12224.8, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.33, clip=0, loss_scale=16, train_wall=89, gb_free=17.1, wall=12234
2023-07-17 15:30:42 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.412, trans_loss=3.475, nll_loss=1.623, w2v_ctc_loss=0.673, task_loss=0.822, contrastive_loss=0.214, total=4176.56, n_correct=2534.94, ppl=3.08, accuracy=60.694, wps=13894.9, ups=1.11, wpb=12467.5, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.329, clip=0, loss_scale=16, train_wall=89, gb_free=16.4, wall=12324
2023-07-17 15:32:11 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.412, trans_loss=3.474, nll_loss=1.622, w2v_ctc_loss=0.685, task_loss=0.863, contrastive_loss=0.099, total=4125.87, n_correct=2500.67, ppl=3.08, accuracy=60.61, wps=13787.1, ups=1.12, wpb=12315.5, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.332, clip=0, loss_scale=16, train_wall=89, gb_free=14.7, wall=12413
2023-07-17 15:32:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 15:32:35 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.743 | trans_loss 5.644 | nll_loss 2.936 | w2v_ctc_loss 1.182 | task_loss 4.309 | contrastive_loss 0.256 | total 4003.4 | n_correct 2428 | ppl 7.65 | accuracy 60.648 | uer 18.05 | wer 19.764 | raw_wer 19.764 | bleu 19.18 | wps 2354.8 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.18
2023-07-17 15:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-17 15:32:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_10_14000.pt
2023-07-17 15:32:37 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_10_14000.pt
2023-07-17 15:32:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.18) (writing took 9.533481442951597 seconds)
2023-07-17 15:34:14 | INFO | train_inner | epoch 010:    842 / 1474 loss=2.4, trans_loss=3.473, nll_loss=1.62, w2v_ctc_loss=0.666, task_loss=0.858, contrastive_loss=0.099, total=4128.44, n_correct=2504.2, ppl=3.07, accuracy=60.657, wps=10002.4, ups=0.81, wpb=12345, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.327, clip=0, loss_scale=16, train_wall=89, gb_free=14.9, wall=12536
2023-07-17 15:35:43 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.409, trans_loss=3.47, nll_loss=1.619, w2v_ctc_loss=0.678, task_loss=0.832, contrastive_loss=0.14, total=4160.94, n_correct=2528.24, ppl=3.07, accuracy=60.761, wps=13910.3, ups=1.12, wpb=12380.2, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.332, clip=0, loss_scale=16, train_wall=89, gb_free=15.6, wall=12625
2023-07-17 15:37:13 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.404, trans_loss=3.477, nll_loss=1.627, w2v_ctc_loss=0.676, task_loss=0.94, contrastive_loss=0.113, total=4067.53, n_correct=2454.75, ppl=3.09, accuracy=60.35, wps=13501.1, ups=1.11, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.332, clip=0, loss_scale=16, train_wall=89, gb_free=17, wall=12715
2023-07-17 15:38:43 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.413, trans_loss=3.479, nll_loss=1.629, w2v_ctc_loss=0.681, task_loss=0.965, contrastive_loss=0.094, total=4044.03, n_correct=2442.28, ppl=3.09, accuracy=60.392, wps=13502.9, ups=1.12, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.333, clip=0, loss_scale=16, train_wall=89, gb_free=17.4, wall=12805
2023-07-17 15:40:13 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.406, trans_loss=3.472, nll_loss=1.624, w2v_ctc_loss=0.677, task_loss=0.887, contrastive_loss=0.089, total=4110.41, n_correct=2489.64, ppl=3.08, accuracy=60.569, wps=13701.5, ups=1.11, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.332, clip=0, loss_scale=16, train_wall=89, gb_free=16.6, wall=12895
2023-07-17 15:41:42 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.401, trans_loss=3.472, nll_loss=1.621, w2v_ctc_loss=0.67, task_loss=0.884, contrastive_loss=0.102, total=4121.38, n_correct=2499.75, ppl=3.07, accuracy=60.653, wps=13704.5, ups=1.11, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.331, clip=0, loss_scale=32, train_wall=89, gb_free=14.3, wall=12984
2023-07-17 15:43:13 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.418, trans_loss=3.477, nll_loss=1.629, w2v_ctc_loss=0.662, task_loss=0.817, contrastive_loss=0.353, total=4192.39, n_correct=2542.13, ppl=3.09, accuracy=60.637, wps=13778.5, ups=1.1, wpb=12477.9, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.331, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=13075
2023-07-17 15:43:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 15:44:06 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 3.722 | trans_loss 5.636 | nll_loss 2.929 | w2v_ctc_loss 1.129 | task_loss 4.302 | contrastive_loss 0.258 | total 4003.4 | n_correct 2430 | ppl 7.61 | accuracy 60.698 | uer 17.692 | wer 19.414 | raw_wer 19.414 | bleu 19.26 | wps 2341.3 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.26
2023-07-17 15:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-17 15:44:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 15:44:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 15:44:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.26) (writing took 8.431262530037202 seconds)
2023-07-17 15:44:14 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-17 15:44:14 | INFO | train | epoch 010 | loss 2.406 | trans_loss 3.471 | nll_loss 1.619 | w2v_ctc_loss 0.67 | task_loss 0.866 | contrastive_loss 0.169 | total 4138.65 | n_correct 2511.03 | ppl 3.07 | accuracy 60.673 | wps 13031.7 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.33 | clip 0 | loss_scale 32 | train_wall 1316 | gb_free 17.4 | wall 13136
2023-07-17 15:44:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 15:44:15 | INFO | fairseq.trainer | begin training epoch 11
2023-07-17 15:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 15:45:23 | INFO | train_inner | epoch 011:     68 / 1474 loss=2.381, trans_loss=3.453, nll_loss=1.596, w2v_ctc_loss=0.65, task_loss=0.802, contrastive_loss=0.178, total=4175.24, n_correct=2564.33, ppl=3.02, accuracy=61.418, wps=9578.2, ups=0.77, wpb=12460.8, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.326, clip=0, loss_scale=32, train_wall=89, gb_free=16.9, wall=13205
2023-07-17 15:46:53 | INFO | train_inner | epoch 011:    168 / 1474 loss=2.372, trans_loss=3.451, nll_loss=1.595, w2v_ctc_loss=0.65, task_loss=0.895, contrastive_loss=0.098, total=4087.78, n_correct=2504.37, ppl=3.02, accuracy=61.265, wps=13631.6, ups=1.11, wpb=12225.8, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.327, clip=0, loss_scale=32, train_wall=89, gb_free=16.7, wall=13295
2023-07-17 15:48:22 | INFO | train_inner | epoch 011:    268 / 1474 loss=2.37, trans_loss=3.45, nll_loss=1.593, w2v_ctc_loss=0.646, task_loss=0.893, contrastive_loss=0.093, total=4118.77, n_correct=2528.48, ppl=3.02, accuracy=61.389, wps=13748.3, ups=1.12, wpb=12285.5, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.329, clip=0, loss_scale=32, train_wall=89, gb_free=12.7, wall=13384
mt_weight tensor(0.2301, device='cuda:0')
asr_weight tensor(0.1513, device='cuda:0')
2023-07-17 15:49:51 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.377, trans_loss=3.448, nll_loss=1.589, w2v_ctc_loss=0.646, task_loss=0.888, contrastive_loss=0.096, total=4097.83, n_correct=2520.09, ppl=3.01, accuracy=61.498, wps=13766.2, ups=1.13, wpb=12202.1, bsz=444.2, num_updates=15100, lr=0.000115087, gnorm=0.247, clip=0, loss_scale=32, train_wall=88, gb_free=16.4, wall=13473
2023-07-17 15:51:21 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.4, trans_loss=3.464, nll_loss=1.606, w2v_ctc_loss=0.649, task_loss=0.909, contrastive_loss=0.254, total=4110.64, n_correct=2512.06, ppl=3.04, accuracy=61.111, wps=13590.5, ups=1.11, wpb=12265.6, bsz=450.5, num_updates=15200, lr=0.000114708, gnorm=0.246, clip=0, loss_scale=32, train_wall=90, gb_free=16.5, wall=13563
2023-07-17 15:52:52 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.404, trans_loss=3.46, nll_loss=1.607, w2v_ctc_loss=0.66, task_loss=0.929, contrastive_loss=0.252, total=4071.69, n_correct=2489.96, ppl=3.05, accuracy=61.153, wps=13449.5, ups=1.1, wpb=12176.5, bsz=440.6, num_updates=15300, lr=0.000114332, gnorm=0.251, clip=0, loss_scale=32, train_wall=90, gb_free=16.5, wall=13654
2023-07-17 15:54:21 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.4, trans_loss=3.456, nll_loss=1.6, w2v_ctc_loss=0.651, task_loss=0.853, contrastive_loss=0.333, total=4157.2, n_correct=2540.82, ppl=3.03, accuracy=61.119, wps=13795.2, ups=1.11, wpb=12400.2, bsz=464.4, num_updates=15400, lr=0.000113961, gnorm=0.248, clip=0, loss_scale=32, train_wall=89, gb_free=16.9, wall=13743
2023-07-17 15:55:51 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.387, trans_loss=3.459, nll_loss=1.602, w2v_ctc_loss=0.658, task_loss=0.871, contrastive_loss=0.099, total=4174.91, n_correct=2558.72, ppl=3.04, accuracy=61.288, wps=13860.4, ups=1.11, wpb=12472.8, bsz=460.4, num_updates=15500, lr=0.000113592, gnorm=0.246, clip=0, loss_scale=32, train_wall=90, gb_free=17.1, wall=13833
2023-07-17 15:57:21 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.381, trans_loss=3.458, nll_loss=1.605, w2v_ctc_loss=0.657, task_loss=0.907, contrastive_loss=0.083, total=4118.44, n_correct=2513.83, ppl=3.04, accuracy=61.038, wps=13749.8, ups=1.12, wpb=12290.5, bsz=440.6, num_updates=15600, lr=0.000113228, gnorm=0.25, clip=0, loss_scale=32, train_wall=89, gb_free=11.2, wall=13923
2023-07-17 15:58:51 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.381, trans_loss=3.459, nll_loss=1.604, w2v_ctc_loss=0.655, task_loss=0.887, contrastive_loss=0.098, total=4140.92, n_correct=2534.16, ppl=3.04, accuracy=61.198, wps=13764, ups=1.11, wpb=12353.7, bsz=452.9, num_updates=15700, lr=0.000112867, gnorm=0.249, clip=0, loss_scale=32, train_wall=89, gb_free=15.8, wall=14013
2023-07-17 16:00:19 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.389, trans_loss=3.458, nll_loss=1.604, w2v_ctc_loss=0.659, task_loss=0.853, contrastive_loss=0.124, total=4136.99, n_correct=2535.35, ppl=3.04, accuracy=61.285, wps=13936.3, ups=1.13, wpb=12367, bsz=463.2, num_updates=15800, lr=0.000112509, gnorm=0.248, clip=0, loss_scale=32, train_wall=88, gb_free=17.7, wall=14101
2023-07-17 16:01:49 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.388, trans_loss=3.459, nll_loss=1.608, w2v_ctc_loss=0.662, task_loss=0.863, contrastive_loss=0.105, total=4185.65, n_correct=2556.56, ppl=3.05, accuracy=61.079, wps=13897.3, ups=1.11, wpb=12477.8, bsz=464.7, num_updates=15900, lr=0.000112154, gnorm=0.249, clip=0, loss_scale=32, train_wall=89, gb_free=14.3, wall=14191
2023-07-17 16:02:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-17 16:03:20 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.405, trans_loss=3.459, nll_loss=1.606, w2v_ctc_loss=0.666, task_loss=0.829, contrastive_loss=0.195, total=4170.25, n_correct=2553.41, ppl=3.04, accuracy=61.229, wps=13764, ups=1.1, wpb=12460.8, bsz=471.3, num_updates=16000, lr=0.000111803, gnorm=0.255, clip=0, loss_scale=16, train_wall=90, gb_free=17.5, wall=14282
2023-07-17 16:03:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.2301, device='cuda:2')
asr_weight tensor(0.1513, device='cuda:2')
mt_weight tensor(0.2301, device='cuda:1')
asr_weight tensor(0.1513, device='cuda:1')
mt_weight tensor(0.2301, device='cuda:4')
asr_weight tensor(0.1513, device='cuda:4')
mt_weight tensor(0.2301, device='cuda:6')
asr_weight tensor(0.1513, device='cuda:6')
mt_weight tensor(0.2301, device='cuda:3')
asr_weight tensor(0.1513, device='cuda:3')
mt_weight tensor(0.2301, device='cuda:5')
asr_weight tensor(0.1513, device='cuda:5')
mt_weight tensor(0.2301, device='cuda:7')
asr_weight tensor(0.1513, device='cuda:7')
2023-07-17 16:03:43 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.73 | trans_loss 5.626 | nll_loss 2.912 | w2v_ctc_loss 1.18 | task_loss 4.309 | contrastive_loss 0.251 | total 4003.4 | n_correct 2438.6 | ppl 7.53 | accuracy 60.913 | uer 17.705 | wer 19.354 | raw_wer 19.354 | bleu 19.51 | wps 2390.9 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.51
2023-07-17 16:03:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-17 16:03:43 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_11_16000.pt
2023-07-17 16:03:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_11_16000.pt
2023-07-17 16:03:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.51) (writing took 9.35463570302818 seconds)
2023-07-17 16:05:23 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.398, trans_loss=3.46, nll_loss=1.606, w2v_ctc_loss=0.646, task_loss=0.801, contrastive_loss=0.415, total=4191.56, n_correct=2558.48, ppl=3.04, accuracy=61.039, wps=10126.8, ups=0.81, wpb=12516.8, bsz=491.5, num_updates=16100, lr=0.000111456, gnorm=0.25, clip=0, loss_scale=16, train_wall=90, gb_free=17.6, wall=14405
2023-07-17 16:06:53 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.378, trans_loss=3.458, nll_loss=1.605, w2v_ctc_loss=0.652, task_loss=0.829, contrastive_loss=0.108, total=4161.81, n_correct=2551.22, ppl=3.04, accuracy=61.301, wps=13792.2, ups=1.11, wpb=12429.3, bsz=469.8, num_updates=16200, lr=0.000111111, gnorm=0.245, clip=0, loss_scale=16, train_wall=90, gb_free=17, wall=14495
2023-07-17 16:06:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 16:07:22 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.712 | trans_loss 5.616 | nll_loss 2.902 | w2v_ctc_loss 1.124 | task_loss 4.274 | contrastive_loss 0.25 | total 4003.4 | n_correct 2436.1 | ppl 7.48 | accuracy 60.851 | uer 17.641 | wer 19.395 | raw_wer 19.395 | bleu 19.36 | wps 2263.4 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 19.51
2023-07-17 16:07:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-07-17 16:07:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.3606.pt
2023-07-17 16:07:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.3606.pt
2023-07-17 16:07:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.3606.pt (epoch 11 @ 16205 updates, score 19.36) (writing took 5.39796320500318 seconds)
2023-07-17 16:07:28 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-17 16:07:28 | INFO | train | epoch 011 | loss 2.387 | trans_loss 3.456 | nll_loss 1.601 | w2v_ctc_loss 0.654 | task_loss 0.867 | contrastive_loss 0.166 | total 4138.72 | n_correct 2534.25 | ppl 3.03 | accuracy 61.233 | wps 13061.2 | ups 1.06 | wpb 12356 | bsz 458.6 | num_updates 16205 | lr 0.000111094 | gnorm 0.263 | clip 0 | loss_scale 16 | train_wall 1315 | gb_free 17.3 | wall 14530
2023-07-17 16:07:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 16:07:28 | INFO | fairseq.trainer | begin training epoch 12
2023-07-17 16:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 16:09:01 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.361, trans_loss=3.433, nll_loss=1.569, w2v_ctc_loss=0.637, task_loss=0.835, contrastive_loss=0.151, total=4139.2, n_correct=2574.45, ppl=2.97, accuracy=62.197, wps=9713.3, ups=0.79, wpb=12361.4, bsz=468.8, num_updates=16300, lr=0.00011077, gnorm=0.246, clip=0, loss_scale=16, train_wall=88, gb_free=16.1, wall=14623
2023-07-17 16:10:31 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.364, trans_loss=3.437, nll_loss=1.575, w2v_ctc_loss=0.642, task_loss=0.893, contrastive_loss=0.087, total=4126.87, n_correct=2560.75, ppl=2.98, accuracy=62.051, wps=13760.4, ups=1.11, wpb=12361.2, bsz=443.9, num_updates=16400, lr=0.000110432, gnorm=0.244, clip=0, loss_scale=16, train_wall=89, gb_free=16.6, wall=14712
2023-07-17 16:12:01 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.35, trans_loss=3.434, nll_loss=1.574, w2v_ctc_loss=0.628, task_loss=0.811, contrastive_loss=0.126, total=4203.54, n_correct=2612.54, ppl=2.98, accuracy=62.151, wps=13907.1, ups=1.11, wpb=12550.7, bsz=481.6, num_updates=16500, lr=0.000110096, gnorm=0.242, clip=0, loss_scale=16, train_wall=90, gb_free=14.8, wall=14803
2023-07-17 16:13:31 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.364, trans_loss=3.44, nll_loss=1.581, w2v_ctc_loss=0.637, task_loss=0.849, contrastive_loss=0.104, total=4149.28, n_correct=2571.45, ppl=2.99, accuracy=61.973, wps=13762.4, ups=1.11, wpb=12403.5, bsz=460.7, num_updates=16600, lr=0.000109764, gnorm=0.244, clip=0, loss_scale=16, train_wall=90, gb_free=15.4, wall=14893
2023-07-17 16:15:00 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.381, trans_loss=3.453, nll_loss=1.594, w2v_ctc_loss=0.652, task_loss=0.876, contrastive_loss=0.115, total=4106.46, n_correct=2533.1, ppl=3.02, accuracy=61.686, wps=13660.2, ups=1.12, wpb=12220.6, bsz=451.8, num_updates=16700, lr=0.000109435, gnorm=0.247, clip=0, loss_scale=16, train_wall=89, gb_free=17.9, wall=14982
2023-07-17 16:16:31 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.379, trans_loss=3.438, nll_loss=1.582, w2v_ctc_loss=0.644, task_loss=0.824, contrastive_loss=0.2, total=4190.91, n_correct=2591.76, ppl=2.99, accuracy=61.842, wps=13848, ups=1.11, wpb=12532.1, bsz=474.7, num_updates=16800, lr=0.000109109, gnorm=0.248, clip=0, loss_scale=16, train_wall=90, gb_free=16, wall=15073
2023-07-17 16:18:00 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.365, trans_loss=3.436, nll_loss=1.577, w2v_ctc_loss=0.628, task_loss=0.796, contrastive_loss=0.318, total=4203.66, n_correct=2608.96, ppl=2.98, accuracy=62.064, wps=14014.7, ups=1.12, wpb=12493.6, bsz=486.5, num_updates=16900, lr=0.000108786, gnorm=0.241, clip=0, loss_scale=16, train_wall=89, gb_free=17.5, wall=15162
2023-07-17 16:19:30 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.364, trans_loss=3.443, nll_loss=1.582, w2v_ctc_loss=0.644, task_loss=0.881, contrastive_loss=0.101, total=4095.72, n_correct=2538, ppl=2.99, accuracy=61.967, wps=13646.5, ups=1.12, wpb=12238.8, bsz=448.3, num_updates=17000, lr=0.000108465, gnorm=0.246, clip=0, loss_scale=16, train_wall=89, gb_free=17.3, wall=15252
2023-07-17 16:21:00 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.376, trans_loss=3.441, nll_loss=1.583, w2v_ctc_loss=0.64, task_loss=0.888, contrastive_loss=0.166, total=4162.82, n_correct=2578.34, ppl=3, accuracy=61.937, wps=13763.8, ups=1.11, wpb=12435.1, bsz=458.1, num_updates=17100, lr=0.000108148, gnorm=0.245, clip=0, loss_scale=16, train_wall=90, gb_free=16.3, wall=15342
2023-07-17 16:22:30 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.38, trans_loss=3.446, nll_loss=1.589, w2v_ctc_loss=0.647, task_loss=0.883, contrastive_loss=0.179, total=4117.63, n_correct=2539.94, ppl=3.01, accuracy=61.685, wps=13730.8, ups=1.12, wpb=12286.8, bsz=452.4, num_updates=17200, lr=0.000107833, gnorm=0.25, clip=0, loss_scale=16, train_wall=89, gb_free=17.1, wall=15432
2023-07-17 16:23:59 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.403, trans_loss=3.449, nll_loss=1.592, w2v_ctc_loss=0.655, task_loss=0.912, contrastive_loss=0.241, total=4046.48, n_correct=2498.74, ppl=3.02, accuracy=61.751, wps=13557, ups=1.12, wpb=12084, bsz=434.4, num_updates=17300, lr=0.000107521, gnorm=0.257, clip=0, loss_scale=16, train_wall=89, gb_free=16.1, wall=15521
2023-07-17 16:25:28 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.385, trans_loss=3.451, nll_loss=1.597, w2v_ctc_loss=0.658, task_loss=0.846, contrastive_loss=0.198, total=4201.13, n_correct=2577.62, ppl=3.03, accuracy=61.355, wps=13971, ups=1.11, wpb=12545, bsz=478.7, num_updates=17400, lr=0.000107211, gnorm=0.244, clip=0, loss_scale=16, train_wall=89, gb_free=17.4, wall=15610
2023-07-17 16:26:58 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.375, trans_loss=3.451, nll_loss=1.597, w2v_ctc_loss=0.653, task_loss=0.969, contrastive_loss=0.082, total=4070.27, n_correct=2513.7, ppl=3.03, accuracy=61.758, wps=13578, ups=1.12, wpb=12168, bsz=429.2, num_updates=17500, lr=0.000106904, gnorm=0.247, clip=0, loss_scale=16, train_wall=89, gb_free=16.1, wall=15700
2023-07-17 16:28:27 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.379, trans_loss=3.444, nll_loss=1.589, w2v_ctc_loss=0.638, task_loss=0.872, contrastive_loss=0.222, total=4139.63, n_correct=2555.78, ppl=3.01, accuracy=61.739, wps=13823.5, ups=1.12, wpb=12331.2, bsz=458.7, num_updates=17600, lr=0.0001066, gnorm=0.245, clip=0, loss_scale=16, train_wall=89, gb_free=17.2, wall=15789
2023-07-17 16:29:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 16:30:02 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.708 | trans_loss 5.602 | nll_loss 2.885 | w2v_ctc_loss 1.168 | task_loss 4.302 | contrastive_loss 0.251 | total 4003.4 | n_correct 2453 | ppl 7.39 | accuracy 61.273 | uer 17.737 | wer 19.362 | raw_wer 19.362 | bleu 19.63 | wps 2382.2 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.63
2023-07-17 16:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-07-17 16:30:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 16:30:06 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 16:30:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 12 @ 17679 updates, score 19.63) (writing took 8.296390845091082 seconds)
2023-07-17 16:30:11 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-17 16:30:11 | INFO | train | epoch 012 | loss 2.373 | trans_loss 3.443 | nll_loss 1.585 | w2v_ctc_loss 0.643 | task_loss 0.867 | contrastive_loss 0.161 | total 4138.65 | n_correct 2560.21 | ppl 3 | accuracy 61.861 | wps 13362.6 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 17679 | lr 0.000106362 | gnorm 0.246 | clip 0 | loss_scale 16 | train_wall 1316 | gb_free 13.2 | wall 15893
2023-07-17 16:30:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 16:30:11 | INFO | fairseq.trainer | begin training epoch 13
2023-07-17 16:30:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 16:30:38 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.377, trans_loss=3.446, nll_loss=1.59, w2v_ctc_loss=0.653, task_loss=0.9, contrastive_loss=0.093, total=4096.49, n_correct=2529.28, ppl=3.01, accuracy=61.743, wps=9378.7, ups=0.77, wpb=12243.5, bsz=443.1, num_updates=17700, lr=0.000106299, gnorm=0.247, clip=0, loss_scale=16, train_wall=89, gb_free=14.8, wall=15920
2023-07-17 16:32:08 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.344, trans_loss=3.422, nll_loss=1.558, w2v_ctc_loss=0.623, task_loss=0.867, contrastive_loss=0.108, total=4160.97, n_correct=2603.43, ppl=2.94, accuracy=62.568, wps=13803.8, ups=1.11, wpb=12418.2, bsz=454.3, num_updates=17800, lr=0.000106, gnorm=0.241, clip=0, loss_scale=16, train_wall=90, gb_free=16.5, wall=16010
2023-07-17 16:33:39 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.364, trans_loss=3.425, nll_loss=1.565, w2v_ctc_loss=0.624, task_loss=0.801, contrastive_loss=0.395, total=4212.08, n_correct=2632.07, ppl=2.96, accuracy=62.489, wps=13790.3, ups=1.1, wpb=12529.8, bsz=494.6, num_updates=17900, lr=0.000105703, gnorm=0.241, clip=0, loss_scale=16, train_wall=90, gb_free=14.9, wall=16101
2023-07-17 16:35:08 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.347, trans_loss=3.426, nll_loss=1.561, w2v_ctc_loss=0.624, task_loss=0.903, contrastive_loss=0.089, total=4102.3, n_correct=2575.67, ppl=2.95, accuracy=62.786, wps=13653.1, ups=1.12, wpb=12230, bsz=441.1, num_updates=18000, lr=0.000105409, gnorm=0.248, clip=0, loss_scale=32, train_wall=89, gb_free=17.4, wall=16190
2023-07-17 16:35:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 16:35:33 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.701 | trans_loss 5.609 | nll_loss 2.89 | w2v_ctc_loss 1.109 | task_loss 4.267 | contrastive_loss 0.255 | total 4003.4 | n_correct 2449.8 | ppl 7.41 | accuracy 61.193 | uer 17.604 | wer 19.556 | raw_wer 19.556 | bleu 19.55 | wps 2210.2 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.63
2023-07-17 16:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-17 16:35:33 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_13_18000.pt
2023-07-17 16:35:35 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_13_18000.pt
2023-07-17 16:35:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.55) (writing took 6.940847333986312 seconds)
2023-07-17 16:37:09 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.356, trans_loss=3.432, nll_loss=1.57, w2v_ctc_loss=0.629, task_loss=0.812, contrastive_loss=0.151, total=4177.29, n_correct=2613.56, ppl=2.97, accuracy=62.566, wps=10325.6, ups=0.83, wpb=12461.8, bsz=477.6, num_updates=18100, lr=0.000105118, gnorm=0.245, clip=0, loss_scale=32, train_wall=88, gb_free=17.6, wall=16311
2023-07-17 16:38:40 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.368, trans_loss=3.434, nll_loss=1.573, w2v_ctc_loss=0.634, task_loss=0.838, contrastive_loss=0.201, total=4201.22, n_correct=2613.63, ppl=2.98, accuracy=62.211, wps=13789, ups=1.1, wpb=12536.9, bsz=478.4, num_updates=18200, lr=0.000104828, gnorm=0.247, clip=0, loss_scale=32, train_wall=90, gb_free=13.2, wall=16402
2023-07-17 16:40:09 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.346, trans_loss=3.426, nll_loss=1.563, w2v_ctc_loss=0.625, task_loss=0.843, contrastive_loss=0.084, total=4161.98, n_correct=2609.19, ppl=2.96, accuracy=62.691, wps=13878, ups=1.12, wpb=12435.5, bsz=462.4, num_updates=18300, lr=0.000104542, gnorm=0.245, clip=0, loss_scale=32, train_wall=89, gb_free=16, wall=16491
2023-07-17 16:41:40 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.371, trans_loss=3.433, nll_loss=1.572, w2v_ctc_loss=0.649, task_loss=0.961, contrastive_loss=0.084, total=4096.76, n_correct=2549.89, ppl=2.97, accuracy=62.242, wps=13566.1, ups=1.11, wpb=12226.1, bsz=426.8, num_updates=18400, lr=0.000104257, gnorm=0.25, clip=0, loss_scale=32, train_wall=90, gb_free=16.8, wall=16582
2023-07-17 16:43:11 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.36, trans_loss=3.432, nll_loss=1.571, w2v_ctc_loss=0.631, task_loss=0.879, contrastive_loss=0.145, total=4121.73, n_correct=2564.5, ppl=2.97, accuracy=62.219, wps=13493.8, ups=1.1, wpb=12319.8, bsz=460, num_updates=18500, lr=0.000103975, gnorm=0.248, clip=0, loss_scale=32, train_wall=91, gb_free=15, wall=16673
2023-07-17 16:44:40 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.351, trans_loss=3.432, nll_loss=1.572, w2v_ctc_loss=0.629, task_loss=0.883, contrastive_loss=0.096, total=4107.01, n_correct=2563.36, ppl=2.97, accuracy=62.414, wps=13762.5, ups=1.12, wpb=12264.1, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.244, clip=0, loss_scale=32, train_wall=89, gb_free=16.1, wall=16762
2023-07-17 16:46:09 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.373, trans_loss=3.43, nll_loss=1.573, w2v_ctc_loss=0.642, task_loss=0.915, contrastive_loss=0.163, total=4081.02, n_correct=2536.98, ppl=2.98, accuracy=62.165, wps=13671.5, ups=1.12, wpb=12208.8, bsz=440.1, num_updates=18700, lr=0.000103418, gnorm=0.248, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=16851
2023-07-17 16:47:39 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.352, trans_loss=3.43, nll_loss=1.569, w2v_ctc_loss=0.626, task_loss=0.856, contrastive_loss=0.142, total=4105.62, n_correct=2567.89, ppl=2.97, accuracy=62.546, wps=13743.7, ups=1.12, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.245, clip=0, loss_scale=32, train_wall=89, gb_free=16.9, wall=16941
2023-07-17 16:49:09 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.366, trans_loss=3.441, nll_loss=1.581, w2v_ctc_loss=0.64, task_loss=0.923, contrastive_loss=0.087, total=4110.35, n_correct=2556.97, ppl=2.99, accuracy=62.208, wps=13655.1, ups=1.11, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.25, clip=0, loss_scale=32, train_wall=90, gb_free=15.1, wall=17031
2023-07-17 16:50:38 | INFO | train_inner | epoch 013:   1321 / 1474 loss=2.36, trans_loss=3.429, nll_loss=1.57, w2v_ctc_loss=0.63, task_loss=0.852, contrastive_loss=0.216, total=4112.2, n_correct=2572.21, ppl=2.97, accuracy=62.551, wps=13671.6, ups=1.11, wpb=12280.4, bsz=462.3, num_updates=19000, lr=0.000102598, gnorm=0.248, clip=0, loss_scale=32, train_wall=89, gb_free=17.7, wall=17120
2023-07-17 16:52:09 | INFO | train_inner | epoch 013:   1421 / 1474 loss=2.367, trans_loss=3.438, nll_loss=1.579, w2v_ctc_loss=0.63, task_loss=0.852, contrastive_loss=0.235, total=4180.88, n_correct=2602.13, ppl=2.99, accuracy=62.239, wps=13726.7, ups=1.1, wpb=12470.5, bsz=468.3, num_updates=19100, lr=0.000102329, gnorm=0.25, clip=0, loss_scale=32, train_wall=90, gb_free=15.5, wall=17211
2023-07-17 16:52:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 16:53:21 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.69 | trans_loss 5.592 | nll_loss 2.875 | w2v_ctc_loss 1.138 | task_loss 4.33 | contrastive_loss 0.25 | total 4003.4 | n_correct 2449.9 | ppl 7.34 | accuracy 61.195 | uer 17.408 | wer 19.093 | raw_wer 19.093 | bleu 19.58 | wps 2179.9 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.63
2023-07-17 16:53:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-17 16:53:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.5803.pt
2023-07-17 16:53:23 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.5803.pt
2023-07-17 16:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.5803.pt (epoch 13 @ 19153 updates, score 19.58) (writing took 5.402708000037819 seconds)
2023-07-17 16:53:27 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-17 16:53:27 | INFO | train | epoch 013 | loss 2.359 | trans_loss 3.43 | nll_loss 1.569 | w2v_ctc_loss 0.631 | task_loss 0.867 | contrastive_loss 0.157 | total 4138.65 | n_correct 2583.86 | ppl 2.97 | accuracy 62.432 | wps 13045.5 | ups 1.06 | wpb 12355.8 | bsz 458.5 | num_updates 19153 | lr 0.000102187 | gnorm 0.246 | clip 0 | loss_scale 32 | train_wall 1319 | gb_free 17.7 | wall 17289
2023-07-17 16:53:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 16:53:27 | INFO | fairseq.trainer | begin training epoch 14
2023-07-17 16:53:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 16:54:17 | INFO | train_inner | epoch 014:     47 / 1474 loss=2.324, trans_loss=3.409, nll_loss=1.543, w2v_ctc_loss=0.614, task_loss=0.791, contrastive_loss=0.103, total=4176.2, n_correct=2640.05, ppl=2.91, accuracy=63.217, wps=9763.9, ups=0.78, wpb=12486.4, bsz=483.4, num_updates=19200, lr=0.000102062, gnorm=0.238, clip=0, loss_scale=32, train_wall=88, gb_free=11.2, wall=17339
2023-07-17 16:55:46 | INFO | train_inner | epoch 014:    147 / 1474 loss=2.327, trans_loss=3.411, nll_loss=1.542, w2v_ctc_loss=0.613, task_loss=0.878, contrastive_loss=0.081, total=4080.86, n_correct=2587.26, ppl=2.91, accuracy=63.4, wps=13690, ups=1.12, wpb=12203.2, bsz=449.3, num_updates=19300, lr=0.000101797, gnorm=0.241, clip=0, loss_scale=32, train_wall=89, gb_free=17, wall=17428
2023-07-17 16:57:16 | INFO | train_inner | epoch 014:    247 / 1474 loss=2.35, trans_loss=3.422, nll_loss=1.556, w2v_ctc_loss=0.615, task_loss=0.914, contrastive_loss=0.216, total=4106.97, n_correct=2589.12, ppl=2.94, accuracy=63.042, wps=13564.1, ups=1.11, wpb=12224.4, bsz=440, num_updates=19400, lr=0.000101535, gnorm=0.245, clip=0, loss_scale=32, train_wall=90, gb_free=12.7, wall=17518
2023-07-17 16:58:47 | INFO | train_inner | epoch 014:    347 / 1474 loss=2.325, trans_loss=3.404, nll_loss=1.543, w2v_ctc_loss=0.612, task_loss=0.791, contrastive_loss=0.126, total=4179.8, n_correct=2641.76, ppl=2.91, accuracy=63.203, wps=13821.2, ups=1.11, wpb=12454.9, bsz=483.8, num_updates=19500, lr=0.000101274, gnorm=0.246, clip=0, loss_scale=32, train_wall=90, gb_free=17.4, wall=17608
2023-07-17 17:00:17 | INFO | train_inner | epoch 014:    447 / 1474 loss=2.342, trans_loss=3.418, nll_loss=1.554, w2v_ctc_loss=0.619, task_loss=0.894, contrastive_loss=0.077, total=4120.38, n_correct=2593.38, ppl=2.94, accuracy=62.94, wps=13635.1, ups=1.11, wpb=12283.1, bsz=444.5, num_updates=19600, lr=0.000101015, gnorm=0.249, clip=0, loss_scale=32, train_wall=90, gb_free=17.3, wall=17699
2023-07-17 17:01:48 | INFO | train_inner | epoch 014:    547 / 1474 loss=2.352, trans_loss=3.426, nll_loss=1.563, w2v_ctc_loss=0.629, task_loss=0.918, contrastive_loss=0.12, total=4089.86, n_correct=2564.64, ppl=2.95, accuracy=62.707, wps=13490.1, ups=1.1, wpb=12262.9, bsz=443.3, num_updates=19700, lr=0.000100759, gnorm=0.249, clip=0, loss_scale=32, train_wall=90, gb_free=12.4, wall=17789
2023-07-17 17:03:17 | INFO | train_inner | epoch 014:    647 / 1474 loss=2.348, trans_loss=3.422, nll_loss=1.559, w2v_ctc_loss=0.618, task_loss=0.868, contrastive_loss=0.179, total=4158.94, n_correct=2612.64, ppl=2.95, accuracy=62.82, wps=13814.7, ups=1.11, wpb=12415.4, bsz=460, num_updates=19800, lr=0.000100504, gnorm=0.249, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=17879
2023-07-17 17:04:47 | INFO | train_inner | epoch 014:    747 / 1474 loss=2.332, trans_loss=3.415, nll_loss=1.551, w2v_ctc_loss=0.617, task_loss=0.841, contrastive_loss=0.09, total=4150.03, n_correct=2618.56, ppl=2.93, accuracy=63.097, wps=13872.6, ups=1.12, wpb=12407.3, bsz=465.5, num_updates=19900, lr=0.000100251, gnorm=0.243, clip=0, loss_scale=32, train_wall=89, gb_free=15.7, wall=17969
2023-07-17 17:06:16 | INFO | train_inner | epoch 014:    847 / 1474 loss=2.342, trans_loss=3.41, nll_loss=1.548, w2v_ctc_loss=0.611, task_loss=0.827, contrastive_loss=0.235, total=4162.8, n_correct=2624.01, ppl=2.92, accuracy=63.035, wps=13923.6, ups=1.12, wpb=12422.9, bsz=475.8, num_updates=20000, lr=0.0001, gnorm=0.245, clip=0, loss_scale=32, train_wall=89, gb_free=17.2, wall=18058
2023-07-17 17:06:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 17:06:42 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.698 | trans_loss 5.587 | nll_loss 2.864 | w2v_ctc_loss 1.162 | task_loss 4.302 | contrastive_loss 0.242 | total 4003.4 | n_correct 2454.3 | ppl 7.28 | accuracy 61.305 | uer 17.251 | wer 19.075 | raw_wer 19.075 | bleu 19.87 | wps 2110.6 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.87
2023-07-17 17:06:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-17 17:06:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_14_20000.pt
2023-07-17 17:06:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_14_20000.pt
2023-07-17 17:06:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.87) (writing took 9.433006120030768 seconds)
mt_weight tensor(0.0177, device='cuda:0')
asr_weight tensor(0.0013, device='cuda:0')
2023-07-17 17:07:55 | INFO | train_inner | epoch 014:    947 / 1474 loss=1.713, trans_loss=5.365, nll_loss=2.711, w2v_ctc_loss=0.568, task_loss=2.559, contrastive_loss=0.137, total=4159.46, n_correct=2602.86, ppl=6.55, accuracy=62.577, wps=4290, ups=1.01, wpb=4251.9, bsz=158.1, num_updates=20100, lr=9.97509e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=63, gb_free=15.6, wall=18157
2023-07-17 17:08:59 | INFO | train_inner | epoch 014:   1047 / 1474 loss=1.704, trans_loss=5.435, nll_loss=2.757, w2v_ctc_loss=0.561, task_loss=2.582, contrastive_loss=0.268, total=4155.93, n_correct=2602.11, ppl=6.76, accuracy=62.612, wps=6475.1, ups=1.56, wpb=4155.9, bsz=153, num_updates=20200, lr=9.95037e-05, gnorm=0.417, clip=0, loss_scale=64, train_wall=64, gb_free=16.7, wall=18221
2023-07-17 17:09:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-17 17:10:04 | INFO | train_inner | epoch 014:   1148 / 1474 loss=1.713, trans_loss=5.44, nll_loss=2.764, w2v_ctc_loss=0.572, task_loss=2.482, contrastive_loss=0.614, total=4212.46, n_correct=2632.99, ppl=6.79, accuracy=62.505, wps=6504.9, ups=1.54, wpb=4212.5, bsz=160.6, num_updates=20300, lr=9.92583e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=64, gb_free=15.9, wall=18286
2023-07-17 17:11:07 | INFO | train_inner | epoch 014:   1248 / 1474 loss=1.723, trans_loss=5.451, nll_loss=2.775, w2v_ctc_loss=0.582, task_loss=3.06, contrastive_loss=0.103, total=4021.19, n_correct=2504.24, ppl=6.85, accuracy=62.276, wps=6394.8, ups=1.59, wpb=4021.2, bsz=135.8, num_updates=20400, lr=9.90148e-05, gnorm=0.439, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=18349
2023-07-17 17:12:10 | INFO | train_inner | epoch 014:   1348 / 1474 loss=1.687, trans_loss=5.426, nll_loss=2.747, w2v_ctc_loss=0.554, task_loss=2.456, contrastive_loss=0.137, total=4213.9, n_correct=2643.83, ppl=6.71, accuracy=62.741, wps=6645.2, ups=1.58, wpb=4213.9, bsz=159.7, num_updates=20500, lr=9.8773e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=18412
2023-07-17 17:13:13 | INFO | train_inner | epoch 014:   1448 / 1474 loss=1.701, trans_loss=5.442, nll_loss=2.767, w2v_ctc_loss=0.563, task_loss=2.598, contrastive_loss=0.211, total=4130.28, n_correct=2581.23, ppl=6.81, accuracy=62.495, wps=6558, ups=1.59, wpb=4130.3, bsz=152, num_updates=20600, lr=9.85329e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=63, gb_free=15.6, wall=18475
2023-07-17 17:13:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.0177, device='cuda:2')
asr_weight tensor(0.0013, device='cuda:2')
mt_weight tensor(0.0177, device='cuda:6')
asr_weight tensor(0.0013, device='cuda:6')
mt_weight tensor(0.0177, device='cuda:7')
asr_weight tensor(0.0013, device='cuda:7')
mt_weight tensor(0.0177, device='cuda:1')
asr_weight tensor(0.0013, device='cuda:1')
mt_weight tensor(0.0177, device='cuda:4')
asr_weight tensor(0.0013, device='cuda:4')
mt_weight tensor(0.0177, device='cuda:5')
asr_weight tensor(0.0013, device='cuda:5')
mt_weight tensor(0.0177, device='cuda:3')
asr_weight tensor(0.0013, device='cuda:3')
2023-07-17 17:13:54 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.699 | trans_loss 5.581 | nll_loss 2.86 | w2v_ctc_loss 1.153 | task_loss 4.281 | contrastive_loss 0.246 | total 4003.4 | n_correct 2471 | ppl 7.26 | accuracy 61.723 | uer 17.394 | wer 19.149 | raw_wer 19.149 | bleu 20.01 | wps 2275.7 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 20.01
2023-07-17 17:13:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-07-17 17:13:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 17:13:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 17:14:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 14 @ 20626 updates, score 20.01) (writing took 8.637880148016848 seconds)
2023-07-17 17:14:03 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-17 17:14:03 | INFO | train | epoch 014 | loss 2.154 | trans_loss 3.816 | nll_loss 1.79 | w2v_ctc_loss 0.602 | task_loss 1.207 | contrastive_loss 0.159 | total 4137.46 | n_correct 2599.65 | ppl 3.46 | accuracy 62.832 | wps 10561.8 | ups 1.19 | wpb 8864.4 | bsz 329.1 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.32 | clip 0 | loss_scale 32 | train_wall 1153 | gb_free 16.6 | wall 18525
2023-07-17 17:14:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 17:14:03 | INFO | fairseq.trainer | begin training epoch 15
2023-07-17 17:14:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 17:14:58 | INFO | train_inner | epoch 015:     74 / 1474 loss=1.696, trans_loss=5.406, nll_loss=2.719, w2v_ctc_loss=0.554, task_loss=2.612, contrastive_loss=0.313, total=4083.88, n_correct=2574.43, ppl=6.59, accuracy=63.039, wps=3907.2, ups=0.96, wpb=4083.9, bsz=150.1, num_updates=20700, lr=9.82946e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=18580
2023-07-17 17:16:02 | INFO | train_inner | epoch 015:    174 / 1474 loss=1.693, trans_loss=5.395, nll_loss=2.703, w2v_ctc_loss=0.561, task_loss=2.712, contrastive_loss=0.129, total=4115.73, n_correct=2602.87, ppl=6.51, accuracy=63.242, wps=6429.4, ups=1.56, wpb=4115.7, bsz=148.9, num_updates=20800, lr=9.80581e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=64, gb_free=17, wall=18644
2023-07-17 17:17:05 | INFO | train_inner | epoch 015:    274 / 1474 loss=1.678, trans_loss=5.39, nll_loss=2.698, w2v_ctc_loss=0.552, task_loss=2.506, contrastive_loss=0.114, total=4193.15, n_correct=2656.56, ppl=6.49, accuracy=63.355, wps=6658.1, ups=1.59, wpb=4193.1, bsz=156.3, num_updates=20900, lr=9.78232e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=63, gb_free=13.1, wall=18707
2023-07-17 17:18:08 | INFO | train_inner | epoch 015:    374 / 1474 loss=1.686, trans_loss=5.384, nll_loss=2.689, w2v_ctc_loss=0.552, task_loss=2.625, contrastive_loss=0.161, total=4167.66, n_correct=2642.73, ppl=6.45, accuracy=63.41, wps=6612.6, ups=1.59, wpb=4167.7, bsz=153, num_updates=21000, lr=9.759e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=18770
2023-07-17 17:19:11 | INFO | train_inner | epoch 015:    474 / 1474 loss=1.698, trans_loss=5.407, nll_loss=2.719, w2v_ctc_loss=0.555, task_loss=2.718, contrastive_loss=0.34, total=4074.53, n_correct=2564.81, ppl=6.58, accuracy=62.947, wps=6462.7, ups=1.59, wpb=4074.5, bsz=147.1, num_updates=21100, lr=9.73585e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=16, wall=18833
2023-07-17 17:20:14 | INFO | train_inner | epoch 015:    574 / 1474 loss=1.695, trans_loss=5.403, nll_loss=2.715, w2v_ctc_loss=0.568, task_loss=2.688, contrastive_loss=0.128, total=4140.59, n_correct=2614.18, ppl=6.57, accuracy=63.135, wps=6528.1, ups=1.58, wpb=4140.6, bsz=149.4, num_updates=21200, lr=9.71286e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=12.6, wall=18896
2023-07-17 17:21:18 | INFO | train_inner | epoch 015:    674 / 1474 loss=1.69, trans_loss=5.4, nll_loss=2.711, w2v_ctc_loss=0.558, task_loss=2.628, contrastive_loss=0.293, total=4134.99, n_correct=2612.87, ppl=6.55, accuracy=63.189, wps=6512.6, ups=1.57, wpb=4135, bsz=153.5, num_updates=21300, lr=9.69003e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=63, gb_free=11.1, wall=18960
2023-07-17 17:22:22 | INFO | train_inner | epoch 015:    774 / 1474 loss=1.693, trans_loss=5.41, nll_loss=2.724, w2v_ctc_loss=0.564, task_loss=2.632, contrastive_loss=0.136, total=4173.66, n_correct=2632.18, ppl=6.61, accuracy=63.066, wps=6540.8, ups=1.57, wpb=4173.7, bsz=152.5, num_updates=21400, lr=9.66736e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=19024
2023-07-17 17:23:25 | INFO | train_inner | epoch 015:    874 / 1474 loss=1.688, trans_loss=5.41, nll_loss=2.726, w2v_ctc_loss=0.56, task_loss=2.812, contrastive_loss=0.123, total=4059.35, n_correct=2555.21, ppl=6.61, accuracy=62.946, wps=6440.7, ups=1.59, wpb=4059.3, bsz=144.1, num_updates=21500, lr=9.64486e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=15.8, wall=19087
2023-07-17 17:24:27 | INFO | train_inner | epoch 015:    974 / 1474 loss=1.694, trans_loss=5.402, nll_loss=2.715, w2v_ctc_loss=0.556, task_loss=2.616, contrastive_loss=0.294, total=4122.87, n_correct=2605.15, ppl=6.57, accuracy=63.188, wps=6601.7, ups=1.6, wpb=4122.9, bsz=150.8, num_updates=21600, lr=9.6225e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=62, gb_free=17.7, wall=19149
2023-07-17 17:25:31 | INFO | train_inner | epoch 015:   1074 / 1474 loss=1.695, trans_loss=5.407, nll_loss=2.723, w2v_ctc_loss=0.553, task_loss=2.428, contrastive_loss=0.607, total=4192.24, n_correct=2640.03, ppl=6.6, accuracy=62.974, wps=6571.6, ups=1.57, wpb=4192.2, bsz=162.6, num_updates=21700, lr=9.60031e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=63, gb_free=17.3, wall=19213
2023-07-17 17:26:34 | INFO | train_inner | epoch 015:   1174 / 1474 loss=1.671, trans_loss=5.39, nll_loss=2.703, w2v_ctc_loss=0.544, task_loss=2.33, contrastive_loss=0.217, total=4185, n_correct=2653.72, ppl=6.51, accuracy=63.41, wps=6636.3, ups=1.59, wpb=4185, bsz=164.6, num_updates=21800, lr=9.57826e-05, gnorm=0.41, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=19276
2023-07-17 17:27:38 | INFO | train_inner | epoch 015:   1274 / 1474 loss=1.692, trans_loss=5.406, nll_loss=2.721, w2v_ctc_loss=0.57, task_loss=2.641, contrastive_loss=0.13, total=4152.04, n_correct=2616.06, ppl=6.59, accuracy=63.007, wps=6511, ups=1.57, wpb=4152, bsz=151.8, num_updates=21900, lr=9.55637e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=19340
2023-07-17 17:28:41 | INFO | train_inner | epoch 015:   1374 / 1474 loss=1.695, trans_loss=5.398, nll_loss=2.711, w2v_ctc_loss=0.561, task_loss=2.682, contrastive_loss=0.102, total=4100.21, n_correct=2593.87, ppl=6.55, accuracy=63.262, wps=6513.1, ups=1.59, wpb=4100.2, bsz=146.8, num_updates=22000, lr=9.53463e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=17.6, wall=19403
2023-07-17 17:28:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 17:29:05 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.685 | trans_loss 5.582 | nll_loss 2.855 | w2v_ctc_loss 1.132 | task_loss 4.323 | contrastive_loss 0.247 | total 4003.4 | n_correct 2471.1 | ppl 7.23 | accuracy 61.725 | uer 17.333 | wer 19.131 | raw_wer 19.131 | bleu 19.71 | wps 2192 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 20.01
2023-07-17 17:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-17 17:29:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_15_22000.pt
2023-07-17 17:29:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_15_22000.pt
2023-07-17 17:29:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.71) (writing took 6.497268441016786 seconds)
2023-07-17 17:30:17 | INFO | train_inner | epoch 015:   1474 / 1474 loss=1.686, trans_loss=5.411, nll_loss=2.729, w2v_ctc_loss=0.558, task_loss=2.523, contrastive_loss=0.283, total=4141.17, n_correct=2606.95, ppl=6.63, accuracy=62.952, wps=4319.5, ups=1.04, wpb=4141.2, bsz=157.2, num_updates=22100, lr=9.51303e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=64, gb_free=17.2, wall=19499
2023-07-17 17:30:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 17:30:42 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.685 | trans_loss 5.581 | nll_loss 2.861 | w2v_ctc_loss 1.132 | task_loss 4.316 | contrastive_loss 0.252 | total 4003.4 | n_correct 2466.1 | ppl 7.27 | accuracy 61.6 | uer 17.317 | wer 18.952 | raw_wer 18.952 | bleu 19.65 | wps 2088.9 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 20.01
2023-07-17 17:30:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-07-17 17:30:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.6502.pt
2023-07-17 17:30:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.6502.pt
2023-07-17 17:30:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.6502.pt (epoch 15 @ 22100 updates, score 19.65) (writing took 5.483810356003232 seconds)
2023-07-17 17:30:48 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-17 17:30:48 | INFO | train | epoch 015 | loss 1.689 | trans_loss 5.4 | nll_loss 2.712 | w2v_ctc_loss 0.557 | task_loss 2.602 | contrastive_loss 0.228 | total 4138.65 | n_correct 2613.98 | ppl 6.55 | accuracy 63.16 | wps 6070.2 | ups 1.47 | wpb 4138.6 | bsz 152.8 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.421 | clip 0 | loss_scale 32 | train_wall 927 | gb_free 17.2 | wall 19530
2023-07-17 17:30:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 17:30:48 | INFO | fairseq.trainer | begin training epoch 16
2023-07-17 17:30:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 17:31:59 | INFO | train_inner | epoch 016:    100 / 1474 loss=1.668, trans_loss=5.352, nll_loss=2.65, w2v_ctc_loss=0.545, task_loss=2.474, contrastive_loss=0.16, total=4126.22, n_correct=2637.66, ppl=6.28, accuracy=63.924, wps=4036, ups=0.98, wpb=4126.2, bsz=157.8, num_updates=22200, lr=9.49158e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=62, gb_free=16.3, wall=19601
2023-07-17 17:33:03 | INFO | train_inner | epoch 016:    200 / 1474 loss=1.658, trans_loss=5.35, nll_loss=2.647, w2v_ctc_loss=0.535, task_loss=2.679, contrastive_loss=0.113, total=4100.6, n_correct=2624.36, ppl=6.26, accuracy=63.999, wps=6441.4, ups=1.57, wpb=4100.6, bsz=148.4, num_updates=22300, lr=9.47027e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=63, gb_free=13, wall=19665
2023-07-17 17:34:06 | INFO | train_inner | epoch 016:    300 / 1474 loss=1.69, trans_loss=5.379, nll_loss=2.686, w2v_ctc_loss=0.559, task_loss=2.579, contrastive_loss=0.259, total=4166.94, n_correct=2646.87, ppl=6.44, accuracy=63.521, wps=6576.3, ups=1.58, wpb=4166.9, bsz=154.5, num_updates=22400, lr=9.44911e-05, gnorm=0.414, clip=0, loss_scale=64, train_wall=63, gb_free=17.3, wall=19728
2023-07-17 17:35:09 | INFO | train_inner | epoch 016:    400 / 1474 loss=1.689, trans_loss=5.384, nll_loss=2.691, w2v_ctc_loss=0.56, task_loss=2.771, contrastive_loss=0.288, total=4073.3, n_correct=2585.85, ppl=6.46, accuracy=63.483, wps=6484, ups=1.59, wpb=4073.3, bsz=144, num_updates=22500, lr=9.42809e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=62, gb_free=17.2, wall=19791
2023-07-17 17:36:13 | INFO | train_inner | epoch 016:    500 / 1474 loss=1.675, trans_loss=5.371, nll_loss=2.676, w2v_ctc_loss=0.552, task_loss=2.5, contrastive_loss=0.18, total=4174.67, n_correct=2660.75, ppl=6.39, accuracy=63.736, wps=6523.8, ups=1.56, wpb=4174.7, bsz=159.5, num_updates=22600, lr=9.40721e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=64, gb_free=16.1, wall=19855
2023-07-17 17:37:16 | INFO | train_inner | epoch 016:    600 / 1474 loss=1.684, trans_loss=5.365, nll_loss=2.668, w2v_ctc_loss=0.551, task_loss=2.621, contrastive_loss=0.105, total=4124.65, n_correct=2628.9, ppl=6.35, accuracy=63.736, wps=6574.8, ups=1.59, wpb=4124.6, bsz=148.8, num_updates=22700, lr=9.38647e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=62, gb_free=16.4, wall=19917
2023-07-17 17:38:18 | INFO | train_inner | epoch 016:    700 / 1474 loss=1.684, trans_loss=5.376, nll_loss=2.682, w2v_ctc_loss=0.555, task_loss=2.666, contrastive_loss=0.116, total=4095.49, n_correct=2602.17, ppl=6.42, accuracy=63.537, wps=6567.4, ups=1.6, wpb=4095.5, bsz=148.2, num_updates=22800, lr=9.36586e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=62, gb_free=16.4, wall=19980
2023-07-17 17:39:21 | INFO | train_inner | epoch 016:    800 / 1474 loss=1.679, trans_loss=5.376, nll_loss=2.682, w2v_ctc_loss=0.545, task_loss=2.492, contrastive_loss=0.237, total=4174.94, n_correct=2651.52, ppl=6.42, accuracy=63.51, wps=6622.9, ups=1.59, wpb=4174.9, bsz=155.4, num_updates=22900, lr=9.34539e-05, gnorm=0.409, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=20043
2023-07-17 17:40:24 | INFO | train_inner | epoch 016:    900 / 1474 loss=1.672, trans_loss=5.367, nll_loss=2.673, w2v_ctc_loss=0.543, task_loss=2.512, contrastive_loss=0.224, total=4163.19, n_correct=2651.28, ppl=6.38, accuracy=63.684, wps=6587.9, ups=1.58, wpb=4163.2, bsz=155.3, num_updates=23000, lr=9.32505e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=63, gb_free=17.1, wall=20106
2023-07-17 17:41:28 | INFO | train_inner | epoch 016:   1000 / 1474 loss=1.69, trans_loss=5.387, nll_loss=2.697, w2v_ctc_loss=0.559, task_loss=2.714, contrastive_loss=0.221, total=4103.45, n_correct=2596.55, ppl=6.48, accuracy=63.277, wps=6454.9, ups=1.57, wpb=4103.4, bsz=149, num_updates=23100, lr=9.30484e-05, gnorm=0.428, clip=0, loss_scale=64, train_wall=63, gb_free=15.1, wall=20170
2023-07-17 17:42:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-17 17:42:32 | INFO | train_inner | epoch 016:   1101 / 1474 loss=1.693, trans_loss=5.392, nll_loss=2.704, w2v_ctc_loss=0.565, task_loss=2.777, contrastive_loss=0.177, total=4118.19, n_correct=2606.03, ppl=6.51, accuracy=63.281, wps=6405.2, ups=1.56, wpb=4118.2, bsz=147.7, num_updates=23200, lr=9.28477e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=64, gb_free=14.9, wall=20234
2023-07-17 17:43:36 | INFO | train_inner | epoch 016:   1201 / 1474 loss=1.686, trans_loss=5.388, nll_loss=2.699, w2v_ctc_loss=0.548, task_loss=2.651, contrastive_loss=0.365, total=4157.51, n_correct=2629.59, ppl=6.49, accuracy=63.249, wps=6520.4, ups=1.57, wpb=4157.5, bsz=153.3, num_updates=23300, lr=9.26482e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=63, gb_free=15.1, wall=20298
2023-07-17 17:44:39 | INFO | train_inner | epoch 016:   1301 / 1474 loss=1.687, trans_loss=5.393, nll_loss=2.706, w2v_ctc_loss=0.558, task_loss=2.522, contrastive_loss=0.331, total=4151.03, n_correct=2628.26, ppl=6.53, accuracy=63.316, wps=6561.6, ups=1.58, wpb=4151, bsz=157.2, num_updates=23400, lr=9.245e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=20361
2023-07-17 17:45:43 | INFO | train_inner | epoch 016:   1401 / 1474 loss=1.681, trans_loss=5.387, nll_loss=2.699, w2v_ctc_loss=0.555, task_loss=2.496, contrastive_loss=0.184, total=4201.47, n_correct=2664.11, ppl=6.49, accuracy=63.409, wps=6608.8, ups=1.57, wpb=4201.5, bsz=160.4, num_updates=23500, lr=9.22531e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=63, gb_free=16.2, wall=20425
2023-07-17 17:46:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 17:46:54 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.684 | trans_loss 5.569 | nll_loss 2.846 | w2v_ctc_loss 1.152 | task_loss 4.323 | contrastive_loss 0.256 | total 4003.4 | n_correct 2469.7 | ppl 7.19 | accuracy 61.69 | uer 17.203 | wer 18.993 | raw_wer 18.993 | bleu 19.78 | wps 2157.6 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 20.01
2023-07-17 17:46:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-07-17 17:46:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.7806.pt
2023-07-17 17:46:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.7806.pt
2023-07-17 17:47:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.7806.pt (epoch 16 @ 23573 updates, score 19.78) (writing took 5.3559326770482585 seconds)
2023-07-17 17:47:00 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-17 17:47:00 | INFO | train | epoch 016 | loss 1.682 | trans_loss 5.377 | nll_loss 2.683 | w2v_ctc_loss 0.552 | task_loss 2.601 | contrastive_loss 0.23 | total 4138.64 | n_correct 2629.66 | ppl 6.42 | accuracy 63.539 | wps 6274.4 | ups 1.52 | wpb 4138.6 | bsz 152.8 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.419 | clip 0 | loss_scale 32 | train_wall 926 | gb_free 15.6 | wall 20502
2023-07-17 17:47:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 17:47:00 | INFO | fairseq.trainer | begin training epoch 17
2023-07-17 17:47:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 17:47:26 | INFO | train_inner | epoch 017:     27 / 1474 loss=1.687, trans_loss=5.368, nll_loss=2.673, w2v_ctc_loss=0.55, task_loss=2.661, contrastive_loss=0.464, total=4145.04, n_correct=2639.93, ppl=6.38, accuracy=63.689, wps=4021, ups=0.97, wpb=4145, bsz=151.2, num_updates=23600, lr=9.20575e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=63, gb_free=15.8, wall=20528
2023-07-17 17:48:29 | INFO | train_inner | epoch 017:    127 / 1474 loss=1.677, trans_loss=5.34, nll_loss=2.635, w2v_ctc_loss=0.552, task_loss=2.673, contrastive_loss=0.132, total=4117.27, n_correct=2639.92, ppl=6.21, accuracy=64.118, wps=6493.1, ups=1.58, wpb=4117.3, bsz=148.1, num_updates=23700, lr=9.1863e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=17.9, wall=20591
2023-07-17 17:49:33 | INFO | train_inner | epoch 017:    227 / 1474 loss=1.673, trans_loss=5.346, nll_loss=2.644, w2v_ctc_loss=0.538, task_loss=2.462, contrastive_loss=0.47, total=4159.6, n_correct=2664.98, ppl=6.25, accuracy=64.068, wps=6536.2, ups=1.57, wpb=4159.6, bsz=158.8, num_updates=23800, lr=9.16698e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=20655
2023-07-17 17:50:36 | INFO | train_inner | epoch 017:    327 / 1474 loss=1.675, trans_loss=5.347, nll_loss=2.645, w2v_ctc_loss=0.544, task_loss=2.588, contrastive_loss=0.478, total=4156.91, n_correct=2657.3, ppl=6.26, accuracy=63.925, wps=6595.7, ups=1.59, wpb=4156.9, bsz=152.9, num_updates=23900, lr=9.14779e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=63, gb_free=17.6, wall=20718
2023-07-17 17:51:39 | INFO | train_inner | epoch 017:    427 / 1474 loss=1.672, trans_loss=5.349, nll_loss=2.647, w2v_ctc_loss=0.549, task_loss=2.574, contrastive_loss=0.136, total=4146.43, n_correct=2657.46, ppl=6.27, accuracy=64.09, wps=6547.6, ups=1.58, wpb=4146.4, bsz=154, num_updates=24000, lr=9.12871e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=20781
2023-07-17 17:51:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 17:52:05 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.703 | trans_loss 5.578 | nll_loss 2.851 | w2v_ctc_loss 1.182 | task_loss 4.317 | contrastive_loss 0.245 | total 4003.4 | n_correct 2465.3 | ppl 7.21 | accuracy 61.58 | uer 17.11 | wer 18.877 | raw_wer 18.877 | bleu 19.61 | wps 2089.9 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.01
2023-07-17 17:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-17 17:52:05 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_17_24000.pt
2023-07-17 17:52:07 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_17_24000.pt
2023-07-17 17:52:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.61) (writing took 6.615621073986404 seconds)
2023-07-17 17:53:16 | INFO | train_inner | epoch 017:    527 / 1474 loss=1.682, trans_loss=5.357, nll_loss=2.659, w2v_ctc_loss=0.553, task_loss=2.711, contrastive_loss=0.229, total=4182.1, n_correct=2667.37, ppl=6.32, accuracy=63.781, wps=4308, ups=1.03, wpb=4182.1, bsz=153.9, num_updates=24100, lr=9.10975e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=64, gb_free=17, wall=20878
2023-07-17 17:54:20 | INFO | train_inner | epoch 017:    627 / 1474 loss=1.674, trans_loss=5.354, nll_loss=2.654, w2v_ctc_loss=0.547, task_loss=2.618, contrastive_loss=0.127, total=4167.27, n_correct=2662.11, ppl=6.3, accuracy=63.881, wps=6526.9, ups=1.57, wpb=4167.3, bsz=151.1, num_updates=24200, lr=9.09091e-05, gnorm=0.414, clip=0, loss_scale=32, train_wall=63, gb_free=11.3, wall=20942
2023-07-17 17:55:23 | INFO | train_inner | epoch 017:    727 / 1474 loss=1.681, trans_loss=5.365, nll_loss=2.669, w2v_ctc_loss=0.558, task_loss=2.566, contrastive_loss=0.226, total=4166.12, n_correct=2652.4, ppl=6.36, accuracy=63.666, wps=6588.6, ups=1.58, wpb=4166.1, bsz=154.1, num_updates=24300, lr=9.07218e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=21005
2023-07-17 17:56:26 | INFO | train_inner | epoch 017:    827 / 1474 loss=1.686, trans_loss=5.36, nll_loss=2.663, w2v_ctc_loss=0.555, task_loss=2.624, contrastive_loss=0.154, total=4091.64, n_correct=2609.62, ppl=6.33, accuracy=63.779, wps=6500.9, ups=1.59, wpb=4091.6, bsz=147.7, num_updates=24400, lr=9.05357e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=62, gb_free=17.4, wall=21068
2023-07-17 17:57:28 | INFO | train_inner | epoch 017:    927 / 1474 loss=1.673, trans_loss=5.348, nll_loss=2.647, w2v_ctc_loss=0.544, task_loss=2.56, contrastive_loss=0.151, total=4106.83, n_correct=2625.97, ppl=6.27, accuracy=63.942, wps=6624.1, ups=1.61, wpb=4106.8, bsz=152.3, num_updates=24500, lr=9.03508e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=62, gb_free=16, wall=21130
2023-07-17 17:58:31 | INFO | train_inner | epoch 017:   1027 / 1474 loss=1.677, trans_loss=5.353, nll_loss=2.655, w2v_ctc_loss=0.55, task_loss=2.563, contrastive_loss=0.158, total=4115.49, n_correct=2627.54, ppl=6.3, accuracy=63.845, wps=6551.9, ups=1.59, wpb=4115.5, bsz=152.9, num_updates=24600, lr=9.0167e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=62, gb_free=16.8, wall=21193
2023-07-17 17:59:34 | INFO | train_inner | epoch 017:   1127 / 1474 loss=1.672, trans_loss=5.355, nll_loss=2.657, w2v_ctc_loss=0.542, task_loss=2.705, contrastive_loss=0.132, total=4078.39, n_correct=2605.23, ppl=6.31, accuracy=63.879, wps=6519.2, ups=1.6, wpb=4078.4, bsz=146.9, num_updates=24700, lr=8.99843e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=62, gb_free=15.8, wall=21256
2023-07-17 18:00:38 | INFO | train_inner | epoch 017:   1227 / 1474 loss=1.69, trans_loss=5.38, nll_loss=2.69, w2v_ctc_loss=0.548, task_loss=2.521, contrastive_loss=0.624, total=4173.49, n_correct=2646.28, ppl=6.45, accuracy=63.407, wps=6505.7, ups=1.56, wpb=4173.5, bsz=161.9, num_updates=24800, lr=8.98027e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=64, gb_free=16.3, wall=21320
2023-07-17 18:00:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-17 18:01:42 | INFO | train_inner | epoch 017:   1328 / 1474 loss=1.67, trans_loss=5.362, nll_loss=2.667, w2v_ctc_loss=0.544, task_loss=2.643, contrastive_loss=0.161, total=4137.75, n_correct=2636.18, ppl=6.35, accuracy=63.71, wps=6486.9, ups=1.57, wpb=4137.8, bsz=150.7, num_updates=24900, lr=8.96221e-05, gnorm=0.419, clip=0, loss_scale=16, train_wall=63, gb_free=17, wall=21384
2023-07-17 18:02:46 | INFO | train_inner | epoch 017:   1428 / 1474 loss=1.658, trans_loss=5.359, nll_loss=2.663, w2v_ctc_loss=0.54, task_loss=2.628, contrastive_loss=0.143, total=4117.13, n_correct=2626.56, ppl=6.33, accuracy=63.796, wps=6438.5, ups=1.56, wpb=4117.1, bsz=151.9, num_updates=25000, lr=8.94427e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=64, gb_free=17.6, wall=21447
mt_weight tensor(0.0177, device='cuda:0')
asr_weight tensor(0.0013, device='cuda:0')
2023-07-17 18:03:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.0177, device='cuda:2')
asr_weight tensor(0.0013, device='cuda:2')
mt_weight tensor(0.0177, device='cuda:4')
asr_weight tensor(0.0013, device='cuda:4')
mt_weight tensor(0.0177, device='cuda:1')
asr_weight tensor(0.0013, device='cuda:1')
mt_weight tensor(0.0177, device='cuda:5')
asr_weight tensor(0.0013, device='cuda:5')
mt_weight tensor(0.0177, device='cuda:6')
asr_weight tensor(0.0013, device='cuda:6')
mt_weight tensor(0.0177, device='cuda:3')
asr_weight tensor(0.0013, device='cuda:3')
mt_weight tensor(0.0177, device='cuda:7')
asr_weight tensor(0.0013, device='cuda:7')
2023-07-17 18:03:40 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.692 | trans_loss 5.571 | nll_loss 2.848 | w2v_ctc_loss 1.135 | task_loss 4.26 | contrastive_loss 0.262 | total 4003.4 | n_correct 2470.2 | ppl 7.2 | accuracy 61.703 | uer 17.073 | wer 18.87 | raw_wer 18.87 | bleu 19.67 | wps 2193.8 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 20.01
2023-07-17 18:03:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-07-17 18:03:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.6706.pt
2023-07-17 18:03:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.6706.pt
2023-07-17 18:03:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.6706.pt (epoch 17 @ 25046 updates, score 19.67) (writing took 5.574288035044447 seconds)
2023-07-17 18:03:46 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-17 18:03:46 | INFO | train | epoch 017 | loss 1.675 | trans_loss 5.355 | nll_loss 2.656 | w2v_ctc_loss 0.548 | task_loss 2.603 | contrastive_loss 0.236 | total 4137.87 | n_correct 2642.51 | ppl 6.3 | accuracy 63.862 | wps 6058.4 | ups 1.46 | wpb 4137.9 | bsz 152.7 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.421 | clip 0 | loss_scale 16 | train_wall 927 | gb_free 16.6 | wall 21508
2023-07-17 18:03:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 18:03:46 | INFO | fairseq.trainer | begin training epoch 18
2023-07-17 18:03:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 18:04:29 | INFO | train_inner | epoch 018:     54 / 1474 loss=1.673, trans_loss=5.34, nll_loss=2.638, w2v_ctc_loss=0.548, task_loss=2.645, contrastive_loss=0.162, total=4138.21, n_correct=2653.53, ppl=6.22, accuracy=64.123, wps=4008.5, ups=0.97, wpb=4138.2, bsz=151.6, num_updates=25100, lr=8.92644e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=63, gb_free=17.8, wall=21551
2023-07-17 18:05:32 | INFO | train_inner | epoch 018:    154 / 1474 loss=1.665, trans_loss=5.317, nll_loss=2.606, w2v_ctc_loss=0.528, task_loss=2.468, contrastive_loss=0.406, total=4158.88, n_correct=2683.02, ppl=6.09, accuracy=64.513, wps=6604.8, ups=1.59, wpb=4158.9, bsz=157, num_updates=25200, lr=8.90871e-05, gnorm=0.419, clip=0, loss_scale=16, train_wall=63, gb_free=17.1, wall=21614
2023-07-17 18:06:35 | INFO | train_inner | epoch 018:    254 / 1474 loss=1.659, trans_loss=5.312, nll_loss=2.601, w2v_ctc_loss=0.537, task_loss=2.526, contrastive_loss=0.146, total=4164.11, n_correct=2692.37, ppl=6.07, accuracy=64.657, wps=6530.6, ups=1.57, wpb=4164.1, bsz=156.2, num_updates=25300, lr=8.89108e-05, gnorm=0.411, clip=0, loss_scale=16, train_wall=63, gb_free=15.2, wall=21677
2023-07-17 18:07:39 | INFO | train_inner | epoch 018:    354 / 1474 loss=1.661, trans_loss=5.326, nll_loss=2.618, w2v_ctc_loss=0.537, task_loss=2.644, contrastive_loss=0.173, total=4163.13, n_correct=2677.85, ppl=6.14, accuracy=64.323, wps=6583.6, ups=1.58, wpb=4163.1, bsz=150.7, num_updates=25400, lr=8.87357e-05, gnorm=0.414, clip=0, loss_scale=16, train_wall=63, gb_free=17.7, wall=21741
2023-07-17 18:08:43 | INFO | train_inner | epoch 018:    454 / 1474 loss=1.678, trans_loss=5.34, nll_loss=2.636, w2v_ctc_loss=0.546, task_loss=2.788, contrastive_loss=0.358, total=4087.83, n_correct=2620.37, ppl=6.22, accuracy=64.102, wps=6359.5, ups=1.56, wpb=4087.8, bsz=147.7, num_updates=25500, lr=8.85615e-05, gnorm=0.417, clip=0, loss_scale=16, train_wall=64, gb_free=16.5, wall=21805
2023-07-17 18:09:46 | INFO | train_inner | epoch 018:    554 / 1474 loss=1.65, trans_loss=5.316, nll_loss=2.608, w2v_ctc_loss=0.532, task_loss=2.335, contrastive_loss=0.173, total=4204.41, n_correct=2711.58, ppl=6.1, accuracy=64.494, wps=6640.8, ups=1.58, wpb=4204.4, bsz=164, num_updates=25600, lr=8.83883e-05, gnorm=0.413, clip=0, loss_scale=16, train_wall=63, gb_free=17.5, wall=21868
2023-07-17 18:10:49 | INFO | train_inner | epoch 018:    654 / 1474 loss=1.674, trans_loss=5.347, nll_loss=2.646, w2v_ctc_loss=0.543, task_loss=2.688, contrastive_loss=0.313, total=4096.81, n_correct=2622.38, ppl=6.26, accuracy=64.01, wps=6572, ups=1.6, wpb=4096.8, bsz=149.4, num_updates=25700, lr=8.82162e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=62, gb_free=16.8, wall=21931
2023-07-17 18:11:52 | INFO | train_inner | epoch 018:    754 / 1474 loss=1.672, trans_loss=5.341, nll_loss=2.64, w2v_ctc_loss=0.548, task_loss=2.471, contrastive_loss=0.49, total=4208.29, n_correct=2696.49, ppl=6.23, accuracy=64.076, wps=6648.3, ups=1.58, wpb=4208.3, bsz=161.4, num_updates=25800, lr=8.80451e-05, gnorm=0.411, clip=0, loss_scale=16, train_wall=63, gb_free=17.9, wall=21994
2023-07-17 18:12:56 | INFO | train_inner | epoch 018:    854 / 1474 loss=1.668, trans_loss=5.336, nll_loss=2.633, w2v_ctc_loss=0.54, task_loss=2.639, contrastive_loss=0.129, total=4166.81, n_correct=2672.1, ppl=6.2, accuracy=64.128, wps=6553.2, ups=1.57, wpb=4166.8, bsz=151, num_updates=25900, lr=8.7875e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=63, gb_free=13, wall=22058
2023-07-17 18:13:58 | INFO | train_inner | epoch 018:    954 / 1474 loss=1.659, trans_loss=5.329, nll_loss=2.624, w2v_ctc_loss=0.534, task_loss=2.4, contrastive_loss=0.175, total=4142.65, n_correct=2663.9, ppl=6.16, accuracy=64.304, wps=6673.2, ups=1.61, wpb=4142.6, bsz=158, num_updates=26000, lr=8.77058e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=62, gb_free=15.1, wall=22120
2023-07-17 18:13:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 18:14:21 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.702 | trans_loss 5.565 | nll_loss 2.835 | w2v_ctc_loss 1.185 | task_loss 4.274 | contrastive_loss 0.258 | total 4003.4 | n_correct 2472.6 | ppl 7.14 | accuracy 61.763 | uer 17.503 | wer 19.261 | raw_wer 19.261 | bleu 19.91 | wps 2302.7 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.01
2023-07-17 18:14:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-17 18:14:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_18_26000.pt
2023-07-17 18:14:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_18_26000.pt
2023-07-17 18:14:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.91) (writing took 6.658817860996351 seconds)
2023-07-17 18:15:32 | INFO | train_inner | epoch 018:   1054 / 1474 loss=1.665, trans_loss=5.34, nll_loss=2.639, w2v_ctc_loss=0.537, task_loss=2.715, contrastive_loss=0.152, total=4137.77, n_correct=2653.79, ppl=6.23, accuracy=64.136, wps=4370.8, ups=1.06, wpb=4137.8, bsz=150.2, num_updates=26100, lr=8.75376e-05, gnorm=0.414, clip=0, loss_scale=16, train_wall=63, gb_free=17.5, wall=22214
2023-07-17 18:16:36 | INFO | train_inner | epoch 018:   1154 / 1474 loss=1.663, trans_loss=5.328, nll_loss=2.623, w2v_ctc_loss=0.537, task_loss=2.471, contrastive_loss=0.363, total=4153.69, n_correct=2673.39, ppl=6.16, accuracy=64.362, wps=6539.6, ups=1.57, wpb=4153.7, bsz=157.4, num_updates=26200, lr=8.73704e-05, gnorm=0.414, clip=0, loss_scale=16, train_wall=63, gb_free=15.4, wall=22278
2023-07-17 18:17:39 | INFO | train_inner | epoch 018:   1254 / 1474 loss=1.674, trans_loss=5.348, nll_loss=2.647, w2v_ctc_loss=0.544, task_loss=2.796, contrastive_loss=0.14, total=4087.62, n_correct=2613.14, ppl=6.26, accuracy=63.928, wps=6499.3, ups=1.59, wpb=4087.6, bsz=143.6, num_updates=26300, lr=8.72041e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=62, gb_free=16.8, wall=22341
2023-07-17 18:18:41 | INFO | train_inner | epoch 018:   1354 / 1474 loss=1.685, trans_loss=5.359, nll_loss=2.664, w2v_ctc_loss=0.56, task_loss=2.776, contrastive_loss=0.19, total=4070.69, n_correct=2600.21, ppl=6.34, accuracy=63.876, wps=6493.2, ups=1.6, wpb=4070.7, bsz=145.9, num_updates=26400, lr=8.70388e-05, gnorm=0.427, clip=0, loss_scale=16, train_wall=62, gb_free=17.5, wall=22403
2023-07-17 18:19:45 | INFO | train_inner | epoch 018:   1454 / 1474 loss=1.673, trans_loss=5.346, nll_loss=2.646, w2v_ctc_loss=0.547, task_loss=2.748, contrastive_loss=0.162, total=4113.2, n_correct=2631.64, ppl=6.26, accuracy=63.98, wps=6504.5, ups=1.58, wpb=4113.2, bsz=148.8, num_updates=26500, lr=8.68744e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=63, gb_free=16.6, wall=22467
2023-07-17 18:19:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 18:20:23 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.694 | trans_loss 5.562 | nll_loss 2.836 | w2v_ctc_loss 1.172 | task_loss 4.316 | contrastive_loss 0.259 | total 4003.4 | n_correct 2474 | ppl 7.14 | accuracy 61.797 | uer 17.113 | wer 19.075 | raw_wer 19.075 | bleu 19.85 | wps 2084 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 20.01
2023-07-17 18:20:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-07-17 18:20:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8507.pt
2023-07-17 18:20:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8507.pt
2023-07-17 18:20:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8507.pt (epoch 18 @ 26520 updates, score 19.85) (writing took 5.475644409074448 seconds)
2023-07-17 18:20:28 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-17 18:20:28 | INFO | train | epoch 018 | loss 1.668 | trans_loss 5.334 | nll_loss 2.63 | w2v_ctc_loss 0.541 | task_loss 2.6 | contrastive_loss 0.247 | total 4138.65 | n_correct 2657.23 | ppl 6.19 | accuracy 64.205 | wps 6084.9 | ups 1.47 | wpb 4138.6 | bsz 152.8 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.418 | clip 0 | loss_scale 16 | train_wall 926 | gb_free 16.1 | wall 22510
2023-07-17 18:20:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 18:20:29 | INFO | fairseq.trainer | begin training epoch 19
2023-07-17 18:20:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 18:21:28 | INFO | train_inner | epoch 019:     80 / 1474 loss=1.671, trans_loss=5.31, nll_loss=2.598, w2v_ctc_loss=0.536, task_loss=2.604, contrastive_loss=0.263, total=4102.06, n_correct=2647.89, ppl=6.05, accuracy=64.55, wps=3975.3, ups=0.97, wpb=4102.1, bsz=148.5, num_updates=26600, lr=8.6711e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=63, gb_free=17.6, wall=22570
2023-07-17 18:22:32 | INFO | train_inner | epoch 019:    180 / 1474 loss=1.653, trans_loss=5.301, nll_loss=2.588, w2v_ctc_loss=0.54, task_loss=2.415, contrastive_loss=0.247, total=4227.7, n_correct=2737.38, ppl=6.01, accuracy=64.749, wps=6549.5, ups=1.55, wpb=4227.7, bsz=162.4, num_updates=26700, lr=8.65485e-05, gnorm=0.426, clip=0, loss_scale=16, train_wall=64, gb_free=17.2, wall=22634
2023-07-17 18:23:35 | INFO | train_inner | epoch 019:    280 / 1474 loss=1.651, trans_loss=5.296, nll_loss=2.58, w2v_ctc_loss=0.533, task_loss=2.567, contrastive_loss=0.133, total=4187.34, n_correct=2717.88, ppl=5.98, accuracy=64.907, wps=6650.1, ups=1.59, wpb=4187.3, bsz=153.2, num_updates=26800, lr=8.63868e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=62, gb_free=16.1, wall=22697
2023-07-17 18:24:39 | INFO | train_inner | epoch 019:    380 / 1474 loss=1.654, trans_loss=5.303, nll_loss=2.59, w2v_ctc_loss=0.526, task_loss=2.563, contrastive_loss=0.347, total=4170.52, n_correct=2697.59, ppl=6.02, accuracy=64.682, wps=6566.1, ups=1.57, wpb=4170.5, bsz=155.5, num_updates=26900, lr=8.62261e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=22761
2023-07-17 18:25:41 | INFO | train_inner | epoch 019:    480 / 1474 loss=1.658, trans_loss=5.315, nll_loss=2.606, w2v_ctc_loss=0.54, task_loss=2.675, contrastive_loss=0.165, total=4113.89, n_correct=2653.21, ppl=6.09, accuracy=64.494, wps=6571.5, ups=1.6, wpb=4113.9, bsz=150.8, num_updates=27000, lr=8.60663e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=62, gb_free=17.3, wall=22823
2023-07-17 18:26:44 | INFO | train_inner | epoch 019:    580 / 1474 loss=1.653, trans_loss=5.307, nll_loss=2.596, w2v_ctc_loss=0.53, task_loss=2.538, contrastive_loss=0.291, total=4128.58, n_correct=2664.65, ppl=6.05, accuracy=64.542, wps=6576.4, ups=1.59, wpb=4128.6, bsz=153.1, num_updates=27100, lr=8.59074e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=62, gb_free=16.8, wall=22886
2023-07-17 18:27:47 | INFO | train_inner | epoch 019:    680 / 1474 loss=1.643, trans_loss=5.306, nll_loss=2.595, w2v_ctc_loss=0.522, task_loss=2.365, contrastive_loss=0.149, total=4201.56, n_correct=2717.53, ppl=6.04, accuracy=64.679, wps=6677.5, ups=1.59, wpb=4201.6, bsz=160.7, num_updates=27200, lr=8.57493e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=62, gb_free=17.9, wall=22949
2023-07-17 18:28:51 | INFO | train_inner | epoch 019:    780 / 1474 loss=1.662, trans_loss=5.314, nll_loss=2.605, w2v_ctc_loss=0.538, task_loss=2.676, contrastive_loss=0.157, total=4124.03, n_correct=2658.4, ppl=6.08, accuracy=64.461, wps=6444.9, ups=1.56, wpb=4124, bsz=149.5, num_updates=27300, lr=8.55921e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=64, gb_free=17.6, wall=23013
2023-07-17 18:29:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-17 18:29:55 | INFO | train_inner | epoch 019:    881 / 1474 loss=1.664, trans_loss=5.324, nll_loss=2.617, w2v_ctc_loss=0.541, task_loss=2.621, contrastive_loss=0.155, total=4164.3, n_correct=2681.3, ppl=6.14, accuracy=64.388, wps=6520.8, ups=1.57, wpb=4164.3, bsz=153.6, num_updates=27400, lr=8.54358e-05, gnorm=0.417, clip=0, loss_scale=16, train_wall=63, gb_free=16.4, wall=23077
2023-07-17 18:30:59 | INFO | train_inner | epoch 019:    981 / 1474 loss=1.671, trans_loss=5.34, nll_loss=2.64, w2v_ctc_loss=0.536, task_loss=2.602, contrastive_loss=0.607, total=4101.29, n_correct=2630.16, ppl=6.23, accuracy=64.13, wps=6409.6, ups=1.56, wpb=4101.3, bsz=155, num_updates=27500, lr=8.52803e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=64, gb_free=16.8, wall=23141
2023-07-17 18:32:02 | INFO | train_inner | epoch 019:   1081 / 1474 loss=1.671, trans_loss=5.34, nll_loss=2.64, w2v_ctc_loss=0.541, task_loss=2.778, contrastive_loss=0.227, total=4036.97, n_correct=2588.3, ppl=6.23, accuracy=64.115, wps=6402.7, ups=1.59, wpb=4037, bsz=145.5, num_updates=27600, lr=8.51257e-05, gnorm=0.431, clip=0, loss_scale=16, train_wall=63, gb_free=14.9, wall=23204
2023-07-17 18:33:06 | INFO | train_inner | epoch 019:   1181 / 1474 loss=1.681, trans_loss=5.337, nll_loss=2.636, w2v_ctc_loss=0.546, task_loss=2.636, contrastive_loss=0.394, total=4137.49, n_correct=2653.99, ppl=6.22, accuracy=64.145, wps=6493.8, ups=1.57, wpb=4137.5, bsz=153.8, num_updates=27700, lr=8.49719e-05, gnorm=0.43, clip=0, loss_scale=16, train_wall=63, gb_free=15.1, wall=23268
2023-07-17 18:34:09 | INFO | train_inner | epoch 019:   1281 / 1474 loss=1.676, trans_loss=5.335, nll_loss=2.634, w2v_ctc_loss=0.538, task_loss=2.635, contrastive_loss=0.189, total=4141.89, n_correct=2657.7, ppl=6.21, accuracy=64.166, wps=6598.2, ups=1.59, wpb=4141.9, bsz=150.1, num_updates=27800, lr=8.48189e-05, gnorm=0.425, clip=0, loss_scale=16, train_wall=62, gb_free=15.9, wall=23331
2023-07-17 18:35:12 | INFO | train_inner | epoch 019:   1381 / 1474 loss=1.663, trans_loss=5.322, nll_loss=2.617, w2v_ctc_loss=0.537, task_loss=2.667, contrastive_loss=0.161, total=4133.26, n_correct=2659.43, ppl=6.13, accuracy=64.342, wps=6501, ups=1.57, wpb=4133.3, bsz=150.5, num_updates=27900, lr=8.46668e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=63, gb_free=16.4, wall=23394
2023-07-17 18:36:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 18:36:36 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.699 | trans_loss 5.56 | nll_loss 2.834 | w2v_ctc_loss 1.216 | task_loss 4.337 | contrastive_loss 0.266 | total 4003.4 | n_correct 2474.2 | ppl 7.13 | accuracy 61.802 | uer 17.309 | wer 19.101 | raw_wer 19.101 | bleu 19.83 | wps 2192.2 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.01
2023-07-17 18:36:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-07-17 18:36:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8302.pt
2023-07-17 18:36:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8302.pt
2023-07-17 18:36:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8302.pt (epoch 19 @ 27993 updates, score 19.83) (writing took 5.48394832003396 seconds)
2023-07-17 18:36:42 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-17 18:36:42 | INFO | train | epoch 019 | loss 1.662 | trans_loss 5.317 | nll_loss 2.61 | w2v_ctc_loss 0.536 | task_loss 2.601 | contrastive_loss 0.248 | total 4138.42 | n_correct 2667.72 | ppl 6.1 | accuracy 64.462 | wps 6262.6 | ups 1.51 | wpb 4138.4 | bsz 152.8 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.422 | clip 0 | loss_scale 16 | train_wall 927 | gb_free 17.5 | wall 23484
2023-07-17 18:36:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 18:36:42 | INFO | fairseq.trainer | begin training epoch 20
2023-07-17 18:36:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 18:36:55 | INFO | train_inner | epoch 020:      7 / 1474 loss=1.67, trans_loss=5.316, nll_loss=2.61, w2v_ctc_loss=0.537, task_loss=2.633, contrastive_loss=0.328, total=4119.08, n_correct=2654.46, ppl=6.1, accuracy=64.443, wps=4018.3, ups=0.98, wpb=4119.1, bsz=152.1, num_updates=28000, lr=8.45154e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=63, gb_free=16.5, wall=23497
2023-07-17 18:36:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 18:37:20 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.692 | trans_loss 5.56 | nll_loss 2.831 | w2v_ctc_loss 1.167 | task_loss 4.309 | contrastive_loss 0.26 | total 4003.4 | n_correct 2473.3 | ppl 7.11 | accuracy 61.78 | uer 17.137 | wer 19.011 | raw_wer 19.011 | bleu 20.01 | wps 2174.1 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.01
2023-07-17 18:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-17 18:37:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_20_28000.pt
2023-07-17 18:37:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_20_28000.pt
2023-07-17 18:37:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.01) (writing took 9.376198573037982 seconds)
2023-07-17 18:38:33 | INFO | train_inner | epoch 020:    107 / 1474 loss=1.642, trans_loss=5.273, nll_loss=2.551, w2v_ctc_loss=0.524, task_loss=2.508, contrastive_loss=0.173, total=4195.03, n_correct=2736.05, ppl=5.86, accuracy=65.221, wps=4262.6, ups=1.02, wpb=4195, bsz=156.8, num_updates=28100, lr=8.43649e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=63, gb_free=15.3, wall=23595
2023-07-17 18:39:36 | INFO | train_inner | epoch 020:    207 / 1474 loss=1.659, trans_loss=5.283, nll_loss=2.564, w2v_ctc_loss=0.529, task_loss=2.71, contrastive_loss=0.279, total=4154.14, n_correct=2700.79, ppl=5.91, accuracy=65.014, wps=6554.7, ups=1.58, wpb=4154.1, bsz=150.5, num_updates=28200, lr=8.42152e-05, gnorm=0.416, clip=0, loss_scale=16, train_wall=63, gb_free=17.4, wall=23658
2023-07-17 18:40:39 | INFO | train_inner | epoch 020:    307 / 1474 loss=1.635, trans_loss=5.277, nll_loss=2.558, w2v_ctc_loss=0.523, task_loss=2.343, contrastive_loss=0.16, total=4188.05, n_correct=2726.57, ppl=5.89, accuracy=65.104, wps=6654.7, ups=1.59, wpb=4188.1, bsz=163.1, num_updates=28300, lr=8.40663e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=63, gb_free=15.7, wall=23721
2023-07-17 18:41:43 | INFO | train_inner | epoch 020:    407 / 1474 loss=1.639, trans_loss=5.282, nll_loss=2.563, w2v_ctc_loss=0.52, task_loss=2.64, contrastive_loss=0.151, total=4115.16, n_correct=2674.13, ppl=5.91, accuracy=64.982, wps=6484.4, ups=1.58, wpb=4115.2, bsz=148.5, num_updates=28400, lr=8.39181e-05, gnorm=0.413, clip=0, loss_scale=16, train_wall=63, gb_free=15.7, wall=23785
2023-07-17 18:42:46 | INFO | train_inner | epoch 020:    507 / 1474 loss=1.664, trans_loss=5.304, nll_loss=2.591, w2v_ctc_loss=0.53, task_loss=2.659, contrastive_loss=0.328, total=4108.46, n_correct=2657.25, ppl=6.03, accuracy=64.678, wps=6467.8, ups=1.57, wpb=4108.5, bsz=150.2, num_updates=28500, lr=8.37708e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=63, gb_free=16.6, wall=23848
2023-07-17 18:43:49 | INFO | train_inner | epoch 020:    607 / 1474 loss=1.665, trans_loss=5.307, nll_loss=2.595, w2v_ctc_loss=0.533, task_loss=2.73, contrastive_loss=0.329, total=4094.9, n_correct=2643.47, ppl=6.04, accuracy=64.555, wps=6543.1, ups=1.6, wpb=4094.9, bsz=148, num_updates=28600, lr=8.36242e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=62, gb_free=12.4, wall=23911
2023-07-17 18:44:52 | INFO | train_inner | epoch 020:    707 / 1474 loss=1.662, trans_loss=5.302, nll_loss=2.589, w2v_ctc_loss=0.536, task_loss=2.596, contrastive_loss=0.139, total=4140.23, n_correct=2676.89, ppl=6.02, accuracy=64.656, wps=6603.2, ups=1.59, wpb=4140.2, bsz=150.3, num_updates=28700, lr=8.34784e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=62, gb_free=16.4, wall=23974
2023-07-17 18:45:54 | INFO | train_inner | epoch 020:    807 / 1474 loss=1.644, trans_loss=5.295, nll_loss=2.581, w2v_ctc_loss=0.527, task_loss=2.592, contrastive_loss=0.147, total=4140.66, n_correct=2686.48, ppl=5.98, accuracy=64.88, wps=6596.1, ups=1.59, wpb=4140.7, bsz=152.8, num_updates=28800, lr=8.33333e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=62, gb_free=17.6, wall=24036
2023-07-17 18:46:58 | INFO | train_inner | epoch 020:    907 / 1474 loss=1.677, trans_loss=5.318, nll_loss=2.611, w2v_ctc_loss=0.53, task_loss=2.486, contrastive_loss=0.727, total=4157.15, n_correct=2682.68, ppl=6.11, accuracy=64.532, wps=6520.2, ups=1.57, wpb=4157.1, bsz=161.3, num_updates=28900, lr=8.3189e-05, gnorm=0.445, clip=0, loss_scale=16, train_wall=63, gb_free=17.8, wall=24100
2023-07-17 18:48:02 | INFO | train_inner | epoch 020:   1007 / 1474 loss=1.656, trans_loss=5.302, nll_loss=2.591, w2v_ctc_loss=0.527, task_loss=2.572, contrastive_loss=0.158, total=4171.86, n_correct=2700.28, ppl=6.03, accuracy=64.726, wps=6560.9, ups=1.57, wpb=4171.9, bsz=154.3, num_updates=29000, lr=8.30455e-05, gnorm=0.417, clip=0, loss_scale=16, train_wall=63, gb_free=16.2, wall=24164
2023-07-17 18:49:05 | INFO | train_inner | epoch 020:   1107 / 1474 loss=1.666, trans_loss=5.313, nll_loss=2.605, w2v_ctc_loss=0.53, task_loss=2.514, contrastive_loss=0.432, total=4162.96, n_correct=2686.92, ppl=6.08, accuracy=64.543, wps=6580.6, ups=1.58, wpb=4163, bsz=157.5, num_updates=29100, lr=8.29027e-05, gnorm=0.431, clip=0, loss_scale=16, train_wall=63, gb_free=17.2, wall=24227
2023-07-17 18:50:08 | INFO | train_inner | epoch 020:   1207 / 1474 loss=1.652, trans_loss=5.305, nll_loss=2.594, w2v_ctc_loss=0.538, task_loss=2.862, contrastive_loss=0.136, total=4033.74, n_correct=2605.54, ppl=6.04, accuracy=64.594, wps=6389.6, ups=1.58, wpb=4033.7, bsz=142.6, num_updates=29200, lr=8.27606e-05, gnorm=0.452, clip=0, loss_scale=16, train_wall=63, gb_free=17.4, wall=24290
2023-07-17 18:51:12 | INFO | train_inner | epoch 020:   1307 / 1474 loss=1.657, trans_loss=5.316, nll_loss=2.609, w2v_ctc_loss=0.533, task_loss=2.77, contrastive_loss=0.145, total=4124.42, n_correct=2657.7, ppl=6.1, accuracy=64.438, wps=6487, ups=1.57, wpb=4124.4, bsz=148.5, num_updates=29300, lr=8.26192e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=63, gb_free=16.2, wall=24354
2023-07-17 18:52:15 | INFO | train_inner | epoch 020:   1407 / 1474 loss=1.664, trans_loss=5.312, nll_loss=2.604, w2v_ctc_loss=0.538, task_loss=2.768, contrastive_loss=0.143, total=4114.1, n_correct=2657.67, ppl=6.08, accuracy=64.599, wps=6483.1, ups=1.58, wpb=4114.1, bsz=146.8, num_updates=29400, lr=8.24786e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=63, gb_free=14.7, wall=24417
2023-07-17 18:52:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 18:53:21 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.671 | trans_loss 5.553 | nll_loss 2.827 | w2v_ctc_loss 1.109 | task_loss 4.281 | contrastive_loss 0.261 | total 4003.4 | n_correct 2478.1 | ppl 7.1 | accuracy 61.9 | uer 16.994 | wer 18.922 | raw_wer 18.922 | bleu 20.28 | wps 2334.3 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.28
2023-07-17 18:53:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-07-17 18:53:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 18:53:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 18:53:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 20 @ 29467 updates, score 20.28) (writing took 8.509587613982148 seconds)
2023-07-17 18:53:30 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-17 18:53:30 | INFO | train | epoch 020 | loss 1.655 | trans_loss 5.3 | nll_loss 2.587 | w2v_ctc_loss 0.53 | task_loss 2.604 | contrastive_loss 0.248 | total 4138.65 | n_correct 2679.56 | ppl 6.01 | accuracy 64.745 | wps 6051.3 | ups 1.46 | wpb 4138.6 | bsz 152.8 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.424 | clip 0 | loss_scale 32 | train_wall 926 | gb_free 16.8 | wall 24492
2023-07-17 18:53:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 18:53:30 | INFO | fairseq.trainer | begin training epoch 21
2023-07-17 18:53:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 18:53:59 | INFO | train_inner | epoch 021:     33 / 1474 loss=1.65, trans_loss=5.307, nll_loss=2.597, w2v_ctc_loss=0.526, task_loss=2.463, contrastive_loss=0.382, total=4155.01, n_correct=2687.24, ppl=6.05, accuracy=64.675, wps=4005.8, ups=0.96, wpb=4155, bsz=158.8, num_updates=29500, lr=8.23387e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=24521
2023-07-17 18:55:03 | INFO | train_inner | epoch 021:    133 / 1474 loss=1.635, trans_loss=5.263, nll_loss=2.539, w2v_ctc_loss=0.515, task_loss=2.461, contrastive_loss=0.374, total=4186.67, n_correct=2733.07, ppl=5.81, accuracy=65.28, wps=6585, ups=1.57, wpb=4186.7, bsz=158.7, num_updates=29600, lr=8.21995e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=63, gb_free=13.4, wall=24585
2023-07-17 18:56:06 | INFO | train_inner | epoch 021:    233 / 1474 loss=1.636, trans_loss=5.268, nll_loss=2.546, w2v_ctc_loss=0.513, task_loss=2.449, contrastive_loss=0.278, total=4166.37, n_correct=2719.8, ppl=5.84, accuracy=65.28, wps=6621.8, ups=1.59, wpb=4166.4, bsz=157.6, num_updates=29700, lr=8.2061e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=62, gb_free=14.3, wall=24647
2023-07-17 18:57:09 | INFO | train_inner | epoch 021:    333 / 1474 loss=1.643, trans_loss=5.276, nll_loss=2.555, w2v_ctc_loss=0.527, task_loss=2.647, contrastive_loss=0.281, total=4132.25, n_correct=2691.46, ppl=5.88, accuracy=65.133, wps=6477.8, ups=1.57, wpb=4132.2, bsz=152.5, num_updates=29800, lr=8.19232e-05, gnorm=0.434, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=24711
2023-07-17 18:58:12 | INFO | train_inner | epoch 021:    433 / 1474 loss=1.641, trans_loss=5.268, nll_loss=2.545, w2v_ctc_loss=0.518, task_loss=2.483, contrastive_loss=0.14, total=4195.53, n_correct=2740.25, ppl=5.84, accuracy=65.314, wps=6694.3, ups=1.6, wpb=4195.5, bsz=155.8, num_updates=29900, lr=8.17861e-05, gnorm=0.414, clip=0, loss_scale=32, train_wall=62, gb_free=16.7, wall=24774
2023-07-17 18:59:15 | INFO | train_inner | epoch 021:    533 / 1474 loss=1.638, trans_loss=5.27, nll_loss=2.548, w2v_ctc_loss=0.525, task_loss=2.683, contrastive_loss=0.132, total=4085.05, n_correct=2663.28, ppl=5.85, accuracy=65.196, wps=6445.3, ups=1.58, wpb=4085.1, bsz=148, num_updates=30000, lr=8.16497e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=24837
2023-07-17 18:59:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 18:59:42 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.685 | trans_loss 5.564 | nll_loss 2.838 | w2v_ctc_loss 1.147 | task_loss 4.303 | contrastive_loss 0.263 | total 4003.4 | n_correct 2473.4 | ppl 7.15 | accuracy 61.782 | uer 17.028 | wer 18.829 | raw_wer 18.829 | bleu 19.88 | wps 1942.5 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.28
2023-07-17 18:59:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-17 18:59:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_21_30000.pt
2023-07-17 18:59:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_21_30000.pt
2023-07-17 18:59:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.88) (writing took 6.531731990980916 seconds)
mt_weight tensor(0.0177, device='cuda:0')
asr_weight tensor(0.0013, device='cuda:0')
2023-07-17 19:00:53 | INFO | train_inner | epoch 021:    633 / 1474 loss=1.655, trans_loss=5.28, nll_loss=2.562, w2v_ctc_loss=0.52, task_loss=2.567, contrastive_loss=0.474, total=4220.3, n_correct=2749.48, ppl=5.9, accuracy=65.149, wps=4325.7, ups=1.02, wpb=4220.3, bsz=157.9, num_updates=30100, lr=8.15139e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=15.9, wall=24935
2023-07-17 19:01:56 | INFO | train_inner | epoch 021:    733 / 1474 loss=1.642, trans_loss=5.288, nll_loss=2.572, w2v_ctc_loss=0.519, task_loss=2.615, contrastive_loss=0.199, total=4148.18, n_correct=2694.83, ppl=5.95, accuracy=64.964, wps=6535.7, ups=1.58, wpb=4148.2, bsz=154.2, num_updates=30200, lr=8.13788e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=63, gb_free=12.3, wall=24998
2023-07-17 19:03:00 | INFO | train_inner | epoch 021:    833 / 1474 loss=1.656, trans_loss=5.294, nll_loss=2.58, w2v_ctc_loss=0.53, task_loss=2.767, contrastive_loss=0.227, total=4062.56, n_correct=2634.88, ppl=5.98, accuracy=64.858, wps=6396.6, ups=1.57, wpb=4062.6, bsz=146.5, num_updates=30300, lr=8.12444e-05, gnorm=0.449, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=25062
2023-07-17 19:04:03 | INFO | train_inner | epoch 021:    933 / 1474 loss=1.658, trans_loss=5.285, nll_loss=2.569, w2v_ctc_loss=0.528, task_loss=2.588, contrastive_loss=0.171, total=4103.66, n_correct=2663.19, ppl=5.93, accuracy=64.898, wps=6541, ups=1.59, wpb=4103.7, bsz=150.7, num_updates=30400, lr=8.11107e-05, gnorm=0.431, clip=0, loss_scale=32, train_wall=62, gb_free=17.3, wall=25125
2023-07-17 19:05:05 | INFO | train_inner | epoch 021:   1033 / 1474 loss=1.661, trans_loss=5.306, nll_loss=2.596, w2v_ctc_loss=0.535, task_loss=2.659, contrastive_loss=0.167, total=4100.54, n_correct=2650.82, ppl=6.05, accuracy=64.646, wps=6544.5, ups=1.6, wpb=4100.5, bsz=149.1, num_updates=30500, lr=8.09776e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=62, gb_free=18, wall=25187
2023-07-17 19:06:09 | INFO | train_inner | epoch 021:   1133 / 1474 loss=1.66, trans_loss=5.293, nll_loss=2.578, w2v_ctc_loss=0.532, task_loss=2.791, contrastive_loss=0.174, total=4119.98, n_correct=2670.77, ppl=5.97, accuracy=64.825, wps=6489.1, ups=1.58, wpb=4120, bsz=147, num_updates=30600, lr=8.08452e-05, gnorm=0.436, clip=0, loss_scale=32, train_wall=63, gb_free=18, wall=25251
2023-07-17 19:07:12 | INFO | train_inner | epoch 021:   1233 / 1474 loss=1.648, trans_loss=5.288, nll_loss=2.573, w2v_ctc_loss=0.524, task_loss=2.455, contrastive_loss=0.277, total=4161.49, n_correct=2701.36, ppl=5.95, accuracy=64.913, wps=6637.1, ups=1.59, wpb=4161.5, bsz=156.5, num_updates=30700, lr=8.07134e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=62, gb_free=17, wall=25313
2023-07-17 19:08:15 | INFO | train_inner | epoch 021:   1333 / 1474 loss=1.648, trans_loss=5.287, nll_loss=2.573, w2v_ctc_loss=0.521, task_loss=2.521, contrastive_loss=0.196, total=4141.76, n_correct=2689.87, ppl=5.95, accuracy=64.945, wps=6554.1, ups=1.58, wpb=4141.8, bsz=155.8, num_updates=30800, lr=8.05823e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=63, gb_free=17.5, wall=25377
2023-07-17 19:09:19 | INFO | train_inner | epoch 021:   1433 / 1474 loss=1.668, trans_loss=5.306, nll_loss=2.596, w2v_ctc_loss=0.54, task_loss=2.75, contrastive_loss=0.295, total=4127.02, n_correct=2668.88, ppl=6.05, accuracy=64.668, wps=6442.2, ups=1.56, wpb=4127, bsz=151.1, num_updates=30900, lr=8.04518e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=64, gb_free=16.7, wall=25441
2023-07-17 19:09:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.0177, device='cuda:4')
asr_weight tensor(0.0013, device='cuda:4')
mt_weight tensor(0.0177, device='cuda:5')
asr_weight tensor(0.0013, device='cuda:5')
mt_weight tensor(0.0177, device='cuda:6')
asr_weight tensor(0.0013, device='cuda:6')
mt_weight tensor(0.0177, device='cuda:2')
asr_weight tensor(0.0013, device='cuda:2')
mt_weight tensor(0.0177, device='cuda:1')
asr_weight tensor(0.0013, device='cuda:1')
mt_weight tensor(0.0177, device='cuda:7')
asr_weight tensor(0.0013, device='cuda:7')
mt_weight tensor(0.0177, device='cuda:3')
asr_weight tensor(0.0013, device='cuda:3')
2023-07-17 19:10:11 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.677 | trans_loss 5.56 | nll_loss 2.834 | w2v_ctc_loss 1.125 | task_loss 4.302 | contrastive_loss 0.264 | total 4003.4 | n_correct 2480.3 | ppl 7.13 | accuracy 61.955 | uer 16.988 | wer 18.717 | raw_wer 18.717 | bleu 19.86 | wps 2087.9 | wpb 4003.4 | bsz 141.8 | num_updates 30941 | best_bleu 20.28
2023-07-17 19:10:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30941 updates
2023-07-17 19:10:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8604.pt
2023-07-17 19:10:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8604.pt
2023-07-17 19:10:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8604.pt (epoch 21 @ 30941 updates, score 19.86) (writing took 5.464295896003023 seconds)
2023-07-17 19:10:17 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-17 19:10:17 | INFO | train | epoch 021 | loss 1.649 | trans_loss 5.284 | nll_loss 2.567 | w2v_ctc_loss 0.525 | task_loss 2.603 | contrastive_loss 0.251 | total 4138.65 | n_correct 2690.09 | ppl 5.93 | accuracy 64.999 | wps 6058.7 | ups 1.46 | wpb 4138.6 | bsz 152.8 | num_updates 30941 | lr 8.03985e-05 | gnorm 0.426 | clip 0 | loss_scale 32 | train_wall 927 | gb_free 15.6 | wall 25499
2023-07-17 19:10:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 19:10:17 | INFO | fairseq.trainer | begin training epoch 22
2023-07-17 19:10:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 19:11:02 | INFO | train_inner | epoch 022:     59 / 1474 loss=1.643, trans_loss=5.269, nll_loss=2.548, w2v_ctc_loss=0.524, task_loss=2.629, contrastive_loss=0.137, total=4140.16, n_correct=2699.72, ppl=5.85, accuracy=65.208, wps=3999.8, ups=0.97, wpb=4140.2, bsz=150.1, num_updates=31000, lr=8.03219e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=17.8, wall=25544
2023-07-17 19:12:06 | INFO | train_inner | epoch 022:    159 / 1474 loss=1.637, trans_loss=5.251, nll_loss=2.525, w2v_ctc_loss=0.516, task_loss=2.617, contrastive_loss=0.296, total=4115.86, n_correct=2694.83, ppl=5.75, accuracy=65.474, wps=6505.4, ups=1.58, wpb=4115.9, bsz=154.7, num_updates=31100, lr=8.01927e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=17.5, wall=25608
2023-07-17 19:13:09 | INFO | train_inner | epoch 022:    259 / 1474 loss=1.626, trans_loss=5.244, nll_loss=2.516, w2v_ctc_loss=0.505, task_loss=2.343, contrastive_loss=0.162, total=4247.73, n_correct=2787.14, ppl=5.72, accuracy=65.615, wps=6695.2, ups=1.58, wpb=4247.7, bsz=161.6, num_updates=31200, lr=8.00641e-05, gnorm=0.408, clip=0, loss_scale=32, train_wall=63, gb_free=14.2, wall=25671
2023-07-17 19:14:14 | INFO | train_inner | epoch 022:    359 / 1474 loss=1.651, trans_loss=5.271, nll_loss=2.55, w2v_ctc_loss=0.518, task_loss=2.566, contrastive_loss=0.505, total=4212.22, n_correct=2745.83, ppl=5.86, accuracy=65.187, wps=6485.5, ups=1.54, wpb=4212.2, bsz=159, num_updates=31300, lr=7.99361e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=65, gb_free=15.8, wall=25736
2023-07-17 19:15:17 | INFO | train_inner | epoch 022:    459 / 1474 loss=1.657, trans_loss=5.275, nll_loss=2.554, w2v_ctc_loss=0.525, task_loss=2.727, contrastive_loss=0.26, total=4131.12, n_correct=2692.35, ppl=5.87, accuracy=65.172, wps=6507.6, ups=1.58, wpb=4131.1, bsz=148.6, num_updates=31400, lr=7.98087e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=25799
2023-07-17 19:16:22 | INFO | train_inner | epoch 022:    559 / 1474 loss=1.642, trans_loss=5.266, nll_loss=2.544, w2v_ctc_loss=0.522, task_loss=2.617, contrastive_loss=0.159, total=4153.54, n_correct=2710.9, ppl=5.83, accuracy=65.267, wps=6460.2, ups=1.56, wpb=4153.5, bsz=153.6, num_updates=31500, lr=7.96819e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=64, gb_free=15.2, wall=25864
2023-07-17 19:17:24 | INFO | train_inner | epoch 022:    659 / 1474 loss=1.632, trans_loss=5.252, nll_loss=2.527, w2v_ctc_loss=0.505, task_loss=2.454, contrastive_loss=0.323, total=4143.91, n_correct=2714.59, ppl=5.76, accuracy=65.508, wps=6691.1, ups=1.61, wpb=4143.9, bsz=156.6, num_updates=31600, lr=7.95557e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=61, gb_free=16, wall=25926
2023-07-17 19:18:27 | INFO | train_inner | epoch 022:    759 / 1474 loss=1.647, trans_loss=5.267, nll_loss=2.545, w2v_ctc_loss=0.525, task_loss=2.668, contrastive_loss=0.166, total=4168.91, n_correct=2718.41, ppl=5.84, accuracy=65.207, wps=6594.6, ups=1.58, wpb=4168.9, bsz=151.8, num_updates=31700, lr=7.94301e-05, gnorm=0.426, clip=0, loss_scale=64, train_wall=63, gb_free=17.7, wall=25989
2023-07-17 19:19:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-17 19:19:31 | INFO | train_inner | epoch 022:    860 / 1474 loss=1.642, trans_loss=5.276, nll_loss=2.557, w2v_ctc_loss=0.522, task_loss=2.841, contrastive_loss=0.135, total=4075.48, n_correct=2654.67, ppl=5.89, accuracy=65.138, wps=6350.2, ups=1.56, wpb=4075.5, bsz=144.1, num_updates=31800, lr=7.93052e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=64, gb_free=17.6, wall=26053
2023-07-17 19:20:34 | INFO | train_inner | epoch 022:    960 / 1474 loss=1.643, trans_loss=5.269, nll_loss=2.55, w2v_ctc_loss=0.518, task_loss=2.6, contrastive_loss=0.141, total=4136.34, n_correct=2698.34, ppl=5.85, accuracy=65.235, wps=6532.1, ups=1.58, wpb=4136.3, bsz=151.8, num_updates=31900, lr=7.91808e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=26116
2023-07-17 19:21:37 | INFO | train_inner | epoch 022:   1060 / 1474 loss=1.641, trans_loss=5.267, nll_loss=2.547, w2v_ctc_loss=0.51, task_loss=2.482, contrastive_loss=0.476, total=4157.21, n_correct=2715.45, ppl=5.84, accuracy=65.319, wps=6591.7, ups=1.59, wpb=4157.2, bsz=157.7, num_updates=32000, lr=7.90569e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=12.4, wall=26179
2023-07-17 19:21:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 19:22:01 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.683 | trans_loss 5.556 | nll_loss 2.827 | w2v_ctc_loss 1.141 | task_loss 4.295 | contrastive_loss 0.27 | total 4003.4 | n_correct 2479.2 | ppl 7.1 | accuracy 61.927 | uer 16.948 | wer 18.747 | raw_wer 18.747 | bleu 19.76 | wps 2336.5 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.28
2023-07-17 19:22:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-17 19:22:01 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_22_32000.pt
2023-07-17 19:22:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_22_32000.pt
2023-07-17 19:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.76) (writing took 5.320764207048342 seconds)
2023-07-17 19:23:10 | INFO | train_inner | epoch 022:   1160 / 1474 loss=1.654, trans_loss=5.295, nll_loss=2.583, w2v_ctc_loss=0.526, task_loss=2.711, contrastive_loss=0.24, total=4092.91, n_correct=2650.28, ppl=5.99, accuracy=64.753, wps=4434.5, ups=1.08, wpb=4092.9, bsz=147.2, num_updates=32100, lr=7.89337e-05, gnorm=0.435, clip=0, loss_scale=32, train_wall=62, gb_free=16.2, wall=26272
2023-07-17 19:24:12 | INFO | train_inner | epoch 022:   1260 / 1474 loss=1.641, trans_loss=5.28, nll_loss=2.564, w2v_ctc_loss=0.519, task_loss=2.407, contrastive_loss=0.231, total=4182.65, n_correct=2721.86, ppl=5.91, accuracy=65.075, wps=6672.6, ups=1.6, wpb=4182.6, bsz=161.8, num_updates=32200, lr=7.8811e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=62, gb_free=16.7, wall=26334
2023-07-17 19:25:15 | INFO | train_inner | epoch 022:   1360 / 1474 loss=1.642, trans_loss=5.271, nll_loss=2.552, w2v_ctc_loss=0.513, task_loss=2.582, contrastive_loss=0.276, total=4071.58, n_correct=2654.36, ppl=5.87, accuracy=65.192, wps=6501.3, ups=1.6, wpb=4071.6, bsz=150.3, num_updates=32300, lr=7.86889e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=62, gb_free=16.9, wall=26397
2023-07-17 19:26:18 | INFO | train_inner | epoch 022:   1460 / 1474 loss=1.658, trans_loss=5.288, nll_loss=2.573, w2v_ctc_loss=0.532, task_loss=2.773, contrastive_loss=0.171, total=4077.83, n_correct=2647.45, ppl=5.95, accuracy=64.923, wps=6479.4, ups=1.59, wpb=4077.8, bsz=144, num_updates=32400, lr=7.85674e-05, gnorm=0.437, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=26460
2023-07-17 19:26:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 19:26:52 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.686 | trans_loss 5.55 | nll_loss 2.817 | w2v_ctc_loss 1.139 | task_loss 4.253 | contrastive_loss 0.281 | total 4003.4 | n_correct 2486.9 | ppl 7.05 | accuracy 62.12 | uer 16.781 | wer 18.515 | raw_wer 18.515 | bleu 20.32 | wps 2189.5 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 20.32
2023-07-17 19:26:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-07-17 19:26:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 19:26:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 19:27:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 22 @ 32414 updates, score 20.32) (writing took 8.447267286013812 seconds)
2023-07-17 19:27:01 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-17 19:27:01 | INFO | train | epoch 022 | loss 1.644 | trans_loss 5.269 | nll_loss 2.548 | w2v_ctc_loss 0.519 | task_loss 2.599 | contrastive_loss 0.249 | total 4138.95 | n_correct 2699.88 | ppl 5.85 | accuracy 65.231 | wps 6069.9 | ups 1.47 | wpb 4139 | bsz 152.8 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.425 | clip 0 | loss_scale 32 | train_wall 926 | gb_free 12.2 | wall 26503
2023-07-17 19:27:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 19:27:01 | INFO | fairseq.trainer | begin training epoch 23
2023-07-17 19:27:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 19:28:04 | INFO | train_inner | epoch 023:     86 / 1474 loss=1.639, trans_loss=5.241, nll_loss=2.511, w2v_ctc_loss=0.518, task_loss=2.688, contrastive_loss=0.155, total=4089.8, n_correct=2687.4, ppl=5.7, accuracy=65.71, wps=3862.2, ups=0.94, wpb=4089.8, bsz=149.7, num_updates=32500, lr=7.84465e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=26566
2023-07-17 19:29:08 | INFO | train_inner | epoch 023:    186 / 1474 loss=1.636, trans_loss=5.241, nll_loss=2.511, w2v_ctc_loss=0.515, task_loss=2.735, contrastive_loss=0.15, total=4117.76, n_correct=2702.27, ppl=5.7, accuracy=65.625, wps=6402.7, ups=1.55, wpb=4117.8, bsz=148, num_updates=32600, lr=7.8326e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=64, gb_free=15.7, wall=26630
2023-07-17 19:30:12 | INFO | train_inner | epoch 023:    286 / 1474 loss=1.636, trans_loss=5.249, nll_loss=2.522, w2v_ctc_loss=0.508, task_loss=2.646, contrastive_loss=0.304, total=4144.73, n_correct=2715.56, ppl=5.75, accuracy=65.518, wps=6453.6, ups=1.56, wpb=4144.7, bsz=152, num_updates=32700, lr=7.82062e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=64, gb_free=17.6, wall=26694
2023-07-17 19:31:16 | INFO | train_inner | epoch 023:    386 / 1474 loss=1.637, trans_loss=5.244, nll_loss=2.514, w2v_ctc_loss=0.513, task_loss=2.666, contrastive_loss=0.135, total=4126.79, n_correct=2711.85, ppl=5.71, accuracy=65.713, wps=6547.8, ups=1.59, wpb=4126.8, bsz=148.2, num_updates=32800, lr=7.80869e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=17.3, wall=26757
2023-07-17 19:32:19 | INFO | train_inner | epoch 023:    486 / 1474 loss=1.63, trans_loss=5.247, nll_loss=2.52, w2v_ctc_loss=0.508, task_loss=2.528, contrastive_loss=0.248, total=4150.15, n_correct=2721.77, ppl=5.74, accuracy=65.582, wps=6550.9, ups=1.58, wpb=4150.1, bsz=156, num_updates=32900, lr=7.79681e-05, gnorm=0.417, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=26821
2023-07-17 19:33:21 | INFO | train_inner | epoch 023:    586 / 1474 loss=1.622, trans_loss=5.233, nll_loss=2.501, w2v_ctc_loss=0.504, task_loss=2.451, contrastive_loss=0.147, total=4174.6, n_correct=2750.11, ppl=5.66, accuracy=65.877, wps=6671.7, ups=1.6, wpb=4174.6, bsz=158.2, num_updates=33000, lr=7.78499e-05, gnorm=0.412, clip=0, loss_scale=32, train_wall=62, gb_free=16.6, wall=26883
2023-07-17 19:34:24 | INFO | train_inner | epoch 023:    686 / 1474 loss=1.641, trans_loss=5.246, nll_loss=2.519, w2v_ctc_loss=0.516, task_loss=2.611, contrastive_loss=0.221, total=4136.6, n_correct=2710.79, ppl=5.73, accuracy=65.532, wps=6578.8, ups=1.59, wpb=4136.6, bsz=150.6, num_updates=33100, lr=7.77322e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=62, gb_free=17.8, wall=26946
2023-07-17 19:35:27 | INFO | train_inner | epoch 023:    786 / 1474 loss=1.651, trans_loss=5.264, nll_loss=2.542, w2v_ctc_loss=0.525, task_loss=2.617, contrastive_loss=0.187, total=4147.22, n_correct=2708.18, ppl=5.82, accuracy=65.301, wps=6588.4, ups=1.59, wpb=4147.2, bsz=152.6, num_updates=33200, lr=7.76151e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=63, gb_free=17.4, wall=27009
2023-07-17 19:36:30 | INFO | train_inner | epoch 023:    886 / 1474 loss=1.635, trans_loss=5.248, nll_loss=2.522, w2v_ctc_loss=0.509, task_loss=2.354, contrastive_loss=0.342, total=4193.16, n_correct=2747.21, ppl=5.74, accuracy=65.516, wps=6669.8, ups=1.59, wpb=4193.2, bsz=163.6, num_updates=33300, lr=7.74984e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=62, gb_free=16.2, wall=27072
2023-07-17 19:37:33 | INFO | train_inner | epoch 023:    986 / 1474 loss=1.655, trans_loss=5.262, nll_loss=2.539, w2v_ctc_loss=0.516, task_loss=2.59, contrastive_loss=0.655, total=4164.33, n_correct=2720.15, ppl=5.81, accuracy=65.32, wps=6586.2, ups=1.58, wpb=4164.3, bsz=155.1, num_updates=33400, lr=7.73823e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=63, gb_free=17.8, wall=27135
2023-07-17 19:38:37 | INFO | train_inner | epoch 023:   1086 / 1474 loss=1.648, trans_loss=5.264, nll_loss=2.542, w2v_ctc_loss=0.527, task_loss=2.791, contrastive_loss=0.165, total=4088.37, n_correct=2670.72, ppl=5.83, accuracy=65.325, wps=6425.9, ups=1.57, wpb=4088.4, bsz=144.8, num_updates=33500, lr=7.72667e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=15.8, wall=27199
2023-07-17 19:39:41 | INFO | train_inner | epoch 023:   1186 / 1474 loss=1.632, trans_loss=5.26, nll_loss=2.538, w2v_ctc_loss=0.513, task_loss=2.588, contrastive_loss=0.151, total=4162.3, n_correct=2719.18, ppl=5.81, accuracy=65.329, wps=6507.9, ups=1.56, wpb=4162.3, bsz=154.5, num_updates=33600, lr=7.71517e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=64, gb_free=15.8, wall=27263
2023-07-17 19:40:44 | INFO | train_inner | epoch 023:   1286 / 1474 loss=1.63, trans_loss=5.255, nll_loss=2.531, w2v_ctc_loss=0.508, task_loss=2.532, contrastive_loss=0.173, total=4131.74, n_correct=2706.14, ppl=5.78, accuracy=65.496, wps=6581.2, ups=1.59, wpb=4131.7, bsz=154.4, num_updates=33700, lr=7.70371e-05, gnorm=0.415, clip=0, loss_scale=32, train_wall=62, gb_free=17.2, wall=27326
2023-07-17 19:40:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-17 19:41:48 | INFO | train_inner | epoch 023:   1387 / 1474 loss=1.645, trans_loss=5.279, nll_loss=2.562, w2v_ctc_loss=0.521, task_loss=2.669, contrastive_loss=0.166, total=4135.79, n_correct=2690.09, ppl=5.9, accuracy=65.044, wps=6410.7, ups=1.55, wpb=4135.8, bsz=150.3, num_updates=33800, lr=7.69231e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=64, gb_free=16.2, wall=27390
2023-07-17 19:42:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 19:43:10 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.683 | trans_loss 5.547 | nll_loss 2.815 | w2v_ctc_loss 1.18 | task_loss 4.33 | contrastive_loss 0.273 | total 4003.4 | n_correct 2490.7 | ppl 7.04 | accuracy 62.215 | uer 17.002 | wer 18.802 | raw_wer 18.802 | bleu 19.85 | wps 2000 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.32
2023-07-17 19:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-07-17 19:43:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8502.pt
2023-07-17 19:43:12 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8502.pt
2023-07-17 19:43:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_19.8502.pt (epoch 23 @ 33887 updates, score 19.85) (writing took 5.636938060983084 seconds)
2023-07-17 19:43:16 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-17 19:43:16 | INFO | train | epoch 023 | loss 1.638 | trans_loss 5.254 | nll_loss 2.529 | w2v_ctc_loss 0.514 | task_loss 2.602 | contrastive_loss 0.245 | total 4137.86 | n_correct 2709.01 | ppl 5.77 | accuracy 65.469 | wps 6252.2 | ups 1.51 | wpb 4137.9 | bsz 152.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.421 | clip 0 | loss_scale 16 | train_wall 928 | gb_free 14.1 | wall 27478
2023-07-17 19:43:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 19:43:16 | INFO | fairseq.trainer | begin training epoch 24
2023-07-17 19:43:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 19:43:33 | INFO | train_inner | epoch 024:     13 / 1474 loss=1.642, trans_loss=5.277, nll_loss=2.561, w2v_ctc_loss=0.51, task_loss=2.612, contrastive_loss=0.438, total=4085.11, n_correct=2660.7, ppl=5.9, accuracy=65.132, wps=3911.2, ups=0.96, wpb=4085.1, bsz=152.1, num_updates=33900, lr=7.68095e-05, gnorm=0.426, clip=0, loss_scale=16, train_wall=63, gb_free=13, wall=27495
2023-07-17 19:44:36 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.635, trans_loss=5.229, nll_loss=2.497, w2v_ctc_loss=0.504, task_loss=2.392, contrastive_loss=0.481, total=4171.44, n_correct=2751.24, ppl=5.65, accuracy=65.954, wps=6599.2, ups=1.58, wpb=4171.4, bsz=162.3, num_updates=34000, lr=7.66965e-05, gnorm=0.442, clip=0, loss_scale=16, train_wall=63, gb_free=16.6, wall=27558
2023-07-17 19:44:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 19:45:02 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.684 | trans_loss 5.551 | nll_loss 2.819 | w2v_ctc_loss 1.156 | task_loss 4.309 | contrastive_loss 0.271 | total 4003.4 | n_correct 2488.1 | ppl 7.06 | accuracy 62.15 | uer 16.757 | wer 18.657 | raw_wer 18.657 | bleu 20.24 | wps 2059.8 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.32
2023-07-17 19:45:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-17 19:45:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_24_34000.pt
2023-07-17 19:45:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_24_34000.pt
2023-07-17 19:45:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 20.24) (writing took 6.55973828502465 seconds)
2023-07-17 19:46:13 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.625, trans_loss=5.23, nll_loss=2.498, w2v_ctc_loss=0.493, task_loss=2.269, contrastive_loss=0.586, total=4251.29, n_correct=2800.99, ppl=5.65, accuracy=65.886, wps=4372.1, ups=1.03, wpb=4251.3, bsz=170.4, num_updates=34100, lr=7.6584e-05, gnorm=0.414, clip=0, loss_scale=16, train_wall=64, gb_free=17, wall=27655
2023-07-17 19:47:16 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.619, trans_loss=5.225, nll_loss=2.492, w2v_ctc_loss=0.503, task_loss=2.548, contrastive_loss=0.14, total=4128.18, n_correct=2723.5, ppl=5.62, accuracy=65.973, wps=6556.2, ups=1.59, wpb=4128.2, bsz=152.8, num_updates=34200, lr=7.64719e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=63, gb_free=16.3, wall=27718
2023-07-17 19:48:20 | INFO | train_inner | epoch 024:    413 / 1474 loss=1.645, trans_loss=5.247, nll_loss=2.52, w2v_ctc_loss=0.516, task_loss=2.73, contrastive_loss=0.427, total=4158.92, n_correct=2728.51, ppl=5.74, accuracy=65.606, wps=6522.1, ups=1.57, wpb=4158.9, bsz=149.9, num_updates=34300, lr=7.63604e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=63, gb_free=16.8, wall=27782
2023-07-17 19:49:24 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.633, trans_loss=5.24, nll_loss=2.511, w2v_ctc_loss=0.511, task_loss=2.641, contrastive_loss=0.28, total=4144.91, n_correct=2724.46, ppl=5.7, accuracy=65.73, wps=6485.9, ups=1.56, wpb=4144.9, bsz=151.6, num_updates=34400, lr=7.62493e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=63, gb_free=17.1, wall=27846
2023-07-17 19:50:27 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.622, trans_loss=5.231, nll_loss=2.499, w2v_ctc_loss=0.502, task_loss=2.622, contrastive_loss=0.207, total=4165.3, n_correct=2740.91, ppl=5.65, accuracy=65.803, wps=6605.9, ups=1.59, wpb=4165.3, bsz=153.8, num_updates=34500, lr=7.61387e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=63, gb_free=16, wall=27909
2023-07-17 19:51:30 | INFO | train_inner | epoch 024:    713 / 1474 loss=1.641, trans_loss=5.25, nll_loss=2.525, w2v_ctc_loss=0.515, task_loss=2.683, contrastive_loss=0.228, total=4102.21, n_correct=2690.67, ppl=5.75, accuracy=65.591, wps=6530.9, ups=1.59, wpb=4102.2, bsz=147.5, num_updates=34600, lr=7.60286e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=62, gb_free=17.2, wall=27972
2023-07-17 19:52:33 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.633, trans_loss=5.241, nll_loss=2.513, w2v_ctc_loss=0.507, task_loss=2.625, contrastive_loss=0.185, total=4110.6, n_correct=2701.71, ppl=5.71, accuracy=65.725, wps=6475.3, ups=1.58, wpb=4110.6, bsz=152.7, num_updates=34700, lr=7.5919e-05, gnorm=0.43, clip=0, loss_scale=16, train_wall=63, gb_free=16.8, wall=28035
2023-07-17 19:53:36 | INFO | train_inner | epoch 024:    913 / 1474 loss=1.645, trans_loss=5.252, nll_loss=2.526, w2v_ctc_loss=0.519, task_loss=2.887, contrastive_loss=0.135, total=4043.03, n_correct=2646.7, ppl=5.76, accuracy=65.463, wps=6453.5, ups=1.6, wpb=4043, bsz=140.5, num_updates=34800, lr=7.58098e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=62, gb_free=11.7, wall=28098
2023-07-17 19:54:39 | INFO | train_inner | epoch 024:   1013 / 1474 loss=1.63, trans_loss=5.248, nll_loss=2.522, w2v_ctc_loss=0.505, task_loss=2.695, contrastive_loss=0.143, total=4136.81, n_correct=2714.29, ppl=5.74, accuracy=65.613, wps=6542.2, ups=1.58, wpb=4136.8, bsz=149.2, num_updates=34900, lr=7.57011e-05, gnorm=0.417, clip=0, loss_scale=16, train_wall=63, gb_free=17.1, wall=28161
2023-07-17 19:55:43 | INFO | train_inner | epoch 024:   1113 / 1474 loss=1.626, trans_loss=5.231, nll_loss=2.5, w2v_ctc_loss=0.507, task_loss=2.513, contrastive_loss=0.227, total=4135.73, n_correct=2724, ppl=5.66, accuracy=65.865, wps=6455.9, ups=1.56, wpb=4135.7, bsz=154.4, num_updates=35000, lr=7.55929e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=64, gb_free=17.2, wall=28225
mt_weight tensor(0.0177, device='cuda:0')
asr_weight tensor(0.0013, device='cuda:0')
2023-07-17 19:56:46 | INFO | train_inner | epoch 024:   1213 / 1474 loss=1.641, trans_loss=5.252, nll_loss=2.528, w2v_ctc_loss=0.51, task_loss=2.573, contrastive_loss=0.209, total=4148.3, n_correct=2717.62, ppl=5.77, accuracy=65.512, wps=6547.6, ups=1.58, wpb=4148.3, bsz=155.4, num_updates=35100, lr=7.54851e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=63, gb_free=16.8, wall=28288
2023-07-17 19:57:50 | INFO | train_inner | epoch 024:   1313 / 1474 loss=1.644, trans_loss=5.256, nll_loss=2.532, w2v_ctc_loss=0.52, task_loss=2.769, contrastive_loss=0.152, total=4110.05, n_correct=2691.39, ppl=5.78, accuracy=65.483, wps=6493.5, ups=1.58, wpb=4110.1, bsz=147.1, num_updates=35200, lr=7.53778e-05, gnorm=0.433, clip=0, loss_scale=16, train_wall=63, gb_free=17.4, wall=28352
2023-07-17 19:58:53 | INFO | train_inner | epoch 024:   1413 / 1474 loss=1.647, trans_loss=5.258, nll_loss=2.536, w2v_ctc_loss=0.523, task_loss=2.722, contrastive_loss=0.148, total=4090.91, n_correct=2676.04, ppl=5.8, accuracy=65.414, wps=6485.6, ups=1.59, wpb=4090.9, bsz=146.4, num_updates=35300, lr=7.5271e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=63, gb_free=16.6, wall=28415
2023-07-17 19:59:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.0177, device='cuda:7')
asr_weight tensor(0.0013, device='cuda:7')
mt_weight tensor(0.0177, device='cuda:1')
asr_weight tensor(0.0013, device='cuda:1')
mt_weight tensor(0.0177, device='cuda:5')
asr_weight tensor(0.0013, device='cuda:5')
mt_weight tensor(0.0177, device='cuda:2')
asr_weight tensor(0.0013, device='cuda:2')
mt_weight tensor(0.0177, device='cuda:6')
asr_weight tensor(0.0013, device='cuda:6')
mt_weight tensor(0.0177, device='cuda:3')
asr_weight tensor(0.0013, device='cuda:3')
mt_weight tensor(0.0177, device='cuda:4')
asr_weight tensor(0.0013, device='cuda:4')
2023-07-17 19:59:56 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.699 | trans_loss 5.554 | nll_loss 2.823 | w2v_ctc_loss 1.172 | task_loss 4.267 | contrastive_loss 0.279 | total 4003.4 | n_correct 2485.8 | ppl 7.08 | accuracy 62.092 | uer 16.8 | wer 18.612 | raw_wer 18.612 | bleu 20.08 | wps 2333.9 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.32
2023-07-17 19:59:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-07-17 19:59:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.0802.pt
2023-07-17 19:59:58 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.0802.pt
2023-07-17 20:00:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.0802.pt (epoch 24 @ 35361 updates, score 20.08) (writing took 5.6372874029912055 seconds)
2023-07-17 20:00:01 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-17 20:00:01 | INFO | train | epoch 024 | loss 1.634 | trans_loss 5.242 | nll_loss 2.514 | w2v_ctc_loss 0.509 | task_loss 2.601 | contrastive_loss 0.254 | total 4138.65 | n_correct 2718.71 | ppl 5.71 | accuracy 65.691 | wps 6066.8 | ups 1.47 | wpb 4138.6 | bsz 152.8 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.424 | clip 0 | loss_scale 16 | train_wall 928 | gb_free 16.3 | wall 28483
2023-07-17 20:00:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 20:00:02 | INFO | fairseq.trainer | begin training epoch 25
2023-07-17 20:00:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 20:00:34 | INFO | train_inner | epoch 025:     39 / 1474 loss=1.615, trans_loss=5.224, nll_loss=2.491, w2v_ctc_loss=0.502, task_loss=2.487, contrastive_loss=0.165, total=4166.95, n_correct=2747.42, ppl=5.62, accuracy=65.934, wps=4117.1, ups=0.99, wpb=4166.9, bsz=156, num_updates=35400, lr=7.51646e-05, gnorm=0.411, clip=0, loss_scale=16, train_wall=62, gb_free=16.6, wall=28516
2023-07-17 20:01:37 | INFO | train_inner | epoch 025:    139 / 1474 loss=1.604, trans_loss=5.21, nll_loss=2.472, w2v_ctc_loss=0.495, task_loss=2.551, contrastive_loss=0.162, total=4133.64, n_correct=2737.17, ppl=5.55, accuracy=66.217, wps=6564.1, ups=1.59, wpb=4133.6, bsz=153.9, num_updates=35500, lr=7.50587e-05, gnorm=0.416, clip=0, loss_scale=16, train_wall=63, gb_free=16, wall=28579
2023-07-17 20:02:41 | INFO | train_inner | epoch 025:    239 / 1474 loss=1.623, trans_loss=5.217, nll_loss=2.481, w2v_ctc_loss=0.507, task_loss=2.674, contrastive_loss=0.171, total=4114.53, n_correct=2719.51, ppl=5.58, accuracy=66.095, wps=6413.5, ups=1.56, wpb=4114.5, bsz=151.4, num_updates=35600, lr=7.49532e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=64, gb_free=17.2, wall=28643
2023-07-17 20:03:45 | INFO | train_inner | epoch 025:    339 / 1474 loss=1.638, trans_loss=5.224, nll_loss=2.489, w2v_ctc_loss=0.507, task_loss=2.767, contrastive_loss=0.226, total=4148.7, n_correct=2733.79, ppl=5.61, accuracy=65.895, wps=6503.2, ups=1.57, wpb=4148.7, bsz=147.6, num_updates=35700, lr=7.48481e-05, gnorm=0.436, clip=0, loss_scale=16, train_wall=63, gb_free=16.8, wall=28707
2023-07-17 20:04:48 | INFO | train_inner | epoch 025:    439 / 1474 loss=1.651, trans_loss=5.237, nll_loss=2.507, w2v_ctc_loss=0.519, task_loss=2.713, contrastive_loss=0.381, total=4167.03, n_correct=2742.06, ppl=5.68, accuracy=65.804, wps=6571.4, ups=1.58, wpb=4167, bsz=149.2, num_updates=35800, lr=7.47435e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=12.7, wall=28770
2023-07-17 20:05:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-17 20:05:53 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.633, trans_loss=5.235, nll_loss=2.505, w2v_ctc_loss=0.511, task_loss=2.54, contrastive_loss=0.171, total=4153.43, n_correct=2735.36, ppl=5.68, accuracy=65.858, wps=6472.4, ups=1.56, wpb=4153.4, bsz=156.4, num_updates=35900, lr=7.46393e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=64, gb_free=17.7, wall=28835
2023-07-17 20:06:55 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.628, trans_loss=5.222, nll_loss=2.489, w2v_ctc_loss=0.504, task_loss=2.577, contrastive_loss=0.301, total=4153.68, n_correct=2744.18, ppl=5.61, accuracy=66.066, wps=6641.2, ups=1.6, wpb=4153.7, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=62, gb_free=16.6, wall=28897
2023-07-17 20:06:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 20:07:20 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.693 | trans_loss 5.546 | nll_loss 2.818 | w2v_ctc_loss 1.186 | task_loss 4.281 | contrastive_loss 0.276 | total 4003.4 | n_correct 2482.7 | ppl 7.05 | accuracy 62.015 | uer 16.954 | wer 18.81 | raw_wer 18.81 | bleu 19.94 | wps 2205.7 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.32
2023-07-17 20:07:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-17 20:07:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_25_36000.pt
2023-07-17 20:07:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_25_36000.pt
2023-07-17 20:07:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.94) (writing took 6.507467552903108 seconds)
2023-07-17 20:08:31 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.629, trans_loss=5.23, nll_loss=2.499, w2v_ctc_loss=0.507, task_loss=2.642, contrastive_loss=0.293, total=4128.34, n_correct=2722.5, ppl=5.65, accuracy=65.947, wps=4326.7, ups=1.05, wpb=4128.3, bsz=150.6, num_updates=36100, lr=7.44323e-05, gnorm=0.427, clip=0, loss_scale=16, train_wall=63, gb_free=17.2, wall=28993
2023-07-17 20:09:34 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.618, trans_loss=5.226, nll_loss=2.493, w2v_ctc_loss=0.501, task_loss=2.391, contrastive_loss=0.19, total=4182.4, n_correct=2759.11, ppl=5.63, accuracy=65.97, wps=6553.9, ups=1.57, wpb=4182.4, bsz=163, num_updates=36200, lr=7.43294e-05, gnorm=0.42, clip=0, loss_scale=16, train_wall=63, gb_free=17.8, wall=29056
2023-07-17 20:10:38 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.629, trans_loss=5.229, nll_loss=2.498, w2v_ctc_loss=0.504, task_loss=2.455, contrastive_loss=0.299, total=4155.21, n_correct=2737.94, ppl=5.65, accuracy=65.892, wps=6570.2, ups=1.58, wpb=4155.2, bsz=158.5, num_updates=36300, lr=7.4227e-05, gnorm=0.419, clip=0, loss_scale=16, train_wall=63, gb_free=14.4, wall=29120
2023-07-17 20:11:41 | INFO | train_inner | epoch 025:   1040 / 1474 loss=1.643, trans_loss=5.24, nll_loss=2.512, w2v_ctc_loss=0.501, task_loss=2.579, contrastive_loss=0.518, total=4177.7, n_correct=2742.25, ppl=5.7, accuracy=65.64, wps=6597.2, ups=1.58, wpb=4177.7, bsz=154.9, num_updates=36400, lr=7.41249e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=63, gb_free=15.9, wall=29183
2023-07-17 20:12:44 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.634, trans_loss=5.236, nll_loss=2.506, w2v_ctc_loss=0.507, task_loss=2.799, contrastive_loss=0.133, total=4039.24, n_correct=2656.88, ppl=5.68, accuracy=65.777, wps=6428.9, ups=1.59, wpb=4039.2, bsz=142.6, num_updates=36500, lr=7.40233e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=62, gb_free=16.6, wall=29246
2023-07-17 20:13:46 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.634, trans_loss=5.236, nll_loss=2.507, w2v_ctc_loss=0.506, task_loss=2.637, contrastive_loss=0.151, total=4090.59, n_correct=2689.47, ppl=5.68, accuracy=65.748, wps=6586.2, ups=1.61, wpb=4090.6, bsz=147.8, num_updates=36600, lr=7.39221e-05, gnorm=0.426, clip=0, loss_scale=16, train_wall=62, gb_free=17.4, wall=29308
2023-07-17 20:14:49 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.63, trans_loss=5.231, nll_loss=2.501, w2v_ctc_loss=0.502, task_loss=2.541, contrastive_loss=0.337, total=4164.34, n_correct=2745.37, ppl=5.66, accuracy=65.926, wps=6558.9, ups=1.58, wpb=4164.3, bsz=155.1, num_updates=36700, lr=7.38213e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=63, gb_free=17.1, wall=29371
2023-07-17 20:15:54 | INFO | train_inner | epoch 025:   1440 / 1474 loss=1.634, trans_loss=5.254, nll_loss=2.53, w2v_ctc_loss=0.511, task_loss=2.709, contrastive_loss=0.243, total=4099.11, n_correct=2685.91, ppl=5.78, accuracy=65.524, wps=6359.4, ups=1.55, wpb=4099.1, bsz=149.7, num_updates=36800, lr=7.3721e-05, gnorm=0.426, clip=0, loss_scale=16, train_wall=64, gb_free=12.6, wall=29436
2023-07-17 20:16:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 20:16:41 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.658 | trans_loss 5.538 | nll_loss 2.804 | w2v_ctc_loss 1.12 | task_loss 4.323 | contrastive_loss 0.272 | total 4003.4 | n_correct 2491.3 | ppl 6.99 | accuracy 62.23 | uer 16.617 | wer 18.568 | raw_wer 18.568 | bleu 20.49 | wps 2227.3 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.49
2023-07-17 20:16:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-07-17 20:16:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 20:16:45 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 20:16:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 25 @ 36834 updates, score 20.49) (writing took 8.411434471956454 seconds)
2023-07-17 20:16:49 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-17 20:16:49 | INFO | train | epoch 025 | loss 1.63 | trans_loss 5.23 | nll_loss 2.499 | w2v_ctc_loss 0.506 | task_loss 2.599 | contrastive_loss 0.253 | total 4138.44 | n_correct 2726.63 | ppl 5.65 | accuracy 65.886 | wps 6050.2 | ups 1.46 | wpb 4138.4 | bsz 152.8 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.425 | clip 0 | loss_scale 16 | train_wall 928 | gb_free 14.6 | wall 29491
2023-07-17 20:16:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 20:16:49 | INFO | fairseq.trainer | begin training epoch 26
2023-07-17 20:16:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 20:17:39 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.612, trans_loss=5.205, nll_loss=2.466, w2v_ctc_loss=0.493, task_loss=2.44, contrastive_loss=0.212, total=4180.21, n_correct=2769.59, ppl=5.53, accuracy=66.255, wps=3989.3, ups=0.95, wpb=4180.2, bsz=159.2, num_updates=36900, lr=7.3621e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=63, gb_free=17.2, wall=29541
2023-07-17 20:18:42 | INFO | train_inner | epoch 026:    166 / 1474 loss=1.618, trans_loss=5.195, nll_loss=2.454, w2v_ctc_loss=0.483, task_loss=2.276, contrastive_loss=0.581, total=4270.78, n_correct=2841.82, ppl=5.48, accuracy=66.541, wps=6690, ups=1.57, wpb=4270.8, bsz=170.2, num_updates=37000, lr=7.35215e-05, gnorm=0.41, clip=0, loss_scale=16, train_wall=63, gb_free=15.5, wall=29604
2023-07-17 20:19:46 | INFO | train_inner | epoch 026:    266 / 1474 loss=1.623, trans_loss=5.214, nll_loss=2.477, w2v_ctc_loss=0.504, task_loss=2.586, contrastive_loss=0.332, total=4125.04, n_correct=2729.95, ppl=5.57, accuracy=66.18, wps=6540.9, ups=1.59, wpb=4125, bsz=153.6, num_updates=37100, lr=7.34223e-05, gnorm=0.427, clip=0, loss_scale=16, train_wall=63, gb_free=15.4, wall=29668
2023-07-17 20:20:48 | INFO | train_inner | epoch 026:    366 / 1474 loss=1.617, trans_loss=5.205, nll_loss=2.466, w2v_ctc_loss=0.496, task_loss=2.489, contrastive_loss=0.248, total=4165.74, n_correct=2760.89, ppl=5.52, accuracy=66.276, wps=6630.1, ups=1.59, wpb=4165.7, bsz=157.3, num_updates=37200, lr=7.33236e-05, gnorm=0.431, clip=0, loss_scale=16, train_wall=62, gb_free=17, wall=29730
2023-07-17 20:21:52 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.621, trans_loss=5.198, nll_loss=2.457, w2v_ctc_loss=0.497, task_loss=2.462, contrastive_loss=0.334, total=4170.23, n_correct=2770.53, ppl=5.49, accuracy=66.436, wps=6579.8, ups=1.58, wpb=4170.2, bsz=157.7, num_updates=37300, lr=7.32252e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=63, gb_free=17.9, wall=29794
2023-07-17 20:22:56 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.622, trans_loss=5.218, nll_loss=2.482, w2v_ctc_loss=0.51, task_loss=2.623, contrastive_loss=0.179, total=4155.02, n_correct=2746.05, ppl=5.59, accuracy=66.09, wps=6507.7, ups=1.57, wpb=4155, bsz=151.9, num_updates=37400, lr=7.31272e-05, gnorm=0.429, clip=0, loss_scale=16, train_wall=63, gb_free=17.9, wall=29858
2023-07-17 20:23:58 | INFO | train_inner | epoch 026:    666 / 1474 loss=1.625, trans_loss=5.208, nll_loss=2.47, w2v_ctc_loss=0.496, task_loss=2.647, contrastive_loss=0.149, total=4136.96, n_correct=2739.71, ppl=5.54, accuracy=66.225, wps=6579.1, ups=1.59, wpb=4137, bsz=149.6, num_updates=37500, lr=7.30297e-05, gnorm=0.425, clip=0, loss_scale=16, train_wall=62, gb_free=15.5, wall=29920
2023-07-17 20:25:02 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.635, trans_loss=5.224, nll_loss=2.491, w2v_ctc_loss=0.502, task_loss=2.648, contrastive_loss=0.371, total=4086.28, n_correct=2695.19, ppl=5.62, accuracy=65.957, wps=6483.7, ups=1.59, wpb=4086.3, bsz=149.2, num_updates=37600, lr=7.29325e-05, gnorm=0.427, clip=0, loss_scale=16, train_wall=63, gb_free=15.3, wall=29983
2023-07-17 20:26:05 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.62, trans_loss=5.216, nll_loss=2.48, w2v_ctc_loss=0.502, task_loss=2.577, contrastive_loss=0.18, total=4183.26, n_correct=2762.75, ppl=5.58, accuracy=66.043, wps=6622.8, ups=1.58, wpb=4183.3, bsz=154.1, num_updates=37700, lr=7.28357e-05, gnorm=0.432, clip=0, loss_scale=16, train_wall=63, gb_free=17.5, wall=30047
2023-07-17 20:27:08 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.627, trans_loss=5.227, nll_loss=2.495, w2v_ctc_loss=0.497, task_loss=2.696, contrastive_loss=0.284, total=4137.96, n_correct=2728.31, ppl=5.64, accuracy=65.934, wps=6546.9, ups=1.58, wpb=4138, bsz=149.5, num_updates=37800, lr=7.27393e-05, gnorm=0.421, clip=0, loss_scale=16, train_wall=63, gb_free=17.1, wall=30110
2023-07-17 20:28:12 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.629, trans_loss=5.224, nll_loss=2.491, w2v_ctc_loss=0.503, task_loss=2.733, contrastive_loss=0.151, total=4120.53, n_correct=2718.23, ppl=5.62, accuracy=65.968, wps=6449.4, ups=1.57, wpb=4120.5, bsz=147.1, num_updates=37900, lr=7.26433e-05, gnorm=0.427, clip=0, loss_scale=16, train_wall=63, gb_free=16.8, wall=30174
2023-07-17 20:29:15 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.626, trans_loss=5.233, nll_loss=2.502, w2v_ctc_loss=0.505, task_loss=2.722, contrastive_loss=0.226, total=4113.86, n_correct=2707.66, ppl=5.66, accuracy=65.818, wps=6476.2, ups=1.57, wpb=4113.9, bsz=149.2, num_updates=38000, lr=7.25476e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=30237
2023-07-17 20:29:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 20:29:41 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.687 | trans_loss 5.544 | nll_loss 2.816 | w2v_ctc_loss 1.173 | task_loss 4.295 | contrastive_loss 0.271 | total 4003.4 | n_correct 2493.8 | ppl 7.04 | accuracy 62.292 | uer 16.967 | wer 18.735 | raw_wer 18.735 | bleu 20.33 | wps 2039.8 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.49
2023-07-17 20:29:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-17 20:29:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_26_38000.pt
2023-07-17 20:29:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_26_38000.pt
2023-07-17 20:29:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.33) (writing took 6.470861498033628 seconds)
2023-07-17 20:30:51 | INFO | train_inner | epoch 026:   1266 / 1474 loss=1.641, trans_loss=5.247, nll_loss=2.52, w2v_ctc_loss=0.518, task_loss=2.908, contrastive_loss=0.153, total=3996.19, n_correct=2619.85, ppl=5.74, accuracy=65.559, wps=4171.9, ups=1.04, wpb=3996.2, bsz=139.6, num_updates=38100, lr=7.24524e-05, gnorm=0.441, clip=0, loss_scale=32, train_wall=63, gb_free=17.8, wall=30333
2023-07-17 20:31:55 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.629, trans_loss=5.233, nll_loss=2.503, w2v_ctc_loss=0.502, task_loss=2.6, contrastive_loss=0.183, total=4159.74, n_correct=2741.61, ppl=5.67, accuracy=65.908, wps=6483.4, ups=1.56, wpb=4159.7, bsz=155.7, num_updates=38200, lr=7.23575e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=64, gb_free=17.4, wall=30397
2023-07-17 20:32:58 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.614, trans_loss=5.224, nll_loss=2.493, w2v_ctc_loss=0.493, task_loss=2.466, contrastive_loss=0.173, total=4165.66, n_correct=2748.5, ppl=5.63, accuracy=65.98, wps=6599.5, ups=1.58, wpb=4165.7, bsz=158.7, num_updates=38300, lr=7.22629e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=30460
2023-07-17 20:33:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 20:33:30 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.67 | trans_loss 5.544 | nll_loss 2.816 | w2v_ctc_loss 1.142 | task_loss 4.33 | contrastive_loss 0.264 | total 4003.4 | n_correct 2493.6 | ppl 7.04 | accuracy 62.287 | uer 16.609 | wer 18.437 | raw_wer 18.437 | bleu 20.05 | wps 2047.8 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.49
2023-07-17 20:33:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-07-17 20:33:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.0507.pt
2023-07-17 20:33:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.0507.pt
2023-07-17 20:33:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.0507.pt (epoch 26 @ 38308 updates, score 20.05) (writing took 5.53927652107086 seconds)
2023-07-17 20:33:36 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-17 20:33:36 | INFO | train | epoch 026 | loss 1.624 | trans_loss 5.217 | nll_loss 2.482 | w2v_ctc_loss 0.5 | task_loss 2.6 | contrastive_loss 0.252 | total 4138.65 | n_correct 2735.19 | ppl 5.59 | accuracy 66.089 | wps 6060.2 | ups 1.46 | wpb 4138.6 | bsz 152.8 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.426 | clip 0 | loss_scale 32 | train_wall 927 | gb_free 16.2 | wall 30498
2023-07-17 20:33:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 20:33:36 | INFO | fairseq.trainer | begin training epoch 27
2023-07-17 20:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 20:34:42 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.619, trans_loss=5.178, nll_loss=2.429, w2v_ctc_loss=0.492, task_loss=2.797, contrastive_loss=0.127, total=4054.57, n_correct=2703.75, ppl=5.39, accuracy=66.684, wps=3930.9, ups=0.97, wpb=4054.6, bsz=141.2, num_updates=38400, lr=7.21688e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=30564
2023-07-17 20:35:46 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.604, trans_loss=5.184, nll_loss=2.439, w2v_ctc_loss=0.491, task_loss=2.474, contrastive_loss=0.188, total=4195.2, n_correct=2793.4, ppl=5.42, accuracy=66.586, wps=6532.4, ups=1.56, wpb=4195.2, bsz=161.6, num_updates=38500, lr=7.2075e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=64, gb_free=17.3, wall=30628
2023-07-17 20:36:50 | INFO | train_inner | epoch 027:    292 / 1474 loss=1.612, trans_loss=5.192, nll_loss=2.449, w2v_ctc_loss=0.492, task_loss=2.606, contrastive_loss=0.151, total=4162.23, n_correct=2771.85, ppl=5.46, accuracy=66.595, wps=6503.2, ups=1.56, wpb=4162.2, bsz=152.7, num_updates=38600, lr=7.19816e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=64, gb_free=17.3, wall=30692
2023-07-17 20:37:54 | INFO | train_inner | epoch 027:    392 / 1474 loss=1.631, trans_loss=5.21, nll_loss=2.473, w2v_ctc_loss=0.498, task_loss=2.727, contrastive_loss=0.513, total=4079.05, n_correct=2701.8, ppl=5.55, accuracy=66.236, wps=6386.6, ups=1.57, wpb=4079.1, bsz=148.6, num_updates=38700, lr=7.18885e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=30756
2023-07-17 20:38:57 | INFO | train_inner | epoch 027:    492 / 1474 loss=1.62, trans_loss=5.209, nll_loss=2.473, w2v_ctc_loss=0.493, task_loss=2.392, contrastive_loss=0.385, total=4243.25, n_correct=2810.1, ppl=5.55, accuracy=66.225, wps=6661.5, ups=1.57, wpb=4243.2, bsz=165.5, num_updates=38800, lr=7.17958e-05, gnorm=0.411, clip=0, loss_scale=32, train_wall=63, gb_free=15.9, wall=30819
2023-07-17 20:40:00 | INFO | train_inner | epoch 027:    592 / 1474 loss=1.619, trans_loss=5.206, nll_loss=2.468, w2v_ctc_loss=0.497, task_loss=2.529, contrastive_loss=0.272, total=4137.92, n_correct=2741.59, ppl=5.53, accuracy=66.255, wps=6595, ups=1.59, wpb=4137.9, bsz=156.7, num_updates=38900, lr=7.17035e-05, gnorm=0.439, clip=0, loss_scale=32, train_wall=62, gb_free=16.1, wall=30882
2023-07-17 20:41:03 | INFO | train_inner | epoch 027:    692 / 1474 loss=1.628, trans_loss=5.215, nll_loss=2.479, w2v_ctc_loss=0.503, task_loss=2.614, contrastive_loss=0.227, total=4158.48, n_correct=2753.11, ppl=5.57, accuracy=66.205, wps=6588.5, ups=1.58, wpb=4158.5, bsz=152, num_updates=39000, lr=7.16115e-05, gnorm=0.433, clip=0, loss_scale=32, train_wall=63, gb_free=15.9, wall=30945
2023-07-17 20:42:06 | INFO | train_inner | epoch 027:    792 / 1474 loss=1.621, trans_loss=5.213, nll_loss=2.476, w2v_ctc_loss=0.504, task_loss=2.753, contrastive_loss=0.151, total=4100.88, n_correct=2710.19, ppl=5.56, accuracy=66.088, wps=6485.1, ups=1.58, wpb=4100.9, bsz=146.1, num_updates=39100, lr=7.15199e-05, gnorm=0.438, clip=0, loss_scale=32, train_wall=63, gb_free=15.9, wall=31008
2023-07-17 20:43:09 | INFO | train_inner | epoch 027:    892 / 1474 loss=1.629, trans_loss=5.213, nll_loss=2.476, w2v_ctc_loss=0.496, task_loss=2.677, contrastive_loss=0.138, total=4111.94, n_correct=2718.18, ppl=5.56, accuracy=66.105, wps=6551.1, ups=1.59, wpb=4111.9, bsz=147.4, num_updates=39200, lr=7.14286e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=31071
2023-07-17 20:44:13 | INFO | train_inner | epoch 027:    992 / 1474 loss=1.624, trans_loss=5.217, nll_loss=2.483, w2v_ctc_loss=0.499, task_loss=2.53, contrastive_loss=0.513, total=4189.27, n_correct=2767.85, ppl=5.59, accuracy=66.07, wps=6546.8, ups=1.56, wpb=4189.3, bsz=157.5, num_updates=39300, lr=7.13376e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=64, gb_free=14.6, wall=31135
2023-07-17 20:45:17 | INFO | train_inner | epoch 027:   1092 / 1474 loss=1.618, trans_loss=5.209, nll_loss=2.472, w2v_ctc_loss=0.498, task_loss=2.595, contrastive_loss=0.175, total=4160.42, n_correct=2752.36, ppl=5.55, accuracy=66.156, wps=6558.7, ups=1.58, wpb=4160.4, bsz=153.7, num_updates=39400, lr=7.1247e-05, gnorm=0.443, clip=0, loss_scale=32, train_wall=63, gb_free=17.2, wall=31199
2023-07-17 20:46:20 | INFO | train_inner | epoch 027:   1192 / 1474 loss=1.621, trans_loss=5.215, nll_loss=2.479, w2v_ctc_loss=0.499, task_loss=2.733, contrastive_loss=0.183, total=4103.72, n_correct=2712.82, ppl=5.58, accuracy=66.106, wps=6512.5, ups=1.59, wpb=4103.7, bsz=148.6, num_updates=39500, lr=7.11568e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=63, gb_free=17.8, wall=31262
2023-07-17 20:47:23 | INFO | train_inner | epoch 027:   1292 / 1474 loss=1.622, trans_loss=5.225, nll_loss=2.492, w2v_ctc_loss=0.495, task_loss=2.782, contrastive_loss=0.286, total=4065.94, n_correct=2681.43, ppl=5.62, accuracy=65.949, wps=6423.9, ups=1.58, wpb=4065.9, bsz=146.2, num_updates=39600, lr=7.10669e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=31325
2023-07-17 20:48:26 | INFO | train_inner | epoch 027:   1392 / 1474 loss=1.624, trans_loss=5.219, nll_loss=2.487, w2v_ctc_loss=0.498, task_loss=2.454, contrastive_loss=0.254, total=4149.21, n_correct=2740.84, ppl=5.6, accuracy=66.057, wps=6624.9, ups=1.6, wpb=4149.2, bsz=156.3, num_updates=39700, lr=7.09773e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=62, gb_free=17.1, wall=31388
2023-07-17 20:49:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 20:49:42 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.676 | trans_loss 5.542 | nll_loss 2.813 | w2v_ctc_loss 1.155 | task_loss 4.309 | contrastive_loss 0.273 | total 4003.4 | n_correct 2493.7 | ppl 7.03 | accuracy 62.29 | uer 16.919 | wer 18.728 | raw_wer 18.728 | bleu 20.32 | wps 2269.9 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 20.49
2023-07-17 20:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-07-17 20:49:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.3209.pt
2023-07-17 20:49:47 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.3209.pt
2023-07-17 20:49:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.3209.pt (epoch 27 @ 39782 updates, score 20.32) (writing took 7.525408129091375 seconds)
2023-07-17 20:49:50 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-17 20:49:50 | INFO | train | epoch 027 | loss 1.62 | trans_loss 5.207 | nll_loss 2.469 | w2v_ctc_loss 0.496 | task_loss 2.601 | contrastive_loss 0.252 | total 4138.65 | n_correct 2741.63 | ppl 5.54 | accuracy 66.245 | wps 6261.3 | ups 1.51 | wpb 4138.6 | bsz 152.8 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.428 | clip 0 | loss_scale 32 | train_wall 928 | gb_free 17.9 | wall 31472
2023-07-17 20:49:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 20:49:50 | INFO | fairseq.trainer | begin training epoch 28
2023-07-17 20:49:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 20:50:10 | INFO | train_inner | epoch 028:     18 / 1474 loss=1.613, trans_loss=5.197, nll_loss=2.458, w2v_ctc_loss=0.489, task_loss=2.506, contrastive_loss=0.154, total=4106.72, n_correct=2726.73, ppl=5.49, accuracy=66.397, wps=3941.6, ups=0.96, wpb=4106.7, bsz=152.5, num_updates=39800, lr=7.08881e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=31492
2023-07-17 20:51:13 | INFO | train_inner | epoch 028:    118 / 1474 loss=1.617, trans_loss=5.183, nll_loss=2.438, w2v_ctc_loss=0.498, task_loss=2.736, contrastive_loss=0.146, total=4103.42, n_correct=2736.42, ppl=5.42, accuracy=66.686, wps=6533.3, ups=1.59, wpb=4103.4, bsz=146, num_updates=39900, lr=7.07992e-05, gnorm=0.434, clip=0, loss_scale=32, train_wall=62, gb_free=16.3, wall=31555
2023-07-17 20:52:16 | INFO | train_inner | epoch 028:    218 / 1474 loss=1.604, trans_loss=5.174, nll_loss=2.426, w2v_ctc_loss=0.485, task_loss=2.439, contrastive_loss=0.163, total=4200.12, n_correct=2809.59, ppl=5.38, accuracy=66.893, wps=6647, ups=1.58, wpb=4200.1, bsz=158.9, num_updates=40000, lr=7.07107e-05, gnorm=0.415, clip=0, loss_scale=64, train_wall=63, gb_free=11.5, wall=31618
2023-07-17 20:52:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 20:52:40 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.683 | trans_loss 5.55 | nll_loss 2.82 | w2v_ctc_loss 1.159 | task_loss 4.309 | contrastive_loss 0.269 | total 4003.4 | n_correct 2494.2 | ppl 7.06 | accuracy 62.302 | uer 16.885 | wer 18.623 | raw_wer 18.623 | bleu 20.22 | wps 2294.9 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.49
2023-07-17 20:52:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-17 20:52:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_28_40000.pt
2023-07-17 20:52:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_28_40000.pt
2023-07-17 20:52:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.22) (writing took 6.344567007035948 seconds)
mt_weight tensor(0.0177, device='cuda:0')
asr_weight tensor(0.0013, device='cuda:0')
2023-07-17 20:53:51 | INFO | train_inner | epoch 028:    318 / 1474 loss=1.628, trans_loss=5.194, nll_loss=2.453, w2v_ctc_loss=0.483, task_loss=2.595, contrastive_loss=0.817, total=4147.36, n_correct=2755.35, ppl=5.48, accuracy=66.436, wps=4367.5, ups=1.05, wpb=4147.4, bsz=157.7, num_updates=40100, lr=7.06225e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=31713
2023-07-17 20:54:54 | INFO | train_inner | epoch 028:    418 / 1474 loss=1.614, trans_loss=5.193, nll_loss=2.451, w2v_ctc_loss=0.497, task_loss=2.69, contrastive_loss=0.137, total=4087.34, n_correct=2718.62, ppl=5.47, accuracy=66.513, wps=6504.5, ups=1.59, wpb=4087.3, bsz=147.6, num_updates=40200, lr=7.05346e-05, gnorm=0.429, clip=0, loss_scale=64, train_wall=62, gb_free=17, wall=31776
2023-07-17 20:55:57 | INFO | train_inner | epoch 028:    518 / 1474 loss=1.617, trans_loss=5.192, nll_loss=2.449, w2v_ctc_loss=0.493, task_loss=2.698, contrastive_loss=0.163, total=4099.71, n_correct=2723.96, ppl=5.46, accuracy=66.443, wps=6486, ups=1.58, wpb=4099.7, bsz=148.1, num_updates=40300, lr=7.0447e-05, gnorm=0.416, clip=0, loss_scale=64, train_wall=63, gb_free=15.5, wall=31839
2023-07-17 20:57:00 | INFO | train_inner | epoch 028:    618 / 1474 loss=1.616, trans_loss=5.2, nll_loss=2.46, w2v_ctc_loss=0.492, task_loss=2.639, contrastive_loss=0.161, total=4177.06, n_correct=2772.57, ppl=5.5, accuracy=66.376, wps=6590.4, ups=1.58, wpb=4177.1, bsz=152, num_updates=40400, lr=7.03598e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=17.4, wall=31902
2023-07-17 20:58:03 | INFO | train_inner | epoch 028:    718 / 1474 loss=1.614, trans_loss=5.196, nll_loss=2.456, w2v_ctc_loss=0.486, task_loss=2.337, contrastive_loss=0.381, total=4190.74, n_correct=2783.06, ppl=5.49, accuracy=66.41, wps=6648, ups=1.59, wpb=4190.7, bsz=164.2, num_updates=40500, lr=7.02728e-05, gnorm=0.428, clip=0, loss_scale=64, train_wall=63, gb_free=15.7, wall=31965
2023-07-17 20:59:06 | INFO | train_inner | epoch 028:    818 / 1474 loss=1.615, trans_loss=5.192, nll_loss=2.45, w2v_ctc_loss=0.488, task_loss=2.56, contrastive_loss=0.146, total=4091.75, n_correct=2723.51, ppl=5.46, accuracy=66.561, wps=6525.5, ups=1.59, wpb=4091.8, bsz=153, num_updates=40600, lr=7.01862e-05, gnorm=0.419, clip=0, loss_scale=64, train_wall=62, gb_free=16.7, wall=32028
2023-07-17 20:59:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-17 21:00:10 | INFO | train_inner | epoch 028:    919 / 1474 loss=1.615, trans_loss=5.21, nll_loss=2.473, w2v_ctc_loss=0.493, task_loss=2.695, contrastive_loss=0.274, total=4114.64, n_correct=2723.58, ppl=5.55, accuracy=66.192, wps=6393.2, ups=1.55, wpb=4114.6, bsz=149.7, num_updates=40700, lr=7.01e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=64, gb_free=17.5, wall=32092
2023-07-17 21:01:14 | INFO | train_inner | epoch 028:   1019 / 1474 loss=1.621, trans_loss=5.206, nll_loss=2.469, w2v_ctc_loss=0.495, task_loss=2.537, contrastive_loss=0.374, total=4177.86, n_correct=2767.39, ppl=5.53, accuracy=66.239, wps=6602, ups=1.58, wpb=4177.9, bsz=155.5, num_updates=40800, lr=7.0014e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=32156
2023-07-17 21:02:18 | INFO | train_inner | epoch 028:   1119 / 1474 loss=1.607, trans_loss=5.19, nll_loss=2.448, w2v_ctc_loss=0.489, task_loss=2.519, contrastive_loss=0.191, total=4210.86, n_correct=2801.04, ppl=5.46, accuracy=66.519, wps=6584.1, ups=1.56, wpb=4210.9, bsz=159.4, num_updates=40900, lr=6.99284e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=64, gb_free=17.6, wall=32220
2023-07-17 21:03:20 | INFO | train_inner | epoch 028:   1219 / 1474 loss=1.604, trans_loss=5.198, nll_loss=2.459, w2v_ctc_loss=0.485, task_loss=2.565, contrastive_loss=0.16, total=4104.61, n_correct=2725.99, ppl=5.5, accuracy=66.413, wps=6547.6, ups=1.6, wpb=4104.6, bsz=152.8, num_updates=41000, lr=6.9843e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=62, gb_free=16.7, wall=32282
2023-07-17 21:04:24 | INFO | train_inner | epoch 028:   1319 / 1474 loss=1.632, trans_loss=5.215, nll_loss=2.479, w2v_ctc_loss=0.507, task_loss=2.849, contrastive_loss=0.19, total=4087.78, n_correct=2704.43, ppl=5.57, accuracy=66.159, wps=6416.5, ups=1.57, wpb=4087.8, bsz=142.6, num_updates=41100, lr=6.9758e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=63, gb_free=15.2, wall=32346
2023-07-17 21:05:27 | INFO | train_inner | epoch 028:   1419 / 1474 loss=1.623, trans_loss=5.211, nll_loss=2.474, w2v_ctc_loss=0.497, task_loss=2.728, contrastive_loss=0.233, total=4145.03, n_correct=2745.03, ppl=5.56, accuracy=66.225, wps=6546.3, ups=1.58, wpb=4145, bsz=148.8, num_updates=41200, lr=6.96733e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=17.8, wall=32409
2023-07-17 21:06:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.0177, device='cuda:5')
asr_weight tensor(0.0013, device='cuda:5')
mt_weight tensor(0.0177, device='cuda:2')
asr_weight tensor(0.0013, device='cuda:2')
mt_weight tensor(0.0177, device='cuda:6')
asr_weight tensor(0.0013, device='cuda:6')
mt_weight tensor(0.0177, device='cuda:1')
asr_weight tensor(0.0013, device='cuda:1')
mt_weight tensor(0.0177, device='cuda:7')
asr_weight tensor(0.0013, device='cuda:7')
mt_weight tensor(0.0177, device='cuda:3')
asr_weight tensor(0.0013, device='cuda:3')
mt_weight tensor(0.0177, device='cuda:4')
asr_weight tensor(0.0013, device='cuda:4')
2023-07-17 21:06:27 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.683 | trans_loss 5.543 | nll_loss 2.814 | w2v_ctc_loss 1.158 | task_loss 4.281 | contrastive_loss 0.279 | total 4003.4 | n_correct 2490.2 | ppl 7.03 | accuracy 62.202 | uer 16.802 | wer 18.5 | raw_wer 18.5 | bleu 20.09 | wps 2172.5 | wpb 4003.4 | bsz 141.8 | num_updates 41255 | best_bleu 20.49
2023-07-17 21:06:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41255 updates
2023-07-17 21:06:27 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.0909.pt
2023-07-17 21:06:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.0909.pt
2023-07-17 21:06:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.0909.pt (epoch 28 @ 41255 updates, score 20.09) (writing took 5.545944532961585 seconds)
2023-07-17 21:06:33 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-17 21:06:33 | INFO | train | epoch 028 | loss 1.616 | trans_loss 5.196 | nll_loss 2.455 | w2v_ctc_loss 0.492 | task_loss 2.601 | contrastive_loss 0.251 | total 4138.29 | n_correct 2749.56 | ppl 5.48 | accuracy 66.442 | wps 6076.9 | ups 1.47 | wpb 4138.3 | bsz 152.8 | num_updates 41255 | lr 6.96268e-05 | gnorm 0.424 | clip 0 | loss_scale 32 | train_wall 926 | gb_free 16.7 | wall 32475
2023-07-17 21:06:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 21:06:33 | INFO | fairseq.trainer | begin training epoch 29
2023-07-17 21:06:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 21:06:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-17 21:07:11 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.605, trans_loss=5.179, nll_loss=2.435, w2v_ctc_loss=0.491, task_loss=2.513, contrastive_loss=0.177, total=4160.3, n_correct=2775.12, ppl=5.41, accuracy=66.705, wps=4020.5, ups=0.97, wpb=4160.3, bsz=157.1, num_updates=41300, lr=6.95889e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=64, gb_free=16.6, wall=32513
2023-07-17 21:08:14 | INFO | train_inner | epoch 029:    146 / 1474 loss=1.61, trans_loss=5.173, nll_loss=2.424, w2v_ctc_loss=0.487, task_loss=2.586, contrastive_loss=0.219, total=4105.72, n_correct=2745.52, ppl=5.37, accuracy=66.871, wps=6511.9, ups=1.59, wpb=4105.7, bsz=152, num_updates=41400, lr=6.95048e-05, gnorm=0.436, clip=0, loss_scale=16, train_wall=63, gb_free=16.2, wall=32576
2023-07-17 21:09:18 | INFO | train_inner | epoch 029:    246 / 1474 loss=1.596, trans_loss=5.174, nll_loss=2.428, w2v_ctc_loss=0.476, task_loss=2.38, contrastive_loss=0.387, total=4199.67, n_correct=2804.07, ppl=5.38, accuracy=66.769, wps=6574.8, ups=1.57, wpb=4199.7, bsz=165.3, num_updates=41500, lr=6.9421e-05, gnorm=0.416, clip=0, loss_scale=16, train_wall=63, gb_free=15.9, wall=32640
2023-07-17 21:10:21 | INFO | train_inner | epoch 029:    346 / 1474 loss=1.624, trans_loss=5.194, nll_loss=2.452, w2v_ctc_loss=0.504, task_loss=2.789, contrastive_loss=0.151, total=4095.17, n_correct=2725.49, ppl=5.47, accuracy=66.554, wps=6453.5, ups=1.58, wpb=4095.2, bsz=145.6, num_updates=41600, lr=6.93375e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=63, gb_free=16.8, wall=32703
2023-07-17 21:11:24 | INFO | train_inner | epoch 029:    446 / 1474 loss=1.597, trans_loss=5.159, nll_loss=2.406, w2v_ctc_loss=0.48, task_loss=2.505, contrastive_loss=0.138, total=4157.44, n_correct=2790.25, ppl=5.3, accuracy=67.115, wps=6609.4, ups=1.59, wpb=4157.4, bsz=153.9, num_updates=41700, lr=6.92543e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=62, gb_free=16.7, wall=32766
2023-07-17 21:12:28 | INFO | train_inner | epoch 029:    546 / 1474 loss=1.632, trans_loss=5.204, nll_loss=2.465, w2v_ctc_loss=0.498, task_loss=2.767, contrastive_loss=0.331, total=4150.87, n_correct=2751.96, ppl=5.52, accuracy=66.298, wps=6523.1, ups=1.57, wpb=4150.9, bsz=147.5, num_updates=41800, lr=6.91714e-05, gnorm=0.434, clip=0, loss_scale=16, train_wall=63, gb_free=16, wall=32830
2023-07-17 21:13:31 | INFO | train_inner | epoch 029:    646 / 1474 loss=1.609, trans_loss=5.182, nll_loss=2.439, w2v_ctc_loss=0.488, task_loss=2.456, contrastive_loss=0.471, total=4143.02, n_correct=2762, ppl=5.42, accuracy=66.666, wps=6580.1, ups=1.59, wpb=4143, bsz=159.3, num_updates=41900, lr=6.90889e-05, gnorm=0.422, clip=0, loss_scale=16, train_wall=63, gb_free=17.2, wall=32893
2023-07-17 21:14:34 | INFO | train_inner | epoch 029:    746 / 1474 loss=1.603, trans_loss=5.179, nll_loss=2.433, w2v_ctc_loss=0.481, task_loss=2.397, contrastive_loss=0.309, total=4249.79, n_correct=2836.92, ppl=5.4, accuracy=66.754, wps=6666.4, ups=1.57, wpb=4249.8, bsz=165, num_updates=42000, lr=6.90066e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=63, gb_free=16.9, wall=32956
2023-07-17 21:14:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 21:15:00 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.693 | trans_loss 5.539 | nll_loss 2.805 | w2v_ctc_loss 1.19 | task_loss 4.274 | contrastive_loss 0.279 | total 4003.4 | n_correct 2489.3 | ppl 6.99 | accuracy 62.18 | uer 16.696 | wer 18.474 | raw_wer 18.474 | bleu 19.95 | wps 1942.6 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.49
2023-07-17 21:15:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-17 21:15:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_29_42000.pt
2023-07-17 21:15:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_29_42000.pt
2023-07-17 21:15:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 19.95) (writing took 5.173708623973653 seconds)
2023-07-17 21:16:09 | INFO | train_inner | epoch 029:    846 / 1474 loss=1.624, trans_loss=5.202, nll_loss=2.463, w2v_ctc_loss=0.494, task_loss=2.896, contrastive_loss=0.138, total=4027.19, n_correct=2669.06, ppl=5.51, accuracy=66.276, wps=4252.2, ups=1.06, wpb=4027.2, bsz=140.3, num_updates=42100, lr=6.89246e-05, gnorm=0.441, clip=0, loss_scale=16, train_wall=63, gb_free=17.4, wall=33051
2023-07-17 21:17:12 | INFO | train_inner | epoch 029:    946 / 1474 loss=1.615, trans_loss=5.195, nll_loss=2.453, w2v_ctc_loss=0.494, task_loss=2.648, contrastive_loss=0.157, total=4082.14, n_correct=2711.32, ppl=5.48, accuracy=66.419, wps=6527.1, ups=1.6, wpb=4082.1, bsz=148.2, num_updates=42200, lr=6.88428e-05, gnorm=0.439, clip=0, loss_scale=16, train_wall=62, gb_free=15.6, wall=33114
2023-07-17 21:18:15 | INFO | train_inner | epoch 029:   1046 / 1474 loss=1.609, trans_loss=5.185, nll_loss=2.441, w2v_ctc_loss=0.484, task_loss=2.591, contrastive_loss=0.306, total=4148.18, n_correct=2763.03, ppl=5.43, accuracy=66.608, wps=6576.5, ups=1.59, wpb=4148.2, bsz=154.1, num_updates=42300, lr=6.87614e-05, gnorm=0.425, clip=0, loss_scale=16, train_wall=63, gb_free=16.1, wall=33177
2023-07-17 21:19:18 | INFO | train_inner | epoch 029:   1146 / 1474 loss=1.616, trans_loss=5.2, nll_loss=2.46, w2v_ctc_loss=0.496, task_loss=2.847, contrastive_loss=0.128, total=4063.95, n_correct=2694.81, ppl=5.5, accuracy=66.31, wps=6420.2, ups=1.58, wpb=4064, bsz=141.5, num_updates=42400, lr=6.86803e-05, gnorm=0.428, clip=0, loss_scale=16, train_wall=63, gb_free=13.6, wall=33240
2023-07-17 21:20:22 | INFO | train_inner | epoch 029:   1246 / 1474 loss=1.615, trans_loss=5.199, nll_loss=2.46, w2v_ctc_loss=0.496, task_loss=2.642, contrastive_loss=0.146, total=4158.81, n_correct=2763.8, ppl=5.5, accuracy=66.457, wps=6553.8, ups=1.58, wpb=4158.8, bsz=150.6, num_updates=42500, lr=6.85994e-05, gnorm=0.417, clip=0, loss_scale=16, train_wall=63, gb_free=15.9, wall=33303
2023-07-17 21:21:25 | INFO | train_inner | epoch 029:   1346 / 1474 loss=1.612, trans_loss=5.189, nll_loss=2.447, w2v_ctc_loss=0.485, task_loss=2.554, contrastive_loss=0.278, total=4166.34, n_correct=2773.08, ppl=5.45, accuracy=66.559, wps=6572, ups=1.58, wpb=4166.3, bsz=155.3, num_updates=42600, lr=6.85189e-05, gnorm=0.43, clip=0, loss_scale=16, train_wall=63, gb_free=17.9, wall=33367
2023-07-17 21:22:29 | INFO | train_inner | epoch 029:   1446 / 1474 loss=1.621, trans_loss=5.188, nll_loss=2.446, w2v_ctc_loss=0.486, task_loss=2.548, contrastive_loss=0.335, total=4162.2, n_correct=2769.16, ppl=5.45, accuracy=66.531, wps=6530.3, ups=1.57, wpb=4162.2, bsz=155.8, num_updates=42700, lr=6.84386e-05, gnorm=0.424, clip=0, loss_scale=16, train_wall=63, gb_free=17.5, wall=33431
2023-07-17 21:22:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 21:23:11 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.668 | trans_loss 5.542 | nll_loss 2.811 | w2v_ctc_loss 1.134 | task_loss 4.33 | contrastive_loss 0.274 | total 4003.4 | n_correct 2495.6 | ppl 7.02 | accuracy 62.337 | uer 16.71 | wer 18.5 | raw_wer 18.5 | bleu 20.49 | wps 2149.9 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 20.49
2023-07-17 21:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-07-17 21:23:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 21:23:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 21:23:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 29 @ 42728 updates, score 20.49) (writing took 8.51545675296802 seconds)
2023-07-17 21:23:20 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-17 21:23:20 | INFO | train | epoch 029 | loss 1.612 | trans_loss 5.187 | nll_loss 2.443 | w2v_ctc_loss 0.489 | task_loss 2.602 | contrastive_loss 0.249 | total 4137.82 | n_correct 2755.69 | ppl 5.44 | accuracy 66.598 | wps 6051.2 | ups 1.46 | wpb 4137.8 | bsz 152.7 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.428 | clip 0 | loss_scale 16 | train_wall 927 | gb_free 16.4 | wall 33482
2023-07-17 21:23:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 21:23:21 | INFO | fairseq.trainer | begin training epoch 30
2023-07-17 21:23:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 21:24:14 | INFO | train_inner | epoch 030:     72 / 1474 loss=1.6, trans_loss=5.167, nll_loss=2.418, w2v_ctc_loss=0.474, task_loss=2.46, contrastive_loss=0.369, total=4182.65, n_correct=2800.68, ppl=5.35, accuracy=66.959, wps=3965.3, ups=0.95, wpb=4182.6, bsz=160.2, num_updates=42800, lr=6.83586e-05, gnorm=0.425, clip=0, loss_scale=16, train_wall=63, gb_free=13.8, wall=33536
2023-07-17 21:25:17 | INFO | train_inner | epoch 030:    172 / 1474 loss=1.593, trans_loss=5.149, nll_loss=2.394, w2v_ctc_loss=0.482, task_loss=2.436, contrastive_loss=0.231, total=4203.05, n_correct=2829.43, ppl=5.26, accuracy=67.318, wps=6661.5, ups=1.58, wpb=4203.1, bsz=159.2, num_updates=42900, lr=6.82789e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=63, gb_free=17.5, wall=33599
2023-07-17 21:26:20 | INFO | train_inner | epoch 030:    272 / 1474 loss=1.609, trans_loss=5.166, nll_loss=2.416, w2v_ctc_loss=0.491, task_loss=2.678, contrastive_loss=0.136, total=4116.93, n_correct=2757.13, ppl=5.34, accuracy=66.971, wps=6528.3, ups=1.59, wpb=4116.9, bsz=147.6, num_updates=43000, lr=6.81994e-05, gnorm=0.418, clip=0, loss_scale=16, train_wall=63, gb_free=17.1, wall=33662
2023-07-17 21:27:24 | INFO | train_inner | epoch 030:    372 / 1474 loss=1.602, trans_loss=5.156, nll_loss=2.402, w2v_ctc_loss=0.479, task_loss=2.608, contrastive_loss=0.146, total=4173.13, n_correct=2802.27, ppl=5.29, accuracy=67.15, wps=6577.1, ups=1.58, wpb=4173.1, bsz=152.8, num_updates=43100, lr=6.81203e-05, gnorm=0.415, clip=0, loss_scale=16, train_wall=63, gb_free=12.2, wall=33726
2023-07-17 21:28:26 | INFO | train_inner | epoch 030:    472 / 1474 loss=1.599, trans_loss=5.165, nll_loss=2.415, w2v_ctc_loss=0.479, task_loss=2.472, contrastive_loss=0.268, total=4135.2, n_correct=2767.26, ppl=5.33, accuracy=66.92, wps=6601.3, ups=1.6, wpb=4135.2, bsz=157.4, num_updates=43200, lr=6.80414e-05, gnorm=0.426, clip=0, loss_scale=16, train_wall=62, gb_free=17, wall=33788
2023-07-17 21:29:30 | INFO | train_inner | epoch 030:    572 / 1474 loss=1.602, trans_loss=5.168, nll_loss=2.419, w2v_ctc_loss=0.478, task_loss=2.528, contrastive_loss=0.197, total=4168.65, n_correct=2792.67, ppl=5.35, accuracy=66.992, wps=6551.9, ups=1.57, wpb=4168.6, bsz=156.1, num_updates=43300, lr=6.79628e-05, gnorm=0.423, clip=0, loss_scale=16, train_wall=63, gb_free=16.1, wall=33852
2023-07-17 21:30:34 | INFO | train_inner | epoch 030:    672 / 1474 loss=1.602, trans_loss=5.172, nll_loss=2.425, w2v_ctc_loss=0.485, task_loss=2.566, contrastive_loss=0.224, total=4183.65, n_correct=2794.3, ppl=5.37, accuracy=66.791, wps=6517.4, ups=1.56, wpb=4183.6, bsz=157.3, num_updates=43400, lr=6.78844e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=64, gb_free=17, wall=33916
2023-07-17 21:31:37 | INFO | train_inner | epoch 030:    772 / 1474 loss=1.622, trans_loss=5.193, nll_loss=2.452, w2v_ctc_loss=0.494, task_loss=2.653, contrastive_loss=0.38, total=4106.9, n_correct=2730.9, ppl=5.47, accuracy=66.495, wps=6494.7, ups=1.58, wpb=4106.9, bsz=151.5, num_updates=43500, lr=6.78064e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=63, gb_free=12.3, wall=33979
2023-07-17 21:32:41 | INFO | train_inner | epoch 030:    872 / 1474 loss=1.614, trans_loss=5.183, nll_loss=2.437, w2v_ctc_loss=0.486, task_loss=2.718, contrastive_loss=0.146, total=4089.18, n_correct=2726.23, ppl=5.42, accuracy=66.669, wps=6467.7, ups=1.58, wpb=4089.2, bsz=145.7, num_updates=43600, lr=6.77285e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=34043
2023-07-17 21:33:44 | INFO | train_inner | epoch 030:    972 / 1474 loss=1.61, trans_loss=5.184, nll_loss=2.439, w2v_ctc_loss=0.491, task_loss=2.626, contrastive_loss=0.186, total=4140.03, n_correct=2757.73, ppl=5.42, accuracy=66.611, wps=6553.4, ups=1.58, wpb=4140, bsz=152, num_updates=43700, lr=6.7651e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=14.2, wall=34106
2023-07-17 21:34:48 | INFO | train_inner | epoch 030:   1072 / 1474 loss=1.629, trans_loss=5.197, nll_loss=2.455, w2v_ctc_loss=0.492, task_loss=2.915, contrastive_loss=0.318, total=4101.12, n_correct=2718.22, ppl=5.48, accuracy=66.28, wps=6404.5, ups=1.56, wpb=4101.1, bsz=141.4, num_updates=43800, lr=6.75737e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=64, gb_free=17, wall=34170
2023-07-17 21:35:52 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.608, trans_loss=5.179, nll_loss=2.435, w2v_ctc_loss=0.482, task_loss=2.494, contrastive_loss=0.291, total=4168.22, n_correct=2782.13, ppl=5.41, accuracy=66.746, wps=6552.9, ups=1.57, wpb=4168.2, bsz=157.3, num_updates=43900, lr=6.74967e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=34233
2023-07-17 21:36:55 | INFO | train_inner | epoch 030:   1272 / 1474 loss=1.622, trans_loss=5.192, nll_loss=2.45, w2v_ctc_loss=0.496, task_loss=2.918, contrastive_loss=0.152, total=4032.74, n_correct=2680.39, ppl=5.46, accuracy=66.466, wps=6327.6, ups=1.57, wpb=4032.7, bsz=140.9, num_updates=44000, lr=6.742e-05, gnorm=0.455, clip=0, loss_scale=32, train_wall=63, gb_free=17, wall=34297
2023-07-17 21:36:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 21:37:20 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.673 | trans_loss 5.534 | nll_loss 2.8 | w2v_ctc_loss 1.159 | task_loss 4.33 | contrastive_loss 0.27 | total 4003.4 | n_correct 2499.6 | ppl 6.96 | accuracy 62.437 | uer 16.606 | wer 18.217 | raw_wer 18.217 | bleu 20.25 | wps 2238.2 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.49
2023-07-17 21:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-17 21:37:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_30_44000.pt
2023-07-17 21:37:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_30_44000.pt
2023-07-17 21:37:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.25) (writing took 6.435587354004383 seconds)
2023-07-17 21:38:30 | INFO | train_inner | epoch 030:   1372 / 1474 loss=1.588, trans_loss=5.176, nll_loss=2.432, w2v_ctc_loss=0.479, task_loss=2.45, contrastive_loss=0.178, total=4166.96, n_correct=2783.42, ppl=5.39, accuracy=66.797, wps=4415.7, ups=1.06, wpb=4167, bsz=161.1, num_updates=44100, lr=6.73435e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=34392
2023-07-17 21:39:33 | INFO | train_inner | epoch 030:   1472 / 1474 loss=1.61, trans_loss=5.182, nll_loss=2.439, w2v_ctc_loss=0.476, task_loss=2.488, contrastive_loss=0.464, total=4125.17, n_correct=2749.3, ppl=5.42, accuracy=66.647, wps=6558.2, ups=1.59, wpb=4125.2, bsz=155, num_updates=44200, lr=6.72673e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=62, gb_free=17.2, wall=34454
2023-07-17 21:39:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 21:40:00 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.678 | trans_loss 5.54 | nll_loss 2.809 | w2v_ctc_loss 1.149 | task_loss 4.288 | contrastive_loss 0.273 | total 4003.4 | n_correct 2501.9 | ppl 7.01 | accuracy 62.494 | uer 16.641 | wer 18.396 | raw_wer 18.396 | bleu 20.7 | wps 1968.3 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 20.7
2023-07-17 21:40:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-07-17 21:40:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 21:40:04 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 21:40:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 30 @ 44202 updates, score 20.7) (writing took 8.414855552953668 seconds)
2023-07-17 21:40:09 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-17 21:40:09 | INFO | train | epoch 030 | loss 1.607 | trans_loss 5.175 | nll_loss 2.428 | w2v_ctc_loss 0.484 | task_loss 2.599 | contrastive_loss 0.248 | total 4138.65 | n_correct 2764.37 | ppl 5.38 | accuracy 66.794 | wps 6047.9 | ups 1.46 | wpb 4138.6 | bsz 152.8 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.426 | clip 0 | loss_scale 32 | train_wall 928 | gb_free 17.3 | wall 34491
2023-07-17 21:40:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 21:40:09 | INFO | fairseq.trainer | begin training epoch 31
2023-07-17 21:40:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 21:41:19 | INFO | train_inner | epoch 031:     98 / 1474 loss=1.606, trans_loss=5.159, nll_loss=2.406, w2v_ctc_loss=0.486, task_loss=2.694, contrastive_loss=0.15, total=4081.34, n_correct=2737.21, ppl=5.3, accuracy=67.066, wps=3830.9, ups=0.94, wpb=4081.3, bsz=147.3, num_updates=44300, lr=6.71913e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=34561
2023-07-17 21:42:23 | INFO | train_inner | epoch 031:    198 / 1474 loss=1.604, trans_loss=5.158, nll_loss=2.405, w2v_ctc_loss=0.481, task_loss=2.65, contrastive_loss=0.198, total=4146.03, n_correct=2780.44, ppl=5.3, accuracy=67.063, wps=6464.9, ups=1.56, wpb=4146, bsz=151.1, num_updates=44400, lr=6.71156e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=64, gb_free=13.7, wall=34625
2023-07-17 21:43:27 | INFO | train_inner | epoch 031:    298 / 1474 loss=1.605, trans_loss=5.163, nll_loss=2.411, w2v_ctc_loss=0.484, task_loss=2.667, contrastive_loss=0.272, total=4146.75, n_correct=2778.53, ppl=5.32, accuracy=67.005, wps=6503.9, ups=1.57, wpb=4146.8, bsz=150.4, num_updates=44500, lr=6.70402e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=17.7, wall=34689
2023-07-17 21:44:30 | INFO | train_inner | epoch 031:    398 / 1474 loss=1.608, trans_loss=5.165, nll_loss=2.414, w2v_ctc_loss=0.483, task_loss=2.841, contrastive_loss=0.148, total=4089.43, n_correct=2737.57, ppl=5.33, accuracy=66.943, wps=6461.5, ups=1.58, wpb=4089.4, bsz=142.8, num_updates=44600, lr=6.6965e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=34752
2023-07-17 21:45:34 | INFO | train_inner | epoch 031:    498 / 1474 loss=1.604, trans_loss=5.156, nll_loss=2.404, w2v_ctc_loss=0.483, task_loss=2.709, contrastive_loss=0.169, total=4114.41, n_correct=2761.55, ppl=5.29, accuracy=67.119, wps=6487.4, ups=1.58, wpb=4114.4, bsz=150.4, num_updates=44700, lr=6.689e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=34816
2023-07-17 21:46:37 | INFO | train_inner | epoch 031:    598 / 1474 loss=1.604, trans_loss=5.168, nll_loss=2.419, w2v_ctc_loss=0.483, task_loss=2.716, contrastive_loss=0.154, total=4084.36, n_correct=2733.97, ppl=5.35, accuracy=66.938, wps=6435.4, ups=1.58, wpb=4084.4, bsz=147.5, num_updates=44800, lr=6.68153e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=34879
2023-07-17 21:47:40 | INFO | train_inner | epoch 031:    698 / 1474 loss=1.594, trans_loss=5.155, nll_loss=2.402, w2v_ctc_loss=0.474, task_loss=2.481, contrastive_loss=0.154, total=4210.09, n_correct=2825.55, ppl=5.29, accuracy=67.114, wps=6699.8, ups=1.59, wpb=4210.1, bsz=157.4, num_updates=44900, lr=6.67409e-05, gnorm=0.416, clip=0, loss_scale=32, train_wall=62, gb_free=15, wall=34942
2023-07-17 21:48:44 | INFO | train_inner | epoch 031:    798 / 1474 loss=1.598, trans_loss=5.171, nll_loss=2.423, w2v_ctc_loss=0.477, task_loss=2.736, contrastive_loss=0.29, total=4098.1, n_correct=2739.94, ppl=5.36, accuracy=66.859, wps=6426.7, ups=1.57, wpb=4098.1, bsz=147.8, num_updates=45000, lr=6.66667e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=63, gb_free=17.2, wall=35006
mt_weight tensor(0.0177, device='cuda:0')
asr_weight tensor(0.0013, device='cuda:0')
2023-07-17 21:49:47 | INFO | train_inner | epoch 031:    898 / 1474 loss=1.604, trans_loss=5.165, nll_loss=2.415, w2v_ctc_loss=0.48, task_loss=2.704, contrastive_loss=0.179, total=4101.05, n_correct=2744.98, ppl=5.33, accuracy=66.934, wps=6503.3, ups=1.59, wpb=4101.1, bsz=148.4, num_updates=45100, lr=6.65927e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=35069
2023-07-17 21:50:50 | INFO | train_inner | epoch 031:    998 / 1474 loss=1.608, trans_loss=5.17, nll_loss=2.423, w2v_ctc_loss=0.477, task_loss=2.449, contrastive_loss=0.346, total=4186.3, n_correct=2800.8, ppl=5.36, accuracy=66.904, wps=6638.2, ups=1.59, wpb=4186.3, bsz=159.3, num_updates=45200, lr=6.6519e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=35132
2023-07-17 21:51:53 | INFO | train_inner | epoch 031:   1098 / 1474 loss=1.601, trans_loss=5.17, nll_loss=2.424, w2v_ctc_loss=0.48, task_loss=2.554, contrastive_loss=0.242, total=4147.34, n_correct=2775.64, ppl=5.36, accuracy=66.926, wps=6549, ups=1.58, wpb=4147.3, bsz=157.3, num_updates=45300, lr=6.64455e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=63, gb_free=17.3, wall=35195
2023-07-17 21:52:56 | INFO | train_inner | epoch 031:   1198 / 1474 loss=1.615, trans_loss=5.175, nll_loss=2.431, w2v_ctc_loss=0.484, task_loss=2.416, contrastive_loss=0.472, total=4185.34, n_correct=2796.04, ppl=5.39, accuracy=66.806, wps=6661.3, ups=1.59, wpb=4185.3, bsz=160.8, num_updates=45400, lr=6.63723e-05, gnorm=0.428, clip=0, loss_scale=64, train_wall=62, gb_free=17.2, wall=35258
2023-07-17 21:53:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-17 21:54:00 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.597, trans_loss=5.167, nll_loss=2.419, w2v_ctc_loss=0.478, task_loss=2.349, contrastive_loss=0.153, total=4224.25, n_correct=2827.23, ppl=5.35, accuracy=66.929, wps=6651.1, ups=1.57, wpb=4224.2, bsz=161.8, num_updates=45500, lr=6.62994e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=35322
2023-07-17 21:55:03 | INFO | train_inner | epoch 031:   1399 / 1474 loss=1.606, trans_loss=5.18, nll_loss=2.436, w2v_ctc_loss=0.479, task_loss=2.381, contrastive_loss=0.572, total=4186.05, n_correct=2793.02, ppl=5.41, accuracy=66.722, wps=6570.3, ups=1.57, wpb=4186.1, bsz=163.3, num_updates=45600, lr=6.62266e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=17.6, wall=35385
2023-07-17 21:55:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.0177, device='cuda:7')
asr_weight tensor(0.0013, device='cuda:7')
mt_weight tensor(0.0177, device='cuda:4')
asr_weight tensor(0.0013, device='cuda:4')
mt_weight tensor(0.0177, device='cuda:3')
asr_weight tensor(0.0013, device='cuda:3')
mt_weight tensor(0.0177, device='cuda:2')
asr_weight tensor(0.0013, device='cuda:2')
mt_weight tensor(0.0177, device='cuda:6')
asr_weight tensor(0.0013, device='cuda:6')
mt_weight tensor(0.0177, device='cuda:5')
asr_weight tensor(0.0013, device='cuda:5')
mt_weight tensor(0.0177, device='cuda:1')
asr_weight tensor(0.0013, device='cuda:1')
2023-07-17 21:56:16 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.676 | trans_loss 5.536 | nll_loss 2.804 | w2v_ctc_loss 1.171 | task_loss 4.316 | contrastive_loss 0.277 | total 4003.4 | n_correct 2503.4 | ppl 6.99 | accuracy 62.532 | uer 16.54 | wer 18.362 | raw_wer 18.362 | bleu 20.84 | wps 2145.9 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 20.84
2023-07-17 21:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-07-17 21:56:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 21:56:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt
2023-07-17 21:56:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_best.pt (epoch 31 @ 45675 updates, score 20.84) (writing took 8.268163016997278 seconds)
2023-07-17 21:56:25 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-17 21:56:25 | INFO | train | epoch 031 | loss 1.604 | trans_loss 5.166 | nll_loss 2.417 | w2v_ctc_loss 0.481 | task_loss 2.599 | contrastive_loss 0.247 | total 4138.25 | n_correct 2770.29 | ppl 5.34 | accuracy 66.943 | wps 6248 | ups 1.51 | wpb 4138.3 | bsz 152.8 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.426 | clip 0 | loss_scale 32 | train_wall 927 | gb_free 12.5 | wall 35467
2023-07-17 21:56:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 21:56:25 | INFO | fairseq.trainer | begin training epoch 32
2023-07-17 21:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 21:56:48 | INFO | train_inner | epoch 032:     25 / 1474 loss=1.603, trans_loss=5.161, nll_loss=2.41, w2v_ctc_loss=0.479, task_loss=2.743, contrastive_loss=0.137, total=4042.6, n_correct=2709.78, ppl=5.32, accuracy=67.031, wps=3843.1, ups=0.95, wpb=4042.6, bsz=144.4, num_updates=45700, lr=6.61541e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=62, gb_free=16.5, wall=35490
2023-07-17 21:57:52 | INFO | train_inner | epoch 032:    125 / 1474 loss=1.576, trans_loss=5.117, nll_loss=2.354, w2v_ctc_loss=0.458, task_loss=2.404, contrastive_loss=0.165, total=4227.68, n_correct=2861.93, ppl=5.11, accuracy=67.695, wps=6635.9, ups=1.57, wpb=4227.7, bsz=161.6, num_updates=45800, lr=6.60819e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=35554
2023-07-17 21:58:56 | INFO | train_inner | epoch 032:    225 / 1474 loss=1.584, trans_loss=5.143, nll_loss=2.387, w2v_ctc_loss=0.472, task_loss=2.473, contrastive_loss=0.184, total=4157.32, n_correct=2796.87, ppl=5.23, accuracy=67.276, wps=6549.7, ups=1.58, wpb=4157.3, bsz=160.3, num_updates=45900, lr=6.60098e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=63, gb_free=17.3, wall=35618
2023-07-17 21:59:58 | INFO | train_inner | epoch 032:    325 / 1474 loss=1.583, trans_loss=5.134, nll_loss=2.374, w2v_ctc_loss=0.467, task_loss=2.448, contrastive_loss=0.17, total=4183.45, n_correct=2821.73, ppl=5.18, accuracy=67.45, wps=6667.9, ups=1.59, wpb=4183.4, bsz=157.2, num_updates=46000, lr=6.5938e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=62, gb_free=17.7, wall=35680
2023-07-17 21:59:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 22:00:23 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.685 | trans_loss 5.54 | nll_loss 2.809 | w2v_ctc_loss 1.181 | task_loss 4.295 | contrastive_loss 0.277 | total 4003.4 | n_correct 2500 | ppl 7.01 | accuracy 62.447 | uer 16.625 | wer 18.411 | raw_wer 18.411 | bleu 20.43 | wps 2239.5 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.84
2023-07-17 22:00:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-17 22:00:23 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_32_46000.pt
2023-07-17 22:00:25 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_32_46000.pt
2023-07-17 22:00:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.43) (writing took 6.1872062149923295 seconds)
2023-07-17 22:01:33 | INFO | train_inner | epoch 032:    425 / 1474 loss=1.595, trans_loss=5.144, nll_loss=2.388, w2v_ctc_loss=0.474, task_loss=2.579, contrastive_loss=0.159, total=4157.28, n_correct=2798.8, ppl=5.24, accuracy=67.323, wps=4408.9, ups=1.06, wpb=4157.3, bsz=152.9, num_updates=46100, lr=6.58665e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=15.1, wall=35775
2023-07-17 22:02:37 | INFO | train_inner | epoch 032:    525 / 1474 loss=1.602, trans_loss=5.155, nll_loss=2.403, w2v_ctc_loss=0.478, task_loss=2.517, contrastive_loss=0.329, total=4198.93, n_correct=2822.01, ppl=5.29, accuracy=67.208, wps=6565.8, ups=1.56, wpb=4198.9, bsz=158.8, num_updates=46200, lr=6.57952e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=64, gb_free=17.4, wall=35839
2023-07-17 22:03:41 | INFO | train_inner | epoch 032:    625 / 1474 loss=1.603, trans_loss=5.16, nll_loss=2.409, w2v_ctc_loss=0.482, task_loss=2.683, contrastive_loss=0.177, total=4142.69, n_correct=2774.03, ppl=5.31, accuracy=66.962, wps=6481.8, ups=1.56, wpb=4142.7, bsz=150.8, num_updates=46300, lr=6.57241e-05, gnorm=0.437, clip=0, loss_scale=32, train_wall=64, gb_free=17.5, wall=35903
2023-07-17 22:04:44 | INFO | train_inner | epoch 032:    725 / 1474 loss=1.605, trans_loss=5.16, nll_loss=2.409, w2v_ctc_loss=0.486, task_loss=2.65, contrastive_loss=0.146, total=4154.59, n_correct=2783.13, ppl=5.31, accuracy=66.989, wps=6503, ups=1.57, wpb=4154.6, bsz=150.9, num_updates=46400, lr=6.56532e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=63, gb_free=16.2, wall=35966
2023-07-17 22:05:48 | INFO | train_inner | epoch 032:    825 / 1474 loss=1.596, trans_loss=5.152, nll_loss=2.398, w2v_ctc_loss=0.473, task_loss=2.689, contrastive_loss=0.141, total=4114.54, n_correct=2763.11, ppl=5.27, accuracy=67.155, wps=6514, ups=1.58, wpb=4114.5, bsz=147.4, num_updates=46500, lr=6.55826e-05, gnorm=0.434, clip=0, loss_scale=32, train_wall=63, gb_free=17.3, wall=36030
2023-07-17 22:06:51 | INFO | train_inner | epoch 032:    925 / 1474 loss=1.602, trans_loss=5.161, nll_loss=2.41, w2v_ctc_loss=0.476, task_loss=2.69, contrastive_loss=0.14, total=4139.67, n_correct=2775.05, ppl=5.32, accuracy=67.036, wps=6509.8, ups=1.57, wpb=4139.7, bsz=149.2, num_updates=46600, lr=6.55122e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=36093
2023-07-17 22:07:54 | INFO | train_inner | epoch 032:   1025 / 1474 loss=1.6, trans_loss=5.157, nll_loss=2.405, w2v_ctc_loss=0.471, task_loss=2.578, contrastive_loss=0.322, total=4119.15, n_correct=2763.33, ppl=5.29, accuracy=67.085, wps=6545.4, ups=1.59, wpb=4119.1, bsz=152.2, num_updates=46700, lr=6.5442e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=36156
2023-07-17 22:08:58 | INFO | train_inner | epoch 032:   1125 / 1474 loss=1.619, trans_loss=5.176, nll_loss=2.429, w2v_ctc_loss=0.485, task_loss=3.08, contrastive_loss=0.21, total=4019.61, n_correct=2679.98, ppl=5.38, accuracy=66.673, wps=6303.3, ups=1.57, wpb=4019.6, bsz=135.7, num_updates=46800, lr=6.5372e-05, gnorm=0.435, clip=0, loss_scale=32, train_wall=63, gb_free=17.8, wall=36220
2023-07-17 22:10:02 | INFO | train_inner | epoch 032:   1225 / 1474 loss=1.614, trans_loss=5.177, nll_loss=2.433, w2v_ctc_loss=0.478, task_loss=2.578, contrastive_loss=0.429, total=4149.28, n_correct=2766.03, ppl=5.4, accuracy=66.663, wps=6498.3, ups=1.57, wpb=4149.3, bsz=155.2, num_updates=46900, lr=6.53023e-05, gnorm=0.447, clip=0, loss_scale=32, train_wall=63, gb_free=16.1, wall=36284
2023-07-17 22:11:05 | INFO | train_inner | epoch 032:   1325 / 1474 loss=1.606, trans_loss=5.167, nll_loss=2.418, w2v_ctc_loss=0.485, task_loss=2.664, contrastive_loss=0.139, total=4079.22, n_correct=2732.08, ppl=5.34, accuracy=66.976, wps=6474.1, ups=1.59, wpb=4079.2, bsz=148.1, num_updates=47000, lr=6.52328e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=15.4, wall=36347
2023-07-17 22:12:08 | INFO | train_inner | epoch 032:   1425 / 1474 loss=1.616, trans_loss=5.179, nll_loss=2.434, w2v_ctc_loss=0.484, task_loss=2.615, contrastive_loss=0.601, total=4111.41, n_correct=2743.24, ppl=5.4, accuracy=66.723, wps=6512.5, ups=1.58, wpb=4111.4, bsz=153.1, num_updates=47100, lr=6.51635e-05, gnorm=0.433, clip=0, loss_scale=32, train_wall=63, gb_free=16.2, wall=36410
2023-07-17 22:12:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 22:13:04 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.679 | trans_loss 5.542 | nll_loss 2.809 | w2v_ctc_loss 1.159 | task_loss 4.302 | contrastive_loss 0.278 | total 4003.4 | n_correct 2492.9 | ppl 7.01 | accuracy 62.27 | uer 16.418 | wer 18.258 | raw_wer 18.258 | bleu 20.49 | wps 2136.4 | wpb 4003.4 | bsz 141.8 | num_updates 47149 | best_bleu 20.84
2023-07-17 22:13:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47149 updates
2023-07-17 22:13:04 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.4902.pt
2023-07-17 22:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.4902.pt
2023-07-17 22:13:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.4902.pt (epoch 32 @ 47149 updates, score 20.49) (writing took 7.252408999018371 seconds)
2023-07-17 22:13:11 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-17 22:13:11 | INFO | train | epoch 032 | loss 1.6 | trans_loss 5.156 | nll_loss 2.404 | w2v_ctc_loss 0.476 | task_loss 2.6 | contrastive_loss 0.247 | total 4138.65 | n_correct 2776.67 | ppl 5.29 | accuracy 67.091 | wps 6061.1 | ups 1.46 | wpb 4138.6 | bsz 152.8 | num_updates 47149 | lr 6.51297e-05 | gnorm 0.429 | clip 0 | loss_scale 32 | train_wall 928 | gb_free 16.8 | wall 36473
2023-07-17 22:13:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 22:13:11 | INFO | fairseq.trainer | begin training epoch 33
2023-07-17 22:13:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 22:13:52 | INFO | train_inner | epoch 033:     51 / 1474 loss=1.591, trans_loss=5.156, nll_loss=2.405, w2v_ctc_loss=0.472, task_loss=2.42, contrastive_loss=0.346, total=4156.71, n_correct=2789.05, ppl=5.3, accuracy=67.098, wps=3994.4, ups=0.96, wpb=4156.7, bsz=161.2, num_updates=47200, lr=6.50945e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=62, gb_free=16.8, wall=36514
2023-07-17 22:14:55 | INFO | train_inner | epoch 033:    151 / 1474 loss=1.59, trans_loss=5.134, nll_loss=2.373, w2v_ctc_loss=0.466, task_loss=2.809, contrastive_loss=0.118, total=4071.44, n_correct=2748.03, ppl=5.18, accuracy=67.495, wps=6432.8, ups=1.58, wpb=4071.4, bsz=142.1, num_updates=47300, lr=6.50256e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=36577
2023-07-17 22:15:59 | INFO | train_inner | epoch 033:    251 / 1474 loss=1.583, trans_loss=5.133, nll_loss=2.375, w2v_ctc_loss=0.465, task_loss=2.215, contrastive_loss=0.479, total=4281.28, n_correct=2892.69, ppl=5.19, accuracy=67.566, wps=6700.6, ups=1.57, wpb=4281.3, bsz=173.2, num_updates=47400, lr=6.4957e-05, gnorm=0.413, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=36641
2023-07-17 22:17:03 | INFO | train_inner | epoch 033:    351 / 1474 loss=1.604, trans_loss=5.146, nll_loss=2.391, w2v_ctc_loss=0.478, task_loss=2.671, contrastive_loss=0.181, total=4111.69, n_correct=2766.64, ppl=5.25, accuracy=67.287, wps=6491.9, ups=1.58, wpb=4111.7, bsz=149.2, num_updates=47500, lr=6.48886e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=36705
2023-07-17 22:18:06 | INFO | train_inner | epoch 033:    451 / 1474 loss=1.58, trans_loss=5.123, nll_loss=2.361, w2v_ctc_loss=0.464, task_loss=2.441, contrastive_loss=0.141, total=4147.28, n_correct=2801.88, ppl=5.14, accuracy=67.559, wps=6567.9, ups=1.58, wpb=4147.3, bsz=156.7, num_updates=47600, lr=6.48204e-05, gnorm=0.431, clip=0, loss_scale=64, train_wall=63, gb_free=16.8, wall=36768
2023-07-17 22:19:09 | INFO | train_inner | epoch 033:    551 / 1474 loss=1.608, trans_loss=5.148, nll_loss=2.392, w2v_ctc_loss=0.478, task_loss=2.702, contrastive_loss=0.179, total=4127.68, n_correct=2774.6, ppl=5.25, accuracy=67.219, wps=6548.9, ups=1.59, wpb=4127.7, bsz=146.3, num_updates=47700, lr=6.47524e-05, gnorm=0.429, clip=0, loss_scale=64, train_wall=63, gb_free=15.9, wall=36831
2023-07-17 22:20:12 | INFO | train_inner | epoch 033:    651 / 1474 loss=1.599, trans_loss=5.157, nll_loss=2.405, w2v_ctc_loss=0.473, task_loss=2.661, contrastive_loss=0.248, total=4164.1, n_correct=2793.51, ppl=5.3, accuracy=67.086, wps=6583.4, ups=1.58, wpb=4164.1, bsz=151.2, num_updates=47800, lr=6.46846e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=63, gb_free=15.6, wall=36894
2023-07-17 22:21:15 | INFO | train_inner | epoch 033:    751 / 1474 loss=1.609, trans_loss=5.164, nll_loss=2.413, w2v_ctc_loss=0.489, task_loss=2.834, contrastive_loss=0.141, total=4064.29, n_correct=2722.12, ppl=5.33, accuracy=66.977, wps=6434.8, ups=1.58, wpb=4064.3, bsz=142.9, num_updates=47900, lr=6.46171e-05, gnorm=0.432, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=36957
2023-07-17 22:22:18 | INFO | train_inner | epoch 033:    851 / 1474 loss=1.591, trans_loss=5.141, nll_loss=2.386, w2v_ctc_loss=0.467, task_loss=2.45, contrastive_loss=0.282, total=4141.12, n_correct=2790.58, ppl=5.23, accuracy=67.387, wps=6582.1, ups=1.59, wpb=4141.1, bsz=159.3, num_updates=48000, lr=6.45497e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=62, gb_free=17, wall=37020
2023-07-17 22:22:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 22:22:42 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.677 | trans_loss 5.538 | nll_loss 2.806 | w2v_ctc_loss 1.163 | task_loss 4.295 | contrastive_loss 0.272 | total 4003.4 | n_correct 2500 | ppl 6.99 | accuracy 62.447 | uer 16.566 | wer 18.519 | raw_wer 18.519 | bleu 20.51 | wps 2300.5 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.84
2023-07-17 22:22:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-17 22:22:42 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_33_48000.pt
2023-07-17 22:22:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_33_48000.pt
2023-07-17 22:22:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.51) (writing took 6.589229739038274 seconds)
2023-07-17 22:23:52 | INFO | train_inner | epoch 033:    951 / 1474 loss=1.596, trans_loss=5.149, nll_loss=2.395, w2v_ctc_loss=0.477, task_loss=2.589, contrastive_loss=0.167, total=4147.76, n_correct=2788, ppl=5.26, accuracy=67.217, wps=4411.4, ups=1.06, wpb=4147.8, bsz=154.1, num_updates=48100, lr=6.44826e-05, gnorm=0.42, clip=0, loss_scale=64, train_wall=63, gb_free=17.7, wall=37114
2023-07-17 22:24:56 | INFO | train_inner | epoch 033:   1051 / 1474 loss=1.606, trans_loss=5.158, nll_loss=2.407, w2v_ctc_loss=0.477, task_loss=2.603, contrastive_loss=0.376, total=4137.41, n_correct=2773.81, ppl=5.3, accuracy=67.042, wps=6447.5, ups=1.56, wpb=4137.4, bsz=154, num_updates=48200, lr=6.44157e-05, gnorm=0.428, clip=0, loss_scale=64, train_wall=64, gb_free=16.1, wall=37178
2023-07-17 22:25:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-17 22:26:00 | INFO | train_inner | epoch 033:   1152 / 1474 loss=1.605, trans_loss=5.155, nll_loss=2.403, w2v_ctc_loss=0.469, task_loss=2.619, contrastive_loss=0.349, total=4181.93, n_correct=2806.04, ppl=5.29, accuracy=67.099, wps=6522.1, ups=1.56, wpb=4181.9, bsz=153.5, num_updates=48300, lr=6.43489e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=64, gb_free=17.7, wall=37242
2023-07-17 22:27:04 | INFO | train_inner | epoch 033:   1252 / 1474 loss=1.603, trans_loss=5.156, nll_loss=2.404, w2v_ctc_loss=0.482, task_loss=2.734, contrastive_loss=0.151, total=4110.02, n_correct=2757.4, ppl=5.29, accuracy=67.09, wps=6501.3, ups=1.58, wpb=4110, bsz=147.2, num_updates=48400, lr=6.42824e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=37306
2023-07-17 22:28:07 | INFO | train_inner | epoch 033:   1352 / 1474 loss=1.58, trans_loss=5.151, nll_loss=2.4, w2v_ctc_loss=0.471, task_loss=2.549, contrastive_loss=0.195, total=4128.82, n_correct=2775.49, ppl=5.28, accuracy=67.222, wps=6499.5, ups=1.57, wpb=4128.8, bsz=156.2, num_updates=48500, lr=6.42161e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=37369
2023-07-17 22:29:11 | INFO | train_inner | epoch 033:   1452 / 1474 loss=1.602, trans_loss=5.155, nll_loss=2.404, w2v_ctc_loss=0.47, task_loss=2.589, contrastive_loss=0.48, total=4123.47, n_correct=2769.16, ppl=5.29, accuracy=67.156, wps=6484.9, ups=1.57, wpb=4123.5, bsz=154.4, num_updates=48600, lr=6.415e-05, gnorm=0.439, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=37433
2023-07-17 22:29:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 22:29:49 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.673 | trans_loss 5.542 | nll_loss 2.81 | w2v_ctc_loss 1.152 | task_loss 4.337 | contrastive_loss 0.278 | total 4003.4 | n_correct 2496.5 | ppl 7.01 | accuracy 62.359 | uer 16.749 | wer 18.541 | raw_wer 18.541 | bleu 20.57 | wps 2251.3 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 20.84
2023-07-17 22:29:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-07-17 22:29:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.5701.pt
2023-07-17 22:29:52 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.5701.pt
2023-07-17 22:29:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.5701.pt (epoch 33 @ 48622 updates, score 20.57) (writing took 5.2964595690136775 seconds)
2023-07-17 22:29:55 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-17 22:29:55 | INFO | train | epoch 033 | loss 1.597 | trans_loss 5.147 | nll_loss 2.393 | w2v_ctc_loss 0.473 | task_loss 2.597 | contrastive_loss 0.247 | total 4138.63 | n_correct 2783.1 | ppl 5.25 | accuracy 67.247 | wps 6072.8 | ups 1.47 | wpb 4138.6 | bsz 152.8 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.425 | clip 0 | loss_scale 32 | train_wall 927 | gb_free 18 | wall 37477
2023-07-17 22:29:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 22:29:55 | INFO | fairseq.trainer | begin training epoch 34
2023-07-17 22:29:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 22:30:54 | INFO | train_inner | epoch 034:     78 / 1474 loss=1.587, trans_loss=5.125, nll_loss=2.364, w2v_ctc_loss=0.47, task_loss=2.555, contrastive_loss=0.155, total=4128.94, n_correct=2793.61, ppl=5.15, accuracy=67.659, wps=4017.6, ups=0.97, wpb=4128.9, bsz=151.1, num_updates=48700, lr=6.40841e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=63, gb_free=15.4, wall=37535
2023-07-17 22:31:57 | INFO | train_inner | epoch 034:    178 / 1474 loss=1.59, trans_loss=5.129, nll_loss=2.368, w2v_ctc_loss=0.476, task_loss=2.709, contrastive_loss=0.159, total=4071.22, n_correct=2752.61, ppl=5.16, accuracy=67.611, wps=6405.3, ups=1.57, wpb=4071.2, bsz=147.6, num_updates=48800, lr=6.40184e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=63, gb_free=15.8, wall=37599
2023-07-17 22:33:01 | INFO | train_inner | epoch 034:    278 / 1474 loss=1.604, trans_loss=5.146, nll_loss=2.392, w2v_ctc_loss=0.465, task_loss=2.447, contrastive_loss=0.57, total=4237.89, n_correct=2854.83, ppl=5.25, accuracy=67.364, wps=6589.3, ups=1.55, wpb=4237.9, bsz=163.5, num_updates=48900, lr=6.39529e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=64, gb_free=10.9, wall=37663
2023-07-17 22:34:05 | INFO | train_inner | epoch 034:    378 / 1474 loss=1.586, trans_loss=5.124, nll_loss=2.363, w2v_ctc_loss=0.464, task_loss=2.452, contrastive_loss=0.35, total=4167, n_correct=2819.68, ppl=5.14, accuracy=67.667, wps=6567.8, ups=1.58, wpb=4167, bsz=159.5, num_updates=49000, lr=6.38877e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=17.5, wall=37727
2023-07-17 22:35:08 | INFO | train_inner | epoch 034:    478 / 1474 loss=1.597, trans_loss=5.139, nll_loss=2.38, w2v_ctc_loss=0.477, task_loss=2.846, contrastive_loss=0.143, total=4071.65, n_correct=2743.71, ppl=5.21, accuracy=67.386, wps=6467.5, ups=1.59, wpb=4071.7, bsz=142.4, num_updates=49100, lr=6.38226e-05, gnorm=0.442, clip=0, loss_scale=32, train_wall=62, gb_free=12, wall=37790
2023-07-17 22:36:11 | INFO | train_inner | epoch 034:    578 / 1474 loss=1.589, trans_loss=5.123, nll_loss=2.36, w2v_ctc_loss=0.47, task_loss=2.636, contrastive_loss=0.148, total=4110.13, n_correct=2782.08, ppl=5.14, accuracy=67.688, wps=6501.1, ups=1.58, wpb=4110.1, bsz=149.5, num_updates=49200, lr=6.37577e-05, gnorm=0.436, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=37853
2023-07-17 22:37:14 | INFO | train_inner | epoch 034:    678 / 1474 loss=1.587, trans_loss=5.128, nll_loss=2.368, w2v_ctc_loss=0.465, task_loss=2.627, contrastive_loss=0.136, total=4128.65, n_correct=2787.63, ppl=5.16, accuracy=67.519, wps=6531.6, ups=1.58, wpb=4128.6, bsz=150.4, num_updates=49300, lr=6.3693e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=18, wall=37916
2023-07-17 22:38:17 | INFO | train_inner | epoch 034:    778 / 1474 loss=1.607, trans_loss=5.151, nll_loss=2.398, w2v_ctc_loss=0.468, task_loss=2.73, contrastive_loss=0.276, total=4075.69, n_correct=2738.89, ppl=5.27, accuracy=67.201, wps=6465.7, ups=1.59, wpb=4075.7, bsz=147.3, num_updates=49400, lr=6.36285e-05, gnorm=0.431, clip=0, loss_scale=32, train_wall=63, gb_free=17.4, wall=37979
2023-07-17 22:39:21 | INFO | train_inner | epoch 034:    878 / 1474 loss=1.603, trans_loss=5.15, nll_loss=2.397, w2v_ctc_loss=0.475, task_loss=2.744, contrastive_loss=0.193, total=4104.97, n_correct=2756.45, ppl=5.27, accuracy=67.149, wps=6467, ups=1.58, wpb=4105, bsz=148.2, num_updates=49500, lr=6.35642e-05, gnorm=0.438, clip=0, loss_scale=32, train_wall=63, gb_free=17.9, wall=38043
2023-07-17 22:40:24 | INFO | train_inner | epoch 034:    978 / 1474 loss=1.589, trans_loss=5.142, nll_loss=2.386, w2v_ctc_loss=0.47, task_loss=2.537, contrastive_loss=0.186, total=4168.94, n_correct=2806.02, ppl=5.23, accuracy=67.308, wps=6628.7, ups=1.59, wpb=4168.9, bsz=156.4, num_updates=49600, lr=6.35001e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=62, gb_free=15.2, wall=38106
2023-07-17 22:41:26 | INFO | train_inner | epoch 034:   1078 / 1474 loss=1.594, trans_loss=5.148, nll_loss=2.394, w2v_ctc_loss=0.476, task_loss=2.514, contrastive_loss=0.151, total=4155.12, n_correct=2794.96, ppl=5.26, accuracy=67.265, wps=6641.7, ups=1.6, wpb=4155.1, bsz=154.6, num_updates=49700, lr=6.34361e-05, gnorm=0.431, clip=0, loss_scale=32, train_wall=62, gb_free=17, wall=38168
2023-07-17 22:42:30 | INFO | train_inner | epoch 034:   1178 / 1474 loss=1.59, trans_loss=5.142, nll_loss=2.387, w2v_ctc_loss=0.47, task_loss=2.688, contrastive_loss=0.174, total=4096.48, n_correct=2756.09, ppl=5.23, accuracy=67.279, wps=6450.5, ups=1.57, wpb=4096.5, bsz=148.6, num_updates=49800, lr=6.33724e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=38232
2023-07-17 22:43:33 | INFO | train_inner | epoch 034:   1278 / 1474 loss=1.589, trans_loss=5.138, nll_loss=2.382, w2v_ctc_loss=0.468, task_loss=2.626, contrastive_loss=0.137, total=4149.03, n_correct=2794.94, ppl=5.21, accuracy=67.364, wps=6552.2, ups=1.58, wpb=4149, bsz=149.9, num_updates=49900, lr=6.33089e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=38295
2023-07-17 22:44:37 | INFO | train_inner | epoch 034:   1378 / 1474 loss=1.591, trans_loss=5.149, nll_loss=2.396, w2v_ctc_loss=0.472, task_loss=2.488, contrastive_loss=0.274, total=4200.34, n_correct=2821.87, ppl=5.26, accuracy=67.182, wps=6578.2, ups=1.57, wpb=4200.3, bsz=161, num_updates=50000, lr=6.32456e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=63, gb_free=15.3, wall=38359
2023-07-17 22:44:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 22:45:02 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.681 | trans_loss 5.544 | nll_loss 2.814 | w2v_ctc_loss 1.163 | task_loss 4.302 | contrastive_loss 0.279 | total 4003.4 | n_correct 2491.1 | ppl 7.03 | accuracy 62.225 | uer 16.479 | wer 18.377 | raw_wer 18.377 | bleu 20.25 | wps 2138.3 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.84
2023-07-17 22:45:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-17 22:45:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_34_50000.pt
2023-07-17 22:45:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_34_50000.pt
2023-07-17 22:45:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.25) (writing took 5.288320859079249 seconds)
mt_weight tensor(0.0177, device='cuda:0')
asr_weight tensor(0.0013, device='cuda:0')
2023-07-17 22:46:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.0177, device='cuda:6')
asr_weight tensor(0.0013, device='cuda:6')
mt_weight tensor(0.0177, device='cuda:2')
asr_weight tensor(0.0013, device='cuda:2')
mt_weight tensor(0.0177, device='cuda:1')
asr_weight tensor(0.0013, device='cuda:1')
mt_weight tensor(0.0177, device='cuda:4')
asr_weight tensor(0.0013, device='cuda:4')
mt_weight tensor(0.0177, device='cuda:3')
asr_weight tensor(0.0013, device='cuda:3')
mt_weight tensor(0.0177, device='cuda:5')
asr_weight tensor(0.0013, device='cuda:5')
mt_weight tensor(0.0177, device='cuda:7')
asr_weight tensor(0.0013, device='cuda:7')
2023-07-17 22:46:34 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.681 | trans_loss 5.541 | nll_loss 2.81 | w2v_ctc_loss 1.156 | task_loss 4.281 | contrastive_loss 0.285 | total 4003.4 | n_correct 2491.7 | ppl 7.01 | accuracy 62.24 | uer 16.51 | wer 18.43 | raw_wer 18.43 | bleu 20.56 | wps 2082.2 | wpb 4003.4 | bsz 141.8 | num_updates 50096 | best_bleu 20.84
2023-07-17 22:46:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50096 updates
2023-07-17 22:46:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.5603.pt
2023-07-17 22:46:37 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.5603.pt
2023-07-17 22:46:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.5603.pt (epoch 34 @ 50096 updates, score 20.56) (writing took 5.622499222052284 seconds)
2023-07-17 22:46:40 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-17 22:46:40 | INFO | train | epoch 034 | loss 1.593 | trans_loss 5.139 | nll_loss 2.382 | w2v_ctc_loss 0.47 | task_loss 2.597 | contrastive_loss 0.246 | total 4138.65 | n_correct 2789.14 | ppl 5.21 | accuracy 67.393 | wps 6068.6 | ups 1.47 | wpb 4138.6 | bsz 152.8 | num_updates 50096 | lr 6.31849e-05 | gnorm 0.429 | clip 0 | loss_scale 32 | train_wall 927 | gb_free 17.5 | wall 38482
2023-07-17 22:46:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 22:46:40 | INFO | fairseq.trainer | begin training epoch 35
2023-07-17 22:46:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 22:46:52 | INFO | train_inner | epoch 035:      4 / 1474 loss=1.596, trans_loss=5.147, nll_loss=2.394, w2v_ctc_loss=0.464, task_loss=2.373, contrastive_loss=0.546, total=4211.77, n_correct=2833.31, ppl=5.26, accuracy=67.271, wps=3123.7, ups=0.74, wpb=4211.8, bsz=163.5, num_updates=50100, lr=6.31824e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=38494
2023-07-17 22:47:55 | INFO | train_inner | epoch 035:    104 / 1474 loss=1.584, trans_loss=5.12, nll_loss=2.357, w2v_ctc_loss=0.458, task_loss=2.515, contrastive_loss=0.423, total=4165.08, n_correct=2821.93, ppl=5.12, accuracy=67.752, wps=6570.2, ups=1.58, wpb=4165.1, bsz=156.3, num_updates=50200, lr=6.31194e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=15.3, wall=38557
2023-07-17 22:48:58 | INFO | train_inner | epoch 035:    204 / 1474 loss=1.571, trans_loss=5.11, nll_loss=2.344, w2v_ctc_loss=0.458, task_loss=2.448, contrastive_loss=0.15, total=4176.66, n_correct=2835.76, ppl=5.08, accuracy=67.895, wps=6617.7, ups=1.58, wpb=4176.7, bsz=158.5, num_updates=50300, lr=6.30567e-05, gnorm=0.427, clip=0, loss_scale=64, train_wall=63, gb_free=15.3, wall=38620
2023-07-17 22:50:03 | INFO | train_inner | epoch 035:    304 / 1474 loss=1.593, trans_loss=5.121, nll_loss=2.358, w2v_ctc_loss=0.464, task_loss=2.716, contrastive_loss=0.472, total=4108.8, n_correct=2783.34, ppl=5.13, accuracy=67.741, wps=6352.9, ups=1.55, wpb=4108.8, bsz=150, num_updates=50400, lr=6.29941e-05, gnorm=0.429, clip=0, loss_scale=64, train_wall=64, gb_free=17, wall=38685
2023-07-17 22:50:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-17 22:51:07 | INFO | train_inner | epoch 035:    405 / 1474 loss=1.599, trans_loss=5.13, nll_loss=2.369, w2v_ctc_loss=0.476, task_loss=2.901, contrastive_loss=0.148, total=4067.14, n_correct=2743.44, ppl=5.17, accuracy=67.454, wps=6370.3, ups=1.57, wpb=4067.1, bsz=141.1, num_updates=50500, lr=6.29317e-05, gnorm=0.443, clip=0, loss_scale=32, train_wall=63, gb_free=17, wall=38749
2023-07-17 22:52:11 | INFO | train_inner | epoch 035:    505 / 1474 loss=1.59, trans_loss=5.132, nll_loss=2.372, w2v_ctc_loss=0.464, task_loss=2.644, contrastive_loss=0.294, total=4154.8, n_correct=2810.18, ppl=5.18, accuracy=67.637, wps=6504.2, ups=1.57, wpb=4154.8, bsz=152.4, num_updates=50600, lr=6.28695e-05, gnorm=0.441, clip=0, loss_scale=32, train_wall=63, gb_free=14, wall=38813
2023-07-17 22:53:14 | INFO | train_inner | epoch 035:    605 / 1474 loss=1.58, trans_loss=5.123, nll_loss=2.362, w2v_ctc_loss=0.459, task_loss=2.57, contrastive_loss=0.313, total=4170.95, n_correct=2823.18, ppl=5.14, accuracy=67.687, wps=6629.5, ups=1.59, wpb=4170.9, bsz=155, num_updates=50700, lr=6.28074e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=62, gb_free=16.3, wall=38876
2023-07-17 22:54:17 | INFO | train_inner | epoch 035:    705 / 1474 loss=1.594, trans_loss=5.133, nll_loss=2.374, w2v_ctc_loss=0.477, task_loss=2.722, contrastive_loss=0.168, total=4081.06, n_correct=2757.8, ppl=5.18, accuracy=67.576, wps=6452.7, ups=1.58, wpb=4081.1, bsz=147.4, num_updates=50800, lr=6.27456e-05, gnorm=0.443, clip=0, loss_scale=32, train_wall=63, gb_free=17.2, wall=38939
2023-07-17 22:55:20 | INFO | train_inner | epoch 035:    805 / 1474 loss=1.587, trans_loss=5.132, nll_loss=2.374, w2v_ctc_loss=0.471, task_loss=2.564, contrastive_loss=0.184, total=4151.95, n_correct=2801.9, ppl=5.18, accuracy=67.484, wps=6532.7, ups=1.57, wpb=4151.9, bsz=155.1, num_updates=50900, lr=6.26839e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=63, gb_free=15.9, wall=39002
2023-07-17 22:56:25 | INFO | train_inner | epoch 035:    905 / 1474 loss=1.593, trans_loss=5.138, nll_loss=2.381, w2v_ctc_loss=0.473, task_loss=2.727, contrastive_loss=0.143, total=4096.04, n_correct=2757.67, ppl=5.21, accuracy=67.325, wps=6389, ups=1.56, wpb=4096, bsz=146.9, num_updates=51000, lr=6.26224e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=64, gb_free=11.6, wall=39066
2023-07-17 22:57:28 | INFO | train_inner | epoch 035:   1005 / 1474 loss=1.604, trans_loss=5.141, nll_loss=2.385, w2v_ctc_loss=0.467, task_loss=2.619, contrastive_loss=0.392, total=4144.92, n_correct=2787.76, ppl=5.22, accuracy=67.257, wps=6516.5, ups=1.57, wpb=4144.9, bsz=153.5, num_updates=51100, lr=6.25611e-05, gnorm=0.431, clip=0, loss_scale=32, train_wall=63, gb_free=15, wall=39130
2023-07-17 22:58:31 | INFO | train_inner | epoch 035:   1105 / 1474 loss=1.59, trans_loss=5.138, nll_loss=2.382, w2v_ctc_loss=0.471, task_loss=2.484, contrastive_loss=0.16, total=4180.8, n_correct=2819.6, ppl=5.21, accuracy=67.442, wps=6624.2, ups=1.58, wpb=4180.8, bsz=155.7, num_updates=51200, lr=6.25e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=17.2, wall=39193
2023-07-17 22:59:34 | INFO | train_inner | epoch 035:   1205 / 1474 loss=1.596, trans_loss=5.138, nll_loss=2.382, w2v_ctc_loss=0.468, task_loss=2.399, contrastive_loss=0.267, total=4214.15, n_correct=2842.42, ppl=5.21, accuracy=67.449, wps=6716.4, ups=1.59, wpb=4214.1, bsz=160.4, num_updates=51300, lr=6.24391e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=62, gb_free=16.9, wall=39256
2023-07-17 23:00:37 | INFO | train_inner | epoch 035:   1305 / 1474 loss=1.585, trans_loss=5.135, nll_loss=2.379, w2v_ctc_loss=0.467, task_loss=2.495, contrastive_loss=0.167, total=4140.13, n_correct=2793.27, ppl=5.2, accuracy=67.468, wps=6536.3, ups=1.58, wpb=4140.1, bsz=156.5, num_updates=51400, lr=6.23783e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=39319
2023-07-17 23:01:41 | INFO | train_inner | epoch 035:   1405 / 1474 loss=1.599, trans_loss=5.148, nll_loss=2.394, w2v_ctc_loss=0.474, task_loss=2.833, contrastive_loss=0.142, total=4056.79, n_correct=2726.85, ppl=5.25, accuracy=67.217, wps=6395.9, ups=1.58, wpb=4056.8, bsz=143.1, num_updates=51500, lr=6.23177e-05, gnorm=0.438, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=39383
2023-07-17 23:02:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 23:02:49 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 3.673 | trans_loss 5.536 | nll_loss 2.802 | w2v_ctc_loss 1.158 | task_loss 4.323 | contrastive_loss 0.281 | total 4003.4 | n_correct 2504 | ppl 6.97 | accuracy 62.547 | uer 16.418 | wer 18.344 | raw_wer 18.344 | bleu 20.13 | wps 2175.4 | wpb 4003.4 | bsz 141.8 | num_updates 51569 | best_bleu 20.84
2023-07-17 23:02:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51569 updates
2023-07-17 23:02:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt
2023-07-17 23:02:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt
2023-07-17 23:02:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt (epoch 35 @ 51569 updates, score 20.13) (writing took 4.549457024084404 seconds)
2023-07-17 23:02:54 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-17 23:02:54 | INFO | train | epoch 035 | loss 1.59 | trans_loss 5.131 | nll_loss 2.372 | w2v_ctc_loss 0.467 | task_loss 2.598 | contrastive_loss 0.247 | total 4138.72 | n_correct 2794.73 | ppl 5.18 | accuracy 67.526 | wps 6261.2 | ups 1.51 | wpb 4138.7 | bsz 152.9 | num_updates 51569 | lr 6.2276e-05 | gnorm 0.431 | clip 0 | loss_scale 32 | train_wall 928 | gb_free 17.4 | wall 39456
2023-07-17 23:02:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 23:02:54 | INFO | fairseq.trainer | begin training epoch 36
2023-07-17 23:02:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 23:03:22 | INFO | train_inner | epoch 036:     31 / 1474 loss=1.589, trans_loss=5.125, nll_loss=2.364, w2v_ctc_loss=0.465, task_loss=2.523, contrastive_loss=0.23, total=4123.87, n_correct=2787.93, ppl=5.15, accuracy=67.605, wps=4075.9, ups=0.99, wpb=4123.9, bsz=154.3, num_updates=51600, lr=6.22573e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=17.5, wall=39484
2023-07-17 23:04:25 | INFO | train_inner | epoch 036:    131 / 1474 loss=1.58, trans_loss=5.113, nll_loss=2.347, w2v_ctc_loss=0.464, task_loss=2.7, contrastive_loss=0.162, total=4105.22, n_correct=2785.72, ppl=5.09, accuracy=67.858, wps=6479.9, ups=1.58, wpb=4105.2, bsz=149.6, num_updates=51700, lr=6.2197e-05, gnorm=0.44, clip=0, loss_scale=32, train_wall=63, gb_free=15.8, wall=39547
2023-07-17 23:05:29 | INFO | train_inner | epoch 036:    231 / 1474 loss=1.584, trans_loss=5.112, nll_loss=2.346, w2v_ctc_loss=0.464, task_loss=2.656, contrastive_loss=0.187, total=4152.4, n_correct=2817.43, ppl=5.08, accuracy=67.851, wps=6529.1, ups=1.57, wpb=4152.4, bsz=151.5, num_updates=51800, lr=6.2137e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=63, gb_free=16.2, wall=39611
2023-07-17 23:06:31 | INFO | train_inner | epoch 036:    331 / 1474 loss=1.575, trans_loss=5.112, nll_loss=2.347, w2v_ctc_loss=0.453, task_loss=2.459, contrastive_loss=0.138, total=4161.71, n_correct=2826.74, ppl=5.09, accuracy=67.923, wps=6661.3, ups=1.6, wpb=4161.7, bsz=155.1, num_updates=51900, lr=6.20771e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=62, gb_free=13.9, wall=39673
2023-07-17 23:07:34 | INFO | train_inner | epoch 036:    431 / 1474 loss=1.577, trans_loss=5.112, nll_loss=2.348, w2v_ctc_loss=0.454, task_loss=2.27, contrastive_loss=0.378, total=4234.57, n_correct=2873.38, ppl=5.09, accuracy=67.855, wps=6732.3, ups=1.59, wpb=4234.6, bsz=166.8, num_updates=52000, lr=6.20174e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=62, gb_free=17.1, wall=39736
2023-07-17 23:07:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 23:08:00 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.694 | trans_loss 5.545 | nll_loss 2.813 | w2v_ctc_loss 1.193 | task_loss 4.295 | contrastive_loss 0.275 | total 4003.4 | n_correct 2502.6 | ppl 7.03 | accuracy 62.512 | uer 16.76 | wer 18.627 | raw_wer 18.627 | bleu 20.46 | wps 2125.2 | wpb 4003.4 | bsz 141.8 | num_updates 52000 | best_bleu 20.84
2023-07-17 23:08:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-17 23:08:00 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_36_52000.pt
2023-07-17 23:08:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_36_52000.pt
2023-07-17 23:08:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 20.46) (writing took 7.304349172976799 seconds)
2023-07-17 23:09:12 | INFO | train_inner | epoch 036:    531 / 1474 loss=1.595, trans_loss=5.134, nll_loss=2.375, w2v_ctc_loss=0.459, task_loss=2.619, contrastive_loss=0.651, total=4145.92, n_correct=2798.37, ppl=5.19, accuracy=67.497, wps=4255, ups=1.03, wpb=4145.9, bsz=155.5, num_updates=52100, lr=6.19578e-05, gnorm=0.436, clip=0, loss_scale=32, train_wall=64, gb_free=16.6, wall=39834
2023-07-17 23:10:16 | INFO | train_inner | epoch 036:    631 / 1474 loss=1.576, trans_loss=5.109, nll_loss=2.343, w2v_ctc_loss=0.46, task_loss=2.497, contrastive_loss=0.299, total=4180.58, n_correct=2835.95, ppl=5.07, accuracy=67.836, wps=6541.9, ups=1.56, wpb=4180.6, bsz=158.3, num_updates=52200, lr=6.18984e-05, gnorm=0.419, clip=0, loss_scale=32, train_wall=63, gb_free=17.2, wall=39898
2023-07-17 23:11:19 | INFO | train_inner | epoch 036:    731 / 1474 loss=1.592, trans_loss=5.13, nll_loss=2.371, w2v_ctc_loss=0.469, task_loss=2.478, contrastive_loss=0.172, total=4185.09, n_correct=2826.56, ppl=5.17, accuracy=67.539, wps=6583.7, ups=1.57, wpb=4185.1, bsz=158.6, num_updates=52300, lr=6.18392e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=63, gb_free=17.3, wall=39961
2023-07-17 23:12:22 | INFO | train_inner | epoch 036:    831 / 1474 loss=1.596, trans_loss=5.144, nll_loss=2.389, w2v_ctc_loss=0.461, task_loss=2.466, contrastive_loss=0.498, total=4167.92, n_correct=2805.32, ppl=5.24, accuracy=67.307, wps=6590.3, ups=1.58, wpb=4167.9, bsz=159.5, num_updates=52400, lr=6.17802e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=40024
2023-07-17 23:13:26 | INFO | train_inner | epoch 036:    931 / 1474 loss=1.586, trans_loss=5.12, nll_loss=2.357, w2v_ctc_loss=0.465, task_loss=2.602, contrastive_loss=0.147, total=4180.47, n_correct=2829.73, ppl=5.12, accuracy=67.689, wps=6565.6, ups=1.57, wpb=4180.5, bsz=153.8, num_updates=52500, lr=6.17213e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=63, gb_free=13.1, wall=40088
2023-07-17 23:14:30 | INFO | train_inner | epoch 036:   1031 / 1474 loss=1.594, trans_loss=5.123, nll_loss=2.362, w2v_ctc_loss=0.469, task_loss=2.698, contrastive_loss=0.136, total=4175.32, n_correct=2824.4, ppl=5.14, accuracy=67.645, wps=6543.2, ups=1.57, wpb=4175.3, bsz=150.4, num_updates=52600, lr=6.16626e-05, gnorm=0.432, clip=0, loss_scale=64, train_wall=63, gb_free=13.6, wall=40152
2023-07-17 23:15:33 | INFO | train_inner | epoch 036:   1131 / 1474 loss=1.581, trans_loss=5.121, nll_loss=2.358, w2v_ctc_loss=0.468, task_loss=2.58, contrastive_loss=0.169, total=4140.45, n_correct=2802.43, ppl=5.13, accuracy=67.684, wps=6526, ups=1.58, wpb=4140.4, bsz=154.1, num_updates=52700, lr=6.16041e-05, gnorm=0.424, clip=0, loss_scale=64, train_wall=63, gb_free=16, wall=40215
2023-07-17 23:16:37 | INFO | train_inner | epoch 036:   1231 / 1474 loss=1.59, trans_loss=5.126, nll_loss=2.364, w2v_ctc_loss=0.469, task_loss=2.9, contrastive_loss=0.124, total=4044.64, n_correct=2736.49, ppl=5.15, accuracy=67.657, wps=6395.5, ups=1.58, wpb=4044.6, bsz=139.5, num_updates=52800, lr=6.15457e-05, gnorm=0.437, clip=0, loss_scale=64, train_wall=63, gb_free=13.7, wall=40279
2023-07-17 23:17:39 | INFO | train_inner | epoch 036:   1331 / 1474 loss=1.583, trans_loss=5.129, nll_loss=2.37, w2v_ctc_loss=0.465, task_loss=2.602, contrastive_loss=0.153, total=4106.95, n_correct=2772.44, ppl=5.17, accuracy=67.506, wps=6568.2, ups=1.6, wpb=4106.9, bsz=152.7, num_updates=52900, lr=6.14875e-05, gnorm=0.428, clip=0, loss_scale=64, train_wall=62, gb_free=17.6, wall=40341
2023-07-17 23:18:42 | INFO | train_inner | epoch 036:   1431 / 1474 loss=1.609, trans_loss=5.148, nll_loss=2.393, w2v_ctc_loss=0.475, task_loss=2.925, contrastive_loss=0.252, total=4043.37, n_correct=2716.14, ppl=5.25, accuracy=67.175, wps=6402, ups=1.58, wpb=4043.4, bsz=139.2, num_updates=53000, lr=6.14295e-05, gnorm=0.442, clip=0, loss_scale=64, train_wall=63, gb_free=16.2, wall=40404
2023-07-17 23:19:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-17 23:19:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 23:19:35 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 3.683 | trans_loss 5.537 | nll_loss 2.805 | w2v_ctc_loss 1.17 | task_loss 4.281 | contrastive_loss 0.281 | total 4003.4 | n_correct 2499.1 | ppl 6.99 | accuracy 62.424 | uer 16.617 | wer 18.43 | raw_wer 18.43 | bleu 20.39 | wps 2049.9 | wpb 4003.4 | bsz 141.8 | num_updates 53042 | best_bleu 20.84
2023-07-17 23:19:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53042 updates
2023-07-17 23:19:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.3907.pt
2023-07-17 23:19:37 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.3907.pt
2023-07-17 23:19:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.3907.pt (epoch 36 @ 53042 updates, score 20.39) (writing took 5.547093181987293 seconds)
2023-07-17 23:19:41 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-17 23:19:41 | INFO | train | epoch 036 | loss 1.587 | trans_loss 5.123 | nll_loss 2.362 | w2v_ctc_loss 0.464 | task_loss 2.598 | contrastive_loss 0.245 | total 4138.16 | n_correct 2799.68 | ppl 5.14 | accuracy 67.655 | wps 6052.4 | ups 1.46 | wpb 4138.2 | bsz 152.8 | num_updates 53042 | lr 6.14052e-05 | gnorm 0.428 | clip 0 | loss_scale 32 | train_wall 926 | gb_free 17 | wall 40463
2023-07-17 23:19:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 23:19:41 | INFO | fairseq.trainer | begin training epoch 37
2023-07-17 23:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 23:20:27 | INFO | train_inner | epoch 037:     58 / 1474 loss=1.578, trans_loss=5.107, nll_loss=2.341, w2v_ctc_loss=0.46, task_loss=2.622, contrastive_loss=0.162, total=4089.93, n_correct=2780.35, ppl=5.07, accuracy=67.98, wps=3923.6, ups=0.96, wpb=4089.9, bsz=149.3, num_updates=53100, lr=6.13716e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=15.6, wall=40509
2023-07-17 23:21:31 | INFO | train_inner | epoch 037:    158 / 1474 loss=1.586, trans_loss=5.108, nll_loss=2.341, w2v_ctc_loss=0.46, task_loss=2.641, contrastive_loss=0.27, total=4124.56, n_correct=2805.48, ppl=5.07, accuracy=68.019, wps=6451.7, ups=1.56, wpb=4124.6, bsz=153.4, num_updates=53200, lr=6.13139e-05, gnorm=0.442, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=40572
2023-07-17 23:22:34 | INFO | train_inner | epoch 037:    258 / 1474 loss=1.56, trans_loss=5.088, nll_loss=2.317, w2v_ctc_loss=0.443, task_loss=2.422, contrastive_loss=0.152, total=4188.93, n_correct=2858.3, ppl=4.98, accuracy=68.235, wps=6586.8, ups=1.57, wpb=4188.9, bsz=159.7, num_updates=53300, lr=6.12564e-05, gnorm=0.418, clip=0, loss_scale=32, train_wall=63, gb_free=15.2, wall=40636
2023-07-17 23:23:38 | INFO | train_inner | epoch 037:    358 / 1474 loss=1.588, trans_loss=5.107, nll_loss=2.34, w2v_ctc_loss=0.466, task_loss=2.624, contrastive_loss=0.165, total=4171.05, n_correct=2835.2, ppl=5.06, accuracy=67.973, wps=6573, ups=1.58, wpb=4171.1, bsz=152.9, num_updates=53400, lr=6.1199e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=63, gb_free=16.2, wall=40700
2023-07-17 23:24:41 | INFO | train_inner | epoch 037:    458 / 1474 loss=1.597, trans_loss=5.13, nll_loss=2.371, w2v_ctc_loss=0.457, task_loss=2.488, contrastive_loss=0.58, total=4184.96, n_correct=2826.56, ppl=5.17, accuracy=67.541, wps=6557, ups=1.57, wpb=4185, bsz=159.5, num_updates=53500, lr=6.11418e-05, gnorm=0.434, clip=0, loss_scale=32, train_wall=63, gb_free=13.6, wall=40763
2023-07-17 23:25:44 | INFO | train_inner | epoch 037:    558 / 1474 loss=1.575, trans_loss=5.111, nll_loss=2.346, w2v_ctc_loss=0.464, task_loss=2.688, contrastive_loss=0.143, total=4091.86, n_correct=2775.53, ppl=5.08, accuracy=67.831, wps=6492.6, ups=1.59, wpb=4091.9, bsz=149.9, num_updates=53600, lr=6.10847e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=40826
2023-07-17 23:26:48 | INFO | train_inner | epoch 037:    658 / 1474 loss=1.59, trans_loss=5.124, nll_loss=2.362, w2v_ctc_loss=0.474, task_loss=2.762, contrastive_loss=0.157, total=4096.37, n_correct=2770.66, ppl=5.14, accuracy=67.637, wps=6421.8, ups=1.57, wpb=4096.4, bsz=145.2, num_updates=53700, lr=6.10278e-05, gnorm=0.433, clip=0, loss_scale=32, train_wall=63, gb_free=15.2, wall=40890
2023-07-17 23:27:51 | INFO | train_inner | epoch 037:    758 / 1474 loss=1.583, trans_loss=5.107, nll_loss=2.342, w2v_ctc_loss=0.456, task_loss=2.575, contrastive_loss=0.276, total=4124.05, n_correct=2799.2, ppl=5.07, accuracy=67.875, wps=6558.7, ups=1.59, wpb=4124.1, bsz=152.7, num_updates=53800, lr=6.09711e-05, gnorm=0.434, clip=0, loss_scale=32, train_wall=62, gb_free=13.8, wall=40953
2023-07-17 23:28:54 | INFO | train_inner | epoch 037:    858 / 1474 loss=1.573, trans_loss=5.109, nll_loss=2.343, w2v_ctc_loss=0.454, task_loss=2.444, contrastive_loss=0.144, total=4161.41, n_correct=2826.43, ppl=5.08, accuracy=67.92, wps=6577.1, ups=1.58, wpb=4161.4, bsz=157.5, num_updates=53900, lr=6.09145e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=63, gb_free=16, wall=41016
2023-07-17 23:29:58 | INFO | train_inner | epoch 037:    958 / 1474 loss=1.59, trans_loss=5.125, nll_loss=2.364, w2v_ctc_loss=0.471, task_loss=2.748, contrastive_loss=0.161, total=4108.96, n_correct=2778.65, ppl=5.15, accuracy=67.624, wps=6496.3, ups=1.58, wpb=4109, bsz=147.4, num_updates=54000, lr=6.08581e-05, gnorm=0.437, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=41080
2023-07-17 23:29:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 23:30:22 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.685 | trans_loss 5.537 | nll_loss 2.805 | w2v_ctc_loss 1.182 | task_loss 4.274 | contrastive_loss 0.273 | total 4003.4 | n_correct 2503.1 | ppl 6.99 | accuracy 62.524 | uer 16.253 | wer 18.098 | raw_wer 18.098 | bleu 20.3 | wps 2269.2 | wpb 4003.4 | bsz 141.8 | num_updates 54000 | best_bleu 20.84
2023-07-17 23:30:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-17 23:30:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_37_54000.pt
2023-07-17 23:30:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_37_54000.pt
2023-07-17 23:30:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 20.3) (writing took 5.305997562012635 seconds)
2023-07-17 23:31:31 | INFO | train_inner | epoch 037:   1058 / 1474 loss=1.581, trans_loss=5.116, nll_loss=2.353, w2v_ctc_loss=0.456, task_loss=2.475, contrastive_loss=0.409, total=4140.79, n_correct=2810.39, ppl=5.11, accuracy=67.871, wps=4451.2, ups=1.07, wpb=4140.8, bsz=157.3, num_updates=54100, lr=6.08018e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=62, gb_free=15.3, wall=41173
2023-07-17 23:32:34 | INFO | train_inner | epoch 037:   1158 / 1474 loss=1.584, trans_loss=5.125, nll_loss=2.365, w2v_ctc_loss=0.456, task_loss=2.47, contrastive_loss=0.47, total=4188.76, n_correct=2833.81, ppl=5.15, accuracy=67.653, wps=6614.4, ups=1.58, wpb=4188.8, bsz=158.6, num_updates=54200, lr=6.07457e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=63, gb_free=15.4, wall=41236
2023-07-17 23:33:37 | INFO | train_inner | epoch 037:   1258 / 1474 loss=1.579, trans_loss=5.125, nll_loss=2.364, w2v_ctc_loss=0.458, task_loss=2.527, contrastive_loss=0.162, total=4170.22, n_correct=2818.77, ppl=5.15, accuracy=67.593, wps=6573.7, ups=1.58, wpb=4170.2, bsz=155.8, num_updates=54300, lr=6.06897e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=63, gb_free=16.9, wall=41299
2023-07-17 23:34:41 | INFO | train_inner | epoch 037:   1358 / 1474 loss=1.606, trans_loss=5.137, nll_loss=2.379, w2v_ctc_loss=0.484, task_loss=2.868, contrastive_loss=0.143, total=4071.07, n_correct=2743.83, ppl=5.2, accuracy=67.398, wps=6433.7, ups=1.58, wpb=4071.1, bsz=142.7, num_updates=54400, lr=6.06339e-05, gnorm=0.442, clip=0, loss_scale=32, train_wall=63, gb_free=10.4, wall=41363
2023-07-17 23:35:44 | INFO | train_inner | epoch 037:   1458 / 1474 loss=1.586, trans_loss=5.125, nll_loss=2.365, w2v_ctc_loss=0.46, task_loss=2.571, contrastive_loss=0.209, total=4160.94, n_correct=2814.32, ppl=5.15, accuracy=67.637, wps=6620.4, ups=1.59, wpb=4160.9, bsz=153.1, num_updates=54500, lr=6.05783e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=62, gb_free=16, wall=41426
2023-07-17 23:35:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 23:36:20 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 3.682 | trans_loss 5.541 | nll_loss 2.808 | w2v_ctc_loss 1.15 | task_loss 4.281 | contrastive_loss 0.278 | total 4003.4 | n_correct 2500.9 | ppl 7 | accuracy 62.469 | uer 16.404 | wer 18.198 | raw_wer 18.198 | bleu 20.31 | wps 2018.3 | wpb 4003.4 | bsz 141.8 | num_updates 54516 | best_bleu 20.84
2023-07-17 23:36:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54516 updates
2023-07-17 23:36:20 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt
2023-07-17 23:36:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt
2023-07-17 23:36:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt (epoch 37 @ 54516 updates, score 20.31) (writing took 4.53281943500042 seconds)
2023-07-17 23:36:25 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-17 23:36:25 | INFO | train | epoch 037 | loss 1.584 | trans_loss 5.117 | nll_loss 2.353 | w2v_ctc_loss 0.462 | task_loss 2.598 | contrastive_loss 0.244 | total 4138.65 | n_correct 2805.16 | ppl 5.11 | accuracy 67.78 | wps 6078.5 | ups 1.47 | wpb 4138.6 | bsz 152.8 | num_updates 54516 | lr 6.05694e-05 | gnorm 0.43 | clip 0 | loss_scale 32 | train_wall 928 | gb_free 13.2 | wall 41466
2023-07-17 23:36:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 23:36:25 | INFO | fairseq.trainer | begin training epoch 38
2023-07-17 23:36:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 23:37:27 | INFO | train_inner | epoch 038:     84 / 1474 loss=1.584, trans_loss=5.097, nll_loss=2.326, w2v_ctc_loss=0.459, task_loss=2.727, contrastive_loss=0.136, total=4084.91, n_correct=2783.72, ppl=5.02, accuracy=68.146, wps=3964.1, ups=0.97, wpb=4084.9, bsz=146.6, num_updates=54600, lr=6.05228e-05, gnorm=0.437, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=41529
2023-07-17 23:38:29 | INFO | train_inner | epoch 038:    184 / 1474 loss=1.573, trans_loss=5.097, nll_loss=2.327, w2v_ctc_loss=0.457, task_loss=2.735, contrastive_loss=0.14, total=4081.45, n_correct=2780.32, ppl=5.02, accuracy=68.121, wps=6494.2, ups=1.59, wpb=4081.5, bsz=146, num_updates=54700, lr=6.04674e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=62, gb_free=17.1, wall=41591
2023-07-17 23:39:32 | INFO | train_inner | epoch 038:    284 / 1474 loss=1.576, trans_loss=5.104, nll_loss=2.337, w2v_ctc_loss=0.455, task_loss=2.737, contrastive_loss=0.177, total=4059.24, n_correct=2759.99, ppl=5.05, accuracy=67.993, wps=6472.8, ups=1.59, wpb=4059.2, bsz=146.6, num_updates=54800, lr=6.04122e-05, gnorm=0.433, clip=0, loss_scale=32, train_wall=62, gb_free=17.1, wall=41654
2023-07-17 23:40:36 | INFO | train_inner | epoch 038:    384 / 1474 loss=1.573, trans_loss=5.104, nll_loss=2.337, w2v_ctc_loss=0.46, task_loss=2.561, contrastive_loss=0.184, total=4176.56, n_correct=2841.22, ppl=5.05, accuracy=68.028, wps=6543.3, ups=1.57, wpb=4176.6, bsz=154.6, num_updates=54900, lr=6.03572e-05, gnorm=0.432, clip=0, loss_scale=32, train_wall=63, gb_free=16.3, wall=41718
2023-07-17 23:41:39 | INFO | train_inner | epoch 038:    484 / 1474 loss=1.565, trans_loss=5.092, nll_loss=2.321, w2v_ctc_loss=0.45, task_loss=2.499, contrastive_loss=0.177, total=4191.63, n_correct=2857.3, ppl=5, accuracy=68.167, wps=6679.5, ups=1.59, wpb=4191.6, bsz=156.4, num_updates=55000, lr=6.03023e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=62, gb_free=15.9, wall=41781
mt_weight tensor(0.0177, device='cuda:0')
asr_weight tensor(0.0013, device='cuda:0')
2023-07-17 23:42:43 | INFO | train_inner | epoch 038:    584 / 1474 loss=1.592, trans_loss=5.123, nll_loss=2.361, w2v_ctc_loss=0.456, task_loss=2.584, contrastive_loss=0.505, total=4179.76, n_correct=2826.6, ppl=5.14, accuracy=67.626, wps=6474.7, ups=1.55, wpb=4179.8, bsz=154.8, num_updates=55100, lr=6.02475e-05, gnorm=0.433, clip=0, loss_scale=64, train_wall=64, gb_free=16.1, wall=41845
2023-07-17 23:43:47 | INFO | train_inner | epoch 038:    684 / 1474 loss=1.576, trans_loss=5.104, nll_loss=2.338, w2v_ctc_loss=0.45, task_loss=2.469, contrastive_loss=0.478, total=4173.72, n_correct=2834.7, ppl=5.06, accuracy=67.918, wps=6545.9, ups=1.57, wpb=4173.7, bsz=160.6, num_updates=55200, lr=6.01929e-05, gnorm=0.425, clip=0, loss_scale=64, train_wall=63, gb_free=16.5, wall=41909
2023-07-17 23:44:50 | INFO | train_inner | epoch 038:    784 / 1474 loss=1.577, trans_loss=5.092, nll_loss=2.322, w2v_ctc_loss=0.449, task_loss=2.385, contrastive_loss=0.326, total=4183.15, n_correct=2852.41, ppl=5, accuracy=68.188, wps=6654, ups=1.59, wpb=4183.1, bsz=163.3, num_updates=55300, lr=6.01385e-05, gnorm=0.421, clip=0, loss_scale=64, train_wall=62, gb_free=17.8, wall=41972
2023-07-17 23:45:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-17 23:45:53 | INFO | train_inner | epoch 038:    885 / 1474 loss=1.565, trans_loss=5.095, nll_loss=2.326, w2v_ctc_loss=0.451, task_loss=2.46, contrastive_loss=0.146, total=4124.62, n_correct=2810.15, ppl=5.02, accuracy=68.131, wps=6552.4, ups=1.59, wpb=4124.6, bsz=156.1, num_updates=55400, lr=6.00842e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=62, gb_free=15.7, wall=42035
2023-07-17 23:46:56 | INFO | train_inner | epoch 038:    985 / 1474 loss=1.581, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=0.461, task_loss=2.613, contrastive_loss=0.215, total=4116.2, n_correct=2790.84, ppl=5.11, accuracy=67.801, wps=6529.1, ups=1.59, wpb=4116.2, bsz=150.8, num_updates=55500, lr=6.003e-05, gnorm=0.421, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=42098
2023-07-17 23:47:59 | INFO | train_inner | epoch 038:   1085 / 1474 loss=1.579, trans_loss=5.109, nll_loss=2.345, w2v_ctc_loss=0.456, task_loss=2.368, contrastive_loss=0.275, total=4248.59, n_correct=2886.52, ppl=5.08, accuracy=67.941, wps=6724.3, ups=1.58, wpb=4248.6, bsz=164.4, num_updates=55600, lr=5.9976e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=42161
2023-07-17 23:49:03 | INFO | train_inner | epoch 038:   1185 / 1474 loss=1.594, trans_loss=5.126, nll_loss=2.365, w2v_ctc_loss=0.472, task_loss=2.859, contrastive_loss=0.154, total=4077.59, n_correct=2753.82, ppl=5.15, accuracy=67.535, wps=6380.2, ups=1.56, wpb=4077.6, bsz=143.7, num_updates=55700, lr=5.99222e-05, gnorm=0.445, clip=0, loss_scale=32, train_wall=63, gb_free=14.3, wall=42225
2023-07-17 23:50:07 | INFO | train_inner | epoch 038:   1285 / 1474 loss=1.599, trans_loss=5.128, nll_loss=2.368, w2v_ctc_loss=0.467, task_loss=2.761, contrastive_loss=0.151, total=4146.3, n_correct=2799.32, ppl=5.16, accuracy=67.514, wps=6458.4, ups=1.56, wpb=4146.3, bsz=147.8, num_updates=55800, lr=5.98684e-05, gnorm=0.441, clip=0, loss_scale=32, train_wall=64, gb_free=17.7, wall=42289
2023-07-17 23:51:10 | INFO | train_inner | epoch 038:   1385 / 1474 loss=1.589, trans_loss=5.122, nll_loss=2.362, w2v_ctc_loss=0.464, task_loss=2.561, contrastive_loss=0.252, total=4156.39, n_correct=2812.99, ppl=5.14, accuracy=67.679, wps=6603, ups=1.59, wpb=4156.4, bsz=155.3, num_updates=55900, lr=5.98149e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=16.6, wall=42352
2023-07-17 23:52:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.0177, device='cuda:6')
asr_weight tensor(0.0013, device='cuda:6')
mt_weight tensor(0.0177, device='cuda:7')
asr_weight tensor(0.0013, device='cuda:7')
mt_weight tensor(0.0177, device='cuda:5')
asr_weight tensor(0.0013, device='cuda:5')
mt_weight tensor(0.0177, device='cuda:4')
asr_weight tensor(0.0013, device='cuda:4')
mt_weight tensor(0.0177, device='cuda:1')
asr_weight tensor(0.0013, device='cuda:1')
mt_weight tensor(0.0177, device='cuda:2')
asr_weight tensor(0.0013, device='cuda:2')
mt_weight tensor(0.0177, device='cuda:3')
asr_weight tensor(0.0013, device='cuda:3')
2023-07-17 23:52:31 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 3.687 | trans_loss 5.545 | nll_loss 2.815 | w2v_ctc_loss 1.159 | task_loss 4.26 | contrastive_loss 0.282 | total 4003.4 | n_correct 2504.8 | ppl 7.04 | accuracy 62.567 | uer 16.649 | wer 18.452 | raw_wer 18.452 | bleu 20.21 | wps 2163.9 | wpb 4003.4 | bsz 141.8 | num_updates 55989 | best_bleu 20.84
2023-07-17 23:52:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55989 updates
2023-07-17 23:52:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt
2023-07-17 23:52:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt
2023-07-17 23:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt (epoch 38 @ 55989 updates, score 20.21) (writing took 4.298639119951986 seconds)
2023-07-17 23:52:36 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-17 23:52:36 | INFO | train | epoch 038 | loss 1.581 | trans_loss 5.108 | nll_loss 2.343 | w2v_ctc_loss 0.458 | task_loss 2.598 | contrastive_loss 0.243 | total 4138.85 | n_correct 2810.67 | ppl 5.07 | accuracy 67.909 | wps 6277.4 | ups 1.52 | wpb 4138.9 | bsz 152.9 | num_updates 55989 | lr 5.97673e-05 | gnorm 0.429 | clip 0 | loss_scale 32 | train_wall 926 | gb_free 16.8 | wall 42438
2023-07-17 23:52:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-17 23:52:36 | INFO | fairseq.trainer | begin training epoch 39
2023-07-17 23:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-17 23:52:51 | INFO | train_inner | epoch 039:     11 / 1474 loss=1.593, trans_loss=5.118, nll_loss=2.355, w2v_ctc_loss=0.464, task_loss=2.794, contrastive_loss=0.271, total=4033.2, n_correct=2734.95, ppl=5.12, accuracy=67.811, wps=3999.8, ups=0.99, wpb=4033.2, bsz=142.9, num_updates=56000, lr=5.97614e-05, gnorm=0.434, clip=0, loss_scale=32, train_wall=62, gb_free=17.5, wall=42453
2023-07-17 23:52:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-17 23:53:15 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.693 | trans_loss 5.542 | nll_loss 2.808 | w2v_ctc_loss 1.187 | task_loss 4.281 | contrastive_loss 0.28 | total 4003.4 | n_correct 2506.7 | ppl 7 | accuracy 62.614 | uer 16.449 | wer 18.128 | raw_wer 18.128 | bleu 20.26 | wps 2309.2 | wpb 4003.4 | bsz 141.8 | num_updates 56000 | best_bleu 20.84
2023-07-17 23:53:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-17 23:53:15 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_39_56000.pt
2023-07-17 23:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_39_56000.pt
2023-07-17 23:53:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 20.26) (writing took 5.183248531073332 seconds)
2023-07-17 23:54:23 | INFO | train_inner | epoch 039:    111 / 1474 loss=1.576, trans_loss=5.081, nll_loss=2.305, w2v_ctc_loss=0.458, task_loss=2.767, contrastive_loss=0.135, total=4057.77, n_correct=2774.3, ppl=4.94, accuracy=68.37, wps=4406.5, ups=1.09, wpb=4057.8, bsz=143.2, num_updates=56100, lr=5.97081e-05, gnorm=0.434, clip=0, loss_scale=32, train_wall=62, gb_free=17.5, wall=42545
2023-07-17 23:55:27 | INFO | train_inner | epoch 039:    211 / 1474 loss=1.576, trans_loss=5.077, nll_loss=2.301, w2v_ctc_loss=0.454, task_loss=2.649, contrastive_loss=0.138, total=4134.99, n_correct=2828.13, ppl=4.93, accuracy=68.395, wps=6500.1, ups=1.57, wpb=4135, bsz=150.2, num_updates=56200, lr=5.9655e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=15.9, wall=42609
2023-07-17 23:56:30 | INFO | train_inner | epoch 039:    311 / 1474 loss=1.571, trans_loss=5.083, nll_loss=2.308, w2v_ctc_loss=0.455, task_loss=2.649, contrastive_loss=0.149, total=4135.88, n_correct=2827.71, ppl=4.95, accuracy=68.37, wps=6533.5, ups=1.58, wpb=4135.9, bsz=149.8, num_updates=56300, lr=5.9602e-05, gnorm=0.435, clip=0, loss_scale=32, train_wall=63, gb_free=13.4, wall=42672
2023-07-17 23:57:34 | INFO | train_inner | epoch 039:    411 / 1474 loss=1.575, trans_loss=5.091, nll_loss=2.321, w2v_ctc_loss=0.451, task_loss=2.565, contrastive_loss=0.444, total=4128.52, n_correct=2815.66, ppl=5, accuracy=68.2, wps=6494.1, ups=1.57, wpb=4128.5, bsz=156.1, num_updates=56400, lr=5.95491e-05, gnorm=0.438, clip=0, loss_scale=32, train_wall=63, gb_free=13, wall=42736
2023-07-17 23:58:37 | INFO | train_inner | epoch 039:    511 / 1474 loss=1.577, trans_loss=5.101, nll_loss=2.333, w2v_ctc_loss=0.452, task_loss=2.554, contrastive_loss=0.464, total=4143.39, n_correct=2817.86, ppl=5.04, accuracy=68.009, wps=6512.6, ups=1.57, wpb=4143.4, bsz=155.8, num_updates=56500, lr=5.94964e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=17, wall=42799
2023-07-17 23:59:40 | INFO | train_inner | epoch 039:    611 / 1474 loss=1.579, trans_loss=5.101, nll_loss=2.333, w2v_ctc_loss=0.454, task_loss=2.64, contrastive_loss=0.253, total=4131.41, n_correct=2812.37, ppl=5.04, accuracy=68.073, wps=6548.6, ups=1.59, wpb=4131.4, bsz=151.4, num_updates=56600, lr=5.94438e-05, gnorm=0.428, clip=0, loss_scale=32, train_wall=63, gb_free=16, wall=42862
2023-07-18 00:00:43 | INFO | train_inner | epoch 039:    711 / 1474 loss=1.58, trans_loss=5.106, nll_loss=2.339, w2v_ctc_loss=0.453, task_loss=2.518, contrastive_loss=0.238, total=4133.78, n_correct=2808.49, ppl=5.06, accuracy=67.94, wps=6639.3, ups=1.61, wpb=4133.8, bsz=152.9, num_updates=56700, lr=5.93914e-05, gnorm=0.427, clip=0, loss_scale=32, train_wall=62, gb_free=16.2, wall=42925
2023-07-18 00:01:47 | INFO | train_inner | epoch 039:    811 / 1474 loss=1.573, trans_loss=5.102, nll_loss=2.334, w2v_ctc_loss=0.458, task_loss=2.615, contrastive_loss=0.164, total=4178.43, n_correct=2839.23, ppl=5.04, accuracy=67.95, wps=6540.3, ups=1.57, wpb=4178.4, bsz=154.9, num_updates=56800, lr=5.93391e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=42988
2023-07-18 00:02:50 | INFO | train_inner | epoch 039:    911 / 1474 loss=1.574, trans_loss=5.104, nll_loss=2.337, w2v_ctc_loss=0.455, task_loss=2.682, contrastive_loss=0.166, total=4125.39, n_correct=2803.38, ppl=5.05, accuracy=67.954, wps=6543, ups=1.59, wpb=4125.4, bsz=149.5, num_updates=56900, lr=5.92869e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=17, wall=43052
2023-07-18 00:03:53 | INFO | train_inner | epoch 039:   1011 / 1474 loss=1.582, trans_loss=5.115, nll_loss=2.352, w2v_ctc_loss=0.456, task_loss=2.54, contrastive_loss=0.389, total=4198.7, n_correct=2848.27, ppl=5.1, accuracy=67.837, wps=6593.7, ups=1.57, wpb=4198.7, bsz=159.7, num_updates=57000, lr=5.92349e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=63, gb_free=16.2, wall=43115
2023-07-18 00:04:56 | INFO | train_inner | epoch 039:   1111 / 1474 loss=1.576, trans_loss=5.099, nll_loss=2.332, w2v_ctc_loss=0.45, task_loss=2.439, contrastive_loss=0.338, total=4194.7, n_correct=2852.72, ppl=5.03, accuracy=68.008, wps=6650.3, ups=1.59, wpb=4194.7, bsz=160.9, num_updates=57100, lr=5.9183e-05, gnorm=0.429, clip=0, loss_scale=32, train_wall=63, gb_free=15.7, wall=43178
2023-07-18 00:05:59 | INFO | train_inner | epoch 039:   1211 / 1474 loss=1.575, trans_loss=5.11, nll_loss=2.346, w2v_ctc_loss=0.454, task_loss=2.612, contrastive_loss=0.224, total=4123.07, n_correct=2794.73, ppl=5.08, accuracy=67.783, wps=6534.7, ups=1.58, wpb=4123.1, bsz=153.6, num_updates=57200, lr=5.91312e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=43241
2023-07-18 00:07:03 | INFO | train_inner | epoch 039:   1311 / 1474 loss=1.579, trans_loss=5.103, nll_loss=2.337, w2v_ctc_loss=0.457, task_loss=2.467, contrastive_loss=0.197, total=4183.27, n_correct=2844.31, ppl=5.05, accuracy=67.993, wps=6604.5, ups=1.58, wpb=4183.3, bsz=158.8, num_updates=57300, lr=5.90796e-05, gnorm=0.444, clip=0, loss_scale=32, train_wall=63, gb_free=17.2, wall=43305
2023-07-18 00:08:06 | INFO | train_inner | epoch 039:   1411 / 1474 loss=1.584, trans_loss=5.108, nll_loss=2.341, w2v_ctc_loss=0.46, task_loss=2.864, contrastive_loss=0.12, total=4052.15, n_correct=2750.06, ppl=5.07, accuracy=67.867, wps=6444.3, ups=1.59, wpb=4052.2, bsz=139.3, num_updates=57400, lr=5.90281e-05, gnorm=0.445, clip=0, loss_scale=32, train_wall=62, gb_free=13.3, wall=43368
2023-07-18 00:08:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-18 00:08:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-18 00:09:10 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 3.692 | trans_loss 5.54 | nll_loss 2.807 | w2v_ctc_loss 1.194 | task_loss 4.302 | contrastive_loss 0.276 | total 4003.4 | n_correct 2506.3 | ppl 7 | accuracy 62.604 | uer 16.534 | wer 18.43 | raw_wer 18.43 | bleu 20.6 | wps 2270.3 | wpb 4003.4 | bsz 141.8 | num_updates 57462 | best_bleu 20.84
2023-07-18 00:09:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57462 updates
2023-07-18 00:09:10 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.6008.pt
2023-07-18 00:09:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.6008.pt
2023-07-18 00:09:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint.best_bleu_20.6008.pt (epoch 39 @ 57462 updates, score 20.6) (writing took 5.379970030975528 seconds)
2023-07-18 00:09:16 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-18 00:09:16 | INFO | train | epoch 039 | loss 1.577 | trans_loss 5.099 | nll_loss 2.33 | w2v_ctc_loss 0.454 | task_loss 2.598 | contrastive_loss 0.243 | total 4140.23 | n_correct 2817.31 | ppl 5.03 | accuracy 68.047 | wps 6096.8 | ups 1.47 | wpb 4140.2 | bsz 152.9 | num_updates 57462 | lr 5.89963e-05 | gnorm 0.431 | clip 0 | loss_scale 32 | train_wall 925 | gb_free 12.6 | wall 43438
2023-07-18 00:09:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-18 00:09:16 | INFO | fairseq.trainer | begin training epoch 40
2023-07-18 00:09:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-18 00:09:49 | INFO | train_inner | epoch 040:     38 / 1474 loss=1.574, trans_loss=5.097, nll_loss=2.328, w2v_ctc_loss=0.445, task_loss=2.485, contrastive_loss=0.168, total=4191.35, n_correct=2852.16, ppl=5.02, accuracy=68.049, wps=4065.2, ups=0.97, wpb=4191.4, bsz=156.9, num_updates=57500, lr=5.89768e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=64, gb_free=16.1, wall=43471
2023-07-18 00:10:52 | INFO | train_inner | epoch 040:    138 / 1474 loss=1.57, trans_loss=5.062, nll_loss=2.282, w2v_ctc_loss=0.451, task_loss=2.587, contrastive_loss=0.15, total=4150.02, n_correct=2852.29, ppl=4.86, accuracy=68.73, wps=6596, ups=1.59, wpb=4150, bsz=152.6, num_updates=57600, lr=5.89256e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=62, gb_free=17.9, wall=43534
2023-07-18 00:11:54 | INFO | train_inner | epoch 040:    238 / 1474 loss=1.563, trans_loss=5.08, nll_loss=2.305, w2v_ctc_loss=0.454, task_loss=2.664, contrastive_loss=0.148, total=4101.15, n_correct=2804.57, ppl=4.94, accuracy=68.385, wps=6573.8, ups=1.6, wpb=4101.1, bsz=149.9, num_updates=57700, lr=5.88745e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=62, gb_free=10.8, wall=43596
2023-07-18 00:12:57 | INFO | train_inner | epoch 040:    338 / 1474 loss=1.561, trans_loss=5.077, nll_loss=2.302, w2v_ctc_loss=0.443, task_loss=2.401, contrastive_loss=0.176, total=4161.74, n_correct=2848.21, ppl=4.93, accuracy=68.438, wps=6644.6, ups=1.6, wpb=4161.7, bsz=160.6, num_updates=57800, lr=5.88235e-05, gnorm=0.426, clip=0, loss_scale=32, train_wall=62, gb_free=17.2, wall=43659
2023-07-18 00:14:00 | INFO | train_inner | epoch 040:    438 / 1474 loss=1.576, trans_loss=5.089, nll_loss=2.318, w2v_ctc_loss=0.451, task_loss=2.586, contrastive_loss=0.324, total=4141.51, n_correct=2826.09, ppl=4.99, accuracy=68.238, wps=6518.8, ups=1.57, wpb=4141.5, bsz=155.3, num_updates=57900, lr=5.87727e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=63, gb_free=16.7, wall=43722
2023-07-18 00:15:04 | INFO | train_inner | epoch 040:    538 / 1474 loss=1.571, trans_loss=5.087, nll_loss=2.315, w2v_ctc_loss=0.446, task_loss=2.525, contrastive_loss=0.372, total=4167.53, n_correct=2848.32, ppl=4.98, accuracy=68.346, wps=6565.4, ups=1.58, wpb=4167.5, bsz=157.8, num_updates=58000, lr=5.8722e-05, gnorm=0.446, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=43786
2023-07-18 00:15:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-18 00:15:30 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 3.686 | trans_loss 5.541 | nll_loss 2.809 | w2v_ctc_loss 1.189 | task_loss 4.33 | contrastive_loss 0.283 | total 4003.4 | n_correct 2503.6 | ppl 7.01 | accuracy 62.537 | uer 16.343 | wer 18.213 | raw_wer 18.213 | bleu 20.54 | wps 2003.8 | wpb 4003.4 | bsz 141.8 | num_updates 58000 | best_bleu 20.84
2023-07-18 00:15:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-18 00:15:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_40_58000.pt
2023-07-18 00:15:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_40_58000.pt
2023-07-18 00:15:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 20.54) (writing took 6.566324845072813 seconds)
2023-07-18 00:16:41 | INFO | train_inner | epoch 040:    638 / 1474 loss=1.581, trans_loss=5.105, nll_loss=2.337, w2v_ctc_loss=0.466, task_loss=2.706, contrastive_loss=0.179, total=4118.6, n_correct=2795.41, ppl=5.05, accuracy=67.873, wps=4241.4, ups=1.03, wpb=4118.6, bsz=149.2, num_updates=58100, lr=5.86715e-05, gnorm=0.437, clip=0, loss_scale=32, train_wall=63, gb_free=12.7, wall=43883
2023-07-18 00:17:43 | INFO | train_inner | epoch 040:    738 / 1474 loss=1.568, trans_loss=5.09, nll_loss=2.319, w2v_ctc_loss=0.452, task_loss=2.508, contrastive_loss=0.138, total=4137.91, n_correct=2824.82, ppl=4.99, accuracy=68.267, wps=6608.4, ups=1.6, wpb=4137.9, bsz=154.2, num_updates=58200, lr=5.8621e-05, gnorm=0.424, clip=0, loss_scale=32, train_wall=62, gb_free=16.4, wall=43945
2023-07-18 00:18:47 | INFO | train_inner | epoch 040:    838 / 1474 loss=1.571, trans_loss=5.101, nll_loss=2.334, w2v_ctc_loss=0.442, task_loss=2.341, contrastive_loss=0.561, total=4214.92, n_correct=2867.94, ppl=5.04, accuracy=68.043, wps=6634.8, ups=1.57, wpb=4214.9, bsz=164.6, num_updates=58300, lr=5.85707e-05, gnorm=0.425, clip=0, loss_scale=32, train_wall=63, gb_free=16.8, wall=44009
2023-07-18 00:19:51 | INFO | train_inner | epoch 040:    938 / 1474 loss=1.58, trans_loss=5.104, nll_loss=2.338, w2v_ctc_loss=0.459, task_loss=2.737, contrastive_loss=0.186, total=4092.24, n_correct=2778.8, ppl=5.05, accuracy=67.904, wps=6395.5, ups=1.56, wpb=4092.2, bsz=146.8, num_updates=58400, lr=5.85206e-05, gnorm=0.431, clip=0, loss_scale=32, train_wall=64, gb_free=15.2, wall=44073
2023-07-18 00:20:54 | INFO | train_inner | epoch 040:   1038 / 1474 loss=1.594, trans_loss=5.118, nll_loss=2.354, w2v_ctc_loss=0.461, task_loss=2.812, contrastive_loss=0.227, total=4119.93, n_correct=2789.99, ppl=5.11, accuracy=67.719, wps=6499.7, ups=1.58, wpb=4119.9, bsz=143.8, num_updates=58500, lr=5.84705e-05, gnorm=0.446, clip=0, loss_scale=32, train_wall=63, gb_free=16, wall=44136
2023-07-18 00:21:58 | INFO | train_inner | epoch 040:   1138 / 1474 loss=1.577, trans_loss=5.105, nll_loss=2.338, w2v_ctc_loss=0.459, task_loss=2.715, contrastive_loss=0.161, total=4124.74, n_correct=2800.48, ppl=5.05, accuracy=67.895, wps=6483.3, ups=1.57, wpb=4124.7, bsz=149.2, num_updates=58600, lr=5.84206e-05, gnorm=0.434, clip=0, loss_scale=32, train_wall=63, gb_free=17, wall=44200
2023-07-18 00:23:02 | INFO | train_inner | epoch 040:   1238 / 1474 loss=1.575, trans_loss=5.095, nll_loss=2.327, w2v_ctc_loss=0.448, task_loss=2.549, contrastive_loss=0.282, total=4198.52, n_correct=2858.63, ppl=5.02, accuracy=68.087, wps=6596.9, ups=1.57, wpb=4198.5, bsz=155.4, num_updates=58700, lr=5.83708e-05, gnorm=0.42, clip=0, loss_scale=32, train_wall=63, gb_free=17.2, wall=44264
2023-07-18 00:24:05 | INFO | train_inner | epoch 040:   1338 / 1474 loss=1.575, trans_loss=5.096, nll_loss=2.328, w2v_ctc_loss=0.446, task_loss=2.617, contrastive_loss=0.295, total=4124.38, n_correct=2811.99, ppl=5.02, accuracy=68.18, wps=6553.3, ups=1.59, wpb=4124.4, bsz=153, num_updates=58800, lr=5.83212e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=63, gb_free=16.4, wall=44327
2023-07-18 00:25:07 | INFO | train_inner | epoch 040:   1438 / 1474 loss=1.586, trans_loss=5.108, nll_loss=2.343, w2v_ctc_loss=0.459, task_loss=2.602, contrastive_loss=0.222, total=4121.8, n_correct=2802.44, ppl=5.07, accuracy=67.991, wps=6557.9, ups=1.59, wpb=4121.8, bsz=152.2, num_updates=58900, lr=5.82717e-05, gnorm=0.44, clip=0, loss_scale=32, train_wall=62, gb_free=15.8, wall=44389
2023-07-18 00:25:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-18 00:25:55 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 3.693 | trans_loss 5.542 | nll_loss 2.808 | w2v_ctc_loss 1.216 | task_loss 4.33 | contrastive_loss 0.276 | total 4003.4 | n_correct 2501.3 | ppl 7 | accuracy 62.479 | uer 16.463 | wer 18.169 | raw_wer 18.169 | bleu 20.31 | wps 2224.6 | wpb 4003.4 | bsz 141.8 | num_updates 58936 | best_bleu 20.84
2023-07-18 00:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58936 updates
2023-07-18 00:25:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt
2023-07-18 00:25:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt
2023-07-18 00:25:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_last.pt (epoch 40 @ 58936 updates, score 20.31) (writing took 4.328629809082486 seconds)
2023-07-18 00:25:59 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-18 00:25:59 | INFO | train | epoch 040 | loss 1.575 | trans_loss 5.094 | nll_loss 2.323 | w2v_ctc_loss 0.452 | task_loss 2.596 | contrastive_loss 0.242 | total 4138.65 | n_correct 2820.86 | ppl 5.01 | accuracy 68.159 | wps 6079.8 | ups 1.47 | wpb 4138.6 | bsz 152.8 | num_updates 58936 | lr 5.82539e-05 | gnorm 0.431 | clip 0 | loss_scale 32 | train_wall 925 | gb_free 16 | wall 44441
2023-07-18 00:26:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-18 00:26:00 | INFO | fairseq.trainer | begin training epoch 41
2023-07-18 00:26:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-18 00:26:49 | INFO | train_inner | epoch 041:     64 / 1474 loss=1.575, trans_loss=5.082, nll_loss=2.307, w2v_ctc_loss=0.451, task_loss=2.705, contrastive_loss=0.161, total=4088.95, n_correct=2796.65, ppl=4.95, accuracy=68.395, wps=4042.9, ups=0.99, wpb=4089, bsz=147.8, num_updates=59000, lr=5.82223e-05, gnorm=0.437, clip=0, loss_scale=32, train_wall=63, gb_free=17.1, wall=44491
2023-07-18 00:27:52 | INFO | train_inner | epoch 041:    164 / 1474 loss=1.564, trans_loss=5.061, nll_loss=2.282, w2v_ctc_loss=0.444, task_loss=2.51, contrastive_loss=0.27, total=4141.51, n_correct=2847.03, ppl=4.86, accuracy=68.744, wps=6567.6, ups=1.59, wpb=4141.5, bsz=155.7, num_updates=59100, lr=5.8173e-05, gnorm=0.422, clip=0, loss_scale=32, train_wall=63, gb_free=16, wall=44554
2023-07-18 00:28:55 | INFO | train_inner | epoch 041:    264 / 1474 loss=1.568, trans_loss=5.073, nll_loss=2.297, w2v_ctc_loss=0.443, task_loss=2.406, contrastive_loss=0.263, total=4181.72, n_correct=2865.68, ppl=4.91, accuracy=68.529, wps=6640.9, ups=1.59, wpb=4181.7, bsz=159.6, num_updates=59200, lr=5.81238e-05, gnorm=0.451, clip=0, loss_scale=32, train_wall=63, gb_free=16.5, wall=44617
2023-07-18 00:29:58 | INFO | train_inner | epoch 041:    364 / 1474 loss=1.565, trans_loss=5.08, nll_loss=2.306, w2v_ctc_loss=0.451, task_loss=2.593, contrastive_loss=0.174, total=4147.02, n_correct=2836.41, ppl=4.94, accuracy=68.396, wps=6596.9, ups=1.59, wpb=4147, bsz=152.5, num_updates=59300, lr=5.80748e-05, gnorm=0.43, clip=0, loss_scale=32, train_wall=62, gb_free=16.7, wall=44679
2023-07-18 00:31:01 | INFO | train_inner | epoch 041:    464 / 1474 loss=1.562, trans_loss=5.077, nll_loss=2.302, w2v_ctc_loss=0.445, task_loss=2.609, contrastive_loss=0.139, total=4144.36, n_correct=2838.61, ppl=4.93, accuracy=68.493, wps=6560.1, ups=1.58, wpb=4144.4, bsz=151.4, num_updates=59400, lr=5.80259e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=63, gb_free=16.1, wall=44743
2023-07-18 00:32:04 | INFO | train_inner | epoch 041:    564 / 1474 loss=1.573, trans_loss=5.079, nll_loss=2.304, w2v_ctc_loss=0.452, task_loss=2.603, contrastive_loss=0.175, total=4145.19, n_correct=2837.11, ppl=4.94, accuracy=68.443, wps=6588.9, ups=1.59, wpb=4145.2, bsz=153.6, num_updates=59500, lr=5.79771e-05, gnorm=0.423, clip=0, loss_scale=32, train_wall=62, gb_free=17.1, wall=44806
2023-07-18 00:33:07 | INFO | train_inner | epoch 041:    664 / 1474 loss=1.564, trans_loss=5.068, nll_loss=2.291, w2v_ctc_loss=0.443, task_loss=2.439, contrastive_loss=0.147, total=4189.74, n_correct=2874.13, ppl=4.89, accuracy=68.599, wps=6650.6, ups=1.59, wpb=4189.7, bsz=159, num_updates=59600, lr=5.79284e-05, gnorm=0.434, clip=0, loss_scale=64, train_wall=63, gb_free=16.6, wall=44869
2023-07-18 00:34:10 | INFO | train_inner | epoch 041:    764 / 1474 loss=1.57, trans_loss=5.084, nll_loss=2.31, w2v_ctc_loss=0.448, task_loss=2.629, contrastive_loss=0.138, total=4150.75, n_correct=2835.39, ppl=4.96, accuracy=68.31, wps=6569.8, ups=1.58, wpb=4150.8, bsz=150.4, num_updates=59700, lr=5.78799e-05, gnorm=0.422, clip=0, loss_scale=64, train_wall=63, gb_free=16.4, wall=44932
2023-07-18 00:35:13 | INFO | train_inner | epoch 041:    864 / 1474 loss=1.569, trans_loss=5.077, nll_loss=2.301, w2v_ctc_loss=0.445, task_loss=2.701, contrastive_loss=0.142, total=4108.1, n_correct=2809.33, ppl=4.93, accuracy=68.385, wps=6492, ups=1.58, wpb=4108.1, bsz=147.9, num_updates=59800, lr=5.78315e-05, gnorm=0.429, clip=0, loss_scale=64, train_wall=63, gb_free=16.9, wall=44995
2023-07-18 00:36:17 | INFO | train_inner | epoch 041:    964 / 1474 loss=1.581, trans_loss=5.101, nll_loss=2.333, w2v_ctc_loss=0.458, task_loss=2.715, contrastive_loss=0.326, total=4122.2, n_correct=2803.35, ppl=5.04, accuracy=68.006, wps=6451.3, ups=1.57, wpb=4122.2, bsz=149.6, num_updates=59900, lr=5.77832e-05, gnorm=0.442, clip=0, loss_scale=64, train_wall=63, gb_free=15.2, wall=45059
2023-07-18 00:37:20 | INFO | train_inner | epoch 041:   1064 / 1474 loss=1.571, trans_loss=5.097, nll_loss=2.328, w2v_ctc_loss=0.451, task_loss=2.587, contrastive_loss=0.152, total=4133.83, n_correct=2813.24, ppl=5.02, accuracy=68.054, wps=6564.7, ups=1.59, wpb=4133.8, bsz=152, num_updates=60000, lr=5.7735e-05, gnorm=0.437, clip=0, loss_scale=64, train_wall=63, gb_free=12.8, wall=45122
2023-07-18 00:37:20 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-18 00:37:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-18 00:37:46 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 3.695 | trans_loss 5.544 | nll_loss 2.815 | w2v_ctc_loss 1.214 | task_loss 4.323 | contrastive_loss 0.281 | total 4003.4 | n_correct 2497.6 | ppl 7.04 | accuracy 62.387 | uer 16.503 | wer 18.351 | raw_wer 18.351 | bleu 20.07 | wps 2064.8 | wpb 4003.4 | bsz 141.8 | num_updates 60000 | best_bleu 20.84
2023-07-18 00:37:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-18 00:37:46 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_41_60000.pt
2023-07-18 00:37:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_41_60000.pt
2023-07-18 00:37:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_window_scale1/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 20.07) (writing took 5.14866531395819 seconds)
2023-07-18 00:37:51 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-18 00:37:51 | INFO | train | epoch 041 | loss 1.569 | trans_loss 5.079 | nll_loss 2.305 | w2v_ctc_loss 0.448 | task_loss 2.584 | contrastive_loss 0.192 | total 4144.26 | n_correct 2834.86 | ppl 4.94 | accuracy 68.405 | wps 6193.5 | ups 1.49 | wpb 4144.3 | bsz 153 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.432 | clip 0 | loss_scale 64 | train_wall 667 | gb_free 12.8 | wall 45153
2023-07-18 00:37:51 | INFO | fairseq_cli.train | done training in 45083.1 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1776 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
