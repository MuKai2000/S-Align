2023-08-04 12:51:54 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16176
2023-08-04 12:51:54 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:16176
2023-08-04 12:51:54 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:16176
2023-08-04 12:51:54 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:16176
2023-08-04 12:51:54 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16176
2023-08-04 12:51:54 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:16176
2023-08-04 12:51:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-04 12:51:54 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16176
2023-08-04 12:51:54 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16176
2023-08-04 12:51:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-04 12:51:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 12:51:55 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 12:51:55 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 12:51:55 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-04 12:51:55 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 12:51:55 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 12:51:55 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 12:51:55 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-04 12:51:55 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-04 12:51:55 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-04 12:52:00 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16176', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.5, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-04 12:52:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-04 12:52:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-04 12:52:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-04 12:52:00 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-04 12:52:00 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-04 12:52:04 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-04 12:52:04 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-04 12:52:04 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-04 12:52:06 | INFO | root | load pretrained hubert
2023-08-04 12:52:09 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-04 12:52:11 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-04 12:52:12 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-04 12:52:12 | INFO | root | share the sematic adapter and textual encoder
2023-08-04 12:52:12 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-04 12:52:12 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-04 12:52:12 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-04 12:52:12 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-04 12:52:12 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-04 12:52:12 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-04 12:52:12 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-04 12:52:12 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 12:52:12 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 12:52:12 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-04 12:52:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-04 12:52:18 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-04 12:52:18 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-04 12:52:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-04 12:52:18 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 12:52:18 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 12:52:18 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 12:52:18 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 12:52:18 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 12:52:18 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 12:52:18 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 12:52:18 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 12:52:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-04 12:52:18 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-04 12:52:18 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-04 12:52:18 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_last.pt
2023-08-04 12:52:18 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_last.pt
2023-08-04 12:52:18 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-04 12:52:18 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-04 12:52:18 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 12:52:18 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 12:52:20 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-04 12:52:22 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-04 12:53:10 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-04 12:53:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 12:53:10 | INFO | fairseq.trainer | begin training epoch 1
2023-08-04 12:53:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 12:54:29 | INFO | train_inner | epoch 001:    100 / 1474 loss=19.136, trans_loss=5.598, nll_loss=4.163, w2v_ctc_loss=22.485, task_loss=2.624, contrastive_loss=3.325, total=4207.04, n_correct=209.22, ppl=17.91, accuracy=4.973, wps=19163.8, ups=1.52, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.884, clip=0, loss_scale=128, train_wall=70, gb_free=19.5, wall=131
2023-08-04 12:55:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-04 12:55:34 | INFO | train_inner | epoch 001:    201 / 1474 loss=16.984, trans_loss=5.478, nll_loss=4.064, w2v_ctc_loss=19.348, task_loss=2.558, contrastive_loss=3.277, total=4124.14, n_correct=223.37, ppl=16.73, accuracy=5.416, wps=19086.5, ups=1.55, wpb=12313.4, bsz=461, num_updates=200, lr=8.096e-06, gnorm=3.628, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=195
2023-08-04 12:56:37 | INFO | train_inner | epoch 001:    301 / 1474 loss=10.065, trans_loss=5.476, nll_loss=4.117, w2v_ctc_loss=8.756, task_loss=2.556, contrastive_loss=3.202, total=4079.62, n_correct=208.93, ppl=17.35, accuracy=5.121, wps=19140.9, ups=1.57, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.593, clip=0, loss_scale=64, train_wall=63, gb_free=19.9, wall=259
2023-08-04 12:57:41 | INFO | train_inner | epoch 001:    401 / 1474 loss=8.835, trans_loss=5.513, nll_loss=4.186, w2v_ctc_loss=6.8, task_loss=2.242, contrastive_loss=3.236, total=4174.14, n_correct=195.57, ppl=18.2, accuracy=4.685, wps=19711.1, ups=1.58, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=2.932, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=322
2023-08-04 12:58:44 | INFO | train_inner | epoch 001:    501 / 1474 loss=8.406, trans_loss=5.494, nll_loss=4.177, w2v_ctc_loss=6.167, task_loss=2.049, contrastive_loss=3.229, total=4176.18, n_correct=189.59, ppl=18.09, accuracy=4.54, wps=19610.4, ups=1.57, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.406, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=386
2023-08-04 12:59:49 | INFO | train_inner | epoch 001:    601 / 1474 loss=8.155, trans_loss=5.523, nll_loss=4.213, w2v_ctc_loss=5.8, task_loss=1.908, contrastive_loss=3.282, total=4147.79, n_correct=187.4, ppl=18.54, accuracy=4.518, wps=19078.6, ups=1.54, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.72, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=451
2023-08-04 13:00:52 | INFO | train_inner | epoch 001:    701 / 1474 loss=7.994, trans_loss=5.519, nll_loss=4.214, w2v_ctc_loss=5.682, task_loss=1.985, contrastive_loss=3.031, total=4152.1, n_correct=199.64, ppl=18.55, accuracy=4.808, wps=19677.6, ups=1.59, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=63, gb_free=19.5, wall=514
2023-08-04 13:01:56 | INFO | train_inner | epoch 001:    801 / 1474 loss=7.718, trans_loss=5.453, nll_loss=4.144, w2v_ctc_loss=5.46, task_loss=1.92, contrastive_loss=2.939, total=4123.83, n_correct=244.65, ppl=17.68, accuracy=5.933, wps=19382.1, ups=1.58, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.83, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=577
2023-08-04 13:02:59 | INFO | train_inner | epoch 001:    901 / 1474 loss=7.463, trans_loss=5.42, nll_loss=4.115, w2v_ctc_loss=5.281, task_loss=1.952, contrastive_loss=2.7, total=4163.61, n_correct=269.6, ppl=17.33, accuracy=6.475, wps=19733.8, ups=1.59, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.385, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=640
2023-08-04 13:04:03 | INFO | train_inner | epoch 001:   1001 / 1474 loss=7.206, trans_loss=5.398, nll_loss=4.096, w2v_ctc_loss=5.072, task_loss=1.965, contrastive_loss=2.55, total=4135.34, n_correct=289.99, ppl=17.1, accuracy=7.012, wps=19019.9, ups=1.54, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.429, clip=0, loss_scale=64, train_wall=64, gb_free=19, wall=705
2023-08-04 13:05:07 | INFO | train_inner | epoch 001:   1101 / 1474 loss=6.937, trans_loss=5.387, nll_loss=4.086, w2v_ctc_loss=4.872, task_loss=1.981, contrastive_loss=2.327, total=4147.38, n_correct=312.84, ppl=16.98, accuracy=7.543, wps=19492.9, ups=1.58, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.665, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=769
2023-08-04 13:06:11 | INFO | train_inner | epoch 001:   1201 / 1474 loss=6.715, trans_loss=5.368, nll_loss=4.07, w2v_ctc_loss=4.702, task_loss=2.065, contrastive_loss=2.123, total=4139.9, n_correct=317.04, ppl=16.79, accuracy=7.658, wps=19430.2, ups=1.57, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.76, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=832
2023-08-04 13:07:14 | INFO | train_inner | epoch 001:   1301 / 1474 loss=6.488, trans_loss=5.366, nll_loss=4.069, w2v_ctc_loss=4.501, task_loss=1.986, contrastive_loss=1.929, total=4046.58, n_correct=321.94, ppl=16.79, accuracy=7.956, wps=19204, ups=1.59, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.739, clip=0, loss_scale=64, train_wall=62, gb_free=19.7, wall=895
2023-08-04 13:08:18 | INFO | train_inner | epoch 001:   1401 / 1474 loss=6.277, trans_loss=5.357, nll_loss=4.061, w2v_ctc_loss=4.295, task_loss=1.962, contrastive_loss=1.996, total=4133.18, n_correct=334.7, ppl=16.69, accuracy=8.098, wps=19190.6, ups=1.55, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.619, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=960
2023-08-04 13:09:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 13:09:43 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.545 | trans_loss 10.912 | nll_loss 9.895 | w2v_ctc_loss 5.57 | task_loss 11.32 | contrastive_loss 2.338 | total 4003.4 | n_correct 386.1 | ppl 952.04 | accuracy 9.644 | uer 71.887 | wer 69.792 | raw_wer 69.792 | bleu 0.02 | wps 1185.2 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-08-04 13:09:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-08-04 13:09:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 13:09:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 13:09:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 6.182962596416473 seconds)
2023-08-04 13:09:49 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-04 13:09:49 | INFO | train | epoch 001 | loss 9.03 | trans_loss 5.449 | nll_loss 4.123 | w2v_ctc_loss 7.635 | task_loss 2.114 | contrastive_loss 2.755 | total 4138.55 | n_correct 254.613 | ppl 17.43 | accuracy 6.152 | wps 18462.7 | ups 1.49 | wpb 12355.5 | bsz 458.4 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.789 | clip 0 | loss_scale 64 | train_wall 938 | gb_free 19.2 | wall 1051
2023-08-04 13:09:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 13:09:50 | INFO | fairseq.trainer | begin training epoch 2
2023-08-04 13:09:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 13:10:16 | INFO | train_inner | epoch 002:     27 / 1474 loss=6.082, trans_loss=5.352, nll_loss=4.05, w2v_ctc_loss=4.095, task_loss=1.869, contrastive_loss=1.837, total=4162.95, n_correct=339.77, ppl=16.57, accuracy=8.162, wps=10511.7, ups=0.85, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.621, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1078
2023-08-04 13:11:19 | INFO | train_inner | epoch 002:    127 / 1474 loss=5.917, trans_loss=5.348, nll_loss=4.044, w2v_ctc_loss=3.972, task_loss=1.994, contrastive_loss=1.632, total=4155.98, n_correct=341.8, ppl=16.49, accuracy=8.224, wps=19652.2, ups=1.59, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.709, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1141
2023-08-04 13:12:23 | INFO | train_inner | epoch 002:    227 / 1474 loss=5.746, trans_loss=5.327, nll_loss=4.023, w2v_ctc_loss=3.771, task_loss=1.73, contrastive_loss=1.658, total=4179.21, n_correct=349.3, ppl=16.26, accuracy=8.358, wps=19590.6, ups=1.57, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.488, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1204
2023-08-04 13:13:27 | INFO | train_inner | epoch 002:    327 / 1474 loss=5.582, trans_loss=5.326, nll_loss=4.019, w2v_ctc_loss=3.677, task_loss=1.987, contrastive_loss=1.365, total=4146.1, n_correct=354.54, ppl=16.21, accuracy=8.551, wps=19279.8, ups=1.56, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.367, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=1269
2023-08-04 13:14:30 | INFO | train_inner | epoch 002:    427 / 1474 loss=5.438, trans_loss=5.317, nll_loss=4.012, w2v_ctc_loss=3.575, task_loss=2.184, contrastive_loss=1.185, total=4037.99, n_correct=342.72, ppl=16.14, accuracy=8.487, wps=19105.8, ups=1.58, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.408, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1332
2023-08-04 13:15:34 | INFO | train_inner | epoch 002:    527 / 1474 loss=5.327, trans_loss=5.307, nll_loss=3.995, w2v_ctc_loss=3.413, task_loss=1.899, contrastive_loss=1.278, total=4176.97, n_correct=361.79, ppl=15.95, accuracy=8.662, wps=19644.9, ups=1.58, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.257, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1395
2023-08-04 13:15:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 13:16:14 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.923 | trans_loss 10.755 | nll_loss 9.681 | w2v_ctc_loss 4.453 | task_loss 11.318 | contrastive_loss 1.6 | total 4003.4 | n_correct 409.7 | ppl 820.89 | accuracy 10.234 | uer 61.086 | wer 59.088 | raw_wer 59.088 | bleu 0.04 | wps 1157 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-08-04 13:16:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-04 13:16:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_2_2000.pt
2023-08-04 13:16:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_2_2000.pt
2023-08-04 13:16:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 25.073647186160088 seconds)
2023-08-04 13:17:43 | INFO | train_inner | epoch 002:    627 / 1474 loss=5.192, trans_loss=5.299, nll_loss=3.985, w2v_ctc_loss=3.308, task_loss=1.963, contrastive_loss=1.076, total=4126.49, n_correct=366.73, ppl=15.84, accuracy=8.887, wps=9526.3, ups=0.77, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.139, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=1525
2023-08-04 13:18:47 | INFO | train_inner | epoch 002:    727 / 1474 loss=5.119, trans_loss=5.282, nll_loss=3.967, w2v_ctc_loss=3.224, task_loss=1.924, contrastive_loss=1.177, total=4149.06, n_correct=376.87, ppl=15.64, accuracy=9.083, wps=19442, ups=1.57, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.124, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1588
2023-08-04 13:19:50 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.031, trans_loss=5.268, nll_loss=3.951, w2v_ctc_loss=3.155, task_loss=1.976, contrastive_loss=1.125, total=4175.4, n_correct=385.36, ppl=15.47, accuracy=9.229, wps=19644.5, ups=1.58, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=0.989, clip=0, loss_scale=128, train_wall=63, gb_free=19.8, wall=1652
2023-08-04 13:20:53 | INFO | train_inner | epoch 002:    927 / 1474 loss=4.939, trans_loss=5.255, nll_loss=3.933, w2v_ctc_loss=3.063, task_loss=2.016, contrastive_loss=1.108, total=4104.2, n_correct=382.12, ppl=15.28, accuracy=9.31, wps=19474.7, ups=1.59, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=0.992, clip=0, loss_scale=128, train_wall=62, gb_free=19, wall=1715
2023-08-04 13:21:56 | INFO | train_inner | epoch 002:   1027 / 1474 loss=4.854, trans_loss=5.247, nll_loss=3.926, w2v_ctc_loss=2.994, task_loss=1.957, contrastive_loss=0.957, total=4102.5, n_correct=388.82, ppl=15.2, accuracy=9.478, wps=19309, ups=1.58, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.87, clip=0, loss_scale=128, train_wall=63, gb_free=19.2, wall=1778
2023-08-04 13:23:01 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.811, trans_loss=5.241, nll_loss=3.917, w2v_ctc_loss=2.905, task_loss=1.781, contrastive_loss=1.17, total=4187.61, n_correct=401.34, ppl=15.11, accuracy=9.584, wps=19465.9, ups=1.56, wpb=12495.7, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.883, clip=0, loss_scale=128, train_wall=64, gb_free=19.5, wall=1842
2023-08-04 13:24:04 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.755, trans_loss=5.229, nll_loss=3.903, w2v_ctc_loss=2.863, task_loss=1.792, contrastive_loss=1.091, total=4221.06, n_correct=417.93, ppl=14.96, accuracy=9.901, wps=19842.8, ups=1.58, wpb=12596.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.792, clip=0, loss_scale=128, train_wall=63, gb_free=19.5, wall=1906
2023-08-04 13:25:07 | INFO | train_inner | epoch 002:   1327 / 1474 loss=4.662, trans_loss=5.221, nll_loss=3.897, w2v_ctc_loss=2.829, task_loss=1.888, contrastive_loss=0.798, total=4157.86, n_correct=418.96, ppl=14.89, accuracy=10.076, wps=19685.7, ups=1.58, wpb=12425.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.752, clip=0, loss_scale=128, train_wall=63, gb_free=19.5, wall=1969
2023-08-04 13:26:11 | INFO | train_inner | epoch 002:   1427 / 1474 loss=4.627, trans_loss=5.225, nll_loss=3.902, w2v_ctc_loss=2.79, task_loss=2.12, contrastive_loss=0.888, total=4054.34, n_correct=402.66, ppl=14.95, accuracy=9.932, wps=19116.4, ups=1.58, wpb=12107, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.707, clip=0, loss_scale=128, train_wall=63, gb_free=19.4, wall=2032
2023-08-04 13:26:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 13:27:21 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.158 | trans_loss 10.239 | nll_loss 9.053 | w2v_ctc_loss 3.574 | task_loss 11.32 | contrastive_loss 0.936 | total 4003.4 | n_correct 503.4 | ppl 531.09 | accuracy 12.574 | uer 51.453 | wer 50.323 | raw_wer 50.323 | bleu 0.11 | wps 1148.7 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.11
2023-08-04 13:27:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-08-04 13:27:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 13:27:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 13:27:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.11) (writing took 23.979491723701358 seconds)
2023-08-04 13:27:45 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-04 13:27:45 | INFO | train | epoch 002 | loss 5.142 | trans_loss 5.277 | nll_loss 3.962 | w2v_ctc_loss 3.252 | task_loss 1.938 | contrastive_loss 1.181 | total 4138.65 | n_correct 378.204 | ppl 15.58 | accuracy 9.138 | wps 16925.3 | ups 1.37 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.1 | clip 0 | loss_scale 128 | train_wall 930 | gb_free 19.3 | wall 2127
2023-08-04 13:27:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 13:27:46 | INFO | fairseq.trainer | begin training epoch 3
2023-08-04 13:27:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 13:28:28 | INFO | train_inner | epoch 003:     53 / 1474 loss=4.552, trans_loss=5.199, nll_loss=3.869, w2v_ctc_loss=2.729, task_loss=1.987, contrastive_loss=0.788, total=4071.2, n_correct=418.63, ppl=14.61, accuracy=10.283, wps=8869.8, ups=0.73, wpb=12154.1, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.688, clip=0, loss_scale=128, train_wall=64, gb_free=19.1, wall=2169
2023-08-04 13:28:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-04 13:28:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 13:28:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 13:28:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-04 13:28:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-04 13:30:02 | INFO | train_inner | epoch 003:    158 / 1474 loss=3.743, trans_loss=4.357, nll_loss=2.765, w2v_ctc_loss=2.407, task_loss=1.355, contrastive_loss=0.728, total=4144.18, n_correct=1179.92, ppl=6.8, accuracy=28.472, wps=13064.1, ups=1.06, wpb=12374.6, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=1.905, clip=1, loss_scale=4, train_wall=94, gb_free=16.6, wall=2264
2023-08-04 13:31:34 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.343, trans_loss=4.146, nll_loss=2.491, w2v_ctc_loss=2.152, task_loss=1.37, contrastive_loss=0.597, total=4161.13, n_correct=1444.53, ppl=5.62, accuracy=34.715, wps=13544.5, ups=1.09, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.472, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=2356
2023-08-04 13:33:06 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.252, trans_loss=4.093, nll_loss=2.418, w2v_ctc_loss=2.079, task_loss=1.38, contrastive_loss=0.65, total=4150.02, n_correct=1521.16, ppl=5.34, accuracy=36.654, wps=13456.9, ups=1.09, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.495, clip=0, loss_scale=4, train_wall=92, gb_free=17.1, wall=2448
2023-08-04 13:34:38 | INFO | train_inner | epoch 003:    458 / 1474 loss=3.132, trans_loss=4.041, nll_loss=2.35, w2v_ctc_loss=2, task_loss=1.337, contrastive_loss=0.502, total=4209.57, n_correct=1625.5, ppl=5.1, accuracy=38.614, wps=13669.6, ups=1.09, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.375, clip=0, loss_scale=4, train_wall=91, gb_free=16.1, wall=2540
2023-08-04 13:36:09 | INFO | train_inner | epoch 003:    558 / 1474 loss=3.041, trans_loss=4.014, nll_loss=2.315, w2v_ctc_loss=1.926, task_loss=1.472, contrastive_loss=0.474, total=4088.48, n_correct=1615.78, ppl=4.98, accuracy=39.52, wps=13418.9, ups=1.1, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.191, clip=0, loss_scale=4, train_wall=90, gb_free=17.7, wall=2631
2023-08-04 13:37:42 | INFO | train_inner | epoch 003:    658 / 1474 loss=2.985, trans_loss=3.976, nll_loss=2.262, w2v_ctc_loss=1.858, task_loss=1.319, contrastive_loss=0.59, total=4221.58, n_correct=1735.69, ppl=4.8, accuracy=41.115, wps=13610.3, ups=1.08, wpb=12587.8, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=1.156, clip=0, loss_scale=4, train_wall=92, gb_free=16.4, wall=2723
2023-08-04 13:39:13 | INFO | train_inner | epoch 003:    758 / 1474 loss=2.917, trans_loss=3.948, nll_loss=2.23, w2v_ctc_loss=1.836, task_loss=1.316, contrastive_loss=0.357, total=4167.41, n_correct=1749.74, ppl=4.69, accuracy=41.986, wps=13629.2, ups=1.09, wpb=12447.6, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=1.176, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=2815
2023-08-04 13:40:45 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.86, trans_loss=3.936, nll_loss=2.211, w2v_ctc_loss=1.79, task_loss=1.395, contrastive_loss=0.319, total=4165.53, n_correct=1778.25, ppl=4.63, accuracy=42.69, wps=13549.2, ups=1.09, wpb=12437.8, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=1.118, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=2906
2023-08-04 13:42:16 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.838, trans_loss=3.918, nll_loss=2.186, w2v_ctc_loss=1.769, task_loss=1.339, contrastive_loss=0.351, total=4162.3, n_correct=1821.61, ppl=4.55, accuracy=43.765, wps=13598.2, ups=1.1, wpb=12417, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=1.179, clip=0, loss_scale=4, train_wall=91, gb_free=16.8, wall=2998
2023-08-04 13:43:47 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.797, trans_loss=3.896, nll_loss=2.159, w2v_ctc_loss=1.748, task_loss=1.471, contrastive_loss=0.305, total=4069.95, n_correct=1798.64, ppl=4.47, accuracy=44.193, wps=13365.9, ups=1.1, wpb=12153.7, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=1.019, clip=0, loss_scale=4, train_wall=90, gb_free=16.3, wall=3089
2023-08-04 13:43:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 13:44:17 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.028 | trans_loss 6.417 | nll_loss 3.96 | w2v_ctc_loss 2.078 | task_loss 6.533 | contrastive_loss 0.428 | total 4003.4 | n_correct 1965.1 | ppl 15.56 | accuracy 49.086 | uer 30.313 | wer 31.058 | raw_wer 31.058 | bleu 11.21 | wps 1557.2 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 11.21
2023-08-04 13:44:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-04 13:44:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_3_4000.pt
2023-08-04 13:44:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_3_4000.pt
2023-08-04 13:44:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 11.21) (writing took 41.55976266041398 seconds)
2023-08-04 13:46:30 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.754, trans_loss=3.887, nll_loss=2.147, w2v_ctc_loss=1.705, task_loss=1.497, contrastive_loss=0.285, total=4038.49, n_correct=1806.74, ppl=4.43, accuracy=44.738, wps=7406.4, ups=0.61, wpb=12054.8, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=0.993, clip=0, loss_scale=4, train_wall=91, gb_free=16.4, wall=3251
2023-08-04 13:48:01 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.707, trans_loss=3.865, nll_loss=2.119, w2v_ctc_loss=1.669, task_loss=1.465, contrastive_loss=0.263, total=4064.31, n_correct=1851.16, ppl=4.34, accuracy=45.547, wps=13367.3, ups=1.1, wpb=12136.8, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.951, clip=0, loss_scale=4, train_wall=90, gb_free=17.3, wall=3342
2023-08-04 13:49:32 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.693, trans_loss=3.849, nll_loss=2.098, w2v_ctc_loss=1.634, task_loss=1.4, contrastive_loss=0.378, total=4134.58, n_correct=1910.72, ppl=4.28, accuracy=46.213, wps=13476.1, ups=1.09, wpb=12343.8, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.961, clip=0, loss_scale=4, train_wall=91, gb_free=17.8, wall=3434
2023-08-04 13:51:04 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.66, trans_loss=3.834, nll_loss=2.08, w2v_ctc_loss=1.611, task_loss=1.318, contrastive_loss=0.353, total=4209.94, n_correct=1970.04, ppl=4.23, accuracy=46.795, wps=13731.3, ups=1.09, wpb=12573.5, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.904, clip=0, loss_scale=4, train_wall=91, gb_free=17, wall=3525
2023-08-04 13:51:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 13:51:42 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.877 | trans_loss 6.273 | nll_loss 3.768 | w2v_ctc_loss 1.924 | task_loss 6.294 | contrastive_loss 0.392 | total 4003.4 | n_correct 2050.9 | ppl 13.62 | accuracy 51.229 | uer 29.491 | wer 29.663 | raw_wer 29.663 | bleu 12.83 | wps 2146.8 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 12.83
2023-08-04 13:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-08-04 13:51:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 13:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 13:52:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 3 @ 4416 updates, score 12.83) (writing took 24.2060732729733 seconds)
2023-08-04 13:52:06 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-04 13:52:06 | INFO | train | epoch 003 | loss 3.033 | trans_loss 4.025 | nll_loss 2.329 | w2v_ctc_loss 1.898 | task_loss 1.407 | contrastive_loss 0.455 | total 4140.05 | n_correct 1656.63 | ppl 5.03 | accuracy 40.015 | wps 12428.3 | ups 1.01 | wpb 12360.1 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 1.184 | clip 0.1 | loss_scale 4 | train_wall 1326 | gb_free 16.4 | wall 3588
2023-08-04 13:52:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 13:52:07 | INFO | fairseq.trainer | begin training epoch 4
2023-08-04 13:52:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 13:53:30 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.583, trans_loss=3.805, nll_loss=2.038, w2v_ctc_loss=1.563, task_loss=1.432, contrastive_loss=0.21, total=4099.41, n_correct=1960.22, ppl=4.11, accuracy=47.817, wps=8370.6, ups=0.68, wpb=12237, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.894, clip=0, loss_scale=4, train_wall=90, gb_free=16.3, wall=3672
2023-08-04 13:55:00 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.56, trans_loss=3.783, nll_loss=2.011, w2v_ctc_loss=1.539, task_loss=1.325, contrastive_loss=0.234, total=4175.15, n_correct=2028.68, ppl=4.03, accuracy=48.589, wps=13847.8, ups=1.11, wpb=12464.9, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.865, clip=0, loss_scale=4, train_wall=90, gb_free=16.6, wall=3762
2023-08-04 13:56:31 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.573, trans_loss=3.785, nll_loss=2.016, w2v_ctc_loss=1.537, task_loss=1.39, contrastive_loss=0.36, total=4145.23, n_correct=2012.96, ppl=4.04, accuracy=48.561, wps=13581.7, ups=1.1, wpb=12382.4, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.856, clip=0, loss_scale=4, train_wall=91, gb_free=15.9, wall=3853
2023-08-04 13:58:02 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.536, trans_loss=3.786, nll_loss=2.014, w2v_ctc_loss=1.52, task_loss=1.45, contrastive_loss=0.204, total=4127.66, n_correct=2013.22, ppl=4.04, accuracy=48.774, wps=13527.2, ups=1.1, wpb=12314.6, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.856, clip=0, loss_scale=4, train_wall=91, gb_free=17.4, wall=3944
2023-08-04 13:59:34 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.566, trans_loss=3.767, nll_loss=1.992, w2v_ctc_loss=1.488, task_loss=1.259, contrastive_loss=0.605, total=4218.78, n_correct=2084.3, ppl=3.98, accuracy=49.405, wps=13641.5, ups=1.08, wpb=12592.4, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.889, clip=0, loss_scale=4, train_wall=92, gb_free=16.5, wall=4036
2023-08-04 14:01:06 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.52, trans_loss=3.759, nll_loss=1.982, w2v_ctc_loss=1.502, task_loss=1.31, contrastive_loss=0.278, total=4217.52, n_correct=2103.79, ppl=3.95, accuracy=49.882, wps=13761.3, ups=1.09, wpb=12591.1, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.85, clip=0, loss_scale=4, train_wall=91, gb_free=16, wall=4128
mt_weight tensor(0.5000)
asr_weight tensor(0.4737, device='cuda:0')
2023-08-04 14:02:39 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.49, trans_loss=3.764, nll_loss=1.983, w2v_ctc_loss=1.463, task_loss=1.427, contrastive_loss=0.321, total=4176.39, n_correct=2093.16, ppl=3.95, accuracy=50.119, wps=13419.3, ups=1.08, wpb=12448.9, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.55, clip=0, loss_scale=8, train_wall=92, gb_free=17.1, wall=4220
2023-08-04 14:04:10 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.479, trans_loss=3.755, nll_loss=1.976, w2v_ctc_loss=1.482, task_loss=1.534, contrastive_loss=0.193, total=4026.63, n_correct=2025.32, ppl=3.93, accuracy=50.298, wps=13205.8, ups=1.1, wpb=12025, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.568, clip=0, loss_scale=8, train_wall=91, gb_free=13.1, wall=4311
2023-08-04 14:05:42 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.492, trans_loss=3.737, nll_loss=1.955, w2v_ctc_loss=1.469, task_loss=1.387, contrastive_loss=0.37, total=4186.04, n_correct=2121.76, ppl=3.88, accuracy=50.687, wps=13536.7, ups=1.08, wpb=12501.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.552, clip=0, loss_scale=8, train_wall=92, gb_free=17.7, wall=4404
2023-08-04 14:07:14 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.448, trans_loss=3.728, nll_loss=1.945, w2v_ctc_loss=1.447, task_loss=1.412, contrastive_loss=0.239, total=4125.02, n_correct=2110.55, ppl=3.85, accuracy=51.165, wps=13470.6, ups=1.09, wpb=12321, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.531, clip=0, loss_scale=8, train_wall=91, gb_free=12.7, wall=4495
2023-08-04 14:08:45 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.449, trans_loss=3.737, nll_loss=1.953, w2v_ctc_loss=1.452, task_loss=1.503, contrastive_loss=0.213, total=4075.6, n_correct=2081.43, ppl=3.87, accuracy=51.071, wps=13294.3, ups=1.09, wpb=12163.4, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.529, clip=0, loss_scale=8, train_wall=91, gb_free=16, wall=4587
2023-08-04 14:10:16 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.454, trans_loss=3.724, nll_loss=1.942, w2v_ctc_loss=1.441, task_loss=1.308, contrastive_loss=0.326, total=4161.18, n_correct=2140.5, ppl=3.84, accuracy=51.44, wps=13669.2, ups=1.1, wpb=12431.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.525, clip=0, loss_scale=8, train_wall=90, gb_free=16.8, wall=4678
2023-08-04 14:11:48 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.424, trans_loss=3.712, nll_loss=1.924, w2v_ctc_loss=1.419, task_loss=1.328, contrastive_loss=0.29, total=4156.53, n_correct=2161.66, ppl=3.79, accuracy=52.006, wps=13498.6, ups=1.09, wpb=12411.4, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.517, clip=0, loss_scale=8, train_wall=91, gb_free=15.8, wall=4770
2023-08-04 14:13:18 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.399, trans_loss=3.713, nll_loss=1.925, w2v_ctc_loss=1.417, task_loss=1.428, contrastive_loss=0.169, total=4101.23, n_correct=2133.53, ppl=3.8, accuracy=52.022, wps=13643.5, ups=1.11, wpb=12249, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.513, clip=0, loss_scale=8, train_wall=89, gb_free=15.6, wall=4859
2023-08-04 14:14:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4737, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4737, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.4737, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4737, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4737, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4737, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4737, device='cuda:2')
2023-08-04 14:15:03 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.521 | trans_loss 5.917 | nll_loss 3.291 | w2v_ctc_loss 1.588 | task_loss 6.676 | contrastive_loss 0.307 | total 4003.4 | n_correct 2257 | ppl 9.79 | accuracy 56.377 | uer 23.433 | wer 25.044 | raw_wer 25.044 | bleu 16.37 | wps 2149.1 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 16.37
2023-08-04 14:15:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-08-04 14:15:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 14:15:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 14:15:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 4 @ 5890 updates, score 16.37) (writing took 24.63575667142868 seconds)
2023-08-04 14:15:28 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-04 14:15:28 | INFO | train | epoch 004 | loss 2.49 | trans_loss 3.75 | nll_loss 1.971 | w2v_ctc_loss 1.475 | task_loss 1.391 | contrastive_loss 0.286 | total 4138.65 | n_correct 2081.37 | ppl 3.92 | accuracy 50.291 | wps 12997.7 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.666 | clip 0 | loss_scale 8 | train_wall 1339 | gb_free 14.8 | wall 4989
2023-08-04 14:15:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 14:15:28 | INFO | fairseq.trainer | begin training epoch 5
2023-08-04 14:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 14:15:45 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.379, trans_loss=3.702, nll_loss=1.91, w2v_ctc_loss=1.389, task_loss=1.447, contrastive_loss=0.188, total=4037.7, n_correct=2116.95, ppl=3.76, accuracy=52.43, wps=8181.6, ups=0.68, wpb=12055.9, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.516, clip=0, loss_scale=8, train_wall=90, gb_free=16.9, wall=5007
2023-08-04 14:17:17 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.305, trans_loss=3.647, nll_loss=1.839, w2v_ctc_loss=1.314, task_loss=1.258, contrastive_loss=0.196, total=4247.37, n_correct=2299.64, ppl=3.58, accuracy=54.143, wps=13842.7, ups=1.09, wpb=12683.4, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.493, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=5098
2023-08-04 14:17:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 14:17:40 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.517 | trans_loss 5.918 | nll_loss 3.291 | w2v_ctc_loss 1.566 | task_loss 6.653 | contrastive_loss 0.319 | total 4003.4 | n_correct 2249.7 | ppl 9.79 | accuracy 56.195 | uer 23.473 | wer 25.159 | raw_wer 25.159 | bleu 16.22 | wps 2122.6 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.37
2023-08-04 14:17:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-04 14:17:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_5_6000.pt
2023-08-04 14:17:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_5_6000.pt
2023-08-04 14:18:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.22) (writing took 20.53900253586471 seconds)
2023-08-04 14:19:32 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.342, trans_loss=3.659, nll_loss=1.852, w2v_ctc_loss=1.327, task_loss=1.288, contrastive_loss=0.412, total=4189.85, n_correct=2259.33, ppl=3.61, accuracy=53.924, wps=9267.8, ups=0.74, wpb=12500.5, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.497, clip=0, loss_scale=8, train_wall=90, gb_free=17.8, wall=5233
2023-08-04 14:21:02 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.33, trans_loss=3.653, nll_loss=1.849, w2v_ctc_loss=1.343, task_loss=1.433, contrastive_loss=0.26, total=4090.1, n_correct=2198.21, ppl=3.6, accuracy=53.745, wps=13554.1, ups=1.11, wpb=12228.1, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.508, clip=0, loss_scale=8, train_wall=90, gb_free=16.2, wall=5324
2023-08-04 14:22:33 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.325, trans_loss=3.646, nll_loss=1.841, w2v_ctc_loss=1.314, task_loss=1.347, contrastive_loss=0.356, total=4147.17, n_correct=2247.4, ppl=3.58, accuracy=54.191, wps=13577.7, ups=1.1, wpb=12395.1, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.513, clip=0, loss_scale=8, train_wall=91, gb_free=14.8, wall=5415
2023-08-04 14:24:04 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.298, trans_loss=3.658, nll_loss=1.854, w2v_ctc_loss=1.325, task_loss=1.568, contrastive_loss=0.141, total=4026.81, n_correct=2169.05, ppl=3.61, accuracy=53.865, wps=13255.7, ups=1.1, wpb=12029.7, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.5, clip=0, loss_scale=8, train_wall=90, gb_free=17.4, wall=5506
2023-08-04 14:25:36 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.315, trans_loss=3.661, nll_loss=1.855, w2v_ctc_loss=1.31, task_loss=1.43, contrastive_loss=0.312, total=4107.75, n_correct=2215.83, ppl=3.62, accuracy=53.943, wps=13340.5, ups=1.09, wpb=12253.8, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.515, clip=0, loss_scale=8, train_wall=91, gb_free=16.1, wall=5597
2023-08-04 14:27:07 | INFO | train_inner | epoch 005:    710 / 1474 loss=2.309, trans_loss=3.653, nll_loss=1.848, w2v_ctc_loss=1.305, task_loss=1.32, contrastive_loss=0.292, total=4178.85, n_correct=2271.75, ppl=3.6, accuracy=54.363, wps=13678.9, ups=1.1, wpb=12473.1, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.494, clip=0, loss_scale=8, train_wall=91, gb_free=17.7, wall=5689
2023-08-04 14:28:39 | INFO | train_inner | epoch 005:    810 / 1474 loss=2.29, trans_loss=3.652, nll_loss=1.845, w2v_ctc_loss=1.3, task_loss=1.434, contrastive_loss=0.215, total=4127.73, n_correct=2245.85, ppl=3.59, accuracy=54.409, wps=13421.9, ups=1.09, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.494, clip=0, loss_scale=8, train_wall=91, gb_free=15.1, wall=5780
2023-08-04 14:30:10 | INFO | train_inner | epoch 005:    910 / 1474 loss=2.273, trans_loss=3.643, nll_loss=1.836, w2v_ctc_loss=1.294, task_loss=1.441, contrastive_loss=0.176, total=4095.48, n_correct=2236.34, ppl=3.57, accuracy=54.605, wps=13452.3, ups=1.1, wpb=12229.5, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.499, clip=0, loss_scale=8, train_wall=90, gb_free=15.6, wall=5871
2023-08-04 14:31:40 | INFO | train_inner | epoch 005:   1010 / 1474 loss=2.282, trans_loss=3.645, nll_loss=1.837, w2v_ctc_loss=1.293, task_loss=1.378, contrastive_loss=0.258, total=4165.12, n_correct=2278.39, ppl=3.57, accuracy=54.702, wps=13742.7, ups=1.11, wpb=12433.6, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.489, clip=0, loss_scale=8, train_wall=90, gb_free=15.6, wall=5962
2023-08-04 14:33:12 | INFO | train_inner | epoch 005:   1110 / 1474 loss=2.295, trans_loss=3.647, nll_loss=1.84, w2v_ctc_loss=1.302, task_loss=1.38, contrastive_loss=0.261, total=4176.72, n_correct=2286.42, ppl=3.58, accuracy=54.742, wps=13558.6, ups=1.09, wpb=12459.2, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.498, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=6054
2023-08-04 14:34:44 | INFO | train_inner | epoch 005:   1210 / 1474 loss=2.255, trans_loss=3.642, nll_loss=1.832, w2v_ctc_loss=1.274, task_loss=1.421, contrastive_loss=0.163, total=4164.13, n_correct=2289.02, ppl=3.56, accuracy=54.97, wps=13519.3, ups=1.09, wpb=12420.9, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.495, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=6146
2023-08-04 14:36:15 | INFO | train_inner | epoch 005:   1310 / 1474 loss=2.246, trans_loss=3.641, nll_loss=1.833, w2v_ctc_loss=1.267, task_loss=1.419, contrastive_loss=0.134, total=4134.91, n_correct=2272.5, ppl=3.56, accuracy=54.959, wps=13529.4, ups=1.1, wpb=12341.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.487, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=6237
2023-08-04 14:37:46 | INFO | train_inner | epoch 005:   1410 / 1474 loss=2.249, trans_loss=3.64, nll_loss=1.834, w2v_ctc_loss=1.261, task_loss=1.407, contrastive_loss=0.196, total=4134.37, n_correct=2274.83, ppl=3.56, accuracy=55.022, wps=13554.9, ups=1.1, wpb=12347.5, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.487, clip=0, loss_scale=16, train_wall=91, gb_free=17.8, wall=6328
2023-08-04 14:38:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 14:39:09 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.42 | trans_loss 5.834 | nll_loss 3.189 | w2v_ctc_loss 1.423 | task_loss 6.705 | contrastive_loss 0.333 | total 4003.4 | n_correct 2307.7 | ppl 9.12 | accuracy 57.644 | uer 22.47 | wer 24.004 | raw_wer 24.004 | bleu 17.29 | wps 2110.3 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 17.29
2023-08-04 14:39:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-08-04 14:39:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 14:39:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 14:39:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 5 @ 7364 updates, score 17.29) (writing took 24.304340679198503 seconds)
2023-08-04 14:39:33 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-04 14:39:33 | INFO | train | epoch 005 | loss 2.293 | trans_loss 3.648 | nll_loss 1.842 | w2v_ctc_loss 1.301 | task_loss 1.393 | contrastive_loss 0.241 | total 4138.65 | n_correct 2252.37 | ppl 3.58 | accuracy 54.423 | wps 12599.6 | ups 1.02 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.498 | clip 0 | loss_scale 16 | train_wall 1337 | gb_free 16.2 | wall 6435
2023-08-04 14:39:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 14:39:33 | INFO | fairseq.trainer | begin training epoch 6
2023-08-04 14:39:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 14:40:14 | INFO | train_inner | epoch 006:     36 / 1474 loss=2.235, trans_loss=3.616, nll_loss=1.8, w2v_ctc_loss=1.255, task_loss=1.432, contrastive_loss=0.193, total=4115.45, n_correct=2288.26, ppl=3.48, accuracy=55.602, wps=8288.3, ups=0.67, wpb=12281.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.495, clip=0, loss_scale=16, train_wall=91, gb_free=16.4, wall=6476
2023-08-04 14:41:45 | INFO | train_inner | epoch 006:    136 / 1474 loss=2.194, trans_loss=3.586, nll_loss=1.763, w2v_ctc_loss=1.209, task_loss=1.389, contrastive_loss=0.238, total=4154.25, n_correct=2336.04, ppl=3.39, accuracy=56.233, wps=13649.1, ups=1.1, wpb=12407.4, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.485, clip=0, loss_scale=16, train_wall=90, gb_free=15.5, wall=6567
2023-08-04 14:43:17 | INFO | train_inner | epoch 006:    236 / 1474 loss=2.204, trans_loss=3.596, nll_loss=1.777, w2v_ctc_loss=1.238, task_loss=1.495, contrastive_loss=0.145, total=4112.66, n_correct=2303.53, ppl=3.43, accuracy=56.011, wps=13436.6, ups=1.09, wpb=12287.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.484, clip=0, loss_scale=16, train_wall=91, gb_free=16.1, wall=6659
2023-08-04 14:44:49 | INFO | train_inner | epoch 006:    336 / 1474 loss=2.215, trans_loss=3.583, nll_loss=1.761, w2v_ctc_loss=1.188, task_loss=1.296, contrastive_loss=0.451, total=4177.51, n_correct=2361.44, ppl=3.39, accuracy=56.527, wps=13493.5, ups=1.08, wpb=12473.8, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.489, clip=0, loss_scale=16, train_wall=92, gb_free=16, wall=6751
2023-08-04 14:46:20 | INFO | train_inner | epoch 006:    436 / 1474 loss=2.174, trans_loss=3.588, nll_loss=1.766, w2v_ctc_loss=1.198, task_loss=1.341, contrastive_loss=0.159, total=4154.57, n_correct=2351.99, ppl=3.4, accuracy=56.612, wps=13706.6, ups=1.1, wpb=12405.5, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.483, clip=0, loss_scale=16, train_wall=90, gb_free=16.1, wall=6841
2023-08-04 14:47:51 | INFO | train_inner | epoch 006:    536 / 1474 loss=2.186, trans_loss=3.596, nll_loss=1.775, w2v_ctc_loss=1.216, task_loss=1.402, contrastive_loss=0.148, total=4167.79, n_correct=2356.35, ppl=3.42, accuracy=56.537, wps=13666.7, ups=1.1, wpb=12438.5, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.494, clip=0, loss_scale=16, train_wall=91, gb_free=15.7, wall=6932
2023-08-04 14:49:22 | INFO | train_inner | epoch 006:    636 / 1474 loss=2.181, trans_loss=3.597, nll_loss=1.778, w2v_ctc_loss=1.194, task_loss=1.322, contrastive_loss=0.205, total=4146.17, n_correct=2340.18, ppl=3.43, accuracy=56.442, wps=13581.7, ups=1.1, wpb=12376.6, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.499, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=7024
2023-08-04 14:49:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 14:49:45 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.386 | trans_loss 5.78 | nll_loss 3.114 | w2v_ctc_loss 1.453 | task_loss 6.75 | contrastive_loss 0.308 | total 4003.4 | n_correct 2340.9 | ppl 8.66 | accuracy 58.473 | uer 21.384 | wer 23.153 | raw_wer 23.153 | bleu 17.72 | wps 2182.2 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.72
2023-08-04 14:49:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-04 14:49:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_6_8000.pt
2023-08-04 14:49:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_6_8000.pt
2023-08-04 14:50:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.72) (writing took 46.5371609646827 seconds)
2023-08-04 14:52:03 | INFO | train_inner | epoch 006:    736 / 1474 loss=2.184, trans_loss=3.597, nll_loss=1.778, w2v_ctc_loss=1.211, task_loss=1.427, contrastive_loss=0.158, total=4148.65, n_correct=2343.24, ppl=3.43, accuracy=56.482, wps=7678, ups=0.62, wpb=12388, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.48, clip=0, loss_scale=16, train_wall=91, gb_free=15.5, wall=7185
2023-08-04 14:53:34 | INFO | train_inner | epoch 006:    836 / 1474 loss=2.179, trans_loss=3.606, nll_loss=1.789, w2v_ctc_loss=1.204, task_loss=1.465, contrastive_loss=0.14, total=4114.34, n_correct=2315.22, ppl=3.46, accuracy=56.272, wps=13502, ups=1.1, wpb=12282.2, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.48, clip=0, loss_scale=16, train_wall=90, gb_free=15, wall=7276
2023-08-04 14:55:05 | INFO | train_inner | epoch 006:    936 / 1474 loss=2.195, trans_loss=3.605, nll_loss=1.788, w2v_ctc_loss=1.206, task_loss=1.452, contrastive_loss=0.236, total=4081.53, n_correct=2298.95, ppl=3.45, accuracy=56.326, wps=13363.1, ups=1.1, wpb=12181.3, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.497, clip=0, loss_scale=16, train_wall=91, gb_free=17.8, wall=7367
2023-08-04 14:56:38 | INFO | train_inner | epoch 006:   1036 / 1474 loss=2.186, trans_loss=3.591, nll_loss=1.772, w2v_ctc_loss=1.187, task_loss=1.322, contrastive_loss=0.314, total=4165.84, n_correct=2357.3, ppl=3.41, accuracy=56.586, wps=13507, ups=1.09, wpb=12435.7, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.496, clip=0, loss_scale=16, train_wall=92, gb_free=16.8, wall=7459
2023-08-04 14:58:09 | INFO | train_inner | epoch 006:   1136 / 1474 loss=2.177, trans_loss=3.598, nll_loss=1.78, w2v_ctc_loss=1.205, task_loss=1.543, contrastive_loss=0.142, total=4072.29, n_correct=2298.22, ppl=3.43, accuracy=56.436, wps=13338.4, ups=1.1, wpb=12157.6, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.498, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=7550
2023-08-04 14:59:40 | INFO | train_inner | epoch 006:   1236 / 1474 loss=2.205, trans_loss=3.587, nll_loss=1.77, w2v_ctc_loss=1.186, task_loss=1.353, contrastive_loss=0.459, total=4141.55, n_correct=2349.79, ppl=3.41, accuracy=56.737, wps=13544.1, ups=1.09, wpb=12370.9, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.501, clip=0, loss_scale=16, train_wall=91, gb_free=13.1, wall=7642
2023-08-04 15:01:10 | INFO | train_inner | epoch 006:   1336 / 1474 loss=2.154, trans_loss=3.595, nll_loss=1.775, w2v_ctc_loss=1.182, task_loss=1.391, contrastive_loss=0.128, total=4125.31, n_correct=2347.49, ppl=3.42, accuracy=56.905, wps=13633.8, ups=1.11, wpb=12305, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.48, clip=0, loss_scale=16, train_wall=90, gb_free=17.8, wall=7732
2023-08-04 15:02:43 | INFO | train_inner | epoch 006:   1436 / 1474 loss=2.152, trans_loss=3.588, nll_loss=1.768, w2v_ctc_loss=1.181, task_loss=1.393, contrastive_loss=0.135, total=4196.2, n_correct=2392.72, ppl=3.41, accuracy=57.021, wps=13565.8, ups=1.08, wpb=12525.2, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.47, clip=0, loss_scale=16, train_wall=92, gb_free=11.2, wall=7824
2023-08-04 15:03:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 15:03:39 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.329 | trans_loss 5.733 | nll_loss 3.057 | w2v_ctc_loss 1.382 | task_loss 6.831 | contrastive_loss 0.28 | total 4003.4 | n_correct 2370.2 | ppl 8.32 | accuracy 59.205 | uer 20.282 | wer 21.89 | raw_wer 21.89 | bleu 18.37 | wps 2196.4 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 18.37
2023-08-04 15:03:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-08-04 15:03:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 15:03:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 15:04:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 6 @ 8838 updates, score 18.37) (writing took 24.769489439204335 seconds)
2023-08-04 15:04:04 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-04 15:04:04 | INFO | train | epoch 006 | loss 2.184 | trans_loss 3.593 | nll_loss 1.774 | w2v_ctc_loss 1.2 | task_loss 1.395 | contrastive_loss 0.218 | total 4138.65 | n_correct 2339.4 | ppl 3.42 | accuracy 56.526 | wps 12378.3 | ups 1 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.488 | clip 0 | loss_scale 16 | train_wall 1339 | gb_free 15.1 | wall 7906
2023-08-04 15:04:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 15:04:05 | INFO | fairseq.trainer | begin training epoch 7
2023-08-04 15:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 15:05:09 | INFO | train_inner | epoch 007:     62 / 1474 loss=2.123, trans_loss=3.564, nll_loss=1.737, w2v_ctc_loss=1.154, task_loss=1.359, contrastive_loss=0.151, total=4108.19, n_correct=2367.05, ppl=3.33, accuracy=57.618, wps=8380, ups=0.68, wpb=12266.6, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.48, clip=0, loss_scale=16, train_wall=90, gb_free=17.1, wall=7971
2023-08-04 15:06:39 | INFO | train_inner | epoch 007:    162 / 1474 loss=2.118, trans_loss=3.553, nll_loss=1.722, w2v_ctc_loss=1.136, task_loss=1.416, contrastive_loss=0.224, total=4106.05, n_correct=2378.99, ppl=3.3, accuracy=57.939, wps=13597.5, ups=1.11, wpb=12258.7, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.478, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=8061
2023-08-04 15:08:09 | INFO | train_inner | epoch 007:    262 / 1474 loss=2.105, trans_loss=3.548, nll_loss=1.714, w2v_ctc_loss=1.142, task_loss=1.413, contrastive_loss=0.13, total=4129.3, n_correct=2402.48, ppl=3.28, accuracy=58.181, wps=13666.3, ups=1.11, wpb=12322.8, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.471, clip=0, loss_scale=16, train_wall=90, gb_free=17.3, wall=8151
2023-08-04 15:09:42 | INFO | train_inner | epoch 007:    362 / 1474 loss=2.137, trans_loss=3.558, nll_loss=1.728, w2v_ctc_loss=1.13, task_loss=1.345, contrastive_loss=0.391, total=4201.67, n_correct=2427.24, ppl=3.31, accuracy=57.768, wps=13534.5, ups=1.08, wpb=12539.8, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.466, clip=0, loss_scale=32, train_wall=92, gb_free=15.4, wall=8244
2023-08-04 15:11:13 | INFO | train_inner | epoch 007:    462 / 1474 loss=2.125, trans_loss=3.558, nll_loss=1.731, w2v_ctc_loss=1.128, task_loss=1.37, contrastive_loss=0.313, total=4155.31, n_correct=2399.84, ppl=3.32, accuracy=57.754, wps=13651.3, ups=1.1, wpb=12410.9, bsz=465.5, num_updates=9300, lr=0.000146647, gnorm=0.478, clip=0, loss_scale=32, train_wall=90, gb_free=16.7, wall=8335
2023-08-04 15:12:43 | INFO | train_inner | epoch 007:    562 / 1474 loss=2.104, trans_loss=3.559, nll_loss=1.728, w2v_ctc_loss=1.132, task_loss=1.369, contrastive_loss=0.138, total=4165.88, n_correct=2414.79, ppl=3.31, accuracy=57.966, wps=13771.6, ups=1.11, wpb=12426.4, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.477, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=8425
2023-08-04 15:14:14 | INFO | train_inner | epoch 007:    662 / 1474 loss=2.093, trans_loss=3.556, nll_loss=1.725, w2v_ctc_loss=1.126, task_loss=1.401, contrastive_loss=0.122, total=4149.29, n_correct=2410.54, ppl=3.31, accuracy=58.095, wps=13573, ups=1.1, wpb=12381.3, bsz=451.6, num_updates=9500, lr=0.000145095, gnorm=0.472, clip=0, loss_scale=32, train_wall=91, gb_free=17, wall=8516
2023-08-04 15:15:47 | INFO | train_inner | epoch 007:    762 / 1474 loss=2.097, trans_loss=3.551, nll_loss=1.721, w2v_ctc_loss=1.13, task_loss=1.448, contrastive_loss=0.124, total=4134.54, n_correct=2405.03, ppl=3.3, accuracy=58.169, wps=13381.4, ups=1.08, wpb=12345.4, bsz=449.8, num_updates=9600, lr=0.000144338, gnorm=0.479, clip=0, loss_scale=32, train_wall=92, gb_free=13.8, wall=8608
2023-08-04 15:17:18 | INFO | train_inner | epoch 007:    862 / 1474 loss=2.099, trans_loss=3.561, nll_loss=1.733, w2v_ctc_loss=1.128, task_loss=1.401, contrastive_loss=0.143, total=4151.77, n_correct=2404.73, ppl=3.32, accuracy=57.921, wps=13515.3, ups=1.09, wpb=12391.6, bsz=461.9, num_updates=9700, lr=0.000143592, gnorm=0.473, clip=0, loss_scale=32, train_wall=91, gb_free=14.8, wall=8700
2023-08-04 15:18:50 | INFO | train_inner | epoch 007:    962 / 1474 loss=2.103, trans_loss=3.555, nll_loss=1.727, w2v_ctc_loss=1.114, task_loss=1.343, contrastive_loss=0.237, total=4124.8, n_correct=2392.79, ppl=3.31, accuracy=58.01, wps=13494.8, ups=1.1, wpb=12313.3, bsz=471.2, num_updates=9800, lr=0.000142857, gnorm=0.472, clip=0, loss_scale=32, train_wall=91, gb_free=16.5, wall=8791
2023-08-04 15:20:20 | INFO | train_inner | epoch 007:   1062 / 1474 loss=2.096, trans_loss=3.567, nll_loss=1.742, w2v_ctc_loss=1.128, task_loss=1.456, contrastive_loss=0.108, total=4113.08, n_correct=2379.8, ppl=3.34, accuracy=57.859, wps=13529.5, ups=1.1, wpb=12279.6, bsz=439.4, num_updates=9900, lr=0.000142134, gnorm=0.471, clip=0, loss_scale=32, train_wall=90, gb_free=14.7, wall=8882
2023-08-04 15:21:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 15:21:53 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.116, trans_loss=3.55, nll_loss=1.724, w2v_ctc_loss=1.118, task_loss=1.397, contrastive_loss=0.315, total=4112.66, n_correct=2392.45, ppl=3.3, accuracy=58.173, wps=13283, ups=1.08, wpb=12289.5, bsz=460.2, num_updates=10000, lr=0.000141421, gnorm=0.479, clip=0, loss_scale=16, train_wall=92, gb_free=15.9, wall=8974
2023-08-04 15:21:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 15:22:16 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.299 | trans_loss 5.684 | nll_loss 2.998 | w2v_ctc_loss 1.393 | task_loss 6.89 | contrastive_loss 0.282 | total 4003.4 | n_correct 2393.9 | ppl 7.99 | accuracy 59.797 | uer 19.356 | wer 21.043 | raw_wer 21.043 | bleu 18.81 | wps 2015.6 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.81
2023-08-04 15:22:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-04 15:22:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_7_10000.pt
2023-08-04 15:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_7_10000.pt
2023-08-04 15:22:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.81) (writing took 23.873143227770925 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:0')
2023-08-04 15:24:12 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.085, trans_loss=3.558, nll_loss=1.732, w2v_ctc_loss=1.113, task_loss=1.413, contrastive_loss=0.135, total=4129.52, n_correct=2398.77, ppl=3.32, accuracy=58.088, wps=8878.9, ups=0.72, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.388, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=9113
2023-08-04 15:25:42 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.099, trans_loss=3.551, nll_loss=1.723, w2v_ctc_loss=1.124, task_loss=1.313, contrastive_loss=0.172, total=4172.87, n_correct=2435.23, ppl=3.3, accuracy=58.359, wps=13790.8, ups=1.11, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.393, clip=0, loss_scale=16, train_wall=90, gb_free=17.2, wall=9204
2023-08-04 15:27:15 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.106, trans_loss=3.556, nll_loss=1.732, w2v_ctc_loss=1.121, task_loss=1.506, contrastive_loss=0.237, total=4109.42, n_correct=2383.52, ppl=3.32, accuracy=58.001, wps=13218.5, ups=1.08, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.398, clip=0, loss_scale=16, train_wall=92, gb_free=16.4, wall=9297
2023-08-04 15:27:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:5')
2023-08-04 15:27:48 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.284 | trans_loss 5.69 | nll_loss 3 | w2v_ctc_loss 1.327 | task_loss 6.862 | contrastive_loss 0.283 | total 4003.4 | n_correct 2391.9 | ppl 8 | accuracy 59.747 | uer 19.698 | wer 21.479 | raw_wer 21.479 | bleu 18.85 | wps 2151.7 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.85
2023-08-04 15:27:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-08-04 15:27:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 15:28:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 15:28:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 7 @ 10311 updates, score 18.85) (writing took 24.59321708418429 seconds)
2023-08-04 15:28:13 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-04 15:28:14 | INFO | train | epoch 007 | loss 2.106 | trans_loss 3.555 | nll_loss 1.727 | w2v_ctc_loss 1.127 | task_loss 1.399 | contrastive_loss 0.198 | total 4137.22 | n_correct 2400.44 | ppl 3.31 | accuracy 58.021 | wps 12556.1 | ups 1.02 | wpb 12351.6 | bsz 457.8 | num_updates 10311 | lr 0.000139272 | gnorm 0.458 | clip 0 | loss_scale 16 | train_wall 1338 | gb_free 13.1 | wall 9355
2023-08-04 15:28:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 15:28:14 | INFO | fairseq.trainer | begin training epoch 8
2023-08-04 15:28:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 15:29:43 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.053, trans_loss=3.533, nll_loss=1.694, w2v_ctc_loss=1.084, task_loss=1.473, contrastive_loss=0.131, total=4116.25, n_correct=2424.28, ppl=3.23, accuracy=58.895, wps=8288.6, ups=0.68, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.393, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=9445
2023-08-04 15:31:13 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.051, trans_loss=3.524, nll_loss=1.682, w2v_ctc_loss=1.079, task_loss=1.513, contrastive_loss=0.15, total=4037.23, n_correct=2384.77, ppl=3.21, accuracy=59.069, wps=13326, ups=1.11, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.397, clip=0, loss_scale=16, train_wall=90, gb_free=12.6, wall=9535
2023-08-04 15:32:44 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.049, trans_loss=3.52, nll_loss=1.681, w2v_ctc_loss=1.078, task_loss=1.31, contrastive_loss=0.15, total=4207.78, n_correct=2489.72, ppl=3.21, accuracy=59.169, wps=13786.3, ups=1.1, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.393, clip=0, loss_scale=16, train_wall=91, gb_free=12.8, wall=9626
2023-08-04 15:34:16 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.068, trans_loss=3.53, nll_loss=1.692, w2v_ctc_loss=1.098, task_loss=1.49, contrastive_loss=0.173, total=4127.24, n_correct=2427.68, ppl=3.23, accuracy=58.821, wps=13411.1, ups=1.09, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.396, clip=0, loss_scale=16, train_wall=91, gb_free=11.6, wall=9718
2023-08-04 15:35:49 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.093, trans_loss=3.523, nll_loss=1.687, w2v_ctc_loss=1.072, task_loss=1.25, contrastive_loss=0.434, total=4203.76, n_correct=2483.56, ppl=3.22, accuracy=59.079, wps=13502.7, ups=1.08, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.4, clip=0, loss_scale=16, train_wall=92, gb_free=14.5, wall=9811
2023-08-04 15:37:20 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.058, trans_loss=3.527, nll_loss=1.694, w2v_ctc_loss=1.098, task_loss=1.526, contrastive_loss=0.106, total=4062.5, n_correct=2386.34, ppl=3.23, accuracy=58.741, wps=13334.1, ups=1.1, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.398, clip=0, loss_scale=16, train_wall=91, gb_free=11.1, wall=9902
2023-08-04 15:38:51 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.048, trans_loss=3.522, nll_loss=1.684, w2v_ctc_loss=1.089, task_loss=1.439, contrastive_loss=0.117, total=4142.78, n_correct=2453.74, ppl=3.21, accuracy=59.229, wps=13599.4, ups=1.1, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.394, clip=0, loss_scale=16, train_wall=90, gb_free=15.8, wall=9993
2023-08-04 15:40:22 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.057, trans_loss=3.523, nll_loss=1.69, w2v_ctc_loss=1.082, task_loss=1.432, contrastive_loss=0.202, total=4118.9, n_correct=2429.13, ppl=3.23, accuracy=58.975, wps=13546.2, ups=1.1, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.394, clip=0, loss_scale=16, train_wall=90, gb_free=15.1, wall=10084
2023-08-04 15:41:54 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.052, trans_loss=3.524, nll_loss=1.69, w2v_ctc_loss=1.071, task_loss=1.342, contrastive_loss=0.212, total=4169.01, n_correct=2468.13, ppl=3.23, accuracy=59.202, wps=13586, ups=1.09, wpb=12452.5, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.393, clip=0, loss_scale=16, train_wall=91, gb_free=16, wall=10175
2023-08-04 15:43:24 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.035, trans_loss=3.525, nll_loss=1.689, w2v_ctc_loss=1.07, task_loss=1.339, contrastive_loss=0.114, total=4154.69, n_correct=2461.28, ppl=3.23, accuracy=59.241, wps=13752.8, ups=1.11, wpb=12403.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.391, clip=0, loss_scale=16, train_wall=90, gb_free=17.7, wall=10266
2023-08-04 15:44:56 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.07, trans_loss=3.532, nll_loss=1.699, w2v_ctc_loss=1.072, task_loss=1.39, contrastive_loss=0.343, total=4199.1, n_correct=2473.37, ppl=3.25, accuracy=58.902, wps=13647.9, ups=1.09, wpb=12534.3, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.397, clip=0, loss_scale=16, train_wall=91, gb_free=12.5, wall=10358
2023-08-04 15:46:27 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.043, trans_loss=3.523, nll_loss=1.689, w2v_ctc_loss=1.075, task_loss=1.322, contrastive_loss=0.123, total=4177.31, n_correct=2473.76, ppl=3.22, accuracy=59.219, wps=13728.2, ups=1.1, wpb=12476.3, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.388, clip=0, loss_scale=16, train_wall=90, gb_free=14.8, wall=10448
2023-08-04 15:47:57 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.052, trans_loss=3.529, nll_loss=1.697, w2v_ctc_loss=1.086, task_loss=1.46, contrastive_loss=0.145, total=4063.85, n_correct=2394.85, ppl=3.24, accuracy=58.931, wps=13393.2, ups=1.1, wpb=12140.6, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.394, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=10539
2023-08-04 15:49:28 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.055, trans_loss=3.531, nll_loss=1.699, w2v_ctc_loss=1.075, task_loss=1.381, contrastive_loss=0.197, total=4141.5, n_correct=2448.14, ppl=3.25, accuracy=59.112, wps=13719.5, ups=1.11, wpb=12367.2, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.385, clip=0, loss_scale=16, train_wall=90, gb_free=16.3, wall=10629
2023-08-04 15:50:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 15:51:08 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.26 | trans_loss 5.651 | nll_loss 2.951 | w2v_ctc_loss 1.347 | task_loss 6.862 | contrastive_loss 0.263 | total 4003.4 | n_correct 2424.6 | ppl 7.73 | accuracy 60.564 | uer 18.767 | wer 20.361 | raw_wer 20.361 | bleu 18.98 | wps 2174.4 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.98
2023-08-04 15:51:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-08-04 15:51:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 15:51:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 15:51:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.98) (writing took 23.780675182119012 seconds)
2023-08-04 15:51:32 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-04 15:51:32 | INFO | train | epoch 008 | loss 2.056 | trans_loss 3.526 | nll_loss 1.691 | w2v_ctc_loss 1.08 | task_loss 1.397 | contrastive_loss 0.192 | total 4138.65 | n_correct 2443.95 | ppl 3.23 | accuracy 59.052 | wps 13019.3 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.394 | clip 0 | loss_scale 16 | train_wall 1336 | gb_free 16.8 | wall 10754
2023-08-04 15:51:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 15:51:33 | INFO | fairseq.trainer | begin training epoch 9
2023-08-04 15:51:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 15:51:54 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.056, trans_loss=3.524, nll_loss=1.688, w2v_ctc_loss=1.061, task_loss=1.345, contrastive_loss=0.324, total=4139.35, n_correct=2453.93, ppl=3.22, accuracy=59.283, wps=8417.4, ups=0.68, wpb=12350.9, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.394, clip=0, loss_scale=16, train_wall=91, gb_free=15.4, wall=10776
2023-08-04 15:53:25 | INFO | train_inner | epoch 009:    115 / 1474 loss=1.998, trans_loss=3.487, nll_loss=1.641, w2v_ctc_loss=1.032, task_loss=1.329, contrastive_loss=0.142, total=4181.9, n_correct=2525.03, ppl=3.12, accuracy=60.38, wps=13725, ups=1.1, wpb=12488.1, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.386, clip=0, loss_scale=16, train_wall=90, gb_free=16.2, wall=10867
2023-08-04 15:54:57 | INFO | train_inner | epoch 009:    215 / 1474 loss=1.998, trans_loss=3.495, nll_loss=1.651, w2v_ctc_loss=1.036, task_loss=1.507, contrastive_loss=0.101, total=4062.07, n_correct=2440.69, ppl=3.14, accuracy=60.085, wps=13227.1, ups=1.09, wpb=12129.1, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.389, clip=0, loss_scale=16, train_wall=91, gb_free=15.5, wall=10959
2023-08-04 15:54:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 15:55:19 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.251 | trans_loss 5.658 | nll_loss 2.958 | w2v_ctc_loss 1.3 | task_loss 6.822 | contrastive_loss 0.265 | total 4003.4 | n_correct 2416.3 | ppl 7.77 | accuracy 60.356 | uer 18.647 | wer 20.488 | raw_wer 20.488 | bleu 18.77 | wps 2307.6 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.98
2023-08-04 15:55:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-04 15:55:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_9_12000.pt
2023-08-04 15:55:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_9_12000.pt
2023-08-04 15:55:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.77) (writing took 19.27146601304412 seconds)
2023-08-04 15:57:09 | INFO | train_inner | epoch 009:    315 / 1474 loss=1.991, trans_loss=3.483, nll_loss=1.638, w2v_ctc_loss=1.022, task_loss=1.308, contrastive_loss=0.148, total=4152.1, n_correct=2512.4, ppl=3.11, accuracy=60.509, wps=9367.3, ups=0.75, wpb=12407.3, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.389, clip=0, loss_scale=32, train_wall=90, gb_free=16.2, wall=11091
2023-08-04 15:58:41 | INFO | train_inner | epoch 009:    415 / 1474 loss=1.998, trans_loss=3.5, nll_loss=1.657, w2v_ctc_loss=1.032, task_loss=1.365, contrastive_loss=0.118, total=4203.78, n_correct=2524.62, ppl=3.15, accuracy=60.056, wps=13668.3, ups=1.09, wpb=12551.8, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.386, clip=0, loss_scale=32, train_wall=91, gb_free=17.1, wall=11183
2023-08-04 16:00:12 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.026, trans_loss=3.504, nll_loss=1.662, w2v_ctc_loss=1.057, task_loss=1.47, contrastive_loss=0.168, total=4112.78, n_correct=2459.78, ppl=3.16, accuracy=59.808, wps=13511.9, ups=1.1, wpb=12275.6, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.398, clip=0, loss_scale=32, train_wall=90, gb_free=16.1, wall=11274
2023-08-04 16:01:43 | INFO | train_inner | epoch 009:    615 / 1474 loss=1.993, trans_loss=3.495, nll_loss=1.654, w2v_ctc_loss=1.026, task_loss=1.423, contrastive_loss=0.128, total=4131.32, n_correct=2485.62, ppl=3.15, accuracy=60.165, wps=13528.9, ups=1.1, wpb=12347.4, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.389, clip=0, loss_scale=32, train_wall=91, gb_free=17.8, wall=11365
2023-08-04 16:03:14 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.029, trans_loss=3.508, nll_loss=1.67, w2v_ctc_loss=1.054, task_loss=1.43, contrastive_loss=0.211, total=4082.11, n_correct=2438.12, ppl=3.18, accuracy=59.727, wps=13466.1, ups=1.1, wpb=12194.8, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.394, clip=0, loss_scale=32, train_wall=90, gb_free=16.9, wall=11456
2023-08-04 16:04:45 | INFO | train_inner | epoch 009:    815 / 1474 loss=2.047, trans_loss=3.499, nll_loss=1.66, w2v_ctc_loss=1.043, task_loss=1.263, contrastive_loss=0.359, total=4221.08, n_correct=2529.51, ppl=3.16, accuracy=59.926, wps=13804.6, ups=1.09, wpb=12613.9, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.4, clip=0, loss_scale=32, train_wall=91, gb_free=17.6, wall=11547
2023-08-04 16:06:18 | INFO | train_inner | epoch 009:    915 / 1474 loss=2.03, trans_loss=3.506, nll_loss=1.664, w2v_ctc_loss=1.04, task_loss=1.448, contrastive_loss=0.334, total=4142.34, n_correct=2478.42, ppl=3.17, accuracy=59.831, wps=13266.7, ups=1.07, wpb=12359.9, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.398, clip=0, loss_scale=32, train_wall=93, gb_free=17.2, wall=11640
2023-08-04 16:07:49 | INFO | train_inner | epoch 009:   1015 / 1474 loss=2.017, trans_loss=3.515, nll_loss=1.676, w2v_ctc_loss=1.051, task_loss=1.572, contrastive_loss=0.116, total=4097.15, n_correct=2440.91, ppl=3.2, accuracy=59.576, wps=13470, ups=1.1, wpb=12228.7, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.397, clip=0, loss_scale=32, train_wall=90, gb_free=16.7, wall=11731
2023-08-04 16:09:20 | INFO | train_inner | epoch 009:   1115 / 1474 loss=2.008, trans_loss=3.509, nll_loss=1.667, w2v_ctc_loss=1.038, task_loss=1.306, contrastive_loss=0.139, total=4182.29, n_correct=2512.35, ppl=3.18, accuracy=60.071, wps=13751.8, ups=1.1, wpb=12467.1, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.394, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=11822
2023-08-04 16:10:52 | INFO | train_inner | epoch 009:   1215 / 1474 loss=2.015, trans_loss=3.509, nll_loss=1.671, w2v_ctc_loss=1.053, task_loss=1.484, contrastive_loss=0.12, total=4141.43, n_correct=2478.13, ppl=3.18, accuracy=59.838, wps=13488.9, ups=1.09, wpb=12364.7, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.393, clip=0, loss_scale=32, train_wall=91, gb_free=17.5, wall=11913
2023-08-04 16:12:23 | INFO | train_inner | epoch 009:   1315 / 1474 loss=2.029, trans_loss=3.505, nll_loss=1.666, w2v_ctc_loss=1.034, task_loss=1.272, contrastive_loss=0.315, total=4203.91, n_correct=2524.48, ppl=3.17, accuracy=60.051, wps=13753.8, ups=1.1, wpb=12545.2, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.41, clip=0, loss_scale=32, train_wall=91, gb_free=17.2, wall=12004
2023-08-04 16:13:54 | INFO | train_inner | epoch 009:   1415 / 1474 loss=2.01, trans_loss=3.516, nll_loss=1.679, w2v_ctc_loss=1.047, task_loss=1.511, contrastive_loss=0.098, total=4077.08, n_correct=2434.15, ppl=3.2, accuracy=59.703, wps=13396.5, ups=1.1, wpb=12165, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.399, clip=0, loss_scale=32, train_wall=90, gb_free=17.3, wall=12095
2023-08-04 16:14:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 16:15:09 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.232 | trans_loss 5.63 | nll_loss 2.928 | w2v_ctc_loss 1.304 | task_loss 6.916 | contrastive_loss 0.259 | total 4003.4 | n_correct 2425.4 | ppl 7.61 | accuracy 60.584 | uer 18.1 | wer 19.981 | raw_wer 19.981 | bleu 19.04 | wps 2169 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 19.04
2023-08-04 16:15:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-08-04 16:15:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 16:15:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 16:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 9 @ 13259 updates, score 19.04) (writing took 23.51151328906417 seconds)
2023-08-04 16:15:33 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-04 16:15:33 | INFO | train | epoch 009 | loss 2.014 | trans_loss 3.502 | nll_loss 1.661 | w2v_ctc_loss 1.04 | task_loss 1.399 | contrastive_loss 0.184 | total 4138.65 | n_correct 2482.52 | ppl 3.16 | accuracy 59.984 | wps 12639.3 | ups 1.02 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.394 | clip 0 | loss_scale 32 | train_wall 1337 | gb_free 11.5 | wall 12195
2023-08-04 16:15:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 16:15:34 | INFO | fairseq.trainer | begin training epoch 10
2023-08-04 16:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 16:16:19 | INFO | train_inner | epoch 010:     41 / 1474 loss=1.999, trans_loss=3.495, nll_loss=1.652, w2v_ctc_loss=1.021, task_loss=1.333, contrastive_loss=0.198, total=4100.86, n_correct=2474.37, ppl=3.14, accuracy=60.338, wps=8423.1, ups=0.69, wpb=12239.9, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.393, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=12241
2023-08-04 16:17:50 | INFO | train_inner | epoch 010:    141 / 1474 loss=1.957, trans_loss=3.469, nll_loss=1.62, w2v_ctc_loss=0.993, task_loss=1.323, contrastive_loss=0.12, total=4240.18, n_correct=2587.76, ppl=3.07, accuracy=61.029, wps=13889.4, ups=1.1, wpb=12664, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.388, clip=0, loss_scale=32, train_wall=91, gb_free=14.8, wall=12332
2023-08-04 16:19:21 | INFO | train_inner | epoch 010:    241 / 1474 loss=1.983, trans_loss=3.472, nll_loss=1.62, w2v_ctc_loss=1.006, task_loss=1.389, contrastive_loss=0.242, total=4126.3, n_correct=2515.15, ppl=3.07, accuracy=60.954, wps=13477.9, ups=1.09, wpb=12312.3, bsz=460.9, num_updates=13500, lr=0.000121716, gnorm=0.391, clip=0, loss_scale=32, train_wall=91, gb_free=15.4, wall=12423
2023-08-04 16:20:52 | INFO | train_inner | epoch 010:    341 / 1474 loss=1.963, trans_loss=3.469, nll_loss=1.622, w2v_ctc_loss=0.996, task_loss=1.423, contrastive_loss=0.154, total=4132.25, n_correct=2517.6, ppl=3.08, accuracy=60.926, wps=13587.9, ups=1.1, wpb=12352, bsz=452.8, num_updates=13600, lr=0.000121268, gnorm=0.389, clip=0, loss_scale=32, train_wall=90, gb_free=14.6, wall=12514
2023-08-04 16:22:24 | INFO | train_inner | epoch 010:    441 / 1474 loss=1.981, trans_loss=3.476, nll_loss=1.628, w2v_ctc_loss=0.987, task_loss=1.339, contrastive_loss=0.33, total=4203.14, n_correct=2560, ppl=3.09, accuracy=60.907, wps=13642.2, ups=1.09, wpb=12548.6, bsz=481.7, num_updates=13700, lr=0.000120824, gnorm=0.39, clip=0, loss_scale=32, train_wall=92, gb_free=16.3, wall=12606
2023-08-04 16:23:55 | INFO | train_inner | epoch 010:    541 / 1474 loss=1.982, trans_loss=3.491, nll_loss=1.643, w2v_ctc_loss=1.021, task_loss=1.487, contrastive_loss=0.109, total=4106.5, n_correct=2484.49, ppl=3.12, accuracy=60.501, wps=13473, ups=1.1, wpb=12244.6, bsz=440, num_updates=13800, lr=0.000120386, gnorm=0.396, clip=0, loss_scale=32, train_wall=90, gb_free=16.3, wall=12697
2023-08-04 16:25:27 | INFO | train_inner | epoch 010:    641 / 1474 loss=1.992, trans_loss=3.484, nll_loss=1.638, w2v_ctc_loss=1.013, task_loss=1.336, contrastive_loss=0.224, total=4170.61, n_correct=2531.97, ppl=3.11, accuracy=60.71, wps=13565.8, ups=1.09, wpb=12448.2, bsz=476.1, num_updates=13900, lr=0.000119952, gnorm=0.397, clip=0, loss_scale=32, train_wall=91, gb_free=10.6, wall=12789
2023-08-04 16:26:58 | INFO | train_inner | epoch 010:    741 / 1474 loss=1.983, trans_loss=3.486, nll_loss=1.641, w2v_ctc_loss=1.026, task_loss=1.411, contrastive_loss=0.107, total=4123.31, n_correct=2498.03, ppl=3.12, accuracy=60.583, wps=13565.9, ups=1.1, wpb=12306.7, bsz=453, num_updates=14000, lr=0.000119523, gnorm=0.397, clip=0, loss_scale=32, train_wall=90, gb_free=17, wall=12879
2023-08-04 16:26:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 16:27:20 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.239 | trans_loss 5.629 | nll_loss 2.919 | w2v_ctc_loss 1.326 | task_loss 6.897 | contrastive_loss 0.267 | total 4003.4 | n_correct 2428.2 | ppl 7.56 | accuracy 60.653 | uer 18.523 | wer 20.171 | raw_wer 20.171 | bleu 19.17 | wps 2308.5 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.17
2023-08-04 16:27:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-04 16:27:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_10_14000.pt
2023-08-04 16:27:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_10_14000.pt
2023-08-04 16:28:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.17) (writing took 41.91867758333683 seconds)
2023-08-04 16:29:34 | INFO | train_inner | epoch 010:    841 / 1474 loss=1.963, trans_loss=3.481, nll_loss=1.636, w2v_ctc_loss=1.001, task_loss=1.382, contrastive_loss=0.108, total=4125.69, n_correct=2509.96, ppl=3.11, accuracy=60.837, wps=7900.2, ups=0.64, wpb=12321, bsz=456.1, num_updates=14100, lr=0.000119098, gnorm=0.391, clip=0, loss_scale=64, train_wall=90, gb_free=15.7, wall=13035
2023-08-04 16:31:04 | INFO | train_inner | epoch 010:    941 / 1474 loss=1.977, trans_loss=3.483, nll_loss=1.636, w2v_ctc_loss=1.008, task_loss=1.336, contrastive_loss=0.147, total=4170.41, n_correct=2536.4, ppl=3.11, accuracy=60.819, wps=13765.5, ups=1.11, wpb=12437.5, bsz=470.8, num_updates=14200, lr=0.000118678, gnorm=0.391, clip=0, loss_scale=64, train_wall=90, gb_free=16, wall=13126
2023-08-04 16:31:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 16:32:36 | INFO | train_inner | epoch 010:   1042 / 1474 loss=1.975, trans_loss=3.487, nll_loss=1.643, w2v_ctc_loss=1.01, task_loss=1.521, contrastive_loss=0.121, total=4065.19, n_correct=2456.44, ppl=3.12, accuracy=60.426, wps=13165.7, ups=1.08, wpb=12138.9, bsz=433.1, num_updates=14300, lr=0.000118262, gnorm=0.397, clip=0, loss_scale=32, train_wall=92, gb_free=16.9, wall=13218
2023-08-04 16:34:07 | INFO | train_inner | epoch 010:   1142 / 1474 loss=1.985, trans_loss=3.494, nll_loss=1.652, w2v_ctc_loss=1.026, task_loss=1.56, contrastive_loss=0.103, total=4044.03, n_correct=2438.75, ppl=3.14, accuracy=60.305, wps=13347.9, ups=1.11, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.395, clip=0, loss_scale=32, train_wall=90, gb_free=17.3, wall=13308
2023-08-04 16:35:38 | INFO | train_inner | epoch 010:   1242 / 1474 loss=1.976, trans_loss=3.483, nll_loss=1.642, w2v_ctc_loss=1.019, task_loss=1.432, contrastive_loss=0.099, total=4110.41, n_correct=2488.07, ppl=3.12, accuracy=60.531, wps=13495.7, ups=1.1, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.397, clip=0, loss_scale=32, train_wall=91, gb_free=16.4, wall=13399
2023-08-04 16:37:09 | INFO | train_inner | epoch 010:   1342 / 1474 loss=1.973, trans_loss=3.489, nll_loss=1.647, w2v_ctc_loss=1.014, task_loss=1.429, contrastive_loss=0.11, total=4121.38, n_correct=2498.6, ppl=3.13, accuracy=60.625, wps=13456, ups=1.09, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.399, clip=0, loss_scale=32, train_wall=91, gb_free=13.9, wall=13491
2023-08-04 16:38:41 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.01, trans_loss=3.494, nll_loss=1.651, w2v_ctc_loss=0.999, task_loss=1.323, contrastive_loss=0.363, total=4192.39, n_correct=2536.95, ppl=3.14, accuracy=60.513, wps=13608, ups=1.09, wpb=12506.1, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.397, clip=0, loss_scale=32, train_wall=91, gb_free=17, wall=13583
2023-08-04 16:39:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 16:39:32 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.228 | trans_loss 5.611 | nll_loss 2.899 | w2v_ctc_loss 1.333 | task_loss 6.921 | contrastive_loss 0.262 | total 4003.4 | n_correct 2439.9 | ppl 7.46 | accuracy 60.946 | uer 17.899 | wer 19.593 | raw_wer 19.593 | bleu 19.49 | wps 2299.5 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.49
2023-08-04 16:39:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-08-04 16:39:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 16:39:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 16:39:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.49) (writing took 23.53954165801406 seconds)
2023-08-04 16:39:57 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-04 16:39:57 | INFO | train | epoch 010 | loss 1.979 | trans_loss 3.482 | nll_loss 1.637 | w2v_ctc_loss 1.007 | task_loss 1.4 | contrastive_loss 0.178 | total 4138.76 | n_correct 2512.31 | ppl 3.11 | accuracy 60.702 | wps 12439.2 | ups 1.01 | wpb 12356.2 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.394 | clip 0 | loss_scale 32 | train_wall 1336 | gb_free 17.2 | wall 13658
2023-08-04 16:39:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 16:39:57 | INFO | fairseq.trainer | begin training epoch 11
2023-08-04 16:39:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 16:41:06 | INFO | train_inner | epoch 011:     68 / 1474 loss=1.949, trans_loss=3.458, nll_loss=1.605, w2v_ctc_loss=0.98, task_loss=1.298, contrastive_loss=0.187, total=4175.24, n_correct=2569.07, ppl=3.04, accuracy=61.531, wps=8617.4, ups=0.69, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.387, clip=0, loss_scale=32, train_wall=89, gb_free=16.7, wall=13727
2023-08-04 16:42:37 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.94, trans_loss=3.458, nll_loss=1.607, w2v_ctc_loss=0.984, task_loss=1.439, contrastive_loss=0.105, total=4087.78, n_correct=2514.23, ppl=3.05, accuracy=61.506, wps=13441.3, ups=1.1, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.399, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=13818
2023-08-04 16:44:08 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.93, trans_loss=3.459, nll_loss=1.607, w2v_ctc_loss=0.973, task_loss=1.445, contrastive_loss=0.1, total=4118.77, n_correct=2531.36, ppl=3.05, accuracy=61.459, wps=13474, ups=1.1, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.392, clip=0, loss_scale=32, train_wall=91, gb_free=12.2, wall=13910
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:0')
2023-08-04 16:45:17 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.094, trans_loss=5.14, nll_loss=2.392, w2v_ctc_loss=0.733, task_loss=2.143, contrastive_loss=0.081, total=4097.83, n_correct=2514.48, ppl=5.25, accuracy=61.361, wps=12021.1, ups=1.46, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.513, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=13978
2023-08-04 16:46:25 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.108, trans_loss=5.178, nll_loss=2.417, w2v_ctc_loss=0.725, task_loss=2.194, contrastive_loss=0.197, total=4110.64, n_correct=2514.02, ppl=5.34, accuracy=61.159, wps=12005.8, ups=1.46, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.515, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=14047
2023-08-04 16:47:33 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.11, trans_loss=5.176, nll_loss=2.415, w2v_ctc_loss=0.737, task_loss=2.252, contrastive_loss=0.197, total=4071.69, n_correct=2489.55, ppl=5.33, accuracy=61.143, wps=11949.7, ups=1.47, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=14115
2023-08-04 16:48:41 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.113, trans_loss=5.177, nll_loss=2.417, w2v_ctc_loss=0.735, task_loss=2.057, contrastive_loss=0.254, total=4157.2, n_correct=2538.16, ppl=5.34, accuracy=61.055, wps=12252.5, ups=1.47, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.509, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=14183
2023-08-04 16:49:50 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.108, trans_loss=5.188, nll_loss=2.431, w2v_ctc_loss=0.747, task_loss=2.104, contrastive_loss=0.08, total=4174.91, n_correct=2553.21, ppl=5.39, accuracy=61.156, wps=12161.4, ups=1.46, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=14251
2023-08-04 16:50:57 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.108, trans_loss=5.189, nll_loss=2.432, w2v_ctc_loss=0.741, task_loss=2.193, contrastive_loss=0.068, total=4118.44, n_correct=2508.31, ppl=5.4, accuracy=60.904, wps=12166, ups=1.48, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.514, clip=0, loss_scale=32, train_wall=67, gb_free=10.7, wall=14319
2023-08-04 16:52:05 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.107, trans_loss=5.186, nll_loss=2.43, w2v_ctc_loss=0.745, task_loss=2.143, contrastive_loss=0.082, total=4140.92, n_correct=2525.44, ppl=5.39, accuracy=60.987, wps=12208.9, ups=1.47, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.527, clip=0, loss_scale=32, train_wall=67, gb_free=15.6, wall=14387
2023-08-04 16:53:13 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.105, trans_loss=5.181, nll_loss=2.424, w2v_ctc_loss=0.744, task_loss=2.064, contrastive_loss=0.101, total=4136.99, n_correct=2531.42, ppl=5.37, accuracy=61.19, wps=12232.8, ups=1.48, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.527, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=14455
2023-08-04 16:54:22 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.107, trans_loss=5.188, nll_loss=2.432, w2v_ctc_loss=0.744, task_loss=2.084, contrastive_loss=0.086, total=4185.65, n_correct=2554.62, ppl=5.4, accuracy=61.033, wps=12164.4, ups=1.45, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=13.9, wall=14523
2023-08-04 16:55:29 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.11, trans_loss=5.183, nll_loss=2.426, w2v_ctc_loss=0.745, task_loss=2.013, contrastive_loss=0.155, total=4171.89, n_correct=2546.52, ppl=5.38, accuracy=61.04, wps=12318.8, ups=1.48, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.518, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=14591
2023-08-04 16:55:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:4')
2023-08-04 16:55:53 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.236 | trans_loss 5.61 | nll_loss 2.901 | w2v_ctc_loss 1.36 | task_loss 6.911 | contrastive_loss 0.265 | total 4003.4 | n_correct 2445.5 | ppl 7.47 | accuracy 61.086 | uer 17.981 | wer 19.66 | raw_wer 19.66 | bleu 19.09 | wps 2197.1 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.49
2023-08-04 16:55:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-04 16:55:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_11_16000.pt
2023-08-04 16:55:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_11_16000.pt
2023-08-04 16:56:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.09) (writing took 30.881048288196325 seconds)
2023-08-04 16:57:33 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.116, trans_loss=5.185, nll_loss=2.43, w2v_ctc_loss=0.733, task_loss=1.937, contrastive_loss=0.317, total=4190.34, n_correct=2557.59, ppl=5.39, accuracy=61.035, wps=6789.1, ups=0.81, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.513, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=14715
2023-08-04 16:58:42 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.104, trans_loss=5.19, nll_loss=2.436, w2v_ctc_loss=0.739, task_loss=2.029, contrastive_loss=0.09, total=4158.39, n_correct=2535.26, ppl=5.41, accuracy=60.967, wps=12096.7, ups=1.45, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.512, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=14783
2023-08-04 16:58:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 16:59:08 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.214 | trans_loss 5.603 | nll_loss 2.893 | w2v_ctc_loss 1.303 | task_loss 6.896 | contrastive_loss 0.259 | total 4003.4 | n_correct 2442.5 | ppl 7.43 | accuracy 61.011 | uer 17.912 | wer 19.656 | raw_wer 19.656 | bleu 19.58 | wps 2283.8 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.58
2023-08-04 16:59:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-08-04 16:59:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 16:59:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 16:59:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.58) (writing took 26.480590749531984 seconds)
2023-08-04 16:59:35 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-04 16:59:35 | INFO | train | epoch 011 | loss 2.065 | trans_loss 4.751 | nll_loss 2.22 | w2v_ctc_loss 0.798 | task_loss 1.924 | contrastive_loss 0.133 | total 4138.65 | n_correct 2531.64 | ppl 4.66 | accuracy 61.171 | wps 11281 | ups 1.25 | wpb 9021 | bsz 333.4 | num_updates 16206 | lr 0.000111091 | gnorm 0.494 | clip 0 | loss_scale 32 | train_wall 1058 | gb_free 17.2 | wall 14837
2023-08-04 16:59:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 16:59:36 | INFO | fairseq.trainer | begin training epoch 12
2023-08-04 16:59:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 17:00:46 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.078, trans_loss=5.13, nll_loss=2.357, w2v_ctc_loss=0.722, task_loss=2.005, contrastive_loss=0.123, total=4146.82, n_correct=2574.04, ppl=5.12, accuracy=62.073, wps=6652.7, ups=0.8, wpb=8293.6, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.513, clip=0, loss_scale=64, train_wall=67, gb_free=15.7, wall=14908
2023-08-04 17:01:54 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.086, trans_loss=5.142, nll_loss=2.371, w2v_ctc_loss=0.732, task_loss=2.169, contrastive_loss=0.073, total=4120.68, n_correct=2545.57, ppl=5.17, accuracy=61.775, wps=12092.2, ups=1.47, wpb=8241.4, bsz=294.7, num_updates=16400, lr=0.000110432, gnorm=0.523, clip=0, loss_scale=64, train_wall=68, gb_free=15.6, wall=14976
2023-08-04 17:03:03 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.078, trans_loss=5.139, nll_loss=2.368, w2v_ctc_loss=0.717, task_loss=1.976, contrastive_loss=0.105, total=4199.46, n_correct=2597.89, ppl=5.16, accuracy=61.862, wps=12346.5, ups=1.47, wpb=8398.9, bsz=320.3, num_updates=16500, lr=0.000110096, gnorm=0.511, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=15044
2023-08-04 17:04:11 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.086, trans_loss=5.149, nll_loss=2.382, w2v_ctc_loss=0.728, task_loss=2.053, contrastive_loss=0.088, total=4151.14, n_correct=2563.49, ppl=5.21, accuracy=61.754, wps=12135.2, ups=1.46, wpb=8302.3, bsz=307.8, num_updates=16600, lr=0.000109764, gnorm=0.515, clip=0, loss_scale=64, train_wall=68, gb_free=17.1, wall=15113
2023-08-04 17:05:19 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.094, trans_loss=5.162, nll_loss=2.399, w2v_ctc_loss=0.737, task_loss=2.11, contrastive_loss=0.094, total=4110.49, n_correct=2533.32, ppl=5.28, accuracy=61.631, wps=12103.3, ups=1.47, wpb=8221, bsz=302.2, num_updates=16700, lr=0.000109435, gnorm=0.52, clip=0, loss_scale=64, train_wall=67, gb_free=13.7, wall=15181
2023-08-04 17:06:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 17:06:27 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.086, trans_loss=5.152, nll_loss=2.386, w2v_ctc_loss=0.73, task_loss=2.052, contrastive_loss=0.094, total=4172.29, n_correct=2577.51, ppl=5.23, accuracy=61.777, wps=12175.8, ups=1.46, wpb=8344.6, bsz=310.2, num_updates=16800, lr=0.000109109, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=15249
2023-08-04 17:07:35 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.085, trans_loss=5.149, nll_loss=2.383, w2v_ctc_loss=0.71, task_loss=1.931, contrastive_loss=0.247, total=4203.66, n_correct=2603.87, ppl=5.22, accuracy=61.943, wps=12415.2, ups=1.48, wpb=8407.3, bsz=324.4, num_updates=16900, lr=0.000108786, gnorm=0.503, clip=0, loss_scale=32, train_wall=67, gb_free=17.4, wall=15317
2023-08-04 17:08:43 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.087, trans_loss=5.151, nll_loss=2.385, w2v_ctc_loss=0.732, task_loss=2.128, contrastive_loss=0.083, total=4095.72, n_correct=2528.3, ppl=5.22, accuracy=61.73, wps=11984.6, ups=1.46, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=15385
2023-08-04 17:09:52 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.094, trans_loss=5.158, nll_loss=2.394, w2v_ctc_loss=0.729, task_loss=2.152, contrastive_loss=0.136, total=4162.82, n_correct=2565.58, ppl=5.26, accuracy=61.631, wps=12214.4, ups=1.47, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.513, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=15453
2023-08-04 17:10:59 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.097, trans_loss=5.166, nll_loss=2.405, w2v_ctc_loss=0.734, task_loss=2.137, contrastive_loss=0.144, total=4117.63, n_correct=2532.54, ppl=5.3, accuracy=61.505, wps=12151.7, ups=1.48, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.516, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=15521
2023-08-04 17:12:07 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.107, trans_loss=5.173, nll_loss=2.413, w2v_ctc_loss=0.739, task_loss=2.211, contrastive_loss=0.188, total=4046.48, n_correct=2481.62, ppl=5.33, accuracy=61.328, wps=11989.9, ups=1.48, wpb=8093, bsz=289.6, num_updates=17300, lr=0.000107521, gnorm=0.534, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=15589
2023-08-04 17:13:15 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.106, trans_loss=5.18, nll_loss=2.424, w2v_ctc_loss=0.742, task_loss=2.046, contrastive_loss=0.159, total=4201.13, n_correct=2572.13, ppl=5.37, accuracy=61.225, wps=12279.7, ups=1.46, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=15657
2023-08-04 17:14:23 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.104, trans_loss=5.173, nll_loss=2.414, w2v_ctc_loss=0.751, task_loss=2.334, contrastive_loss=0.072, total=4070.27, n_correct=2496.19, ppl=5.33, accuracy=61.327, wps=12009.1, ups=1.48, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.524, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=15725
2023-08-04 17:15:31 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.096, trans_loss=5.171, nll_loss=2.413, w2v_ctc_loss=0.724, task_loss=2.111, contrastive_loss=0.175, total=4139.63, n_correct=2544.9, ppl=5.33, accuracy=61.477, wps=12182.2, ups=1.47, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.522, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=15793
2023-08-04 17:16:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 17:16:47 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.224 | trans_loss 5.593 | nll_loss 2.879 | w2v_ctc_loss 1.357 | task_loss 6.896 | contrastive_loss 0.267 | total 4003.4 | n_correct 2455.9 | ppl 7.36 | accuracy 61.345 | uer 18.026 | wer 19.854 | raw_wer 19.854 | bleu 19.46 | wps 2291.6 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.58
2023-08-04 17:16:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-04 17:16:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.4601.pt
2023-08-04 17:16:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.4601.pt
2023-08-04 17:17:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.4601.pt (epoch 12 @ 17679 updates, score 19.46) (writing took 17.82123632915318 seconds)
2023-08-04 17:17:05 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-04 17:17:05 | INFO | train | epoch 012 | loss 2.092 | trans_loss 5.157 | nll_loss 2.394 | w2v_ctc_loss 0.731 | task_loss 2.102 | contrastive_loss 0.125 | total 4137.47 | n_correct 2550.46 | ppl 5.25 | accuracy 61.643 | wps 11608.6 | ups 1.4 | wpb 8274.9 | bsz 305.3 | num_updates 17679 | lr 0.000106362 | gnorm 0.519 | clip 0 | loss_scale 32 | train_wall 995 | gb_free 12.7 | wall 15887
2023-08-04 17:17:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 17:17:06 | INFO | fairseq.trainer | begin training epoch 13
2023-08-04 17:17:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 17:17:27 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.096, trans_loss=5.17, nll_loss=2.411, w2v_ctc_loss=0.739, task_loss=2.182, contrastive_loss=0.08, total=4096.49, n_correct=2522.19, ppl=5.32, accuracy=61.57, wps=7061.4, ups=0.86, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=14.5, wall=15909
2023-08-04 17:18:35 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.069, trans_loss=5.119, nll_loss=2.343, w2v_ctc_loss=0.716, task_loss=2.103, contrastive_loss=0.091, total=4160.97, n_correct=2596.41, ppl=5.07, accuracy=62.399, wps=12210.9, ups=1.47, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.51, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=15977
2023-08-04 17:19:44 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.083, trans_loss=5.129, nll_loss=2.358, w2v_ctc_loss=0.711, task_loss=1.935, contrastive_loss=0.312, total=4212.08, n_correct=2616.94, ppl=5.13, accuracy=62.129, wps=12306.4, ups=1.46, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.511, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=16045
2023-08-04 17:20:52 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.067, trans_loss=5.12, nll_loss=2.344, w2v_ctc_loss=0.711, task_loss=2.177, contrastive_loss=0.075, total=4102.3, n_correct=2563.75, ppl=5.08, accuracy=62.495, wps=12092.7, ups=1.47, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.514, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=16113
2023-08-04 17:20:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 17:21:15 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.221 | trans_loss 5.604 | nll_loss 2.889 | w2v_ctc_loss 1.322 | task_loss 6.88 | contrastive_loss 0.264 | total 4003.4 | n_correct 2453.2 | ppl 7.41 | accuracy 61.278 | uer 18.265 | wer 20.115 | raw_wer 20.115 | bleu 19.38 | wps 2136.9 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.58
2023-08-04 17:21:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-04 17:21:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_13_18000.pt
2023-08-04 17:21:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_13_18000.pt
2023-08-04 17:21:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.38) (writing took 31.174571361392736 seconds)
2023-08-04 17:22:55 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.074, trans_loss=5.13, nll_loss=2.358, w2v_ctc_loss=0.719, task_loss=1.965, contrastive_loss=0.126, total=4177.29, n_correct=2603.79, ppl=5.13, accuracy=62.332, wps=6794.8, ups=0.81, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.505, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=16236
2023-08-04 17:24:03 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.079, trans_loss=5.136, nll_loss=2.366, w2v_ctc_loss=0.718, task_loss=2.033, contrastive_loss=0.163, total=4201.22, n_correct=2607.19, ppl=5.16, accuracy=62.058, wps=12265.8, ups=1.46, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.514, clip=0, loss_scale=32, train_wall=68, gb_free=12.8, wall=16305
2023-08-04 17:25:11 | INFO | train_inner | epoch 013:    621 / 1474 loss=2.068, trans_loss=5.132, nll_loss=2.361, w2v_ctc_loss=0.713, task_loss=2.035, contrastive_loss=0.073, total=4161.98, n_correct=2593.11, ppl=5.14, accuracy=62.305, wps=12306.7, ups=1.48, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.513, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=16372
2023-08-04 17:26:19 | INFO | train_inner | epoch 013:    721 / 1474 loss=2.088, trans_loss=5.145, nll_loss=2.377, w2v_ctc_loss=0.74, task_loss=2.335, contrastive_loss=0.071, total=4096.76, n_correct=2532.02, ppl=5.2, accuracy=61.805, wps=12084.2, ups=1.47, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.527, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=16440
2023-08-04 17:27:27 | INFO | train_inner | epoch 013:    821 / 1474 loss=2.081, trans_loss=5.141, nll_loss=2.373, w2v_ctc_loss=0.721, task_loss=2.122, contrastive_loss=0.122, total=4121.73, n_correct=2553.69, ppl=5.18, accuracy=61.957, wps=11997.4, ups=1.46, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=16509
2023-08-04 17:28:35 | INFO | train_inner | epoch 013:    921 / 1474 loss=2.082, trans_loss=5.146, nll_loss=2.38, w2v_ctc_loss=0.726, task_loss=2.146, contrastive_loss=0.082, total=4107.01, n_correct=2545.2, ppl=5.2, accuracy=61.972, wps=12160.4, ups=1.48, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.531, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=16576
2023-08-04 17:29:42 | INFO | train_inner | epoch 013:   1021 / 1474 loss=2.088, trans_loss=5.148, nll_loss=2.382, w2v_ctc_loss=0.73, task_loss=2.218, contrastive_loss=0.133, total=4081.02, n_correct=2523.08, ppl=5.21, accuracy=61.825, wps=12151, ups=1.49, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.528, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=16644
2023-08-04 17:30:49 | INFO | train_inner | epoch 013:   1121 / 1474 loss=2.076, trans_loss=5.138, nll_loss=2.37, w2v_ctc_loss=0.717, task_loss=2.071, contrastive_loss=0.117, total=4105.62, n_correct=2548.04, ppl=5.17, accuracy=62.062, wps=12177.5, ups=1.48, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.513, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=16711
2023-08-04 17:31:58 | INFO | train_inner | epoch 013:   1221 / 1474 loss=2.083, trans_loss=5.152, nll_loss=2.388, w2v_ctc_loss=0.729, task_loss=2.233, contrastive_loss=0.073, total=4110.35, n_correct=2547.41, ppl=5.23, accuracy=61.976, wps=12036.8, ups=1.46, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.519, clip=0, loss_scale=64, train_wall=68, gb_free=14.8, wall=16779
2023-08-04 17:32:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 17:33:07 | INFO | train_inner | epoch 013:   1322 / 1474 loss=2.079, trans_loss=5.138, nll_loss=2.371, w2v_ctc_loss=0.72, task_loss=2.086, contrastive_loss=0.173, total=4109.21, n_correct=2555.86, ppl=5.17, accuracy=62.198, wps=11893.4, ups=1.45, wpb=8218.4, bsz=306.6, num_updates=19000, lr=0.000102598, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=17.8, wall=16848
2023-08-04 17:34:14 | INFO | train_inner | epoch 013:   1422 / 1474 loss=2.087, trans_loss=5.152, nll_loss=2.389, w2v_ctc_loss=0.718, task_loss=2.061, contrastive_loss=0.183, total=4179.06, n_correct=2584.81, ppl=5.24, accuracy=61.851, wps=12383.9, ups=1.48, wpb=8358.1, bsz=311.9, num_updates=19100, lr=0.000102329, gnorm=0.513, clip=0, loss_scale=32, train_wall=67, gb_free=16, wall=16916
2023-08-04 17:34:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 17:35:12 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.586 | nll_loss 2.868 | w2v_ctc_loss 1.331 | task_loss 6.952 | contrastive_loss 0.258 | total 4003.4 | n_correct 2460.7 | ppl 7.3 | accuracy 61.465 | uer 17.965 | wer 19.772 | raw_wer 19.772 | bleu 19.47 | wps 2279.4 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 19.58
2023-08-04 17:35:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-08-04 17:35:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.4701.pt
2023-08-04 17:35:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.4701.pt
2023-08-04 17:35:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.4701.pt (epoch 13 @ 19152 updates, score 19.47) (writing took 13.672739051282406 seconds)
2023-08-04 17:35:26 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-04 17:35:26 | INFO | train | epoch 013 | loss 2.078 | trans_loss 5.137 | nll_loss 2.368 | w2v_ctc_loss 0.72 | task_loss 2.099 | contrastive_loss 0.128 | total 4138.55 | n_correct 2570.46 | ppl 5.16 | accuracy 62.11 | wps 11077.9 | ups 1.34 | wpb 8277.1 | bsz 305.6 | num_updates 19152 | lr 0.00010219 | gnorm 0.517 | clip 0 | loss_scale 32 | train_wall 994 | gb_free 17.6 | wall 16988
2023-08-04 17:35:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 17:35:26 | INFO | fairseq.trainer | begin training epoch 14
2023-08-04 17:35:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 17:36:06 | INFO | train_inner | epoch 014:     48 / 1474 loss=2.054, trans_loss=5.105, nll_loss=2.329, w2v_ctc_loss=0.706, task_loss=1.932, contrastive_loss=0.088, total=4179.66, n_correct=2627.85, ppl=5.02, accuracy=62.872, wps=7486, ups=0.9, wpb=8359.3, bsz=322, num_updates=19200, lr=0.000102062, gnorm=0.517, clip=0, loss_scale=32, train_wall=67, gb_free=10.3, wall=17028
2023-08-04 17:37:14 | INFO | train_inner | epoch 014:    148 / 1474 loss=2.053, trans_loss=5.094, nll_loss=2.312, w2v_ctc_loss=0.71, task_loss=2.104, contrastive_loss=0.071, total=4081.01, n_correct=2573.77, ppl=4.97, accuracy=63.067, wps=12028.4, ups=1.47, wpb=8162, bsz=300.6, num_updates=19300, lr=0.000101797, gnorm=0.523, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=17095
2023-08-04 17:38:22 | INFO | train_inner | epoch 014:    248 / 1474 loss=2.067, trans_loss=5.113, nll_loss=2.336, w2v_ctc_loss=0.71, task_loss=2.192, contrastive_loss=0.171, total=4109.83, n_correct=2578.7, ppl=5.05, accuracy=62.745, wps=12032.1, ups=1.46, wpb=8219.7, bsz=295.2, num_updates=19400, lr=0.000101535, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=17164
2023-08-04 17:39:30 | INFO | train_inner | epoch 014:    348 / 1474 loss=2.055, trans_loss=5.106, nll_loss=2.329, w2v_ctc_loss=0.704, task_loss=1.958, contrastive_loss=0.107, total=4171.83, n_correct=2621.27, ppl=5.02, accuracy=62.833, wps=12278.2, ups=1.47, wpb=8343.7, bsz=319.7, num_updates=19500, lr=0.000101274, gnorm=0.529, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=17232
2023-08-04 17:40:38 | INFO | train_inner | epoch 014:    448 / 1474 loss=2.062, trans_loss=5.118, nll_loss=2.343, w2v_ctc_loss=0.709, task_loss=2.106, contrastive_loss=0.08, total=4142.75, n_correct=2590.7, ppl=5.07, accuracy=62.536, wps=12249.1, ups=1.48, wpb=8285.5, bsz=302.2, num_updates=19600, lr=0.000101015, gnorm=0.529, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=17299
2023-08-04 17:41:46 | INFO | train_inner | epoch 014:    548 / 1474 loss=2.073, trans_loss=5.122, nll_loss=2.348, w2v_ctc_loss=0.727, task_loss=2.257, contrastive_loss=0.088, total=4073.76, n_correct=2540.71, ppl=5.09, accuracy=62.368, wps=11892, ups=1.46, wpb=8147.5, bsz=290.9, num_updates=19700, lr=0.000100759, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=17368
2023-08-04 17:42:55 | INFO | train_inner | epoch 014:    648 / 1474 loss=2.069, trans_loss=5.122, nll_loss=2.35, w2v_ctc_loss=0.71, task_loss=2.096, contrastive_loss=0.146, total=4158.79, n_correct=2598.08, ppl=5.1, accuracy=62.472, wps=12168.6, ups=1.46, wpb=8317.6, bsz=306.8, num_updates=19800, lr=0.000100504, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=17436
2023-08-04 17:44:02 | INFO | train_inner | epoch 014:    748 / 1474 loss=2.056, trans_loss=5.109, nll_loss=2.333, w2v_ctc_loss=0.705, task_loss=2.042, contrastive_loss=0.077, total=4145.47, n_correct=2603.12, ppl=5.04, accuracy=62.794, wps=12255.4, ups=1.48, wpb=8290.9, bsz=309.6, num_updates=19900, lr=0.000100251, gnorm=0.526, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=17504
2023-08-04 17:45:10 | INFO | train_inner | epoch 014:    848 / 1474 loss=2.066, trans_loss=5.113, nll_loss=2.339, w2v_ctc_loss=0.708, task_loss=1.992, contrastive_loss=0.188, total=4171.1, n_correct=2612.43, ppl=5.06, accuracy=62.632, wps=12384.8, ups=1.48, wpb=8342.2, bsz=319.7, num_updates=20000, lr=0.0001, gnorm=0.524, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=17571
2023-08-04 17:45:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 17:45:32 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.582 | nll_loss 2.861 | w2v_ctc_loss 1.367 | task_loss 6.89 | contrastive_loss 0.253 | total 4003.4 | n_correct 2461 | ppl 7.26 | accuracy 61.473 | uer 17.941 | wer 19.645 | raw_wer 19.645 | bleu 19.77 | wps 2237.3 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.77
2023-08-04 17:45:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-04 17:45:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_14_20000.pt
2023-08-04 17:45:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_14_20000.pt
2023-08-04 17:45:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.77) (writing took 24.062100315466523 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:0')
2023-08-04 17:47:06 | INFO | train_inner | epoch 014:    948 / 1474 loss=2.066, trans_loss=5.122, nll_loss=2.35, w2v_ctc_loss=0.711, task_loss=2.108, contrastive_loss=0.124, total=4167.75, n_correct=2603.23, ppl=5.1, accuracy=62.461, wps=7168, ups=0.86, wpb=8335.5, bsz=310.1, num_updates=20100, lr=9.97509e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=17688
2023-08-04 17:48:15 | INFO | train_inner | epoch 014:   1048 / 1474 loss=2.066, trans_loss=5.127, nll_loss=2.356, w2v_ctc_loss=0.707, task_loss=2.135, contrastive_loss=0.099, total=4143.92, n_correct=2585.92, ppl=5.12, accuracy=62.403, wps=11936.5, ups=1.44, wpb=8287.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=17757
2023-08-04 17:49:24 | INFO | train_inner | epoch 014:   1148 / 1474 loss=2.086, trans_loss=5.126, nll_loss=2.357, w2v_ctc_loss=0.717, task_loss=1.965, contrastive_loss=0.374, total=4228.69, n_correct=2635.4, ppl=5.12, accuracy=62.322, wps=12361.3, ups=1.46, wpb=8457.4, bsz=327.2, num_updates=20300, lr=9.92583e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=17825
2023-08-04 17:50:31 | INFO | train_inner | epoch 014:   1248 / 1474 loss=2.082, trans_loss=5.145, nll_loss=2.378, w2v_ctc_loss=0.732, task_loss=2.468, contrastive_loss=0.059, total=4021.19, n_correct=2495.69, ppl=5.2, accuracy=62.063, wps=11889, ups=1.48, wpb=8042.4, bsz=271.7, num_updates=20400, lr=9.90148e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=17893
2023-08-04 17:51:40 | INFO | train_inner | epoch 014:   1348 / 1474 loss=2.063, trans_loss=5.13, nll_loss=2.362, w2v_ctc_loss=0.706, task_loss=1.981, contrastive_loss=0.078, total=4213.9, n_correct=2629.49, ppl=5.14, accuracy=62.4, wps=12311.2, ups=1.46, wpb=8427.8, bsz=319.4, num_updates=20500, lr=9.8773e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=17962
2023-08-04 17:52:48 | INFO | train_inner | epoch 014:   1448 / 1474 loss=2.071, trans_loss=5.137, nll_loss=2.37, w2v_ctc_loss=0.711, task_loss=2.1, contrastive_loss=0.117, total=4130.28, n_correct=2572.83, ppl=5.17, accuracy=62.292, wps=12199.3, ups=1.48, wpb=8260.6, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=67, gb_free=15.3, wall=18029
2023-08-04 17:53:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:3')
2023-08-04 17:53:28 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.212 | trans_loss 5.581 | nll_loss 2.863 | w2v_ctc_loss 1.348 | task_loss 6.903 | contrastive_loss 0.262 | total 4003.4 | n_correct 2466.5 | ppl 7.27 | accuracy 61.61 | uer 17.816 | wer 19.611 | raw_wer 19.611 | bleu 19.49 | wps 2286.8 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.77
2023-08-04 17:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-08-04 17:53:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.4900.pt
2023-08-04 17:53:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.4900.pt
2023-08-04 17:53:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.4900.pt (epoch 14 @ 20626 updates, score 19.49) (writing took 17.34732099249959 seconds)
2023-08-04 17:53:45 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-04 17:53:45 | INFO | train | epoch 014 | loss 2.067 | trans_loss 5.12 | nll_loss 2.347 | w2v_ctc_loss 0.712 | task_loss 2.1 | contrastive_loss 0.126 | total 4138.65 | n_correct 2588.18 | ppl 5.09 | accuracy 62.537 | wps 11097 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.523 | clip 0 | loss_scale 32 | train_wall 997 | gb_free 16.4 | wall 18087
2023-08-04 17:53:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 17:53:46 | INFO | fairseq.trainer | begin training epoch 15
2023-08-04 17:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 17:54:43 | INFO | train_inner | epoch 015:     74 / 1474 loss=2.06, trans_loss=5.106, nll_loss=2.329, w2v_ctc_loss=0.702, task_loss=2.111, contrastive_loss=0.165, total=4083.88, n_correct=2566.25, ppl=5.03, accuracy=62.839, wps=7083.8, ups=0.87, wpb=8167.8, bsz=300.2, num_updates=20700, lr=9.82946e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=18145
2023-08-04 17:55:51 | INFO | train_inner | epoch 015:    174 / 1474 loss=2.052, trans_loss=5.096, nll_loss=2.315, w2v_ctc_loss=0.709, task_loss=2.188, contrastive_loss=0.075, total=4115.73, n_correct=2594.53, ppl=4.98, accuracy=63.039, wps=12148.5, ups=1.48, wpb=8231.5, bsz=297.8, num_updates=20800, lr=9.80581e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=18212
2023-08-04 17:56:59 | INFO | train_inner | epoch 015:    274 / 1474 loss=2.047, trans_loss=5.098, nll_loss=2.318, w2v_ctc_loss=0.7, task_loss=2.019, contrastive_loss=0.067, total=4193.15, n_correct=2651.49, ppl=4.99, accuracy=63.234, wps=12300.5, ups=1.47, wpb=8386.3, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=18281
2023-08-04 17:58:07 | INFO | train_inner | epoch 015:    374 / 1474 loss=2.049, trans_loss=5.091, nll_loss=2.309, w2v_ctc_loss=0.701, task_loss=2.118, contrastive_loss=0.092, total=4167.66, n_correct=2625.76, ppl=4.95, accuracy=63.003, wps=12304.1, ups=1.48, wpb=8335.3, bsz=306, num_updates=21000, lr=9.759e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=67, gb_free=16, wall=18348
2023-08-04 17:59:15 | INFO | train_inner | epoch 015:    474 / 1474 loss=2.056, trans_loss=5.1, nll_loss=2.32, w2v_ctc_loss=0.691, task_loss=2.197, contrastive_loss=0.18, total=4074.53, n_correct=2560.16, ppl=4.99, accuracy=62.833, wps=11951.2, ups=1.47, wpb=8149.1, bsz=294.2, num_updates=21100, lr=9.73585e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=68, gb_free=15.7, wall=18416
2023-08-04 18:00:23 | INFO | train_inner | epoch 015:    574 / 1474 loss=2.05, trans_loss=5.097, nll_loss=2.317, w2v_ctc_loss=0.704, task_loss=2.175, contrastive_loss=0.073, total=4140.59, n_correct=2612.62, ppl=4.98, accuracy=63.098, wps=12200, ups=1.47, wpb=8281.2, bsz=298.8, num_updates=21200, lr=9.71286e-05, gnorm=0.512, clip=0, loss_scale=64, train_wall=67, gb_free=12, wall=18484
2023-08-04 18:01:31 | INFO | train_inner | epoch 015:    674 / 1474 loss=2.06, trans_loss=5.099, nll_loss=2.32, w2v_ctc_loss=0.708, task_loss=2.123, contrastive_loss=0.158, total=4134.99, n_correct=2603.3, ppl=4.99, accuracy=62.958, wps=12133, ups=1.47, wpb=8270, bsz=307.1, num_updates=21300, lr=9.69003e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=68, gb_free=10.5, wall=18553
2023-08-04 18:02:39 | INFO | train_inner | epoch 015:    774 / 1474 loss=2.056, trans_loss=5.109, nll_loss=2.333, w2v_ctc_loss=0.708, task_loss=2.128, contrastive_loss=0.076, total=4173.66, n_correct=2619.52, ppl=5.04, accuracy=62.763, wps=12235.4, ups=1.47, wpb=8347.3, bsz=305, num_updates=21400, lr=9.66736e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=18621
2023-08-04 18:03:46 | INFO | train_inner | epoch 015:    874 / 1474 loss=2.061, trans_loss=5.114, nll_loss=2.34, w2v_ctc_loss=0.714, task_loss=2.27, contrastive_loss=0.072, total=4059.35, n_correct=2544.7, ppl=5.06, accuracy=62.687, wps=12043.2, ups=1.48, wpb=8118.7, bsz=288.3, num_updates=21500, lr=9.64486e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=67, gb_free=15.5, wall=18688
2023-08-04 18:04:54 | INFO | train_inner | epoch 015:    974 / 1474 loss=2.059, trans_loss=5.11, nll_loss=2.334, w2v_ctc_loss=0.702, task_loss=2.117, contrastive_loss=0.156, total=4122.87, n_correct=2590.96, ppl=5.04, accuracy=62.844, wps=12206.5, ups=1.48, wpb=8245.7, bsz=301.7, num_updates=21600, lr=9.6225e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=67, gb_free=17.5, wall=18756
2023-08-04 18:05:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 18:06:04 | INFO | train_inner | epoch 015:   1075 / 1474 loss=2.072, trans_loss=5.116, nll_loss=2.344, w2v_ctc_loss=0.706, task_loss=1.991, contrastive_loss=0.314, total=4180.02, n_correct=2616.29, ppl=5.08, accuracy=62.59, wps=12024.2, ups=1.44, wpb=8360, bsz=323, num_updates=21700, lr=9.60031e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=18825
2023-08-04 18:07:11 | INFO | train_inner | epoch 015:   1175 / 1474 loss=2.042, trans_loss=5.101, nll_loss=2.327, w2v_ctc_loss=0.683, task_loss=1.881, contrastive_loss=0.121, total=4187.68, n_correct=2646.52, ppl=5.02, accuracy=63.198, wps=12343.2, ups=1.47, wpb=8375.4, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.509, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=18893
2023-08-04 18:08:19 | INFO | train_inner | epoch 015:   1275 / 1474 loss=2.061, trans_loss=5.112, nll_loss=2.339, w2v_ctc_loss=0.715, task_loss=2.167, contrastive_loss=0.076, total=4141.6, n_correct=2595.51, ppl=5.06, accuracy=62.669, wps=12183.2, ups=1.47, wpb=8283.2, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=68, gb_free=13.4, wall=18961
2023-08-04 18:09:27 | INFO | train_inner | epoch 015:   1375 / 1474 loss=2.054, trans_loss=5.111, nll_loss=2.337, w2v_ctc_loss=0.703, task_loss=2.179, contrastive_loss=0.06, total=4099.6, n_correct=2578.5, ppl=5.05, accuracy=62.896, wps=12123.3, ups=1.48, wpb=8199.2, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=67, gb_free=14.3, wall=19029
2023-08-04 18:09:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 18:09:52 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.19 | trans_loss 5.573 | nll_loss 2.85 | w2v_ctc_loss 1.297 | task_loss 6.947 | contrastive_loss 0.252 | total 4003.4 | n_correct 2473.3 | ppl 7.21 | accuracy 61.78 | uer 17.554 | wer 19.336 | raw_wer 19.336 | bleu 19.9 | wps 2028.1 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.9
2023-08-04 18:09:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-04 18:09:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_15_22000.pt
2023-08-04 18:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_15_22000.pt
2023-08-04 18:10:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.9) (writing took 24.74632361344993 seconds)
2023-08-04 18:11:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 18:11:50 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.195 | trans_loss 5.571 | nll_loss 2.851 | w2v_ctc_loss 1.322 | task_loss 6.929 | contrastive_loss 0.245 | total 4003.4 | n_correct 2476.2 | ppl 7.21 | accuracy 61.852 | uer 17.506 | wer 19.235 | raw_wer 19.235 | bleu 19.77 | wps 2049.2 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 19.9
2023-08-04 18:11:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-08-04 18:11:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.7701.pt
2023-08-04 18:11:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.7701.pt
2023-08-04 18:12:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.7701.pt (epoch 15 @ 22099 updates, score 19.77) (writing took 18.489021096378565 seconds)
2023-08-04 18:12:09 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-04 18:12:09 | INFO | train | epoch 015 | loss 2.055 | trans_loss 5.104 | nll_loss 2.327 | w2v_ctc_loss 0.703 | task_loss 2.106 | contrastive_loss 0.124 | total 4137.68 | n_correct 2603.3 | ppl 5.02 | accuracy 62.917 | wps 11047.5 | ups 1.33 | wpb 8275.4 | bsz 305.4 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.517 | clip 0 | loss_scale 32 | train_wall 995 | gb_free 16.9 | wall 19190
2023-08-04 18:12:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 18:12:09 | INFO | fairseq.trainer | begin training epoch 16
2023-08-04 18:12:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 18:12:17 | INFO | train_inner | epoch 016:      1 / 1474 loss=2.061, trans_loss=5.116, nll_loss=2.346, w2v_ctc_loss=0.705, task_loss=2.015, contrastive_loss=0.151, total=4149.9, n_correct=2605.38, ppl=5.08, accuracy=62.782, wps=4880.5, ups=0.59, wpb=8299.8, bsz=316.3, num_updates=22100, lr=9.51303e-05, gnorm=0.505, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=19199
2023-08-04 18:13:24 | INFO | train_inner | epoch 016:    101 / 1474 loss=2.035, trans_loss=5.074, nll_loss=2.288, w2v_ctc_loss=0.692, task_loss=2.021, contrastive_loss=0.093, total=4118.73, n_correct=2618.06, ppl=4.88, accuracy=63.565, wps=12265, ups=1.49, wpb=8237.5, bsz=314, num_updates=22200, lr=9.49158e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=19266
2023-08-04 18:14:32 | INFO | train_inner | epoch 016:    201 / 1474 loss=2.033, trans_loss=5.073, nll_loss=2.286, w2v_ctc_loss=0.685, task_loss=2.155, contrastive_loss=0.067, total=4106.45, n_correct=2610.32, ppl=4.88, accuracy=63.566, wps=12098.7, ups=1.47, wpb=8212.9, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=19334
2023-08-04 18:15:40 | INFO | train_inner | epoch 016:    301 / 1474 loss=2.046, trans_loss=5.082, nll_loss=2.3, w2v_ctc_loss=0.697, task_loss=2.072, contrastive_loss=0.141, total=4169.65, n_correct=2639.73, ppl=4.92, accuracy=63.308, wps=12230.5, ups=1.47, wpb=8339.3, bsz=309.9, num_updates=22400, lr=9.44911e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=10.6, wall=19402
2023-08-04 18:16:48 | INFO | train_inner | epoch 016:    401 / 1474 loss=2.051, trans_loss=5.085, nll_loss=2.301, w2v_ctc_loss=0.701, task_loss=2.253, contrastive_loss=0.156, total=4063.79, n_correct=2570.14, ppl=4.93, accuracy=63.245, wps=12028.4, ups=1.48, wpb=8127.6, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=67, gb_free=12.6, wall=19470
2023-08-04 18:17:56 | INFO | train_inner | epoch 016:    501 / 1474 loss=2.038, trans_loss=5.081, nll_loss=2.298, w2v_ctc_loss=0.692, task_loss=2.018, contrastive_loss=0.1, total=4179.53, n_correct=2654.45, ppl=4.92, accuracy=63.511, wps=12297.3, ups=1.47, wpb=8359.1, bsz=319.5, num_updates=22600, lr=9.40721e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=67, gb_free=17.7, wall=19538
2023-08-04 18:19:03 | INFO | train_inner | epoch 016:    601 / 1474 loss=2.04, trans_loss=5.086, nll_loss=2.304, w2v_ctc_loss=0.69, task_loss=2.117, contrastive_loss=0.062, total=4121.37, n_correct=2609.76, ppl=4.94, accuracy=63.323, wps=12199.9, ups=1.48, wpb=8242.7, bsz=297.5, num_updates=22700, lr=9.38647e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=67, gb_free=17.8, wall=19605
2023-08-04 18:20:11 | INFO | train_inner | epoch 016:    701 / 1474 loss=2.043, trans_loss=5.091, nll_loss=2.31, w2v_ctc_loss=0.697, task_loss=2.148, contrastive_loss=0.064, total=4099.17, n_correct=2590.91, ppl=4.96, accuracy=63.206, wps=12129.3, ups=1.48, wpb=8198.3, bsz=297.5, num_updates=22800, lr=9.36586e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=19673
2023-08-04 18:21:19 | INFO | train_inner | epoch 016:    801 / 1474 loss=2.043, trans_loss=5.091, nll_loss=2.311, w2v_ctc_loss=0.687, task_loss=2.003, contrastive_loss=0.127, total=4184.53, n_correct=2643.96, ppl=4.96, accuracy=63.184, wps=12325.3, ups=1.47, wpb=8369.1, bsz=313, num_updates=22900, lr=9.34539e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=67, gb_free=13.3, wall=19741
2023-08-04 18:22:27 | INFO | train_inner | epoch 016:    901 / 1474 loss=2.044, trans_loss=5.089, nll_loss=2.309, w2v_ctc_loss=0.691, task_loss=2.06, contrastive_loss=0.118, total=4151.84, n_correct=2629.05, ppl=4.96, accuracy=63.323, wps=12262.4, ups=1.48, wpb=8303.7, bsz=307, num_updates=23000, lr=9.32505e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=19808
2023-08-04 18:23:35 | INFO | train_inner | epoch 016:   1001 / 1474 loss=2.056, trans_loss=5.103, nll_loss=2.327, w2v_ctc_loss=0.708, task_loss=2.17, contrastive_loss=0.118, total=4112.79, n_correct=2588.49, ppl=5.02, accuracy=62.938, wps=12059.6, ups=1.47, wpb=8225.6, bsz=299.5, num_updates=23100, lr=9.30484e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=19877
2023-08-04 18:24:43 | INFO | train_inner | epoch 016:   1101 / 1474 loss=2.057, trans_loss=5.107, nll_loss=2.332, w2v_ctc_loss=0.709, task_loss=2.23, contrastive_loss=0.091, total=4111.6, n_correct=2584.96, ppl=5.04, accuracy=62.87, wps=12043.9, ups=1.46, wpb=8223.2, bsz=295.6, num_updates=23200, lr=9.28477e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=19945
2023-08-04 18:25:52 | INFO | train_inner | epoch 016:   1201 / 1474 loss=2.051, trans_loss=5.1, nll_loss=2.324, w2v_ctc_loss=0.685, task_loss=2.145, contrastive_loss=0.188, total=4157.51, n_correct=2620.17, ppl=5.01, accuracy=63.023, wps=12100.3, ups=1.46, wpb=8315, bsz=306.6, num_updates=23300, lr=9.26482e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=20014
2023-08-04 18:27:00 | INFO | train_inner | epoch 016:   1301 / 1474 loss=2.054, trans_loss=5.1, nll_loss=2.323, w2v_ctc_loss=0.703, task_loss=2.039, contrastive_loss=0.166, total=4151.03, n_correct=2617.83, ppl=5, accuracy=63.065, wps=12214.3, ups=1.47, wpb=8302.1, bsz=314.5, num_updates=23400, lr=9.245e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=67, gb_free=16, wall=20082
2023-08-04 18:28:08 | INFO | train_inner | epoch 016:   1401 / 1474 loss=2.047, trans_loss=5.101, nll_loss=2.326, w2v_ctc_loss=0.7, task_loss=2.003, contrastive_loss=0.098, total=4201.47, n_correct=2652.72, ppl=5.01, accuracy=63.138, wps=12301.7, ups=1.46, wpb=8402.9, bsz=320.7, num_updates=23500, lr=9.22531e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=20150
2023-08-04 18:28:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 18:29:23 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.189 | trans_loss 5.569 | nll_loss 2.844 | w2v_ctc_loss 1.306 | task_loss 6.973 | contrastive_loss 0.249 | total 4003.4 | n_correct 2474.2 | ppl 7.18 | accuracy 61.802 | uer 17.524 | wer 19.242 | raw_wer 19.242 | bleu 19.66 | wps 1958.7 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 19.9
2023-08-04 18:29:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-08-04 18:29:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.6605.pt
2023-08-04 18:29:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.6605.pt
2023-08-04 18:29:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.6605.pt (epoch 16 @ 23573 updates, score 19.66) (writing took 14.024289041757584 seconds)
2023-08-04 18:29:37 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-04 18:29:37 | INFO | train | epoch 016 | loss 2.046 | trans_loss 5.091 | nll_loss 2.31 | w2v_ctc_loss 0.695 | task_loss 2.1 | contrastive_loss 0.122 | total 4138.65 | n_correct 2616.82 | ppl 4.96 | accuracy 63.229 | wps 11634.2 | ups 1.41 | wpb 8277.3 | bsz 305.7 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.525 | clip 0 | loss_scale 32 | train_wall 995 | gb_free 15.4 | wall 20239
2023-08-04 18:29:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 18:29:38 | INFO | fairseq.trainer | begin training epoch 17
2023-08-04 18:29:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 18:30:04 | INFO | train_inner | epoch 017:     27 / 1474 loss=2.048, trans_loss=5.084, nll_loss=2.302, w2v_ctc_loss=0.689, task_loss=2.147, contrastive_loss=0.23, total=4145.04, n_correct=2628.02, ppl=4.93, accuracy=63.402, wps=7189.1, ups=0.87, wpb=8290.1, bsz=302.4, num_updates=23600, lr=9.20575e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=20265
2023-08-04 18:31:12 | INFO | train_inner | epoch 017:    127 / 1474 loss=2.032, trans_loss=5.062, nll_loss=2.272, w2v_ctc_loss=0.693, task_loss=2.161, contrastive_loss=0.068, total=4117.27, n_correct=2629.49, ppl=4.83, accuracy=63.865, wps=12083.1, ups=1.47, wpb=8234.5, bsz=296.2, num_updates=23700, lr=9.1863e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=68, gb_free=17.8, wall=20333
2023-08-04 18:32:19 | INFO | train_inner | epoch 017:    227 / 1474 loss=2.033, trans_loss=5.059, nll_loss=2.27, w2v_ctc_loss=0.672, task_loss=1.99, contrastive_loss=0.234, total=4159.6, n_correct=2654.24, ppl=4.82, accuracy=63.81, wps=12280.6, ups=1.48, wpb=8319.2, bsz=317.6, num_updates=23800, lr=9.16698e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=67, gb_free=16.9, wall=20401
2023-08-04 18:33:27 | INFO | train_inner | epoch 017:    327 / 1474 loss=2.039, trans_loss=5.069, nll_loss=2.282, w2v_ctc_loss=0.682, task_loss=2.096, contrastive_loss=0.236, total=4156.91, n_correct=2643.9, ppl=4.86, accuracy=63.603, wps=12314, ups=1.48, wpb=8313.8, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=67, gb_free=17.5, wall=20469
2023-08-04 18:34:35 | INFO | train_inner | epoch 017:    427 / 1474 loss=2.026, trans_loss=5.068, nll_loss=2.28, w2v_ctc_loss=0.681, task_loss=2.085, contrastive_loss=0.067, total=4146.43, n_correct=2647.07, ppl=4.86, accuracy=63.84, wps=12117.8, ups=1.46, wpb=8292.9, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=68, gb_free=16.2, wall=20537
2023-08-04 18:34:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 18:34:58 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.569 | nll_loss 2.842 | w2v_ctc_loss 1.332 | task_loss 6.972 | contrastive_loss 0.252 | total 4003.4 | n_correct 2473.8 | ppl 7.17 | accuracy 61.792 | uer 17.4 | wer 19.246 | raw_wer 19.246 | bleu 19.61 | wps 2251.1 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.9
2023-08-04 18:34:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-04 18:34:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_17_24000.pt
2023-08-04 18:35:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_17_24000.pt
2023-08-04 18:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.61) (writing took 35.716689547523856 seconds)
2023-08-04 18:36:44 | INFO | train_inner | epoch 017:    527 / 1474 loss=2.035, trans_loss=5.073, nll_loss=2.288, w2v_ctc_loss=0.689, task_loss=2.181, contrastive_loss=0.112, total=4182.1, n_correct=2661.49, ppl=4.88, accuracy=63.64, wps=6488.1, ups=0.78, wpb=8364.2, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.515, clip=0, loss_scale=64, train_wall=69, gb_free=16.7, wall=20666
2023-08-04 18:37:52 | INFO | train_inner | epoch 017:    627 / 1474 loss=2.031, trans_loss=5.077, nll_loss=2.293, w2v_ctc_loss=0.685, task_loss=2.116, contrastive_loss=0.061, total=4167.27, n_correct=2650.88, ppl=4.9, accuracy=63.612, wps=12239.8, ups=1.47, wpb=8334.5, bsz=302.2, num_updates=24200, lr=9.09091e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=68, gb_free=10.6, wall=20734
2023-08-04 18:39:00 | INFO | train_inner | epoch 017:    727 / 1474 loss=2.042, trans_loss=5.081, nll_loss=2.299, w2v_ctc_loss=0.698, task_loss=2.08, contrastive_loss=0.112, total=4166.12, n_correct=2644.1, ppl=4.92, accuracy=63.467, wps=12294.1, ups=1.48, wpb=8332.2, bsz=308.1, num_updates=24300, lr=9.07218e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=67, gb_free=16.3, wall=20802
2023-08-04 18:40:08 | INFO | train_inner | epoch 017:    827 / 1474 loss=2.034, trans_loss=5.08, nll_loss=2.297, w2v_ctc_loss=0.688, task_loss=2.13, contrastive_loss=0.074, total=4091.64, n_correct=2599.03, ppl=4.91, accuracy=63.52, wps=12049, ups=1.47, wpb=8183.3, bsz=295.3, num_updates=24400, lr=9.05357e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=67, gb_free=17.3, wall=20870
2023-08-04 18:41:16 | INFO | train_inner | epoch 017:    927 / 1474 loss=2.032, trans_loss=5.081, nll_loss=2.299, w2v_ctc_loss=0.682, task_loss=2.072, contrastive_loss=0.073, total=4106.83, n_correct=2607.25, ppl=4.92, accuracy=63.486, wps=12171.2, ups=1.48, wpb=8213.7, bsz=304.6, num_updates=24500, lr=9.03508e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=67, gb_free=15.8, wall=20937
2023-08-04 18:42:23 | INFO | train_inner | epoch 017:   1027 / 1474 loss=2.032, trans_loss=5.078, nll_loss=2.296, w2v_ctc_loss=0.686, task_loss=2.074, contrastive_loss=0.077, total=4115.49, n_correct=2620.13, ppl=4.91, accuracy=63.665, wps=12119.6, ups=1.47, wpb=8231, bsz=305.8, num_updates=24600, lr=9.0167e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=21005
2023-08-04 18:43:31 | INFO | train_inner | epoch 017:   1127 / 1474 loss=2.033, trans_loss=5.081, nll_loss=2.299, w2v_ctc_loss=0.684, task_loss=2.185, contrastive_loss=0.063, total=4078.39, n_correct=2593.08, ppl=4.92, accuracy=63.581, wps=12111.5, ups=1.48, wpb=8156.8, bsz=293.7, num_updates=24700, lr=8.99843e-05, gnorm=0.513, clip=0, loss_scale=64, train_wall=67, gb_free=15.5, wall=21073
2023-08-04 18:43:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 18:44:40 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2.048, trans_loss=5.089, nll_loss=2.311, w2v_ctc_loss=0.682, task_loss=2.093, contrastive_loss=0.257, total=4148.2, n_correct=2618.99, ppl=4.96, accuracy=63.136, wps=11927.3, ups=1.44, wpb=8296.4, bsz=315.7, num_updates=24800, lr=8.98027e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=21142
2023-08-04 18:45:49 | INFO | train_inner | epoch 017:   1328 / 1474 loss=2.037, trans_loss=5.087, nll_loss=2.307, w2v_ctc_loss=0.676, task_loss=2.09, contrastive_loss=0.147, total=4149.03, n_correct=2631.8, ppl=4.95, accuracy=63.432, wps=12145.1, ups=1.46, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=21210
2023-08-04 18:46:57 | INFO | train_inner | epoch 017:   1428 / 1474 loss=2.034, trans_loss=5.087, nll_loss=2.307, w2v_ctc_loss=0.683, task_loss=2.111, contrastive_loss=0.067, total=4117.13, n_correct=2612.12, ppl=4.95, accuracy=63.445, wps=12099.1, ups=1.47, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=21278
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:0')
2023-08-04 18:47:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:2')
2023-08-04 18:47:52 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.196 | trans_loss 5.565 | nll_loss 2.844 | w2v_ctc_loss 1.335 | task_loss 6.982 | contrastive_loss 0.255 | total 4003.4 | n_correct 2472.1 | ppl 7.18 | accuracy 61.75 | uer 17.328 | wer 19.004 | raw_wer 19.004 | bleu 19.53 | wps 2194.3 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 19.9
2023-08-04 18:47:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-08-04 18:47:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.5304.pt
2023-08-04 18:47:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.5304.pt
2023-08-04 18:48:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_19.5304.pt (epoch 17 @ 25046 updates, score 19.53) (writing took 13.68462137132883 seconds)
2023-08-04 18:48:06 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-04 18:48:06 | INFO | train | epoch 017 | loss 2.035 | trans_loss 5.076 | nll_loss 2.293 | w2v_ctc_loss 0.685 | task_loss 2.105 | contrastive_loss 0.116 | total 4136.92 | n_correct 2630.27 | ppl 4.9 | accuracy 63.58 | wps 10996.9 | ups 1.33 | wpb 8273.8 | bsz 305.1 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.519 | clip 0 | loss_scale 32 | train_wall 996 | gb_free 16.3 | wall 21347
2023-08-04 18:48:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 18:48:06 | INFO | fairseq.trainer | begin training epoch 18
2023-08-04 18:48:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 18:48:51 | INFO | train_inner | epoch 018:     54 / 1474 loss=2.031, trans_loss=5.071, nll_loss=2.285, w2v_ctc_loss=0.689, task_loss=2.145, contrastive_loss=0.078, total=4138.21, n_correct=2634.59, ppl=4.87, accuracy=63.665, wps=7268.5, ups=0.88, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=21392
2023-08-04 18:49:59 | INFO | train_inner | epoch 018:    154 / 1474 loss=2.02, trans_loss=5.046, nll_loss=2.253, w2v_ctc_loss=0.66, task_loss=1.998, contrastive_loss=0.201, total=4158.88, n_correct=2668.77, ppl=4.77, accuracy=64.17, wps=12108.2, ups=1.46, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=21461
2023-08-04 18:51:08 | INFO | train_inner | epoch 018:    254 / 1474 loss=2.013, trans_loss=5.047, nll_loss=2.254, w2v_ctc_loss=0.671, task_loss=2.038, contrastive_loss=0.069, total=4164.11, n_correct=2676.49, ppl=4.77, accuracy=64.275, wps=12208.2, ups=1.47, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=21529
2023-08-04 18:52:16 | INFO | train_inner | epoch 018:    354 / 1474 loss=2.022, trans_loss=5.054, nll_loss=2.262, w2v_ctc_loss=0.678, task_loss=2.133, contrastive_loss=0.083, total=4163.13, n_correct=2663.65, ppl=4.8, accuracy=63.982, wps=12233.2, ups=1.47, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=21597
2023-08-04 18:53:24 | INFO | train_inner | epoch 018:    454 / 1474 loss=2.031, trans_loss=5.062, nll_loss=2.274, w2v_ctc_loss=0.676, task_loss=2.247, contrastive_loss=0.174, total=4087.83, n_correct=2605.58, ppl=4.84, accuracy=63.74, wps=11999.4, ups=1.47, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=21665
2023-08-04 18:54:32 | INFO | train_inner | epoch 018:    554 / 1474 loss=2.011, trans_loss=5.047, nll_loss=2.255, w2v_ctc_loss=0.668, task_loss=1.887, contrastive_loss=0.083, total=4204.41, n_correct=2698.96, ppl=4.77, accuracy=64.194, wps=12315.5, ups=1.46, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=68, gb_free=17.4, wall=21734
2023-08-04 18:55:40 | INFO | train_inner | epoch 018:    654 / 1474 loss=2.034, trans_loss=5.073, nll_loss=2.288, w2v_ctc_loss=0.682, task_loss=2.176, contrastive_loss=0.152, total=4096.81, n_correct=2608.65, ppl=4.89, accuracy=63.675, wps=12095.2, ups=1.48, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=21801
2023-08-04 18:56:48 | INFO | train_inner | epoch 018:    754 / 1474 loss=2.038, trans_loss=5.069, nll_loss=2.284, w2v_ctc_loss=0.685, task_loss=2.003, contrastive_loss=0.241, total=4208.29, n_correct=2678.4, ppl=4.87, accuracy=63.646, wps=12405.8, ups=1.47, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=67, gb_free=17.8, wall=21869
2023-08-04 18:57:56 | INFO | train_inner | epoch 018:    854 / 1474 loss=2.025, trans_loss=5.07, nll_loss=2.284, w2v_ctc_loss=0.677, task_loss=2.135, contrastive_loss=0.058, total=4166.81, n_correct=2658.89, ppl=4.87, accuracy=63.811, wps=12266.8, ups=1.47, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=67, gb_free=12.5, wall=21937
2023-08-04 18:59:03 | INFO | train_inner | epoch 018:    954 / 1474 loss=2.015, trans_loss=5.059, nll_loss=2.271, w2v_ctc_loss=0.666, task_loss=1.958, contrastive_loss=0.082, total=4142.65, n_correct=2651.95, ppl=4.83, accuracy=64.016, wps=12274.7, ups=1.48, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=67, gb_free=14.7, wall=22005
2023-08-04 18:59:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 18:59:27 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.194 | trans_loss 5.57 | nll_loss 2.845 | w2v_ctc_loss 1.32 | task_loss 6.938 | contrastive_loss 0.247 | total 4003.4 | n_correct 2474.5 | ppl 7.18 | accuracy 61.81 | uer 17.458 | wer 19.246 | raw_wer 19.246 | bleu 20.04 | wps 2170.6 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.04
2023-08-04 18:59:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-04 18:59:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_18_26000.pt
2023-08-04 18:59:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_18_26000.pt
2023-08-04 19:00:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 20.04) (writing took 42.2475448846817 seconds)
2023-08-04 19:01:18 | INFO | train_inner | epoch 018:   1054 / 1474 loss=2.023, trans_loss=5.068, nll_loss=2.283, w2v_ctc_loss=0.67, task_loss=2.19, contrastive_loss=0.07, total=4137.77, n_correct=2640.18, ppl=4.87, accuracy=63.807, wps=6141.2, ups=0.74, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=22140
2023-08-04 19:02:26 | INFO | train_inner | epoch 018:   1154 / 1474 loss=2.025, trans_loss=5.055, nll_loss=2.266, w2v_ctc_loss=0.674, task_loss=1.993, contrastive_loss=0.179, total=4153.69, n_correct=2659.03, ppl=4.81, accuracy=64.016, wps=12288.4, ups=1.48, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=67, gb_free=15, wall=22207
2023-08-04 19:03:33 | INFO | train_inner | epoch 018:   1254 / 1474 loss=2.031, trans_loss=5.081, nll_loss=2.298, w2v_ctc_loss=0.679, task_loss=2.254, contrastive_loss=0.062, total=4087.62, n_correct=2595.93, ppl=4.92, accuracy=63.507, wps=12088.6, ups=1.48, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=22275
2023-08-04 19:04:41 | INFO | train_inner | epoch 018:   1354 / 1474 loss=2.04, trans_loss=5.085, nll_loss=2.305, w2v_ctc_loss=0.693, task_loss=2.238, contrastive_loss=0.088, total=4070.69, n_correct=2581.29, ppl=4.94, accuracy=63.412, wps=12012.2, ups=1.48, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=22343
2023-08-04 19:05:49 | INFO | train_inner | epoch 018:   1454 / 1474 loss=2.03, trans_loss=5.077, nll_loss=2.295, w2v_ctc_loss=0.681, task_loss=2.214, contrastive_loss=0.074, total=4113.2, n_correct=2614.7, ppl=4.91, accuracy=63.569, wps=12114.7, ups=1.47, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=22410
2023-08-04 19:06:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 19:06:25 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.188 | trans_loss 5.553 | nll_loss 2.827 | w2v_ctc_loss 1.337 | task_loss 6.9 | contrastive_loss 0.252 | total 4003.4 | n_correct 2479.1 | ppl 7.09 | accuracy 61.925 | uer 16.994 | wer 18.534 | raw_wer 18.534 | bleu 20.02 | wps 2176.1 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 20.04
2023-08-04 19:06:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-08-04 19:06:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.0209.pt
2023-08-04 19:06:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.0209.pt
2023-08-04 19:06:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.0209.pt (epoch 18 @ 26520 updates, score 20.02) (writing took 13.150635376572609 seconds)
2023-08-04 19:06:39 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-04 19:06:39 | INFO | train | epoch 018 | loss 2.026 | trans_loss 5.063 | nll_loss 2.276 | w2v_ctc_loss 0.676 | task_loss 2.102 | contrastive_loss 0.119 | total 4138.65 | n_correct 2642.42 | ppl 4.84 | accuracy 63.848 | wps 10960.8 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.52 | clip 0 | loss_scale 32 | train_wall 995 | gb_free 15.9 | wall 22461
2023-08-04 19:06:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 19:06:39 | INFO | fairseq.trainer | begin training epoch 19
2023-08-04 19:06:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 19:07:40 | INFO | train_inner | epoch 019:     80 / 1474 loss=2.016, trans_loss=5.04, nll_loss=2.245, w2v_ctc_loss=0.67, task_loss=2.107, contrastive_loss=0.125, total=4102.06, n_correct=2636.83, ppl=4.74, accuracy=64.281, wps=7381.2, ups=0.9, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=67, gb_free=17.4, wall=22522
2023-08-04 19:08:49 | INFO | train_inner | epoch 019:    180 / 1474 loss=2.013, trans_loss=5.033, nll_loss=2.236, w2v_ctc_loss=0.676, task_loss=1.96, contrastive_loss=0.118, total=4227.7, n_correct=2725.19, ppl=4.71, accuracy=64.46, wps=12261.8, ups=1.45, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=22591
2023-08-04 19:09:58 | INFO | train_inner | epoch 019:    280 / 1474 loss=2.008, trans_loss=5.036, nll_loss=2.239, w2v_ctc_loss=0.671, task_loss=2.076, contrastive_loss=0.06, total=4187.34, n_correct=2700.91, ppl=4.72, accuracy=64.502, wps=12166.4, ups=1.45, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.514, clip=0, loss_scale=64, train_wall=68, gb_free=15.9, wall=22659
2023-08-04 19:11:05 | INFO | train_inner | epoch 019:    380 / 1474 loss=2.016, trans_loss=5.041, nll_loss=2.248, w2v_ctc_loss=0.661, task_loss=2.072, contrastive_loss=0.169, total=4170.52, n_correct=2684.65, ppl=4.75, accuracy=64.372, wps=12332.8, ups=1.48, wpb=8341, bsz=311, num_updates=26900, lr=8.62261e-05, gnorm=0.516, clip=0, loss_scale=64, train_wall=67, gb_free=16.3, wall=22727
2023-08-04 19:12:13 | INFO | train_inner | epoch 019:    480 / 1474 loss=2.016, trans_loss=5.049, nll_loss=2.258, w2v_ctc_loss=0.673, task_loss=2.158, contrastive_loss=0.076, total=4113.89, n_correct=2641.3, ppl=4.78, accuracy=64.204, wps=12204.3, ups=1.48, wpb=8227.8, bsz=301.5, num_updates=27000, lr=8.60663e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=67, gb_free=17.1, wall=22795
2023-08-04 19:13:21 | INFO | train_inner | epoch 019:    580 / 1474 loss=2.014, trans_loss=5.045, nll_loss=2.253, w2v_ctc_loss=0.666, task_loss=2.06, contrastive_loss=0.14, total=4128.58, n_correct=2656.45, ppl=4.77, accuracy=64.343, wps=12172, ups=1.47, wpb=8257.2, bsz=306.2, num_updates=27100, lr=8.59074e-05, gnorm=0.517, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=22862
2023-08-04 19:14:29 | INFO | train_inner | epoch 019:    680 / 1474 loss=2.002, trans_loss=5.046, nll_loss=2.255, w2v_ctc_loss=0.652, task_loss=1.912, contrastive_loss=0.066, total=4201.56, n_correct=2704.29, ppl=4.77, accuracy=64.364, wps=12338.4, ups=1.47, wpb=8403.1, bsz=321.5, num_updates=27200, lr=8.57493e-05, gnorm=0.506, clip=0, loss_scale=64, train_wall=68, gb_free=17.8, wall=22930
2023-08-04 19:15:37 | INFO | train_inner | epoch 019:    780 / 1474 loss=2.016, trans_loss=5.048, nll_loss=2.257, w2v_ctc_loss=0.675, task_loss=2.165, contrastive_loss=0.072, total=4124.03, n_correct=2647.9, ppl=4.78, accuracy=64.207, wps=12153.9, ups=1.47, wpb=8248.1, bsz=299, num_updates=27300, lr=8.55921e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=67, gb_free=17.5, wall=22998
2023-08-04 19:16:44 | INFO | train_inner | epoch 019:    880 / 1474 loss=2.02, trans_loss=5.06, nll_loss=2.273, w2v_ctc_loss=0.675, task_loss=2.09, contrastive_loss=0.069, total=4177.8, n_correct=2672.71, ppl=4.83, accuracy=63.974, wps=12347, ups=1.48, wpb=8355.6, bsz=309.6, num_updates=27400, lr=8.54358e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=67, gb_free=14.8, wall=23066
2023-08-04 19:17:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 19:17:54 | INFO | train_inner | epoch 019:    981 / 1474 loss=2.033, trans_loss=5.069, nll_loss=2.286, w2v_ctc_loss=0.674, task_loss=2.171, contrastive_loss=0.236, total=4072.4, n_correct=2595.56, ppl=4.88, accuracy=63.735, wps=11687.5, ups=1.43, wpb=8144.8, bsz=301.4, num_updates=27500, lr=8.52803e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=23136
2023-08-04 19:19:02 | INFO | train_inner | epoch 019:   1081 / 1474 loss=2.026, trans_loss=5.071, nll_loss=2.287, w2v_ctc_loss=0.672, task_loss=2.249, contrastive_loss=0.106, total=4036.97, n_correct=2576.1, ppl=4.88, accuracy=63.813, wps=11883.9, ups=1.47, wpb=8073.9, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=67, gb_free=14.6, wall=23204
2023-08-04 19:20:10 | INFO | train_inner | epoch 019:   1181 / 1474 loss=2.034, trans_loss=5.067, nll_loss=2.282, w2v_ctc_loss=0.678, task_loss=2.135, contrastive_loss=0.189, total=4137.49, n_correct=2636.09, ppl=4.86, accuracy=63.712, wps=12092.9, ups=1.46, wpb=8275, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=23272
2023-08-04 19:21:17 | INFO | train_inner | epoch 019:   1281 / 1474 loss=2.02, trans_loss=5.068, nll_loss=2.283, w2v_ctc_loss=0.666, task_loss=2.128, contrastive_loss=0.086, total=4141.89, n_correct=2645.68, ppl=4.87, accuracy=63.876, wps=12395.9, ups=1.5, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=66, gb_free=15.5, wall=23339
2023-08-04 19:22:25 | INFO | train_inner | epoch 019:   1381 / 1474 loss=2.02, trans_loss=5.062, nll_loss=2.276, w2v_ctc_loss=0.671, task_loss=2.15, contrastive_loss=0.072, total=4133.26, n_correct=2644, ppl=4.85, accuracy=63.969, wps=12241.8, ups=1.48, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=23406
2023-08-04 19:23:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 19:23:52 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.179 | trans_loss 5.551 | nll_loss 2.823 | w2v_ctc_loss 1.313 | task_loss 7.006 | contrastive_loss 0.25 | total 4003.4 | n_correct 2484.8 | ppl 7.08 | accuracy 62.067 | uer 17.049 | wer 18.81 | raw_wer 18.81 | bleu 20.16 | wps 2179.2 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.16
2023-08-04 19:23:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-08-04 19:23:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 19:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt
2023-08-04 19:24:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_best.pt (epoch 19 @ 27993 updates, score 20.16) (writing took 23.541224844753742 seconds)
2023-08-04 19:24:16 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-04 19:24:16 | INFO | train | epoch 019 | loss 2.018 | trans_loss 5.053 | nll_loss 2.263 | w2v_ctc_loss 0.67 | task_loss 2.106 | contrastive_loss 0.113 | total 4137.38 | n_correct 2653.44 | ppl 4.8 | accuracy 64.133 | wps 11530.4 | ups 1.39 | wpb 8274.8 | bsz 305.2 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.521 | clip 0 | loss_scale 32 | train_wall 995 | gb_free 17.3 | wall 23518
2023-08-04 19:24:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 19:24:16 | INFO | fairseq.trainer | begin training epoch 20
2023-08-04 19:24:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 19:24:28 | INFO | train_inner | epoch 020:      7 / 1474 loss=2.018, trans_loss=5.055, nll_loss=2.267, w2v_ctc_loss=0.664, task_loss=2.121, contrastive_loss=0.156, total=4119.08, n_correct=2641.59, ppl=4.81, accuracy=64.131, wps=6680.4, ups=0.81, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=23530
2023-08-04 19:24:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 19:24:51 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.176 | trans_loss 5.552 | nll_loss 2.822 | w2v_ctc_loss 1.305 | task_loss 6.98 | contrastive_loss 0.242 | total 4003.4 | n_correct 2487.5 | ppl 7.07 | accuracy 62.135 | uer 16.959 | wer 18.635 | raw_wer 18.635 | bleu 20.6 | wps 2256 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.6
2023-08-04 19:24:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-04 19:24:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_20_28000.pt
2023-08-04 19:24:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_20_28000.pt
2023-08-04 19:25:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.6) (writing took 24.48786094225943 seconds)
2023-08-04 19:26:25 | INFO | train_inner | epoch 020:    107 / 1474 loss=1.996, trans_loss=5.02, nll_loss=2.22, w2v_ctc_loss=0.653, task_loss=2.028, contrastive_loss=0.08, total=4195.03, n_correct=2718.85, ppl=4.66, accuracy=64.811, wps=7190.9, ups=0.86, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=23646
2023-08-04 19:27:33 | INFO | train_inner | epoch 020:    207 / 1474 loss=2.007, trans_loss=5.03, nll_loss=2.233, w2v_ctc_loss=0.66, task_loss=2.179, contrastive_loss=0.132, total=4154.14, n_correct=2681.48, ppl=4.7, accuracy=64.55, wps=12236.2, ups=1.47, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=23714
2023-08-04 19:28:41 | INFO | train_inner | epoch 020:    307 / 1474 loss=1.996, trans_loss=5.022, nll_loss=2.224, w2v_ctc_loss=0.66, task_loss=1.892, contrastive_loss=0.071, total=4188.05, n_correct=2709.96, ppl=4.67, accuracy=64.707, wps=12284.1, ups=1.47, wpb=8376.1, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=23783
2023-08-04 19:29:49 | INFO | train_inner | epoch 020:    407 / 1474 loss=2.001, trans_loss=5.029, nll_loss=2.232, w2v_ctc_loss=0.654, task_loss=2.128, contrastive_loss=0.067, total=4115.16, n_correct=2659.79, ppl=4.7, accuracy=64.634, wps=12160.8, ups=1.48, wpb=8230.3, bsz=297, num_updates=28400, lr=8.39181e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=67, gb_free=15.4, wall=23850
2023-08-04 19:30:56 | INFO | train_inner | epoch 020:    507 / 1474 loss=2.013, trans_loss=5.044, nll_loss=2.251, w2v_ctc_loss=0.658, task_loss=2.148, contrastive_loss=0.155, total=4108.46, n_correct=2642.36, ppl=4.76, accuracy=64.315, wps=12148.8, ups=1.48, wpb=8216.9, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=23918
2023-08-04 19:32:03 | INFO | train_inner | epoch 020:    607 / 1474 loss=2.019, trans_loss=5.045, nll_loss=2.252, w2v_ctc_loss=0.665, task_loss=2.215, contrastive_loss=0.159, total=4094.9, n_correct=2629.71, ppl=4.77, accuracy=64.219, wps=12168.6, ups=1.49, wpb=8189.8, bsz=296.1, num_updates=28600, lr=8.36242e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=67, gb_free=11.8, wall=23985
2023-08-04 19:33:12 | INFO | train_inner | epoch 020:    707 / 1474 loss=2.009, trans_loss=5.044, nll_loss=2.251, w2v_ctc_loss=0.667, task_loss=2.105, contrastive_loss=0.06, total=4140.23, n_correct=2661.59, ppl=4.76, accuracy=64.286, wps=12148.5, ups=1.47, wpb=8280.5, bsz=300.6, num_updates=28700, lr=8.34784e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=24053
2023-08-04 19:34:19 | INFO | train_inner | epoch 020:    807 / 1474 loss=2.009, trans_loss=5.042, nll_loss=2.249, w2v_ctc_loss=0.67, task_loss=2.087, contrastive_loss=0.064, total=4140.66, n_correct=2668.04, ppl=4.75, accuracy=64.435, wps=12213.8, ups=1.47, wpb=8281.3, bsz=305.6, num_updates=28800, lr=8.33333e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=24121
2023-08-04 19:35:28 | INFO | train_inner | epoch 020:    907 / 1474 loss=2.032, trans_loss=5.053, nll_loss=2.265, w2v_ctc_loss=0.665, task_loss=2.007, contrastive_loss=0.358, total=4157.15, n_correct=2663.02, ppl=4.81, accuracy=64.059, wps=12148.7, ups=1.46, wpb=8314.3, bsz=322.6, num_updates=28900, lr=8.3189e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=24190
2023-08-04 19:36:36 | INFO | train_inner | epoch 020:   1007 / 1474 loss=2.006, trans_loss=5.044, nll_loss=2.253, w2v_ctc_loss=0.658, task_loss=2.073, contrastive_loss=0.07, total=4171.86, n_correct=2686.61, ppl=4.77, accuracy=64.398, wps=12289.6, ups=1.47, wpb=8343.7, bsz=308.6, num_updates=29000, lr=8.30455e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=67, gb_free=15.7, wall=24257
2023-08-04 19:37:44 | INFO | train_inner | epoch 020:   1107 / 1474 loss=2.018, trans_loss=5.049, nll_loss=2.26, w2v_ctc_loss=0.66, task_loss=2.03, contrastive_loss=0.207, total=4162.96, n_correct=2676.57, ppl=4.79, accuracy=64.295, wps=12138.8, ups=1.46, wpb=8325.9, bsz=314.9, num_updates=29100, lr=8.29027e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=24326
2023-08-04 19:38:52 | INFO | train_inner | epoch 020:   1207 / 1474 loss=2.014, trans_loss=5.044, nll_loss=2.252, w2v_ctc_loss=0.674, task_loss=2.304, contrastive_loss=0.058, total=4033.74, n_correct=2590.66, ppl=4.76, accuracy=64.225, wps=11870.4, ups=1.47, wpb=8067.5, bsz=285.2, num_updates=29200, lr=8.27606e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=24394
2023-08-04 19:40:01 | INFO | train_inner | epoch 020:   1307 / 1474 loss=2.011, trans_loss=5.055, nll_loss=2.267, w2v_ctc_loss=0.662, task_loss=2.217, contrastive_loss=0.063, total=4124.42, n_correct=2650.6, ppl=4.81, accuracy=64.266, wps=12092.5, ups=1.47, wpb=8248.8, bsz=297, num_updates=29300, lr=8.26192e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=24462
2023-08-04 19:41:08 | INFO | train_inner | epoch 020:   1407 / 1474 loss=2.011, trans_loss=5.051, nll_loss=2.261, w2v_ctc_loss=0.663, task_loss=2.225, contrastive_loss=0.062, total=4114.1, n_correct=2646.05, ppl=4.79, accuracy=64.317, wps=12164.8, ups=1.48, wpb=8228.2, bsz=293.7, num_updates=29400, lr=8.24786e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=67, gb_free=14.4, wall=24530
2023-08-04 19:41:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 19:42:18 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.176 | trans_loss 5.553 | nll_loss 2.824 | w2v_ctc_loss 1.299 | task_loss 6.915 | contrastive_loss 0.255 | total 4003.4 | n_correct 2485.6 | ppl 7.08 | accuracy 62.087 | uer 17.142 | wer 18.892 | raw_wer 18.892 | bleu 20.15 | wps 2103.1 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.6
2023-08-04 19:42:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-08-04 19:42:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.1503.pt
2023-08-04 19:42:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.1503.pt
2023-08-04 19:42:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.1503.pt (epoch 20 @ 29467 updates, score 20.15) (writing took 17.714907348155975 seconds)
2023-08-04 19:42:36 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-04 19:42:36 | INFO | train | epoch 020 | loss 2.01 | trans_loss 5.041 | nll_loss 2.249 | w2v_ctc_loss 0.662 | task_loss 2.101 | contrastive_loss 0.116 | total 4138.65 | n_correct 2664.76 | ppl 4.75 | accuracy 64.387 | wps 11093 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.522 | clip 0 | loss_scale 32 | train_wall 995 | gb_free 16.1 | wall 24618
2023-08-04 19:42:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 19:42:36 | INFO | fairseq.trainer | begin training epoch 21
2023-08-04 19:42:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 19:43:06 | INFO | train_inner | epoch 021:     33 / 1474 loss=2.015, trans_loss=5.047, nll_loss=2.257, w2v_ctc_loss=0.661, task_loss=1.987, contrastive_loss=0.184, total=4155.01, n_correct=2669.98, ppl=4.78, accuracy=64.259, wps=7081.6, ups=0.85, wpb=8310, bsz=317.6, num_updates=29500, lr=8.23387e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=68, gb_free=16.2, wall=24647
2023-08-04 19:43:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 19:44:15 | INFO | train_inner | epoch 021:    134 / 1474 loss=1.99, trans_loss=5.011, nll_loss=2.208, w2v_ctc_loss=0.652, task_loss=2.033, contrastive_loss=0.063, total=4168.09, n_correct=2707.98, ppl=4.62, accuracy=64.969, wps=12018.3, ups=1.44, wpb=8336.2, bsz=310.2, num_updates=29600, lr=8.21995e-05, gnorm=0.512, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=24717
2023-08-04 19:45:23 | INFO | train_inner | epoch 021:    234 / 1474 loss=1.991, trans_loss=5.018, nll_loss=2.217, w2v_ctc_loss=0.642, task_loss=2.004, contrastive_loss=0.129, total=4155.31, n_correct=2697.98, ppl=4.65, accuracy=64.928, wps=12297.5, ups=1.48, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.518, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=24784
2023-08-04 19:46:31 | INFO | train_inner | epoch 021:    334 / 1474 loss=1.999, trans_loss=5.02, nll_loss=2.221, w2v_ctc_loss=0.654, task_loss=2.085, contrastive_loss=0.133, total=4151.51, n_correct=2687.81, ppl=4.66, accuracy=64.743, wps=12095.7, ups=1.46, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=24853
2023-08-04 19:47:39 | INFO | train_inner | epoch 021:    434 / 1474 loss=1.989, trans_loss=5.019, nll_loss=2.219, w2v_ctc_loss=0.643, task_loss=2.039, contrastive_loss=0.056, total=4180.85, n_correct=2713.79, ppl=4.65, accuracy=64.91, wps=12288.4, ups=1.47, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=24921
2023-08-04 19:48:47 | INFO | train_inner | epoch 021:    534 / 1474 loss=1.993, trans_loss=5.018, nll_loss=2.218, w2v_ctc_loss=0.652, task_loss=2.185, contrastive_loss=0.056, total=4083.98, n_correct=2648.94, ppl=4.65, accuracy=64.862, wps=12046.2, ups=1.47, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=67, gb_free=12.9, wall=24989
2023-08-04 19:48:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 19:49:10 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.176 | trans_loss 5.561 | nll_loss 2.834 | w2v_ctc_loss 1.28 | task_loss 6.97 | contrastive_loss 0.251 | total 4003.4 | n_correct 2486.3 | ppl 7.13 | accuracy 62.105 | uer 17.11 | wer 18.884 | raw_wer 18.884 | bleu 20.06 | wps 2270.6 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.6
2023-08-04 19:49:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-04 19:49:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_21_30000.pt
2023-08-04 19:49:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_21_30000.pt
2023-08-04 19:49:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 20.06) (writing took 18.797854280099273 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:0')
2023-08-04 19:50:37 | INFO | train_inner | epoch 021:    634 / 1474 loss=2.005, trans_loss=5.025, nll_loss=2.228, w2v_ctc_loss=0.647, task_loss=2.079, contrastive_loss=0.228, total=4215.41, n_correct=2724.11, ppl=4.69, accuracy=64.623, wps=7632.8, ups=0.91, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=11.2, wall=25099
2023-08-04 19:51:46 | INFO | train_inner | epoch 021:    734 / 1474 loss=2.002, trans_loss=5.036, nll_loss=2.242, w2v_ctc_loss=0.653, task_loss=2.091, contrastive_loss=0.09, total=4152.97, n_correct=2682.19, ppl=4.73, accuracy=64.585, wps=12174.9, ups=1.47, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=25167
2023-08-04 19:52:54 | INFO | train_inner | epoch 021:    834 / 1474 loss=2.006, trans_loss=5.04, nll_loss=2.246, w2v_ctc_loss=0.654, task_loss=2.218, contrastive_loss=0.101, total=4066.93, n_correct=2623.18, ppl=4.74, accuracy=64.5, wps=11867, ups=1.46, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=25236
2023-08-04 19:54:02 | INFO | train_inner | epoch 021:    934 / 1474 loss=1.999, trans_loss=5.031, nll_loss=2.235, w2v_ctc_loss=0.653, task_loss=2.104, contrastive_loss=0.075, total=4103.34, n_correct=2650.36, ppl=4.71, accuracy=64.59, wps=12123.1, ups=1.48, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=67, gb_free=13.9, wall=25304
2023-08-04 19:55:09 | INFO | train_inner | epoch 021:   1034 / 1474 loss=2.005, trans_loss=5.046, nll_loss=2.256, w2v_ctc_loss=0.655, task_loss=2.137, contrastive_loss=0.072, total=4099.86, n_correct=2638.53, ppl=4.78, accuracy=64.357, wps=12170.2, ups=1.48, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=67, gb_free=11.2, wall=25371
2023-08-04 19:56:17 | INFO | train_inner | epoch 021:   1134 / 1474 loss=2.005, trans_loss=5.037, nll_loss=2.242, w2v_ctc_loss=0.658, task_loss=2.26, contrastive_loss=0.074, total=4120.75, n_correct=2657.49, ppl=4.73, accuracy=64.49, wps=12100.2, ups=1.47, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=25439
2023-08-04 19:57:25 | INFO | train_inner | epoch 021:   1234 / 1474 loss=2.003, trans_loss=5.036, nll_loss=2.243, w2v_ctc_loss=0.652, task_loss=1.996, contrastive_loss=0.127, total=4154.73, n_correct=2678.11, ppl=4.73, accuracy=64.459, wps=12308.2, ups=1.48, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=67, gb_free=12.5, wall=25507
2023-08-04 19:58:34 | INFO | train_inner | epoch 021:   1334 / 1474 loss=2.004, trans_loss=5.039, nll_loss=2.247, w2v_ctc_loss=0.657, task_loss=2.032, contrastive_loss=0.088, total=4147.17, n_correct=2676.21, ppl=4.75, accuracy=64.531, wps=12079.1, ups=1.46, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=25575
2023-08-04 19:59:42 | INFO | train_inner | epoch 021:   1434 / 1474 loss=2.019, trans_loss=5.049, nll_loss=2.259, w2v_ctc_loss=0.673, task_loss=2.195, contrastive_loss=0.139, total=4133.93, n_correct=2653.35, ppl=4.79, accuracy=64.185, wps=12152.7, ups=1.47, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=25643
2023-08-04 20:00:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:1')
2023-08-04 20:00:34 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.184 | trans_loss 5.557 | nll_loss 2.832 | w2v_ctc_loss 1.318 | task_loss 6.892 | contrastive_loss 0.248 | total 4003.4 | n_correct 2485.8 | ppl 7.12 | accuracy 62.092 | uer 17.193 | wer 18.948 | raw_wer 18.948 | bleu 20.18 | wps 2076.3 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.6
2023-08-04 20:00:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-08-04 20:00:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.1804.pt
2023-08-04 20:00:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.1804.pt
2023-08-04 20:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.1804.pt (epoch 21 @ 30940 updates, score 20.18) (writing took 16.92710119858384 seconds)
2023-08-04 20:00:51 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-04 20:00:51 | INFO | train | epoch 021 | loss 2.001 | trans_loss 5.031 | nll_loss 2.235 | w2v_ctc_loss 0.653 | task_loss 2.105 | contrastive_loss 0.107 | total 4137.02 | n_correct 2673.41 | ppl 4.71 | accuracy 64.621 | wps 11130.6 | ups 1.35 | wpb 8274 | bsz 305.1 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.524 | clip 0 | loss_scale 32 | train_wall 997 | gb_free 15.4 | wall 25713
2023-08-04 20:00:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 20:00:51 | INFO | fairseq.trainer | begin training epoch 22
2023-08-04 20:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 20:01:40 | INFO | train_inner | epoch 022:     60 / 1474 loss=1.993, trans_loss=5.017, nll_loss=2.217, w2v_ctc_loss=0.653, task_loss=2.134, contrastive_loss=0.054, total=4128.84, n_correct=2685.42, ppl=4.65, accuracy=65.041, wps=7002.3, ups=0.85, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=14.1, wall=25761
2023-08-04 20:02:48 | INFO | train_inner | epoch 022:    160 / 1474 loss=1.993, trans_loss=5.006, nll_loss=2.203, w2v_ctc_loss=0.65, task_loss=2.109, contrastive_loss=0.141, total=4123.35, n_correct=2682.32, ppl=4.6, accuracy=65.052, wps=12046, ups=1.46, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=25830
2023-08-04 20:03:56 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.977, trans_loss=5.002, nll_loss=2.199, w2v_ctc_loss=0.633, task_loss=1.848, contrastive_loss=0.079, total=4267.16, n_correct=2787.23, ppl=4.59, accuracy=65.318, wps=12559.2, ups=1.47, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.515, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=25898
2023-08-04 20:04:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 20:05:06 | INFO | train_inner | epoch 022:    361 / 1474 loss=2, trans_loss=5.016, nll_loss=2.216, w2v_ctc_loss=0.65, task_loss=2.172, contrastive_loss=0.179, total=4163.56, n_correct=2701.64, ppl=4.65, accuracy=64.888, wps=11948.1, ups=1.43, wpb=8327.1, bsz=304, num_updates=31300, lr=7.99361e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=25967
2023-08-04 20:06:14 | INFO | train_inner | epoch 022:    461 / 1474 loss=2, trans_loss=5.023, nll_loss=2.224, w2v_ctc_loss=0.651, task_loss=2.206, contrastive_loss=0.12, total=4132.96, n_correct=2681.9, ppl=4.67, accuracy=64.891, wps=12160.2, ups=1.47, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=26035
2023-08-04 20:07:22 | INFO | train_inner | epoch 022:    561 / 1474 loss=1.991, trans_loss=5.016, nll_loss=2.215, w2v_ctc_loss=0.65, task_loss=2.097, contrastive_loss=0.067, total=4158.17, n_correct=2704.86, ppl=4.64, accuracy=65.049, wps=12119.4, ups=1.46, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=26104
2023-08-04 20:08:30 | INFO | train_inner | epoch 022:    661 / 1474 loss=1.987, trans_loss=5.01, nll_loss=2.21, w2v_ctc_loss=0.635, task_loss=2.005, contrastive_loss=0.15, total=4139.66, n_correct=2692.51, ppl=4.63, accuracy=65.042, wps=12232.5, ups=1.48, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=67, gb_free=16.1, wall=26172
2023-08-04 20:09:38 | INFO | train_inner | epoch 022:    761 / 1474 loss=1.992, trans_loss=5.016, nll_loss=2.215, w2v_ctc_loss=0.651, task_loss=2.156, contrastive_loss=0.069, total=4167.89, n_correct=2709.16, ppl=4.64, accuracy=65.001, wps=12242.9, ups=1.47, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=68, gb_free=12.7, wall=26240
2023-08-04 20:10:47 | INFO | train_inner | epoch 022:    861 / 1474 loss=1.998, trans_loss=5.028, nll_loss=2.232, w2v_ctc_loss=0.653, task_loss=2.271, contrastive_loss=0.055, total=4075.79, n_correct=2634.36, ppl=4.7, accuracy=64.634, wps=11901.4, ups=1.46, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=26308
2023-08-04 20:11:55 | INFO | train_inner | epoch 022:    961 / 1474 loss=1.989, trans_loss=5.022, nll_loss=2.224, w2v_ctc_loss=0.641, task_loss=2.114, contrastive_loss=0.056, total=4134.72, n_correct=2685.32, ppl=4.67, accuracy=64.946, wps=12132.7, ups=1.47, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=14.1, wall=26376
2023-08-04 20:13:03 | INFO | train_inner | epoch 022:   1061 / 1474 loss=1.999, trans_loss=5.02, nll_loss=2.223, w2v_ctc_loss=0.643, task_loss=2.008, contrastive_loss=0.226, total=4160.57, n_correct=2699.88, ppl=4.67, accuracy=64.892, wps=12273.6, ups=1.47, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=67, gb_free=17.2, wall=26444
2023-08-04 20:13:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 20:13:26 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.183 | trans_loss 5.553 | nll_loss 2.825 | w2v_ctc_loss 1.322 | task_loss 6.948 | contrastive_loss 0.248 | total 4003.4 | n_correct 2486.7 | ppl 7.09 | accuracy 62.115 | uer 17.025 | wer 18.776 | raw_wer 18.776 | bleu 20.01 | wps 2141.5 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.6
2023-08-04 20:13:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-04 20:13:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_22_32000.pt
2023-08-04 20:13:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_22_32000.pt
2023-08-04 20:13:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 20.01) (writing took 31.63800742663443 seconds)
2023-08-04 20:15:06 | INFO | train_inner | epoch 022:   1161 / 1474 loss=2.009, trans_loss=5.042, nll_loss=2.251, w2v_ctc_loss=0.661, task_loss=2.169, contrastive_loss=0.108, total=4099.59, n_correct=2644.33, ppl=4.76, accuracy=64.502, wps=6655.5, ups=0.81, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=67, gb_free=14.9, wall=26567
2023-08-04 20:16:14 | INFO | train_inner | epoch 022:   1261 / 1474 loss=1.999, trans_loss=5.035, nll_loss=2.242, w2v_ctc_loss=0.651, task_loss=1.943, contrastive_loss=0.104, total=4182.05, n_correct=2701.74, ppl=4.73, accuracy=64.603, wps=12283.8, ups=1.47, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=15.5, wall=26636
2023-08-04 20:17:21 | INFO | train_inner | epoch 022:   1361 / 1474 loss=1.993, trans_loss=5.024, nll_loss=2.228, w2v_ctc_loss=0.64, task_loss=2.109, contrastive_loss=0.125, total=4062.31, n_correct=2634.91, ppl=4.69, accuracy=64.862, wps=12083.5, ups=1.49, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=67, gb_free=15, wall=26703
2023-08-04 20:18:29 | INFO | train_inner | epoch 022:   1461 / 1474 loss=2.008, trans_loss=5.047, nll_loss=2.255, w2v_ctc_loss=0.662, task_loss=2.253, contrastive_loss=0.072, total=4081.88, n_correct=2629.02, ppl=4.77, accuracy=64.407, wps=12029.1, ups=1.47, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.552, clip=0, loss_scale=16, train_wall=67, gb_free=17.2, wall=26771
2023-08-04 20:18:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 20:19:03 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.172 | trans_loss 5.547 | nll_loss 2.817 | w2v_ctc_loss 1.3 | task_loss 6.885 | contrastive_loss 0.247 | total 4003.4 | n_correct 2489.6 | ppl 7.05 | accuracy 62.187 | uer 17.007 | wer 18.81 | raw_wer 18.81 | bleu 20.25 | wps 1974.9 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.6
2023-08-04 20:19:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-08-04 20:19:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2501.pt
2023-08-04 20:19:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2501.pt
2023-08-04 20:19:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2501.pt (epoch 22 @ 32413 updates, score 20.25) (writing took 13.114513970911503 seconds)
2023-08-04 20:19:17 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-04 20:19:17 | INFO | train | epoch 022 | loss 1.995 | trans_loss 5.021 | nll_loss 2.223 | w2v_ctc_loss 0.648 | task_loss 2.103 | contrastive_loss 0.109 | total 4137.49 | n_correct 2684.55 | ppl 4.67 | accuracy 64.884 | wps 11024.7 | ups 1.33 | wpb 8275 | bsz 305.2 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.531 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 11.6 | wall 26818
2023-08-04 20:19:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 20:19:17 | INFO | fairseq.trainer | begin training epoch 23
2023-08-04 20:19:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 20:20:23 | INFO | train_inner | epoch 023:     87 / 1474 loss=1.981, trans_loss=4.997, nll_loss=2.192, w2v_ctc_loss=0.646, task_loss=2.147, contrastive_loss=0.062, total=4096.09, n_correct=2677.19, ppl=4.57, accuracy=65.36, wps=7163.9, ups=0.87, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=26885
2023-08-04 20:21:32 | INFO | train_inner | epoch 023:    187 / 1474 loss=1.978, trans_loss=4.994, nll_loss=2.187, w2v_ctc_loss=0.635, task_loss=2.239, contrastive_loss=0.059, total=4107.77, n_correct=2689.76, ppl=4.55, accuracy=65.48, wps=12024.4, ups=1.46, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=26953
2023-08-04 20:22:40 | INFO | train_inner | epoch 023:    287 / 1474 loss=1.983, trans_loss=5.002, nll_loss=2.198, w2v_ctc_loss=0.631, task_loss=2.106, contrastive_loss=0.139, total=4153.12, n_correct=2709.09, ppl=4.59, accuracy=65.23, wps=12177, ups=1.47, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=27022
2023-08-04 20:23:48 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.981, trans_loss=5.004, nll_loss=2.199, w2v_ctc_loss=0.638, task_loss=2.184, contrastive_loss=0.052, total=4116.7, n_correct=2688.76, ppl=4.59, accuracy=65.313, wps=12160.3, ups=1.48, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=67, gb_free=15.2, wall=27089
2023-08-04 20:24:55 | INFO | train_inner | epoch 023:    487 / 1474 loss=1.988, trans_loss=5.008, nll_loss=2.206, w2v_ctc_loss=0.643, task_loss=2.041, contrastive_loss=0.114, total=4157.6, n_correct=2708.58, ppl=4.61, accuracy=65.148, wps=12267.5, ups=1.48, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=67, gb_free=17.3, wall=27157
2023-08-04 20:26:03 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.973, trans_loss=4.997, nll_loss=2.192, w2v_ctc_loss=0.631, task_loss=1.989, contrastive_loss=0.057, total=4173.42, n_correct=2730.29, ppl=4.57, accuracy=65.421, wps=12294.7, ups=1.47, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=67, gb_free=12.5, wall=27225
2023-08-04 20:27:11 | INFO | train_inner | epoch 023:    687 / 1474 loss=1.982, trans_loss=5.003, nll_loss=2.2, w2v_ctc_loss=0.635, task_loss=2.107, contrastive_loss=0.098, total=4137.82, n_correct=2702.04, ppl=4.6, accuracy=65.301, wps=12294.8, ups=1.49, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=67, gb_free=17.1, wall=27292
2023-08-04 20:28:19 | INFO | train_inner | epoch 023:    787 / 1474 loss=1.989, trans_loss=5.015, nll_loss=2.216, w2v_ctc_loss=0.643, task_loss=2.117, contrastive_loss=0.078, total=4150.99, n_correct=2699.91, ppl=4.64, accuracy=65.043, wps=12218.4, ups=1.47, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=27360
2023-08-04 20:29:26 | INFO | train_inner | epoch 023:    887 / 1474 loss=1.988, trans_loss=5.01, nll_loss=2.21, w2v_ctc_loss=0.639, task_loss=1.916, contrastive_loss=0.159, total=4181.99, n_correct=2724.46, ppl=4.63, accuracy=65.147, wps=12359.8, ups=1.48, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=27428
2023-08-04 20:30:35 | INFO | train_inner | epoch 023:    987 / 1474 loss=1.996, trans_loss=5.013, nll_loss=2.213, w2v_ctc_loss=0.631, task_loss=2.094, contrastive_loss=0.312, total=4168.73, n_correct=2715.55, ppl=4.64, accuracy=65.141, wps=12199.1, ups=1.46, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=68, gb_free=10.7, wall=27496
2023-08-04 20:31:43 | INFO | train_inner | epoch 023:   1087 / 1474 loss=1.994, trans_loss=5.021, nll_loss=2.223, w2v_ctc_loss=0.652, task_loss=2.242, contrastive_loss=0.064, total=4088.49, n_correct=2652.91, ppl=4.67, accuracy=64.887, wps=11917.6, ups=1.46, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=27565
2023-08-04 20:32:51 | INFO | train_inner | epoch 023:   1187 / 1474 loss=1.987, trans_loss=5.02, nll_loss=2.222, w2v_ctc_loss=0.644, task_loss=2.086, contrastive_loss=0.057, total=4162.7, n_correct=2704.42, ppl=4.67, accuracy=64.968, wps=12217.7, ups=1.47, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=27633
2023-08-04 20:33:59 | INFO | train_inner | epoch 023:   1287 / 1474 loss=1.983, trans_loss=5.018, nll_loss=2.22, w2v_ctc_loss=0.636, task_loss=2.044, contrastive_loss=0.07, total=4135.53, n_correct=2693.56, ppl=4.66, accuracy=65.132, wps=12225, ups=1.48, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=27701
2023-08-04 20:35:08 | INFO | train_inner | epoch 023:   1387 / 1474 loss=2.002, trans_loss=5.039, nll_loss=2.247, w2v_ctc_loss=0.648, task_loss=2.122, contrastive_loss=0.129, total=4143.98, n_correct=2679.84, ppl=4.75, accuracy=64.668, wps=12087.9, ups=1.46, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=27769
2023-08-04 20:36:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 20:36:30 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.176 | trans_loss 5.554 | nll_loss 2.825 | w2v_ctc_loss 1.302 | task_loss 6.956 | contrastive_loss 0.24 | total 4003.4 | n_correct 2491.7 | ppl 7.08 | accuracy 62.24 | uer 16.792 | wer 18.586 | raw_wer 18.586 | bleu 20.24 | wps 2158.4 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.6
2023-08-04 20:36:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-08-04 20:36:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2409.pt
2023-08-04 20:36:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2409.pt
2023-08-04 20:36:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2409.pt (epoch 23 @ 33887 updates, score 20.24) (writing took 13.558736370876431 seconds)
2023-08-04 20:36:44 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-04 20:36:44 | INFO | train | epoch 023 | loss 1.987 | trans_loss 5.011 | nll_loss 2.211 | w2v_ctc_loss 0.639 | task_loss 2.101 | contrastive_loss 0.112 | total 4138.65 | n_correct 2695.65 | ppl 4.63 | accuracy 65.134 | wps 11645.5 | ups 1.41 | wpb 8277.3 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.531 | clip 0 | loss_scale 32 | train_wall 995 | gb_free 13.6 | wall 27866
2023-08-04 20:36:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 20:36:44 | INFO | fairseq.trainer | begin training epoch 24
2023-08-04 20:36:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 20:37:01 | INFO | train_inner | epoch 024:     13 / 1474 loss=2.001, trans_loss=5.027, nll_loss=2.232, w2v_ctc_loss=0.639, task_loss=2.111, contrastive_loss=0.206, total=4085.11, n_correct=2646.66, ppl=4.7, accuracy=64.788, wps=7221.5, ups=0.88, wpb=8170.2, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=12.5, wall=27882
2023-08-04 20:38:09 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.979, trans_loss=4.984, nll_loss=2.174, w2v_ctc_loss=0.628, task_loss=1.938, contrastive_loss=0.224, total=4171.44, n_correct=2736.88, ppl=4.51, accuracy=65.61, wps=12283.7, ups=1.47, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=27950
2023-08-04 20:38:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 20:38:33 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.186 | trans_loss 5.561 | nll_loss 2.831 | w2v_ctc_loss 1.313 | task_loss 6.901 | contrastive_loss 0.25 | total 4003.4 | n_correct 2485.9 | ppl 7.12 | accuracy 62.095 | uer 17.012 | wer 18.802 | raw_wer 18.802 | bleu 19.86 | wps 2013.4 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.6
2023-08-04 20:38:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-04 20:38:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_24_34000.pt
2023-08-04 20:38:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_24_34000.pt
2023-08-04 20:38:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.86) (writing took 13.698604729026556 seconds)
2023-08-04 20:39:56 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.977, trans_loss=4.986, nll_loss=2.179, w2v_ctc_loss=0.618, task_loss=1.839, contrastive_loss=0.277, total=4251.29, n_correct=2789.26, ppl=4.53, accuracy=65.61, wps=7890.6, ups=0.93, wpb=8502.6, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=28058
2023-08-04 20:41:04 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.971, trans_loss=4.991, nll_loss=2.183, w2v_ctc_loss=0.632, task_loss=2.057, contrastive_loss=0.054, total=4128.18, n_correct=2706.43, ppl=4.54, accuracy=65.56, wps=12200.6, ups=1.48, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=28126
2023-08-04 20:42:12 | INFO | train_inner | epoch 024:    413 / 1474 loss=1.995, trans_loss=5, nll_loss=2.196, w2v_ctc_loss=0.644, task_loss=2.193, contrastive_loss=0.201, total=4158.92, n_correct=2712.94, ppl=4.58, accuracy=65.232, wps=12187, ups=1.47, wpb=8317.8, bsz=299.7, num_updates=34300, lr=7.63604e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=28194
2023-08-04 20:43:20 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.98, trans_loss=4.996, nll_loss=2.19, w2v_ctc_loss=0.634, task_loss=2.128, contrastive_loss=0.124, total=4144.91, n_correct=2712.91, ppl=4.56, accuracy=65.452, wps=12192.2, ups=1.47, wpb=8289.8, bsz=303.3, num_updates=34400, lr=7.62493e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=28262
2023-08-04 20:44:28 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.975, trans_loss=4.995, nll_loss=2.189, w2v_ctc_loss=0.628, task_loss=2.111, contrastive_loss=0.087, total=4165.3, n_correct=2726.7, ppl=4.56, accuracy=65.462, wps=12226.6, ups=1.47, wpb=8330.6, bsz=307.7, num_updates=34500, lr=7.61387e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=28330
2023-08-04 20:45:36 | INFO | train_inner | epoch 024:    713 / 1474 loss=1.985, trans_loss=5.009, nll_loss=2.206, w2v_ctc_loss=0.636, task_loss=2.166, contrastive_loss=0.099, total=4102.21, n_correct=2679.12, ppl=4.62, accuracy=65.309, wps=12111, ups=1.48, wpb=8204.4, bsz=295.1, num_updates=34600, lr=7.60286e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=28398
2023-08-04 20:46:45 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.98, trans_loss=5.008, nll_loss=2.207, w2v_ctc_loss=0.633, task_loss=2.114, contrastive_loss=0.076, total=4110.6, n_correct=2681.76, ppl=4.62, accuracy=65.24, wps=12003.7, ups=1.46, wpb=8221.2, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=28466
2023-08-04 20:47:52 | INFO | train_inner | epoch 024:    913 / 1474 loss=1.989, trans_loss=5.016, nll_loss=2.216, w2v_ctc_loss=0.643, task_loss=2.328, contrastive_loss=0.049, total=4043.03, n_correct=2626, ppl=4.64, accuracy=64.951, wps=11953, ups=1.48, wpb=8086.1, bsz=281, num_updates=34800, lr=7.58098e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=67, gb_free=11.1, wall=28534
2023-08-04 20:49:01 | INFO | train_inner | epoch 024:   1013 / 1474 loss=1.98, trans_loss=5.011, nll_loss=2.21, w2v_ctc_loss=0.633, task_loss=2.173, contrastive_loss=0.053, total=4136.81, n_correct=2701.93, ppl=4.63, accuracy=65.314, wps=12088, ups=1.46, wpb=8273.6, bsz=298.4, num_updates=34900, lr=7.57011e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=28602
2023-08-04 20:50:09 | INFO | train_inner | epoch 024:   1113 / 1474 loss=1.981, trans_loss=5, nll_loss=2.197, w2v_ctc_loss=0.639, task_loss=2.02, contrastive_loss=0.098, total=4135.73, n_correct=2700.76, ppl=4.58, accuracy=65.303, wps=12132.6, ups=1.47, wpb=8271.5, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=28671
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:0')
2023-08-04 20:51:17 | INFO | train_inner | epoch 024:   1213 / 1474 loss=1.98, trans_loss=5.01, nll_loss=2.209, w2v_ctc_loss=0.632, task_loss=2.079, contrastive_loss=0.087, total=4148.3, n_correct=2706.44, ppl=4.62, accuracy=65.242, wps=12170.9, ups=1.47, wpb=8296.6, bsz=310.8, num_updates=35100, lr=7.54851e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=28739
2023-08-04 20:52:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 20:52:26 | INFO | train_inner | epoch 024:   1314 / 1474 loss=1.991, trans_loss=5.019, nll_loss=2.221, w2v_ctc_loss=0.649, task_loss=2.223, contrastive_loss=0.059, total=4107.17, n_correct=2668.02, ppl=4.66, accuracy=64.96, wps=11971.4, ups=1.46, wpb=8214.3, bsz=294.8, num_updates=35200, lr=7.53778e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=28807
2023-08-04 20:53:34 | INFO | train_inner | epoch 024:   1414 / 1474 loss=1.989, trans_loss=5.021, nll_loss=2.224, w2v_ctc_loss=0.646, task_loss=2.195, contrastive_loss=0.058, total=4094.39, n_correct=2662.31, ppl=4.67, accuracy=65.023, wps=12006.8, ups=1.47, wpb=8188.8, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=28876
2023-08-04 20:54:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:7')
2023-08-04 20:54:37 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.176 | trans_loss 5.551 | nll_loss 2.821 | w2v_ctc_loss 1.304 | task_loss 6.948 | contrastive_loss 0.247 | total 4003.4 | n_correct 2491.9 | ppl 7.07 | accuracy 62.245 | uer 16.962 | wer 18.705 | raw_wer 18.705 | bleu 19.85 | wps 2295.4 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 20.6
2023-08-04 20:54:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-08-04 20:54:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_last.pt
2023-08-04 20:54:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_last.pt
2023-08-04 20:54:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_last.pt (epoch 24 @ 35360 updates, score 19.85) (writing took 12.893865413963795 seconds)
2023-08-04 20:54:50 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-04 20:54:50 | INFO | train | epoch 024 | loss 1.982 | trans_loss 5.003 | nll_loss 2.2 | w2v_ctc_loss 0.635 | task_loss 2.098 | contrastive_loss 0.111 | total 4138.64 | n_correct 2702.95 | ppl 4.59 | accuracy 65.31 | wps 11225.7 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.531 | clip 0 | loss_scale 16 | train_wall 997 | gb_free 16.1 | wall 28952
2023-08-04 20:54:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 20:54:51 | INFO | fairseq.trainer | begin training epoch 25
2023-08-04 20:54:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 20:55:24 | INFO | train_inner | epoch 025:     40 / 1474 loss=1.97, trans_loss=4.993, nll_loss=2.188, w2v_ctc_loss=0.628, task_loss=2.026, contrastive_loss=0.065, total=4165.57, n_correct=2732.55, ppl=4.56, accuracy=65.598, wps=7542, ups=0.91, wpb=8331.1, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=67, gb_free=13, wall=28986
2023-08-04 20:56:32 | INFO | train_inner | epoch 025:    140 / 1474 loss=1.962, trans_loss=4.974, nll_loss=2.162, w2v_ctc_loss=0.622, task_loss=2.039, contrastive_loss=0.063, total=4135.43, n_correct=2726.15, ppl=4.48, accuracy=65.922, wps=12184, ups=1.47, wpb=8270.9, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=67, gb_free=17.7, wall=29054
2023-08-04 20:57:40 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.966, trans_loss=4.98, nll_loss=2.17, w2v_ctc_loss=0.625, task_loss=2.154, contrastive_loss=0.066, total=4116.13, n_correct=2709.4, ppl=4.5, accuracy=65.824, wps=12069.6, ups=1.47, wpb=8232.3, bsz=303, num_updates=35600, lr=7.49532e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=29122
2023-08-04 20:58:49 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.974, trans_loss=4.986, nll_loss=2.176, w2v_ctc_loss=0.628, task_loss=2.239, contrastive_loss=0.095, total=4141.49, n_correct=2714.85, ppl=4.52, accuracy=65.552, wps=12023, ups=1.45, wpb=8283, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=68, gb_free=15.1, wall=29191
2023-08-04 20:59:58 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.989, trans_loss=4.991, nll_loss=2.184, w2v_ctc_loss=0.645, task_loss=2.195, contrastive_loss=0.173, total=4167.4, n_correct=2726.65, ppl=4.54, accuracy=65.428, wps=12177.4, ups=1.46, wpb=8334.8, bsz=297.7, num_updates=35800, lr=7.47435e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=29260
2023-08-04 21:01:06 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.973, trans_loss=4.997, nll_loss=2.192, w2v_ctc_loss=0.63, task_loss=2.043, contrastive_loss=0.067, total=4160.61, n_correct=2725.65, ppl=4.57, accuracy=65.511, wps=12171.8, ups=1.46, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=29328
2023-08-04 21:02:14 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.977, trans_loss=4.988, nll_loss=2.182, w2v_ctc_loss=0.633, task_loss=2.077, contrastive_loss=0.135, total=4153.68, n_correct=2724.91, ppl=4.54, accuracy=65.602, wps=12308.9, ups=1.48, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=29395
2023-08-04 21:02:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 21:02:39 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.181 | trans_loss 5.548 | nll_loss 2.818 | w2v_ctc_loss 1.328 | task_loss 6.932 | contrastive_loss 0.251 | total 4003.4 | n_correct 2493.2 | ppl 7.05 | accuracy 62.277 | uer 17.187 | wer 19.052 | raw_wer 19.052 | bleu 19.7 | wps 1922.1 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.6
2023-08-04 21:02:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-04 21:02:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_25_36000.pt
2023-08-04 21:02:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_25_36000.pt
2023-08-04 21:02:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.7) (writing took 13.939241584390402 seconds)
2023-08-04 21:04:02 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.981, trans_loss=4.993, nll_loss=2.187, w2v_ctc_loss=0.634, task_loss=2.128, contrastive_loss=0.13, total=4128.34, n_correct=2702.2, ppl=4.55, accuracy=65.455, wps=7650.2, ups=0.93, wpb=8256.7, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=29503
2023-08-04 21:05:09 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.968, trans_loss=4.994, nll_loss=2.19, w2v_ctc_loss=0.623, task_loss=1.937, contrastive_loss=0.076, total=4182.4, n_correct=2745.52, ppl=4.56, accuracy=65.645, wps=12348.1, ups=1.48, wpb=8364.8, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=67, gb_free=17.7, wall=29571
2023-08-04 21:06:17 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.978, trans_loss=5, nll_loss=2.199, w2v_ctc_loss=0.633, task_loss=1.994, contrastive_loss=0.133, total=4155.21, n_correct=2721.2, ppl=4.59, accuracy=65.489, wps=12257.3, ups=1.47, wpb=8310.4, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=67, gb_free=14, wall=29639
2023-08-04 21:07:25 | INFO | train_inner | epoch 025:   1040 / 1474 loss=1.986, trans_loss=5.007, nll_loss=2.206, w2v_ctc_loss=0.623, task_loss=2.087, contrastive_loss=0.242, total=4177.7, n_correct=2726.69, ppl=4.61, accuracy=65.268, wps=12264.2, ups=1.47, wpb=8355.4, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=29707
2023-08-04 21:08:33 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.973, trans_loss=5.001, nll_loss=2.196, w2v_ctc_loss=0.624, task_loss=2.273, contrastive_loss=0.048, total=4039.24, n_correct=2644.3, ppl=4.58, accuracy=65.465, wps=11864.7, ups=1.47, wpb=8078.5, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=29775
2023-08-04 21:09:41 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.976, trans_loss=5.006, nll_loss=2.204, w2v_ctc_loss=0.63, task_loss=2.122, contrastive_loss=0.059, total=4090.59, n_correct=2673.7, ppl=4.61, accuracy=65.362, wps=12174.8, ups=1.49, wpb=8181.2, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=67, gb_free=17.2, wall=29842
2023-08-04 21:10:48 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.982, trans_loss=5.001, nll_loss=2.198, w2v_ctc_loss=0.633, task_loss=2.047, contrastive_loss=0.154, total=4164.34, n_correct=2722.62, ppl=4.59, accuracy=65.379, wps=12278.8, ups=1.47, wpb=8328.7, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=67, gb_free=16.8, wall=29910
2023-08-04 21:11:57 | INFO | train_inner | epoch 025:   1440 / 1474 loss=1.989, trans_loss=5.019, nll_loss=2.221, w2v_ctc_loss=0.638, task_loss=2.187, contrastive_loss=0.103, total=4099.11, n_correct=2662.79, ppl=4.66, accuracy=64.96, wps=12037, ups=1.47, wpb=8198.2, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=12.1, wall=29978
2023-08-04 21:12:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 21:12:45 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.174 | trans_loss 5.544 | nll_loss 2.816 | w2v_ctc_loss 1.309 | task_loss 6.989 | contrastive_loss 0.255 | total 4003.4 | n_correct 2486.1 | ppl 7.04 | accuracy 62.1 | uer 16.98 | wer 18.862 | raw_wer 18.862 | bleu 20.09 | wps 2011.8 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.6
2023-08-04 21:12:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-08-04 21:12:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.0902.pt
2023-08-04 21:12:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.0902.pt
2023-08-04 21:12:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.0902.pt (epoch 25 @ 36834 updates, score 20.09) (writing took 13.740140542387962 seconds)
2023-08-04 21:12:59 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-04 21:12:59 | INFO | train | epoch 025 | loss 1.976 | trans_loss 4.995 | nll_loss 2.19 | w2v_ctc_loss 0.63 | task_loss 2.099 | contrastive_loss 0.109 | total 4138.65 | n_correct 2710.63 | ppl 4.56 | accuracy 65.495 | wps 11205.6 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.53 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 14.2 | wall 30041
2023-08-04 21:12:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 21:12:59 | INFO | fairseq.trainer | begin training epoch 26
2023-08-04 21:12:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 21:13:52 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.961, trans_loss=4.974, nll_loss=2.163, w2v_ctc_loss=0.619, task_loss=1.977, contrastive_loss=0.089, total=4180.21, n_correct=2754.94, ppl=4.48, accuracy=65.904, wps=7237.9, ups=0.87, wpb=8360.4, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=30094
2023-08-04 21:14:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-04 21:15:01 | INFO | train_inner | epoch 026:    167 / 1474 loss=1.968, trans_loss=4.97, nll_loss=2.159, w2v_ctc_loss=0.611, task_loss=1.844, contrastive_loss=0.277, total=4275.85, n_correct=2823.62, ppl=4.47, accuracy=66.036, wps=12396.7, ups=1.45, wpb=8551.7, bsz=341.4, num_updates=37000, lr=7.35215e-05, gnorm=0.522, clip=0, loss_scale=8, train_wall=68, gb_free=15.4, wall=30163
2023-08-04 21:16:09 | INFO | train_inner | epoch 026:    267 / 1474 loss=1.971, trans_loss=4.977, nll_loss=2.166, w2v_ctc_loss=0.627, task_loss=2.081, contrastive_loss=0.148, total=4123.94, n_correct=2711.35, ppl=4.49, accuracy=65.747, wps=12087.1, ups=1.47, wpb=8247.9, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.522, clip=0, loss_scale=8, train_wall=68, gb_free=16.9, wall=30231
2023-08-04 21:17:17 | INFO | train_inner | epoch 026:    367 / 1474 loss=1.966, trans_loss=4.978, nll_loss=2.168, w2v_ctc_loss=0.625, task_loss=2.001, contrastive_loss=0.107, total=4168.11, n_correct=2744.92, ppl=4.5, accuracy=65.855, wps=12302.4, ups=1.48, wpb=8336.2, bsz=315.2, num_updates=37200, lr=7.33236e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=67, gb_free=17.2, wall=30299
2023-08-04 21:18:25 | INFO | train_inner | epoch 026:    467 / 1474 loss=1.966, trans_loss=4.971, nll_loss=2.159, w2v_ctc_loss=0.621, task_loss=2.013, contrastive_loss=0.152, total=4167.53, n_correct=2750.31, ppl=4.47, accuracy=65.994, wps=12321.9, ups=1.48, wpb=8335.1, bsz=314.6, num_updates=37300, lr=7.32252e-05, gnorm=0.53, clip=0, loss_scale=8, train_wall=67, gb_free=14, wall=30366
2023-08-04 21:19:33 | INFO | train_inner | epoch 026:    567 / 1474 loss=1.971, trans_loss=4.985, nll_loss=2.176, w2v_ctc_loss=0.634, task_loss=2.111, contrastive_loss=0.071, total=4158.48, n_correct=2733.78, ppl=4.52, accuracy=65.74, wps=12152.8, ups=1.46, wpb=8317, bsz=304.4, num_updates=37400, lr=7.31272e-05, gnorm=0.53, clip=0, loss_scale=8, train_wall=68, gb_free=12.7, wall=30435
2023-08-04 21:20:41 | INFO | train_inner | epoch 026:    667 / 1474 loss=1.967, trans_loss=4.987, nll_loss=2.179, w2v_ctc_loss=0.623, task_loss=2.155, contrastive_loss=0.056, total=4129.11, n_correct=2712.4, ppl=4.53, accuracy=65.69, wps=12134.3, ups=1.47, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=68, gb_free=13.8, wall=30503
2023-08-04 21:21:49 | INFO | train_inner | epoch 026:    767 / 1474 loss=1.978, trans_loss=4.992, nll_loss=2.186, w2v_ctc_loss=0.625, task_loss=2.112, contrastive_loss=0.171, total=4096.84, n_correct=2686.45, ppl=4.55, accuracy=65.574, wps=12130.5, ups=1.48, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.541, clip=0, loss_scale=8, train_wall=67, gb_free=16.6, wall=30570
2023-08-04 21:22:57 | INFO | train_inner | epoch 026:    867 / 1474 loss=1.97, trans_loss=4.987, nll_loss=2.179, w2v_ctc_loss=0.629, task_loss=2.095, contrastive_loss=0.07, total=4176.27, n_correct=2739.73, ppl=4.53, accuracy=65.602, wps=12323.6, ups=1.48, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=67, gb_free=16.3, wall=30638
2023-08-04 21:24:05 | INFO | train_inner | epoch 026:    967 / 1474 loss=1.975, trans_loss=4.998, nll_loss=2.194, w2v_ctc_loss=0.618, task_loss=2.167, contrastive_loss=0.125, total=4141.01, n_correct=2709.58, ppl=4.57, accuracy=65.433, wps=12148.3, ups=1.47, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.536, clip=0, loss_scale=8, train_wall=68, gb_free=15.5, wall=30706
2023-08-04 21:25:13 | INFO | train_inner | epoch 026:   1067 / 1474 loss=1.969, trans_loss=4.993, nll_loss=2.188, w2v_ctc_loss=0.624, task_loss=2.219, contrastive_loss=0.055, total=4113.69, n_correct=2701.75, ppl=4.56, accuracy=65.677, wps=12104.2, ups=1.47, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=68, gb_free=15.5, wall=30774
2023-08-04 21:26:21 | INFO | train_inner | epoch 026:   1167 / 1474 loss=1.975, trans_loss=4.998, nll_loss=2.195, w2v_ctc_loss=0.626, task_loss=2.187, contrastive_loss=0.095, total=4116.78, n_correct=2698.17, ppl=4.58, accuracy=65.541, wps=12045.8, ups=1.46, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.53, clip=0, loss_scale=8, train_wall=68, gb_free=16.6, wall=30843
2023-08-04 21:26:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 21:26:45 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.185 | trans_loss 5.552 | nll_loss 2.82 | w2v_ctc_loss 1.335 | task_loss 6.943 | contrastive_loss 0.244 | total 4003.4 | n_correct 2494.7 | ppl 7.06 | accuracy 62.315 | uer 16.885 | wer 18.638 | raw_wer 18.638 | bleu 20.07 | wps 2082.2 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.6
2023-08-04 21:26:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-04 21:26:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_26_38000.pt
2023-08-04 21:26:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_26_38000.pt
2023-08-04 21:27:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.07) (writing took 22.295380234718323 seconds)
2023-08-04 21:28:16 | INFO | train_inner | epoch 026:   1267 / 1474 loss=1.984, trans_loss=5.01, nll_loss=2.209, w2v_ctc_loss=0.641, task_loss=2.328, contrastive_loss=0.057, total=4001.06, n_correct=2608.81, ppl=4.62, accuracy=65.203, wps=6947.4, ups=0.87, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.544, clip=0, loss_scale=8, train_wall=68, gb_free=15.6, wall=30958
2023-08-04 21:29:25 | INFO | train_inner | epoch 026:   1367 / 1474 loss=1.97, trans_loss=5.001, nll_loss=2.199, w2v_ctc_loss=0.62, task_loss=2.102, contrastive_loss=0.073, total=4157.69, n_correct=2725.41, ppl=4.59, accuracy=65.551, wps=12128.6, ups=1.46, wpb=8315.4, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=68, gb_free=16.1, wall=31026
2023-08-04 21:30:33 | INFO | train_inner | epoch 026:   1467 / 1474 loss=1.965, trans_loss=4.995, nll_loss=2.192, w2v_ctc_loss=0.617, task_loss=1.993, contrastive_loss=0.066, total=4158.47, n_correct=2733.29, ppl=4.57, accuracy=65.728, wps=12282, ups=1.48, wpb=8316.9, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.534, clip=0, loss_scale=8, train_wall=67, gb_free=17.4, wall=31094
2023-08-04 21:30:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 21:31:00 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.175 | trans_loss 5.548 | nll_loss 2.819 | w2v_ctc_loss 1.308 | task_loss 6.941 | contrastive_loss 0.251 | total 4003.4 | n_correct 2496.2 | ppl 7.05 | accuracy 62.352 | uer 16.874 | wer 18.732 | raw_wer 18.732 | bleu 20.05 | wps 2017.2 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 20.6
2023-08-04 21:31:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-08-04 21:31:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.0502.pt
2023-08-04 21:31:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.0502.pt
2023-08-04 21:31:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.0502.pt (epoch 26 @ 38307 updates, score 20.05) (writing took 36.62906307168305 seconds)
2023-08-04 21:31:37 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-04 21:31:37 | INFO | train | epoch 026 | loss 1.97 | trans_loss 4.987 | nll_loss 2.18 | w2v_ctc_loss 0.624 | task_loss 2.099 | contrastive_loss 0.109 | total 4138.93 | n_correct 2719.18 | ppl 4.53 | accuracy 65.698 | wps 10907.9 | ups 1.32 | wpb 8277.9 | bsz 305.7 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.531 | clip 0 | loss_scale 8 | train_wall 996 | gb_free 15.9 | wall 31159
2023-08-04 21:31:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 21:31:37 | INFO | fairseq.trainer | begin training epoch 27
2023-08-04 21:31:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 21:32:47 | INFO | train_inner | epoch 027:     93 / 1474 loss=1.951, trans_loss=4.953, nll_loss=2.133, w2v_ctc_loss=0.612, task_loss=2.239, contrastive_loss=0.045, total=4067.62, n_correct=2700.56, ppl=4.39, accuracy=66.392, wps=6028.6, ups=0.74, wpb=8135.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.538, clip=0, loss_scale=8, train_wall=67, gb_free=14.8, wall=31229
2023-08-04 21:33:56 | INFO | train_inner | epoch 027:    193 / 1474 loss=1.953, trans_loss=4.959, nll_loss=2.143, w2v_ctc_loss=0.618, task_loss=2.012, contrastive_loss=0.075, total=4185.52, n_correct=2773.8, ppl=4.42, accuracy=66.271, wps=12268.9, ups=1.47, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.546, clip=0, loss_scale=8, train_wall=68, gb_free=17.6, wall=31297
2023-08-04 21:35:04 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.956, trans_loss=4.967, nll_loss=2.153, w2v_ctc_loss=0.617, task_loss=2.095, contrastive_loss=0.057, total=4167.92, n_correct=2759.68, ppl=4.45, accuracy=66.212, wps=12142.5, ups=1.46, wpb=8335.8, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=68, gb_free=16.8, wall=31366
2023-08-04 21:36:13 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.973, trans_loss=4.976, nll_loss=2.165, w2v_ctc_loss=0.614, task_loss=2.2, contrastive_loss=0.241, total=4075.21, n_correct=2681.78, ppl=4.48, accuracy=65.807, wps=11872.7, ups=1.46, wpb=8150.4, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.531, clip=0, loss_scale=8, train_wall=68, gb_free=17.7, wall=31435
2023-08-04 21:37:22 | INFO | train_inner | epoch 027:    493 / 1474 loss=1.967, trans_loss=4.981, nll_loss=2.172, w2v_ctc_loss=0.617, task_loss=1.918, contrastive_loss=0.179, total=4249.35, n_correct=2791.75, ppl=4.51, accuracy=65.698, wps=12372, ups=1.46, wpb=8498.7, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.533, clip=0, loss_scale=8, train_wall=68, gb_free=11.9, wall=31503
2023-08-04 21:38:30 | INFO | train_inner | epoch 027:    593 / 1474 loss=1.966, trans_loss=4.978, nll_loss=2.167, w2v_ctc_loss=0.623, task_loss=2.057, contrastive_loss=0.117, total=4133.39, n_correct=2725.24, ppl=4.49, accuracy=65.932, wps=12188.8, ups=1.47, wpb=8266.8, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=67, gb_free=11.9, wall=31571
2023-08-04 21:39:38 | INFO | train_inner | epoch 027:    693 / 1474 loss=1.968, trans_loss=4.983, nll_loss=2.175, w2v_ctc_loss=0.625, task_loss=2.096, contrastive_loss=0.094, total=4162.71, n_correct=2739.6, ppl=4.52, accuracy=65.813, wps=12192.5, ups=1.46, wpb=8325.4, bsz=305.4, num_updates=39000, lr=7.16115e-05, gnorm=0.529, clip=0, loss_scale=8, train_wall=68, gb_free=16.2, wall=31639
2023-08-04 21:40:45 | INFO | train_inner | epoch 027:    793 / 1474 loss=1.966, trans_loss=4.983, nll_loss=2.174, w2v_ctc_loss=0.623, task_loss=2.215, contrastive_loss=0.059, total=4103.81, n_correct=2698.6, ppl=4.51, accuracy=65.758, wps=12221.6, ups=1.49, wpb=8207.6, bsz=294.2, num_updates=39100, lr=7.15199e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=67, gb_free=16.2, wall=31707
2023-08-04 21:41:53 | INFO | train_inner | epoch 027:    893 / 1474 loss=1.96, trans_loss=4.985, nll_loss=2.176, w2v_ctc_loss=0.611, task_loss=2.193, contrastive_loss=0.048, total=4101.56, n_correct=2706.66, ppl=4.52, accuracy=65.991, wps=12011.6, ups=1.46, wpb=8203.1, bsz=292.1, num_updates=39200, lr=7.14286e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=68, gb_free=17.7, wall=31775
2023-08-04 21:43:02 | INFO | train_inner | epoch 027:    993 / 1474 loss=1.971, trans_loss=4.982, nll_loss=2.175, w2v_ctc_loss=0.615, task_loss=2.036, contrastive_loss=0.236, total=4199.56, n_correct=2763.72, ppl=4.52, accuracy=65.81, wps=12279.8, ups=1.46, wpb=8399.1, bsz=316.8, num_updates=39300, lr=7.13376e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=11.5, wall=31843
2023-08-04 21:44:10 | INFO | train_inner | epoch 027:   1093 / 1474 loss=1.959, trans_loss=4.982, nll_loss=2.173, w2v_ctc_loss=0.612, task_loss=2.117, contrastive_loss=0.067, total=4150.97, n_correct=2734.38, ppl=4.51, accuracy=65.873, wps=12178.3, ups=1.47, wpb=8301.9, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=11.9, wall=31912
2023-08-04 21:45:17 | INFO | train_inner | epoch 027:   1193 / 1474 loss=1.972, trans_loss=4.989, nll_loss=2.183, w2v_ctc_loss=0.63, task_loss=2.19, contrastive_loss=0.073, total=4103.06, n_correct=2695.64, ppl=4.54, accuracy=65.698, wps=12146.3, ups=1.48, wpb=8206.1, bsz=297.7, num_updates=39500, lr=7.11568e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=67, gb_free=16.5, wall=31979
2023-08-04 21:46:25 | INFO | train_inner | epoch 027:   1293 / 1474 loss=1.977, trans_loss=4.995, nll_loss=2.19, w2v_ctc_loss=0.626, task_loss=2.251, contrastive_loss=0.122, total=4062.52, n_correct=2659.63, ppl=4.56, accuracy=65.467, wps=11995.1, ups=1.48, wpb=8125, bsz=292.2, num_updates=39600, lr=7.10669e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=32047
2023-08-04 21:47:32 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.965, trans_loss=4.989, nll_loss=2.183, w2v_ctc_loss=0.615, task_loss=1.987, contrastive_loss=0.105, total=4152, n_correct=2728.91, ppl=4.54, accuracy=65.725, wps=12336.3, ups=1.49, wpb=8304, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=32114
2023-08-04 21:48:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 21:48:50 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.167 | trans_loss 5.544 | nll_loss 2.813 | w2v_ctc_loss 1.293 | task_loss 6.944 | contrastive_loss 0.241 | total 4003.4 | n_correct 2500 | ppl 7.03 | accuracy 62.447 | uer 16.967 | wer 18.713 | raw_wer 18.713 | bleu 20.21 | wps 2285.5 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.6
2023-08-04 21:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-08-04 21:48:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2108.pt
2023-08-04 21:48:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2108.pt
2023-08-04 21:49:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2108.pt (epoch 27 @ 39781 updates, score 20.21) (writing took 18.027462864294648 seconds)
2023-08-04 21:49:08 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-04 21:49:08 | INFO | train | epoch 027 | loss 1.964 | trans_loss 4.979 | nll_loss 2.169 | w2v_ctc_loss 0.618 | task_loss 2.101 | contrastive_loss 0.107 | total 4138.65 | n_correct 2727.04 | ppl 4.5 | accuracy 65.892 | wps 11606.2 | ups 1.4 | wpb 8277.3 | bsz 305.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.534 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 17.8 | wall 32210
2023-08-04 21:49:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 21:49:08 | INFO | fairseq.trainer | begin training epoch 28
2023-08-04 21:49:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 21:49:29 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.956, trans_loss=4.979, nll_loss=2.171, w2v_ctc_loss=0.61, task_loss=2.03, contrastive_loss=0.058, total=4108.43, n_correct=2711.33, ppl=4.5, accuracy=65.994, wps=7071.1, ups=0.86, wpb=8216.9, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=32230
2023-08-04 21:50:36 | INFO | train_inner | epoch 028:    119 / 1474 loss=1.947, trans_loss=4.949, nll_loss=2.13, w2v_ctc_loss=0.608, task_loss=2.19, contrastive_loss=0.054, total=4113.41, n_correct=2736.88, ppl=4.38, accuracy=66.536, wps=12173.6, ups=1.48, wpb=8226.8, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=32298
2023-08-04 21:51:44 | INFO | train_inner | epoch 028:    219 / 1474 loss=1.948, trans_loss=4.957, nll_loss=2.141, w2v_ctc_loss=0.608, task_loss=1.993, contrastive_loss=0.061, total=4191.56, n_correct=2784.2, ppl=4.41, accuracy=66.424, wps=12289.8, ups=1.47, wpb=8383.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=15.1, wall=32366
2023-08-04 21:51:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 21:52:07 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.189 | trans_loss 5.557 | nll_loss 2.83 | w2v_ctc_loss 1.336 | task_loss 6.941 | contrastive_loss 0.242 | total 4003.4 | n_correct 2491.3 | ppl 7.11 | accuracy 62.23 | uer 16.943 | wer 18.612 | raw_wer 18.612 | bleu 20.12 | wps 2232.9 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.6
2023-08-04 21:52:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-04 21:52:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_28_40000.pt
2023-08-04 21:52:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_28_40000.pt
2023-08-04 21:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.12) (writing took 19.30138255469501 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:0')
2023-08-04 21:53:39 | INFO | train_inner | epoch 028:    319 / 1474 loss=1.974, trans_loss=4.966, nll_loss=2.154, w2v_ctc_loss=0.604, task_loss=2.085, contrastive_loss=0.394, total=4145.32, n_correct=2734.73, ppl=4.45, accuracy=65.972, wps=7246.9, ups=0.87, wpb=8290.6, bsz=316.1, num_updates=40100, lr=7.06225e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=32481
2023-08-04 21:54:47 | INFO | train_inner | epoch 028:    419 / 1474 loss=1.954, trans_loss=4.962, nll_loss=2.146, w2v_ctc_loss=0.615, task_loss=2.172, contrastive_loss=0.049, total=4092.14, n_correct=2712.83, ppl=4.43, accuracy=66.294, wps=12103.1, ups=1.48, wpb=8184.3, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=32548
2023-08-04 21:55:55 | INFO | train_inner | epoch 028:    519 / 1474 loss=1.955, trans_loss=4.967, nll_loss=2.154, w2v_ctc_loss=0.612, task_loss=2.19, contrastive_loss=0.06, total=4096.35, n_correct=2708.54, ppl=4.45, accuracy=66.121, wps=12031.8, ups=1.47, wpb=8192.7, bsz=295.5, num_updates=40300, lr=7.0447e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=32616
2023-08-04 21:57:03 | INFO | train_inner | epoch 028:    619 / 1474 loss=1.959, trans_loss=4.978, nll_loss=2.168, w2v_ctc_loss=0.616, task_loss=2.117, contrastive_loss=0.062, total=4178.12, n_correct=2758.06, ppl=4.49, accuracy=66.012, wps=12202.5, ups=1.46, wpb=8356.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=32685
2023-08-04 21:58:11 | INFO | train_inner | epoch 028:    719 / 1474 loss=1.96, trans_loss=4.973, nll_loss=2.162, w2v_ctc_loss=0.61, task_loss=1.908, contrastive_loss=0.174, total=4185.82, n_correct=2766.27, ppl=4.48, accuracy=66.087, wps=12283.5, ups=1.47, wpb=8371.6, bsz=326.4, num_updates=40500, lr=7.02728e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=32753
2023-08-04 21:59:19 | INFO | train_inner | epoch 028:    819 / 1474 loss=1.951, trans_loss=4.968, nll_loss=2.156, w2v_ctc_loss=0.61, task_loss=2.065, contrastive_loss=0.053, total=4096.2, n_correct=2713.98, ppl=4.46, accuracy=66.256, wps=12097.2, ups=1.48, wpb=8192.4, bsz=307, num_updates=40600, lr=7.01862e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=67, gb_free=15.7, wall=32821
2023-08-04 22:00:28 | INFO | train_inner | epoch 028:    919 / 1474 loss=1.968, trans_loss=4.983, nll_loss=2.175, w2v_ctc_loss=0.619, task_loss=2.159, contrastive_loss=0.117, total=4120.27, n_correct=2710.05, ppl=4.51, accuracy=65.774, wps=12005, ups=1.46, wpb=8240.5, bsz=300.8, num_updates=40700, lr=7.01e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=32889
2023-08-04 22:01:36 | INFO | train_inner | epoch 028:   1019 / 1474 loss=1.972, trans_loss=4.982, nll_loss=2.174, w2v_ctc_loss=0.623, task_loss=2.055, contrastive_loss=0.17, total=4177.86, n_correct=2747.84, ppl=4.51, accuracy=65.771, wps=12259.5, ups=1.47, wpb=8355.7, bsz=311.1, num_updates=40800, lr=7.0014e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=32957
2023-08-04 22:02:44 | INFO | train_inner | epoch 028:   1119 / 1474 loss=1.954, trans_loss=4.97, nll_loss=2.159, w2v_ctc_loss=0.611, task_loss=2.037, contrastive_loss=0.072, total=4210.86, n_correct=2784.51, ppl=4.47, accuracy=66.127, wps=12279.2, ups=1.46, wpb=8421.7, bsz=318.9, num_updates=40900, lr=6.99284e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=33026
2023-08-04 22:03:52 | INFO | train_inner | epoch 028:   1219 / 1474 loss=1.957, trans_loss=4.98, nll_loss=2.172, w2v_ctc_loss=0.61, task_loss=2.071, contrastive_loss=0.062, total=4104.61, n_correct=2706.93, ppl=4.51, accuracy=65.949, wps=12119.5, ups=1.48, wpb=8209.2, bsz=305.6, num_updates=41000, lr=6.9843e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=67, gb_free=16.5, wall=33094
2023-08-04 22:05:00 | INFO | train_inner | epoch 028:   1319 / 1474 loss=1.97, trans_loss=4.986, nll_loss=2.177, w2v_ctc_loss=0.629, task_loss=2.304, contrastive_loss=0.074, total=4087.78, n_correct=2688.16, ppl=4.52, accuracy=65.761, wps=11959.6, ups=1.46, wpb=8175.6, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=33162
2023-08-04 22:06:09 | INFO | train_inner | epoch 028:   1419 / 1474 loss=1.966, trans_loss=4.985, nll_loss=2.178, w2v_ctc_loss=0.615, task_loss=2.205, contrastive_loss=0.096, total=4145.03, n_correct=2725.89, ppl=4.52, accuracy=65.763, wps=12170.8, ups=1.47, wpb=8290.1, bsz=297.6, num_updates=41200, lr=6.96733e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=33230
2023-08-04 22:06:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:2')
2023-08-04 22:07:10 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.183 | trans_loss 5.548 | nll_loss 2.819 | w2v_ctc_loss 1.335 | task_loss 6.94 | contrastive_loss 0.244 | total 4003.4 | n_correct 2496.5 | ppl 7.06 | accuracy 62.359 | uer 16.856 | wer 18.609 | raw_wer 18.609 | bleu 20.44 | wps 2136.6 | wpb 4003.4 | bsz 141.8 | num_updates 41255 | best_bleu 20.6
2023-08-04 22:07:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41255 updates
2023-08-04 22:07:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.4408.pt
2023-08-04 22:07:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.4408.pt
2023-08-04 22:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.4408.pt (epoch 28 @ 41255 updates, score 20.44) (writing took 13.12355050817132 seconds)
2023-08-04 22:07:23 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-04 22:07:23 | INFO | train | epoch 028 | loss 1.959 | trans_loss 4.972 | nll_loss 2.16 | w2v_ctc_loss 0.614 | task_loss 2.101 | contrastive_loss 0.106 | total 4138.65 | n_correct 2734.34 | ppl 4.47 | accuracy 66.068 | wps 11140.8 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 41255 | lr 6.96268e-05 | gnorm 0.539 | clip 0 | loss_scale 32 | train_wall 998 | gb_free 16.4 | wall 33305
2023-08-04 22:07:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 22:07:24 | INFO | fairseq.trainer | begin training epoch 29
2023-08-04 22:07:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 22:08:02 | INFO | train_inner | epoch 029:     45 / 1474 loss=1.949, trans_loss=4.957, nll_loss=2.141, w2v_ctc_loss=0.614, task_loss=2.028, contrastive_loss=0.066, total=4163.06, n_correct=2762.59, ppl=4.41, accuracy=66.36, wps=7345.6, ups=0.88, wpb=8326.1, bsz=314, num_updates=41300, lr=6.95889e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=33344
2023-08-04 22:09:10 | INFO | train_inner | epoch 029:    145 / 1474 loss=1.95, trans_loss=4.955, nll_loss=2.137, w2v_ctc_loss=0.61, task_loss=2.06, contrastive_loss=0.097, total=4116.29, n_correct=2735.53, ppl=4.4, accuracy=66.456, wps=12048.2, ups=1.46, wpb=8232.6, bsz=308.5, num_updates=41400, lr=6.95048e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=13.9, wall=33412
2023-08-04 22:10:19 | INFO | train_inner | epoch 029:    245 / 1474 loss=1.947, trans_loss=4.949, nll_loss=2.131, w2v_ctc_loss=0.595, task_loss=1.919, contrastive_loss=0.176, total=4197.24, n_correct=2792.69, ppl=4.38, accuracy=66.536, wps=12241.4, ups=1.46, wpb=8394.5, bsz=329.9, num_updates=41500, lr=6.9421e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=33481
2023-08-04 22:11:27 | INFO | train_inner | epoch 029:    345 / 1474 loss=1.957, trans_loss=4.968, nll_loss=2.155, w2v_ctc_loss=0.618, task_loss=2.254, contrastive_loss=0.056, total=4092.21, n_correct=2706.88, ppl=4.45, accuracy=66.147, wps=11992.4, ups=1.47, wpb=8184.4, bsz=290.6, num_updates=41600, lr=6.93375e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=33549
2023-08-04 22:12:35 | INFO | train_inner | epoch 029:    445 / 1474 loss=1.94, trans_loss=4.943, nll_loss=2.122, w2v_ctc_loss=0.602, task_loss=2.022, contrastive_loss=0.049, total=4161.27, n_correct=2772.03, ppl=4.35, accuracy=66.615, wps=12249.4, ups=1.47, wpb=8322.5, bsz=307.8, num_updates=41700, lr=6.92543e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=67, gb_free=16, wall=33617
2023-08-04 22:13:44 | INFO | train_inner | epoch 029:    545 / 1474 loss=1.961, trans_loss=4.968, nll_loss=2.154, w2v_ctc_loss=0.607, task_loss=2.215, contrastive_loss=0.146, total=4159.68, n_correct=2750.37, ppl=4.45, accuracy=66.12, wps=12134.9, ups=1.46, wpb=8319.4, bsz=296.5, num_updates=41800, lr=6.91714e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=33685
2023-08-04 22:14:52 | INFO | train_inner | epoch 029:    645 / 1474 loss=1.953, trans_loss=4.957, nll_loss=2.142, w2v_ctc_loss=0.602, task_loss=1.988, contrastive_loss=0.217, total=4143.76, n_correct=2755.26, ppl=4.41, accuracy=66.492, wps=12166.6, ups=1.47, wpb=8287.5, bsz=318.8, num_updates=41900, lr=6.90889e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=33753
2023-08-04 22:16:00 | INFO | train_inner | epoch 029:    745 / 1474 loss=1.947, trans_loss=4.955, nll_loss=2.139, w2v_ctc_loss=0.599, task_loss=1.946, contrastive_loss=0.134, total=4234.8, n_correct=2808.92, ppl=4.41, accuracy=66.329, wps=12352.3, ups=1.46, wpb=8469.6, bsz=328.1, num_updates=42000, lr=6.90066e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=33822
2023-08-04 22:16:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 22:16:24 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.183 | trans_loss 5.542 | nll_loss 2.809 | w2v_ctc_loss 1.35 | task_loss 6.977 | contrastive_loss 0.243 | total 4003.4 | n_correct 2504.6 | ppl 7.01 | accuracy 62.562 | uer 16.864 | wer 18.571 | raw_wer 18.571 | bleu 19.98 | wps 2254.1 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.6
2023-08-04 22:16:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-04 22:16:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_29_42000.pt
2023-08-04 22:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_29_42000.pt
2023-08-04 22:16:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 19.98) (writing took 19.37710450962186 seconds)
2023-08-04 22:17:51 | INFO | train_inner | epoch 029:    845 / 1474 loss=1.961, trans_loss=4.982, nll_loss=2.172, w2v_ctc_loss=0.613, task_loss=2.324, contrastive_loss=0.048, total=4033.21, n_correct=2656.08, ppl=4.51, accuracy=65.855, wps=7281, ups=0.9, wpb=8066.4, bsz=281.6, num_updates=42100, lr=6.89246e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=67, gb_free=16.5, wall=33933
2023-08-04 22:18:58 | INFO | train_inner | epoch 029:    945 / 1474 loss=1.959, trans_loss=4.979, nll_loss=2.17, w2v_ctc_loss=0.615, task_loss=2.138, contrastive_loss=0.06, total=4085.97, n_correct=2695.25, ppl=4.5, accuracy=65.964, wps=12132.7, ups=1.48, wpb=8171.9, bsz=296.8, num_updates=42200, lr=6.88428e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=34000
2023-08-04 22:20:06 | INFO | train_inner | epoch 029:   1045 / 1474 loss=1.953, trans_loss=4.964, nll_loss=2.151, w2v_ctc_loss=0.604, task_loss=2.101, contrastive_loss=0.135, total=4140.84, n_correct=2742.98, ppl=4.44, accuracy=66.242, wps=12195.3, ups=1.47, wpb=8281.7, bsz=306.7, num_updates=42300, lr=6.87614e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=34068
2023-08-04 22:21:14 | INFO | train_inner | epoch 029:   1145 / 1474 loss=1.96, trans_loss=4.978, nll_loss=2.169, w2v_ctc_loss=0.619, task_loss=2.285, contrastive_loss=0.044, total=4068.4, n_correct=2685.9, ppl=4.5, accuracy=66.019, wps=11961.6, ups=1.47, wpb=8136.8, bsz=284.2, num_updates=42400, lr=6.86803e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=34136
2023-08-04 22:22:22 | INFO | train_inner | epoch 029:   1245 / 1474 loss=1.958, trans_loss=4.981, nll_loss=2.173, w2v_ctc_loss=0.613, task_loss=2.155, contrastive_loss=0.052, total=4154.79, n_correct=2740.13, ppl=4.51, accuracy=65.951, wps=12229, ups=1.47, wpb=8309.6, bsz=299.6, num_updates=42500, lr=6.85994e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=34204
2023-08-04 22:23:31 | INFO | train_inner | epoch 029:   1345 / 1474 loss=1.955, trans_loss=4.969, nll_loss=2.158, w2v_ctc_loss=0.604, task_loss=2.058, contrastive_loss=0.12, total=4166.4, n_correct=2757.15, ppl=4.46, accuracy=66.176, wps=12229.1, ups=1.47, wpb=8332.8, bsz=311.5, num_updates=42600, lr=6.85189e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=34272
2023-08-04 22:24:39 | INFO | train_inner | epoch 029:   1445 / 1474 loss=1.96, trans_loss=4.972, nll_loss=2.163, w2v_ctc_loss=0.613, task_loss=2.061, contrastive_loss=0.146, total=4169.4, n_correct=2751.52, ppl=4.48, accuracy=65.993, wps=12247.1, ups=1.47, wpb=8338.8, bsz=312, num_updates=42700, lr=6.84386e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=34340
2023-08-04 22:24:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 22:25:21 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.172 | trans_loss 5.542 | nll_loss 2.811 | w2v_ctc_loss 1.312 | task_loss 6.931 | contrastive_loss 0.243 | total 4003.4 | n_correct 2501.5 | ppl 7.02 | accuracy 62.484 | uer 16.72 | wer 18.538 | raw_wer 18.538 | bleu 20.36 | wps 2183.9 | wpb 4003.4 | bsz 141.8 | num_updates 42729 | best_bleu 20.6
2023-08-04 22:25:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42729 updates
2023-08-04 22:25:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.3604.pt
2023-08-04 22:25:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.3604.pt
2023-08-04 22:25:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.3604.pt (epoch 29 @ 42729 updates, score 20.36) (writing took 18.687312692403793 seconds)
2023-08-04 22:25:40 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-04 22:25:40 | INFO | train | epoch 029 | loss 1.954 | trans_loss 4.965 | nll_loss 2.151 | w2v_ctc_loss 0.608 | task_loss 2.1 | contrastive_loss 0.105 | total 4138.65 | n_correct 2740.67 | ppl 4.44 | accuracy 66.221 | wps 11122.2 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 42729 | lr 6.84154e-05 | gnorm 0.534 | clip 0 | loss_scale 32 | train_wall 996 | gb_free 16 | wall 34402
2023-08-04 22:25:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 22:25:41 | INFO | fairseq.trainer | begin training epoch 30
2023-08-04 22:25:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 22:26:37 | INFO | train_inner | epoch 030:     71 / 1474 loss=1.946, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.594, task_loss=1.996, contrastive_loss=0.164, total=4176.73, n_correct=2777.27, ppl=4.38, accuracy=66.494, wps=7036.3, ups=0.84, wpb=8353.5, bsz=319, num_updates=42800, lr=6.83586e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=34459
2023-08-04 22:26:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 22:27:45 | INFO | train_inner | epoch 030:    172 / 1474 loss=1.937, trans_loss=4.931, nll_loss=2.107, w2v_ctc_loss=0.599, task_loss=1.969, contrastive_loss=0.095, total=4200.39, n_correct=2810.82, ppl=4.31, accuracy=66.918, wps=12369.4, ups=1.47, wpb=8400.8, bsz=318.6, num_updates=42900, lr=6.82789e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=67, gb_free=17.4, wall=34527
2023-08-04 22:28:53 | INFO | train_inner | epoch 030:    272 / 1474 loss=1.945, trans_loss=4.949, nll_loss=2.13, w2v_ctc_loss=0.611, task_loss=2.163, contrastive_loss=0.048, total=4116.93, n_correct=2742.07, ppl=4.38, accuracy=66.605, wps=12195.3, ups=1.48, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=34594
2023-08-04 22:30:02 | INFO | train_inner | epoch 030:    372 / 1474 loss=1.937, trans_loss=4.941, nll_loss=2.12, w2v_ctc_loss=0.597, task_loss=2.108, contrastive_loss=0.051, total=4173.13, n_correct=2788.17, ppl=4.35, accuracy=66.812, wps=12115.3, ups=1.45, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=11.7, wall=34663
2023-08-04 22:31:09 | INFO | train_inner | epoch 030:    472 / 1474 loss=1.942, trans_loss=4.948, nll_loss=2.13, w2v_ctc_loss=0.595, task_loss=1.997, contrastive_loss=0.116, total=4135.2, n_correct=2754.69, ppl=4.38, accuracy=66.616, wps=12219.9, ups=1.48, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=67, gb_free=16.8, wall=34731
2023-08-04 22:32:17 | INFO | train_inner | epoch 030:    572 / 1474 loss=1.945, trans_loss=4.957, nll_loss=2.141, w2v_ctc_loss=0.601, task_loss=2.043, contrastive_loss=0.077, total=4168.65, n_correct=2770.97, ppl=4.41, accuracy=66.472, wps=12269.9, ups=1.47, wpb=8337.3, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=67, gb_free=15.8, wall=34799
2023-08-04 22:33:26 | INFO | train_inner | epoch 030:    672 / 1474 loss=1.95, trans_loss=4.956, nll_loss=2.14, w2v_ctc_loss=0.612, task_loss=2.074, contrastive_loss=0.094, total=4183.65, n_correct=2778.93, ppl=4.41, accuracy=66.424, wps=12204.2, ups=1.46, wpb=8367.3, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=34868
2023-08-04 22:34:34 | INFO | train_inner | epoch 030:    772 / 1474 loss=1.967, trans_loss=4.971, nll_loss=2.159, w2v_ctc_loss=0.621, task_loss=2.141, contrastive_loss=0.173, total=4106.9, n_correct=2713.5, ppl=4.47, accuracy=66.072, wps=12057.9, ups=1.47, wpb=8213.8, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=68, gb_free=11.8, wall=34936
2023-08-04 22:35:42 | INFO | train_inner | epoch 030:    872 / 1474 loss=1.949, trans_loss=4.963, nll_loss=2.148, w2v_ctc_loss=0.604, task_loss=2.201, contrastive_loss=0.053, total=4089.18, n_correct=2712.29, ppl=4.43, accuracy=66.328, wps=12058, ups=1.47, wpb=8178.4, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=67, gb_free=16.5, wall=35003
2023-08-04 22:36:50 | INFO | train_inner | epoch 030:    972 / 1474 loss=1.952, trans_loss=4.966, nll_loss=2.152, w2v_ctc_loss=0.608, task_loss=2.116, contrastive_loss=0.073, total=4140.03, n_correct=2741.94, ppl=4.45, accuracy=66.23, wps=12185.5, ups=1.47, wpb=8280.1, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=67, gb_free=13.7, wall=35071
2023-08-04 22:37:58 | INFO | train_inner | epoch 030:   1072 / 1474 loss=1.965, trans_loss=4.977, nll_loss=2.166, w2v_ctc_loss=0.613, task_loss=2.348, contrastive_loss=0.14, total=4101.12, n_correct=2704.32, ppl=4.49, accuracy=65.941, wps=11936.1, ups=1.46, wpb=8202.2, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=35140
2023-08-04 22:39:07 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.947, trans_loss=4.962, nll_loss=2.148, w2v_ctc_loss=0.593, task_loss=2.011, contrastive_loss=0.122, total=4168.22, n_correct=2766.71, ppl=4.43, accuracy=66.376, wps=12199, ups=1.46, wpb=8336.4, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=35209
2023-08-04 22:40:15 | INFO | train_inner | epoch 030:   1272 / 1474 loss=1.958, trans_loss=4.974, nll_loss=2.163, w2v_ctc_loss=0.614, task_loss=2.339, contrastive_loss=0.057, total=4032.74, n_correct=2665.41, ppl=4.48, accuracy=66.094, wps=11774.6, ups=1.46, wpb=8065.5, bsz=281.8, num_updates=44000, lr=6.742e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=35277
2023-08-04 22:40:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 22:40:39 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.189 | trans_loss 5.549 | nll_loss 2.818 | w2v_ctc_loss 1.349 | task_loss 6.97 | contrastive_loss 0.249 | total 4003.4 | n_correct 2493 | ppl 7.05 | accuracy 62.272 | uer 16.925 | wer 18.672 | raw_wer 18.672 | bleu 20.06 | wps 2160.9 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.6
2023-08-04 22:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-04 22:40:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_30_44000.pt
2023-08-04 22:40:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_30_44000.pt
2023-08-04 22:40:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.06) (writing took 15.586711443960667 seconds)
2023-08-04 22:42:03 | INFO | train_inner | epoch 030:   1372 / 1474 loss=1.944, trans_loss=4.964, nll_loss=2.152, w2v_ctc_loss=0.601, task_loss=1.978, contrastive_loss=0.069, total=4166.96, n_correct=2765.2, ppl=4.45, accuracy=66.36, wps=7773.7, ups=0.93, wpb=8333.9, bsz=322.3, num_updates=44100, lr=6.73435e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=67, gb_free=15.2, wall=35384
2023-08-04 22:43:10 | INFO | train_inner | epoch 030:   1472 / 1474 loss=1.955, trans_loss=4.968, nll_loss=2.158, w2v_ctc_loss=0.597, task_loss=2.011, contrastive_loss=0.212, total=4125.17, n_correct=2732.78, ppl=4.46, accuracy=66.246, wps=12243.1, ups=1.48, wpb=8250.3, bsz=310, num_updates=44200, lr=6.72673e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=35452
2023-08-04 22:43:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 22:43:35 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.178 | trans_loss 5.541 | nll_loss 2.807 | w2v_ctc_loss 1.336 | task_loss 6.973 | contrastive_loss 0.238 | total 4003.4 | n_correct 2506.3 | ppl 7 | accuracy 62.604 | uer 16.741 | wer 18.489 | raw_wer 18.489 | bleu 20.31 | wps 2097.4 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 20.6
2023-08-04 22:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-08-04 22:43:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.3105.pt
2023-08-04 22:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.3105.pt
2023-08-04 22:43:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.3105.pt (epoch 30 @ 44202 updates, score 20.31) (writing took 18.075127927586436 seconds)
2023-08-04 22:43:54 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-04 22:43:54 | INFO | train | epoch 030 | loss 1.949 | trans_loss 4.958 | nll_loss 2.143 | w2v_ctc_loss 0.604 | task_loss 2.098 | contrastive_loss 0.104 | total 4138.36 | n_correct 2748.15 | ppl 4.42 | accuracy 66.407 | wps 11149.5 | ups 1.35 | wpb 8276.7 | bsz 305.6 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.541 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 17.1 | wall 35496
2023-08-04 22:43:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 22:43:54 | INFO | fairseq.trainer | begin training epoch 31
2023-08-04 22:43:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 22:45:08 | INFO | train_inner | epoch 031:     98 / 1474 loss=1.94, trans_loss=4.94, nll_loss=2.117, w2v_ctc_loss=0.604, task_loss=2.182, contrastive_loss=0.054, total=4081.34, n_correct=2727.8, ppl=4.34, accuracy=66.836, wps=6888.2, ups=0.84, wpb=8162.7, bsz=294.7, num_updates=44300, lr=6.71913e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=35570
2023-08-04 22:46:17 | INFO | train_inner | epoch 031:    198 / 1474 loss=1.943, trans_loss=4.943, nll_loss=2.122, w2v_ctc_loss=0.604, task_loss=2.152, contrastive_loss=0.079, total=4146.03, n_correct=2765.69, ppl=4.35, accuracy=66.707, wps=12176.2, ups=1.47, wpb=8292.1, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=68, gb_free=13.3, wall=35638
2023-08-04 22:47:25 | INFO | train_inner | epoch 031:    298 / 1474 loss=1.942, trans_loss=4.94, nll_loss=2.118, w2v_ctc_loss=0.598, task_loss=2.156, contrastive_loss=0.117, total=4146.75, n_correct=2769.38, ppl=4.34, accuracy=66.784, wps=12142.2, ups=1.46, wpb=8293.5, bsz=300.7, num_updates=44500, lr=6.70402e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=17.6, wall=35707
2023-08-04 22:48:33 | INFO | train_inner | epoch 031:    398 / 1474 loss=1.946, trans_loss=4.953, nll_loss=2.134, w2v_ctc_loss=0.604, task_loss=2.293, contrastive_loss=0.054, total=4089.43, n_correct=2718.09, ppl=4.39, accuracy=66.466, wps=12033.4, ups=1.47, wpb=8178.9, bsz=285.5, num_updates=44600, lr=6.6965e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=67, gb_free=16.2, wall=35775
2023-08-04 22:49:41 | INFO | train_inner | epoch 031:    498 / 1474 loss=1.946, trans_loss=4.948, nll_loss=2.129, w2v_ctc_loss=0.612, task_loss=2.189, contrastive_loss=0.064, total=4114.41, n_correct=2736.13, ppl=4.38, accuracy=66.501, wps=12010.6, ups=1.46, wpb=8228.8, bsz=300.9, num_updates=44700, lr=6.689e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=35843
2023-08-04 22:50:49 | INFO | train_inner | epoch 031:    598 / 1474 loss=1.937, trans_loss=4.945, nll_loss=2.126, w2v_ctc_loss=0.594, task_loss=2.185, contrastive_loss=0.052, total=4084.36, n_correct=2727.9, ppl=4.36, accuracy=66.789, wps=12026, ups=1.47, wpb=8168.7, bsz=295, num_updates=44800, lr=6.68153e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=35911
2023-08-04 22:51:57 | INFO | train_inner | epoch 031:    698 / 1474 loss=1.933, trans_loss=4.943, nll_loss=2.123, w2v_ctc_loss=0.591, task_loss=2.01, contrastive_loss=0.054, total=4210.09, n_correct=2811.79, ppl=4.36, accuracy=66.787, wps=12454.4, ups=1.48, wpb=8420.2, bsz=314.9, num_updates=44900, lr=6.67409e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=67, gb_free=14.7, wall=35979
2023-08-04 22:52:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 22:53:06 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.953, trans_loss=4.961, nll_loss=2.146, w2v_ctc_loss=0.603, task_loss=2.201, contrastive_loss=0.125, total=4102.94, n_correct=2722.97, ppl=4.43, accuracy=66.366, wps=11955.4, ups=1.46, wpb=8205.9, bsz=296.3, num_updates=45000, lr=6.66667e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=12.9, wall=36047
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:0')
2023-08-04 22:54:14 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.944, trans_loss=4.949, nll_loss=2.132, w2v_ctc_loss=0.602, task_loss=2.191, contrastive_loss=0.07, total=4096.72, n_correct=2724.4, ppl=4.38, accuracy=66.502, wps=12029.4, ups=1.47, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=36115
2023-08-04 22:55:22 | INFO | train_inner | epoch 031:    999 / 1474 loss=1.949, trans_loss=4.96, nll_loss=2.147, w2v_ctc_loss=0.598, task_loss=1.982, contrastive_loss=0.154, total=4187.84, n_correct=2782.81, ppl=4.43, accuracy=66.45, wps=12306.7, ups=1.47, wpb=8375.7, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.548, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=36183
2023-08-04 22:56:29 | INFO | train_inner | epoch 031:   1099 / 1474 loss=1.945, trans_loss=4.954, nll_loss=2.139, w2v_ctc_loss=0.599, task_loss=2.054, contrastive_loss=0.102, total=4149.44, n_correct=2762.69, ppl=4.4, accuracy=66.58, wps=12247, ups=1.48, wpb=8298.9, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=67, gb_free=17.5, wall=36251
2023-08-04 22:57:37 | INFO | train_inner | epoch 031:   1199 / 1474 loss=1.952, trans_loss=4.961, nll_loss=2.148, w2v_ctc_loss=0.596, task_loss=1.968, contrastive_loss=0.216, total=4189.76, n_correct=2780.07, ppl=4.43, accuracy=66.354, wps=12381.4, ups=1.48, wpb=8379.5, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=67, gb_free=13.1, wall=36319
2023-08-04 22:58:45 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.94, trans_loss=4.958, nll_loss=2.144, w2v_ctc_loss=0.598, task_loss=1.886, contrastive_loss=0.06, total=4227.44, n_correct=2813.78, ppl=4.42, accuracy=66.56, wps=12486.7, ups=1.48, wpb=8454.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=36387
2023-08-04 22:59:53 | INFO | train_inner | epoch 031:   1399 / 1474 loss=1.958, trans_loss=4.961, nll_loss=2.148, w2v_ctc_loss=0.598, task_loss=1.93, contrastive_loss=0.266, total=4186.05, n_correct=2775.3, ppl=4.43, accuracy=66.299, wps=12268.4, ups=1.47, wpb=8372.1, bsz=326.6, num_updates=45600, lr=6.62266e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=36455
2023-08-04 23:00:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2589, device='cuda:1')
2023-08-04 23:01:07 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.174 | trans_loss 5.545 | nll_loss 2.815 | w2v_ctc_loss 1.313 | task_loss 6.971 | contrastive_loss 0.244 | total 4003.4 | n_correct 2494.6 | ppl 7.04 | accuracy 62.312 | uer 16.572 | wer 18.403 | raw_wer 18.403 | bleu 20.59 | wps 2223.1 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 20.6
2023-08-04 23:01:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-08-04 23:01:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.5902.pt
2023-08-04 23:01:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.5902.pt
2023-08-04 23:01:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.5902.pt (epoch 31 @ 45675 updates, score 20.59) (writing took 13.594556575641036 seconds)
2023-08-04 23:01:21 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-04 23:01:21 | INFO | train | epoch 031 | loss 1.945 | trans_loss 4.952 | nll_loss 2.135 | w2v_ctc_loss 0.6 | task_loss 2.101 | contrastive_loss 0.104 | total 4139.05 | n_correct 2754.64 | ppl 4.39 | accuracy 66.552 | wps 11644.9 | ups 1.41 | wpb 8278.1 | bsz 305.7 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.541 | clip 0 | loss_scale 16 | train_wall 995 | gb_free 12 | wall 36543
2023-08-04 23:01:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 23:01:21 | INFO | fairseq.trainer | begin training epoch 32
2023-08-04 23:01:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 23:01:46 | INFO | train_inner | epoch 032:     25 / 1474 loss=1.943, trans_loss=4.953, nll_loss=2.137, w2v_ctc_loss=0.601, task_loss=2.222, contrastive_loss=0.049, total=4042.6, n_correct=2688.38, ppl=4.4, accuracy=66.501, wps=7192.2, ups=0.89, wpb=8085.2, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=36567
2023-08-04 23:02:56 | INFO | train_inner | epoch 032:    125 / 1474 loss=1.919, trans_loss=4.917, nll_loss=2.089, w2v_ctc_loss=0.58, task_loss=1.937, contrastive_loss=0.06, total=4227.68, n_correct=2844.1, ppl=4.26, accuracy=67.273, wps=12376.3, ups=1.46, wpb=8455.4, bsz=323.3, num_updates=45800, lr=6.60819e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=36638
2023-08-04 23:04:05 | INFO | train_inner | epoch 032:    225 / 1474 loss=1.928, trans_loss=4.932, nll_loss=2.11, w2v_ctc_loss=0.589, task_loss=2, contrastive_loss=0.07, total=4157.32, n_correct=2786.92, ppl=4.32, accuracy=67.036, wps=12090.9, ups=1.45, wpb=8314.6, bsz=320.6, num_updates=45900, lr=6.60098e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=36706
2023-08-04 23:05:12 | INFO | train_inner | epoch 032:    325 / 1474 loss=1.923, trans_loss=4.924, nll_loss=2.098, w2v_ctc_loss=0.582, task_loss=1.984, contrastive_loss=0.063, total=4183.45, n_correct=2811.69, ppl=4.28, accuracy=67.21, wps=12403.2, ups=1.48, wpb=8366.9, bsz=314.4, num_updates=46000, lr=6.5938e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=67, gb_free=17.5, wall=36774
2023-08-04 23:05:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 23:05:36 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.18 | trans_loss 5.55 | nll_loss 2.822 | w2v_ctc_loss 1.321 | task_loss 6.966 | contrastive_loss 0.251 | total 4003.4 | n_correct 2498.5 | ppl 7.07 | accuracy 62.409 | uer 16.675 | wer 18.519 | raw_wer 18.519 | bleu 20.12 | wps 2169.2 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.6
2023-08-04 23:05:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-04 23:05:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_32_46000.pt
2023-08-04 23:05:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_32_46000.pt
2023-08-04 23:05:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.12) (writing took 17.290027931332588 seconds)
2023-08-04 23:07:02 | INFO | train_inner | epoch 032:    425 / 1474 loss=1.933, trans_loss=4.933, nll_loss=2.11, w2v_ctc_loss=0.595, task_loss=2.087, contrastive_loss=0.059, total=4157.28, n_correct=2785.53, ppl=4.32, accuracy=67.004, wps=7564.8, ups=0.91, wpb=8314.6, bsz=305.9, num_updates=46100, lr=6.58665e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=36884
2023-08-04 23:08:11 | INFO | train_inner | epoch 032:    525 / 1474 loss=1.942, trans_loss=4.944, nll_loss=2.125, w2v_ctc_loss=0.598, task_loss=2.034, contrastive_loss=0.144, total=4198.93, n_correct=2802.38, ppl=4.36, accuracy=66.74, wps=12196.2, ups=1.45, wpb=8397.9, bsz=317.6, num_updates=46200, lr=6.57952e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=36953
2023-08-04 23:09:19 | INFO | train_inner | epoch 032:    625 / 1474 loss=1.939, trans_loss=4.946, nll_loss=2.126, w2v_ctc_loss=0.597, task_loss=2.17, contrastive_loss=0.067, total=4142.69, n_correct=2763.66, ppl=4.37, accuracy=66.712, wps=12074.5, ups=1.46, wpb=8285.4, bsz=301.6, num_updates=46300, lr=6.57241e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=37021
2023-08-04 23:10:28 | INFO | train_inner | epoch 032:    725 / 1474 loss=1.941, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.605, task_loss=2.144, contrastive_loss=0.051, total=4154.59, n_correct=2770.24, ppl=4.38, accuracy=66.679, wps=12213.9, ups=1.47, wpb=8309.2, bsz=301.8, num_updates=46400, lr=6.56532e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=37089
2023-08-04 23:11:35 | INFO | train_inner | epoch 032:    825 / 1474 loss=1.935, trans_loss=4.945, nll_loss=2.125, w2v_ctc_loss=0.591, task_loss=2.165, contrastive_loss=0.048, total=4114.54, n_correct=2746.02, ppl=4.36, accuracy=66.739, wps=12210, ups=1.48, wpb=8229.1, bsz=294.9, num_updates=46500, lr=6.55826e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=67, gb_free=17.1, wall=37157
2023-08-04 23:12:43 | INFO | train_inner | epoch 032:    925 / 1474 loss=1.935, trans_loss=4.946, nll_loss=2.128, w2v_ctc_loss=0.589, task_loss=2.171, contrastive_loss=0.046, total=4139.67, n_correct=2760.1, ppl=4.37, accuracy=66.674, wps=12163.6, ups=1.47, wpb=8279.3, bsz=298.3, num_updates=46600, lr=6.55122e-05, gnorm=0.556, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=37225
2023-08-04 23:13:51 | INFO | train_inner | epoch 032:   1025 / 1474 loss=1.949, trans_loss=4.957, nll_loss=2.141, w2v_ctc_loss=0.6, task_loss=2.084, contrastive_loss=0.144, total=4119.15, n_correct=2735.43, ppl=4.41, accuracy=66.408, wps=12092.3, ups=1.47, wpb=8238.3, bsz=304.5, num_updates=46700, lr=6.5442e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=37293
2023-08-04 23:14:59 | INFO | train_inner | epoch 032:   1125 / 1474 loss=1.952, trans_loss=4.959, nll_loss=2.143, w2v_ctc_loss=0.602, task_loss=2.472, contrastive_loss=0.084, total=4019.61, n_correct=2667.09, ppl=4.42, accuracy=66.352, wps=11832.5, ups=1.47, wpb=8039.2, bsz=271.4, num_updates=46800, lr=6.5372e-05, gnorm=0.551, clip=0, loss_scale=16, train_wall=67, gb_free=17.6, wall=37361
2023-08-04 23:16:07 | INFO | train_inner | epoch 032:   1225 / 1474 loss=1.955, trans_loss=4.965, nll_loss=2.153, w2v_ctc_loss=0.598, task_loss=2.075, contrastive_loss=0.192, total=4149.28, n_correct=2752.02, ppl=4.45, accuracy=66.325, wps=12183.5, ups=1.47, wpb=8298.6, bsz=310.3, num_updates=46900, lr=6.53023e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=37429
2023-08-04 23:17:15 | INFO | train_inner | epoch 032:   1325 / 1474 loss=1.943, trans_loss=4.956, nll_loss=2.14, w2v_ctc_loss=0.6, task_loss=2.155, contrastive_loss=0.048, total=4079.22, n_correct=2712.38, ppl=4.41, accuracy=66.493, wps=12054.5, ups=1.48, wpb=8158.4, bsz=296.2, num_updates=47000, lr=6.52328e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=67, gb_free=15.1, wall=37497
2023-08-04 23:17:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 23:18:24 | INFO | train_inner | epoch 032:   1426 / 1474 loss=1.961, trans_loss=4.96, nll_loss=2.146, w2v_ctc_loss=0.606, task_loss=2.1, contrastive_loss=0.282, total=4113.78, n_correct=2729.39, ppl=4.43, accuracy=66.347, wps=11953, ups=1.45, wpb=8227.6, bsz=307.1, num_updates=47100, lr=6.51635e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=37565
2023-08-04 23:18:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 23:19:20 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.182 | trans_loss 5.543 | nll_loss 2.813 | w2v_ctc_loss 1.346 | task_loss 6.94 | contrastive_loss 0.243 | total 4003.4 | n_correct 2497.1 | ppl 7.03 | accuracy 62.374 | uer 16.683 | wer 18.538 | raw_wer 18.538 | bleu 20.22 | wps 2075.8 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.6
2023-08-04 23:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-08-04 23:19:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2209.pt
2023-08-04 23:19:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2209.pt
2023-08-04 23:19:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint.best_bleu_20.2209.pt (epoch 32 @ 47148 updates, score 20.22) (writing took 16.702331256121397 seconds)
2023-08-04 23:19:37 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-04 23:19:37 | INFO | train | epoch 032 | loss 1.94 | trans_loss 4.945 | nll_loss 2.126 | w2v_ctc_loss 0.594 | task_loss 2.1 | contrastive_loss 0.102 | total 4138.67 | n_correct 2761.37 | ppl 4.36 | accuracy 66.721 | wps 11120.4 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.541 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 16.4 | wall 37639
2023-08-04 23:19:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 23:19:38 | INFO | fairseq.trainer | begin training epoch 33
2023-08-04 23:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 23:20:20 | INFO | train_inner | epoch 033:     52 / 1474 loss=1.939, trans_loss=4.941, nll_loss=2.123, w2v_ctc_loss=0.588, task_loss=1.978, contrastive_loss=0.156, total=4149.21, n_correct=2769.22, ppl=4.35, accuracy=66.741, wps=7119.2, ups=0.86, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=67, gb_free=17, wall=37682
2023-08-04 23:21:28 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.925, trans_loss=4.924, nll_loss=2.096, w2v_ctc_loss=0.579, task_loss=2.249, contrastive_loss=0.039, total=4073.9, n_correct=2735.54, ppl=4.28, accuracy=67.148, wps=12031.2, ups=1.48, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=67, gb_free=15.2, wall=37750
2023-08-04 23:22:36 | INFO | train_inner | epoch 033:    252 / 1474 loss=1.933, trans_loss=4.923, nll_loss=2.099, w2v_ctc_loss=0.583, task_loss=1.79, contrastive_loss=0.219, total=4280.14, n_correct=2874.64, ppl=4.28, accuracy=67.162, wps=12515.5, ups=1.46, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=37818
2023-08-04 23:23:45 | INFO | train_inner | epoch 033:    352 / 1474 loss=1.932, trans_loss=4.934, nll_loss=2.111, w2v_ctc_loss=0.591, task_loss=2.139, contrastive_loss=0.07, total=4120.27, n_correct=2758.54, ppl=4.32, accuracy=66.95, wps=12064.7, ups=1.46, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=37886
2023-08-04 23:24:52 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.919, trans_loss=4.919, nll_loss=2.092, w2v_ctc_loss=0.583, task_loss=1.988, contrastive_loss=0.046, total=4141.22, n_correct=2783.62, ppl=4.26, accuracy=67.217, wps=12373.4, ups=1.49, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=66, gb_free=16.4, wall=37953
2023-08-04 23:26:00 | INFO | train_inner | epoch 033:    552 / 1474 loss=1.941, trans_loss=4.943, nll_loss=2.121, w2v_ctc_loss=0.6, task_loss=2.18, contrastive_loss=0.069, total=4133.59, n_correct=2757.92, ppl=4.35, accuracy=66.72, wps=12159.2, ups=1.47, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=68, gb_free=15.2, wall=38021
2023-08-04 23:27:08 | INFO | train_inner | epoch 033:    652 / 1474 loss=1.941, trans_loss=4.95, nll_loss=2.133, w2v_ctc_loss=0.593, task_loss=2.15, contrastive_loss=0.104, total=4157.63, n_correct=2770.98, ppl=4.39, accuracy=66.648, wps=12247.2, ups=1.47, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=67, gb_free=17.7, wall=38089
2023-08-04 23:28:16 | INFO | train_inner | epoch 033:    752 / 1474 loss=1.944, trans_loss=4.948, nll_loss=2.129, w2v_ctc_loss=0.606, task_loss=2.282, contrastive_loss=0.048, total=4070.75, n_correct=2711.07, ppl=4.38, accuracy=66.599, wps=11970.3, ups=1.47, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=38157
2023-08-04 23:29:23 | INFO | train_inner | epoch 033:    852 / 1474 loss=1.924, trans_loss=4.933, nll_loss=2.112, w2v_ctc_loss=0.572, task_loss=1.994, contrastive_loss=0.119, total=4130.24, n_correct=2771.03, ppl=4.32, accuracy=67.091, wps=12291.3, ups=1.49, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=67, gb_free=16.7, wall=38224
2023-08-04 23:29:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 23:29:46 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.179 | trans_loss 5.549 | nll_loss 2.817 | w2v_ctc_loss 1.323 | task_loss 6.992 | contrastive_loss 0.244 | total 4003.4 | n_correct 2496.4 | ppl 7.05 | accuracy 62.357 | uer 16.672 | wer 18.541 | raw_wer 18.541 | bleu 20.29 | wps 2228.5 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.6
2023-08-04 23:29:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-04 23:29:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_33_48000.pt
2023-08-04 23:29:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_33_48000.pt
2023-08-04 23:30:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.29) (writing took 29.660208117216825 seconds)
2023-08-04 23:31:24 | INFO | train_inner | epoch 033:    952 / 1474 loss=1.939, trans_loss=4.946, nll_loss=2.127, w2v_ctc_loss=0.6, task_loss=2.097, contrastive_loss=0.061, total=4151.18, n_correct=2772.12, ppl=4.37, accuracy=66.779, wps=6830.3, ups=0.82, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=68, gb_free=11.1, wall=38346
2023-08-04 23:32:33 | INFO | train_inner | epoch 033:   1052 / 1474 loss=1.942, trans_loss=4.943, nll_loss=2.124, w2v_ctc_loss=0.59, task_loss=2.102, contrastive_loss=0.168, total=4140.1, n_correct=2762.83, ppl=4.36, accuracy=66.733, wps=12047.7, ups=1.46, wpb=8280.2, bsz=307.6, num_updates=48200, lr=6.44157e-05, gnorm=0.544, clip=0, loss_scale=16, train_wall=68, gb_free=11.6, wall=38415
2023-08-04 23:33:41 | INFO | train_inner | epoch 033:   1152 / 1474 loss=1.943, trans_loss=4.951, nll_loss=2.134, w2v_ctc_loss=0.589, task_loss=2.105, contrastive_loss=0.154, total=4182.67, n_correct=2785.35, ppl=4.39, accuracy=66.593, wps=12243.9, ups=1.46, wpb=8365.3, bsz=309.5, num_updates=48300, lr=6.43489e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=68, gb_free=17.5, wall=38483
2023-08-04 23:34:49 | INFO | train_inner | epoch 033:   1252 / 1474 loss=1.938, trans_loss=4.944, nll_loss=2.125, w2v_ctc_loss=0.599, task_loss=2.207, contrastive_loss=0.052, total=4110.02, n_correct=2744.38, ppl=4.36, accuracy=66.773, wps=12130.2, ups=1.48, wpb=8220, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.549, clip=0, loss_scale=16, train_wall=67, gb_free=16.8, wall=38551
2023-08-04 23:35:58 | INFO | train_inner | epoch 033:   1352 / 1474 loss=1.936, trans_loss=4.948, nll_loss=2.131, w2v_ctc_loss=0.593, task_loss=2.059, contrastive_loss=0.073, total=4128.82, n_correct=2756.28, ppl=4.38, accuracy=66.757, wps=12057.7, ups=1.46, wpb=8257.6, bsz=312.4, num_updates=48500, lr=6.42161e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=38619
2023-08-04 23:37:06 | INFO | train_inner | epoch 033:   1452 / 1474 loss=1.943, trans_loss=4.945, nll_loss=2.128, w2v_ctc_loss=0.588, task_loss=2.095, contrastive_loss=0.218, total=4123.47, n_correct=2751.61, ppl=4.37, accuracy=66.73, wps=12068.3, ups=1.46, wpb=8246.9, bsz=308.9, num_updates=48600, lr=6.415e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=38688
2023-08-04 23:37:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 23:37:44 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.187 | trans_loss 5.549 | nll_loss 2.814 | w2v_ctc_loss 1.347 | task_loss 6.961 | contrastive_loss 0.244 | total 4003.4 | n_correct 2501.4 | ppl 7.03 | accuracy 62.482 | uer 16.718 | wer 18.579 | raw_wer 18.579 | bleu 20.14 | wps 2127.5 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 20.6
2023-08-04 23:37:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-08-04 23:37:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_last.pt
2023-08-04 23:37:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_last.pt
2023-08-04 23:37:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_last.pt (epoch 33 @ 48622 updates, score 20.14) (writing took 12.972737893462181 seconds)
2023-08-04 23:37:57 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-04 23:37:57 | INFO | train | epoch 033 | loss 1.936 | trans_loss 4.939 | nll_loss 2.118 | w2v_ctc_loss 0.591 | task_loss 2.098 | contrastive_loss 0.102 | total 4138.65 | n_correct 2766.73 | ppl 4.34 | accuracy 66.851 | wps 11093.4 | ups 1.34 | wpb 8277.3 | bsz 305.7 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.542 | clip 0 | loss_scale 16 | train_wall 995 | gb_free 17.8 | wall 38739
2023-08-04 23:37:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 23:37:58 | INFO | fairseq.trainer | begin training epoch 34
2023-08-04 23:37:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 23:38:58 | INFO | train_inner | epoch 034:     78 / 1474 loss=1.924, trans_loss=4.921, nll_loss=2.095, w2v_ctc_loss=0.588, task_loss=2.075, contrastive_loss=0.054, total=4128.94, n_correct=2775.02, ppl=4.27, accuracy=67.209, wps=7387.8, ups=0.89, wpb=8257.9, bsz=302.1, num_updates=48700, lr=6.40841e-05, gnorm=0.545, clip=0, loss_scale=16, train_wall=67, gb_free=15.1, wall=38799
2023-08-04 23:40:06 | INFO | train_inner | epoch 034:    178 / 1474 loss=1.92, trans_loss=4.914, nll_loss=2.085, w2v_ctc_loss=0.582, task_loss=2.189, contrastive_loss=0.055, total=4071.22, n_correct=2742.25, ppl=4.24, accuracy=67.357, wps=12010.5, ups=1.48, wpb=8142.4, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=67, gb_free=15.5, wall=38867
2023-08-04 23:41:14 | INFO | train_inner | epoch 034:    278 / 1474 loss=1.942, trans_loss=4.933, nll_loss=2.111, w2v_ctc_loss=0.582, task_loss=1.981, contrastive_loss=0.267, total=4237.89, n_correct=2833.78, ppl=4.32, accuracy=66.868, wps=12394.3, ups=1.46, wpb=8475.8, bsz=326.9, num_updates=48900, lr=6.39529e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=68, gb_free=10.3, wall=38936
2023-08-04 23:42:22 | INFO | train_inner | epoch 034:    378 / 1474 loss=1.923, trans_loss=4.916, nll_loss=2.089, w2v_ctc_loss=0.576, task_loss=1.983, contrastive_loss=0.154, total=4167, n_correct=2806.86, ppl=4.26, accuracy=67.359, wps=12305.8, ups=1.48, wpb=8334, bsz=319, num_updates=49000, lr=6.38877e-05, gnorm=0.547, clip=0, loss_scale=16, train_wall=67, gb_free=17.3, wall=39003
2023-08-04 23:43:29 | INFO | train_inner | epoch 034:    478 / 1474 loss=1.936, trans_loss=4.936, nll_loss=2.113, w2v_ctc_loss=0.598, task_loss=2.299, contrastive_loss=0.049, total=4071.65, n_correct=2725.24, ppl=4.33, accuracy=66.932, wps=12021.3, ups=1.48, wpb=8143.3, bsz=284.8, num_updates=49100, lr=6.38226e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=67, gb_free=11.4, wall=39071
2023-08-04 23:44:37 | INFO | train_inner | epoch 034:    578 / 1474 loss=1.925, trans_loss=4.923, nll_loss=2.097, w2v_ctc_loss=0.586, task_loss=2.134, contrastive_loss=0.05, total=4110.13, n_correct=2760.91, ppl=4.28, accuracy=67.173, wps=12209.4, ups=1.49, wpb=8220.3, bsz=299, num_updates=49200, lr=6.37577e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=39138
2023-08-04 23:45:45 | INFO | train_inner | epoch 034:    678 / 1474 loss=1.925, trans_loss=4.93, nll_loss=2.107, w2v_ctc_loss=0.584, task_loss=2.127, contrastive_loss=0.045, total=4128.65, n_correct=2770.52, ppl=4.31, accuracy=67.105, wps=12057.5, ups=1.46, wpb=8257.3, bsz=300.7, num_updates=49300, lr=6.3693e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=39207
2023-08-04 23:46:53 | INFO | train_inner | epoch 034:    778 / 1474 loss=1.936, trans_loss=4.947, nll_loss=2.128, w2v_ctc_loss=0.578, task_loss=2.206, contrastive_loss=0.116, total=4075.69, n_correct=2723.49, ppl=4.37, accuracy=66.823, wps=12051.7, ups=1.48, wpb=8151.4, bsz=294.5, num_updates=49400, lr=6.36285e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=39275
2023-08-04 23:48:01 | INFO | train_inner | epoch 034:    878 / 1474 loss=1.935, trans_loss=4.94, nll_loss=2.12, w2v_ctc_loss=0.59, task_loss=2.222, contrastive_loss=0.076, total=4104.97, n_correct=2747.19, ppl=4.35, accuracy=66.924, wps=12048.5, ups=1.47, wpb=8209.9, bsz=296.3, num_updates=49500, lr=6.35642e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=39343
2023-08-04 23:49:09 | INFO | train_inner | epoch 034:    978 / 1474 loss=1.934, trans_loss=4.94, nll_loss=2.121, w2v_ctc_loss=0.593, task_loss=2.056, contrastive_loss=0.07, total=4168.94, n_correct=2785.6, ppl=4.35, accuracy=66.818, wps=12259.6, ups=1.47, wpb=8337.9, bsz=312.8, num_updates=49600, lr=6.35001e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=39411
2023-08-04 23:50:17 | INFO | train_inner | epoch 034:   1078 / 1474 loss=1.933, trans_loss=4.942, nll_loss=2.122, w2v_ctc_loss=0.594, task_loss=2.031, contrastive_loss=0.051, total=4155.12, n_correct=2779.34, ppl=4.35, accuracy=66.89, wps=12280.7, ups=1.48, wpb=8310.2, bsz=309.1, num_updates=49700, lr=6.34361e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=39478
2023-08-04 23:51:24 | INFO | train_inner | epoch 034:   1178 / 1474 loss=1.933, trans_loss=4.941, nll_loss=2.12, w2v_ctc_loss=0.589, task_loss=2.17, contrastive_loss=0.064, total=4096.48, n_correct=2738.07, ppl=4.35, accuracy=66.84, wps=12141.4, ups=1.48, wpb=8193, bsz=297.2, num_updates=49800, lr=6.33724e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=39546
2023-08-04 23:52:32 | INFO | train_inner | epoch 034:   1278 / 1474 loss=1.93, trans_loss=4.938, nll_loss=2.118, w2v_ctc_loss=0.586, task_loss=2.131, contrastive_loss=0.047, total=4149.03, n_correct=2774.78, ppl=4.34, accuracy=66.878, wps=12208, ups=1.47, wpb=8298.1, bsz=299.7, num_updates=49900, lr=6.33089e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=39614
2023-08-04 23:53:41 | INFO | train_inner | epoch 034:   1378 / 1474 loss=1.942, trans_loss=4.947, nll_loss=2.13, w2v_ctc_loss=0.6, task_loss=2.008, contrastive_loss=0.116, total=4200.34, n_correct=2800.54, ppl=4.38, accuracy=66.674, wps=12227, ups=1.46, wpb=8400.7, bsz=321.9, num_updates=50000, lr=6.32456e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=39683
2023-08-04 23:53:41 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-04 23:53:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 23:54:04 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.184 | trans_loss 5.547 | nll_loss 2.817 | w2v_ctc_loss 1.342 | task_loss 7.004 | contrastive_loss 0.246 | total 4003.4 | n_correct 2497.7 | ppl 7.04 | accuracy 62.389 | uer 16.619 | wer 18.478 | raw_wer 18.478 | bleu 20.45 | wps 2200.6 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.6
2023-08-04 23:54:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-04 23:54:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_34_50000.pt
2023-08-04 23:54:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_34_50000.pt
2023-08-04 23:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0804_at_sentence_0.5mt_1.5at/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.45) (writing took 30.797100799158216 seconds)
2023-08-04 23:54:36 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-04 23:54:36 | INFO | train | epoch 034 | loss 1.931 | trans_loss 4.933 | nll_loss 2.111 | w2v_ctc_loss 0.587 | task_loss 2.114 | contrastive_loss 0.089 | total 4133.33 | n_correct 2769 | ppl 4.32 | accuracy 66.992 | wps 11406.9 | ups 1.38 | wpb 8266.7 | bsz 304.3 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.542 | clip 0 | loss_scale 32 | train_wall 930 | gb_free 15 | wall 39738
2023-08-04 23:54:36 | INFO | fairseq_cli.train | done training in 39685.6 seconds
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
