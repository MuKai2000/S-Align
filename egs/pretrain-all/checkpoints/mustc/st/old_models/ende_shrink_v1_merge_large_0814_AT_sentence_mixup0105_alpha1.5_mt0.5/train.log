2023-08-14 13:38:50 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11399
2023-08-14 13:38:51 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11399
2023-08-14 13:38:51 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11399
2023-08-14 13:38:51 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11399
2023-08-14 13:38:51 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11399
2023-08-14 13:38:51 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11399
2023-08-14 13:38:51 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11399
2023-08-14 13:38:51 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11399
2023-08-14 13:38:51 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 13:38:52 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 13:38:52 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 13:38:52 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-14 13:38:52 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 13:38:52 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-14 13:38:52 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-14 13:38:52 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-14 13:38:52 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-14 13:38:52 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-14 13:38:56 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11399', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=-0.1, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-14 13:38:56 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-14 13:38:56 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-14 13:38:56 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-14 13:38:56 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-14 13:38:56 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-14 13:39:01 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-14 13:39:01 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-14 13:39:01 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-14 13:39:03 | INFO | root | load pretrained hubert
2023-08-14 13:39:06 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-14 13:39:07 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-14 13:39:10 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-14 13:39:10 | INFO | root | share the sematic adapter and textual encoder
2023-08-14 13:39:10 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-14 13:39:10 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-14 13:39:10 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-14 13:39:10 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-14 13:39:10 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-14 13:39:10 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-14 13:39:10 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-14 13:39:10 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 13:39:10 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 13:39:10 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-14 13:39:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-14 13:39:14 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-14 13:39:14 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-14 13:39:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-14 13:39:15 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 13:39:15 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 13:39:15 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 13:39:15 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 13:39:15 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 13:39:15 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 13:39:15 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 13:39:15 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-14 13:39:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-14 13:39:15 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-14 13:39:15 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-14 13:39:15 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 13:39:15 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 13:39:15 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-14 13:39:15 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-14 13:39:15 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 13:39:15 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-14 13:39:16 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-14 13:39:18 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-14 13:40:08 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-14 13:40:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 13:40:08 | INFO | fairseq.trainer | begin training epoch 1
2023-08-14 13:40:08 | INFO | fairseq_cli.train | Start iterating over samples
None None None
2023-08-14 13:40:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
None None None
2023-08-14 13:40:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
None None None
2023-08-14 13:40:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 13:40:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
None None None
None None None
None None None
2023-08-14 13:41:28 | INFO | train_inner | epoch 001:    104 / 1474 loss=20.046, trans_loss=5.872, nll_loss=4.68, w2v_ctc_loss=22.327, task_loss=1.769, contrastive_loss=3.271, total=4215.43, n_correct=123.27, ppl=25.63, accuracy=2.924, wps=18585.1, ups=1.48, wpb=12576.1, bsz=475.2, num_updates=100, lr=4.098e-06, gnorm=2.839, clip=0, loss_scale=8, train_wall=72, gb_free=18.6, wall=134
2023-08-14 13:41:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-14 13:42:35 | INFO | train_inner | epoch 001:    205 / 1474 loss=16.566, trans_loss=5.871, nll_loss=4.706, w2v_ctc_loss=17.03, task_loss=1.714, contrastive_loss=3.236, total=4109.06, n_correct=112.57, ppl=26.1, accuracy=2.74, wps=18476.1, ups=1.51, wpb=12269.9, bsz=458.5, num_updates=200, lr=8.096e-06, gnorm=7.274, clip=17, loss_scale=4, train_wall=66, gb_free=19.4, wall=200
2023-08-14 13:43:40 | INFO | train_inner | epoch 001:    305 / 1474 loss=9.916, trans_loss=5.843, nll_loss=4.707, w2v_ctc_loss=6.884, task_loss=1.66, contrastive_loss=3.175, total=4080.91, n_correct=111.06, ppl=26.12, accuracy=2.721, wps=18814.9, ups=1.54, wpb=12190.4, bsz=439.4, num_updates=300, lr=1.2094e-05, gnorm=2.172, clip=0, loss_scale=4, train_wall=64, gb_free=18.6, wall=265
2023-08-14 13:43:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-14 13:44:45 | INFO | train_inner | epoch 001:    406 / 1474 loss=9.391, trans_loss=5.777, nll_loss=4.658, w2v_ctc_loss=6.103, task_loss=1.42, contrastive_loss=3.207, total=4175.81, n_correct=100.14, ppl=25.24, accuracy=2.398, wps=19089.3, ups=1.53, wpb=12468.9, bsz=461.8, num_updates=400, lr=1.6092e-05, gnorm=1.343, clip=0, loss_scale=2, train_wall=65, gb_free=18.6, wall=330
2023-08-14 13:45:50 | INFO | train_inner | epoch 001:    506 / 1474 loss=9.171, trans_loss=5.683, nll_loss=4.551, w2v_ctc_loss=5.812, task_loss=1.276, contrastive_loss=3.301, total=4181.66, n_correct=104.39, ppl=23.44, accuracy=2.496, wps=19239.6, ups=1.54, wpb=12495.1, bsz=487, num_updates=500, lr=2.009e-05, gnorm=1.593, clip=1, loss_scale=2, train_wall=64, gb_free=19.2, wall=395
2023-08-14 13:46:56 | INFO | train_inner | epoch 001:    606 / 1474 loss=9.067, trans_loss=5.712, nll_loss=4.584, w2v_ctc_loss=5.674, task_loss=1.243, contrastive_loss=3.253, total=4137.35, n_correct=97.37, ppl=23.99, accuracy=2.353, wps=18755.5, ups=1.52, wpb=12337.2, bsz=474.5, num_updates=600, lr=2.4088e-05, gnorm=1.68, clip=0, loss_scale=2, train_wall=65, gb_free=18.7, wall=461
2023-08-14 13:48:00 | INFO | train_inner | epoch 001:    706 / 1474 loss=9.004, trans_loss=5.725, nll_loss=4.597, w2v_ctc_loss=5.637, task_loss=1.312, contrastive_loss=3.134, total=4145.85, n_correct=102.61, ppl=24.21, accuracy=2.475, wps=19204.7, ups=1.55, wpb=12381.9, bsz=454.4, num_updates=700, lr=2.8086e-05, gnorm=1.218, clip=0, loss_scale=2, train_wall=64, gb_free=19.5, wall=525
2023-08-14 13:49:05 | INFO | train_inner | epoch 001:    806 / 1474 loss=8.996, trans_loss=5.913, nll_loss=4.843, w2v_ctc_loss=5.473, task_loss=1.271, contrastive_loss=3.154, total=4129.2, n_correct=70.12, ppl=28.7, accuracy=1.698, wps=19078.2, ups=1.55, wpb=12318.4, bsz=463.3, num_updates=800, lr=3.2084e-05, gnorm=1.34, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=590
2023-08-14 13:50:09 | INFO | train_inner | epoch 001:    906 / 1474 loss=8.884, trans_loss=5.969, nll_loss=4.904, w2v_ctc_loss=5.295, task_loss=1.291, contrastive_loss=3.069, total=4167.97, n_correct=77.9, ppl=29.94, accuracy=1.869, wps=19312.2, ups=1.55, wpb=12446.3, bsz=458.8, num_updates=900, lr=3.6082e-05, gnorm=1.403, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=654
2023-08-14 13:51:15 | INFO | train_inner | epoch 001:   1006 / 1474 loss=8.682, trans_loss=5.962, nll_loss=4.889, w2v_ctc_loss=5.028, task_loss=1.292, contrastive_loss=3.063, total=4137.5, n_correct=91.07, ppl=29.62, accuracy=2.201, wps=18845.6, ups=1.52, wpb=12361.1, bsz=459.1, num_updates=1000, lr=4.008e-05, gnorm=1.631, clip=1, loss_scale=2, train_wall=65, gb_free=19.3, wall=720
2023-08-14 13:52:20 | INFO | train_inner | epoch 001:   1106 / 1474 loss=8.454, trans_loss=5.996, nll_loss=4.919, w2v_ctc_loss=4.764, task_loss=1.327, contrastive_loss=2.972, total=4151.84, n_correct=91.89, ppl=30.26, accuracy=2.213, wps=19106.3, ups=1.54, wpb=12382.4, bsz=452.7, num_updates=1100, lr=4.4078e-05, gnorm=1.679, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=785
2023-08-14 13:53:24 | INFO | train_inner | epoch 001:   1206 / 1474 loss=8.259, trans_loss=6.019, nll_loss=4.956, w2v_ctc_loss=4.561, task_loss=1.383, contrastive_loss=2.857, total=4123.25, n_correct=93.99, ppl=31.03, accuracy=2.28, wps=19050.9, ups=1.55, wpb=12316.7, bsz=437.7, num_updates=1200, lr=4.8076e-05, gnorm=2.022, clip=0, loss_scale=2, train_wall=64, gb_free=19.6, wall=850
2023-08-14 13:54:29 | INFO | train_inner | epoch 001:   1306 / 1474 loss=8.091, trans_loss=6.007, nll_loss=4.936, w2v_ctc_loss=4.365, task_loss=1.302, contrastive_loss=2.809, total=4066.16, n_correct=102.84, ppl=30.6, accuracy=2.529, wps=18858.4, ups=1.55, wpb=12138.7, bsz=445.8, num_updates=1300, lr=5.2074e-05, gnorm=2.379, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=914
2023-08-14 13:55:33 | INFO | train_inner | epoch 001:   1406 / 1474 loss=7.927, trans_loss=5.975, nll_loss=4.901, w2v_ctc_loss=4.21, task_loss=1.324, contrastive_loss=2.875, total=4119.98, n_correct=104.22, ppl=29.88, accuracy=2.53, wps=18977.8, ups=1.54, wpb=12311.1, bsz=449.5, num_updates=1400, lr=5.6072e-05, gnorm=2.701, clip=1, loss_scale=2, train_wall=64, gb_free=18.6, wall=979
2023-08-14 13:56:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
None None None
2023-08-14 13:56:59 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 12.173 | trans_loss 13.402 | nll_loss 13.098 | w2v_ctc_loss 5.551 | task_loss 7.545 | contrastive_loss 4.068 | total 4003.4 | n_correct 73.4 | ppl 8767.98 | accuracy 1.833 | uer 71.104 | wer 68.655 | raw_wer 68.655 | bleu 0 | wps 1140.6 | wpb 4003.4 | bsz 141.8 | num_updates 1468
2023-08-14 13:56:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1468 updates
2023-08-14 13:56:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 13:57:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 13:57:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1468 updates, score 0.0) (writing took 6.884058307856321 seconds)
2023-08-14 13:57:06 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-14 13:57:06 | INFO | train | epoch 001 | loss 10.079 | trans_loss 5.884 | nll_loss 4.779 | w2v_ctc_loss 7.234 | task_loss 1.392 | contrastive_loss 3.089 | total 4138.5 | n_correct 98.9898 | ppl 27.46 | accuracy 2.392 | wps 18048.9 | ups 1.46 | wpb 12355.4 | bsz 458.8 | num_updates 1468 | lr 5.87906e-05 | gnorm 2.262 | clip 1.4 | loss_scale 2 | train_wall 955 | gb_free 18.9 | wall 1071
2023-08-14 13:57:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 13:57:06 | INFO | fairseq.trainer | begin training epoch 2
2023-08-14 13:57:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 13:57:35 | INFO | train_inner | epoch 002:     32 / 1474 loss=7.834, trans_loss=5.985, nll_loss=4.917, w2v_ctc_loss=4.074, task_loss=1.253, contrastive_loss=2.851, total=4165.61, n_correct=101.14, ppl=30.21, accuracy=2.428, wps=10260.3, ups=0.83, wpb=12422.6, bsz=470.4, num_updates=1500, lr=6.007e-05, gnorm=2.825, clip=0, loss_scale=2, train_wall=65, gb_free=18.7, wall=1100
2023-08-14 13:58:39 | INFO | train_inner | epoch 002:    132 / 1474 loss=7.72, trans_loss=5.987, nll_loss=4.924, w2v_ctc_loss=3.991, task_loss=1.31, contrastive_loss=2.722, total=4153.7, n_correct=97.66, ppl=30.35, accuracy=2.351, wps=19191.7, ups=1.55, wpb=12391.2, bsz=453.7, num_updates=1600, lr=6.4068e-05, gnorm=2.683, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=1164
2023-08-14 13:59:44 | INFO | train_inner | epoch 002:    232 / 1474 loss=7.659, trans_loss=6.009, nll_loss=4.957, w2v_ctc_loss=3.841, task_loss=1.144, contrastive_loss=2.792, total=4201.44, n_correct=91.83, ppl=31.06, accuracy=2.186, wps=19448.7, ups=1.55, wpb=12547.2, bsz=493.6, num_updates=1700, lr=6.8066e-05, gnorm=2.579, clip=0, loss_scale=2, train_wall=64, gb_free=18.9, wall=1229
2023-08-14 14:00:48 | INFO | train_inner | epoch 002:    332 / 1474 loss=7.466, trans_loss=5.987, nll_loss=4.93, w2v_ctc_loss=3.788, task_loss=1.337, contrastive_loss=2.558, total=4130.13, n_correct=94.75, ppl=30.48, accuracy=2.294, wps=19147.6, ups=1.55, wpb=12330.1, bsz=445.5, num_updates=1800, lr=7.2064e-05, gnorm=2.626, clip=0, loss_scale=2, train_wall=64, gb_free=18.7, wall=1293
2023-08-14 14:01:53 | INFO | train_inner | epoch 002:    432 / 1474 loss=7.32, trans_loss=5.98, nll_loss=4.927, w2v_ctc_loss=3.726, task_loss=1.468, contrastive_loss=2.368, total=4035.12, n_correct=92.09, ppl=30.42, accuracy=2.282, wps=18424.2, ups=1.53, wpb=12062.7, bsz=413.5, num_updates=1900, lr=7.6062e-05, gnorm=2.515, clip=0, loss_scale=2, train_wall=65, gb_free=19, wall=1359
2023-08-14 14:02:58 | INFO | train_inner | epoch 002:    532 / 1474 loss=7.243, trans_loss=5.943, nll_loss=4.876, w2v_ctc_loss=3.591, task_loss=1.268, contrastive_loss=2.521, total=4183.09, n_correct=107.46, ppl=29.37, accuracy=2.569, wps=19472.7, ups=1.56, wpb=12479, bsz=468.4, num_updates=2000, lr=8.006e-05, gnorm=2.657, clip=0, loss_scale=2, train_wall=64, gb_free=18.5, wall=1423
2023-08-14 14:02:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 14:03:37 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.671 | trans_loss 13.322 | nll_loss 13.002 | w2v_ctc_loss 4.668 | task_loss 7.545 | contrastive_loss 3.593 | total 4003.4 | n_correct 74.4 | ppl 8201.26 | accuracy 1.858 | uer 62.549 | wer 60.553 | raw_wer 60.553 | bleu 0 | wps 1187.8 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-14 14:03:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-14 14:03:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-14 14:03:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-14 14:04:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 49.10298888385296 seconds)
2023-08-14 14:05:31 | INFO | train_inner | epoch 002:    632 / 1474 loss=7.12, trans_loss=5.963, nll_loss=4.902, w2v_ctc_loss=3.501, task_loss=1.301, contrastive_loss=2.337, total=4123.85, n_correct=97.76, ppl=29.91, accuracy=2.371, wps=8045.2, ups=0.65, wpb=12306.4, bsz=448.7, num_updates=2100, lr=8.4058e-05, gnorm=2.535, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=1576
2023-08-14 14:06:35 | INFO | train_inner | epoch 002:    732 / 1474 loss=7.052, trans_loss=5.964, nll_loss=4.905, w2v_ctc_loss=3.437, task_loss=1.288, contrastive_loss=2.406, total=4148.13, n_correct=100.89, ppl=29.97, accuracy=2.432, wps=19263.7, ups=1.56, wpb=12381, bsz=462.1, num_updates=2200, lr=8.8056e-05, gnorm=2.592, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=1640
2023-08-14 14:07:40 | INFO | train_inner | epoch 002:    832 / 1474 loss=6.956, trans_loss=5.953, nll_loss=4.896, w2v_ctc_loss=3.383, task_loss=1.301, contrastive_loss=2.35, total=4172.27, n_correct=101.43, ppl=29.77, accuracy=2.431, wps=19181.7, ups=1.54, wpb=12465.7, bsz=464.5, num_updates=2300, lr=9.2054e-05, gnorm=2.349, clip=0, loss_scale=2, train_wall=65, gb_free=18.8, wall=1705
2023-08-14 14:08:45 | INFO | train_inner | epoch 002:    932 / 1474 loss=6.806, trans_loss=5.925, nll_loss=4.858, w2v_ctc_loss=3.298, task_loss=1.362, contrastive_loss=2.269, total=4101.67, n_correct=99.93, ppl=29, accuracy=2.436, wps=18887.2, ups=1.54, wpb=12242.5, bsz=441.6, num_updates=2400, lr=9.6052e-05, gnorm=2.447, clip=0, loss_scale=4, train_wall=64, gb_free=18.9, wall=1770
2023-08-14 14:09:49 | INFO | train_inner | epoch 002:   1032 / 1474 loss=6.737, trans_loss=5.958, nll_loss=4.899, w2v_ctc_loss=3.234, task_loss=1.324, contrastive_loss=2.153, total=4091.09, n_correct=91.85, ppl=29.83, accuracy=2.245, wps=19052.1, ups=1.56, wpb=12214.8, bsz=451.5, num_updates=2500, lr=0.00010005, gnorm=2.191, clip=0, loss_scale=4, train_wall=64, gb_free=19.2, wall=1834
2023-08-14 14:10:54 | INFO | train_inner | epoch 002:   1132 / 1474 loss=6.706, trans_loss=5.942, nll_loss=4.88, w2v_ctc_loss=3.136, task_loss=1.149, contrastive_loss=2.376, total=4219.19, n_correct=98.8, ppl=29.45, accuracy=2.342, wps=19326.4, ups=1.53, wpb=12595.1, bsz=500.6, num_updates=2600, lr=0.000104048, gnorm=2.299, clip=0, loss_scale=4, train_wall=65, gb_free=19, wall=1899
2023-08-14 14:11:59 | INFO | train_inner | epoch 002:   1232 / 1474 loss=6.594, trans_loss=5.935, nll_loss=4.869, w2v_ctc_loss=3.101, task_loss=1.21, contrastive_loss=2.181, total=4212.91, n_correct=95.55, ppl=29.23, accuracy=2.268, wps=19424.9, ups=1.55, wpb=12571.7, bsz=486.8, num_updates=2700, lr=0.000108046, gnorm=2.122, clip=0, loss_scale=4, train_wall=64, gb_free=19.1, wall=1964
2023-08-14 14:13:03 | INFO | train_inner | epoch 002:   1332 / 1474 loss=6.489, trans_loss=5.932, nll_loss=4.869, w2v_ctc_loss=3.064, task_loss=1.271, contrastive_loss=1.963, total=4142.48, n_correct=95.86, ppl=29.23, accuracy=2.314, wps=19123.1, ups=1.54, wpb=12381.2, bsz=456.3, num_updates=2800, lr=0.000112044, gnorm=2.111, clip=0, loss_scale=4, train_wall=64, gb_free=18.9, wall=2029
2023-08-14 14:14:08 | INFO | train_inner | epoch 002:   1432 / 1474 loss=6.404, trans_loss=5.946, nll_loss=4.885, w2v_ctc_loss=3.016, task_loss=1.386, contrastive_loss=2.016, total=4063.28, n_correct=86.97, ppl=29.54, accuracy=2.14, wps=18785.9, ups=1.55, wpb=12131.5, bsz=444.3, num_updates=2900, lr=0.000116042, gnorm=2.074, clip=0, loss_scale=4, train_wall=64, gb_free=19.6, wall=2093
2023-08-14 14:14:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 14:15:14 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.846 | trans_loss 12.973 | nll_loss 12.56 | w2v_ctc_loss 3.827 | task_loss 7.545 | contrastive_loss 2.727 | total 4003.4 | n_correct 91.8 | ppl 6039.72 | accuracy 2.293 | uer 53.311 | wer 52.91 | raw_wer 52.91 | bleu 0 | wps 1172.8 | wpb 4003.4 | bsz 141.8 | num_updates 2942 | best_bleu 0
2023-08-14 14:15:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2942 updates
2023-08-14 14:15:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 14:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 14:15:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2942 updates, score 0.0) (writing took 27.239848190918565 seconds)
2023-08-14 14:15:41 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-14 14:15:41 | INFO | train | epoch 002 | loss 7.018 | trans_loss 5.959 | nll_loss 4.898 | w2v_ctc_loss 3.437 | task_loss 1.292 | contrastive_loss 2.357 | total 4138.65 | n_correct 96.6377 | ppl 29.83 | accuracy 2.335 | wps 16323.3 | ups 1.32 | wpb 12355.8 | bsz 458.5 | num_updates 2942 | lr 0.000117721 | gnorm 2.404 | clip 0 | loss_scale 4 | train_wall 945 | gb_free 19 | wall 2187
2023-08-14 14:15:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 14:15:42 | INFO | fairseq.trainer | begin training epoch 3
2023-08-14 14:15:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 14:16:27 | INFO | train_inner | epoch 003:     58 / 1474 loss=6.291, trans_loss=5.921, nll_loss=4.854, w2v_ctc_loss=2.962, task_loss=1.362, contrastive_loss=1.862, total=4048.67, n_correct=94.75, ppl=28.91, accuracy=2.34, wps=8705, ups=0.72, wpb=12085.6, bsz=433.9, num_updates=3000, lr=0.00012004, gnorm=1.797, clip=0, loss_scale=4, train_wall=64, gb_free=18.8, wall=2232
2023-08-14 14:16:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-14 14:18:00 | INFO | train_inner | epoch 003:    159 / 1474 loss=5.515, trans_loss=5.075, nll_loss=3.761, w2v_ctc_loss=2.699, task_loss=0.898, contrastive_loss=1.823, total=4156.77, n_correct=462.89, ppl=13.56, accuracy=11.136, wps=13367.9, ups=1.08, wpb=12412.5, bsz=463.1, num_updates=3100, lr=0.000124038, gnorm=3.841, clip=2, loss_scale=2, train_wall=92, gb_free=16.2, wall=2325
2023-08-14 14:19:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-08-14 14:19:35 | INFO | train_inner | epoch 003:    260 / 1474 loss=4.608, trans_loss=4.355, nll_loss=2.809, w2v_ctc_loss=2.424, task_loss=0.921, contrastive_loss=1.598, total=4159.4, n_correct=1077.81, ppl=7.01, accuracy=25.913, wps=13053.4, ups=1.05, wpb=12425.9, bsz=467.9, num_updates=3200, lr=0.000128036, gnorm=2.689, clip=0, loss_scale=1, train_wall=95, gb_free=15.3, wall=2420
2023-08-14 14:21:07 | INFO | train_inner | epoch 003:    360 / 1474 loss=4.349, trans_loss=4.238, nll_loss=2.657, w2v_ctc_loss=2.31, task_loss=0.911, contrastive_loss=1.512, total=4159.93, n_correct=1240.19, ppl=6.31, accuracy=29.813, wps=13415.8, ups=1.08, wpb=12413.4, bsz=467.3, num_updates=3300, lr=0.000132034, gnorm=2.462, clip=1, loss_scale=1, train_wall=92, gb_free=15.6, wall=2513
2023-08-14 14:22:40 | INFO | train_inner | epoch 003:    460 / 1474 loss=4.14, trans_loss=4.186, nll_loss=2.592, w2v_ctc_loss=2.207, task_loss=0.913, contrastive_loss=1.315, total=4196.46, n_correct=1325.88, ppl=6.03, accuracy=31.595, wps=13522.1, ups=1.08, wpb=12527.1, bsz=468.6, num_updates=3400, lr=0.000136032, gnorm=2.157, clip=1, loss_scale=1, train_wall=92, gb_free=15.4, wall=2605
2023-08-14 14:24:13 | INFO | train_inner | epoch 003:    560 / 1474 loss=3.957, trans_loss=4.155, nll_loss=2.555, w2v_ctc_loss=2.112, task_loss=0.988, contrastive_loss=1.202, total=4085.25, n_correct=1334.54, ppl=5.88, accuracy=32.667, wps=13173.1, ups=1.08, wpb=12203.2, bsz=439.8, num_updates=3500, lr=0.00014003, gnorm=1.973, clip=0, loss_scale=1, train_wall=92, gb_free=15.4, wall=2698
2023-08-14 14:25:47 | INFO | train_inner | epoch 003:    660 / 1474 loss=3.877, trans_loss=4.132, nll_loss=2.522, w2v_ctc_loss=2.025, task_loss=0.876, contrastive_loss=1.271, total=4229.91, n_correct=1424.96, ppl=5.74, accuracy=33.688, wps=13397.7, ups=1.06, wpb=12610.8, bsz=484.8, num_updates=3600, lr=0.000144028, gnorm=1.873, clip=0, loss_scale=1, train_wall=94, gb_free=17, wall=2792
2023-08-14 14:27:19 | INFO | train_inner | epoch 003:    760 / 1474 loss=3.728, trans_loss=4.099, nll_loss=2.484, w2v_ctc_loss=1.986, task_loss=0.894, contrastive_loss=0.988, total=4157.48, n_correct=1444.66, ppl=5.6, accuracy=34.748, wps=13444.6, ups=1.08, wpb=12420.7, bsz=467.8, num_updates=3700, lr=0.000148026, gnorm=1.742, clip=0, loss_scale=1, train_wall=92, gb_free=11.1, wall=2885
2023-08-14 14:28:52 | INFO | train_inner | epoch 003:    860 / 1474 loss=3.639, trans_loss=4.087, nll_loss=2.467, w2v_ctc_loss=1.941, task_loss=0.925, contrastive_loss=0.918, total=4172.27, n_correct=1476.54, ppl=5.53, accuracy=35.389, wps=13425.4, ups=1.08, wpb=12457.6, bsz=458.8, num_updates=3800, lr=0.000152024, gnorm=1.743, clip=0, loss_scale=1, train_wall=92, gb_free=16.3, wall=2977
2023-08-14 14:30:25 | INFO | train_inner | epoch 003:    960 / 1474 loss=3.566, trans_loss=4.063, nll_loss=2.433, w2v_ctc_loss=1.903, task_loss=0.888, contrastive_loss=0.921, total=4171.53, n_correct=1525.07, ppl=5.4, accuracy=36.559, wps=13446.2, ups=1.08, wpb=12442.2, bsz=473.5, num_updates=3900, lr=0.000156022, gnorm=1.819, clip=0, loss_scale=1, train_wall=92, gb_free=15.9, wall=3070
2023-08-14 14:31:57 | INFO | train_inner | epoch 003:   1060 / 1474 loss=3.502, trans_loss=4.043, nll_loss=2.41, w2v_ctc_loss=1.912, task_loss=0.998, contrastive_loss=0.809, total=4051.14, n_correct=1501.53, ppl=5.31, accuracy=37.064, wps=13094.8, ups=1.08, wpb=12099.4, bsz=436.8, num_updates=4000, lr=0.00016002, gnorm=1.783, clip=0, loss_scale=1, train_wall=92, gb_free=16.5, wall=3162
2023-08-14 14:31:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 14:32:30 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.733 | trans_loss 6.936 | nll_loss 4.703 | w2v_ctc_loss 2.27 | task_loss 4.198 | contrastive_loss 1.136 | total 4003.4 | n_correct 1626.7 | ppl 26.05 | accuracy 40.633 | uer 33.048 | wer 33.343 | raw_wer 33.343 | bleu 2.98 | wps 1444.9 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 2.98
2023-08-14 14:32:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-14 14:32:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-14 14:32:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-14 14:33:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 2.98) (writing took 50.13742082007229 seconds)
2023-08-14 14:34:52 | INFO | train_inner | epoch 003:   1160 / 1474 loss=3.429, trans_loss=4.03, nll_loss=2.392, w2v_ctc_loss=1.873, task_loss=0.986, contrastive_loss=0.767, total=4050.25, n_correct=1530.78, ppl=5.25, accuracy=37.795, wps=6894.2, ups=0.57, wpb=12088.6, bsz=435.7, num_updates=4100, lr=0.000164018, gnorm=1.824, clip=0, loss_scale=1, train_wall=91, gb_free=15.9, wall=3338
2023-08-14 14:36:24 | INFO | train_inner | epoch 003:   1260 / 1474 loss=3.337, trans_loss=3.997, nll_loss=2.35, w2v_ctc_loss=1.824, task_loss=0.986, contrastive_loss=0.704, total=4058.28, n_correct=1577.34, ppl=5.1, accuracy=38.867, wps=13190.9, ups=1.09, wpb=12119.7, bsz=431.2, num_updates=4200, lr=0.000168016, gnorm=1.645, clip=0, loss_scale=1, train_wall=91, gb_free=16.1, wall=3429
2023-08-14 14:37:57 | INFO | train_inner | epoch 003:   1360 / 1474 loss=3.322, trans_loss=3.973, nll_loss=2.318, w2v_ctc_loss=1.797, task_loss=0.934, contrastive_loss=0.809, total=4134.29, n_correct=1654.4, ppl=4.99, accuracy=40.017, wps=13236.2, ups=1.07, wpb=12343, bsz=460.8, num_updates=4300, lr=0.000172014, gnorm=1.683, clip=0, loss_scale=1, train_wall=93, gb_free=16.4, wall=3523
2023-08-14 14:39:31 | INFO | train_inner | epoch 003:   1460 / 1474 loss=3.257, trans_loss=3.946, nll_loss=2.285, w2v_ctc_loss=1.766, task_loss=0.883, contrastive_loss=0.764, total=4206.08, n_correct=1726.6, ppl=4.87, accuracy=41.05, wps=13400.5, ups=1.07, wpb=12563.6, bsz=476.5, num_updates=4400, lr=0.000176012, gnorm=1.508, clip=0, loss_scale=1, train_wall=93, gb_free=14.1, wall=3617
2023-08-14 14:39:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 14:40:17 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.409 | trans_loss 6.646 | nll_loss 4.326 | w2v_ctc_loss 2.106 | task_loss 4.148 | contrastive_loss 0.912 | total 4003.4 | n_correct 1802.8 | ppl 20.06 | accuracy 45.032 | uer 32.182 | wer 32.463 | raw_wer 32.463 | bleu 6.23 | wps 1421.4 | wpb 4003.4 | bsz 141.8 | num_updates 4414 | best_bleu 6.23
2023-08-14 14:40:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4414 updates
2023-08-14 14:40:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 14:40:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 14:40:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 3 @ 4414 updates, score 6.23) (writing took 30.285305643454194 seconds)
2023-08-14 14:40:48 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-14 14:40:48 | INFO | train | epoch 003 | loss 3.963 | trans_loss 4.237 | nll_loss 2.661 | w2v_ctc_loss 2.088 | task_loss 0.944 | contrastive_loss 1.132 | total 4138.81 | n_correct 1330.7 | ppl 6.32 | accuracy 32.152 | wps 12076 | ups 0.98 | wpb 12356.2 | bsz 458.7 | num_updates 4414 | lr 0.000176572 | gnorm 2.044 | clip 0.3 | loss_scale 1 | train_wall 1343 | gb_free 16.2 | wall 3693
2023-08-14 14:40:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 14:40:48 | INFO | fairseq.trainer | begin training epoch 4
2023-08-14 14:40:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 14:42:14 | INFO | train_inner | epoch 004:     86 / 1474 loss=3.15, trans_loss=3.921, nll_loss=2.249, w2v_ctc_loss=1.739, task_loss=0.966, contrastive_loss=0.581, total=4096.88, n_correct=1724.43, ppl=4.75, accuracy=42.091, wps=7516.2, ups=0.61, wpb=12226.6, bsz=438.5, num_updates=4500, lr=0.00018001, gnorm=1.604, clip=0, loss_scale=1, train_wall=91, gb_free=13.8, wall=3779
2023-08-14 14:43:46 | INFO | train_inner | epoch 004:    186 / 1474 loss=3.096, trans_loss=3.885, nll_loss=2.203, w2v_ctc_loss=1.705, task_loss=0.883, contrastive_loss=0.587, total=4177.87, n_correct=1815.06, ppl=4.61, accuracy=43.445, wps=13595, ups=1.09, wpb=12473.8, bsz=469, num_updates=4600, lr=0.000184008, gnorm=1.414, clip=0, loss_scale=1, train_wall=91, gb_free=15.2, wall=3871
2023-08-14 14:45:19 | INFO | train_inner | epoch 004:    286 / 1474 loss=3.098, trans_loss=3.877, nll_loss=2.194, w2v_ctc_loss=1.709, task_loss=0.927, contrastive_loss=0.693, total=4147.79, n_correct=1812.98, ppl=4.58, accuracy=43.71, wps=13331.6, ups=1.08, wpb=12391.1, bsz=464.6, num_updates=4700, lr=0.000188006, gnorm=1.494, clip=0, loss_scale=1, train_wall=92, gb_free=15.8, wall=3964
2023-08-14 14:46:52 | INFO | train_inner | epoch 004:    386 / 1474 loss=3.009, trans_loss=3.86, nll_loss=2.169, w2v_ctc_loss=1.68, task_loss=0.97, contrastive_loss=0.507, total=4120.11, n_correct=1835.8, ppl=4.5, accuracy=44.557, wps=13219.5, ups=1.08, wpb=12293.6, bsz=440.8, num_updates=4800, lr=0.000192004, gnorm=1.347, clip=0, loss_scale=1, train_wall=92, gb_free=17.2, wall=4057
2023-08-14 14:48:24 | INFO | train_inner | epoch 004:    486 / 1474 loss=3.041, trans_loss=3.829, nll_loss=2.13, w2v_ctc_loss=1.639, task_loss=0.834, contrastive_loss=0.887, total=4223.31, n_correct=1936.53, ppl=4.38, accuracy=45.853, wps=13584.7, ups=1.08, wpb=12605.5, bsz=500.9, num_updates=4900, lr=0.000196002, gnorm=1.354, clip=0, loss_scale=1, train_wall=92, gb_free=15.8, wall=4150
2023-08-14 14:49:57 | INFO | train_inner | epoch 004:    586 / 1474 loss=2.956, trans_loss=3.809, nll_loss=2.106, w2v_ctc_loss=1.647, task_loss=0.863, contrastive_loss=0.566, total=4228.66, n_correct=1976.86, ppl=4.3, accuracy=46.749, wps=13612.4, ups=1.08, wpb=12623.9, bsz=488.4, num_updates=5000, lr=0.0002, gnorm=1.262, clip=0, loss_scale=1, train_wall=92, gb_free=15.2, wall=4242
mt_weight tensor(0.5000)
asr_weight tensor(0.5864, device='cuda:0')
2023-08-14 14:51:31 | INFO | train_inner | epoch 004:    686 / 1474 loss=2.925, trans_loss=3.806, nll_loss=2.096, w2v_ctc_loss=1.634, task_loss=0.968, contrastive_loss=0.591, total=4172.53, n_correct=1967.35, ppl=4.28, accuracy=47.15, wps=13185.9, ups=1.06, wpb=12437.1, bsz=453.2, num_updates=5100, lr=0.00019803, gnorm=1.043, clip=0, loss_scale=1, train_wall=94, gb_free=16.9, wall=4337
2023-08-14 14:53:04 | INFO | train_inner | epoch 004:    786 / 1474 loss=2.873, trans_loss=3.784, nll_loss=2.073, w2v_ctc_loss=1.639, task_loss=1.027, contrastive_loss=0.445, total=4019.56, n_correct=1920.56, ppl=4.21, accuracy=47.78, wps=12948.3, ups=1.08, wpb=12004.8, bsz=419.9, num_updates=5200, lr=0.000196116, gnorm=0.957, clip=0, loss_scale=1, train_wall=92, gb_free=14.6, wall=4429
2023-08-14 14:54:37 | INFO | train_inner | epoch 004:    886 / 1474 loss=2.892, trans_loss=3.764, nll_loss=2.048, w2v_ctc_loss=1.624, task_loss=0.934, contrastive_loss=0.616, total=4183.92, n_correct=2026.05, ppl=4.14, accuracy=48.425, wps=13473.2, ups=1.08, wpb=12492.9, bsz=465.6, num_updates=5300, lr=0.000194257, gnorm=0.948, clip=0, loss_scale=2, train_wall=92, gb_free=17.4, wall=4522
2023-08-14 14:56:10 | INFO | train_inner | epoch 004:    986 / 1474 loss=2.83, trans_loss=3.746, nll_loss=2.025, w2v_ctc_loss=1.604, task_loss=0.946, contrastive_loss=0.481, total=4126.25, n_correct=2030.84, ppl=4.07, accuracy=49.218, wps=13296.7, ups=1.08, wpb=12324.7, bsz=455.9, num_updates=5400, lr=0.00019245, gnorm=0.951, clip=0, loss_scale=2, train_wall=92, gb_free=14.3, wall=4615
2023-08-14 14:57:42 | INFO | train_inner | epoch 004:   1086 / 1474 loss=2.849, trans_loss=3.753, nll_loss=2.033, w2v_ctc_loss=1.632, task_loss=0.986, contrastive_loss=0.467, total=4084.57, n_correct=2005.15, ppl=4.09, accuracy=49.091, wps=13154.9, ups=1.08, wpb=12192, bsz=441.2, num_updates=5500, lr=0.000190693, gnorm=1.098, clip=0, loss_scale=2, train_wall=92, gb_free=16.3, wall=4708
2023-08-14 14:59:15 | INFO | train_inner | epoch 004:   1186 / 1474 loss=2.825, trans_loss=3.732, nll_loss=2.009, w2v_ctc_loss=1.597, task_loss=0.874, contrastive_loss=0.555, total=4162.44, n_correct=2079.32, ppl=4.02, accuracy=49.954, wps=13462.3, ups=1.08, wpb=12433, bsz=482.7, num_updates=5600, lr=0.000188982, gnorm=0.926, clip=0, loss_scale=2, train_wall=92, gb_free=16.6, wall=4800
2023-08-14 15:00:47 | INFO | train_inner | epoch 004:   1286 / 1474 loss=2.783, trans_loss=3.715, nll_loss=1.986, w2v_ctc_loss=1.577, task_loss=0.894, contrastive_loss=0.508, total=4144.75, n_correct=2093.75, ppl=3.96, accuracy=50.516, wps=13422.9, ups=1.08, wpb=12378.7, bsz=470, num_updates=5700, lr=0.000187317, gnorm=0.9, clip=0, loss_scale=2, train_wall=92, gb_free=16.3, wall=4892
2023-08-14 15:02:18 | INFO | train_inner | epoch 004:   1386 / 1474 loss=2.716, trans_loss=3.7, nll_loss=1.966, w2v_ctc_loss=1.557, task_loss=0.954, contrastive_loss=0.374, total=4107.86, n_correct=2101.1, ppl=3.91, accuracy=51.148, wps=13435.1, ups=1.1, wpb=12268.5, bsz=439.2, num_updates=5800, lr=0.000185695, gnorm=0.782, clip=0, loss_scale=2, train_wall=91, gb_free=16.9, wall=4983
2023-08-14 15:03:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5864, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5864, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5864, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.5864, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5864, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.5864, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.5864, device='cuda:2')
2023-08-14 15:04:08 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.617 | trans_loss 5.797 | nll_loss 3.226 | w2v_ctc_loss 1.793 | task_loss 4.426 | contrastive_loss 0.546 | total 4003.4 | n_correct 2260.5 | ppl 9.36 | accuracy 56.465 | uer 26.539 | wer 27.732 | raw_wer 27.732 | bleu 14.49 | wps 1626.7 | wpb 4003.4 | bsz 141.8 | num_updates 5888 | best_bleu 14.49
2023-08-14 15:04:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5888 updates
2023-08-14 15:04:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 15:04:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 15:04:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 4 @ 5888 updates, score 14.49) (writing took 29.371741328388453 seconds)
2023-08-14 15:04:37 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-14 15:04:37 | INFO | train | epoch 004 | loss 2.916 | trans_loss 3.791 | nll_loss 2.083 | w2v_ctc_loss 1.634 | task_loss 0.93 | contrastive_loss 0.555 | total 4138.65 | n_correct 1962.35 | ppl 4.24 | accuracy 47.415 | wps 12737.8 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 5888 | lr 0.000184302 | gnorm 1.116 | clip 0 | loss_scale 2 | train_wall 1356 | gb_free 14.5 | wall 5123
2023-08-14 15:04:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 15:04:38 | INFO | fairseq.trainer | begin training epoch 5
2023-08-14 15:04:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 15:04:56 | INFO | train_inner | epoch 005:     12 / 1474 loss=2.685, trans_loss=3.692, nll_loss=1.954, w2v_ctc_loss=1.525, task_loss=0.973, contrastive_loss=0.381, total=4036.09, n_correct=2078.49, ppl=3.88, accuracy=51.498, wps=7624.9, ups=0.63, wpb=12049.9, bsz=436.9, num_updates=5900, lr=0.000184115, gnorm=0.778, clip=0, loss_scale=2, train_wall=91, gb_free=11.3, wall=5142
2023-08-14 15:06:29 | INFO | train_inner | epoch 005:    112 / 1474 loss=2.626, trans_loss=3.651, nll_loss=1.903, w2v_ctc_loss=1.455, task_loss=0.831, contrastive_loss=0.406, total=4256.69, n_correct=2256.94, ppl=3.74, accuracy=53.021, wps=13695.5, ups=1.08, wpb=12710.6, bsz=500.9, num_updates=6000, lr=0.000182574, gnorm=0.728, clip=0, loss_scale=2, train_wall=92, gb_free=17.1, wall=5234
2023-08-14 15:06:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 15:06:57 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.575 | trans_loss 5.772 | nll_loss 3.187 | w2v_ctc_loss 1.724 | task_loss 4.425 | contrastive_loss 0.532 | total 4003.4 | n_correct 2298.1 | ppl 9.11 | accuracy 57.404 | uer 25.989 | wer 27.475 | raw_wer 27.475 | bleu 15.23 | wps 1642.1 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 15.23
2023-08-14 15:06:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-14 15:06:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-14 15:07:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-14 15:07:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 15.23) (writing took 48.81137467175722 seconds)
2023-08-14 15:09:18 | INFO | train_inner | epoch 005:    212 / 1474 loss=2.654, trans_loss=3.655, nll_loss=1.906, w2v_ctc_loss=1.467, task_loss=0.867, contrastive_loss=0.587, total=4186.1, n_correct=2218.84, ppl=3.75, accuracy=53.005, wps=7408.5, ups=0.59, wpb=12490.5, bsz=484.8, num_updates=6100, lr=0.000181071, gnorm=0.767, clip=0, loss_scale=2, train_wall=91, gb_free=14.4, wall=5403
2023-08-14 15:10:49 | INFO | train_inner | epoch 005:    312 / 1474 loss=2.629, trans_loss=3.641, nll_loss=1.893, w2v_ctc_loss=1.481, task_loss=0.951, contrastive_loss=0.446, total=4098.24, n_correct=2171.31, ppl=3.71, accuracy=52.982, wps=13360.1, ups=1.09, wpb=12253.4, bsz=447.9, num_updates=6200, lr=0.000179605, gnorm=0.766, clip=0, loss_scale=2, train_wall=91, gb_free=16, wall=5495
2023-08-14 15:12:23 | INFO | train_inner | epoch 005:    412 / 1474 loss=2.612, trans_loss=3.631, nll_loss=1.879, w2v_ctc_loss=1.443, task_loss=0.922, contrastive_loss=0.516, total=4138.6, n_correct=2217.86, ppl=3.68, accuracy=53.59, wps=13191.8, ups=1.07, wpb=12367.6, bsz=466.6, num_updates=6300, lr=0.000178174, gnorm=0.746, clip=0, loss_scale=2, train_wall=93, gb_free=12.6, wall=5588
2023-08-14 15:13:55 | INFO | train_inner | epoch 005:    512 / 1474 loss=2.55, trans_loss=3.63, nll_loss=1.876, w2v_ctc_loss=1.444, task_loss=1.043, contrastive_loss=0.302, total=4018.65, n_correct=2158.78, ppl=3.67, accuracy=53.719, wps=13027.2, ups=1.09, wpb=12005.2, bsz=417.4, num_updates=6400, lr=0.000176777, gnorm=0.696, clip=0, loss_scale=2, train_wall=92, gb_free=16.4, wall=5681
2023-08-14 15:15:28 | INFO | train_inner | epoch 005:    612 / 1474 loss=2.574, trans_loss=3.632, nll_loss=1.876, w2v_ctc_loss=1.43, task_loss=0.959, contrastive_loss=0.467, total=4121.58, n_correct=2221.33, ppl=3.67, accuracy=53.895, wps=13297.3, ups=1.08, wpb=12295, bsz=451, num_updates=6500, lr=0.000175412, gnorm=0.711, clip=0, loss_scale=2, train_wall=92, gb_free=16.3, wall=5773
2023-08-14 15:17:00 | INFO | train_inner | epoch 005:    712 / 1474 loss=2.572, trans_loss=3.622, nll_loss=1.866, w2v_ctc_loss=1.425, task_loss=0.88, contrastive_loss=0.459, total=4169.57, n_correct=2266.99, ppl=3.64, accuracy=54.37, wps=13439.7, ups=1.08, wpb=12447.3, bsz=482.2, num_updates=6600, lr=0.000174078, gnorm=0.712, clip=0, loss_scale=2, train_wall=92, gb_free=16.8, wall=5866
2023-08-14 15:18:34 | INFO | train_inner | epoch 005:    812 / 1474 loss=2.531, trans_loss=3.612, nll_loss=1.851, w2v_ctc_loss=1.418, task_loss=0.961, contrastive_loss=0.368, total=4123.32, n_correct=2252.53, ppl=3.61, accuracy=54.629, wps=13143.6, ups=1.07, wpb=12307, bsz=448.5, num_updates=6700, lr=0.000172774, gnorm=0.665, clip=0, loss_scale=2, train_wall=93, gb_free=17.4, wall=5959
2023-08-14 15:20:06 | INFO | train_inner | epoch 005:    912 / 1474 loss=2.5, trans_loss=3.601, nll_loss=1.839, w2v_ctc_loss=1.403, task_loss=0.958, contrastive_loss=0.329, total=4109.54, n_correct=2261.04, ppl=3.58, accuracy=55.019, wps=13304.8, ups=1.08, wpb=12270.4, bsz=449.3, num_updates=6800, lr=0.000171499, gnorm=0.693, clip=0, loss_scale=2, train_wall=92, gb_free=16.1, wall=6052
2023-08-14 15:21:38 | INFO | train_inner | epoch 005:   1012 / 1474 loss=2.504, trans_loss=3.604, nll_loss=1.843, w2v_ctc_loss=1.4, task_loss=0.934, contrastive_loss=0.394, total=4157.73, n_correct=2289.84, ppl=3.59, accuracy=55.074, wps=13516.6, ups=1.09, wpb=12411.9, bsz=458.8, num_updates=6900, lr=0.000170251, gnorm=0.655, clip=0, loss_scale=2, train_wall=91, gb_free=17.1, wall=6143
2023-08-14 15:23:11 | INFO | train_inner | epoch 005:   1112 / 1474 loss=2.52, trans_loss=3.598, nll_loss=1.833, w2v_ctc_loss=1.408, task_loss=0.925, contrastive_loss=0.406, total=4172.61, n_correct=2310.68, ppl=3.56, accuracy=55.377, wps=13356.7, ups=1.07, wpb=12446.4, bsz=466.7, num_updates=7000, lr=0.000169031, gnorm=0.705, clip=0, loss_scale=2, train_wall=93, gb_free=13.2, wall=6237
2023-08-14 15:24:44 | INFO | train_inner | epoch 005:   1212 / 1474 loss=2.465, trans_loss=3.591, nll_loss=1.824, w2v_ctc_loss=1.379, task_loss=0.948, contrastive_loss=0.302, total=4166.97, n_correct=2318.71, ppl=3.54, accuracy=55.645, wps=13367.7, ups=1.08, wpb=12430.2, bsz=454.5, num_updates=7100, lr=0.000167836, gnorm=0.655, clip=0, loss_scale=2, train_wall=92, gb_free=16.7, wall=6330
2023-08-14 15:26:17 | INFO | train_inner | epoch 005:   1312 / 1474 loss=2.436, trans_loss=3.584, nll_loss=1.817, w2v_ctc_loss=1.362, task_loss=0.948, contrastive_loss=0.264, total=4132.22, n_correct=2307.86, ppl=3.52, accuracy=55.85, wps=13294.1, ups=1.08, wpb=12332.7, bsz=445.1, num_updates=7200, lr=0.000166667, gnorm=0.635, clip=0, loss_scale=2, train_wall=92, gb_free=16.3, wall=6422
2023-08-14 15:27:50 | INFO | train_inner | epoch 005:   1412 / 1474 loss=2.447, trans_loss=3.581, nll_loss=1.815, w2v_ctc_loss=1.359, task_loss=0.946, contrastive_loss=0.328, total=4135.72, n_correct=2319.07, ppl=3.52, accuracy=56.074, wps=13353.4, ups=1.08, wpb=12352.5, bsz=457.5, num_updates=7300, lr=0.000165521, gnorm=0.641, clip=0, loss_scale=4, train_wall=92, gb_free=15.9, wall=6515
2023-08-14 15:28:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 15:29:12 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.348 | trans_loss 5.549 | nll_loss 2.92 | w2v_ctc_loss 1.545 | task_loss 4.465 | contrastive_loss 0.473 | total 4003.4 | n_correct 2420.9 | ppl 7.57 | accuracy 60.471 | uer 24.418 | wer 25.86 | raw_wer 25.86 | bleu 17.51 | wps 1864.6 | wpb 4003.4 | bsz 141.8 | num_updates 7362 | best_bleu 17.51
2023-08-14 15:29:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7362 updates
2023-08-14 15:29:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 15:29:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 15:29:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7362 updates, score 17.51) (writing took 29.35618762113154 seconds)
2023-08-14 15:29:42 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-14 15:29:42 | INFO | train | epoch 005 | loss 2.542 | trans_loss 3.615 | nll_loss 1.857 | w2v_ctc_loss 1.418 | task_loss 0.933 | contrastive_loss 0.398 | total 4138.65 | n_correct 2255.37 | ppl 3.62 | accuracy 54.495 | wps 12106 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 7362 | lr 0.000164823 | gnorm 0.697 | clip 0 | loss_scale 4 | train_wall 1356 | gb_free 16 | wall 6627
2023-08-14 15:29:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 15:29:42 | INFO | fairseq.trainer | begin training epoch 6
2023-08-14 15:29:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 15:30:26 | INFO | train_inner | epoch 006:     38 / 1474 loss=2.431, trans_loss=3.565, nll_loss=1.792, w2v_ctc_loss=1.353, task_loss=0.961, contrastive_loss=0.319, total=4115.39, n_correct=2319.02, ppl=3.46, accuracy=56.35, wps=7861.5, ups=0.64, wpb=12279.5, bsz=446.7, num_updates=7400, lr=0.000164399, gnorm=0.648, clip=0, loss_scale=4, train_wall=92, gb_free=16.6, wall=6671
2023-08-14 15:31:58 | INFO | train_inner | epoch 006:    138 / 1474 loss=2.397, trans_loss=3.54, nll_loss=1.762, w2v_ctc_loss=1.312, task_loss=0.927, contrastive_loss=0.365, total=4157.06, n_correct=2373.43, ppl=3.39, accuracy=57.094, wps=13447.4, ups=1.08, wpb=12417.1, bsz=457.8, num_updates=7500, lr=0.000163299, gnorm=0.713, clip=0, loss_scale=4, train_wall=92, gb_free=17.5, wall=6763
2023-08-14 15:33:30 | INFO | train_inner | epoch 006:    238 / 1474 loss=2.388, trans_loss=3.547, nll_loss=1.772, w2v_ctc_loss=1.332, task_loss=0.993, contrastive_loss=0.269, total=4115.6, n_correct=2341.01, ppl=3.41, accuracy=56.881, wps=13349.7, ups=1.09, wpb=12295.8, bsz=440.7, num_updates=7600, lr=0.000162221, gnorm=0.628, clip=0, loss_scale=4, train_wall=92, gb_free=16.6, wall=6855
2023-08-14 15:35:04 | INFO | train_inner | epoch 006:    338 / 1474 loss=2.413, trans_loss=3.534, nll_loss=1.753, w2v_ctc_loss=1.279, task_loss=0.886, contrastive_loss=0.568, total=4163.86, n_correct=2392.14, ppl=3.37, accuracy=57.45, wps=13239.7, ups=1.06, wpb=12432.8, bsz=484.8, num_updates=7700, lr=0.000161165, gnorm=0.633, clip=0, loss_scale=4, train_wall=93, gb_free=15.8, wall=6949
2023-08-14 15:36:36 | INFO | train_inner | epoch 006:    438 / 1474 loss=2.347, trans_loss=3.529, nll_loss=1.748, w2v_ctc_loss=1.29, task_loss=0.893, contrastive_loss=0.275, total=4156.74, n_correct=2400.97, ppl=3.36, accuracy=57.761, wps=13464.3, ups=1.08, wpb=12410.9, bsz=471.8, num_updates=7800, lr=0.000160128, gnorm=0.631, clip=0, loss_scale=4, train_wall=92, gb_free=15.1, wall=7042
2023-08-14 15:38:09 | INFO | train_inner | epoch 006:    538 / 1474 loss=2.349, trans_loss=3.532, nll_loss=1.751, w2v_ctc_loss=1.301, task_loss=0.94, contrastive_loss=0.261, total=4173.1, n_correct=2411.17, ppl=3.37, accuracy=57.779, wps=13376.6, ups=1.07, wpb=12456.1, bsz=456.3, num_updates=7900, lr=0.000159111, gnorm=0.619, clip=0, loss_scale=4, train_wall=93, gb_free=15.6, wall=7135
2023-08-14 15:39:41 | INFO | train_inner | epoch 006:    638 / 1474 loss=2.347, trans_loss=3.532, nll_loss=1.751, w2v_ctc_loss=1.281, task_loss=0.886, contrastive_loss=0.313, total=4147.23, n_correct=2395.73, ppl=3.37, accuracy=57.767, wps=13488, ups=1.09, wpb=12379.1, bsz=471.9, num_updates=8000, lr=0.000158114, gnorm=0.652, clip=0, loss_scale=4, train_wall=91, gb_free=12.2, wall=7226
2023-08-14 15:39:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 15:40:06 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.287 | trans_loss 5.478 | nll_loss 2.831 | w2v_ctc_loss 1.55 | task_loss 4.489 | contrastive_loss 0.435 | total 4003.4 | n_correct 2459.8 | ppl 7.11 | accuracy 61.443 | uer 23.51 | wer 25.219 | raw_wer 25.219 | bleu 18.06 | wps 2125.4 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 18.06
2023-08-14 15:40:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-14 15:40:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-14 15:40:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-14 15:40:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 18.06) (writing took 48.663764245808125 seconds)
2023-08-14 15:42:28 | INFO | train_inner | epoch 006:    738 / 1474 loss=2.34, trans_loss=3.53, nll_loss=1.749, w2v_ctc_loss=1.295, task_loss=0.957, contrastive_loss=0.263, total=4147.61, n_correct=2401.73, ppl=3.36, accuracy=57.906, wps=7439.8, ups=0.6, wpb=12383.5, bsz=453.2, num_updates=8100, lr=0.000157135, gnorm=0.607, clip=0, loss_scale=4, train_wall=92, gb_free=16, wall=7393
2023-08-14 15:44:00 | INFO | train_inner | epoch 006:    838 / 1474 loss=2.324, trans_loss=3.53, nll_loss=1.748, w2v_ctc_loss=1.283, task_loss=0.98, contrastive_loss=0.241, total=4114.7, n_correct=2382.87, ppl=3.36, accuracy=57.911, wps=13323, ups=1.08, wpb=12284.9, bsz=442.6, num_updates=8200, lr=0.000156174, gnorm=0.606, clip=0, loss_scale=4, train_wall=92, gb_free=17.6, wall=7485
2023-08-14 15:45:33 | INFO | train_inner | epoch 006:    938 / 1474 loss=2.355, trans_loss=3.534, nll_loss=1.753, w2v_ctc_loss=1.292, task_loss=0.988, contrastive_loss=0.341, total=4082.44, n_correct=2358.99, ppl=3.37, accuracy=57.784, wps=13022.9, ups=1.07, wpb=12184.1, bsz=442.4, num_updates=8300, lr=0.00015523, gnorm=0.62, clip=0, loss_scale=4, train_wall=93, gb_free=15.9, wall=7579
2023-08-14 15:47:06 | INFO | train_inner | epoch 006:   1038 / 1474 loss=2.347, trans_loss=3.518, nll_loss=1.733, w2v_ctc_loss=1.268, task_loss=0.882, contrastive_loss=0.415, total=4168.55, n_correct=2430.46, ppl=3.32, accuracy=58.305, wps=13493.8, ups=1.08, wpb=12442.3, bsz=478.7, num_updates=8400, lr=0.000154303, gnorm=0.676, clip=0, loss_scale=4, train_wall=92, gb_free=15.4, wall=7671
2023-08-14 15:48:38 | INFO | train_inner | epoch 006:   1138 / 1474 loss=2.314, trans_loss=3.518, nll_loss=1.734, w2v_ctc_loss=1.279, task_loss=1.026, contrastive_loss=0.244, total=4075.88, n_correct=2371.48, ppl=3.33, accuracy=58.183, wps=13207.8, ups=1.09, wpb=12168.6, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.612, clip=0, loss_scale=4, train_wall=92, gb_free=13.8, wall=7763
2023-08-14 15:50:11 | INFO | train_inner | epoch 006:   1238 / 1474 loss=2.364, trans_loss=3.507, nll_loss=1.722, w2v_ctc_loss=1.26, task_loss=0.92, contrastive_loss=0.554, total=4136.41, n_correct=2418.33, ppl=3.3, accuracy=58.464, wps=13249.3, ups=1.07, wpb=12356.2, bsz=470.5, num_updates=8600, lr=0.000152499, gnorm=0.623, clip=0, loss_scale=4, train_wall=93, gb_free=15, wall=7856
2023-08-14 15:51:43 | INFO | train_inner | epoch 006:   1338 / 1474 loss=2.285, trans_loss=3.511, nll_loss=1.723, w2v_ctc_loss=1.258, task_loss=0.929, contrastive_loss=0.224, total=4123.87, n_correct=2425.66, ppl=3.3, accuracy=58.82, wps=13318.9, ups=1.08, wpb=12299.9, bsz=453.6, num_updates=8700, lr=0.00015162, gnorm=0.595, clip=0, loss_scale=4, train_wall=92, gb_free=16, wall=7949
2023-08-14 15:53:16 | INFO | train_inner | epoch 006:   1438 / 1474 loss=2.284, trans_loss=3.505, nll_loss=1.717, w2v_ctc_loss=1.255, task_loss=0.931, contrastive_loss=0.23, total=4197.44, n_correct=2468.4, ppl=3.29, accuracy=58.807, wps=13483.7, ups=1.08, wpb=12530.9, bsz=462.9, num_updates=8800, lr=0.000150756, gnorm=0.591, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=8042
2023-08-14 15:53:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 15:54:12 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.235 | trans_loss 5.407 | nll_loss 2.747 | w2v_ctc_loss 1.566 | task_loss 4.533 | contrastive_loss 0.409 | total 4003.4 | n_correct 2494.9 | ppl 6.71 | accuracy 62.32 | uer 22.87 | wer 24.634 | raw_wer 24.634 | bleu 18.97 | wps 2246.6 | wpb 4003.4 | bsz 141.8 | num_updates 8836 | best_bleu 18.97
2023-08-14 15:54:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8836 updates
2023-08-14 15:54:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 15:54:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 15:54:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 6 @ 8836 updates, score 18.97) (writing took 28.98767562583089 seconds)
2023-08-14 15:54:41 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-14 15:54:41 | INFO | train | epoch 006 | loss 2.346 | trans_loss 3.526 | nll_loss 1.744 | w2v_ctc_loss 1.284 | task_loss 0.936 | contrastive_loss 0.325 | total 4138.65 | n_correct 2397.43 | ppl 3.35 | accuracy 57.928 | wps 12147 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 8836 | lr 0.000150448 | gnorm 0.629 | clip 0 | loss_scale 4 | train_wall 1357 | gb_free 14.8 | wall 8127
2023-08-14 15:54:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 15:54:41 | INFO | fairseq.trainer | begin training epoch 7
2023-08-14 15:54:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 15:55:49 | INFO | train_inner | epoch 007:     64 / 1474 loss=2.251, trans_loss=3.491, nll_loss=1.698, w2v_ctc_loss=1.223, task_loss=0.918, contrastive_loss=0.241, total=4105.94, n_correct=2437.07, ppl=3.25, accuracy=59.355, wps=8029.3, ups=0.66, wpb=12258, bsz=460.8, num_updates=8900, lr=0.000149906, gnorm=0.592, clip=0, loss_scale=4, train_wall=92, gb_free=14.7, wall=8194
2023-08-14 15:57:21 | INFO | train_inner | epoch 007:    164 / 1474 loss=2.253, trans_loss=3.482, nll_loss=1.688, w2v_ctc_loss=1.211, task_loss=0.956, contrastive_loss=0.312, total=4101.13, n_correct=2439.62, ppl=3.22, accuracy=59.487, wps=13297.8, ups=1.09, wpb=12245.3, bsz=452.9, num_updates=9000, lr=0.000149071, gnorm=0.59, clip=0, loss_scale=4, train_wall=92, gb_free=16.6, wall=8286
2023-08-14 15:58:54 | INFO | train_inner | epoch 007:    264 / 1474 loss=2.229, trans_loss=3.475, nll_loss=1.677, w2v_ctc_loss=1.211, task_loss=0.93, contrastive_loss=0.219, total=4143.65, n_correct=2475.93, ppl=3.2, accuracy=59.752, wps=13345.4, ups=1.08, wpb=12365.3, bsz=458, num_updates=9100, lr=0.00014825, gnorm=0.588, clip=0, loss_scale=4, train_wall=92, gb_free=15.8, wall=8379
2023-08-14 16:00:27 | INFO | train_inner | epoch 007:    364 / 1474 loss=2.279, trans_loss=3.481, nll_loss=1.686, w2v_ctc_loss=1.203, task_loss=0.905, contrastive_loss=0.484, total=4190.59, n_correct=2493.83, ppl=3.22, accuracy=59.51, wps=13428.9, ups=1.07, wpb=12506.9, bsz=477.2, num_updates=9200, lr=0.000147442, gnorm=0.592, clip=0, loss_scale=4, train_wall=93, gb_free=16.4, wall=8472
2023-08-14 16:01:59 | INFO | train_inner | epoch 007:    464 / 1474 loss=2.262, trans_loss=3.481, nll_loss=1.687, w2v_ctc_loss=1.202, task_loss=0.928, contrastive_loss=0.399, total=4154.13, n_correct=2473.59, ppl=3.22, accuracy=59.545, wps=13422.6, ups=1.08, wpb=12405.4, bsz=461.6, num_updates=9300, lr=0.000146647, gnorm=0.617, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=8565
2023-08-14 16:03:32 | INFO | train_inner | epoch 007:    564 / 1474 loss=2.219, trans_loss=3.476, nll_loss=1.678, w2v_ctc_loss=1.199, task_loss=0.912, contrastive_loss=0.224, total=4171.52, n_correct=2499.36, ppl=3.2, accuracy=59.915, wps=13487.6, ups=1.08, wpb=12446, bsz=461, num_updates=9400, lr=0.000145865, gnorm=0.574, clip=0, loss_scale=8, train_wall=92, gb_free=16.7, wall=8657
2023-08-14 16:05:05 | INFO | train_inner | epoch 007:    664 / 1474 loss=2.208, trans_loss=3.471, nll_loss=1.672, w2v_ctc_loss=1.194, task_loss=0.935, contrastive_loss=0.209, total=4151.13, n_correct=2496.91, ppl=3.19, accuracy=60.15, wps=13271.4, ups=1.07, wpb=12385.9, bsz=454, num_updates=9500, lr=0.000145095, gnorm=0.581, clip=0, loss_scale=8, train_wall=93, gb_free=12.3, wall=8750
2023-08-14 16:06:38 | INFO | train_inner | epoch 007:    764 / 1474 loss=2.203, trans_loss=3.464, nll_loss=1.665, w2v_ctc_loss=1.193, task_loss=0.976, contrastive_loss=0.202, total=4124.23, n_correct=2478.74, ppl=3.17, accuracy=60.102, wps=13273, ups=1.08, wpb=12314.5, bsz=446.8, num_updates=9600, lr=0.000144338, gnorm=0.579, clip=0, loss_scale=8, train_wall=92, gb_free=13.8, wall=8843
2023-08-14 16:08:11 | INFO | train_inner | epoch 007:    864 / 1474 loss=2.209, trans_loss=3.473, nll_loss=1.675, w2v_ctc_loss=1.194, task_loss=0.938, contrastive_loss=0.223, total=4148.43, n_correct=2489.11, ppl=3.19, accuracy=60.001, wps=13271.4, ups=1.07, wpb=12380.2, bsz=461.8, num_updates=9700, lr=0.000143592, gnorm=0.58, clip=0, loss_scale=8, train_wall=93, gb_free=16.1, wall=8936
2023-08-14 16:09:45 | INFO | train_inner | epoch 007:    964 / 1474 loss=2.218, trans_loss=3.464, nll_loss=1.666, w2v_ctc_loss=1.179, task_loss=0.895, contrastive_loss=0.317, total=4141.1, n_correct=2492.1, ppl=3.17, accuracy=60.18, wps=13183.8, ups=1.07, wpb=12362.4, bsz=473.7, num_updates=9800, lr=0.000142857, gnorm=0.597, clip=0, loss_scale=8, train_wall=93, gb_free=13.4, wall=9030
2023-08-14 16:11:18 | INFO | train_inner | epoch 007:   1064 / 1474 loss=2.2, trans_loss=3.473, nll_loss=1.677, w2v_ctc_loss=1.196, task_loss=0.979, contrastive_loss=0.188, total=4100.93, n_correct=2462.18, ppl=3.2, accuracy=60.04, wps=13160.8, ups=1.07, wpb=12243.4, bsz=437.6, num_updates=9900, lr=0.000142134, gnorm=0.615, clip=0, loss_scale=8, train_wall=92, gb_free=14.4, wall=9123
2023-08-14 16:12:51 | INFO | train_inner | epoch 007:   1164 / 1474 loss=2.243, trans_loss=3.457, nll_loss=1.658, w2v_ctc_loss=1.178, task_loss=0.91, contrastive_loss=0.442, total=4139.88, n_correct=2500.74, ppl=3.16, accuracy=60.406, wps=13245.6, ups=1.07, wpb=12369.6, bsz=471.4, num_updates=10000, lr=0.000141421, gnorm=0.589, clip=0, loss_scale=8, train_wall=93, gb_free=16.3, wall=9216
2023-08-14 16:12:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 16:13:17 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.131 | trans_loss 5.341 | nll_loss 2.663 | w2v_ctc_loss 1.406 | task_loss 4.588 | contrastive_loss 0.373 | total 4003.4 | n_correct 2541.7 | ppl 6.33 | accuracy 63.489 | uer 21.411 | wer 23.463 | raw_wer 23.463 | bleu 19.48 | wps 1852.2 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 19.48
2023-08-14 16:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-14 16:13:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-14 16:13:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-14 16:13:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 19.48) (writing took 30.036685654893517 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:0')
2023-08-14 16:15:19 | INFO | train_inner | epoch 007:   1264 / 1474 loss=2.184, trans_loss=3.46, nll_loss=1.661, w2v_ctc_loss=1.174, task_loss=0.954, contrastive_loss=0.213, total=4129.16, n_correct=2491.83, ppl=3.16, accuracy=60.347, wps=8316.2, ups=0.67, wpb=12331, bsz=448.9, num_updates=10100, lr=0.00014072, gnorm=0.423, clip=0, loss_scale=8, train_wall=92, gb_free=16.5, wall=9365
2023-08-14 16:16:52 | INFO | train_inner | epoch 007:   1364 / 1474 loss=2.202, trans_loss=3.454, nll_loss=1.653, w2v_ctc_loss=1.186, task_loss=0.875, contrastive_loss=0.25, total=4177.71, n_correct=2531.84, ppl=3.15, accuracy=60.604, wps=13487.3, ups=1.08, wpb=12473.7, bsz=478.6, num_updates=10200, lr=0.000140028, gnorm=0.424, clip=0, loss_scale=8, train_wall=92, gb_free=16.4, wall=9457
2023-08-14 16:18:27 | INFO | train_inner | epoch 007:   1464 / 1474 loss=2.212, trans_loss=3.459, nll_loss=1.661, w2v_ctc_loss=1.184, task_loss=1.009, contrastive_loss=0.314, total=4107.01, n_correct=2476.04, ppl=3.16, accuracy=60.288, wps=12971.9, ups=1.06, wpb=12270.2, bsz=442.8, num_updates=10300, lr=0.000139347, gnorm=0.44, clip=0, loss_scale=8, train_wall=94, gb_free=12.8, wall=9552
2023-08-14 16:18:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:5')
2023-08-14 16:19:00 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.139 | trans_loss 5.328 | nll_loss 2.643 | w2v_ctc_loss 1.463 | task_loss 4.576 | contrastive_loss 0.372 | total 4003.4 | n_correct 2553.1 | ppl 6.25 | accuracy 63.773 | uer 21.703 | wer 23.623 | raw_wer 23.623 | bleu 20.01 | wps 2089.6 | wpb 4003.4 | bsz 141.8 | num_updates 10310 | best_bleu 20.01
2023-08-14 16:19:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10310 updates
2023-08-14 16:19:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 16:19:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 16:19:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 7 @ 10310 updates, score 20.01) (writing took 33.324391800910234 seconds)
2023-08-14 16:19:33 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-14 16:19:33 | INFO | train | epoch 007 | loss 2.223 | trans_loss 3.47 | nll_loss 1.672 | w2v_ctc_loss 1.194 | task_loss 0.936 | contrastive_loss 0.284 | total 4138.65 | n_correct 2483.42 | ppl 3.19 | accuracy 60.006 | wps 12209.4 | ups 0.99 | wpb 12355.8 | bsz 458.5 | num_updates 10310 | lr 0.000139279 | gnorm 0.557 | clip 0 | loss_scale 8 | train_wall 1362 | gb_free 12.8 | wall 9618
2023-08-14 16:19:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 16:19:33 | INFO | fairseq.trainer | begin training epoch 8
2023-08-14 16:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 16:21:04 | INFO | train_inner | epoch 008:     90 / 1474 loss=2.153, trans_loss=3.447, nll_loss=1.64, w2v_ctc_loss=1.148, task_loss=0.996, contrastive_loss=0.204, total=4106.01, n_correct=2503.43, ppl=3.12, accuracy=60.97, wps=7753.8, ups=0.63, wpb=12242.2, bsz=440.9, num_updates=10400, lr=0.000138675, gnorm=0.416, clip=0, loss_scale=8, train_wall=92, gb_free=16.8, wall=9710
2023-08-14 16:22:37 | INFO | train_inner | epoch 008:    190 / 1474 loss=2.151, trans_loss=3.437, nll_loss=1.627, w2v_ctc_loss=1.143, task_loss=1.014, contrastive_loss=0.225, total=4043.12, n_correct=2474.09, ppl=3.09, accuracy=61.193, wps=13067.9, ups=1.08, wpb=12058.4, bsz=430, num_updates=10500, lr=0.000138013, gnorm=0.423, clip=0, loss_scale=8, train_wall=92, gb_free=12.8, wall=9802
2023-08-14 16:24:10 | INFO | train_inner | epoch 008:    290 / 1474 loss=2.149, trans_loss=3.432, nll_loss=1.623, w2v_ctc_loss=1.143, task_loss=0.879, contrastive_loss=0.219, total=4207.9, n_correct=2579.93, ppl=3.08, accuracy=61.312, wps=13484.2, ups=1.07, wpb=12558.3, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.417, clip=0, loss_scale=8, train_wall=93, gb_free=13.6, wall=9895
2023-08-14 16:25:44 | INFO | train_inner | epoch 008:    390 / 1474 loss=2.163, trans_loss=3.436, nll_loss=1.627, w2v_ctc_loss=1.157, task_loss=0.985, contrastive_loss=0.243, total=4134.6, n_correct=2528.31, ppl=3.09, accuracy=61.15, wps=13143.9, ups=1.07, wpb=12337.2, bsz=444.7, num_updates=10700, lr=0.000136717, gnorm=0.42, clip=0, loss_scale=8, train_wall=93, gb_free=17, wall=9989
2023-08-14 16:27:18 | INFO | train_inner | epoch 008:    490 / 1474 loss=2.215, trans_loss=3.433, nll_loss=1.626, w2v_ctc_loss=1.136, task_loss=0.846, contrastive_loss=0.507, total=4196.6, n_correct=2573.56, ppl=3.09, accuracy=61.325, wps=13344.5, ups=1.07, wpb=12528.1, bsz=501.4, num_updates=10800, lr=0.000136083, gnorm=0.446, clip=0, loss_scale=8, train_wall=93, gb_free=12.4, wall=10083
2023-08-14 16:28:51 | INFO | train_inner | epoch 008:    590 / 1474 loss=2.146, trans_loss=3.43, nll_loss=1.624, w2v_ctc_loss=1.156, task_loss=1.018, contrastive_loss=0.177, total=4065.55, n_correct=2488.23, ppl=3.08, accuracy=61.203, wps=13041.7, ups=1.07, wpb=12153.4, bsz=428.3, num_updates=10900, lr=0.000135457, gnorm=0.413, clip=0, loss_scale=8, train_wall=93, gb_free=15.8, wall=10176
2023-08-14 16:30:24 | INFO | train_inner | epoch 008:    690 / 1474 loss=2.138, trans_loss=3.426, nll_loss=1.617, w2v_ctc_loss=1.149, task_loss=0.969, contrastive_loss=0.187, total=4135.41, n_correct=2544.37, ppl=3.07, accuracy=61.526, wps=13217.6, ups=1.07, wpb=12343.8, bsz=447.2, num_updates=11000, lr=0.00013484, gnorm=0.412, clip=0, loss_scale=8, train_wall=93, gb_free=15.6, wall=10270
2023-08-14 16:31:57 | INFO | train_inner | epoch 008:    790 / 1474 loss=2.148, trans_loss=3.421, nll_loss=1.614, w2v_ctc_loss=1.14, task_loss=0.947, contrastive_loss=0.272, total=4128.86, n_correct=2541.6, ppl=3.06, accuracy=61.557, wps=13356, ups=1.08, wpb=12339, bsz=452.1, num_updates=11100, lr=0.000134231, gnorm=0.462, clip=0, loss_scale=8, train_wall=92, gb_free=16, wall=10362
2023-08-14 16:33:29 | INFO | train_inner | epoch 008:    890 / 1474 loss=2.145, trans_loss=3.425, nll_loss=1.617, w2v_ctc_loss=1.128, task_loss=0.904, contrastive_loss=0.279, total=4166.92, n_correct=2564.5, ppl=3.07, accuracy=61.544, wps=13477.8, ups=1.08, wpb=12446.8, bsz=471.5, num_updates=11200, lr=0.000133631, gnorm=0.417, clip=0, loss_scale=8, train_wall=92, gb_free=14.1, wall=10454
2023-08-14 16:35:01 | INFO | train_inner | epoch 008:    990 / 1474 loss=2.117, trans_loss=3.424, nll_loss=1.614, w2v_ctc_loss=1.129, task_loss=0.902, contrastive_loss=0.179, total=4150.39, n_correct=2566.42, ppl=3.06, accuracy=61.836, wps=13396.8, ups=1.08, wpb=12390.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.411, clip=0, loss_scale=8, train_wall=92, gb_free=17, wall=10547
2023-08-14 16:36:35 | INFO | train_inner | epoch 008:   1090 / 1474 loss=2.168, trans_loss=3.428, nll_loss=1.619, w2v_ctc_loss=1.132, task_loss=0.926, contrastive_loss=0.405, total=4197.39, n_correct=2578.57, ppl=3.07, accuracy=61.433, wps=13344.2, ups=1.07, wpb=12529.5, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.428, clip=0, loss_scale=16, train_wall=93, gb_free=16.5, wall=10641
2023-08-14 16:38:08 | INFO | train_inner | epoch 008:   1190 / 1474 loss=2.124, trans_loss=3.419, nll_loss=1.609, w2v_ctc_loss=1.134, task_loss=0.888, contrastive_loss=0.189, total=4180.55, n_correct=2579.98, ppl=3.05, accuracy=61.714, wps=13514.8, ups=1.08, wpb=12487.2, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.413, clip=0, loss_scale=16, train_wall=92, gb_free=17, wall=10733
2023-08-14 16:39:39 | INFO | train_inner | epoch 008:   1290 / 1474 loss=2.134, trans_loss=3.424, nll_loss=1.615, w2v_ctc_loss=1.143, task_loss=0.98, contrastive_loss=0.212, total=4062.6, n_correct=2498.57, ppl=3.06, accuracy=61.502, wps=13283.9, ups=1.09, wpb=12135.3, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.42, clip=0, loss_scale=16, train_wall=91, gb_free=12.6, wall=10824
2023-08-14 16:41:11 | INFO | train_inner | epoch 008:   1390 / 1474 loss=2.142, trans_loss=3.423, nll_loss=1.615, w2v_ctc_loss=1.129, task_loss=0.91, contrastive_loss=0.277, total=4159.11, n_correct=2569.87, ppl=3.06, accuracy=61.789, wps=13541.3, ups=1.09, wpb=12419, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.415, clip=0, loss_scale=16, train_wall=91, gb_free=13, wall=10916
2023-08-14 16:42:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 16:42:53 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.078 | trans_loss 5.268 | nll_loss 2.567 | w2v_ctc_loss 1.419 | task_loss 4.617 | contrastive_loss 0.35 | total 4003.4 | n_correct 2584.1 | ppl 5.92 | accuracy 64.548 | uer 20.848 | wer 22.904 | raw_wer 22.904 | bleu 20.37 | wps 1991.5 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 20.37
2023-08-14 16:42:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-08-14 16:42:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 16:43:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 16:43:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 11784 updates, score 20.37) (writing took 30.103289544582367 seconds)
2023-08-14 16:43:24 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-14 16:43:24 | INFO | train | epoch 008 | loss 2.149 | trans_loss 3.429 | nll_loss 1.62 | w2v_ctc_loss 1.139 | task_loss 0.937 | contrastive_loss 0.261 | total 4138.65 | n_correct 2543.36 | ppl 3.07 | accuracy 61.454 | wps 12728.9 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 11784 | lr 0.000130277 | gnorm 0.422 | clip 0 | loss_scale 16 | train_wall 1360 | gb_free 16.6 | wall 11049
2023-08-14 16:43:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 16:43:24 | INFO | fairseq.trainer | begin training epoch 9
2023-08-14 16:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 16:43:47 | INFO | train_inner | epoch 009:     16 / 1474 loss=2.142, trans_loss=3.419, nll_loss=1.607, w2v_ctc_loss=1.116, task_loss=0.917, contrastive_loss=0.373, total=4121.25, n_correct=2550.06, ppl=3.05, accuracy=61.876, wps=7874.9, ups=0.64, wpb=12298.5, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.413, clip=0, loss_scale=16, train_wall=93, gb_free=17.5, wall=11072
2023-08-14 16:45:19 | INFO | train_inner | epoch 009:    116 / 1474 loss=2.085, trans_loss=3.393, nll_loss=1.575, w2v_ctc_loss=1.093, task_loss=0.881, contrastive_loss=0.206, total=4191.82, n_correct=2627.98, ppl=2.98, accuracy=62.693, wps=13599.1, ups=1.09, wpb=12518.2, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.418, clip=0, loss_scale=16, train_wall=92, gb_free=15.6, wall=11164
2023-08-14 16:46:51 | INFO | train_inner | epoch 009:    216 / 1474 loss=2.076, trans_loss=3.398, nll_loss=1.581, w2v_ctc_loss=1.095, task_loss=1.009, contrastive_loss=0.162, total=4061.27, n_correct=2536.16, ppl=2.99, accuracy=62.447, wps=13122.1, ups=1.08, wpb=12126.5, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.423, clip=0, loss_scale=16, train_wall=92, gb_free=17.3, wall=11257
2023-08-14 16:46:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 16:47:16 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.088 | trans_loss 5.28 | nll_loss 2.581 | w2v_ctc_loss 1.425 | task_loss 4.587 | contrastive_loss 0.355 | total 4003.4 | n_correct 2583.2 | ppl 5.98 | accuracy 64.525 | uer 20.866 | wer 22.937 | raw_wer 22.937 | bleu 20.5 | wps 2025.9 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 20.5
2023-08-14 16:47:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-14 16:47:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-14 16:47:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-14 16:48:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 20.5) (writing took 51.26893131248653 seconds)
2023-08-14 16:49:40 | INFO | train_inner | epoch 009:    316 / 1474 loss=2.073, trans_loss=3.386, nll_loss=1.567, w2v_ctc_loss=1.08, task_loss=0.886, contrastive_loss=0.212, total=4146.43, n_correct=2603.13, ppl=2.96, accuracy=62.78, wps=7331.2, ups=0.59, wpb=12389.9, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.418, clip=0, loss_scale=16, train_wall=91, gb_free=16, wall=11426
2023-08-14 16:51:14 | INFO | train_inner | epoch 009:    416 / 1474 loss=2.076, trans_loss=3.401, nll_loss=1.585, w2v_ctc_loss=1.089, task_loss=0.919, contrastive_loss=0.177, total=4194.84, n_correct=2618.92, ppl=3, accuracy=62.432, wps=13362.2, ups=1.07, wpb=12524.6, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.402, clip=0, loss_scale=16, train_wall=93, gb_free=15.8, wall=11520
2023-08-14 16:52:46 | INFO | train_inner | epoch 009:    516 / 1474 loss=2.102, trans_loss=3.401, nll_loss=1.584, w2v_ctc_loss=1.11, task_loss=0.982, contrastive_loss=0.229, total=4124.3, n_correct=2570.15, ppl=3, accuracy=62.317, wps=13369.6, ups=1.09, wpb=12310.3, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.413, clip=0, loss_scale=16, train_wall=92, gb_free=11.1, wall=11612
2023-08-14 16:54:19 | INFO | train_inner | epoch 009:    616 / 1474 loss=2.068, trans_loss=3.392, nll_loss=1.576, w2v_ctc_loss=1.086, task_loss=0.96, contrastive_loss=0.187, total=4120.96, n_correct=2581.77, ppl=2.98, accuracy=62.65, wps=13306, ups=1.08, wpb=12316.4, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.415, clip=0, loss_scale=16, train_wall=92, gb_free=15.9, wall=11704
2023-08-14 16:55:51 | INFO | train_inner | epoch 009:    716 / 1474 loss=2.103, trans_loss=3.4, nll_loss=1.585, w2v_ctc_loss=1.107, task_loss=0.955, contrastive_loss=0.267, total=4088.53, n_correct=2549.47, ppl=3, accuracy=62.357, wps=13221.7, ups=1.08, wpb=12213.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.409, clip=0, loss_scale=16, train_wall=92, gb_free=16.7, wall=11797
2023-08-14 16:57:25 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.14, trans_loss=3.394, nll_loss=1.579, w2v_ctc_loss=1.097, task_loss=0.848, contrastive_loss=0.413, total=4220.43, n_correct=2637.77, ppl=2.99, accuracy=62.5, wps=13419.6, ups=1.06, wpb=12611.1, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.426, clip=0, loss_scale=16, train_wall=93, gb_free=14, wall=11891
2023-08-14 16:58:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-14 16:59:00 | INFO | train_inner | epoch 009:    917 / 1474 loss=2.077, trans_loss=3.399, nll_loss=1.581, w2v_ctc_loss=1.105, task_loss=1.005, contrastive_loss=0.163, total=4126.01, n_correct=2576.76, ppl=2.99, accuracy=62.452, wps=12981.9, ups=1.05, wpb=12312.3, bsz=435.1, num_updates=12700, lr=0.000125491, gnorm=0.408, clip=0, loss_scale=8, train_wall=94, gb_free=11.4, wall=11985
2023-08-14 17:00:32 | INFO | train_inner | epoch 009:   1017 / 1474 loss=2.079, trans_loss=3.405, nll_loss=1.589, w2v_ctc_loss=1.1, task_loss=1.043, contrastive_loss=0.175, total=4101.32, n_correct=2557.86, ppl=3.01, accuracy=62.367, wps=13253.3, ups=1.08, wpb=12242.4, bsz=424.9, num_updates=12800, lr=0.000125, gnorm=0.411, clip=0, loss_scale=8, train_wall=92, gb_free=15.5, wall=12078
2023-08-14 17:02:05 | INFO | train_inner | epoch 009:   1117 / 1474 loss=2.076, trans_loss=3.402, nll_loss=1.583, w2v_ctc_loss=1.088, task_loss=0.887, contrastive_loss=0.193, total=4172.83, n_correct=2611.03, ppl=3, accuracy=62.572, wps=13467.5, ups=1.08, wpb=12437.9, bsz=471.9, num_updates=12900, lr=0.000124515, gnorm=0.406, clip=0, loss_scale=8, train_wall=92, gb_free=16, wall=12170
2023-08-14 17:03:39 | INFO | train_inner | epoch 009:   1217 / 1474 loss=2.084, trans_loss=3.399, nll_loss=1.583, w2v_ctc_loss=1.109, task_loss=0.987, contrastive_loss=0.179, total=4138.15, n_correct=2582.77, ppl=3, accuracy=62.414, wps=13130.5, ups=1.06, wpb=12357.2, bsz=448.8, num_updates=13000, lr=0.000124035, gnorm=0.415, clip=0, loss_scale=8, train_wall=94, gb_free=15.8, wall=12264
2023-08-14 17:05:12 | INFO | train_inner | epoch 009:   1317 / 1474 loss=2.107, trans_loss=3.393, nll_loss=1.574, w2v_ctc_loss=1.083, task_loss=0.858, contrastive_loss=0.367, total=4205.27, n_correct=2638.91, ppl=2.98, accuracy=62.752, wps=13512, ups=1.08, wpb=12548.1, bsz=491.2, num_updates=13100, lr=0.00012356, gnorm=0.405, clip=0, loss_scale=8, train_wall=92, gb_free=16.3, wall=12357
2023-08-14 17:06:43 | INFO | train_inner | epoch 009:   1417 / 1474 loss=2.07, trans_loss=3.405, nll_loss=1.588, w2v_ctc_loss=1.098, task_loss=1.006, contrastive_loss=0.154, total=4071.37, n_correct=2543.48, ppl=3.01, accuracy=62.472, wps=13256.4, ups=1.09, wpb=12147.5, bsz=429, num_updates=13200, lr=0.000123091, gnorm=0.407, clip=0, loss_scale=8, train_wall=91, gb_free=14.5, wall=12449
2023-08-14 17:07:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 17:07:58 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.022 | trans_loss 5.24 | nll_loss 2.534 | w2v_ctc_loss 1.318 | task_loss 4.585 | contrastive_loss 0.335 | total 4003.4 | n_correct 2597 | ppl 5.79 | accuracy 64.87 | uer 19.133 | wer 21.114 | raw_wer 21.114 | bleu 20.71 | wps 2189.2 | wpb 4003.4 | bsz 141.8 | num_updates 13257 | best_bleu 20.71
2023-08-14 17:07:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13257 updates
2023-08-14 17:07:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 17:08:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 17:08:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 9 @ 13257 updates, score 20.71) (writing took 28.94791211001575 seconds)
2023-08-14 17:08:28 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-14 17:08:28 | INFO | train | epoch 009 | loss 2.087 | trans_loss 3.397 | nll_loss 1.58 | w2v_ctc_loss 1.096 | task_loss 0.94 | contrastive_loss 0.227 | total 4136.88 | n_correct 2586.58 | ppl 2.99 | accuracy 62.525 | wps 12094.6 | ups 0.98 | wpb 12350.7 | bsz 457.4 | num_updates 13257 | lr 0.000122827 | gnorm 0.412 | clip 0 | loss_scale 8 | train_wall 1359 | gb_free 11.1 | wall 12553
2023-08-14 17:08:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 17:08:28 | INFO | fairseq.trainer | begin training epoch 10
2023-08-14 17:08:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 17:09:15 | INFO | train_inner | epoch 010:     43 / 1474 loss=2.067, trans_loss=3.386, nll_loss=1.566, w2v_ctc_loss=1.07, task_loss=0.877, contrastive_loss=0.25, total=4113.02, n_correct=2590.42, ppl=2.96, accuracy=62.981, wps=8090.1, ups=0.66, wpb=12276.4, bsz=475.9, num_updates=13300, lr=0.000122628, gnorm=0.405, clip=0, loss_scale=8, train_wall=91, gb_free=16, wall=12600
2023-08-14 17:10:48 | INFO | train_inner | epoch 010:    143 / 1474 loss=2.022, trans_loss=3.37, nll_loss=1.546, w2v_ctc_loss=1.044, task_loss=0.902, contrastive_loss=0.17, total=4234.99, n_correct=2687.01, ppl=2.92, accuracy=63.448, wps=13635.8, ups=1.08, wpb=12647.2, bsz=473.2, num_updates=13400, lr=0.000122169, gnorm=0.395, clip=0, loss_scale=8, train_wall=92, gb_free=16.1, wall=12693
2023-08-14 17:12:20 | INFO | train_inner | epoch 010:    243 / 1474 loss=2.053, trans_loss=3.366, nll_loss=1.539, w2v_ctc_loss=1.054, task_loss=0.918, contrastive_loss=0.294, total=4131.11, n_correct=2623.07, ppl=2.91, accuracy=63.496, wps=13362.8, ups=1.08, wpb=12328.7, bsz=463.9, num_updates=13500, lr=0.000121716, gnorm=0.405, clip=0, loss_scale=8, train_wall=92, gb_free=15.8, wall=12785
2023-08-14 17:13:53 | INFO | train_inner | epoch 010:    343 / 1474 loss=2.033, trans_loss=3.368, nll_loss=1.546, w2v_ctc_loss=1.05, task_loss=0.948, contrastive_loss=0.207, total=4135.65, n_correct=2619.31, ppl=2.92, accuracy=63.335, wps=13329.9, ups=1.08, wpb=12362.4, bsz=454, num_updates=13600, lr=0.000121268, gnorm=0.403, clip=0, loss_scale=8, train_wall=92, gb_free=15.4, wall=12878
2023-08-14 17:15:26 | INFO | train_inner | epoch 010:    443 / 1474 loss=2.066, trans_loss=3.374, nll_loss=1.55, w2v_ctc_loss=1.043, task_loss=0.9, contrastive_loss=0.389, total=4199.14, n_correct=2656.02, ppl=2.93, accuracy=63.252, wps=13403.6, ups=1.07, wpb=12535.9, bsz=482.3, num_updates=13700, lr=0.000120824, gnorm=0.444, clip=0, loss_scale=8, train_wall=93, gb_free=16.5, wall=12972
2023-08-14 17:17:00 | INFO | train_inner | epoch 010:    543 / 1474 loss=2.041, trans_loss=3.383, nll_loss=1.558, w2v_ctc_loss=1.072, task_loss=1.022, contrastive_loss=0.16, total=4094.23, n_correct=2583.31, ppl=2.95, accuracy=63.096, wps=13066.5, ups=1.07, wpb=12209.6, bsz=433.2, num_updates=13800, lr=0.000120386, gnorm=0.412, clip=0, loss_scale=8, train_wall=93, gb_free=14, wall=13065
2023-08-14 17:18:33 | INFO | train_inner | epoch 010:    643 / 1474 loss=2.06, trans_loss=3.376, nll_loss=1.552, w2v_ctc_loss=1.06, task_loss=0.88, contrastive_loss=0.276, total=4182.84, n_correct=2648.33, ppl=2.93, accuracy=63.314, wps=13429.8, ups=1.08, wpb=12481.2, bsz=481.3, num_updates=13900, lr=0.000119952, gnorm=0.405, clip=0, loss_scale=8, train_wall=92, gb_free=16.3, wall=13158
2023-08-14 17:20:05 | INFO | train_inner | epoch 010:    743 / 1474 loss=2.043, trans_loss=3.375, nll_loss=1.551, w2v_ctc_loss=1.077, task_loss=0.945, contrastive_loss=0.157, total=4120.62, n_correct=2606.38, ppl=2.93, accuracy=63.252, wps=13412.6, ups=1.09, wpb=12301.2, bsz=451.7, num_updates=14000, lr=0.000119523, gnorm=0.407, clip=0, loss_scale=8, train_wall=91, gb_free=16.5, wall=13250
2023-08-14 17:20:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 17:20:30 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.043 | trans_loss 5.232 | nll_loss 2.52 | w2v_ctc_loss 1.398 | task_loss 4.63 | contrastive_loss 0.35 | total 4003.4 | n_correct 2612.5 | ppl 5.74 | accuracy 65.257 | uer 19.996 | wer 22.005 | raw_wer 22.005 | bleu 21.09 | wps 2009.6 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 21.09
2023-08-14 17:20:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-14 17:20:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-14 17:20:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-14 17:21:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 21.09) (writing took 56.52764668688178 seconds)
2023-08-14 17:23:01 | INFO | train_inner | epoch 010:    843 / 1474 loss=2.021, trans_loss=3.373, nll_loss=1.55, w2v_ctc_loss=1.049, task_loss=0.925, contrastive_loss=0.16, total=4132.62, n_correct=2620.41, ppl=2.93, accuracy=63.408, wps=7008.6, ups=0.57, wpb=12339.2, bsz=457.4, num_updates=14100, lr=0.000119098, gnorm=0.398, clip=0, loss_scale=8, train_wall=92, gb_free=16.4, wall=13426
2023-08-14 17:24:33 | INFO | train_inner | epoch 010:    943 / 1474 loss=2.039, trans_loss=3.372, nll_loss=1.546, w2v_ctc_loss=1.06, task_loss=0.902, contrastive_loss=0.198, total=4160.84, n_correct=2639.17, ppl=2.92, accuracy=63.429, wps=13502.3, ups=1.09, wpb=12411.3, bsz=467.9, num_updates=14200, lr=0.000118678, gnorm=0.407, clip=0, loss_scale=8, train_wall=91, gb_free=15.5, wall=13518
2023-08-14 17:26:05 | INFO | train_inner | epoch 010:   1043 / 1474 loss=2.035, trans_loss=3.373, nll_loss=1.549, w2v_ctc_loss=1.064, task_loss=1.024, contrastive_loss=0.172, total=4059.22, n_correct=2567.26, ppl=2.93, accuracy=63.245, wps=13100.1, ups=1.08, wpb=12120, bsz=431.2, num_updates=14300, lr=0.000118262, gnorm=0.41, clip=0, loss_scale=8, train_wall=92, gb_free=9, wall=13610
2023-08-14 17:27:37 | INFO | train_inner | epoch 010:   1143 / 1474 loss=2.04, trans_loss=3.38, nll_loss=1.559, w2v_ctc_loss=1.074, task_loss=1.042, contrastive_loss=0.155, total=4045.82, n_correct=2556.21, ppl=2.95, accuracy=63.182, wps=13190.2, ups=1.09, wpb=12079.3, bsz=422.8, num_updates=14400, lr=0.000117851, gnorm=0.408, clip=0, loss_scale=8, train_wall=91, gb_free=12.4, wall=13702
2023-08-14 17:29:09 | INFO | train_inner | epoch 010:   1243 / 1474 loss=2.029, trans_loss=3.365, nll_loss=1.544, w2v_ctc_loss=1.068, task_loss=0.956, contrastive_loss=0.15, total=4107.6, n_correct=2602.64, ppl=2.92, accuracy=63.362, wps=13302.6, ups=1.08, wpb=12284.6, bsz=446.5, num_updates=14500, lr=0.000117444, gnorm=0.403, clip=0, loss_scale=8, train_wall=92, gb_free=16.3, wall=13794
2023-08-14 17:30:42 | INFO | train_inner | epoch 010:   1343 / 1474 loss=2.029, trans_loss=3.373, nll_loss=1.55, w2v_ctc_loss=1.064, task_loss=0.957, contrastive_loss=0.159, total=4127.69, n_correct=2618.33, ppl=2.93, accuracy=63.433, wps=13222.6, ups=1.07, wpb=12326.4, bsz=452.2, num_updates=14600, lr=0.000117041, gnorm=0.404, clip=0, loss_scale=8, train_wall=93, gb_free=15.7, wall=13888
2023-08-14 17:32:15 | INFO | train_inner | epoch 010:   1443 / 1474 loss=2.087, trans_loss=3.381, nll_loss=1.559, w2v_ctc_loss=1.047, task_loss=0.882, contrastive_loss=0.411, total=4195.02, n_correct=2653.07, ppl=2.95, accuracy=63.243, wps=13419.5, ups=1.07, wpb=12514.1, bsz=483, num_updates=14700, lr=0.000116642, gnorm=0.406, clip=0, loss_scale=8, train_wall=93, gb_free=16.1, wall=13981
2023-08-14 17:32:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 17:33:07 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.007 | trans_loss 5.216 | nll_loss 2.501 | w2v_ctc_loss 1.331 | task_loss 4.617 | contrastive_loss 0.328 | total 4003.4 | n_correct 2620.4 | ppl 5.66 | accuracy 65.454 | uer 18.692 | wer 20.532 | raw_wer 20.532 | bleu 21.13 | wps 2185.5 | wpb 4003.4 | bsz 141.8 | num_updates 14731 | best_bleu 21.13
2023-08-14 17:33:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14731 updates
2023-08-14 17:33:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 17:33:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 17:33:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 10 @ 14731 updates, score 21.13) (writing took 33.29229403287172 seconds)
2023-08-14 17:33:41 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-14 17:33:41 | INFO | train | epoch 010 | loss 2.043 | trans_loss 3.373 | nll_loss 1.55 | w2v_ctc_loss 1.057 | task_loss 0.938 | contrastive_loss 0.23 | total 4138.65 | n_correct 2620.79 | ppl 2.93 | accuracy 63.325 | wps 12034.8 | ups 0.97 | wpb 12355.8 | bsz 458.5 | num_updates 14731 | lr 0.00011652 | gnorm 0.407 | clip 0 | loss_scale 8 | train_wall 1357 | gb_free 17 | wall 14067
2023-08-14 17:33:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 17:33:42 | INFO | fairseq.trainer | begin training epoch 11
2023-08-14 17:33:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 17:34:52 | INFO | train_inner | epoch 011:     69 / 1474 loss=2.013, trans_loss=3.352, nll_loss=1.522, w2v_ctc_loss=1.029, task_loss=0.877, contrastive_loss=0.236, total=4166, n_correct=2666.77, ppl=2.87, accuracy=64.013, wps=7937.3, ups=0.64, wpb=12436.1, bsz=475.7, num_updates=14800, lr=0.000116248, gnorm=0.398, clip=0, loss_scale=16, train_wall=91, gb_free=17.6, wall=14137
2023-08-14 17:36:26 | INFO | train_inner | epoch 011:    169 / 1474 loss=1.998, trans_loss=3.354, nll_loss=1.526, w2v_ctc_loss=1.032, task_loss=0.961, contrastive_loss=0.159, total=4100.74, n_correct=2623.51, ppl=2.88, accuracy=63.977, wps=13086.9, ups=1.07, wpb=12251.1, bsz=450.6, num_updates=14900, lr=0.000115857, gnorm=0.403, clip=0, loss_scale=16, train_wall=93, gb_free=14.1, wall=14231
2023-08-14 17:37:58 | INFO | train_inner | epoch 011:    269 / 1474 loss=1.983, trans_loss=3.351, nll_loss=1.521, w2v_ctc_loss=1.023, task_loss=0.971, contrastive_loss=0.141, total=4115.58, n_correct=2636.15, ppl=2.87, accuracy=64.053, wps=13277.5, ups=1.08, wpb=12290.6, bsz=444.2, num_updates=15000, lr=0.00011547, gnorm=0.411, clip=0, loss_scale=16, train_wall=92, gb_free=15.7, wall=14324
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:0')
2023-08-14 17:39:08 | INFO | train_inner | epoch 011:    369 / 1474 loss=2.06, trans_loss=4.981, nll_loss=2.263, w2v_ctc_loss=0.766, task_loss=1.444, contrastive_loss=0.114, total=4094.16, n_correct=2622.23, ppl=4.8, accuracy=64.048, wps=11881.2, ups=1.44, wpb=8227.1, bsz=296.5, num_updates=15100, lr=0.000115087, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=12.3, wall=14393
2023-08-14 17:40:18 | INFO | train_inner | epoch 011:    469 / 1474 loss=2.083, trans_loss=5.017, nll_loss=2.289, w2v_ctc_loss=0.771, task_loss=1.455, contrastive_loss=0.235, total=4112.8, n_correct=2615.29, ppl=4.89, accuracy=63.589, wps=11705.2, ups=1.42, wpb=8225.6, bsz=302.2, num_updates=15200, lr=0.000114708, gnorm=0.542, clip=0, loss_scale=16, train_wall=70, gb_free=16.8, wall=14463
2023-08-14 17:41:28 | INFO | train_inner | epoch 011:    569 / 1474 loss=2.081, trans_loss=5.013, nll_loss=2.284, w2v_ctc_loss=0.775, task_loss=1.518, contrastive_loss=0.232, total=4071.06, n_correct=2593.07, ppl=4.87, accuracy=63.695, wps=11669.1, ups=1.43, wpb=8142.1, bsz=292.6, num_updates=15300, lr=0.000114332, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=14533
2023-08-14 17:42:38 | INFO | train_inner | epoch 011:    669 / 1474 loss=2.079, trans_loss=5.002, nll_loss=2.271, w2v_ctc_loss=0.767, task_loss=1.375, contrastive_loss=0.293, total=4156.4, n_correct=2657.5, ppl=4.83, accuracy=63.938, wps=11860.8, ups=1.43, wpb=8312.8, bsz=310.2, num_updates=15400, lr=0.000113961, gnorm=0.54, clip=0, loss_scale=16, train_wall=70, gb_free=16, wall=14603
2023-08-14 17:43:48 | INFO | train_inner | epoch 011:    769 / 1474 loss=2.072, trans_loss=5.016, nll_loss=2.288, w2v_ctc_loss=0.782, task_loss=1.428, contrastive_loss=0.114, total=4169.17, n_correct=2665.92, ppl=4.88, accuracy=63.944, wps=11924.5, ups=1.43, wpb=8338.3, bsz=304.8, num_updates=15500, lr=0.000113592, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=11.7, wall=14673
2023-08-14 17:44:57 | INFO | train_inner | epoch 011:    869 / 1474 loss=2.069, trans_loss=5.015, nll_loss=2.287, w2v_ctc_loss=0.776, task_loss=1.472, contrastive_loss=0.104, total=4120.01, n_correct=2626.28, ppl=4.88, accuracy=63.745, wps=11867, ups=1.44, wpb=8240, bsz=293.5, num_updates=15600, lr=0.000113228, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=13, wall=14742
2023-08-14 17:46:07 | INFO | train_inner | epoch 011:    969 / 1474 loss=2.068, trans_loss=5.013, nll_loss=2.284, w2v_ctc_loss=0.778, task_loss=1.424, contrastive_loss=0.116, total=4145.45, n_correct=2647.42, ppl=4.87, accuracy=63.863, wps=11825.1, ups=1.43, wpb=8290.9, bsz=303.7, num_updates=15700, lr=0.000112867, gnorm=0.535, clip=0, loss_scale=16, train_wall=70, gb_free=16.8, wall=14813
2023-08-14 17:47:17 | INFO | train_inner | epoch 011:   1069 / 1474 loss=2.069, trans_loss=5.01, nll_loss=2.281, w2v_ctc_loss=0.778, task_loss=1.378, contrastive_loss=0.135, total=4141.18, n_correct=2647.15, ppl=4.86, accuracy=63.923, wps=11825.4, ups=1.43, wpb=8282.4, bsz=309.4, num_updates=15800, lr=0.000112509, gnorm=0.537, clip=0, loss_scale=16, train_wall=70, gb_free=16.3, wall=14883
2023-08-14 17:48:27 | INFO | train_inner | epoch 011:   1169 / 1474 loss=2.072, trans_loss=5.017, nll_loss=2.29, w2v_ctc_loss=0.783, task_loss=1.406, contrastive_loss=0.119, total=4173.93, n_correct=2661.09, ppl=4.89, accuracy=63.755, wps=11977.3, ups=1.43, wpb=8347.9, bsz=307.2, num_updates=15900, lr=0.000112154, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=14952
2023-08-14 17:49:37 | INFO | train_inner | epoch 011:   1269 / 1474 loss=2.076, trans_loss=5.009, nll_loss=2.28, w2v_ctc_loss=0.779, task_loss=1.35, contrastive_loss=0.189, total=4174.26, n_correct=2663.27, ppl=4.86, accuracy=63.802, wps=11947.7, ups=1.43, wpb=8348.5, bsz=314.4, num_updates=16000, lr=0.000111803, gnorm=0.537, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=15022
2023-08-14 17:49:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:1')
2023-08-14 17:50:00 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.01 | trans_loss 5.213 | nll_loss 2.496 | w2v_ctc_loss 1.351 | task_loss 4.625 | contrastive_loss 0.328 | total 4003.4 | n_correct 2624.5 | ppl 5.64 | accuracy 65.557 | uer 18.443 | wer 20.372 | raw_wer 20.372 | bleu 20.84 | wps 2117.9 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 21.13
2023-08-14 17:50:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-14 17:50:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-14 17:50:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-14 17:50:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 20.84) (writing took 19.23117307946086 seconds)
2023-08-14 17:51:32 | INFO | train_inner | epoch 011:   1369 / 1474 loss=2.083, trans_loss=5.008, nll_loss=2.28, w2v_ctc_loss=0.763, task_loss=1.298, contrastive_loss=0.35, total=4191.56, n_correct=2675.97, ppl=4.86, accuracy=63.842, wps=7313, ups=0.87, wpb=8383.1, bsz=327.7, num_updates=16100, lr=0.000111456, gnorm=0.535, clip=0, loss_scale=16, train_wall=70, gb_free=17.2, wall=15137
2023-08-14 17:52:41 | INFO | train_inner | epoch 011:   1469 / 1474 loss=2.063, trans_loss=5.01, nll_loss=2.282, w2v_ctc_loss=0.77, task_loss=1.347, contrastive_loss=0.124, total=4161.81, n_correct=2660.01, ppl=4.86, accuracy=63.915, wps=11943.8, ups=1.43, wpb=8323.6, bsz=313.2, num_updates=16200, lr=0.000111111, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=15207
2023-08-14 17:52:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 17:53:08 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.994 | trans_loss 5.209 | nll_loss 2.493 | w2v_ctc_loss 1.296 | task_loss 4.617 | contrastive_loss 0.338 | total 4003.4 | n_correct 2631.3 | ppl 5.63 | accuracy 65.727 | uer 19.184 | wer 21.043 | raw_wer 21.043 | bleu 21.61 | wps 2137.7 | wpb 4003.4 | bsz 141.8 | num_updates 16205 | best_bleu 21.61
2023-08-14 17:53:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16205 updates
2023-08-14 17:53:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 17:53:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 17:53:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 11 @ 16205 updates, score 21.61) (writing took 30.224292315542698 seconds)
2023-08-14 17:53:39 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-14 17:53:39 | INFO | train | epoch 011 | loss 2.053 | trans_loss 4.595 | nll_loss 2.092 | w2v_ctc_loss 0.837 | task_loss 1.289 | contrastive_loss 0.171 | total 4138.65 | n_correct 2643.69 | ppl 4.26 | accuracy 63.878 | wps 11106.9 | ups 1.23 | wpb 9023.7 | bsz 333.5 | num_updates 16205 | lr 0.000111094 | gnorm 0.511 | clip 0 | loss_scale 16 | train_wall 1084 | gb_free 16.9 | wall 15264
2023-08-14 17:53:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 17:53:39 | INFO | fairseq.trainer | begin training epoch 12
2023-08-14 17:53:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 17:54:53 | INFO | train_inner | epoch 012:     95 / 1474 loss=2.046, trans_loss=4.972, nll_loss=2.231, w2v_ctc_loss=0.757, task_loss=1.356, contrastive_loss=0.152, total=4139.2, n_correct=2677.43, ppl=4.7, accuracy=64.685, wps=6269.8, ups=0.76, wpb=8278.4, bsz=312.5, num_updates=16300, lr=0.00011077, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=15339
2023-08-14 17:56:03 | INFO | train_inner | epoch 012:    195 / 1474 loss=2.049, trans_loss=4.978, nll_loss=2.239, w2v_ctc_loss=0.764, task_loss=1.449, contrastive_loss=0.105, total=4126.87, n_correct=2660.16, ppl=4.72, accuracy=64.46, wps=11835.4, ups=1.43, wpb=8253.7, bsz=295.9, num_updates=16400, lr=0.000110432, gnorm=0.545, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=15408
2023-08-14 17:57:13 | INFO | train_inner | epoch 012:    295 / 1474 loss=2.042, trans_loss=4.976, nll_loss=2.237, w2v_ctc_loss=0.747, task_loss=1.315, contrastive_loss=0.134, total=4203.54, n_correct=2717.68, ppl=4.71, accuracy=64.652, wps=12030.4, ups=1.43, wpb=8407.1, bsz=321.1, num_updates=16500, lr=0.000110096, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=14.3, wall=15478
2023-08-14 17:58:23 | INFO | train_inner | epoch 012:    395 / 1474 loss=2.046, trans_loss=4.98, nll_loss=2.242, w2v_ctc_loss=0.756, task_loss=1.376, contrastive_loss=0.119, total=4149.28, n_correct=2678.31, ppl=4.73, accuracy=64.549, wps=11802.6, ups=1.42, wpb=8298.6, bsz=307.1, num_updates=16600, lr=0.000109764, gnorm=0.531, clip=0, loss_scale=16, train_wall=70, gb_free=14.8, wall=15549
2023-08-14 17:59:33 | INFO | train_inner | epoch 012:    495 / 1474 loss=2.057, trans_loss=4.994, nll_loss=2.261, w2v_ctc_loss=0.768, task_loss=1.418, contrastive_loss=0.127, total=4106.46, n_correct=2643.13, ppl=4.79, accuracy=64.365, wps=11802.6, ups=1.44, wpb=8212.9, bsz=301.2, num_updates=16700, lr=0.000109435, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=15618
2023-08-14 18:00:43 | INFO | train_inner | epoch 012:    595 / 1474 loss=2.054, trans_loss=4.98, nll_loss=2.243, w2v_ctc_loss=0.758, task_loss=1.34, contrastive_loss=0.194, total=4190.91, n_correct=2704.18, ppl=4.73, accuracy=64.525, wps=11921.9, ups=1.42, wpb=8381.8, bsz=316.5, num_updates=16800, lr=0.000109109, gnorm=0.528, clip=0, loss_scale=32, train_wall=70, gb_free=15.6, wall=15688
2023-08-14 18:01:53 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.053, trans_loss=4.979, nll_loss=2.242, w2v_ctc_loss=0.745, task_loss=1.293, contrastive_loss=0.277, total=4203.66, n_correct=2716.6, ppl=4.73, accuracy=64.625, wps=12049.4, ups=1.43, wpb=8407.3, bsz=324.4, num_updates=16900, lr=0.000108786, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=15758
2023-08-14 18:03:03 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.046, trans_loss=4.976, nll_loss=2.238, w2v_ctc_loss=0.761, task_loss=1.424, contrastive_loss=0.116, total=4095.72, n_correct=2643.87, ppl=4.72, accuracy=64.552, wps=11764.8, ups=1.44, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.548, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=15828
2023-08-14 18:04:13 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.055, trans_loss=4.982, nll_loss=2.245, w2v_ctc_loss=0.76, task_loss=1.441, contrastive_loss=0.168, total=4162.82, n_correct=2682.22, ppl=4.74, accuracy=64.433, wps=11841.3, ups=1.42, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.532, clip=0, loss_scale=32, train_wall=70, gb_free=15.8, wall=15898
2023-08-14 18:05:23 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.056, trans_loss=4.986, nll_loss=2.25, w2v_ctc_loss=0.763, task_loss=1.43, contrastive_loss=0.176, total=4117.63, n_correct=2650.21, ppl=4.76, accuracy=64.363, wps=11812.2, ups=1.43, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.548, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=15968
2023-08-14 18:06:32 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.067, trans_loss=4.99, nll_loss=2.256, w2v_ctc_loss=0.768, task_loss=1.478, contrastive_loss=0.219, total=4046.48, n_correct=2602.41, ppl=4.78, accuracy=64.313, wps=11576.8, ups=1.43, wpb=8093, bsz=289.6, num_updates=17300, lr=0.000107521, gnorm=0.546, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=16038
2023-08-14 18:07:43 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.069, trans_loss=5.005, nll_loss=2.275, w2v_ctc_loss=0.777, task_loss=1.369, contrastive_loss=0.188, total=4201.13, n_correct=2692.42, ppl=4.84, accuracy=64.088, wps=11968.2, ups=1.42, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.528, clip=0, loss_scale=32, train_wall=70, gb_free=17, wall=16108
2023-08-14 18:08:53 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.055, trans_loss=4.986, nll_loss=2.25, w2v_ctc_loss=0.777, task_loss=1.567, contrastive_loss=0.101, total=4070.27, n_correct=2615.66, ppl=4.76, accuracy=64.263, wps=11639.4, ups=1.43, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=16178
2023-08-14 18:10:02 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.06, trans_loss=4.993, nll_loss=2.26, w2v_ctc_loss=0.76, task_loss=1.417, contrastive_loss=0.205, total=4139.63, n_correct=2661.25, ppl=4.79, accuracy=64.287, wps=11924.4, ups=1.44, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=16247
2023-08-14 18:10:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 18:11:22 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.019 | trans_loss 5.205 | nll_loss 2.491 | w2v_ctc_loss 1.4 | task_loss 4.621 | contrastive_loss 0.326 | total 4003.4 | n_correct 2626.1 | ppl 5.62 | accuracy 65.597 | uer 19.547 | wer 21.442 | raw_wer 21.442 | bleu 21.27 | wps 2033.7 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 21.61
2023-08-14 18:11:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-14 18:11:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.2701.pt
2023-08-14 18:11:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.2701.pt
2023-08-14 18:11:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.2701.pt (epoch 12 @ 17679 updates, score 21.27) (writing took 17.450913902372122 seconds)
2023-08-14 18:11:40 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-14 18:11:40 | INFO | train | epoch 012 | loss 2.054 | trans_loss 4.985 | nll_loss 2.248 | w2v_ctc_loss 0.762 | task_loss 1.405 | contrastive_loss 0.161 | total 4138.65 | n_correct 2666.57 | ppl 4.75 | accuracy 64.431 | wps 11286 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 17679 | lr 0.000106362 | gnorm 0.534 | clip 0 | loss_scale 32 | train_wall 1023 | gb_free 12.5 | wall 16345
2023-08-14 18:11:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 18:11:40 | INFO | fairseq.trainer | begin training epoch 13
2023-08-14 18:11:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 18:12:03 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.056, trans_loss=4.993, nll_loss=2.26, w2v_ctc_loss=0.775, task_loss=1.462, contrastive_loss=0.11, total=4096.49, n_correct=2630.39, ppl=4.79, accuracy=64.211, wps=6750.4, ups=0.82, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.53, clip=0, loss_scale=32, train_wall=70, gb_free=14.2, wall=16369
2023-08-14 18:13:13 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.034, trans_loss=4.958, nll_loss=2.214, w2v_ctc_loss=0.745, task_loss=1.41, contrastive_loss=0.123, total=4160.97, n_correct=2702.8, ppl=4.64, accuracy=64.956, wps=11913, ups=1.43, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=16439
2023-08-14 18:14:24 | INFO | train_inner | epoch 013:    221 / 1474 loss=2.053, trans_loss=4.968, nll_loss=2.227, w2v_ctc_loss=0.743, task_loss=1.299, contrastive_loss=0.334, total=4212.08, n_correct=2730.6, ppl=4.68, accuracy=64.828, wps=11988.7, ups=1.42, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.518, clip=0, loss_scale=32, train_wall=70, gb_free=14.3, wall=16509
2023-08-14 18:15:34 | INFO | train_inner | epoch 013:    321 / 1474 loss=2.027, trans_loss=4.951, nll_loss=2.204, w2v_ctc_loss=0.742, task_loss=1.461, contrastive_loss=0.104, total=4102.3, n_correct=2671.77, ppl=4.61, accuracy=65.129, wps=11695.9, ups=1.43, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.522, clip=0, loss_scale=32, train_wall=70, gb_free=16.9, wall=16579
2023-08-14 18:15:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 18:15:58 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.011 | trans_loss 5.217 | nll_loss 2.506 | w2v_ctc_loss 1.342 | task_loss 4.605 | contrastive_loss 0.332 | total 4003.4 | n_correct 2622.2 | ppl 5.68 | accuracy 65.499 | uer 19.563 | wer 21.61 | raw_wer 21.61 | bleu 21.33 | wps 2106.9 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 21.61
2023-08-14 18:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-14 18:15:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-14 18:16:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-14 18:16:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 21.33) (writing took 19.404795307666063 seconds)
2023-08-14 18:17:28 | INFO | train_inner | epoch 013:    421 / 1474 loss=2.034, trans_loss=4.958, nll_loss=2.215, w2v_ctc_loss=0.744, task_loss=1.315, contrastive_loss=0.154, total=4177.29, n_correct=2718.32, ppl=4.64, accuracy=65.074, wps=7294.6, ups=0.87, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.542, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=16694
2023-08-14 18:18:38 | INFO | train_inner | epoch 013:    521 / 1474 loss=2.042, trans_loss=4.965, nll_loss=2.223, w2v_ctc_loss=0.75, task_loss=1.362, contrastive_loss=0.19, total=4201.22, n_correct=2721.84, ppl=4.67, accuracy=64.787, wps=12075.2, ups=1.44, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=12.5, wall=16763
2023-08-14 18:19:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 18:19:48 | INFO | train_inner | epoch 013:    622 / 1474 loss=2.027, trans_loss=4.959, nll_loss=2.216, w2v_ctc_loss=0.743, task_loss=1.365, contrastive_loss=0.102, total=4162.64, n_correct=2709.71, ppl=4.65, accuracy=65.096, wps=11853.5, ups=1.42, wpb=8325.3, bsz=307.9, num_updates=18300, lr=0.000104542, gnorm=0.546, clip=0, loss_scale=16, train_wall=70, gb_free=13, wall=16833
2023-08-14 18:20:58 | INFO | train_inner | epoch 013:    722 / 1474 loss=2.045, trans_loss=4.967, nll_loss=2.225, w2v_ctc_loss=0.769, task_loss=1.558, contrastive_loss=0.103, total=4099.91, n_correct=2651.36, ppl=4.67, accuracy=64.669, wps=11663.3, ups=1.42, wpb=8199.8, bsz=285.5, num_updates=18400, lr=0.000104257, gnorm=0.562, clip=0, loss_scale=16, train_wall=70, gb_free=16.4, wall=16904
2023-08-14 18:22:09 | INFO | train_inner | epoch 013:    822 / 1474 loss=2.042, trans_loss=4.968, nll_loss=2.227, w2v_ctc_loss=0.752, task_loss=1.427, contrastive_loss=0.149, total=4122.78, n_correct=2670.05, ppl=4.68, accuracy=64.763, wps=11673.6, ups=1.42, wpb=8245.6, bsz=306, num_updates=18500, lr=0.000103975, gnorm=0.541, clip=0, loss_scale=16, train_wall=70, gb_free=14.6, wall=16974
2023-08-14 18:23:18 | INFO | train_inner | epoch 013:    922 / 1474 loss=2.033, trans_loss=4.962, nll_loss=2.219, w2v_ctc_loss=0.747, task_loss=1.436, contrastive_loss=0.111, total=4102.59, n_correct=2663.93, ppl=4.66, accuracy=64.933, wps=11871.2, ups=1.45, wpb=8205.2, bsz=296.6, num_updates=18600, lr=0.000103695, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=17043
2023-08-14 18:24:28 | INFO | train_inner | epoch 013:   1022 / 1474 loss=2.051, trans_loss=4.971, nll_loss=2.231, w2v_ctc_loss=0.764, task_loss=1.487, contrastive_loss=0.163, total=4087.8, n_correct=2639.4, ppl=4.69, accuracy=64.568, wps=11731.7, ups=1.43, wpb=8175.6, bsz=293.7, num_updates=18700, lr=0.000103418, gnorm=0.549, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=17113
2023-08-14 18:25:37 | INFO | train_inner | epoch 013:   1122 / 1474 loss=2.029, trans_loss=4.954, nll_loss=2.209, w2v_ctc_loss=0.741, task_loss=1.395, contrastive_loss=0.141, total=4098.77, n_correct=2666.39, ppl=4.62, accuracy=65.053, wps=11790.5, ups=1.44, wpb=8197.5, bsz=304.8, num_updates=18800, lr=0.000103142, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=13.2, wall=17183
2023-08-14 18:26:47 | INFO | train_inner | epoch 013:   1222 / 1474 loss=2.038, trans_loss=4.967, nll_loss=2.226, w2v_ctc_loss=0.755, task_loss=1.492, contrastive_loss=0.104, total=4115.57, n_correct=2670.54, ppl=4.68, accuracy=64.889, wps=11743.5, ups=1.43, wpb=8231.1, bsz=295.9, num_updates=18900, lr=0.000102869, gnorm=0.527, clip=0, loss_scale=16, train_wall=70, gb_free=14.8, wall=17253
2023-08-14 18:27:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-14 18:27:58 | INFO | train_inner | epoch 013:   1323 / 1474 loss=2.04, trans_loss=4.956, nll_loss=2.213, w2v_ctc_loss=0.752, task_loss=1.378, contrastive_loss=0.201, total=4118.87, n_correct=2681.64, ppl=4.64, accuracy=65.106, wps=11694.2, ups=1.42, wpb=8237.7, bsz=309.8, num_updates=19000, lr=0.000102598, gnorm=0.534, clip=0, loss_scale=8, train_wall=70, gb_free=16.2, wall=17323
2023-08-14 18:29:08 | INFO | train_inner | epoch 013:   1423 / 1474 loss=2.045, trans_loss=4.967, nll_loss=2.227, w2v_ctc_loss=0.748, task_loss=1.385, contrastive_loss=0.21, total=4171.47, n_correct=2703.6, ppl=4.68, accuracy=64.812, wps=11953.5, ups=1.43, wpb=8342.9, bsz=310.5, num_updates=19100, lr=0.000102329, gnorm=0.532, clip=0, loss_scale=8, train_wall=69, gb_free=14.9, wall=17393
2023-08-14 18:29:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 18:30:07 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.003 | trans_loss 5.191 | nll_loss 2.465 | w2v_ctc_loss 1.381 | task_loss 4.652 | contrastive_loss 0.324 | total 4003.4 | n_correct 2636.9 | ppl 5.52 | accuracy 65.867 | uer 19.048 | wer 20.92 | raw_wer 20.92 | bleu 21.59 | wps 2163.2 | wpb 4003.4 | bsz 141.8 | num_updates 19151 | best_bleu 21.61
2023-08-14 18:30:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19151 updates
2023-08-14 18:30:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.5907.pt
2023-08-14 18:30:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.5907.pt
2023-08-14 18:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.5907.pt (epoch 13 @ 19151 updates, score 21.59) (writing took 38.9997095875442 seconds)
2023-08-14 18:30:47 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-14 18:30:47 | INFO | train | epoch 013 | loss 2.038 | trans_loss 4.962 | nll_loss 2.219 | w2v_ctc_loss 0.75 | task_loss 1.406 | contrastive_loss 0.157 | total 4139.48 | n_correct 2686.91 | ppl 4.66 | accuracy 64.909 | wps 10623.2 | ups 1.28 | wpb 8279 | bsz 305.8 | num_updates 19151 | lr 0.000102193 | gnorm 0.535 | clip 0 | loss_scale 8 | train_wall 1022 | gb_free 17.3 | wall 17492
2023-08-14 18:30:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 18:30:47 | INFO | fairseq.trainer | begin training epoch 14
2023-08-14 18:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 18:31:29 | INFO | train_inner | epoch 014:     49 / 1474 loss=2.019, trans_loss=4.938, nll_loss=2.189, w2v_ctc_loss=0.739, task_loss=1.293, contrastive_loss=0.117, total=4182.69, n_correct=2735.63, ppl=4.56, accuracy=65.404, wps=5909.2, ups=0.71, wpb=8365.4, bsz=322.3, num_updates=19200, lr=0.000102062, gnorm=0.538, clip=0, loss_scale=8, train_wall=69, gb_free=15.6, wall=17535
2023-08-14 18:32:39 | INFO | train_inner | epoch 014:    149 / 1474 loss=2.01, trans_loss=4.925, nll_loss=2.171, w2v_ctc_loss=0.734, task_loss=1.4, contrastive_loss=0.096, total=4086.4, n_correct=2682.22, ppl=4.5, accuracy=65.638, wps=11776.7, ups=1.44, wpb=8172.8, bsz=301.5, num_updates=19300, lr=0.000101797, gnorm=0.533, clip=0, loss_scale=8, train_wall=69, gb_free=16.7, wall=17604
2023-08-14 18:33:47 | INFO | train_inner | epoch 014:    249 / 1474 loss=2.031, trans_loss=4.944, nll_loss=2.196, w2v_ctc_loss=0.738, task_loss=1.472, contrastive_loss=0.199, total=4103.37, n_correct=2680.39, ppl=4.58, accuracy=65.322, wps=11926.6, ups=1.45, wpb=8206.7, bsz=294, num_updates=19400, lr=0.000101535, gnorm=0.554, clip=0, loss_scale=8, train_wall=68, gb_free=16.9, wall=17673
2023-08-14 18:34:58 | INFO | train_inner | epoch 014:    349 / 1474 loss=2.018, trans_loss=4.941, nll_loss=2.193, w2v_ctc_loss=0.731, task_loss=1.319, contrastive_loss=0.133, total=4168.35, n_correct=2730.18, ppl=4.57, accuracy=65.498, wps=11899.2, ups=1.43, wpb=8336.7, bsz=318.7, num_updates=19500, lr=0.000101274, gnorm=0.534, clip=0, loss_scale=8, train_wall=70, gb_free=16, wall=17743
2023-08-14 18:36:07 | INFO | train_inner | epoch 014:    449 / 1474 loss=2.017, trans_loss=4.943, nll_loss=2.195, w2v_ctc_loss=0.731, task_loss=1.381, contrastive_loss=0.114, total=4155.83, n_correct=2716.37, ppl=4.58, accuracy=65.363, wps=11909.7, ups=1.43, wpb=8311.7, bsz=306.7, num_updates=19600, lr=0.000101015, gnorm=0.537, clip=0, loss_scale=8, train_wall=69, gb_free=15.6, wall=17813
2023-08-14 18:37:18 | INFO | train_inner | epoch 014:    549 / 1474 loss=2.031, trans_loss=4.946, nll_loss=2.198, w2v_ctc_loss=0.756, task_loss=1.529, contrastive_loss=0.109, total=4064.87, n_correct=2648.97, ppl=4.59, accuracy=65.167, wps=11561.2, ups=1.42, wpb=8129.7, bsz=288.5, num_updates=19700, lr=0.000100759, gnorm=0.536, clip=0, loss_scale=8, train_wall=70, gb_free=17.6, wall=17883
2023-08-14 18:38:27 | INFO | train_inner | epoch 014:    649 / 1474 loss=2.03, trans_loss=4.946, nll_loss=2.199, w2v_ctc_loss=0.74, task_loss=1.397, contrastive_loss=0.172, total=4167.34, n_correct=2719.11, ppl=4.59, accuracy=65.248, wps=11981.5, ups=1.44, wpb=8334.7, bsz=307.8, num_updates=19800, lr=0.000100504, gnorm=0.525, clip=0, loss_scale=8, train_wall=69, gb_free=16.8, wall=17953
2023-08-14 18:39:37 | INFO | train_inner | epoch 014:    749 / 1474 loss=2.019, trans_loss=4.934, nll_loss=2.183, w2v_ctc_loss=0.744, task_loss=1.374, contrastive_loss=0.106, total=4142.94, n_correct=2713.25, ppl=4.54, accuracy=65.491, wps=11853.2, ups=1.43, wpb=8285.9, bsz=308.6, num_updates=19900, lr=0.000100251, gnorm=0.531, clip=0, loss_scale=8, train_wall=69, gb_free=16.1, wall=18022
2023-08-14 18:40:47 | INFO | train_inner | epoch 014:    849 / 1474 loss=2.03, trans_loss=4.938, nll_loss=2.189, w2v_ctc_loss=0.736, task_loss=1.341, contrastive_loss=0.216, total=4173.06, n_correct=2725.69, ppl=4.56, accuracy=65.316, wps=11899, ups=1.43, wpb=8346.1, bsz=319.1, num_updates=20000, lr=0.0001, gnorm=0.535, clip=0, loss_scale=8, train_wall=70, gb_free=12.4, wall=18093
2023-08-14 18:40:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 18:41:13 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.997 | trans_loss 5.192 | nll_loss 2.47 | w2v_ctc_loss 1.366 | task_loss 4.628 | contrastive_loss 0.317 | total 4003.4 | n_correct 2643.5 | ppl 5.54 | accuracy 66.031 | uer 19.239 | wer 21.286 | raw_wer 21.286 | bleu 21.67 | wps 1958.7 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21.67
2023-08-14 18:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-14 18:41:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-14 18:41:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-14 18:42:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.67) (writing took 61.43037045933306 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:0')
2023-08-14 18:43:27 | INFO | train_inner | epoch 014:    949 / 1474 loss=2.022, trans_loss=4.941, nll_loss=2.193, w2v_ctc_loss=0.734, task_loss=1.401, contrastive_loss=0.151, total=4166.71, n_correct=2718.37, ppl=4.57, accuracy=65.24, wps=5227.5, ups=0.63, wpb=8333.4, bsz=310.6, num_updates=20100, lr=9.97509e-05, gnorm=0.53, clip=0, loss_scale=8, train_wall=70, gb_free=16.2, wall=18252
2023-08-14 18:44:37 | INFO | train_inner | epoch 014:   1049 / 1474 loss=2.024, trans_loss=4.944, nll_loss=2.197, w2v_ctc_loss=0.738, task_loss=1.426, contrastive_loss=0.129, total=4145.57, n_correct=2711.03, ppl=4.58, accuracy=65.396, wps=11806.3, ups=1.42, wpb=8291.1, bsz=301.1, num_updates=20200, lr=9.95037e-05, gnorm=0.528, clip=0, loss_scale=8, train_wall=70, gb_free=17, wall=18322
2023-08-14 18:45:48 | INFO | train_inner | epoch 014:   1149 / 1474 loss=2.051, trans_loss=4.946, nll_loss=2.199, w2v_ctc_loss=0.743, task_loss=1.327, contrastive_loss=0.399, total=4219.9, n_correct=2749.51, ppl=4.59, accuracy=65.156, wps=11943, ups=1.42, wpb=8439.8, bsz=325.2, num_updates=20300, lr=9.92583e-05, gnorm=0.52, clip=0, loss_scale=8, train_wall=70, gb_free=16, wall=18393
2023-08-14 18:46:58 | INFO | train_inner | epoch 014:   1249 / 1474 loss=2.03, trans_loss=4.95, nll_loss=2.204, w2v_ctc_loss=0.755, task_loss=1.63, contrastive_loss=0.089, total=4032.06, n_correct=2626.62, ppl=4.61, accuracy=65.143, wps=11510.5, ups=1.43, wpb=8064.1, bsz=274.4, num_updates=20400, lr=9.90148e-05, gnorm=0.538, clip=0, loss_scale=8, train_wall=70, gb_free=17.4, wall=18463
2023-08-14 18:48:08 | INFO | train_inner | epoch 014:   1349 / 1474 loss=2.017, trans_loss=4.944, nll_loss=2.197, w2v_ctc_loss=0.735, task_loss=1.333, contrastive_loss=0.105, total=4205.07, n_correct=2750.95, ppl=4.58, accuracy=65.42, wps=12045.2, ups=1.43, wpb=8410.1, bsz=317.3, num_updates=20500, lr=9.8773e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=69, gb_free=16.3, wall=18533
2023-08-14 18:49:17 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.026, trans_loss=4.949, nll_loss=2.203, w2v_ctc_loss=0.737, task_loss=1.402, contrastive_loss=0.142, total=4126.44, n_correct=2688.99, ppl=4.61, accuracy=65.165, wps=11872.5, ups=1.44, wpb=8252.9, bsz=303.9, num_updates=20600, lr=9.85329e-05, gnorm=0.535, clip=0, loss_scale=8, train_wall=69, gb_free=15.8, wall=18602
2023-08-14 18:49:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:1')
2023-08-14 18:50:00 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.989 | trans_loss 5.184 | nll_loss 2.463 | w2v_ctc_loss 1.353 | task_loss 4.621 | contrastive_loss 0.321 | total 4003.4 | n_correct 2643.4 | ppl 5.51 | accuracy 66.029 | uer 19.465 | wer 21.599 | raw_wer 21.599 | bleu 21.82 | wps 1951.5 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 21.82
2023-08-14 18:50:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-08-14 18:50:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 18:50:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 18:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 14 @ 20625 updates, score 21.82) (writing took 32.68968778476119 seconds)
2023-08-14 18:50:33 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-14 18:50:33 | INFO | train | epoch 014 | loss 2.025 | trans_loss 4.942 | nll_loss 2.194 | w2v_ctc_loss 0.739 | task_loss 1.405 | contrastive_loss 0.154 | total 4138.65 | n_correct 2703.71 | ppl 4.58 | accuracy 65.328 | wps 10286.9 | ups 1.24 | wpb 8277.3 | bsz 305.7 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.533 | clip 0 | loss_scale 8 | train_wall 1022 | gb_free 16 | wall 18678
2023-08-14 18:50:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 18:50:33 | INFO | fairseq.trainer | begin training epoch 15
2023-08-14 18:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 18:51:34 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.018, trans_loss=4.93, nll_loss=2.178, w2v_ctc_loss=0.728, task_loss=1.41, contrastive_loss=0.193, total=4090.99, n_correct=2686.64, ppl=4.53, accuracy=65.672, wps=5980.7, ups=0.73, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=69, gb_free=16.6, wall=18739
2023-08-14 18:52:43 | INFO | train_inner | epoch 015:    175 / 1474 loss=2.007, trans_loss=4.92, nll_loss=2.165, w2v_ctc_loss=0.73, task_loss=1.453, contrastive_loss=0.102, total=4115.56, n_correct=2711.6, ppl=4.48, accuracy=65.887, wps=11828, ups=1.44, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.519, clip=0, loss_scale=8, train_wall=69, gb_free=16.5, wall=18809
2023-08-14 18:53:53 | INFO | train_inner | epoch 015:    275 / 1474 loss=2.002, trans_loss=4.922, nll_loss=2.167, w2v_ctc_loss=0.722, task_loss=1.369, contrastive_loss=0.093, total=4182.19, n_correct=2758.22, ppl=4.49, accuracy=65.952, wps=11994.2, ups=1.43, wpb=8364.4, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.521, clip=0, loss_scale=8, train_wall=69, gb_free=16.1, wall=18878
2023-08-14 18:55:03 | INFO | train_inner | epoch 015:    375 / 1474 loss=2.005, trans_loss=4.916, nll_loss=2.16, w2v_ctc_loss=0.722, task_loss=1.405, contrastive_loss=0.116, total=4172.52, n_correct=2748.07, ppl=4.47, accuracy=65.861, wps=12009.5, ups=1.44, wpb=8345, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=18948
2023-08-14 18:56:12 | INFO | train_inner | epoch 015:    475 / 1474 loss=2.015, trans_loss=4.921, nll_loss=2.166, w2v_ctc_loss=0.718, task_loss=1.472, contrastive_loss=0.207, total=4076.84, n_correct=2678.53, ppl=4.49, accuracy=65.701, wps=11717, ups=1.44, wpb=8153.7, bsz=293.4, num_updates=21100, lr=9.73585e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=19018
2023-08-14 18:57:22 | INFO | train_inner | epoch 015:    575 / 1474 loss=2.012, trans_loss=4.924, nll_loss=2.171, w2v_ctc_loss=0.733, task_loss=1.434, contrastive_loss=0.119, total=4156.05, n_correct=2727.79, ppl=4.5, accuracy=65.634, wps=11954.3, ups=1.44, wpb=8312.1, bsz=302.8, num_updates=21200, lr=9.71286e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=11.3, wall=19087
2023-08-14 18:58:31 | INFO | train_inner | epoch 015:    675 / 1474 loss=2.014, trans_loss=4.918, nll_loss=2.163, w2v_ctc_loss=0.729, task_loss=1.439, contrastive_loss=0.163, total=4118.87, n_correct=2707.8, ppl=4.48, accuracy=65.741, wps=11828.9, ups=1.44, wpb=8237.7, bsz=303, num_updates=21300, lr=9.69003e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=19157
2023-08-14 18:59:42 | INFO | train_inner | epoch 015:    775 / 1474 loss=2.01, trans_loss=4.926, nll_loss=2.173, w2v_ctc_loss=0.734, task_loss=1.415, contrastive_loss=0.102, total=4176.64, n_correct=2740.93, ppl=4.51, accuracy=65.625, wps=11909.2, ups=1.43, wpb=8353.3, bsz=305.3, num_updates=21400, lr=9.66736e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=70, gb_free=13.6, wall=19227
2023-08-14 19:00:51 | INFO | train_inner | epoch 015:    875 / 1474 loss=2.014, trans_loss=4.93, nll_loss=2.179, w2v_ctc_loss=0.738, task_loss=1.519, contrastive_loss=0.096, total=4056.99, n_correct=2658.88, ppl=4.53, accuracy=65.538, wps=11649, ups=1.44, wpb=8114, bsz=288, num_updates=21500, lr=9.64486e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=19297
2023-08-14 19:02:00 | INFO | train_inner | epoch 015:    975 / 1474 loss=2.011, trans_loss=4.922, nll_loss=2.168, w2v_ctc_loss=0.722, task_loss=1.399, contrastive_loss=0.183, total=4134.44, n_correct=2722.25, ppl=4.49, accuracy=65.843, wps=11963.2, ups=1.45, wpb=8268.9, bsz=304.8, num_updates=21600, lr=9.6225e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=19366
2023-08-14 19:03:11 | INFO | train_inner | epoch 015:   1075 / 1474 loss=2.034, trans_loss=4.934, nll_loss=2.185, w2v_ctc_loss=0.729, task_loss=1.324, contrastive_loss=0.343, total=4185.02, n_correct=2740.33, ppl=4.55, accuracy=65.479, wps=11821.9, ups=1.41, wpb=8370, bsz=324.2, num_updates=21700, lr=9.60031e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=70, gb_free=16.4, wall=19436
2023-08-14 19:04:20 | INFO | train_inner | epoch 015:   1175 / 1474 loss=1.999, trans_loss=4.921, nll_loss=2.168, w2v_ctc_loss=0.711, task_loss=1.254, contrastive_loss=0.145, total=4187.68, n_correct=2760.59, ppl=4.5, accuracy=65.922, wps=12093.1, ups=1.44, wpb=8375.4, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=19506
2023-08-14 19:05:30 | INFO | train_inner | epoch 015:   1275 / 1474 loss=2.016, trans_loss=4.924, nll_loss=2.171, w2v_ctc_loss=0.746, task_loss=1.448, contrastive_loss=0.101, total=4141.6, n_correct=2715.39, ppl=4.5, accuracy=65.564, wps=11870.5, ups=1.43, wpb=8283.2, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=13, wall=19576
2023-08-14 19:06:39 | INFO | train_inner | epoch 015:   1375 / 1474 loss=2.006, trans_loss=4.922, nll_loss=2.169, w2v_ctc_loss=0.729, task_loss=1.454, contrastive_loss=0.087, total=4099.6, n_correct=2695.03, ppl=4.5, accuracy=65.739, wps=11872.1, ups=1.45, wpb=8199.2, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=14, wall=19645
2023-08-14 19:06:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 19:07:05 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.97 | trans_loss 5.178 | nll_loss 2.452 | w2v_ctc_loss 1.313 | task_loss 4.604 | contrastive_loss 0.313 | total 4003.4 | n_correct 2654 | ppl 5.47 | accuracy 66.294 | uer 18.615 | wer 20.469 | raw_wer 20.469 | bleu 22.06 | wps 2071.1 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 22.06
2023-08-14 19:07:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-14 19:07:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-14 19:07:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-14 19:07:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 22.06) (writing took 34.90848656371236 seconds)
2023-08-14 19:08:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 19:09:16 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.967 | trans_loss 5.184 | nll_loss 2.458 | w2v_ctc_loss 1.285 | task_loss 4.617 | contrastive_loss 0.326 | total 4003.4 | n_correct 2644.2 | ppl 5.5 | accuracy 66.049 | uer 18.17 | wer 19.977 | raw_wer 19.977 | bleu 21.94 | wps 1991.5 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 22.06
2023-08-14 19:09:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-08-14 19:09:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.9404.pt
2023-08-14 19:09:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.9404.pt
2023-08-14 19:09:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.9404.pt (epoch 15 @ 22099 updates, score 21.94) (writing took 38.105774369090796 seconds)
2023-08-14 19:09:54 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-14 19:09:54 | INFO | train | epoch 015 | loss 2.012 | trans_loss 4.923 | nll_loss 2.17 | w2v_ctc_loss 0.728 | task_loss 1.405 | contrastive_loss 0.15 | total 4138.65 | n_correct 2720.25 | ppl 4.5 | accuracy 65.728 | wps 10509 | ups 1.27 | wpb 8277.3 | bsz 305.7 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.532 | clip 0 | loss_scale 16 | train_wall 1020 | gb_free 16.6 | wall 19839
2023-08-14 19:09:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 19:09:54 | INFO | fairseq.trainer | begin training epoch 16
2023-08-14 19:09:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 19:10:02 | INFO | train_inner | epoch 016:      1 / 1474 loss=2.017, trans_loss=4.931, nll_loss=2.181, w2v_ctc_loss=0.728, task_loss=1.346, contrastive_loss=0.176, total=4149.9, n_correct=2722.34, ppl=4.53, accuracy=65.6, wps=4087.1, ups=0.49, wpb=8299.8, bsz=316.3, num_updates=22100, lr=9.51303e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=70, gb_free=17.1, wall=19848
2023-08-14 19:10:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-14 19:11:12 | INFO | train_inner | epoch 016:    102 / 1474 loss=1.994, trans_loss=4.904, nll_loss=2.144, w2v_ctc_loss=0.717, task_loss=1.357, contrastive_loss=0.116, total=4110.54, n_correct=2723.02, ppl=4.42, accuracy=66.245, wps=11823.5, ups=1.44, wpb=8221.1, bsz=312.5, num_updates=22200, lr=9.49158e-05, gnorm=0.545, clip=0, loss_scale=8, train_wall=69, gb_free=12.2, wall=19917
2023-08-14 19:12:22 | INFO | train_inner | epoch 016:    202 / 1474 loss=1.988, trans_loss=4.896, nll_loss=2.135, w2v_ctc_loss=0.707, task_loss=1.444, contrastive_loss=0.091, total=4109.58, n_correct=2724.16, ppl=4.39, accuracy=66.288, wps=11795.5, ups=1.44, wpb=8219.2, bsz=297.3, num_updates=22300, lr=9.47027e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=69, gb_free=14.7, wall=19987
2023-08-14 19:13:32 | INFO | train_inner | epoch 016:    302 / 1474 loss=2.005, trans_loss=4.906, nll_loss=2.148, w2v_ctc_loss=0.722, task_loss=1.396, contrastive_loss=0.167, total=4164.1, n_correct=2750.48, ppl=4.43, accuracy=66.052, wps=11872.5, ups=1.43, wpb=8328.2, bsz=308.6, num_updates=22400, lr=9.44911e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=70, gb_free=17, wall=20057
2023-08-14 19:14:41 | INFO | train_inner | epoch 016:    402 / 1474 loss=2.005, trans_loss=4.902, nll_loss=2.142, w2v_ctc_loss=0.723, task_loss=1.512, contrastive_loss=0.18, total=4065.22, n_correct=2689.08, ppl=4.41, accuracy=66.148, wps=11731.1, ups=1.44, wpb=8130.4, bsz=286.4, num_updates=22500, lr=9.42809e-05, gnorm=0.518, clip=0, loss_scale=8, train_wall=69, gb_free=15.9, wall=20126
2023-08-14 19:15:52 | INFO | train_inner | epoch 016:    502 / 1474 loss=1.995, trans_loss=4.908, nll_loss=2.15, w2v_ctc_loss=0.714, task_loss=1.345, contrastive_loss=0.123, total=4181.93, n_correct=2766.08, ppl=4.44, accuracy=66.144, wps=11845.6, ups=1.42, wpb=8363.9, bsz=320.3, num_updates=22600, lr=9.40721e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=70, gb_free=15.5, wall=20197
2023-08-14 19:17:01 | INFO | train_inner | epoch 016:    602 / 1474 loss=1.997, trans_loss=4.909, nll_loss=2.151, w2v_ctc_loss=0.722, task_loss=1.402, contrastive_loss=0.087, total=4122.97, n_correct=2722.57, ppl=4.44, accuracy=66.034, wps=11827.2, ups=1.43, wpb=8245.9, bsz=299, num_updates=22700, lr=9.38647e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=69, gb_free=15.8, wall=20267
2023-08-14 19:18:10 | INFO | train_inner | epoch 016:    702 / 1474 loss=1.997, trans_loss=4.909, nll_loss=2.15, w2v_ctc_loss=0.723, task_loss=1.445, contrastive_loss=0.089, total=4093.15, n_correct=2700.98, ppl=4.44, accuracy=65.988, wps=11898.2, ups=1.45, wpb=8186.3, bsz=296.5, num_updates=22800, lr=9.36586e-05, gnorm=0.521, clip=0, loss_scale=8, train_wall=68, gb_free=17.6, wall=20336
2023-08-14 19:19:20 | INFO | train_inner | epoch 016:    802 / 1474 loss=1.996, trans_loss=4.903, nll_loss=2.144, w2v_ctc_loss=0.71, task_loss=1.347, contrastive_loss=0.151, total=4183.24, n_correct=2767.6, ppl=4.42, accuracy=66.159, wps=11986.5, ups=1.43, wpb=8366.5, bsz=312.1, num_updates=22900, lr=9.34539e-05, gnorm=0.53, clip=0, loss_scale=8, train_wall=69, gb_free=17.5, wall=20405
2023-08-14 19:20:29 | INFO | train_inner | epoch 016:    902 / 1474 loss=1.999, trans_loss=4.907, nll_loss=2.149, w2v_ctc_loss=0.716, task_loss=1.384, contrastive_loss=0.143, total=4150.23, n_correct=2743.52, ppl=4.43, accuracy=66.105, wps=11944.1, ups=1.44, wpb=8300.5, bsz=306.5, num_updates=23000, lr=9.32505e-05, gnorm=0.528, clip=0, loss_scale=8, train_wall=69, gb_free=11.8, wall=20475
2023-08-14 19:21:40 | INFO | train_inner | epoch 016:   1002 / 1474 loss=2.008, trans_loss=4.912, nll_loss=2.156, w2v_ctc_loss=0.731, task_loss=1.448, contrastive_loss=0.142, total=4116.59, n_correct=2711.86, ppl=4.46, accuracy=65.876, wps=11748.6, ups=1.43, wpb=8233.2, bsz=300.6, num_updates=23100, lr=9.30484e-05, gnorm=0.542, clip=0, loss_scale=8, train_wall=70, gb_free=16.5, wall=20545
2023-08-14 19:22:49 | INFO | train_inner | epoch 016:   1102 / 1474 loss=2.008, trans_loss=4.918, nll_loss=2.163, w2v_ctc_loss=0.732, task_loss=1.493, contrastive_loss=0.116, total=4112.71, n_correct=2706.18, ppl=4.48, accuracy=65.8, wps=11787.2, ups=1.43, wpb=8225.4, bsz=295.7, num_updates=23200, lr=9.28477e-05, gnorm=0.531, clip=0, loss_scale=8, train_wall=69, gb_free=11.8, wall=20615
2023-08-14 19:24:00 | INFO | train_inner | epoch 016:   1202 / 1474 loss=2.004, trans_loss=4.912, nll_loss=2.156, w2v_ctc_loss=0.704, task_loss=1.425, contrastive_loss=0.21, total=4161.11, n_correct=2745.84, ppl=4.46, accuracy=65.988, wps=11834.2, ups=1.42, wpb=8322.2, bsz=308.2, num_updates=23300, lr=9.26482e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=70, gb_free=15.3, wall=20685
2023-08-14 19:25:09 | INFO | train_inner | epoch 016:   1302 / 1474 loss=2.007, trans_loss=4.908, nll_loss=2.151, w2v_ctc_loss=0.726, task_loss=1.382, contrastive_loss=0.192, total=4149.14, n_correct=2739.69, ppl=4.44, accuracy=66.03, wps=11897.6, ups=1.43, wpb=8298.3, bsz=311.9, num_updates=23400, lr=9.245e-05, gnorm=0.532, clip=0, loss_scale=8, train_wall=69, gb_free=10.9, wall=20755
2023-08-14 19:26:20 | INFO | train_inner | epoch 016:   1402 / 1474 loss=1.997, trans_loss=4.908, nll_loss=2.15, w2v_ctc_loss=0.723, task_loss=1.336, contrastive_loss=0.12, total=4200.01, n_correct=2775.49, ppl=4.44, accuracy=66.083, wps=11928.3, ups=1.42, wpb=8400, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.525, clip=0, loss_scale=8, train_wall=70, gb_free=16.6, wall=20825
2023-08-14 19:27:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 19:27:35 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.972 | trans_loss 5.175 | nll_loss 2.448 | w2v_ctc_loss 1.327 | task_loss 4.65 | contrastive_loss 0.315 | total 4003.4 | n_correct 2654.2 | ppl 5.46 | accuracy 66.299 | uer 18.841 | wer 20.849 | raw_wer 20.849 | bleu 22.12 | wps 1984.8 | wpb 4003.4 | bsz 141.8 | num_updates 23572 | best_bleu 22.12
2023-08-14 19:27:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23572 updates
2023-08-14 19:27:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 19:27:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 19:28:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 16 @ 23572 updates, score 22.12) (writing took 29.917583376169205 seconds)
2023-08-14 19:28:05 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-14 19:28:05 | INFO | train | epoch 016 | loss 2.001 | trans_loss 4.907 | nll_loss 2.149 | w2v_ctc_loss 0.719 | task_loss 1.407 | contrastive_loss 0.146 | total 4137.99 | n_correct 2733.83 | ppl 4.44 | accuracy 66.067 | wps 11173.5 | ups 1.35 | wpb 8276 | bsz 305.5 | num_updates 23572 | lr 9.21121e-05 | gnorm 0.528 | clip 0 | loss_scale 8 | train_wall 1021 | gb_free 15.1 | wall 20931
2023-08-14 19:28:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 19:28:05 | INFO | fairseq.trainer | begin training epoch 17
2023-08-14 19:28:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 19:28:33 | INFO | train_inner | epoch 017:     28 / 1474 loss=2.001, trans_loss=4.895, nll_loss=2.134, w2v_ctc_loss=0.705, task_loss=1.442, contrastive_loss=0.256, total=4141.79, n_correct=2743.8, ppl=4.39, accuracy=66.247, wps=6218.8, ups=0.75, wpb=8283.6, bsz=301.5, num_updates=23600, lr=9.20575e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=70, gb_free=15.8, wall=20958
2023-08-14 19:29:42 | INFO | train_inner | epoch 017:    128 / 1474 loss=1.983, trans_loss=4.883, nll_loss=2.118, w2v_ctc_loss=0.709, task_loss=1.455, contrastive_loss=0.092, total=4110.88, n_correct=2734.37, ppl=4.34, accuracy=66.515, wps=11921.4, ups=1.45, wpb=8221.8, bsz=295.4, num_updates=23700, lr=9.1863e-05, gnorm=0.523, clip=0, loss_scale=8, train_wall=68, gb_free=16, wall=21027
2023-08-14 19:30:52 | INFO | train_inner | epoch 017:    228 / 1474 loss=1.997, trans_loss=4.885, nll_loss=2.121, w2v_ctc_loss=0.701, task_loss=1.321, contrastive_loss=0.254, total=4171.95, n_correct=2772.86, ppl=4.35, accuracy=66.464, wps=11934, ups=1.43, wpb=8343.9, bsz=320.4, num_updates=23800, lr=9.16698e-05, gnorm=0.524, clip=0, loss_scale=8, train_wall=69, gb_free=15.6, wall=21097
2023-08-14 19:32:01 | INFO | train_inner | epoch 017:    328 / 1474 loss=1.997, trans_loss=4.888, nll_loss=2.125, w2v_ctc_loss=0.705, task_loss=1.402, contrastive_loss=0.261, total=4157.94, n_correct=2760.94, ppl=4.36, accuracy=66.402, wps=11984, ups=1.44, wpb=8315.9, bsz=305, num_updates=23900, lr=9.14779e-05, gnorm=0.55, clip=0, loss_scale=8, train_wall=69, gb_free=14.1, wall=21167
2023-08-14 19:33:11 | INFO | train_inner | epoch 017:    428 / 1474 loss=1.984, trans_loss=4.89, nll_loss=2.127, w2v_ctc_loss=0.712, task_loss=1.401, contrastive_loss=0.09, total=4141.8, n_correct=2756.64, ppl=4.37, accuracy=66.557, wps=11870.6, ups=1.43, wpb=8283.6, bsz=306.7, num_updates=24000, lr=9.12871e-05, gnorm=0.587, clip=0, loss_scale=8, train_wall=69, gb_free=17, wall=21236
2023-08-14 19:33:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 19:33:35 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.972 | trans_loss 5.176 | nll_loss 2.443 | w2v_ctc_loss 1.333 | task_loss 4.665 | contrastive_loss 0.304 | total 4003.4 | n_correct 2653.3 | ppl 5.44 | accuracy 66.276 | uer 18.045 | wer 19.85 | raw_wer 19.85 | bleu 21.71 | wps 2097.2 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 22.12
2023-08-14 19:33:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-14 19:33:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-14 19:33:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-14 19:34:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 21.71) (writing took 43.37871568650007 seconds)
2023-08-14 19:35:30 | INFO | train_inner | epoch 017:    528 / 1474 loss=1.99, trans_loss=4.893, nll_loss=2.131, w2v_ctc_loss=0.71, task_loss=1.463, contrastive_loss=0.135, total=4180.09, n_correct=2772.09, ppl=4.38, accuracy=66.317, wps=6029.6, ups=0.72, wpb=8360.2, bsz=307.5, num_updates=24100, lr=9.10975e-05, gnorm=0.527, clip=0, loss_scale=8, train_wall=70, gb_free=16.8, wall=21375
2023-08-14 19:36:39 | INFO | train_inner | epoch 017:    628 / 1474 loss=1.985, trans_loss=4.894, nll_loss=2.132, w2v_ctc_loss=0.709, task_loss=1.415, contrastive_loss=0.086, total=4166.6, n_correct=2768.55, ppl=4.38, accuracy=66.446, wps=12004.1, ups=1.44, wpb=8333.2, bsz=302.3, num_updates=24200, lr=9.09091e-05, gnorm=0.579, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=21445
2023-08-14 19:37:49 | INFO | train_inner | epoch 017:    728 / 1474 loss=1.997, trans_loss=4.895, nll_loss=2.134, w2v_ctc_loss=0.723, task_loss=1.39, contrastive_loss=0.134, total=4168.97, n_correct=2763.55, ppl=4.39, accuracy=66.289, wps=12023.3, ups=1.44, wpb=8337.9, bsz=308.4, num_updates=24300, lr=9.07218e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=21514
2023-08-14 19:38:58 | INFO | train_inner | epoch 017:    828 / 1474 loss=1.986, trans_loss=4.892, nll_loss=2.129, w2v_ctc_loss=0.712, task_loss=1.414, contrastive_loss=0.098, total=4097.38, n_correct=2721.9, ppl=4.37, accuracy=66.43, wps=11844.4, ups=1.45, wpb=8194.8, bsz=297.3, num_updates=24400, lr=9.05357e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=69, gb_free=10.1, wall=21583
2023-08-14 19:40:06 | INFO | train_inner | epoch 017:    928 / 1474 loss=1.983, trans_loss=4.892, nll_loss=2.13, w2v_ctc_loss=0.706, task_loss=1.389, contrastive_loss=0.095, total=4105.01, n_correct=2724.57, ppl=4.38, accuracy=66.372, wps=12008.7, ups=1.46, wpb=8210, bsz=304.1, num_updates=24500, lr=9.03508e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=21651
2023-08-14 19:41:15 | INFO | train_inner | epoch 017:   1028 / 1474 loss=1.987, trans_loss=4.893, nll_loss=2.131, w2v_ctc_loss=0.714, task_loss=1.404, contrastive_loss=0.099, total=4105.88, n_correct=2723.78, ppl=4.38, accuracy=66.339, wps=11912.1, ups=1.45, wpb=8211.8, bsz=303.4, num_updates=24600, lr=9.0167e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=21720
2023-08-14 19:42:24 | INFO | train_inner | epoch 017:   1128 / 1474 loss=1.981, trans_loss=4.889, nll_loss=2.126, w2v_ctc_loss=0.703, task_loss=1.437, contrastive_loss=0.09, total=4095.58, n_correct=2725.24, ppl=4.36, accuracy=66.541, wps=11909.6, ups=1.45, wpb=8191.2, bsz=298.5, num_updates=24700, lr=8.99843e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=68, gb_free=15.2, wall=21789
2023-08-14 19:43:34 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2.011, trans_loss=4.901, nll_loss=2.141, w2v_ctc_loss=0.704, task_loss=1.38, contrastive_loss=0.33, total=4162.14, n_correct=2753.8, ppl=4.41, accuracy=66.163, wps=11875.3, ups=1.43, wpb=8324.3, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=70, gb_free=15.7, wall=21859
2023-08-14 19:44:43 | INFO | train_inner | epoch 017:   1328 / 1474 loss=1.992, trans_loss=4.896, nll_loss=2.136, w2v_ctc_loss=0.701, task_loss=1.399, contrastive_loss=0.172, total=4149.03, n_correct=2753.37, ppl=4.39, accuracy=66.362, wps=11987.7, ups=1.44, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=21929
2023-08-14 19:45:52 | INFO | train_inner | epoch 017:   1428 / 1474 loss=1.983, trans_loss=4.895, nll_loss=2.134, w2v_ctc_loss=0.705, task_loss=1.413, contrastive_loss=0.09, total=4117.13, n_correct=2732.4, ppl=4.39, accuracy=66.367, wps=11894.9, ups=1.44, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=21998
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:0')
2023-08-14 19:46:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:1')
2023-08-14 19:46:47 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.985 | trans_loss 5.178 | nll_loss 2.453 | w2v_ctc_loss 1.361 | task_loss 4.658 | contrastive_loss 0.318 | total 4003.4 | n_correct 2651.1 | ppl 5.47 | accuracy 66.221 | uer 18.992 | wer 20.931 | raw_wer 20.931 | bleu 21.76 | wps 2208.1 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 22.12
2023-08-14 19:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-08-14 19:46:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.7603.pt
2023-08-14 19:46:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.7603.pt
2023-08-14 19:47:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_21.7603.pt (epoch 17 @ 25046 updates, score 21.76) (writing took 22.525727853178978 seconds)
2023-08-14 19:47:10 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-14 19:47:10 | INFO | train | epoch 017 | loss 1.989 | trans_loss 4.891 | nll_loss 2.129 | w2v_ctc_loss 0.708 | task_loss 1.406 | contrastive_loss 0.143 | total 4138.65 | n_correct 2748.54 | ppl 4.37 | accuracy 66.412 | wps 10654.3 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.536 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 16.1 | wall 22076
2023-08-14 19:47:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 19:47:11 | INFO | fairseq.trainer | begin training epoch 18
2023-08-14 19:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 19:47:57 | INFO | train_inner | epoch 018:     54 / 1474 loss=1.979, trans_loss=4.882, nll_loss=2.117, w2v_ctc_loss=0.708, task_loss=1.433, contrastive_loss=0.099, total=4138.21, n_correct=2759.11, ppl=4.34, accuracy=66.674, wps=6648.8, ups=0.8, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=70, gb_free=17.5, wall=22122
2023-08-14 19:49:06 | INFO | train_inner | epoch 018:    154 / 1474 loss=1.978, trans_loss=4.866, nll_loss=2.096, w2v_ctc_loss=0.682, task_loss=1.338, contrastive_loss=0.22, total=4158.88, n_correct=2780.94, ppl=4.28, accuracy=66.868, wps=11979.4, ups=1.44, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=22192
2023-08-14 19:50:16 | INFO | train_inner | epoch 018:    254 / 1474 loss=1.967, trans_loss=4.866, nll_loss=2.096, w2v_ctc_loss=0.695, task_loss=1.368, contrastive_loss=0.09, total=4164.11, n_correct=2788.8, ppl=4.28, accuracy=66.972, wps=12019.7, ups=1.44, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=22261
2023-08-14 19:51:25 | INFO | train_inner | epoch 018:    354 / 1474 loss=1.971, trans_loss=4.874, nll_loss=2.106, w2v_ctc_loss=0.691, task_loss=1.429, contrastive_loss=0.103, total=4163.13, n_correct=2780.86, ppl=4.3, accuracy=66.797, wps=11995.1, ups=1.44, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.516, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=22330
2023-08-14 19:52:35 | INFO | train_inner | epoch 018:    454 / 1474 loss=1.987, trans_loss=4.881, nll_loss=2.115, w2v_ctc_loss=0.698, task_loss=1.501, contrastive_loss=0.196, total=4087.83, n_correct=2721.97, ppl=4.33, accuracy=66.587, wps=11704.2, ups=1.43, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=22400
2023-08-14 19:53:44 | INFO | train_inner | epoch 018:    554 / 1474 loss=1.961, trans_loss=4.862, nll_loss=2.092, w2v_ctc_loss=0.683, task_loss=1.265, contrastive_loss=0.103, total=4204.41, n_correct=2819.46, ppl=4.26, accuracy=67.06, wps=12143.1, ups=1.44, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=22469
2023-08-14 19:54:53 | INFO | train_inner | epoch 018:    654 / 1474 loss=1.991, trans_loss=4.885, nll_loss=2.121, w2v_ctc_loss=0.711, task_loss=1.448, contrastive_loss=0.175, total=4096.81, n_correct=2729.07, ppl=4.35, accuracy=66.615, wps=11871.2, ups=1.45, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=22538
2023-08-14 19:56:03 | INFO | train_inner | epoch 018:    754 / 1474 loss=1.992, trans_loss=4.881, nll_loss=2.115, w2v_ctc_loss=0.704, task_loss=1.34, contrastive_loss=0.263, total=4208.29, n_correct=2805.92, ppl=4.33, accuracy=66.676, wps=12067.8, ups=1.43, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=22608
2023-08-14 19:57:13 | INFO | train_inner | epoch 018:    854 / 1474 loss=1.973, trans_loss=4.877, nll_loss=2.11, w2v_ctc_loss=0.699, task_loss=1.429, contrastive_loss=0.082, total=4166.81, n_correct=2783.42, ppl=4.32, accuracy=66.8, wps=11969.8, ups=1.44, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=12.2, wall=22678
2023-08-14 19:58:22 | INFO | train_inner | epoch 018:    954 / 1474 loss=1.967, trans_loss=4.871, nll_loss=2.103, w2v_ctc_loss=0.687, task_loss=1.308, contrastive_loss=0.103, total=4142.65, n_correct=2771.34, ppl=4.3, accuracy=66.898, wps=12002.7, ups=1.45, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=14.5, wall=22747
2023-08-14 19:58:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 19:58:45 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.968 | trans_loss 5.166 | nll_loss 2.433 | w2v_ctc_loss 1.342 | task_loss 4.662 | contrastive_loss 0.312 | total 4003.4 | n_correct 2665.5 | ppl 5.4 | accuracy 66.581 | uer 18.323 | wer 20.257 | raw_wer 20.257 | bleu 22.44 | wps 2137.7 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 22.44
2023-08-14 19:58:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-14 19:58:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-14 19:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-14 19:59:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 22.44) (writing took 54.089639423415065 seconds)
2023-08-14 20:00:50 | INFO | train_inner | epoch 018:   1054 / 1474 loss=1.971, trans_loss=4.875, nll_loss=2.108, w2v_ctc_loss=0.69, task_loss=1.462, contrastive_loss=0.09, total=4137.77, n_correct=2761.54, ppl=4.31, accuracy=66.74, wps=5583.5, ups=0.67, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=22895
2023-08-14 20:01:59 | INFO | train_inner | epoch 018:   1154 / 1474 loss=1.981, trans_loss=4.868, nll_loss=2.099, w2v_ctc_loss=0.698, task_loss=1.336, contrastive_loss=0.197, total=4153.69, n_correct=2777.78, ppl=4.28, accuracy=66.875, wps=11956.5, ups=1.44, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=14.8, wall=22965
2023-08-14 20:03:09 | INFO | train_inner | epoch 018:   1254 / 1474 loss=1.977, trans_loss=4.885, nll_loss=2.121, w2v_ctc_loss=0.698, task_loss=1.512, contrastive_loss=0.085, total=4087.62, n_correct=2722.6, ppl=4.35, accuracy=66.606, wps=11795.5, ups=1.44, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=23034
2023-08-14 20:04:18 | INFO | train_inner | epoch 018:   1354 / 1474 loss=1.989, trans_loss=4.886, nll_loss=2.123, w2v_ctc_loss=0.718, task_loss=1.499, contrastive_loss=0.112, total=4070.69, n_correct=2707.87, ppl=4.36, accuracy=66.521, wps=11810.3, ups=1.45, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=23103
2023-08-14 20:05:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 20:05:28 | INFO | train_inner | epoch 018:   1455 / 1474 loss=1.981, trans_loss=4.883, nll_loss=2.118, w2v_ctc_loss=0.709, task_loss=1.503, contrastive_loss=0.091, total=4104.92, n_correct=2735.32, ppl=4.34, accuracy=66.635, wps=11684.1, ups=1.42, wpb=8209.8, bsz=294.5, num_updates=26500, lr=8.68744e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=70, gb_free=16.3, wall=23173
2023-08-14 20:05:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 20:06:04 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.969 | trans_loss 5.165 | nll_loss 2.431 | w2v_ctc_loss 1.347 | task_loss 4.642 | contrastive_loss 0.305 | total 4003.4 | n_correct 2660.2 | ppl 5.39 | accuracy 66.449 | uer 17.962 | wer 19.794 | raw_wer 19.794 | bleu 22.13 | wps 2225.6 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 22.44
2023-08-14 20:06:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-08-14 20:06:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.1305.pt
2023-08-14 20:06:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.1305.pt
2023-08-14 20:06:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.1305.pt (epoch 18 @ 26519 updates, score 22.13) (writing took 22.278163013979793 seconds)
2023-08-14 20:06:27 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-14 20:06:27 | INFO | train | epoch 018 | loss 1.978 | trans_loss 4.876 | nll_loss 2.109 | w2v_ctc_loss 0.697 | task_loss 1.407 | contrastive_loss 0.14 | total 4138.22 | n_correct 2762.53 | ppl 4.31 | accuracy 66.756 | wps 10541.8 | ups 1.27 | wpb 8276.4 | bsz 305.5 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.523 | clip 0 | loss_scale 16 | train_wall 1017 | gb_free 15.7 | wall 23232
2023-08-14 20:06:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 20:06:27 | INFO | fairseq.trainer | begin training epoch 19
2023-08-14 20:06:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 20:07:31 | INFO | train_inner | epoch 019:     81 / 1474 loss=1.969, trans_loss=4.858, nll_loss=2.086, w2v_ctc_loss=0.689, task_loss=1.4, contrastive_loss=0.146, total=4107.26, n_correct=2753.66, ppl=4.25, accuracy=67.044, wps=6659.6, ups=0.81, wpb=8214.5, bsz=297.5, num_updates=26600, lr=8.6711e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=12.3, wall=23296
2023-08-14 20:08:41 | INFO | train_inner | epoch 019:    181 / 1474 loss=1.972, trans_loss=4.859, nll_loss=2.087, w2v_ctc_loss=0.701, task_loss=1.317, contrastive_loss=0.138, total=4222.18, n_correct=2832.22, ppl=4.25, accuracy=67.08, wps=12035.6, ups=1.43, wpb=8444.4, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=70, gb_free=11.3, wall=23367
2023-08-14 20:09:51 | INFO | train_inner | epoch 019:    281 / 1474 loss=1.959, trans_loss=4.854, nll_loss=2.08, w2v_ctc_loss=0.686, task_loss=1.382, contrastive_loss=0.082, total=4187.37, n_correct=2815.77, ppl=4.23, accuracy=67.244, wps=12103.7, ups=1.45, wpb=8374.7, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=23436
2023-08-14 20:11:00 | INFO | train_inner | epoch 019:    381 / 1474 loss=1.971, trans_loss=4.856, nll_loss=2.083, w2v_ctc_loss=0.684, task_loss=1.389, contrastive_loss=0.188, total=4170.67, n_correct=2796.85, ppl=4.24, accuracy=67.06, wps=12083.4, ups=1.45, wpb=8341.3, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=23505
2023-08-14 20:12:08 | INFO | train_inner | epoch 019:    481 / 1474 loss=1.97, trans_loss=4.864, nll_loss=2.093, w2v_ctc_loss=0.699, task_loss=1.443, contrastive_loss=0.097, total=4115.22, n_correct=2756.76, ppl=4.27, accuracy=66.989, wps=11959.6, ups=1.45, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=23574
2023-08-14 20:13:18 | INFO | train_inner | epoch 019:    581 / 1474 loss=1.965, trans_loss=4.856, nll_loss=2.084, w2v_ctc_loss=0.683, task_loss=1.377, contrastive_loss=0.162, total=4129.22, n_correct=2771.01, ppl=4.24, accuracy=67.107, wps=11884, ups=1.44, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=23643
2023-08-14 20:14:27 | INFO | train_inner | epoch 019:    681 / 1474 loss=1.956, trans_loss=4.862, nll_loss=2.092, w2v_ctc_loss=0.674, task_loss=1.281, contrastive_loss=0.088, total=4197.2, n_correct=2816.8, ppl=4.26, accuracy=67.111, wps=12168, ups=1.45, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=68, gb_free=14.3, wall=23712
2023-08-14 20:15:36 | INFO | train_inner | epoch 019:    781 / 1474 loss=1.967, trans_loss=4.861, nll_loss=2.09, w2v_ctc_loss=0.694, task_loss=1.415, contrastive_loss=0.101, total=4142.6, n_correct=2777.66, ppl=4.26, accuracy=67.051, wps=11962.9, ups=1.44, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=23781
2023-08-14 20:16:46 | INFO | train_inner | epoch 019:    881 / 1474 loss=1.969, trans_loss=4.869, nll_loss=2.099, w2v_ctc_loss=0.695, task_loss=1.439, contrastive_loss=0.085, total=4153.47, n_correct=2777.09, ppl=4.28, accuracy=66.862, wps=11957, ups=1.44, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=23851
2023-08-14 20:17:56 | INFO | train_inner | epoch 019:    981 / 1474 loss=1.989, trans_loss=4.875, nll_loss=2.108, w2v_ctc_loss=0.686, task_loss=1.401, contrastive_loss=0.32, total=4101.29, n_correct=2740.29, ppl=4.31, accuracy=66.815, wps=11642.7, ups=1.42, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=70, gb_free=16.4, wall=23921
2023-08-14 20:19:05 | INFO | train_inner | epoch 019:   1081 / 1474 loss=1.971, trans_loss=4.872, nll_loss=2.103, w2v_ctc_loss=0.687, task_loss=1.502, contrastive_loss=0.127, total=4036.97, n_correct=2700.29, ppl=4.3, accuracy=66.889, wps=11708.1, ups=1.45, wpb=8073.9, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=14.3, wall=23990
2023-08-14 20:20:15 | INFO | train_inner | epoch 019:   1181 / 1474 loss=1.985, trans_loss=4.871, nll_loss=2.103, w2v_ctc_loss=0.698, task_loss=1.43, contrastive_loss=0.21, total=4137.49, n_correct=2763.91, ppl=4.3, accuracy=66.802, wps=11883.9, ups=1.44, wpb=8275, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=14.4, wall=24060
2023-08-14 20:21:23 | INFO | train_inner | epoch 019:   1281 / 1474 loss=1.97, trans_loss=4.87, nll_loss=2.102, w2v_ctc_loss=0.689, task_loss=1.425, contrastive_loss=0.109, total=4141.89, n_correct=2771.55, ppl=4.29, accuracy=66.915, wps=12109.5, ups=1.46, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=24128
2023-08-14 20:22:32 | INFO | train_inner | epoch 019:   1381 / 1474 loss=1.969, trans_loss=4.866, nll_loss=2.096, w2v_ctc_loss=0.695, task_loss=1.435, contrastive_loss=0.095, total=4133.26, n_correct=2768.76, ppl=4.28, accuracy=66.987, wps=11937.1, ups=1.44, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=24198
2023-08-14 20:23:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 20:24:01 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.961 | trans_loss 5.162 | nll_loss 2.43 | w2v_ctc_loss 1.324 | task_loss 4.63 | contrastive_loss 0.311 | total 4003.4 | n_correct 2665.5 | ppl 5.39 | accuracy 66.581 | uer 18.342 | wer 20.335 | raw_wer 20.335 | bleu 22.16 | wps 2143 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 22.44
2023-08-14 20:24:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-08-14 20:24:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.1608.pt
2023-08-14 20:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.1608.pt
2023-08-14 20:24:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.1608.pt (epoch 19 @ 27993 updates, score 22.16) (writing took 21.39236611686647 seconds)
2023-08-14 20:24:22 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-14 20:24:22 | INFO | train | epoch 019 | loss 1.97 | trans_loss 4.863 | nll_loss 2.092 | w2v_ctc_loss 0.69 | task_loss 1.406 | contrastive_loss 0.139 | total 4138.65 | n_correct 2773.41 | ppl 4.26 | accuracy 67.012 | wps 11344.4 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.526 | clip 0 | loss_scale 16 | train_wall 1014 | gb_free 17.1 | wall 24308
2023-08-14 20:24:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 20:24:23 | INFO | fairseq.trainer | begin training epoch 20
2023-08-14 20:24:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 20:24:35 | INFO | train_inner | epoch 020:      7 / 1474 loss=1.966, trans_loss=4.856, nll_loss=2.084, w2v_ctc_loss=0.682, task_loss=1.418, contrastive_loss=0.176, total=4119.08, n_correct=2766.92, ppl=4.24, accuracy=67.173, wps=6714.5, ups=0.82, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=24320
2023-08-14 20:24:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 20:24:59 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.95 | trans_loss 5.159 | nll_loss 2.425 | w2v_ctc_loss 1.3 | task_loss 4.654 | contrastive_loss 0.306 | total 4003.4 | n_correct 2668.7 | ppl 5.37 | accuracy 66.661 | uer 18.17 | wer 20.115 | raw_wer 20.115 | bleu 22.4 | wps 2054 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 22.44
2023-08-14 20:24:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-14 20:24:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-14 20:25:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-14 20:25:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 22.4) (writing took 41.24098980426788 seconds)
2023-08-14 20:26:54 | INFO | train_inner | epoch 020:    107 / 1474 loss=1.946, trans_loss=4.837, nll_loss=2.058, w2v_ctc_loss=0.669, task_loss=1.359, contrastive_loss=0.1, total=4195.03, n_correct=2835.34, ppl=4.17, accuracy=67.588, wps=6023.6, ups=0.72, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=24460
2023-08-14 20:28:04 | INFO | train_inner | epoch 020:    207 / 1474 loss=1.961, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.683, task_loss=1.459, contrastive_loss=0.153, total=4154.14, n_correct=2796.49, ppl=4.2, accuracy=67.318, wps=11940.8, ups=1.44, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=24529
2023-08-14 20:29:13 | INFO | train_inner | epoch 020:    307 / 1474 loss=1.946, trans_loss=4.841, nll_loss=2.064, w2v_ctc_loss=0.675, task_loss=1.268, contrastive_loss=0.09, total=4188.05, n_correct=2828.83, ppl=4.18, accuracy=67.545, wps=12109.2, ups=1.45, wpb=8376.1, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=24598
2023-08-14 20:30:22 | INFO | train_inner | epoch 020:    407 / 1474 loss=1.951, trans_loss=4.841, nll_loss=2.063, w2v_ctc_loss=0.675, task_loss=1.425, contrastive_loss=0.089, total=4115.16, n_correct=2776.33, ppl=4.18, accuracy=67.466, wps=11888.2, ups=1.44, wpb=8230.3, bsz=297, num_updates=28400, lr=8.39181e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=24668
2023-08-14 20:31:32 | INFO | train_inner | epoch 020:    507 / 1474 loss=1.961, trans_loss=4.851, nll_loss=2.076, w2v_ctc_loss=0.673, task_loss=1.44, contrastive_loss=0.176, total=4108.46, n_correct=2765.86, ppl=4.22, accuracy=67.321, wps=11840, ups=1.44, wpb=8216.9, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=24737
2023-08-14 20:32:41 | INFO | train_inner | epoch 020:    607 / 1474 loss=1.968, trans_loss=4.851, nll_loss=2.076, w2v_ctc_loss=0.682, task_loss=1.477, contrastive_loss=0.178, total=4094.9, n_correct=2753.13, ppl=4.22, accuracy=67.233, wps=11851.1, ups=1.45, wpb=8189.8, bsz=296.1, num_updates=28600, lr=8.36242e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=11.5, wall=24806
2023-08-14 20:33:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 20:33:51 | INFO | train_inner | epoch 020:    708 / 1474 loss=1.96, trans_loss=4.853, nll_loss=2.079, w2v_ctc_loss=0.691, task_loss=1.417, contrastive_loss=0.083, total=4132.33, n_correct=2776.82, ppl=4.22, accuracy=67.197, wps=11826.8, ups=1.43, wpb=8264.7, bsz=299.1, num_updates=28700, lr=8.34784e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=24876
2023-08-14 20:35:00 | INFO | train_inner | epoch 020:    808 / 1474 loss=1.958, trans_loss=4.854, nll_loss=2.081, w2v_ctc_loss=0.686, task_loss=1.39, contrastive_loss=0.086, total=4146.78, n_correct=2789.19, ppl=4.23, accuracy=67.262, wps=11942.3, ups=1.44, wpb=8293.6, bsz=307.3, num_updates=28800, lr=8.33333e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=14.9, wall=24945
2023-08-14 20:36:10 | INFO | train_inner | epoch 020:    908 / 1474 loss=1.988, trans_loss=4.859, nll_loss=2.087, w2v_ctc_loss=0.68, task_loss=1.34, contrastive_loss=0.377, total=4161, n_correct=2788.92, ppl=4.25, accuracy=67.025, wps=11840.3, ups=1.42, wpb=8322, bsz=323.2, num_updates=28900, lr=8.3189e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=70, gb_free=17.2, wall=25016
2023-08-14 20:37:20 | INFO | train_inner | epoch 020:   1008 / 1474 loss=1.952, trans_loss=4.851, nll_loss=2.077, w2v_ctc_loss=0.671, task_loss=1.401, contrastive_loss=0.091, total=4168.14, n_correct=2807.25, ppl=4.22, accuracy=67.35, wps=11998.2, ups=1.44, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=25085
2023-08-14 20:38:29 | INFO | train_inner | epoch 020:   1108 / 1474 loss=1.971, trans_loss=4.853, nll_loss=2.08, w2v_ctc_loss=0.679, task_loss=1.357, contrastive_loss=0.23, total=4166.49, n_correct=2802.81, ppl=4.23, accuracy=67.27, wps=11982.1, ups=1.44, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=14.5, wall=25155
2023-08-14 20:39:38 | INFO | train_inner | epoch 020:   1208 / 1474 loss=1.961, trans_loss=4.847, nll_loss=2.072, w2v_ctc_loss=0.693, task_loss=1.554, contrastive_loss=0.08, total=4029.18, n_correct=2709.03, ppl=4.2, accuracy=67.235, wps=11692, ups=1.45, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=11.4, wall=25224
2023-08-14 20:40:48 | INFO | train_inner | epoch 020:   1308 / 1474 loss=1.958, trans_loss=4.854, nll_loss=2.081, w2v_ctc_loss=0.682, task_loss=1.479, contrastive_loss=0.085, total=4123.21, n_correct=2771.26, ppl=4.23, accuracy=67.211, wps=11830.3, ups=1.43, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=25293
2023-08-14 20:41:58 | INFO | train_inner | epoch 020:   1408 / 1474 loss=1.962, trans_loss=4.856, nll_loss=2.084, w2v_ctc_loss=0.686, task_loss=1.486, contrastive_loss=0.084, total=4116.28, n_correct=2761.76, ppl=4.24, accuracy=67.094, wps=11846.6, ups=1.44, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=25363
2023-08-14 20:42:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 20:43:07 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.941 | trans_loss 5.167 | nll_loss 2.429 | w2v_ctc_loss 1.257 | task_loss 4.649 | contrastive_loss 0.304 | total 4003.4 | n_correct 2664.1 | ppl 5.38 | accuracy 66.546 | uer 17.639 | wer 19.559 | raw_wer 19.559 | bleu 22.54 | wps 2093.8 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 22.54
2023-08-14 20:43:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-08-14 20:43:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 20:43:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 20:43:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 20 @ 29466 updates, score 22.54) (writing took 29.058418231084943 seconds)
2023-08-14 20:43:37 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-14 20:43:37 | INFO | train | epoch 020 | loss 1.96 | trans_loss 4.85 | nll_loss 2.075 | w2v_ctc_loss 0.68 | task_loss 1.407 | contrastive_loss 0.137 | total 4138.55 | n_correct 2784.91 | ppl 4.21 | accuracy 67.292 | wps 10562.2 | ups 1.28 | wpb 8277.1 | bsz 305.6 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.525 | clip 0 | loss_scale 16 | train_wall 1016 | gb_free 15.9 | wall 25462
2023-08-14 20:43:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 20:43:37 | INFO | fairseq.trainer | begin training epoch 21
2023-08-14 20:43:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 20:44:09 | INFO | train_inner | epoch 021:     34 / 1474 loss=1.965, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.673, task_loss=1.34, contrastive_loss=0.205, total=4152.26, n_correct=2792.34, ppl=4.22, accuracy=67.249, wps=6304.3, ups=0.76, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=25495
2023-08-14 20:45:18 | INFO | train_inner | epoch 021:    134 / 1474 loss=1.953, trans_loss=4.829, nll_loss=2.049, w2v_ctc_loss=0.667, task_loss=1.314, contrastive_loss=0.196, total=4195.08, n_correct=2839.3, ppl=4.14, accuracy=67.682, wps=12149.2, ups=1.45, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=25564
2023-08-14 20:46:28 | INFO | train_inner | epoch 021:    234 / 1474 loss=1.943, trans_loss=4.832, nll_loss=2.052, w2v_ctc_loss=0.66, task_loss=1.341, contrastive_loss=0.149, total=4155.31, n_correct=2816.08, ppl=4.15, accuracy=67.771, wps=11991.1, ups=1.44, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=25633
2023-08-14 20:47:38 | INFO | train_inner | epoch 021:    334 / 1474 loss=1.956, trans_loss=4.838, nll_loss=2.06, w2v_ctc_loss=0.678, task_loss=1.394, contrastive_loss=0.153, total=4151.51, n_correct=2801.03, ppl=4.17, accuracy=67.47, wps=11871.9, ups=1.43, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=25703
2023-08-14 20:48:46 | INFO | train_inner | epoch 021:    434 / 1474 loss=1.941, trans_loss=4.832, nll_loss=2.052, w2v_ctc_loss=0.665, task_loss=1.36, contrastive_loss=0.077, total=4180.85, n_correct=2832.97, ppl=4.15, accuracy=67.761, wps=12151.1, ups=1.45, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=25772
2023-08-14 20:49:56 | INFO | train_inner | epoch 021:    534 / 1474 loss=1.943, trans_loss=4.827, nll_loss=2.045, w2v_ctc_loss=0.673, task_loss=1.461, contrastive_loss=0.076, total=4083.98, n_correct=2769.21, ppl=4.13, accuracy=67.807, wps=11759.9, ups=1.44, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=12.7, wall=25841
2023-08-14 20:49:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 20:50:21 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.167 | nll_loss 2.435 | w2v_ctc_loss 1.331 | task_loss 4.637 | contrastive_loss 0.3 | total 4003.4 | n_correct 2662.2 | ppl 5.41 | accuracy 66.498 | uer 18.008 | wer 19.977 | raw_wer 19.977 | bleu 22.46 | wps 2027.7 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 22.54
2023-08-14 20:50:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-14 20:50:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-14 20:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-14 20:51:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 22.46) (writing took 39.33694492094219 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:0')
2023-08-14 20:52:11 | INFO | train_inner | epoch 021:    634 / 1474 loss=1.958, trans_loss=4.834, nll_loss=2.055, w2v_ctc_loss=0.666, task_loss=1.391, contrastive_loss=0.248, total=4215.41, n_correct=2848.8, ppl=4.15, accuracy=67.581, wps=6237.8, ups=0.74, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=10.8, wall=25976
2023-08-14 20:53:21 | INFO | train_inner | epoch 021:    734 / 1474 loss=1.95, trans_loss=4.842, nll_loss=2.066, w2v_ctc_loss=0.669, task_loss=1.4, contrastive_loss=0.109, total=4152.97, n_correct=2803.63, ppl=4.19, accuracy=67.509, wps=11911.2, ups=1.43, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=26046
2023-08-14 20:54:30 | INFO | train_inner | epoch 021:    834 / 1474 loss=1.959, trans_loss=4.849, nll_loss=2.073, w2v_ctc_loss=0.679, task_loss=1.487, contrastive_loss=0.122, total=4066.93, n_correct=2737.81, ppl=4.21, accuracy=67.319, wps=11692.1, ups=1.44, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=26116
2023-08-14 20:55:39 | INFO | train_inner | epoch 021:    934 / 1474 loss=1.945, trans_loss=4.835, nll_loss=2.056, w2v_ctc_loss=0.67, task_loss=1.409, contrastive_loss=0.093, total=4103.34, n_correct=2772.3, ppl=4.16, accuracy=67.562, wps=11892, ups=1.45, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=13.7, wall=26185
2023-08-14 20:56:48 | INFO | train_inner | epoch 021:   1034 / 1474 loss=1.95, trans_loss=4.845, nll_loss=2.069, w2v_ctc_loss=0.674, task_loss=1.434, contrastive_loss=0.091, total=4099.86, n_correct=2766.73, ppl=4.2, accuracy=67.484, wps=11885.4, ups=1.45, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=11, wall=26254
2023-08-14 20:57:58 | INFO | train_inner | epoch 021:   1134 / 1474 loss=1.952, trans_loss=4.837, nll_loss=2.059, w2v_ctc_loss=0.679, task_loss=1.513, contrastive_loss=0.094, total=4120.75, n_correct=2784.53, ppl=4.17, accuracy=67.573, wps=11856.6, ups=1.44, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=26323
2023-08-14 20:59:07 | INFO | train_inner | epoch 021:   1234 / 1474 loss=1.954, trans_loss=4.841, nll_loss=2.065, w2v_ctc_loss=0.671, task_loss=1.337, contrastive_loss=0.146, total=4154.73, n_correct=2802.63, ppl=4.18, accuracy=67.456, wps=11997.9, ups=1.44, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=12.3, wall=26393
2023-08-14 21:00:17 | INFO | train_inner | epoch 021:   1334 / 1474 loss=1.949, trans_loss=4.839, nll_loss=2.063, w2v_ctc_loss=0.672, task_loss=1.363, contrastive_loss=0.108, total=4147.17, n_correct=2804.72, ppl=4.18, accuracy=67.63, wps=11920.7, ups=1.44, wpb=8294.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=26462
2023-08-14 21:01:27 | INFO | train_inner | epoch 021:   1434 / 1474 loss=1.969, trans_loss=4.849, nll_loss=2.075, w2v_ctc_loss=0.692, task_loss=1.469, contrastive_loss=0.158, total=4133.93, n_correct=2777.28, ppl=4.21, accuracy=67.183, wps=11786.9, ups=1.43, wpb=8267.9, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=70, gb_free=15.2, wall=26532
2023-08-14 21:01:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:3')
2023-08-14 21:02:18 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.168 | nll_loss 2.434 | w2v_ctc_loss 1.291 | task_loss 4.647 | contrastive_loss 0.31 | total 4003.4 | n_correct 2663.6 | ppl 5.4 | accuracy 66.533 | uer 18.4 | wer 20.544 | raw_wer 20.544 | bleu 22.47 | wps 2255.1 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 22.54
2023-08-14 21:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-08-14 21:02:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.4708.pt
2023-08-14 21:02:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.4708.pt
2023-08-14 21:02:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.4708.pt (epoch 21 @ 30940 updates, score 22.47) (writing took 22.01768814213574 seconds)
2023-08-14 21:02:40 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-14 21:02:40 | INFO | train | epoch 021 | loss 1.952 | trans_loss 4.838 | nll_loss 2.06 | w2v_ctc_loss 0.672 | task_loss 1.406 | contrastive_loss 0.135 | total 4138.65 | n_correct 2796.03 | ppl 4.17 | accuracy 67.559 | wps 10669.2 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.53 | clip 0 | loss_scale 32 | train_wall 1017 | gb_free 15.1 | wall 26606
2023-08-14 21:02:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 21:02:41 | INFO | fairseq.trainer | begin training epoch 22
2023-08-14 21:02:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 21:03:30 | INFO | train_inner | epoch 022:     60 / 1474 loss=1.94, trans_loss=4.823, nll_loss=2.041, w2v_ctc_loss=0.67, task_loss=1.431, contrastive_loss=0.075, total=4128.84, n_correct=2805.4, ppl=4.11, accuracy=67.946, wps=6731.7, ups=0.82, wpb=8257.7, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=13.8, wall=26655
2023-08-14 21:04:40 | INFO | train_inner | epoch 022:    160 / 1474 loss=1.946, trans_loss=4.822, nll_loss=2.038, w2v_ctc_loss=0.668, task_loss=1.417, contrastive_loss=0.158, total=4123.35, n_correct=2798.95, ppl=4.11, accuracy=67.88, wps=11795.1, ups=1.43, wpb=8246.7, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=14.4, wall=26725
2023-08-14 21:05:49 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.929, trans_loss=4.815, nll_loss=2.031, w2v_ctc_loss=0.654, task_loss=1.239, contrastive_loss=0.099, total=4267.16, n_correct=2908.1, ppl=4.09, accuracy=68.151, wps=12249.4, ups=1.44, wpb=8534.3, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.508, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=26794
2023-08-14 21:07:00 | INFO | train_inner | epoch 022:    360 / 1474 loss=1.961, trans_loss=4.829, nll_loss=2.048, w2v_ctc_loss=0.669, task_loss=1.425, contrastive_loss=0.253, total=4180.09, n_correct=2828.4, ppl=4.14, accuracy=67.664, wps=11855.8, ups=1.42, wpb=8360.2, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=70, gb_free=17.3, wall=26865
2023-08-14 21:08:09 | INFO | train_inner | epoch 022:    460 / 1474 loss=1.949, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.667, task_loss=1.478, contrastive_loss=0.14, total=4132.62, n_correct=2802.11, ppl=4.13, accuracy=67.805, wps=11914.7, ups=1.44, wpb=8265.2, bsz=297.2, num_updates=31400, lr=7.98087e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=26934
2023-08-14 21:09:19 | INFO | train_inner | epoch 022:    560 / 1474 loss=1.936, trans_loss=4.821, nll_loss=2.038, w2v_ctc_loss=0.663, task_loss=1.415, contrastive_loss=0.087, total=4155.5, n_correct=2820.01, ppl=4.11, accuracy=67.862, wps=11884.4, ups=1.43, wpb=8311, bsz=307.3, num_updates=31500, lr=7.96819e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=27004
2023-08-14 21:09:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 21:10:28 | INFO | train_inner | epoch 022:    661 / 1474 loss=1.936, trans_loss=4.817, nll_loss=2.033, w2v_ctc_loss=0.65, task_loss=1.339, contrastive_loss=0.171, total=4139.27, n_correct=2817.04, ppl=4.09, accuracy=68.056, wps=11978, ups=1.45, wpb=8278.5, bsz=311.7, num_updates=31600, lr=7.95557e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=27073
2023-08-14 21:11:38 | INFO | train_inner | epoch 022:    761 / 1474 loss=1.94, trans_loss=4.823, nll_loss=2.04, w2v_ctc_loss=0.669, task_loss=1.444, contrastive_loss=0.088, total=4167.89, n_correct=2828.87, ppl=4.11, accuracy=67.873, wps=11904.8, ups=1.43, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=70, gb_free=12.4, wall=27143
2023-08-14 21:12:48 | INFO | train_inner | epoch 022:    861 / 1474 loss=1.945, trans_loss=4.833, nll_loss=2.054, w2v_ctc_loss=0.671, task_loss=1.524, contrastive_loss=0.076, total=4075.79, n_correct=2754.67, ppl=4.15, accuracy=67.586, wps=11708, ups=1.44, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=27213
2023-08-14 21:13:57 | INFO | train_inner | epoch 022:    961 / 1474 loss=1.935, trans_loss=4.821, nll_loss=2.038, w2v_ctc_loss=0.663, task_loss=1.415, contrastive_loss=0.075, total=4134.72, n_correct=2807.33, ppl=4.11, accuracy=67.896, wps=11930.7, ups=1.44, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=13.8, wall=27282
2023-08-14 21:15:06 | INFO | train_inner | epoch 022:   1061 / 1474 loss=1.946, trans_loss=4.82, nll_loss=2.037, w2v_ctc_loss=0.655, task_loss=1.341, contrastive_loss=0.246, total=4160.57, n_correct=2827.44, ppl=4.1, accuracy=67.958, wps=12036.5, ups=1.45, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=27352
2023-08-14 21:15:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 21:15:31 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.965 | trans_loss 5.161 | nll_loss 2.429 | w2v_ctc_loss 1.347 | task_loss 4.64 | contrastive_loss 0.307 | total 4003.4 | n_correct 2667.3 | ppl 5.39 | accuracy 66.626 | uer 18.231 | wer 20.286 | raw_wer 20.286 | bleu 22.15 | wps 2104.8 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 22.54
2023-08-14 21:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-14 21:15:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-14 21:15:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-14 21:16:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 22.15) (writing took 39.63823855482042 seconds)
2023-08-14 21:17:21 | INFO | train_inner | epoch 022:   1161 / 1474 loss=1.954, trans_loss=4.842, nll_loss=2.065, w2v_ctc_loss=0.673, task_loss=1.45, contrastive_loss=0.127, total=4099.59, n_correct=2769.58, ppl=4.18, accuracy=67.557, wps=6100.8, ups=0.74, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=27486
2023-08-14 21:18:30 | INFO | train_inner | epoch 022:   1261 / 1474 loss=1.948, trans_loss=4.84, nll_loss=2.063, w2v_ctc_loss=0.67, task_loss=1.3, contrastive_loss=0.122, total=4182.05, n_correct=2826.63, ppl=4.18, accuracy=67.59, wps=12084.4, ups=1.44, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=27555
2023-08-14 21:19:39 | INFO | train_inner | epoch 022:   1361 / 1474 loss=1.942, trans_loss=4.823, nll_loss=2.041, w2v_ctc_loss=0.66, task_loss=1.407, contrastive_loss=0.147, total=4062.31, n_correct=2757.72, ppl=4.12, accuracy=67.886, wps=11795.6, ups=1.45, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=68, gb_free=14.7, wall=27624
2023-08-14 21:20:48 | INFO | train_inner | epoch 022:   1461 / 1474 loss=1.951, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.68, task_loss=1.502, contrastive_loss=0.093, total=4081.88, n_correct=2756.56, ppl=4.17, accuracy=67.532, wps=11794.4, ups=1.44, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=27693
2023-08-14 21:20:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 21:21:22 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.946 | trans_loss 5.16 | nll_loss 2.425 | w2v_ctc_loss 1.29 | task_loss 4.604 | contrastive_loss 0.302 | total 4003.4 | n_correct 2670.5 | ppl 5.37 | accuracy 66.706 | uer 18.148 | wer 20.174 | raw_wer 20.174 | bleu 22.51 | wps 2058.7 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 22.54
2023-08-14 21:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-08-14 21:21:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.5102.pt
2023-08-14 21:21:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.5102.pt
2023-08-14 21:21:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.5102.pt (epoch 22 @ 32413 updates, score 22.51) (writing took 17.684811739251018 seconds)
2023-08-14 21:21:40 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-14 21:21:43 | INFO | train | epoch 022 | loss 1.944 | trans_loss 4.826 | nll_loss 2.045 | w2v_ctc_loss 0.666 | task_loss 1.406 | contrastive_loss 0.132 | total 4138.38 | n_correct 2806.49 | ppl 4.13 | accuracy 67.816 | wps 10670.2 | ups 1.29 | wpb 8276.8 | bsz 305.6 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.523 | clip 0 | loss_scale 16 | train_wall 1017 | gb_free 11.3 | wall 27748
2023-08-14 21:21:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 21:21:43 | INFO | fairseq.trainer | begin training epoch 23
2023-08-14 21:21:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 21:22:52 | INFO | train_inner | epoch 023:     87 / 1474 loss=1.931, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.664, task_loss=1.435, contrastive_loss=0.082, total=4096.09, n_correct=2793.51, ppl=4.06, accuracy=68.199, wps=6615.4, ups=0.81, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=27817
2023-08-14 21:24:01 | INFO | train_inner | epoch 023:    187 / 1474 loss=1.928, trans_loss=4.803, nll_loss=2.014, w2v_ctc_loss=0.656, task_loss=1.495, contrastive_loss=0.08, total=4107.77, n_correct=2804.37, ppl=4.04, accuracy=68.27, wps=11814.4, ups=1.44, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=27887
2023-08-14 21:25:12 | INFO | train_inner | epoch 023:    287 / 1474 loss=1.937, trans_loss=4.817, nll_loss=2.032, w2v_ctc_loss=0.65, task_loss=1.407, contrastive_loss=0.159, total=4153.12, n_correct=2827.5, ppl=4.09, accuracy=68.081, wps=11831.4, ups=1.42, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=70, gb_free=16.7, wall=27957
2023-08-14 21:26:20 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.928, trans_loss=4.807, nll_loss=2.018, w2v_ctc_loss=0.656, task_loss=1.462, contrastive_loss=0.072, total=4116.7, n_correct=2807.34, ppl=4.05, accuracy=68.194, wps=11962.8, ups=1.45, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=68, gb_free=15, wall=28026
2023-08-14 21:27:30 | INFO | train_inner | epoch 023:    487 / 1474 loss=1.933, trans_loss=4.814, nll_loss=2.029, w2v_ctc_loss=0.651, task_loss=1.362, contrastive_loss=0.129, total=4157.6, n_correct=2830.57, ppl=4.08, accuracy=68.082, wps=11978, ups=1.44, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=28095
2023-08-14 21:28:39 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.924, trans_loss=4.807, nll_loss=2.019, w2v_ctc_loss=0.654, task_loss=1.328, contrastive_loss=0.077, total=4173.42, n_correct=2851.55, ppl=4.05, accuracy=68.326, wps=12083.7, ups=1.45, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=12.2, wall=28164
2023-08-14 21:29:48 | INFO | train_inner | epoch 023:    687 / 1474 loss=1.937, trans_loss=4.817, nll_loss=2.033, w2v_ctc_loss=0.66, task_loss=1.405, contrastive_loss=0.118, total=4137.82, n_correct=2813.39, ppl=4.09, accuracy=67.992, wps=11969.4, ups=1.45, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=28233
2023-08-14 21:30:57 | INFO | train_inner | epoch 023:    787 / 1474 loss=1.937, trans_loss=4.819, nll_loss=2.036, w2v_ctc_loss=0.664, task_loss=1.417, contrastive_loss=0.096, total=4150.99, n_correct=2821.9, ppl=4.1, accuracy=67.981, wps=11992.5, ups=1.44, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=28303
2023-08-14 21:32:07 | INFO | train_inner | epoch 023:    887 / 1474 loss=1.935, trans_loss=4.81, nll_loss=2.024, w2v_ctc_loss=0.655, task_loss=1.283, contrastive_loss=0.175, total=4181.99, n_correct=2849.27, ppl=4.07, accuracy=68.132, wps=12033.6, ups=1.44, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=28372
2023-08-14 21:33:17 | INFO | train_inner | epoch 023:    987 / 1474 loss=1.953, trans_loss=4.816, nll_loss=2.031, w2v_ctc_loss=0.653, task_loss=1.4, contrastive_loss=0.331, total=4168.73, n_correct=2836.83, ppl=4.09, accuracy=68.05, wps=11952.1, ups=1.43, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=10.5, wall=28442
2023-08-14 21:34:26 | INFO | train_inner | epoch 023:   1087 / 1474 loss=1.94, trans_loss=4.821, nll_loss=2.037, w2v_ctc_loss=0.67, task_loss=1.499, contrastive_loss=0.084, total=4088.49, n_correct=2777.48, ppl=4.1, accuracy=67.934, wps=11756.4, ups=1.44, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=28511
2023-08-14 21:35:36 | INFO | train_inner | epoch 023:   1187 / 1474 loss=1.936, trans_loss=4.824, nll_loss=2.042, w2v_ctc_loss=0.666, task_loss=1.396, contrastive_loss=0.077, total=4162.7, n_correct=2827.26, ppl=4.12, accuracy=67.919, wps=11938.7, ups=1.43, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=28581
2023-08-14 21:36:45 | INFO | train_inner | epoch 023:   1287 / 1474 loss=1.929, trans_loss=4.816, nll_loss=2.031, w2v_ctc_loss=0.654, task_loss=1.367, contrastive_loss=0.088, total=4135.53, n_correct=2814.83, ppl=4.09, accuracy=68.065, wps=11945.6, ups=1.44, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=28650
2023-08-14 21:37:55 | INFO | train_inner | epoch 023:   1387 / 1474 loss=1.944, trans_loss=4.828, nll_loss=2.047, w2v_ctc_loss=0.661, task_loss=1.418, contrastive_loss=0.145, total=4143.98, n_correct=2810.42, ppl=4.13, accuracy=67.819, wps=11912.6, ups=1.44, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=28720
2023-08-14 21:38:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 21:39:19 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.944 | trans_loss 5.155 | nll_loss 2.418 | w2v_ctc_loss 1.297 | task_loss 4.659 | contrastive_loss 0.296 | total 4003.4 | n_correct 2675.2 | ppl 5.35 | accuracy 66.823 | uer 17.546 | wer 19.574 | raw_wer 19.574 | bleu 22.58 | wps 2058.4 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 22.58
2023-08-14 21:39:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-08-14 21:39:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 21:39:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 21:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 23 @ 33887 updates, score 22.58) (writing took 29.34150842949748 seconds)
2023-08-14 21:39:49 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-14 21:39:49 | INFO | train | epoch 023 | loss 1.936 | trans_loss 4.815 | nll_loss 2.031 | w2v_ctc_loss 0.658 | task_loss 1.404 | contrastive_loss 0.131 | total 4138.65 | n_correct 2816.72 | ppl 4.09 | accuracy 68.059 | wps 11235.8 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.524 | clip 0 | loss_scale 32 | train_wall 1016 | gb_free 13.2 | wall 28834
2023-08-14 21:39:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 21:39:49 | INFO | fairseq.trainer | begin training epoch 24
2023-08-14 21:39:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 21:40:06 | INFO | train_inner | epoch 024:     13 / 1474 loss=1.95, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.653, task_loss=1.411, contrastive_loss=0.223, total=4085.11, n_correct=2770.3, ppl=4.13, accuracy=67.815, wps=6231.4, ups=0.76, wpb=8170.2, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=12.2, wall=28851
2023-08-14 21:41:15 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.932, trans_loss=4.795, nll_loss=2.003, w2v_ctc_loss=0.643, task_loss=1.298, contrastive_loss=0.241, total=4171.44, n_correct=2854.22, ppl=4.01, accuracy=68.423, wps=12036.2, ups=1.44, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=28920
2023-08-14 21:41:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 21:41:38 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.944 | trans_loss 5.16 | nll_loss 2.42 | w2v_ctc_loss 1.285 | task_loss 4.668 | contrastive_loss 0.298 | total 4003.4 | n_correct 2673.6 | ppl 5.35 | accuracy 66.783 | uer 17.49 | wer 19.444 | raw_wer 19.444 | bleu 22.34 | wps 2253.4 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.58
2023-08-14 21:41:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-14 21:41:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-14 21:41:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-14 21:42:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 22.34) (writing took 23.96177065744996 seconds)
2023-08-14 21:43:13 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.936, trans_loss=4.801, nll_loss=2.012, w2v_ctc_loss=0.636, task_loss=1.231, contrastive_loss=0.295, total=4251.29, n_correct=2907.28, ppl=4.03, accuracy=68.386, wps=7229.2, ups=0.85, wpb=8502.6, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=29038
2023-08-14 21:44:22 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.922, trans_loss=4.801, nll_loss=2.012, w2v_ctc_loss=0.651, task_loss=1.378, contrastive_loss=0.075, total=4128.18, n_correct=2819.16, ppl=4.03, accuracy=68.291, wps=11894.7, ups=1.44, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=29107
2023-08-14 21:45:32 | INFO | train_inner | epoch 024:    413 / 1474 loss=1.947, trans_loss=4.805, nll_loss=2.017, w2v_ctc_loss=0.66, task_loss=1.475, contrastive_loss=0.221, total=4158.92, n_correct=2833.99, ppl=4.05, accuracy=68.142, wps=11952.2, ups=1.44, wpb=8317.8, bsz=299.7, num_updates=34300, lr=7.63604e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=29177
2023-08-14 21:46:41 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.929, trans_loss=4.799, nll_loss=2.01, w2v_ctc_loss=0.652, task_loss=1.429, contrastive_loss=0.145, total=4144.91, n_correct=2833.15, ppl=4.03, accuracy=68.353, wps=11946.9, ups=1.44, wpb=8289.8, bsz=303.3, num_updates=34400, lr=7.62493e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=29246
2023-08-14 21:47:51 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.923, trans_loss=4.802, nll_loss=2.013, w2v_ctc_loss=0.643, task_loss=1.409, contrastive_loss=0.105, total=4165.3, n_correct=2845.32, ppl=4.04, accuracy=68.31, wps=11987.3, ups=1.44, wpb=8330.6, bsz=307.7, num_updates=34500, lr=7.61387e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=29316
2023-08-14 21:49:00 | INFO | train_inner | epoch 024:    713 / 1474 loss=1.931, trans_loss=4.81, nll_loss=2.023, w2v_ctc_loss=0.65, task_loss=1.451, contrastive_loss=0.121, total=4102.21, n_correct=2793.99, ppl=4.06, accuracy=68.109, wps=11828.4, ups=1.44, wpb=8204.4, bsz=295.1, num_updates=34600, lr=7.60286e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=29385
2023-08-14 21:50:09 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.929, trans_loss=4.814, nll_loss=2.029, w2v_ctc_loss=0.652, task_loss=1.419, contrastive_loss=0.094, total=4110.6, n_correct=2801.37, ppl=4.08, accuracy=68.15, wps=11830.3, ups=1.44, wpb=8221.2, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=29455
2023-08-14 21:51:18 | INFO | train_inner | epoch 024:    913 / 1474 loss=1.934, trans_loss=4.811, nll_loss=2.024, w2v_ctc_loss=0.664, task_loss=1.56, contrastive_loss=0.071, total=4043.03, n_correct=2750.88, ppl=4.07, accuracy=68.04, wps=11782.8, ups=1.46, wpb=8086.1, bsz=281, num_updates=34800, lr=7.58098e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=68, gb_free=10.8, wall=29523
2023-08-14 21:52:27 | INFO | train_inner | epoch 024:   1013 / 1474 loss=1.924, trans_loss=4.81, nll_loss=2.022, w2v_ctc_loss=0.648, task_loss=1.45, contrastive_loss=0.074, total=4136.81, n_correct=2826.87, ppl=4.06, accuracy=68.335, wps=11936.5, ups=1.44, wpb=8273.6, bsz=298.4, num_updates=34900, lr=7.57011e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=29593
2023-08-14 21:53:37 | INFO | train_inner | epoch 024:   1113 / 1474 loss=1.925, trans_loss=4.796, nll_loss=2.006, w2v_ctc_loss=0.653, task_loss=1.354, contrastive_loss=0.117, total=4135.73, n_correct=2829.8, ppl=4.02, accuracy=68.423, wps=11864.2, ups=1.43, wpb=8271.5, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=29662
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:0')
2023-08-14 21:54:47 | INFO | train_inner | epoch 024:   1213 / 1474 loss=1.928, trans_loss=4.809, nll_loss=2.022, w2v_ctc_loss=0.652, task_loss=1.392, contrastive_loss=0.104, total=4148.3, n_correct=2831.53, ppl=4.06, accuracy=68.258, wps=11913.4, ups=1.44, wpb=8296.6, bsz=310.8, num_updates=35100, lr=7.54851e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=29732
2023-08-14 21:55:56 | INFO | train_inner | epoch 024:   1313 / 1474 loss=1.932, trans_loss=4.812, nll_loss=2.026, w2v_ctc_loss=0.663, task_loss=1.498, contrastive_loss=0.078, total=4110.05, n_correct=2799.54, ppl=4.07, accuracy=68.114, wps=11844.4, ups=1.44, wpb=8220.1, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=29802
2023-08-14 21:57:05 | INFO | train_inner | epoch 024:   1413 / 1474 loss=1.932, trans_loss=4.812, nll_loss=2.027, w2v_ctc_loss=0.664, task_loss=1.471, contrastive_loss=0.076, total=4090.91, n_correct=2786.52, ppl=4.08, accuracy=68.115, wps=11910.3, ups=1.46, wpb=8181.8, bsz=292.7, num_updates=35300, lr=7.5271e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=29870
2023-08-14 21:57:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:3')
2023-08-14 21:58:11 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.934 | trans_loss 5.154 | nll_loss 2.416 | w2v_ctc_loss 1.268 | task_loss 4.659 | contrastive_loss 0.295 | total 4003.4 | n_correct 2677.1 | ppl 5.34 | accuracy 66.871 | uer 17.288 | wer 19.168 | raw_wer 19.168 | bleu 22.56 | wps 2175 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 22.58
2023-08-14 21:58:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-08-14 21:58:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.5601.pt
2023-08-14 21:58:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.5601.pt
2023-08-14 21:58:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.5601.pt (epoch 24 @ 35361 updates, score 22.56) (writing took 22.00683895498514 seconds)
2023-08-14 21:58:33 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-14 21:58:33 | INFO | train | epoch 024 | loss 1.93 | trans_loss 4.805 | nll_loss 2.018 | w2v_ctc_loss 0.652 | task_loss 1.406 | contrastive_loss 0.13 | total 4138.65 | n_correct 2824.95 | ppl 4.05 | accuracy 68.258 | wps 10849.4 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.525 | clip 0 | loss_scale 32 | train_wall 1016 | gb_free 15.9 | wall 29959
2023-08-14 21:58:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 21:58:34 | INFO | fairseq.trainer | begin training epoch 25
2023-08-14 21:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 21:59:09 | INFO | train_inner | epoch 025:     39 / 1474 loss=1.916, trans_loss=4.798, nll_loss=2.009, w2v_ctc_loss=0.643, task_loss=1.346, contrastive_loss=0.083, total=4166.95, n_correct=2857.42, ppl=4.02, accuracy=68.573, wps=6700.2, ups=0.8, wpb=8333.9, bsz=312, num_updates=35400, lr=7.51646e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=29995
2023-08-14 22:00:18 | INFO | train_inner | epoch 025:    139 / 1474 loss=1.91, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.638, task_loss=1.377, contrastive_loss=0.081, total=4133.64, n_correct=2841.58, ppl=3.97, accuracy=68.743, wps=11969.7, ups=1.45, wpb=8267.3, bsz=307.7, num_updates=35500, lr=7.50587e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=30064
2023-08-14 22:00:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 22:01:29 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.917, trans_loss=4.79, nll_loss=1.997, w2v_ctc_loss=0.646, task_loss=1.445, contrastive_loss=0.085, total=4115.89, n_correct=2823.03, ppl=3.99, accuracy=68.589, wps=11685.7, ups=1.42, wpb=8231.8, bsz=302.6, num_updates=35600, lr=7.49532e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=70, gb_free=16.9, wall=30134
2023-08-14 22:02:39 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.921, trans_loss=4.791, nll_loss=1.998, w2v_ctc_loss=0.642, task_loss=1.501, contrastive_loss=0.115, total=4141.49, n_correct=2835.81, ppl=3.99, accuracy=68.473, wps=11814, ups=1.43, wpb=8283, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=70, gb_free=14.9, wall=30204
2023-08-14 22:03:49 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.937, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.659, task_loss=1.471, contrastive_loss=0.193, total=4167.4, n_correct=2852.84, ppl=4, accuracy=68.456, wps=11941.4, ups=1.43, wpb=8334.8, bsz=297.7, num_updates=35800, lr=7.47435e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=30274
2023-08-14 22:04:58 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.921, trans_loss=4.802, nll_loss=2.013, w2v_ctc_loss=0.645, task_loss=1.369, contrastive_loss=0.085, total=4160.61, n_correct=2846.64, ppl=4.04, accuracy=68.419, wps=11954, ups=1.44, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=30344
2023-08-14 22:06:08 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.924, trans_loss=4.789, nll_loss=1.996, w2v_ctc_loss=0.648, task_loss=1.394, contrastive_loss=0.153, total=4153.68, n_correct=2843.8, ppl=3.99, accuracy=68.465, wps=12008.9, ups=1.45, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=30413
2023-08-14 22:06:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 22:06:31 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.965 | trans_loss 5.158 | nll_loss 2.418 | w2v_ctc_loss 1.363 | task_loss 4.633 | contrastive_loss 0.296 | total 4003.4 | n_correct 2674.9 | ppl 5.34 | accuracy 66.816 | uer 17.713 | wer 19.556 | raw_wer 19.556 | bleu 22.63 | wps 2226 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.63
2023-08-14 22:06:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-14 22:06:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-14 22:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-14 22:07:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.63) (writing took 31.430830851197243 seconds)
2023-08-14 22:08:13 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.926, trans_loss=4.789, nll_loss=1.997, w2v_ctc_loss=0.647, task_loss=1.424, contrastive_loss=0.147, total=4128.34, n_correct=2826.47, ppl=3.99, accuracy=68.465, wps=6584.1, ups=0.8, wpb=8256.7, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=30538
2023-08-14 22:09:23 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.917, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.646, task_loss=1.297, contrastive_loss=0.093, total=4182.4, n_correct=2865.21, ppl=4.02, accuracy=68.506, wps=12010.5, ups=1.44, wpb=8364.8, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=17.4, wall=30608
2023-08-14 22:10:32 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.924, trans_loss=4.796, nll_loss=2.007, w2v_ctc_loss=0.646, task_loss=1.334, contrastive_loss=0.151, total=4155.21, n_correct=2847.45, ppl=4.02, accuracy=68.527, wps=11932.8, ups=1.44, wpb=8310.4, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=13.7, wall=30678
2023-08-14 22:11:42 | INFO | train_inner | epoch 025:   1040 / 1474 loss=1.938, trans_loss=4.805, nll_loss=2.018, w2v_ctc_loss=0.641, task_loss=1.399, contrastive_loss=0.263, total=4177.7, n_correct=2850.76, ppl=4.05, accuracy=68.238, wps=11965.8, ups=1.43, wpb=8355.4, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=30747
2023-08-14 22:12:52 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.917, trans_loss=4.795, nll_loss=2.004, w2v_ctc_loss=0.643, task_loss=1.525, contrastive_loss=0.068, total=4039.24, n_correct=2766.53, ppl=4.01, accuracy=68.491, wps=11603, ups=1.44, wpb=8078.5, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=30817
2023-08-14 22:14:00 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.92, trans_loss=4.801, nll_loss=2.012, w2v_ctc_loss=0.645, task_loss=1.426, contrastive_loss=0.078, total=4090.59, n_correct=2798.29, ppl=4.03, accuracy=68.408, wps=11891.4, ups=1.45, wpb=8181.2, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=30886
2023-08-14 22:15:10 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.925, trans_loss=4.796, nll_loss=2.005, w2v_ctc_loss=0.642, task_loss=1.373, contrastive_loss=0.172, total=4164.34, n_correct=2852.06, ppl=4.01, accuracy=68.488, wps=11975.2, ups=1.44, wpb=8328.7, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=30955
2023-08-14 22:16:20 | INFO | train_inner | epoch 025:   1440 / 1474 loss=1.934, trans_loss=4.812, nll_loss=2.027, w2v_ctc_loss=0.653, task_loss=1.463, contrastive_loss=0.122, total=4099.11, n_correct=2789.5, ppl=4.08, accuracy=68.051, wps=11690.4, ups=1.43, wpb=8198.2, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=70, gb_free=11.9, wall=31025
2023-08-14 22:16:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 22:17:09 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.943 | trans_loss 5.158 | nll_loss 2.419 | w2v_ctc_loss 1.286 | task_loss 4.644 | contrastive_loss 0.303 | total 4003.4 | n_correct 2672.5 | ppl 5.35 | accuracy 66.756 | uer 17.511 | wer 19.436 | raw_wer 19.436 | bleu 22.32 | wps 2005.8 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 22.63
2023-08-14 22:17:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-08-14 22:17:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 22:17:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 22:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt (epoch 25 @ 36834 updates, score 22.32) (writing took 16.5743659529835 seconds)
2023-08-14 22:17:25 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-14 22:17:25 | INFO | train | epoch 025 | loss 1.923 | trans_loss 4.796 | nll_loss 2.005 | w2v_ctc_loss 0.646 | task_loss 1.407 | contrastive_loss 0.128 | total 4138.55 | n_correct 2832.96 | ppl 4.01 | accuracy 68.453 | wps 10770.8 | ups 1.3 | wpb 8277.1 | bsz 305.6 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.526 | clip 0 | loss_scale 16 | train_wall 1019 | gb_free 13.9 | wall 31091
2023-08-14 22:17:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 22:17:26 | INFO | fairseq.trainer | begin training epoch 26
2023-08-14 22:17:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 22:18:20 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.91, trans_loss=4.783, nll_loss=1.988, w2v_ctc_loss=0.631, task_loss=1.325, contrastive_loss=0.107, total=4180.21, n_correct=2873.39, ppl=3.97, accuracy=68.738, wps=6950.7, ups=0.83, wpb=8360.4, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=31146
2023-08-14 22:19:31 | INFO | train_inner | epoch 026:    166 / 1474 loss=1.923, trans_loss=4.782, nll_loss=1.988, w2v_ctc_loss=0.624, task_loss=1.236, contrastive_loss=0.291, total=4270.78, n_correct=2942.25, ppl=3.97, accuracy=68.893, wps=12102.2, ups=1.42, wpb=8541.6, bsz=340.4, num_updates=37000, lr=7.35215e-05, gnorm=0.514, clip=0, loss_scale=16, train_wall=70, gb_free=14.9, wall=31216
2023-08-14 22:20:41 | INFO | train_inner | epoch 026:    266 / 1474 loss=1.921, trans_loss=4.78, nll_loss=1.984, w2v_ctc_loss=0.645, task_loss=1.394, contrastive_loss=0.168, total=4125.04, n_correct=2836.78, ppl=3.96, accuracy=68.77, wps=11845.5, ups=1.44, wpb=8250.1, bsz=307.1, num_updates=37100, lr=7.34223e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=14.8, wall=31286
2023-08-14 22:21:50 | INFO | train_inner | epoch 026:    366 / 1474 loss=1.914, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.639, task_loss=1.346, contrastive_loss=0.124, total=4165.74, n_correct=2862.24, ppl=3.97, accuracy=68.709, wps=12019.5, ups=1.44, wpb=8331.5, bsz=314.7, num_updates=37200, lr=7.33236e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=31355
2023-08-14 22:22:59 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.916, trans_loss=4.774, nll_loss=1.977, w2v_ctc_loss=0.638, task_loss=1.342, contrastive_loss=0.169, total=4170.23, n_correct=2871.36, ppl=3.94, accuracy=68.854, wps=12039.4, ups=1.44, wpb=8340.5, bsz=315.4, num_updates=37300, lr=7.32252e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=31425
2023-08-14 22:24:10 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.917, trans_loss=4.786, nll_loss=1.993, w2v_ctc_loss=0.65, task_loss=1.423, contrastive_loss=0.091, total=4155.02, n_correct=2851.21, ppl=3.98, accuracy=68.621, wps=11802.2, ups=1.42, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=70, gb_free=17.5, wall=31495
2023-08-14 22:25:19 | INFO | train_inner | epoch 026:    666 / 1474 loss=1.909, trans_loss=4.783, nll_loss=1.987, w2v_ctc_loss=0.632, task_loss=1.433, contrastive_loss=0.076, total=4136.96, n_correct=2843.05, ppl=3.97, accuracy=68.723, wps=11886.1, ups=1.44, wpb=8273.9, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=15, wall=31565
2023-08-14 22:26:28 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.924, trans_loss=4.787, nll_loss=1.994, w2v_ctc_loss=0.638, task_loss=1.429, contrastive_loss=0.189, total=4086.28, n_correct=2802.49, ppl=3.98, accuracy=68.583, wps=11834.6, ups=1.45, wpb=8172.6, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=31634
2023-08-14 22:27:37 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.916, trans_loss=4.785, nll_loss=1.991, w2v_ctc_loss=0.646, task_loss=1.393, contrastive_loss=0.09, total=4183.26, n_correct=2871.98, ppl=3.97, accuracy=68.654, wps=12109.5, ups=1.45, wpb=8366.5, bsz=308.1, num_updates=37700, lr=7.28357e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=31703
2023-08-14 22:28:48 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.918, trans_loss=4.791, nll_loss=1.999, w2v_ctc_loss=0.63, task_loss=1.454, contrastive_loss=0.143, total=4137.96, n_correct=2837.49, ppl=4, accuracy=68.572, wps=11768.3, ups=1.42, wpb=8275.9, bsz=299, num_updates=37800, lr=7.27393e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=70, gb_free=16.6, wall=31773
2023-08-14 22:29:57 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.913, trans_loss=4.787, nll_loss=1.994, w2v_ctc_loss=0.642, task_loss=1.472, contrastive_loss=0.075, total=4120.53, n_correct=2831.81, ppl=3.98, accuracy=68.724, wps=11932.7, ups=1.45, wpb=8241.1, bsz=294.3, num_updates=37900, lr=7.26433e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=31842
2023-08-14 22:31:06 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.918, trans_loss=4.793, nll_loss=2.001, w2v_ctc_loss=0.638, task_loss=1.469, contrastive_loss=0.113, total=4113.86, n_correct=2819.52, ppl=4, accuracy=68.537, wps=11818.2, ups=1.44, wpb=8227.7, bsz=298.5, num_updates=38000, lr=7.25476e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=31912
2023-08-14 22:31:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 22:31:32 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.948 | trans_loss 5.159 | nll_loss 2.422 | w2v_ctc_loss 1.307 | task_loss 4.647 | contrastive_loss 0.29 | total 4003.4 | n_correct 2672.2 | ppl 5.36 | accuracy 66.748 | uer 17.524 | wer 19.418 | raw_wer 19.418 | bleu 22.26 | wps 1922.1 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.63
2023-08-14 22:31:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-14 22:31:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-14 22:31:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-14 22:31:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 22.26) (writing took 21.737594299018383 seconds)
2023-08-14 22:33:03 | INFO | train_inner | epoch 026:   1266 / 1474 loss=1.927, trans_loss=4.802, nll_loss=2.013, w2v_ctc_loss=0.659, task_loss=1.574, contrastive_loss=0.077, total=3996.19, n_correct=2728.64, ppl=4.04, accuracy=68.281, wps=6831.2, ups=0.85, wpb=7992.4, bsz=279.3, num_updates=38100, lr=7.24524e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=32029
2023-08-14 22:34:14 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.912, trans_loss=4.794, nll_loss=2.003, w2v_ctc_loss=0.631, task_loss=1.399, contrastive_loss=0.088, total=4159.74, n_correct=2854.1, ppl=4.01, accuracy=68.612, wps=11765.2, ups=1.41, wpb=8319.5, bsz=311.4, num_updates=38200, lr=7.23575e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=70, gb_free=16.9, wall=32100
2023-08-14 22:35:23 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.908, trans_loss=4.788, nll_loss=1.996, w2v_ctc_loss=0.631, task_loss=1.334, contrastive_loss=0.083, total=4165.66, n_correct=2860.73, ppl=3.99, accuracy=68.674, wps=12139.3, ups=1.46, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=32168
2023-08-14 22:35:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 22:35:52 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.936 | trans_loss 5.155 | nll_loss 2.415 | w2v_ctc_loss 1.273 | task_loss 4.628 | contrastive_loss 0.298 | total 4003.4 | n_correct 2672.5 | ppl 5.33 | accuracy 66.756 | uer 17.206 | wer 19.101 | raw_wer 19.101 | bleu 22.15 | wps 1905.2 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 22.63
2023-08-14 22:35:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-08-14 22:35:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 22:36:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 22:36:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt (epoch 26 @ 38308 updates, score 22.15) (writing took 15.347702980041504 seconds)
2023-08-14 22:36:08 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-14 22:36:08 | INFO | train | epoch 026 | loss 1.916 | trans_loss 4.786 | nll_loss 1.992 | w2v_ctc_loss 0.638 | task_loss 1.406 | contrastive_loss 0.127 | total 4138.65 | n_correct 2842.15 | ppl 3.98 | accuracy 68.673 | wps 10871.4 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 1019 | gb_free 15.7 | wall 32213
2023-08-14 22:36:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 22:36:08 | INFO | fairseq.trainer | begin training epoch 27
2023-08-14 22:36:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 22:37:19 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.894, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.621, task_loss=1.515, contrastive_loss=0.064, total=4054.57, n_correct=2809.17, ppl=3.86, accuracy=69.284, wps=6980.2, ups=0.86, wpb=8109.1, bsz=282.4, num_updates=38400, lr=7.21688e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=32284
2023-08-14 22:38:29 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.898, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.626, task_loss=1.335, contrastive_loss=0.09, total=4195.2, n_correct=2899.58, ppl=3.91, accuracy=69.117, wps=12064.3, ups=1.44, wpb=8390.4, bsz=323.2, num_updates=38500, lr=7.2075e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=32354
2023-08-14 22:39:39 | INFO | train_inner | epoch 027:    292 / 1474 loss=1.904, trans_loss=4.773, nll_loss=1.975, w2v_ctc_loss=0.632, task_loss=1.41, contrastive_loss=0.075, total=4162.23, n_correct=2872.47, ppl=3.93, accuracy=69.013, wps=11905.8, ups=1.43, wpb=8324.5, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=32424
2023-08-14 22:40:48 | INFO | train_inner | epoch 027:    392 / 1474 loss=1.928, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.634, task_loss=1.472, contrastive_loss=0.261, total=4079.05, n_correct=2800.51, ppl=3.96, accuracy=68.656, wps=11657.2, ups=1.43, wpb=8158.1, bsz=297.1, num_updates=38700, lr=7.18885e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=70, gb_free=16.5, wall=32494
2023-08-14 22:41:58 | INFO | train_inner | epoch 027:    492 / 1474 loss=1.918, trans_loss=4.784, nll_loss=1.99, w2v_ctc_loss=0.63, task_loss=1.292, contrastive_loss=0.196, total=4243.25, n_correct=2919.96, ppl=3.97, accuracy=68.814, wps=12167.4, ups=1.43, wpb=8486.5, bsz=331, num_updates=38800, lr=7.17958e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=32564
2023-08-14 22:43:08 | INFO | train_inner | epoch 027:    592 / 1474 loss=1.912, trans_loss=4.773, nll_loss=1.976, w2v_ctc_loss=0.638, task_loss=1.37, contrastive_loss=0.134, total=4137.92, n_correct=2849.98, ppl=3.93, accuracy=68.875, wps=11912.7, ups=1.44, wpb=8275.8, bsz=313.5, num_updates=38900, lr=7.17035e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=32633
2023-08-14 22:44:17 | INFO | train_inner | epoch 027:    692 / 1474 loss=1.913, trans_loss=4.78, nll_loss=1.984, w2v_ctc_loss=0.636, task_loss=1.412, contrastive_loss=0.114, total=4158.48, n_correct=2861.92, ppl=3.96, accuracy=68.821, wps=11993.8, ups=1.44, wpb=8317, bsz=304.1, num_updates=39000, lr=7.16115e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=32702
2023-08-14 22:45:25 | INFO | train_inner | epoch 027:    792 / 1474 loss=1.911, trans_loss=4.779, nll_loss=1.982, w2v_ctc_loss=0.643, task_loss=1.492, contrastive_loss=0.075, total=4100.88, n_correct=2820.71, ppl=3.95, accuracy=68.783, wps=11999.5, ups=1.46, wpb=8201.8, bsz=292.2, num_updates=39100, lr=7.15199e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=32771
2023-08-14 22:46:34 | INFO | train_inner | epoch 027:    892 / 1474 loss=1.904, trans_loss=4.781, nll_loss=1.985, w2v_ctc_loss=0.629, task_loss=1.45, contrastive_loss=0.069, total=4111.94, n_correct=2833.66, ppl=3.96, accuracy=68.913, wps=11944.5, ups=1.45, wpb=8223.9, bsz=294.9, num_updates=39200, lr=7.14286e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=32840
2023-08-14 22:47:44 | INFO | train_inner | epoch 027:    992 / 1474 loss=1.922, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.631, task_loss=1.366, contrastive_loss=0.255, total=4189.27, n_correct=2881.59, ppl=3.96, accuracy=68.785, wps=11932.8, ups=1.42, wpb=8378.5, bsz=314.9, num_updates=39300, lr=7.13376e-05, gnorm=0.514, clip=0, loss_scale=32, train_wall=70, gb_free=14, wall=32910
2023-08-14 22:48:54 | INFO | train_inner | epoch 027:   1092 / 1474 loss=1.903, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.626, task_loss=1.4, contrastive_loss=0.085, total=4160.42, n_correct=2867.89, ppl=3.94, accuracy=68.933, wps=11985.9, ups=1.44, wpb=8320.8, bsz=307.3, num_updates=39400, lr=7.1247e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=32979
2023-08-14 22:50:03 | INFO | train_inner | epoch 027:   1192 / 1474 loss=1.914, trans_loss=4.782, nll_loss=1.986, w2v_ctc_loss=0.645, task_loss=1.476, contrastive_loss=0.09, total=4103.72, n_correct=2820, ppl=3.96, accuracy=68.718, wps=11837.5, ups=1.44, wpb=8207.4, bsz=297.1, num_updates=39500, lr=7.11568e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=17.4, wall=33049
2023-08-14 22:51:12 | INFO | train_inner | epoch 027:   1292 / 1474 loss=1.918, trans_loss=4.785, nll_loss=1.99, w2v_ctc_loss=0.636, task_loss=1.503, contrastive_loss=0.142, total=4065.94, n_correct=2791.09, ppl=3.97, accuracy=68.646, wps=11756.3, ups=1.45, wpb=8131.9, bsz=292.4, num_updates=39600, lr=7.10669e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=33118
2023-08-14 22:51:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-14 22:52:22 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.905, trans_loss=4.781, nll_loss=1.986, w2v_ctc_loss=0.631, task_loss=1.34, contrastive_loss=0.081, total=4138.31, n_correct=2847.93, ppl=3.96, accuracy=68.819, wps=11908.5, ups=1.44, wpb=8276.6, bsz=309.1, num_updates=39700, lr=7.09773e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=33187
2023-08-14 22:53:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 22:53:42 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.938 | trans_loss 5.156 | nll_loss 2.418 | w2v_ctc_loss 1.282 | task_loss 4.64 | contrastive_loss 0.29 | total 4003.4 | n_correct 2677.6 | ppl 5.34 | accuracy 66.883 | uer 17.336 | wer 19.503 | raw_wer 19.503 | bleu 22.58 | wps 2137.9 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 22.63
2023-08-14 22:53:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-08-14 22:53:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.5805.pt
2023-08-14 22:53:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.5805.pt
2023-08-14 22:54:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint.best_bleu_22.5805.pt (epoch 27 @ 39781 updates, score 22.58) (writing took 38.133490052074194 seconds)
2023-08-14 22:54:20 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-14 22:54:20 | INFO | train | epoch 027 | loss 1.91 | trans_loss 4.777 | nll_loss 1.98 | w2v_ctc_loss 0.632 | task_loss 1.407 | contrastive_loss 0.122 | total 4138.14 | n_correct 2850.04 | ppl 3.95 | accuracy 68.872 | wps 11157.9 | ups 1.35 | wpb 8276.3 | bsz 305.5 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 1015 | gb_free 17.5 | wall 33306
2023-08-14 22:54:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 22:54:21 | INFO | fairseq.trainer | begin training epoch 28
2023-08-14 22:54:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 22:54:41 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.9, trans_loss=4.775, nll_loss=1.978, w2v_ctc_loss=0.625, task_loss=1.36, contrastive_loss=0.077, total=4108.43, n_correct=2834.29, ppl=3.94, accuracy=68.987, wps=5888.3, ups=0.72, wpb=8216.9, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=33327
2023-08-14 22:55:50 | INFO | train_inner | epoch 028:    119 / 1474 loss=1.893, trans_loss=4.751, nll_loss=1.946, w2v_ctc_loss=0.625, task_loss=1.466, contrastive_loss=0.07, total=4113.41, n_correct=2856.34, ppl=3.85, accuracy=69.44, wps=11925.6, ups=1.45, wpb=8226.8, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=33396
2023-08-14 22:56:59 | INFO | train_inner | epoch 028:    219 / 1474 loss=1.893, trans_loss=4.762, nll_loss=1.961, w2v_ctc_loss=0.62, task_loss=1.33, contrastive_loss=0.078, total=4191.56, n_correct=2903.73, ppl=3.89, accuracy=69.276, wps=12211, ups=1.46, wpb=8383.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=33464
2023-08-14 22:56:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 22:57:22 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.946 | trans_loss 5.159 | nll_loss 2.42 | w2v_ctc_loss 1.299 | task_loss 4.647 | contrastive_loss 0.291 | total 4003.4 | n_correct 2675.2 | ppl 5.35 | accuracy 66.823 | uer 17.434 | wer 19.384 | raw_wer 19.384 | bleu 22.65 | wps 2242.4 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.65
2023-08-14 22:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-14 22:57:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-14 22:57:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-14 22:57:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.65) (writing took 29.82798371836543 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:0')
2023-08-14 22:59:03 | INFO | train_inner | epoch 028:    319 / 1474 loss=1.932, trans_loss=4.773, nll_loss=1.975, w2v_ctc_loss=0.617, task_loss=1.393, contrastive_loss=0.411, total=4145.32, n_correct=2853.37, ppl=3.93, accuracy=68.834, wps=6695.5, ups=0.81, wpb=8290.6, bsz=316.1, num_updates=40100, lr=7.06225e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=33588
2023-08-14 23:00:12 | INFO | train_inner | epoch 028:    419 / 1474 loss=1.899, trans_loss=4.761, nll_loss=1.959, w2v_ctc_loss=0.632, task_loss=1.45, contrastive_loss=0.067, total=4092.14, n_correct=2829.41, ppl=3.89, accuracy=69.143, wps=11841.2, ups=1.45, wpb=8184.3, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=33657
2023-08-14 23:01:21 | INFO | train_inner | epoch 028:    519 / 1474 loss=1.899, trans_loss=4.765, nll_loss=1.965, w2v_ctc_loss=0.625, task_loss=1.463, contrastive_loss=0.079, total=4096.35, n_correct=2829.27, ppl=3.9, accuracy=69.068, wps=11900.9, ups=1.45, wpb=8192.7, bsz=295.5, num_updates=40300, lr=7.0447e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=33726
2023-08-14 23:02:30 | INFO | train_inner | epoch 028:    619 / 1474 loss=1.902, trans_loss=4.773, nll_loss=1.975, w2v_ctc_loss=0.63, task_loss=1.411, contrastive_loss=0.079, total=4178.12, n_correct=2884.51, ppl=3.93, accuracy=69.038, wps=12113.8, ups=1.45, wpb=8356.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=33795
2023-08-14 23:03:40 | INFO | train_inner | epoch 028:    719 / 1474 loss=1.909, trans_loss=4.775, nll_loss=1.979, w2v_ctc_loss=0.623, task_loss=1.279, contrastive_loss=0.189, total=4185.82, n_correct=2886.6, ppl=3.94, accuracy=68.961, wps=12029, ups=1.44, wpb=8371.6, bsz=326.4, num_updates=40500, lr=7.02728e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=33865
2023-08-14 23:04:49 | INFO | train_inner | epoch 028:    819 / 1474 loss=1.894, trans_loss=4.766, nll_loss=1.967, w2v_ctc_loss=0.621, task_loss=1.379, contrastive_loss=0.072, total=4096.2, n_correct=2835.7, ppl=3.91, accuracy=69.228, wps=11874.8, ups=1.45, wpb=8192.4, bsz=307, num_updates=40600, lr=7.01862e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=33934
2023-08-14 23:05:58 | INFO | train_inner | epoch 028:    919 / 1474 loss=1.912, trans_loss=4.775, nll_loss=1.978, w2v_ctc_loss=0.634, task_loss=1.444, contrastive_loss=0.133, total=4120.27, n_correct=2835.36, ppl=3.94, accuracy=68.815, wps=11793.8, ups=1.43, wpb=8240.5, bsz=300.8, num_updates=40700, lr=7.01e-05, gnorm=0.541, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=34004
2023-08-14 23:07:08 | INFO | train_inner | epoch 028:   1019 / 1474 loss=1.916, trans_loss=4.774, nll_loss=1.977, w2v_ctc_loss=0.631, task_loss=1.373, contrastive_loss=0.186, total=4177.86, n_correct=2878.12, ppl=3.94, accuracy=68.89, wps=12040.2, ups=1.44, wpb=8355.7, bsz=311.1, num_updates=40800, lr=7.0014e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=34073
2023-08-14 23:08:18 | INFO | train_inner | epoch 028:   1119 / 1474 loss=1.898, trans_loss=4.765, nll_loss=1.966, w2v_ctc_loss=0.624, task_loss=1.361, contrastive_loss=0.09, total=4210.86, n_correct=2906.84, ppl=3.91, accuracy=69.032, wps=12072.7, ups=1.43, wpb=8421.7, bsz=318.9, num_updates=40900, lr=6.99284e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=34143
2023-08-14 23:09:26 | INFO | train_inner | epoch 028:   1219 / 1474 loss=1.899, trans_loss=4.773, nll_loss=1.976, w2v_ctc_loss=0.621, task_loss=1.387, contrastive_loss=0.078, total=4104.61, n_correct=2831.19, ppl=3.93, accuracy=68.976, wps=11916.7, ups=1.45, wpb=8209.2, bsz=305.6, num_updates=41000, lr=6.9843e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=34212
2023-08-14 23:10:37 | INFO | train_inner | epoch 028:   1319 / 1474 loss=1.909, trans_loss=4.773, nll_loss=1.975, w2v_ctc_loss=0.636, task_loss=1.541, contrastive_loss=0.093, total=4087.78, n_correct=2816.04, ppl=3.93, accuracy=68.889, wps=11647.4, ups=1.42, wpb=8175.6, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=70, gb_free=14.7, wall=34282
2023-08-14 23:11:46 | INFO | train_inner | epoch 028:   1419 / 1474 loss=1.906, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.626, task_loss=1.476, contrastive_loss=0.115, total=4145.03, n_correct=2857.29, ppl=3.92, accuracy=68.933, wps=11964.8, ups=1.44, wpb=8290.1, bsz=297.6, num_updates=41200, lr=6.96733e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=34351
2023-08-14 23:12:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:6')
2023-08-14 23:12:48 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.939 | trans_loss 5.156 | nll_loss 2.413 | w2v_ctc_loss 1.286 | task_loss 4.64 | contrastive_loss 0.29 | total 4003.4 | n_correct 2681.1 | ppl 5.33 | accuracy 66.971 | uer 17.129 | wer 18.981 | raw_wer 18.981 | bleu 22.66 | wps 2115.6 | wpb 4003.4 | bsz 141.8 | num_updates 41255 | best_bleu 22.66
2023-08-14 23:12:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41255 updates
2023-08-14 23:12:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 23:13:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 23:13:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 28 @ 41255 updates, score 22.66) (writing took 31.520990557968616 seconds)
2023-08-14 23:13:20 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-14 23:13:20 | INFO | train | epoch 028 | loss 1.904 | trans_loss 4.768 | nll_loss 1.969 | w2v_ctc_loss 0.626 | task_loss 1.404 | contrastive_loss 0.123 | total 4138.65 | n_correct 2857.78 | ppl 3.91 | accuracy 69.051 | wps 10707.4 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 41255 | lr 6.96268e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 1014 | gb_free 16.1 | wall 34445
2023-08-14 23:13:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 23:13:20 | INFO | fairseq.trainer | begin training epoch 29
2023-08-14 23:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 23:13:59 | INFO | train_inner | epoch 029:     45 / 1474 loss=1.895, trans_loss=4.758, nll_loss=1.957, w2v_ctc_loss=0.626, task_loss=1.361, contrastive_loss=0.082, total=4163.06, n_correct=2886.78, ppl=3.88, accuracy=69.343, wps=6277.5, ups=0.75, wpb=8326.1, bsz=314, num_updates=41300, lr=6.95889e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=34484
2023-08-14 23:15:08 | INFO | train_inner | epoch 029:    145 / 1474 loss=1.901, trans_loss=4.761, nll_loss=1.96, w2v_ctc_loss=0.627, task_loss=1.382, contrastive_loss=0.114, total=4116.29, n_correct=2847.07, ppl=3.89, accuracy=69.166, wps=11868.3, ups=1.44, wpb=8232.6, bsz=308.5, num_updates=41400, lr=6.95048e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=13.7, wall=34553
2023-08-14 23:16:18 | INFO | train_inner | epoch 029:    245 / 1474 loss=1.898, trans_loss=4.753, nll_loss=1.951, w2v_ctc_loss=0.608, task_loss=1.286, contrastive_loss=0.191, total=4197.24, n_correct=2910.49, ppl=3.87, accuracy=69.343, wps=11993.9, ups=1.43, wpb=8394.5, bsz=329.9, num_updates=41500, lr=6.9421e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=34623
2023-08-14 23:17:27 | INFO | train_inner | epoch 029:    345 / 1474 loss=1.904, trans_loss=4.769, nll_loss=1.969, w2v_ctc_loss=0.635, task_loss=1.51, contrastive_loss=0.075, total=4092.21, n_correct=2829.19, ppl=3.91, accuracy=69.136, wps=11773.9, ups=1.44, wpb=8184.4, bsz=290.6, num_updates=41600, lr=6.93375e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=34693
2023-08-14 23:18:37 | INFO | train_inner | epoch 029:    445 / 1474 loss=1.881, trans_loss=4.738, nll_loss=1.931, w2v_ctc_loss=0.611, task_loss=1.359, contrastive_loss=0.067, total=4161.27, n_correct=2900.76, ppl=3.81, accuracy=69.709, wps=11963, ups=1.44, wpb=8322.5, bsz=307.8, num_updates=41700, lr=6.92543e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=34762
2023-08-14 23:18:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-14 23:19:47 | INFO | train_inner | epoch 029:    546 / 1474 loss=1.91, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.622, task_loss=1.493, contrastive_loss=0.164, total=4146.82, n_correct=2861.6, ppl=3.91, accuracy=69.007, wps=11840.8, ups=1.43, wpb=8293.6, bsz=295.1, num_updates=41800, lr=6.91714e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=70, gb_free=15.4, wall=34832
2023-08-14 23:20:56 | INFO | train_inner | epoch 029:    646 / 1474 loss=1.903, trans_loss=4.757, nll_loss=1.956, w2v_ctc_loss=0.616, task_loss=1.33, contrastive_loss=0.233, total=4143.02, n_correct=2871.12, ppl=3.88, accuracy=69.3, wps=11968, ups=1.44, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=34902
2023-08-14 23:22:06 | INFO | train_inner | epoch 029:    746 / 1474 loss=1.896, trans_loss=4.754, nll_loss=1.951, w2v_ctc_loss=0.616, task_loss=1.298, contrastive_loss=0.15, total=4249.79, n_correct=2946.28, ppl=3.87, accuracy=69.328, wps=12137.3, ups=1.43, wpb=8499.6, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=70, gb_free=16.3, wall=34972
2023-08-14 23:22:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 23:22:31 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.164 | nll_loss 2.424 | w2v_ctc_loss 1.348 | task_loss 4.652 | contrastive_loss 0.298 | total 4003.4 | n_correct 2669.7 | ppl 5.37 | accuracy 66.686 | uer 17.44 | wer 19.198 | raw_wer 19.198 | bleu 22.39 | wps 2209.9 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.66
2023-08-14 23:22:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-14 23:22:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-14 23:22:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-14 23:22:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.39) (writing took 16.069201296195388 seconds)
2023-08-14 23:23:57 | INFO | train_inner | epoch 029:    846 / 1474 loss=1.9, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.621, task_loss=1.563, contrastive_loss=0.067, total=4027.19, n_correct=2780.84, ppl=3.92, accuracy=69.052, wps=7257.7, ups=0.9, wpb=8054.4, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=35083
2023-08-14 23:25:06 | INFO | train_inner | epoch 029:    946 / 1474 loss=1.9, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.63, task_loss=1.431, contrastive_loss=0.078, total=4082.14, n_correct=2823.8, ppl=3.91, accuracy=69.175, wps=11925.8, ups=1.46, wpb=8164.3, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=35151
2023-08-14 23:26:15 | INFO | train_inner | epoch 029:   1046 / 1474 loss=1.898, trans_loss=4.758, nll_loss=1.956, w2v_ctc_loss=0.616, task_loss=1.401, contrastive_loss=0.151, total=4148.18, n_correct=2875.55, ppl=3.88, accuracy=69.321, wps=11977.1, ups=1.44, wpb=8296.4, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=35220
2023-08-14 23:27:24 | INFO | train_inner | epoch 029:   1146 / 1474 loss=1.903, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.631, task_loss=1.541, contrastive_loss=0.065, total=4063.95, n_correct=2804.84, ppl=3.92, accuracy=69.018, wps=11807.6, ups=1.45, wpb=8127.9, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=12.9, wall=35289
2023-08-14 23:28:33 | INFO | train_inner | epoch 029:   1246 / 1474 loss=1.899, trans_loss=4.768, nll_loss=1.969, w2v_ctc_loss=0.627, task_loss=1.426, contrastive_loss=0.072, total=4158.81, n_correct=2874.29, ppl=3.91, accuracy=69.113, wps=11981.7, ups=1.44, wpb=8317.6, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=35359
2023-08-14 23:28:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-14 23:29:43 | INFO | train_inner | epoch 029:   1347 / 1474 loss=1.896, trans_loss=4.756, nll_loss=1.954, w2v_ctc_loss=0.613, task_loss=1.402, contrastive_loss=0.133, total=4158.6, n_correct=2881.48, ppl=3.87, accuracy=69.29, wps=11898.1, ups=1.43, wpb=8317.2, bsz=307.1, num_updates=42600, lr=6.85189e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.3, wall=35429
2023-08-14 23:30:52 | INFO | train_inner | epoch 029:   1447 / 1474 loss=1.904, trans_loss=4.759, nll_loss=1.958, w2v_ctc_loss=0.627, task_loss=1.37, contrastive_loss=0.165, total=4166.06, n_correct=2883.7, ppl=3.89, accuracy=69.219, wps=12062.7, ups=1.45, wpb=8332.1, bsz=313.1, num_updates=42700, lr=6.84386e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=35498
2023-08-14 23:31:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 23:31:36 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.959 | trans_loss 5.156 | nll_loss 2.413 | w2v_ctc_loss 1.344 | task_loss 4.668 | contrastive_loss 0.3 | total 4003.4 | n_correct 2672.7 | ppl 5.33 | accuracy 66.761 | uer 17.304 | wer 19.272 | raw_wer 19.272 | bleu 22.71 | wps 2190.2 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 22.71
2023-08-14 23:31:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-08-14 23:31:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 23:31:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-14 23:32:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 29 @ 42727 updates, score 22.71) (writing took 29.21096247807145 seconds)
2023-08-14 23:32:06 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-14 23:32:06 | INFO | train | epoch 029 | loss 1.899 | trans_loss 4.76 | nll_loss 1.959 | w2v_ctc_loss 0.621 | task_loss 1.408 | contrastive_loss 0.123 | total 4137.69 | n_correct 2864.95 | ppl 3.89 | accuracy 69.24 | wps 10819.1 | ups 1.31 | wpb 8275.4 | bsz 305.4 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.532 | clip 0 | loss_scale 16 | train_wall 1014 | gb_free 15.8 | wall 35571
2023-08-14 23:32:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 23:32:06 | INFO | fairseq.trainer | begin training epoch 30
2023-08-14 23:32:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 23:33:05 | INFO | train_inner | epoch 030:     73 / 1474 loss=1.893, trans_loss=4.748, nll_loss=1.943, w2v_ctc_loss=0.606, task_loss=1.342, contrastive_loss=0.182, total=4175.11, n_correct=2901.06, ppl=3.85, accuracy=69.485, wps=6284.8, ups=0.75, wpb=8350.2, bsz=318.6, num_updates=42800, lr=6.83586e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=35630
2023-08-14 23:34:14 | INFO | train_inner | epoch 030:    173 / 1474 loss=1.884, trans_loss=4.734, nll_loss=1.925, w2v_ctc_loss=0.612, task_loss=1.318, contrastive_loss=0.112, total=4202.64, n_correct=2932.47, ppl=3.8, accuracy=69.777, wps=12143.5, ups=1.44, wpb=8405.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=35700
2023-08-14 23:35:23 | INFO | train_inner | epoch 030:    273 / 1474 loss=1.891, trans_loss=4.75, nll_loss=1.945, w2v_ctc_loss=0.624, task_loss=1.451, contrastive_loss=0.067, total=4120.21, n_correct=2864.65, ppl=3.85, accuracy=69.527, wps=12019.9, ups=1.46, wpb=8240.4, bsz=294.9, num_updates=43000, lr=6.81994e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=35768
2023-08-14 23:36:32 | INFO | train_inner | epoch 030:    373 / 1474 loss=1.88, trans_loss=4.74, nll_loss=1.932, w2v_ctc_loss=0.609, task_loss=1.402, contrastive_loss=0.07, total=4178.23, n_correct=2914.87, ppl=3.81, accuracy=69.763, wps=12019.7, ups=1.44, wpb=8356.5, bsz=307.5, num_updates=43100, lr=6.81203e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=69, gb_free=9.6, wall=35838
2023-08-14 23:37:41 | INFO | train_inner | epoch 030:    473 / 1474 loss=1.888, trans_loss=4.747, nll_loss=1.942, w2v_ctc_loss=0.606, task_loss=1.35, contrastive_loss=0.133, total=4124.47, n_correct=2867.94, ppl=3.84, accuracy=69.535, wps=11987.8, ups=1.45, wpb=8248.9, bsz=312.6, num_updates=43200, lr=6.80414e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=35907
2023-08-14 23:38:50 | INFO | train_inner | epoch 030:    573 / 1474 loss=1.891, trans_loss=4.751, nll_loss=1.947, w2v_ctc_loss=0.618, task_loss=1.366, contrastive_loss=0.094, total=4168.41, n_correct=2895.98, ppl=3.86, accuracy=69.474, wps=12119.1, ups=1.45, wpb=8336.8, bsz=312.4, num_updates=43300, lr=6.79628e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=35975
2023-08-14 23:39:59 | INFO | train_inner | epoch 030:    673 / 1474 loss=1.897, trans_loss=4.754, nll_loss=1.951, w2v_ctc_loss=0.625, task_loss=1.391, contrastive_loss=0.108, total=4187.95, n_correct=2898.04, ppl=3.87, accuracy=69.199, wps=12109.4, ups=1.45, wpb=8375.9, bsz=315, num_updates=43400, lr=6.78844e-05, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=36045
2023-08-14 23:41:09 | INFO | train_inner | epoch 030:    773 / 1474 loss=1.908, trans_loss=4.758, nll_loss=1.955, w2v_ctc_loss=0.627, task_loss=1.439, contrastive_loss=0.188, total=4105.32, n_correct=2840.57, ppl=3.88, accuracy=69.192, wps=11841.5, ups=1.44, wpb=8210.6, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=12.6, wall=36114
2023-08-14 23:42:18 | INFO | train_inner | epoch 030:    873 / 1474 loss=1.896, trans_loss=4.759, nll_loss=1.957, w2v_ctc_loss=0.621, task_loss=1.452, contrastive_loss=0.081, total=4102.11, n_correct=2840.17, ppl=3.88, accuracy=69.237, wps=11856.9, ups=1.45, wpb=8204.2, bsz=295.6, num_updates=43600, lr=6.77285e-05, gnorm=0.557, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=36183
2023-08-14 23:43:27 | INFO | train_inner | epoch 030:    973 / 1474 loss=1.897, trans_loss=4.76, nll_loss=1.958, w2v_ctc_loss=0.626, task_loss=1.442, contrastive_loss=0.082, total=4129.98, n_correct=2857.68, ppl=3.88, accuracy=69.194, wps=11891.4, ups=1.44, wpb=8260, bsz=300.4, num_updates=43700, lr=6.7651e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=36253
2023-08-14 23:44:37 | INFO | train_inner | epoch 030:   1073 / 1474 loss=1.906, trans_loss=4.76, nll_loss=1.958, w2v_ctc_loss=0.623, task_loss=1.573, contrastive_loss=0.162, total=4101.17, n_correct=2835.78, ppl=3.88, accuracy=69.146, wps=11759.1, ups=1.43, wpb=8202.3, bsz=282.3, num_updates=43800, lr=6.75737e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=36322
2023-08-14 23:45:47 | INFO | train_inner | epoch 030:   1173 / 1474 loss=1.89, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.607, task_loss=1.354, contrastive_loss=0.141, total=4168.36, n_correct=2896.16, ppl=3.86, accuracy=69.48, wps=11970, ups=1.44, wpb=8336.7, bsz=314, num_updates=43900, lr=6.74967e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=36392
2023-08-14 23:46:56 | INFO | train_inner | epoch 030:   1273 / 1474 loss=1.898, trans_loss=4.759, nll_loss=1.958, w2v_ctc_loss=0.627, task_loss=1.553, contrastive_loss=0.074, total=4036.17, n_correct=2791.92, ppl=3.88, accuracy=69.173, wps=11605.8, ups=1.44, wpb=8072.3, bsz=284.3, num_updates=44000, lr=6.742e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=36462
2023-08-14 23:46:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 23:47:20 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.16 | nll_loss 2.418 | w2v_ctc_loss 1.359 | task_loss 4.647 | contrastive_loss 0.296 | total 4003.4 | n_correct 2672.3 | ppl 5.35 | accuracy 66.751 | uer 17.615 | wer 19.474 | raw_wer 19.474 | bleu 22.41 | wps 2082 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.71
2023-08-14 23:47:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-14 23:47:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-14 23:47:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-14 23:47:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.41) (writing took 18.880178205668926 seconds)
2023-08-14 23:48:49 | INFO | train_inner | epoch 030:   1373 / 1474 loss=1.888, trans_loss=4.756, nll_loss=1.954, w2v_ctc_loss=0.615, task_loss=1.328, contrastive_loss=0.083, total=4165.07, n_correct=2889.94, ppl=3.87, accuracy=69.385, wps=7411.9, ups=0.89, wpb=8330.1, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=36574
2023-08-14 23:49:58 | INFO | train_inner | epoch 030:   1473 / 1474 loss=1.898, trans_loss=4.756, nll_loss=1.954, w2v_ctc_loss=0.605, task_loss=1.323, contrastive_loss=0.232, total=4141.76, n_correct=2871.24, ppl=3.87, accuracy=69.324, wps=11972.1, ups=1.45, wpb=8283.5, bsz=314.3, num_updates=44200, lr=6.72673e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=36643
2023-08-14 23:49:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-14 23:50:21 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.949 | trans_loss 5.155 | nll_loss 2.414 | w2v_ctc_loss 1.322 | task_loss 4.676 | contrastive_loss 0.29 | total 4003.4 | n_correct 2682.1 | ppl 5.33 | accuracy 66.996 | uer 16.999 | wer 18.761 | raw_wer 18.761 | bleu 22.42 | wps 2074.1 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 22.71
2023-08-14 23:50:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-08-14 23:50:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 23:50:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-14 23:50:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt (epoch 30 @ 44201 updates, score 22.42) (writing took 15.331073019653559 seconds)
2023-08-14 23:50:36 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-14 23:50:36 | INFO | train | epoch 030 | loss 1.894 | trans_loss 4.752 | nll_loss 1.948 | w2v_ctc_loss 0.617 | task_loss 1.406 | contrastive_loss 0.122 | total 4138.65 | n_correct 2871.89 | ppl 3.86 | accuracy 69.392 | wps 10984.7 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.534 | clip 0 | loss_scale 16 | train_wall 1014 | gb_free 16.8 | wall 36682
2023-08-14 23:50:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-14 23:50:37 | INFO | fairseq.trainer | begin training epoch 31
2023-08-14 23:50:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-14 23:51:53 | INFO | train_inner | epoch 031:     99 / 1474 loss=1.885, trans_loss=4.741, nll_loss=1.933, w2v_ctc_loss=0.615, task_loss=1.503, contrastive_loss=0.068, total=4054.44, n_correct=2822.23, ppl=3.82, accuracy=69.608, wps=7060, ups=0.87, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=36758
2023-08-14 23:53:03 | INFO | train_inner | epoch 031:    199 / 1474 loss=1.886, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.612, task_loss=1.439, contrastive_loss=0.097, total=4147.4, n_correct=2888.78, ppl=3.82, accuracy=69.653, wps=11866.8, ups=1.43, wpb=8294.8, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=36828
2023-08-14 23:54:12 | INFO | train_inner | epoch 031:    299 / 1474 loss=1.889, trans_loss=4.737, nll_loss=1.929, w2v_ctc_loss=0.612, task_loss=1.436, contrastive_loss=0.135, total=4149.21, n_correct=2893.35, ppl=3.81, accuracy=69.733, wps=11967.1, ups=1.44, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=36897
2023-08-14 23:55:21 | INFO | train_inner | epoch 031:    399 / 1474 loss=1.887, trans_loss=4.748, nll_loss=1.942, w2v_ctc_loss=0.61, task_loss=1.537, contrastive_loss=0.072, total=4092.62, n_correct=2845.9, ppl=3.84, accuracy=69.537, wps=11822.3, ups=1.44, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=36967
2023-08-14 23:56:31 | INFO | train_inner | epoch 031:    499 / 1474 loss=1.888, trans_loss=4.743, nll_loss=1.936, w2v_ctc_loss=0.62, task_loss=1.473, contrastive_loss=0.08, total=4111.85, n_correct=2858.43, ppl=3.83, accuracy=69.517, wps=11835.6, ups=1.44, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=10.6, wall=37036
2023-08-14 23:57:40 | INFO | train_inner | epoch 031:    599 / 1474 loss=1.883, trans_loss=4.741, nll_loss=1.934, w2v_ctc_loss=0.612, task_loss=1.467, contrastive_loss=0.07, total=4083.44, n_correct=2842.43, ppl=3.82, accuracy=69.609, wps=11711.3, ups=1.43, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=37106
2023-08-14 23:58:49 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.878, trans_loss=4.74, nll_loss=1.932, w2v_ctc_loss=0.604, task_loss=1.339, contrastive_loss=0.072, total=4213.98, n_correct=2934.96, ppl=3.82, accuracy=69.648, wps=12267.1, ups=1.46, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=37174
2023-08-14 23:59:59 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.897, trans_loss=4.749, nll_loss=1.944, w2v_ctc_loss=0.616, task_loss=1.472, contrastive_loss=0.141, total=4097.37, n_correct=2841.99, ppl=3.85, accuracy=69.361, wps=11743.2, ups=1.43, wpb=8194.7, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=12.5, wall=37244
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:0')
2023-08-15 00:01:08 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.883, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.613, task_loss=1.464, contrastive_loss=0.087, total=4096.72, n_correct=2852.11, ppl=3.8, accuracy=69.619, wps=11877.7, ups=1.45, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=37313
2023-08-15 00:02:18 | INFO | train_inner | epoch 031:    999 / 1474 loss=1.893, trans_loss=4.751, nll_loss=1.947, w2v_ctc_loss=0.609, task_loss=1.328, contrastive_loss=0.17, total=4187.84, n_correct=2911.86, ppl=3.86, accuracy=69.531, wps=12012.3, ups=1.43, wpb=8375.7, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=37383
2023-08-15 00:03:27 | INFO | train_inner | epoch 031:   1099 / 1474 loss=1.889, trans_loss=4.747, nll_loss=1.942, w2v_ctc_loss=0.611, task_loss=1.374, contrastive_loss=0.117, total=4149.44, n_correct=2885.73, ppl=3.84, accuracy=69.545, wps=12035.7, ups=1.45, wpb=8298.9, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=37452
2023-08-15 00:04:36 | INFO | train_inner | epoch 031:   1199 / 1474 loss=1.895, trans_loss=4.746, nll_loss=1.941, w2v_ctc_loss=0.604, task_loss=1.313, contrastive_loss=0.234, total=4189.76, n_correct=2915.91, ppl=3.84, accuracy=69.596, wps=12101, ups=1.44, wpb=8379.5, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=12.9, wall=37521
2023-08-15 00:05:44 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.885, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.615, task_loss=1.263, contrastive_loss=0.077, total=4227.44, n_correct=2937.7, ppl=3.86, accuracy=69.491, wps=12328.7, ups=1.46, wpb=8454.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=37590
2023-08-15 00:06:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 00:06:55 | INFO | train_inner | epoch 031:   1400 / 1474 loss=1.893, trans_loss=4.746, nll_loss=1.941, w2v_ctc_loss=0.611, task_loss=1.316, contrastive_loss=0.178, total=4162.83, n_correct=2893.99, ppl=3.84, accuracy=69.52, wps=11819.2, ups=1.42, wpb=8325.7, bsz=319.1, num_updates=45600, lr=6.62266e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=70, gb_free=16.3, wall=37660
2023-08-15 00:07:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2264, device='cuda:5')
2023-08-15 00:08:10 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.934 | trans_loss 5.15 | nll_loss 2.405 | w2v_ctc_loss 1.285 | task_loss 4.671 | contrastive_loss 0.289 | total 4003.4 | n_correct 2685.5 | ppl 5.3 | accuracy 67.08 | uer 16.914 | wer 18.877 | raw_wer 18.877 | bleu 22.44 | wps 2121.5 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 22.71
2023-08-15 00:08:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-08-15 00:08:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 00:08:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 00:08:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt (epoch 31 @ 45674 updates, score 22.44) (writing took 15.281412540003657 seconds)
2023-08-15 00:08:25 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-15 00:08:25 | INFO | train | epoch 031 | loss 1.888 | trans_loss 4.744 | nll_loss 1.938 | w2v_ctc_loss 0.612 | task_loss 1.408 | contrastive_loss 0.113 | total 4136.77 | n_correct 2877.78 | ppl 3.83 | accuracy 69.566 | wps 11407 | ups 1.38 | wpb 8273.5 | bsz 305.1 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.53 | clip 0 | loss_scale 16 | train_wall 1014 | gb_free 11.7 | wall 37750
2023-08-15 00:08:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 00:08:25 | INFO | fairseq.trainer | begin training epoch 32
2023-08-15 00:08:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 00:08:50 | INFO | train_inner | epoch 032:     26 / 1474 loss=1.885, trans_loss=4.741, nll_loss=1.934, w2v_ctc_loss=0.617, task_loss=1.486, contrastive_loss=0.067, total=4040.88, n_correct=2814.99, ppl=3.82, accuracy=69.663, wps=6996.4, ups=0.87, wpb=8081.8, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=68, gb_free=15.2, wall=37776
2023-08-15 00:10:00 | INFO | train_inner | epoch 032:    126 / 1474 loss=1.865, trans_loss=4.72, nll_loss=1.907, w2v_ctc_loss=0.592, task_loss=1.298, contrastive_loss=0.077, total=4222.14, n_correct=2960.23, ppl=3.75, accuracy=70.112, wps=12207.6, ups=1.45, wpb=8444.3, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.515, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=37845
2023-08-15 00:11:09 | INFO | train_inner | epoch 032:    226 / 1474 loss=1.879, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.607, task_loss=1.339, contrastive_loss=0.086, total=4159.77, n_correct=2897.26, ppl=3.81, accuracy=69.65, wps=11962.4, ups=1.44, wpb=8319.5, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=37914
2023-08-15 00:12:18 | INFO | train_inner | epoch 032:    326 / 1474 loss=1.871, trans_loss=4.724, nll_loss=1.912, w2v_ctc_loss=0.597, task_loss=1.331, contrastive_loss=0.08, total=4179.65, n_correct=2927.33, ppl=3.76, accuracy=70.038, wps=12153.1, ups=1.45, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=37983
2023-08-15 00:12:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 00:12:42 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.949 | trans_loss 5.166 | nll_loss 2.427 | w2v_ctc_loss 1.297 | task_loss 4.643 | contrastive_loss 0.291 | total 4003.4 | n_correct 2675.7 | ppl 5.38 | accuracy 66.836 | uer 17.254 | wer 19.108 | raw_wer 19.108 | bleu 22.19 | wps 2098 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.71
2023-08-15 00:12:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-15 00:12:42 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-15 00:12:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-15 00:13:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.19) (writing took 38.82612647116184 seconds)
2023-08-15 00:14:30 | INFO | train_inner | epoch 032:    426 / 1474 loss=1.876, trans_loss=4.727, nll_loss=1.916, w2v_ctc_loss=0.608, task_loss=1.373, contrastive_loss=0.077, total=4172.34, n_correct=2918.68, ppl=3.77, accuracy=69.953, wps=6314.2, ups=0.76, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=38115
2023-08-15 00:15:40 | INFO | train_inner | epoch 032:    526 / 1474 loss=1.89, trans_loss=4.739, nll_loss=1.932, w2v_ctc_loss=0.61, task_loss=1.371, contrastive_loss=0.158, total=4191.15, n_correct=2919.3, ppl=3.81, accuracy=69.654, wps=12032.8, ups=1.44, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.539, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=38185
2023-08-15 00:16:49 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.882, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.609, task_loss=1.472, contrastive_loss=0.083, total=4138.05, n_correct=2883.77, ppl=3.81, accuracy=69.689, wps=11890.3, ups=1.44, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=13, wall=38255
2023-08-15 00:17:59 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.882, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.615, task_loss=1.425, contrastive_loss=0.069, total=4156.23, n_correct=2895.8, ppl=3.81, accuracy=69.674, wps=11961.7, ups=1.44, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=38324
2023-08-15 00:19:07 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.88, trans_loss=4.738, nll_loss=1.929, w2v_ctc_loss=0.606, task_loss=1.455, contrastive_loss=0.066, total=4112.3, n_correct=2865.37, ppl=3.81, accuracy=69.678, wps=11985.1, ups=1.46, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=38393
2023-08-15 00:20:17 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.877, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.603, task_loss=1.454, contrastive_loss=0.064, total=4139.37, n_correct=2886.34, ppl=3.81, accuracy=69.729, wps=11931.3, ups=1.44, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=12.4, wall=38462
2023-08-15 00:21:26 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.889, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.61, task_loss=1.385, contrastive_loss=0.159, total=4121.85, n_correct=2872.63, ppl=3.82, accuracy=69.693, wps=11971.5, ups=1.45, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=38531
2023-08-15 00:22:35 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.889, trans_loss=4.74, nll_loss=1.931, w2v_ctc_loss=0.61, task_loss=1.668, contrastive_loss=0.102, total=4015.59, n_correct=2792.84, ppl=3.81, accuracy=69.55, wps=11555.8, ups=1.44, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=38601
2023-08-15 00:23:45 | INFO | train_inner | epoch 032:   1226 / 1474 loss=1.901, trans_loss=4.751, nll_loss=1.947, w2v_ctc_loss=0.61, task_loss=1.389, contrastive_loss=0.209, total=4153.44, n_correct=2881.9, ppl=3.85, accuracy=69.386, wps=11957.4, ups=1.44, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=38670
2023-08-15 00:24:54 | INFO | train_inner | epoch 032:   1326 / 1474 loss=1.88, trans_loss=4.738, nll_loss=1.929, w2v_ctc_loss=0.61, task_loss=1.45, contrastive_loss=0.065, total=4075.86, n_correct=2840.6, ppl=3.81, accuracy=69.693, wps=11846.4, ups=1.45, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=38739
2023-08-15 00:26:03 | INFO | train_inner | epoch 032:   1426 / 1474 loss=1.908, trans_loss=4.744, nll_loss=1.938, w2v_ctc_loss=0.621, task_loss=1.403, contrastive_loss=0.302, total=4116.4, n_correct=2862.06, ppl=3.83, accuracy=69.528, wps=11860.5, ups=1.44, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=38808
2023-08-15 00:26:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 00:26:59 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.946 | trans_loss 5.158 | nll_loss 2.417 | w2v_ctc_loss 1.305 | task_loss 4.645 | contrastive_loss 0.293 | total 4003.4 | n_correct 2684.5 | ppl 5.34 | accuracy 67.056 | uer 17.371 | wer 19.38 | raw_wer 19.38 | bleu 22.29 | wps 2200.9 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 22.71
2023-08-15 00:26:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-08-15 00:26:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 00:27:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-15 00:27:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_last.pt (epoch 32 @ 47148 updates, score 22.29) (writing took 16.88039444759488 seconds)
2023-08-15 00:27:16 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-15 00:27:16 | INFO | train | epoch 032 | loss 1.884 | trans_loss 4.737 | nll_loss 1.928 | w2v_ctc_loss 0.607 | task_loss 1.406 | contrastive_loss 0.119 | total 4138.65 | n_correct 2885.5 | ppl 3.81 | accuracy 69.721 | wps 10783.8 | ups 1.3 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.529 | clip 0 | loss_scale 16 | train_wall 1013 | gb_free 16.1 | wall 38882
2023-08-15 00:27:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 00:27:16 | INFO | fairseq.trainer | begin training epoch 33
2023-08-15 00:27:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 00:28:00 | INFO | train_inner | epoch 033:     52 / 1474 loss=1.884, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.599, task_loss=1.326, contrastive_loss=0.167, total=4149.21, n_correct=2897.43, ppl=3.8, accuracy=69.831, wps=7089.7, ups=0.85, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.538, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=38925
2023-08-15 00:29:09 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.865, trans_loss=4.717, nll_loss=1.901, w2v_ctc_loss=0.588, task_loss=1.508, contrastive_loss=0.057, total=4073.9, n_correct=2856.53, ppl=3.73, accuracy=70.118, wps=11829.8, ups=1.45, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=38994
2023-08-15 00:30:18 | INFO | train_inner | epoch 033:    252 / 1474 loss=1.886, trans_loss=4.723, nll_loss=1.911, w2v_ctc_loss=0.596, task_loss=1.2, contrastive_loss=0.231, total=4280.14, n_correct=2998.16, ppl=3.76, accuracy=70.048, wps=12365.1, ups=1.44, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=39063
2023-08-15 00:31:28 | INFO | train_inner | epoch 033:    352 / 1474 loss=1.877, trans_loss=4.728, nll_loss=1.917, w2v_ctc_loss=0.604, task_loss=1.436, contrastive_loss=0.085, total=4120.27, n_correct=2880.78, ppl=3.78, accuracy=69.917, wps=11787, ups=1.43, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=39133
2023-08-15 00:32:36 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.86, trans_loss=4.715, nll_loss=1.899, w2v_ctc_loss=0.589, task_loss=1.332, contrastive_loss=0.064, total=4141.22, n_correct=2910.22, ppl=3.73, accuracy=70.274, wps=12132.6, ups=1.46, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.517, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=39202
2023-08-15 00:33:45 | INFO | train_inner | epoch 033:    552 / 1474 loss=1.882, trans_loss=4.731, nll_loss=1.92, w2v_ctc_loss=0.61, task_loss=1.462, contrastive_loss=0.086, total=4133.59, n_correct=2884.24, ppl=3.79, accuracy=69.776, wps=11974.5, ups=1.45, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=14.9, wall=39271
2023-08-15 00:34:54 | INFO | train_inner | epoch 033:    652 / 1474 loss=1.884, trans_loss=4.74, nll_loss=1.931, w2v_ctc_loss=0.602, task_loss=1.437, contrastive_loss=0.119, total=4157.63, n_correct=2900.83, ppl=3.81, accuracy=69.771, wps=12028, ups=1.45, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=39340
2023-08-15 00:36:04 | INFO | train_inner | epoch 033:    752 / 1474 loss=1.886, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.621, task_loss=1.528, contrastive_loss=0.066, total=4070.75, n_correct=2837.57, ppl=3.8, accuracy=69.706, wps=11679.5, ups=1.43, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=39409
2023-08-15 00:37:13 | INFO | train_inner | epoch 033:    852 / 1474 loss=1.867, trans_loss=4.722, nll_loss=1.909, w2v_ctc_loss=0.585, task_loss=1.335, contrastive_loss=0.135, total=4130.24, n_correct=2900.65, ppl=3.76, accuracy=70.23, wps=11966.3, ups=1.45, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.513, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=39479
2023-08-15 00:37:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 00:37:37 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.961 | trans_loss 5.164 | nll_loss 2.421 | w2v_ctc_loss 1.344 | task_loss 4.673 | contrastive_loss 0.291 | total 4003.4 | n_correct 2677.6 | ppl 5.35 | accuracy 66.883 | uer 17.137 | wer 18.948 | raw_wer 18.948 | bleu 22.34 | wps 2182.6 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.71
2023-08-15 00:37:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-15 00:37:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-15 00:37:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-15 00:38:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.34) (writing took 36.71228860877454 seconds)
2023-08-15 00:39:23 | INFO | train_inner | epoch 033:    952 / 1474 loss=1.88, trans_loss=4.733, nll_loss=1.924, w2v_ctc_loss=0.612, task_loss=1.404, contrastive_loss=0.078, total=4151.18, n_correct=2898.55, ppl=3.79, accuracy=69.825, wps=6400.9, ups=0.77, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=10.9, wall=39608
2023-08-15 00:40:32 | INFO | train_inner | epoch 033:   1052 / 1474 loss=1.887, trans_loss=4.729, nll_loss=1.918, w2v_ctc_loss=0.603, task_loss=1.408, contrastive_loss=0.179, total=4140.1, n_correct=2890.73, ppl=3.78, accuracy=69.823, wps=11935.3, ups=1.44, wpb=8280.2, bsz=307.6, num_updates=48200, lr=6.44157e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=11.2, wall=39678
2023-08-15 00:41:43 | INFO | train_inner | epoch 033:   1152 / 1474 loss=1.887, trans_loss=4.74, nll_loss=1.933, w2v_ctc_loss=0.598, task_loss=1.413, contrastive_loss=0.168, total=4182.67, n_correct=2912.53, ppl=3.82, accuracy=69.633, wps=11876.3, ups=1.42, wpb=8365.3, bsz=309.5, num_updates=48300, lr=6.43489e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=70, gb_free=17.3, wall=39748
2023-08-15 00:42:52 | INFO | train_inner | epoch 033:   1252 / 1474 loss=1.876, trans_loss=4.727, nll_loss=1.916, w2v_ctc_loss=0.608, task_loss=1.48, contrastive_loss=0.069, total=4110.02, n_correct=2873.14, ppl=3.77, accuracy=69.906, wps=11840.8, ups=1.44, wpb=8220, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=39817
2023-08-15 00:44:02 | INFO | train_inner | epoch 033:   1352 / 1474 loss=1.876, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.602, task_loss=1.378, contrastive_loss=0.088, total=4128.82, n_correct=2884.44, ppl=3.79, accuracy=69.861, wps=11878.7, ups=1.44, wpb=8257.6, bsz=312.4, num_updates=48500, lr=6.42161e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=39887
2023-08-15 00:45:11 | INFO | train_inner | epoch 033:   1452 / 1474 loss=1.888, trans_loss=4.732, nll_loss=1.923, w2v_ctc_loss=0.598, task_loss=1.403, contrastive_loss=0.235, total=4123.47, n_correct=2877.92, ppl=3.79, accuracy=69.794, wps=11915.2, ups=1.44, wpb=8246.9, bsz=308.9, num_updates=48600, lr=6.415e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=39956
2023-08-15 00:45:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 00:45:49 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.956 | trans_loss 5.161 | nll_loss 2.417 | w2v_ctc_loss 1.328 | task_loss 4.664 | contrastive_loss 0.3 | total 4003.4 | n_correct 2684.3 | ppl 5.34 | accuracy 67.051 | uer 16.972 | wer 18.784 | raw_wer 18.784 | bleu 22.84 | wps 2160.1 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 22.84
2023-08-15 00:45:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-08-15 00:45:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 00:46:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-15 00:46:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_best.pt (epoch 33 @ 48622 updates, score 22.84) (writing took 30.45481700077653 seconds)
2023-08-15 00:46:20 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-15 00:46:20 | INFO | train | epoch 033 | loss 1.878 | trans_loss 4.729 | nll_loss 1.918 | w2v_ctc_loss 0.601 | task_loss 1.406 | contrastive_loss 0.118 | total 4138.65 | n_correct 2893.41 | ppl 3.78 | accuracy 69.912 | wps 10665.1 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 1014 | gb_free 17.5 | wall 40026
2023-08-15 00:46:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-15 00:46:21 | INFO | fairseq.trainer | begin training epoch 34
2023-08-15 00:46:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-15 00:47:23 | INFO | train_inner | epoch 034:     78 / 1474 loss=1.867, trans_loss=4.717, nll_loss=1.903, w2v_ctc_loss=0.596, task_loss=1.385, contrastive_loss=0.071, total=4128.94, n_correct=2895.92, ppl=3.74, accuracy=70.137, wps=6249.6, ups=0.76, wpb=8257.9, bsz=302.1, num_updates=48700, lr=6.40841e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=14.9, wall=40088
2023-08-15 00:48:33 | INFO | train_inner | epoch 034:    178 / 1474 loss=1.864, trans_loss=4.709, nll_loss=1.892, w2v_ctc_loss=0.595, task_loss=1.467, contrastive_loss=0.072, total=4071.22, n_correct=2863.29, ppl=3.71, accuracy=70.33, wps=11696.1, ups=1.44, wpb=8142.4, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=40158
2023-08-15 00:49:43 | INFO | train_inner | epoch 034:    278 / 1474 loss=1.893, trans_loss=4.727, nll_loss=1.916, w2v_ctc_loss=0.593, task_loss=1.326, contrastive_loss=0.283, total=4237.89, n_correct=2959.85, ppl=3.77, accuracy=69.843, wps=12123.6, ups=1.43, wpb=8475.8, bsz=326.9, num_updates=48900, lr=6.39529e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=10, wall=40228
2023-08-15 00:50:52 | INFO | train_inner | epoch 034:    378 / 1474 loss=1.87, trans_loss=4.712, nll_loss=1.896, w2v_ctc_loss=0.588, task_loss=1.328, contrastive_loss=0.171, total=4167, n_correct=2929.03, ppl=3.72, accuracy=70.291, wps=12062.6, ups=1.45, wpb=8334, bsz=319, num_updates=49000, lr=6.38877e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=40297
2023-08-15 00:52:01 | INFO | train_inner | epoch 034:    478 / 1474 loss=1.876, trans_loss=4.724, nll_loss=1.91, w2v_ctc_loss=0.61, task_loss=1.541, contrastive_loss=0.066, total=4071.65, n_correct=2850.03, ppl=3.76, accuracy=69.997, wps=11721.9, ups=1.44, wpb=8143.3, bsz=284.8, num_updates=49100, lr=6.38226e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=11.2, wall=40366
2023-08-15 00:53:10 | INFO | train_inner | epoch 034:    578 / 1474 loss=1.864, trans_loss=4.71, nll_loss=1.894, w2v_ctc_loss=0.592, task_loss=1.427, contrastive_loss=0.067, total=4110.13, n_correct=2887.35, ppl=3.72, accuracy=70.25, wps=11936, ups=1.45, wpb=8220.3, bsz=299, num_updates=49200, lr=6.37577e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=40435
2023-08-15 00:53:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-15 00:54:20 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.865, trans_loss=4.719, nll_loss=1.905, w2v_ctc_loss=0.594, task_loss=1.417, contrastive_loss=0.063, total=4135.94, n_correct=2902.33, ppl=3.75, accuracy=70.173, wps=11847.3, ups=1.43, wpb=8271.9, bsz=301.9, num_updates=49300, lr=6.3693e-05, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=13.9, wall=40505
2023-08-15 00:55:29 | INFO | train_inner | epoch 034:    779 / 1474 loss=1.882, trans_loss=4.74, nll_loss=1.932, w2v_ctc_loss=0.595, task_loss=1.475, contrastive_loss=0.133, total=4082.07, n_correct=2845.27, ppl=3.82, accuracy=69.702, wps=11782.8, ups=1.44, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=40574
2023-08-15 00:56:39 | INFO | train_inner | epoch 034:    879 / 1474 loss=1.876, trans_loss=4.727, nll_loss=1.916, w2v_ctc_loss=0.602, task_loss=1.485, contrastive_loss=0.09, total=4100.9, n_correct=2868.93, ppl=3.77, accuracy=69.959, wps=11737, ups=1.43, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.554, clip=0, loss_scale=16, train_wall=69, gb_free=11.8, wall=40644
2023-08-15 00:57:48 | INFO | train_inner | epoch 034:    979 / 1474 loss=1.876, trans_loss=4.725, nll_loss=1.913, w2v_ctc_loss=0.607, task_loss=1.379, contrastive_loss=0.085, total=4168.39, n_correct=2916.46, ppl=3.77, accuracy=69.966, wps=12055.3, ups=1.45, wpb=8336.8, bsz=311.9, num_updates=49600, lr=6.35001e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=15.6, wall=40713
2023-08-15 00:58:57 | INFO | train_inner | epoch 034:   1079 / 1474 loss=1.872, trans_loss=4.725, nll_loss=1.913, w2v_ctc_loss=0.605, task_loss=1.364, contrastive_loss=0.069, total=4150.57, n_correct=2906.54, ppl=3.76, accuracy=70.027, wps=12056.1, ups=1.45, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=40782
2023-08-15 01:00:06 | INFO | train_inner | epoch 034:   1179 / 1474 loss=1.873, trans_loss=4.726, nll_loss=1.915, w2v_ctc_loss=0.598, task_loss=1.455, contrastive_loss=0.081, total=4098.77, n_correct=2866.7, ppl=3.77, accuracy=69.94, wps=11941.5, ups=1.46, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=40851
2023-08-15 01:01:15 | INFO | train_inner | epoch 034:   1279 / 1474 loss=1.869, trans_loss=4.72, nll_loss=1.907, w2v_ctc_loss=0.599, task_loss=1.417, contrastive_loss=0.064, total=4150.54, n_correct=2905.63, ppl=3.75, accuracy=70.006, wps=11970.6, ups=1.44, wpb=8301.1, bsz=301, num_updates=49900, lr=6.33089e-05, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=16.8, wall=40920
2023-08-15 01:02:25 | INFO | train_inner | epoch 034:   1379 / 1474 loss=1.883, trans_loss=4.731, nll_loss=1.921, w2v_ctc_loss=0.609, task_loss=1.346, contrastive_loss=0.13, total=4196.91, n_correct=2929.42, ppl=3.79, accuracy=69.799, wps=11937.7, ups=1.42, wpb=8393.8, bsz=321.4, num_updates=50000, lr=6.32456e-05, gnorm=0.537, clip=0, loss_scale=16, train_wall=70, gb_free=15.8, wall=40991
2023-08-15 01:02:25 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-15 01:02:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-15 01:02:49 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.161 | nll_loss 2.416 | w2v_ctc_loss 1.325 | task_loss 4.655 | contrastive_loss 0.297 | total 4003.4 | n_correct 2683 | ppl 5.34 | accuracy 67.018 | uer 16.858 | wer 18.672 | raw_wer 18.672 | bleu 22.22 | wps 2159.8 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.84
2023-08-15 01:02:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-15 01:02:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-15 01:02:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-15 01:03:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0814_AT_sentence_mixup0105_alpha1.5_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.22) (writing took 16.918317092582583 seconds)
2023-08-15 01:03:07 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-15 01:03:07 | INFO | train | epoch 034 | loss 1.874 | trans_loss 4.722 | nll_loss 1.909 | w2v_ctc_loss 0.599 | task_loss 1.415 | contrastive_loss 0.105 | total 4133.69 | n_correct 2894.83 | ppl 3.76 | accuracy 70.03 | wps 11321.5 | ups 1.37 | wpb 8267.4 | bsz 304.4 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.533 | clip 0 | loss_scale 16 | train_wall 950 | gb_free 15.8 | wall 41032
2023-08-15 01:03:07 | INFO | fairseq_cli.train | done training in 40978.6 seconds
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
