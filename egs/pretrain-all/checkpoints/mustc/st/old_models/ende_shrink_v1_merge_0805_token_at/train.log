2023-08-05 12:16:31 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16927
2023-08-05 12:16:31 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:16927
2023-08-05 12:16:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-05 12:16:31 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16927
2023-08-05 12:16:31 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16927
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:16927
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16927
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:16927
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:16927
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-05 12:16:32 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-05 12:16:32 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-05 12:16:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16927', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='token', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='token', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='token', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=2.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-05 12:16:36 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-05 12:16:36 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-05 12:16:36 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-05 12:16:36 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-05 12:16:36 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-05 12:16:40 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-05 12:16:40 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-05 12:16:40 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-05 12:16:42 | INFO | root | load pretrained hubert
2023-08-05 12:16:44 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-05 12:16:45 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-05 12:16:46 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-05 12:16:46 | INFO | root | share the sematic adapter and textual encoder
2023-08-05 12:16:46 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-05 12:16:46 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-05 12:16:46 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-05 12:16:46 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-05 12:16:46 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-05 12:16:46 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-05 12:16:46 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-05 12:16:46 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-05 12:16:46 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-05 12:16:46 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-05 12:16:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-05 12:16:55 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-05 12:16:55 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-05 12:16:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-05 12:16:56 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-05 12:16:56 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-05 12:16:56 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-05 12:16:56 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-05 12:16:56 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-05 12:16:56 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-05 12:16:56 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-05 12:16:56 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-05 12:16:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-05 12:16:56 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-05 12:16:56 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-05 12:16:56 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_last.pt
2023-08-05 12:16:56 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_last.pt
2023-08-05 12:16:56 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-05 12:16:56 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-05 12:16:56 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-05 12:16:56 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-05 12:16:57 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-05 12:16:59 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-05 12:17:46 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-05 12:17:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 12:17:46 | INFO | fairseq.trainer | begin training epoch 1
2023-08-05 12:17:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 12:19:05 | INFO | train_inner | epoch 001:    100 / 1474 loss=8.753, trans_loss=5.598, nll_loss=4.162, w2v_ctc_loss=9.397, task_loss=1.756, contrastive_loss=3.325, total=4207.04, n_correct=209.42, ppl=17.9, accuracy=4.978, wps=19172, ups=1.52, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.401, clip=0, loss_scale=128, train_wall=71, gb_free=19.5, wall=130
2023-08-05 12:20:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-05 12:20:10 | INFO | train_inner | epoch 001:    201 / 1474 loss=7.876, trans_loss=5.473, nll_loss=4.058, w2v_ctc_loss=8.149, task_loss=1.718, contrastive_loss=3.285, total=4123.37, n_correct=223.74, ppl=16.66, accuracy=5.426, wps=18946, ups=1.54, wpb=12310.5, bsz=462.6, num_updates=200, lr=8.096e-06, gnorm=1.47, clip=0, loss_scale=64, train_wall=65, gb_free=19.2, wall=195
2023-08-05 12:21:14 | INFO | train_inner | epoch 001:    301 / 1474 loss=4.928, trans_loss=5.48, nll_loss=4.121, w2v_ctc_loss=3.67, task_loss=1.724, contrastive_loss=3.202, total=4079.62, n_correct=206.69, ppl=17.4, accuracy=5.066, wps=19110, ups=1.57, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=1.932, clip=0, loss_scale=64, train_wall=63, gb_free=19.9, wall=258
2023-08-05 12:22:18 | INFO | train_inner | epoch 001:    401 / 1474 loss=4.407, trans_loss=5.513, nll_loss=4.184, w2v_ctc_loss=2.836, task_loss=1.51, contrastive_loss=3.233, total=4174.14, n_correct=196.91, ppl=18.18, accuracy=4.717, wps=19601.7, ups=1.57, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=1.227, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=322
2023-08-05 12:23:22 | INFO | train_inner | epoch 001:    501 / 1474 loss=4.238, trans_loss=5.494, nll_loss=4.176, w2v_ctc_loss=2.584, task_loss=1.393, contrastive_loss=3.218, total=4176.18, n_correct=191.41, ppl=18.07, accuracy=4.583, wps=19456, ups=1.56, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=0.61, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=386
2023-08-05 12:24:27 | INFO | train_inner | epoch 001:    601 / 1474 loss=4.12, trans_loss=5.517, nll_loss=4.202, w2v_ctc_loss=2.439, task_loss=1.311, contrastive_loss=3.257, total=4147.79, n_correct=196.43, ppl=18.41, accuracy=4.736, wps=19084.5, ups=1.54, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.375, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=451
2023-08-05 12:25:30 | INFO | train_inner | epoch 001:    701 / 1474 loss=4.004, trans_loss=5.5, nll_loss=4.192, w2v_ctc_loss=2.396, task_loss=1.361, contrastive_loss=2.986, total=4152.1, n_correct=216, ppl=18.28, accuracy=5.202, wps=19560.3, ups=1.58, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.45, clip=0, loss_scale=64, train_wall=63, gb_free=19.5, wall=514
2023-08-05 12:26:34 | INFO | train_inner | epoch 001:    801 / 1474 loss=3.867, trans_loss=5.446, nll_loss=4.137, w2v_ctc_loss=2.325, task_loss=1.307, contrastive_loss=2.897, total=4123.83, n_correct=252.47, ppl=17.59, accuracy=6.122, wps=19322, ups=1.57, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.641, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=578
2023-08-05 12:27:38 | INFO | train_inner | epoch 001:    901 / 1474 loss=3.768, trans_loss=5.423, nll_loss=4.119, w2v_ctc_loss=2.298, task_loss=1.325, contrastive_loss=2.684, total=4163.61, n_correct=269.25, ppl=17.38, accuracy=6.467, wps=19392.3, ups=1.56, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.026, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=642
2023-08-05 12:28:43 | INFO | train_inner | epoch 001:   1001 / 1474 loss=3.62, trans_loss=5.399, nll_loss=4.096, w2v_ctc_loss=2.223, task_loss=1.333, contrastive_loss=2.561, total=4135.34, n_correct=291.21, ppl=17.11, accuracy=7.042, wps=18978.1, ups=1.54, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.091, clip=0, loss_scale=64, train_wall=65, gb_free=19, wall=707
2023-08-05 12:29:46 | INFO | train_inner | epoch 001:   1101 / 1474 loss=3.518, trans_loss=5.39, nll_loss=4.088, w2v_ctc_loss=2.184, task_loss=1.343, contrastive_loss=2.371, total=4147.38, n_correct=309.72, ppl=17.01, accuracy=7.468, wps=19493, ups=1.58, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.299, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=771
2023-08-05 12:30:50 | INFO | train_inner | epoch 001:   1201 / 1474 loss=3.381, trans_loss=5.372, nll_loss=4.073, w2v_ctc_loss=2.121, task_loss=1.394, contrastive_loss=2.179, total=4139.9, n_correct=318.05, ppl=16.84, accuracy=7.683, wps=19454, ups=1.57, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.274, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=834
2023-08-05 12:31:53 | INFO | train_inner | epoch 001:   1301 / 1474 loss=3.278, trans_loss=5.371, nll_loss=4.074, w2v_ctc_loss=2.06, task_loss=1.335, contrastive_loss=2, total=4046.58, n_correct=316.78, ppl=16.85, accuracy=7.828, wps=19101.2, ups=1.58, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.302, clip=0, loss_scale=64, train_wall=63, gb_free=19.7, wall=898
2023-08-05 12:32:58 | INFO | train_inner | epoch 001:   1401 / 1474 loss=3.168, trans_loss=5.363, nll_loss=4.07, w2v_ctc_loss=1.981, task_loss=1.314, contrastive_loss=2.064, total=4133.18, n_correct=325.99, ppl=16.8, accuracy=7.887, wps=19088.4, ups=1.55, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.179, clip=0, loss_scale=64, train_wall=64, gb_free=19.9, wall=962
2023-08-05 12:33:45 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 12:34:25 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 2.726 | trans_loss 10.981 | nll_loss 9.985 | w2v_ctc_loss 1.645 | task_loss 7.548 | contrastive_loss 2.477 | total 4003.4 | n_correct 374 | ppl 1013.47 | accuracy 9.342 | uer 79.147 | wer 78.625 | raw_wer 78.625 | bleu 0.02 | wps 1148.3 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-08-05 12:34:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-08-05 12:34:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 12:34:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 12:34:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 5.6577819008380175 seconds)
2023-08-05 12:34:31 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-05 12:34:31 | INFO | train | epoch 001 | loss 4.43 | trans_loss 5.449 | nll_loss 4.123 | w2v_ctc_loss 3.269 | task_loss 1.429 | contrastive_loss 2.766 | total 4138.5 | n_correct 255.627 | ppl 17.42 | accuracy 6.177 | wps 18371.7 | ups 1.49 | wpb 12355.3 | bsz 458.5 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.031 | clip 0 | loss_scale 64 | train_wall 944 | gb_free 19.2 | wall 1055
2023-08-05 12:34:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 12:34:31 | INFO | fairseq.trainer | begin training epoch 2
2023-08-05 12:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 12:34:56 | INFO | train_inner | epoch 002:     27 / 1474 loss=3.054, trans_loss=5.362, nll_loss=4.064, w2v_ctc_loss=1.891, task_loss=1.25, contrastive_loss=1.912, total=4162.95, n_correct=332.81, ppl=16.73, accuracy=7.995, wps=10494.7, ups=0.85, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.236, clip=0, loss_scale=64, train_wall=64, gb_free=19.6, wall=1081
2023-08-05 12:36:00 | INFO | train_inner | epoch 002:    127 / 1474 loss=2.955, trans_loss=5.362, nll_loss=4.065, w2v_ctc_loss=1.844, task_loss=1.332, contrastive_loss=1.703, total=4155.98, n_correct=332.01, ppl=16.73, accuracy=7.989, wps=19605.5, ups=1.58, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.296, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1144
2023-08-05 12:37:03 | INFO | train_inner | epoch 002:    227 / 1474 loss=2.872, trans_loss=5.345, nll_loss=4.048, w2v_ctc_loss=1.754, task_loss=1.155, contrastive_loss=1.725, total=4179.21, n_correct=336.85, ppl=16.55, accuracy=8.06, wps=19584.9, ups=1.57, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.154, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1208
2023-08-05 12:38:07 | INFO | train_inner | epoch 002:    327 / 1474 loss=2.749, trans_loss=5.348, nll_loss=4.048, w2v_ctc_loss=1.705, task_loss=1.326, contrastive_loss=1.428, total=4146.1, n_correct=338.42, ppl=16.54, accuracy=8.162, wps=19320.8, ups=1.56, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.04, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=1272
2023-08-05 12:39:10 | INFO | train_inner | epoch 002:    427 / 1474 loss=2.636, trans_loss=5.343, nll_loss=4.046, w2v_ctc_loss=1.648, task_loss=1.457, contrastive_loss=1.236, total=4037.99, n_correct=330.51, ppl=16.51, accuracy=8.185, wps=19181.4, ups=1.59, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.061, clip=0, loss_scale=64, train_wall=62, gb_free=18.9, wall=1335
2023-08-05 12:40:13 | INFO | train_inner | epoch 002:    527 / 1474 loss=2.592, trans_loss=5.331, nll_loss=4.026, w2v_ctc_loss=1.575, task_loss=1.267, contrastive_loss=1.324, total=4176.97, n_correct=350.77, ppl=16.3, accuracy=8.398, wps=19759.6, ups=1.59, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=0.957, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1398
2023-08-05 12:40:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 12:40:52 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 2.502 | trans_loss 10.875 | nll_loss 9.836 | w2v_ctc_loss 1.311 | task_loss 7.545 | contrastive_loss 1.668 | total 4003.4 | n_correct 393.6 | ppl 913.98 | accuracy 9.832 | uer 66.751 | wer 64.263 | raw_wer 64.263 | bleu 0.03 | wps 1192.7 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.03
2023-08-05 12:40:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-05 12:40:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_2_2000.pt
2023-08-05 12:40:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_2_2000.pt
2023-08-05 12:41:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.03) (writing took 24.810913490131497 seconds)
2023-08-05 12:42:21 | INFO | train_inner | epoch 002:    627 / 1474 loss=2.501, trans_loss=5.326, nll_loss=4.019, w2v_ctc_loss=1.519, task_loss=1.309, contrastive_loss=1.117, total=4126.49, n_correct=353.19, ppl=16.21, accuracy=8.559, wps=9637.6, ups=0.78, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=0.869, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1525
2023-08-05 12:43:25 | INFO | train_inner | epoch 002:    727 / 1474 loss=2.459, trans_loss=5.307, nll_loss=3.999, w2v_ctc_loss=1.471, task_loss=1.283, contrastive_loss=1.213, total=4149.06, n_correct=362.96, ppl=15.99, accuracy=8.748, wps=19344, ups=1.56, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=0.791, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=1589
2023-08-05 12:44:29 | INFO | train_inner | epoch 002:    827 / 1474 loss=2.397, trans_loss=5.292, nll_loss=3.982, w2v_ctc_loss=1.432, task_loss=1.317, contrastive_loss=1.152, total=4175.4, n_correct=369.34, ppl=15.8, accuracy=8.846, wps=19674.5, ups=1.58, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=0.717, clip=0, loss_scale=128, train_wall=63, gb_free=19.8, wall=1653
2023-08-05 12:45:32 | INFO | train_inner | epoch 002:    927 / 1474 loss=2.335, trans_loss=5.28, nll_loss=3.965, w2v_ctc_loss=1.381, task_loss=1.344, contrastive_loss=1.13, total=4104.2, n_correct=366.56, ppl=15.61, accuracy=8.931, wps=19455.7, ups=1.59, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=0.706, clip=0, loss_scale=128, train_wall=63, gb_free=19, wall=1716
2023-08-05 12:46:35 | INFO | train_inner | epoch 002:   1027 / 1474 loss=2.289, trans_loss=5.274, nll_loss=3.96, w2v_ctc_loss=1.348, task_loss=1.305, contrastive_loss=0.979, total=4102.5, n_correct=373.06, ppl=15.57, accuracy=9.093, wps=19265.9, ups=1.57, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.602, clip=0, loss_scale=128, train_wall=63, gb_free=19.2, wall=1779
2023-08-05 12:46:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-05 12:47:40 | INFO | train_inner | epoch 002:   1128 / 1474 loss=2.254, trans_loss=5.263, nll_loss=3.945, w2v_ctc_loss=1.308, task_loss=1.219, contrastive_loss=1.05, total=4166.43, n_correct=387.32, ppl=15.4, accuracy=9.296, wps=19101.6, ups=1.54, wpb=12432.5, bsz=474.9, num_updates=2600, lr=0.000104048, gnorm=0.612, clip=0, loss_scale=64, train_wall=65, gb_free=18.9, wall=1845
2023-08-05 12:48:44 | INFO | train_inner | epoch 002:   1228 / 1474 loss=2.222, trans_loss=5.248, nll_loss=3.927, w2v_ctc_loss=1.273, task_loss=1.198, contrastive_loss=1.101, total=4219.96, n_correct=404.82, ppl=15.21, accuracy=9.593, wps=19769.3, ups=1.57, wpb=12591.9, bsz=491.8, num_updates=2700, lr=0.000108046, gnorm=0.532, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1908
2023-08-05 12:49:47 | INFO | train_inner | epoch 002:   1328 / 1474 loss=2.161, trans_loss=5.228, nll_loss=3.904, w2v_ctc_loss=1.258, task_loss=1.25, contrastive_loss=0.811, total=4163.26, n_correct=406.46, ppl=14.97, accuracy=9.763, wps=19807.4, ups=1.59, wpb=12441.6, bsz=463, num_updates=2800, lr=0.000112044, gnorm=0.501, clip=0, loss_scale=64, train_wall=62, gb_free=19, wall=1971
2023-08-05 12:50:51 | INFO | train_inner | epoch 002:   1428 / 1474 loss=2.122, trans_loss=5.236, nll_loss=3.913, w2v_ctc_loss=1.23, task_loss=1.417, contrastive_loss=0.893, total=4049.42, n_correct=394.59, ppl=15.07, accuracy=9.744, wps=18890.5, ups=1.56, wpb=12091.6, bsz=437.6, num_updates=2900, lr=0.000116042, gnorm=0.471, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=2035
2023-08-05 12:51:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 12:52:00 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 2.22 | trans_loss 10.301 | nll_loss 9.12 | w2v_ctc_loss 0.997 | task_loss 7.545 | contrastive_loss 0.967 | total 4003.4 | n_correct 498.1 | ppl 556.51 | accuracy 12.442 | uer 54.721 | wer 53.115 | raw_wer 53.115 | bleu 0.12 | wps 1186.6 | wpb 4003.4 | bsz 141.8 | num_updates 2946 | best_bleu 0.12
2023-08-05 12:52:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2946 updates
2023-08-05 12:52:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 12:52:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 12:52:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 2 @ 2946 updates, score 0.12) (writing took 23.55684795603156 seconds)
2023-08-05 12:52:23 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-05 12:52:23 | INFO | train | epoch 002 | loss 2.467 | trans_loss 5.298 | nll_loss 3.988 | w2v_ctc_loss 1.481 | task_loss 1.295 | contrastive_loss 1.207 | total 4137.19 | n_correct 365.476 | ppl 15.86 | accuracy 8.834 | wps 16958.7 | ups 1.37 | wpb 12351.4 | bsz 457.7 | num_updates 2946 | lr 0.000117881 | gnorm 0.805 | clip 0 | loss_scale 64 | train_wall 931 | gb_free 19.3 | wall 2128
2023-08-05 12:52:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 12:52:24 | INFO | fairseq.trainer | begin training epoch 3
2023-08-05 12:52:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 12:53:06 | INFO | train_inner | epoch 003:     54 / 1474 loss=2.074, trans_loss=5.205, nll_loss=3.875, w2v_ctc_loss=1.199, task_loss=1.33, contrastive_loss=0.789, total=4067, n_correct=415.84, ppl=14.67, accuracy=10.225, wps=9010.4, ups=0.74, wpb=12142, bsz=441.4, num_updates=3000, lr=0.00012004, gnorm=0.457, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=2170
2023-08-05 12:53:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 12:53:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 12:53:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-05 12:53:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-05 12:54:39 | INFO | train_inner | epoch 003:    158 / 1474 loss=1.968, trans_loss=4.475, nll_loss=2.919, w2v_ctc_loss=1.196, task_loss=0.909, contrastive_loss=0.7, total=4144.24, n_correct=1077.2, ppl=7.56, accuracy=25.993, wps=13178.1, ups=1.06, wpb=12374.7, bsz=457.6, num_updates=3100, lr=0.000124038, gnorm=1.157, clip=1, loss_scale=4, train_wall=93, gb_free=16.5, wall=2264
2023-08-05 12:56:12 | INFO | train_inner | epoch 003:    258 / 1474 loss=1.723, trans_loss=4.185, nll_loss=2.54, w2v_ctc_loss=1.066, task_loss=0.915, contrastive_loss=0.579, total=4161.13, n_correct=1408.86, ppl=5.82, accuracy=33.858, wps=13464.5, ups=1.08, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=0.792, clip=0, loss_scale=4, train_wall=92, gb_free=17.1, wall=2356
2023-08-05 12:57:43 | INFO | train_inner | epoch 003:    358 / 1474 loss=1.643, trans_loss=4.107, nll_loss=2.435, w2v_ctc_loss=1.011, task_loss=0.919, contrastive_loss=0.62, total=4150.02, n_correct=1511.14, ppl=5.41, accuracy=36.413, wps=13539.9, ups=1.09, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=0.776, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=2448
2023-08-05 12:59:15 | INFO | train_inner | epoch 003:    458 / 1474 loss=1.575, trans_loss=4.058, nll_loss=2.373, w2v_ctc_loss=0.971, task_loss=0.892, contrastive_loss=0.471, total=4209.57, n_correct=1608.48, ppl=5.18, accuracy=38.21, wps=13641.7, ups=1.09, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=0.728, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=2540
2023-08-05 13:00:46 | INFO | train_inner | epoch 003:    558 / 1474 loss=1.525, trans_loss=4.029, nll_loss=2.334, w2v_ctc_loss=0.939, task_loss=0.978, contrastive_loss=0.449, total=4088.48, n_correct=1604.48, ppl=5.04, accuracy=39.244, wps=13410.8, ups=1.1, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=0.699, clip=0, loss_scale=4, train_wall=91, gb_free=17.7, wall=2631
2023-08-05 13:02:19 | INFO | train_inner | epoch 003:    658 / 1474 loss=1.505, trans_loss=3.993, nll_loss=2.283, w2v_ctc_loss=0.906, task_loss=0.88, contrastive_loss=0.558, total=4221.58, n_correct=1719.33, ppl=4.87, accuracy=40.727, wps=13571.6, ups=1.08, wpb=12587.8, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=0.659, clip=0, loss_scale=4, train_wall=92, gb_free=16.4, wall=2723
2023-08-05 13:03:51 | INFO | train_inner | epoch 003:    758 / 1474 loss=1.45, trans_loss=3.959, nll_loss=2.244, w2v_ctc_loss=0.89, task_loss=0.877, contrastive_loss=0.327, total=4167.41, n_correct=1743.06, ppl=4.74, accuracy=41.826, wps=13622.4, ups=1.09, wpb=12447.6, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=0.643, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=2815
2023-08-05 13:05:22 | INFO | train_inner | epoch 003:    858 / 1474 loss=1.419, trans_loss=3.949, nll_loss=2.229, w2v_ctc_loss=0.869, task_loss=0.93, contrastive_loss=0.293, total=4165.53, n_correct=1767.96, ppl=4.69, accuracy=42.443, wps=13602.4, ups=1.09, wpb=12437.8, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=0.639, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=2906
2023-08-05 13:06:53 | INFO | train_inner | epoch 003:    958 / 1474 loss=1.406, trans_loss=3.927, nll_loss=2.198, w2v_ctc_loss=0.853, task_loss=0.892, contrastive_loss=0.323, total=4162.3, n_correct=1817.04, ppl=4.59, accuracy=43.655, wps=13579.2, ups=1.09, wpb=12417, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=0.581, clip=0, loss_scale=4, train_wall=91, gb_free=16.8, wall=2998
2023-08-05 13:08:24 | INFO | train_inner | epoch 003:   1058 / 1474 loss=1.385, trans_loss=3.905, nll_loss=2.171, w2v_ctc_loss=0.848, task_loss=0.978, contrastive_loss=0.28, total=4069.95, n_correct=1793.37, ppl=4.5, accuracy=44.064, wps=13392.7, ups=1.1, wpb=12153.7, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=0.573, clip=0, loss_scale=4, train_wall=90, gb_free=16.3, wall=3088
2023-08-05 13:08:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 13:08:53 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 1.868 | trans_loss 6.423 | nll_loss 3.973 | w2v_ctc_loss 0.796 | task_loss 4.282 | contrastive_loss 0.389 | total 4003.4 | n_correct 1948 | ppl 15.7 | accuracy 48.659 | uer 31.301 | wer 32.072 | raw_wer 32.072 | bleu 11.01 | wps 1605.1 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 11.01
2023-08-05 13:08:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-05 13:08:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_3_4000.pt
2023-08-05 13:08:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_3_4000.pt
2023-08-05 13:09:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 11.01) (writing took 23.15970770828426 seconds)
2023-08-05 13:10:48 | INFO | train_inner | epoch 003:   1158 / 1474 loss=1.367, trans_loss=3.896, nll_loss=2.158, w2v_ctc_loss=0.832, task_loss=0.995, contrastive_loss=0.264, total=4038.49, n_correct=1802.43, ppl=4.46, accuracy=44.631, wps=8403.4, ups=0.7, wpb=12054.8, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=0.582, clip=0, loss_scale=4, train_wall=91, gb_free=16.4, wall=3232
2023-08-05 13:12:18 | INFO | train_inner | epoch 003:   1258 / 1474 loss=1.341, trans_loss=3.875, nll_loss=2.131, w2v_ctc_loss=0.813, task_loss=0.974, contrastive_loss=0.248, total=4064.31, n_correct=1846.3, ppl=4.38, accuracy=45.427, wps=13448.3, ups=1.11, wpb=12136.8, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.537, clip=0, loss_scale=4, train_wall=90, gb_free=17.3, wall=3322
2023-08-05 13:13:50 | INFO | train_inner | epoch 003:   1358 / 1474 loss=1.332, trans_loss=3.859, nll_loss=2.112, w2v_ctc_loss=0.79, task_loss=0.93, contrastive_loss=0.351, total=4134.58, n_correct=1904.02, ppl=4.32, accuracy=46.051, wps=13460, ups=1.09, wpb=12343.8, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.552, clip=0, loss_scale=4, train_wall=91, gb_free=17.8, wall=3414
2023-08-05 13:15:22 | INFO | train_inner | epoch 003:   1458 / 1474 loss=1.317, trans_loss=3.845, nll_loss=2.095, w2v_ctc_loss=0.78, task_loss=0.879, contrastive_loss=0.333, total=4209.94, n_correct=1961.12, ppl=4.27, accuracy=46.583, wps=13662.7, ups=1.09, wpb=12573.5, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.535, clip=0, loss_scale=4, train_wall=92, gb_free=17, wall=3506
2023-08-05 13:15:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 13:16:01 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 1.847 | trans_loss 6.3 | nll_loss 3.806 | w2v_ctc_loss 0.75 | task_loss 4.149 | contrastive_loss 0.359 | total 4003.4 | n_correct 2038.3 | ppl 13.99 | accuracy 50.914 | uer 30.367 | wer 30.428 | raw_wer 30.428 | bleu 12.31 | wps 2007.7 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 12.31
2023-08-05 13:16:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-08-05 13:16:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 13:16:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 13:16:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 3 @ 4416 updates, score 12.31) (writing took 23.433496836572886 seconds)
2023-08-05 13:16:24 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-05 13:16:24 | INFO | train | epoch 003 | loss 1.519 | trans_loss 4.047 | nll_loss 2.357 | w2v_ctc_loss 0.922 | task_loss 0.938 | contrastive_loss 0.43 | total 4139.74 | n_correct 1638.86 | ppl 5.12 | accuracy 39.589 | wps 12608.1 | ups 1.02 | wpb 12359.1 | bsz 458.8 | num_updates 4416 | lr 0.000176652 | gnorm 0.665 | clip 0.1 | loss_scale 4 | train_wall 1326 | gb_free 16.4 | wall 3569
2023-08-05 13:16:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 13:16:25 | INFO | fairseq.trainer | begin training epoch 4
2023-08-05 13:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 13:17:49 | INFO | train_inner | epoch 004:     84 / 1474 loss=1.279, trans_loss=3.821, nll_loss=2.059, w2v_ctc_loss=0.767, task_loss=0.955, contrastive_loss=0.193, total=4099.41, n_correct=1940, ppl=4.17, accuracy=47.324, wps=8306.1, ups=0.68, wpb=12237, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.536, clip=0, loss_scale=4, train_wall=91, gb_free=16.3, wall=3653
2023-08-05 13:19:19 | INFO | train_inner | epoch 004:    184 / 1474 loss=1.258, trans_loss=3.797, nll_loss=2.03, w2v_ctc_loss=0.747, task_loss=0.883, contrastive_loss=0.217, total=4175.15, n_correct=2013.88, ppl=4.08, accuracy=48.235, wps=13814.4, ups=1.11, wpb=12464.9, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.495, clip=0, loss_scale=4, train_wall=90, gb_free=16.6, wall=3744
2023-08-05 13:20:50 | INFO | train_inner | epoch 004:    284 / 1474 loss=1.275, trans_loss=3.801, nll_loss=2.037, w2v_ctc_loss=0.749, task_loss=0.926, contrastive_loss=0.342, total=4145.23, n_correct=1991.44, ppl=4.1, accuracy=48.042, wps=13591.4, ups=1.1, wpb=12382.4, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.5, clip=0, loss_scale=4, train_wall=91, gb_free=15.9, wall=3835
2023-08-05 13:22:21 | INFO | train_inner | epoch 004:    384 / 1474 loss=1.259, trans_loss=3.806, nll_loss=2.039, w2v_ctc_loss=0.75, task_loss=0.965, contrastive_loss=0.193, total=4127.66, n_correct=1986.71, ppl=4.11, accuracy=48.132, wps=13622.6, ups=1.11, wpb=12314.6, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.541, clip=0, loss_scale=4, train_wall=90, gb_free=17.4, wall=3925
2023-08-05 13:23:53 | INFO | train_inner | epoch 004:    484 / 1474 loss=1.288, trans_loss=3.785, nll_loss=2.015, w2v_ctc_loss=0.724, task_loss=0.838, contrastive_loss=0.573, total=4218.78, n_correct=2063.86, ppl=4.04, accuracy=48.921, wps=13666.6, ups=1.09, wpb=12592.4, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.509, clip=0, loss_scale=4, train_wall=92, gb_free=16.5, wall=4017
2023-08-05 13:25:25 | INFO | train_inner | epoch 004:    584 / 1474 loss=1.251, trans_loss=3.778, nll_loss=2.007, w2v_ctc_loss=0.735, task_loss=0.871, contrastive_loss=0.259, total=4217.52, n_correct=2078.72, ppl=4.02, accuracy=49.288, wps=13707.4, ups=1.09, wpb=12591.1, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.47, clip=0, loss_scale=4, train_wall=91, gb_free=16, wall=4109
mt_weight tensor(0.5000)
asr_weight tensor(0.5145, device='cuda:0')
2023-08-05 13:26:58 | INFO | train_inner | epoch 004:    684 / 1474 loss=1.235, trans_loss=3.781, nll_loss=2.005, w2v_ctc_loss=0.716, task_loss=0.949, contrastive_loss=0.303, total=4176.39, n_correct=2070.39, ppl=4.02, accuracy=49.574, wps=13407.4, ups=1.08, wpb=12448.9, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.318, clip=0, loss_scale=8, train_wall=92, gb_free=17.1, wall=4202
2023-08-05 13:28:29 | INFO | train_inner | epoch 004:    784 / 1474 loss=1.219, trans_loss=3.768, nll_loss=1.994, w2v_ctc_loss=0.722, task_loss=1.021, contrastive_loss=0.176, total=4026.63, n_correct=2007.04, ppl=3.98, accuracy=49.844, wps=13220.9, ups=1.1, wpb=12025, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.304, clip=0, loss_scale=8, train_wall=90, gb_free=13.1, wall=4293
2023-08-05 13:30:01 | INFO | train_inner | epoch 004:    884 / 1474 loss=1.239, trans_loss=3.755, nll_loss=1.978, w2v_ctc_loss=0.715, task_loss=0.924, contrastive_loss=0.355, total=4186.04, n_correct=2099.79, ppl=3.94, accuracy=50.162, wps=13552.8, ups=1.08, wpb=12501.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.31, clip=0, loss_scale=8, train_wall=92, gb_free=17.7, wall=4385
2023-08-05 13:31:33 | INFO | train_inner | epoch 004:    984 / 1474 loss=1.205, trans_loss=3.744, nll_loss=1.964, w2v_ctc_loss=0.702, task_loss=0.94, contrastive_loss=0.222, total=4125.02, n_correct=2092.67, ppl=3.9, accuracy=50.731, wps=13423.6, ups=1.09, wpb=12321, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.3, clip=0, loss_scale=8, train_wall=91, gb_free=12.7, wall=4477
2023-08-05 13:33:04 | INFO | train_inner | epoch 004:   1084 / 1474 loss=1.208, trans_loss=3.754, nll_loss=1.975, w2v_ctc_loss=0.709, task_loss=1.002, contrastive_loss=0.197, total=4075.6, n_correct=2060.19, ppl=3.93, accuracy=50.549, wps=13295.8, ups=1.09, wpb=12163.4, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.298, clip=0, loss_scale=8, train_wall=91, gb_free=16, wall=4568
2023-08-05 13:34:35 | INFO | train_inner | epoch 004:   1184 / 1474 loss=1.21, trans_loss=3.737, nll_loss=1.959, w2v_ctc_loss=0.697, task_loss=0.871, contrastive_loss=0.307, total=4161.18, n_correct=2123.89, ppl=3.89, accuracy=51.041, wps=13671.1, ups=1.1, wpb=12431.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.289, clip=0, loss_scale=8, train_wall=90, gb_free=16.8, wall=4659
2023-08-05 13:36:07 | INFO | train_inner | epoch 004:   1284 / 1474 loss=1.197, trans_loss=3.728, nll_loss=1.945, w2v_ctc_loss=0.689, task_loss=0.884, contrastive_loss=0.269, total=4156.53, n_correct=2142.76, ppl=3.85, accuracy=51.552, wps=13469.4, ups=1.09, wpb=12411.4, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.287, clip=0, loss_scale=8, train_wall=92, gb_free=15.8, wall=4751
2023-08-05 13:37:37 | INFO | train_inner | epoch 004:   1384 / 1474 loss=1.175, trans_loss=3.725, nll_loss=1.941, w2v_ctc_loss=0.688, task_loss=0.952, contrastive_loss=0.153, total=4101.23, n_correct=2121.46, ppl=3.84, accuracy=51.727, wps=13692.7, ups=1.12, wpb=12249, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.279, clip=0, loss_scale=8, train_wall=89, gb_free=15.6, wall=4841
2023-08-05 13:38:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.5145, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.5145, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.5145, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.5145, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.5145, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.5145, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.5145, device='cuda:7')
2023-08-05 13:39:22 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 1.658 | trans_loss 5.951 | nll_loss 3.34 | w2v_ctc_loss 0.593 | task_loss 4.385 | contrastive_loss 0.289 | total 4003.4 | n_correct 2233.8 | ppl 10.12 | accuracy 55.798 | uer 24.851 | wer 26.364 | raw_wer 26.364 | bleu 15.86 | wps 2019.4 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 15.86
2023-08-05 13:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-08-05 13:39:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 13:39:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 13:39:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 4 @ 5890 updates, score 15.86) (writing took 22.737185632809997 seconds)
2023-08-05 13:39:45 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-05 13:39:45 | INFO | train | epoch 004 | loss 1.231 | trans_loss 3.766 | nll_loss 1.992 | w2v_ctc_loss 0.719 | task_loss 0.927 | contrastive_loss 0.267 | total 4138.65 | n_correct 2061.61 | ppl 3.98 | accuracy 49.814 | wps 12999.1 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.38 | clip 0 | loss_scale 8 | train_wall 1339 | gb_free 14.8 | wall 4970
2023-08-05 13:39:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 13:39:46 | INFO | fairseq.trainer | begin training epoch 5
2023-08-05 13:39:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 13:40:02 | INFO | train_inner | epoch 005:     10 / 1474 loss=1.167, trans_loss=3.717, nll_loss=1.929, w2v_ctc_loss=0.675, task_loss=0.964, contrastive_loss=0.169, total=4037.7, n_correct=2100.5, ppl=3.81, accuracy=52.022, wps=8285.1, ups=0.69, wpb=12055.9, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.28, clip=0, loss_scale=8, train_wall=90, gb_free=16.9, wall=4986
2023-08-05 13:41:33 | INFO | train_inner | epoch 005:    110 / 1474 loss=1.132, trans_loss=3.661, nll_loss=1.857, w2v_ctc_loss=0.639, task_loss=0.838, contrastive_loss=0.175, total=4247.37, n_correct=2284.14, ppl=3.62, accuracy=53.778, wps=13926.3, ups=1.1, wpb=12683.4, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.268, clip=0, loss_scale=8, train_wall=91, gb_free=16.7, wall=5078
2023-08-05 13:41:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 13:41:59 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 1.64 | trans_loss 5.94 | nll_loss 3.325 | w2v_ctc_loss 0.571 | task_loss 4.398 | contrastive_loss 0.29 | total 4003.4 | n_correct 2239.5 | ppl 10.02 | accuracy 55.94 | uer 24.394 | wer 25.845 | raw_wer 25.845 | bleu 15.9 | wps 1906.8 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 15.9
2023-08-05 13:41:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-05 13:41:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_5_6000.pt
2023-08-05 13:42:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_5_6000.pt
2023-08-05 13:42:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 15.9) (writing took 27.12666617333889 seconds)
2023-08-05 13:43:57 | INFO | train_inner | epoch 005:    210 / 1474 loss=1.162, trans_loss=3.673, nll_loss=1.87, w2v_ctc_loss=0.645, task_loss=0.857, contrastive_loss=0.395, total=4189.85, n_correct=2239.6, ppl=3.66, accuracy=53.453, wps=8710.2, ups=0.7, wpb=12500.5, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.264, clip=0, loss_scale=8, train_wall=90, gb_free=17.8, wall=5221
2023-08-05 13:45:27 | INFO | train_inner | epoch 005:    310 / 1474 loss=1.137, trans_loss=3.667, nll_loss=1.867, w2v_ctc_loss=0.647, task_loss=0.955, contrastive_loss=0.24, total=4090.1, n_correct=2178.18, ppl=3.65, accuracy=53.255, wps=13553, ups=1.11, wpb=12228.1, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.265, clip=0, loss_scale=8, train_wall=90, gb_free=16.2, wall=5311
2023-08-05 13:46:58 | INFO | train_inner | epoch 005:    410 / 1474 loss=1.147, trans_loss=3.658, nll_loss=1.857, w2v_ctc_loss=0.635, task_loss=0.898, contrastive_loss=0.329, total=4147.17, n_correct=2229.03, ppl=3.62, accuracy=53.748, wps=13615, ups=1.1, wpb=12395.1, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.276, clip=0, loss_scale=8, train_wall=91, gb_free=14.8, wall=5402
2023-08-05 13:48:29 | INFO | train_inner | epoch 005:    510 / 1474 loss=1.122, trans_loss=3.671, nll_loss=1.871, w2v_ctc_loss=0.643, task_loss=1.044, contrastive_loss=0.127, total=4026.81, n_correct=2152.24, ppl=3.66, accuracy=53.448, wps=13212.4, ups=1.1, wpb=12029.7, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.269, clip=0, loss_scale=8, train_wall=91, gb_free=17.4, wall=5493
2023-08-05 13:50:00 | INFO | train_inner | epoch 005:    610 / 1474 loss=1.14, trans_loss=3.674, nll_loss=1.872, w2v_ctc_loss=0.635, task_loss=0.954, contrastive_loss=0.292, total=4107.75, n_correct=2201, ppl=3.66, accuracy=53.582, wps=13455.1, ups=1.1, wpb=12253.8, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.283, clip=0, loss_scale=8, train_wall=91, gb_free=16.1, wall=5584
2023-08-05 13:51:31 | INFO | train_inner | epoch 005:    710 / 1474 loss=1.135, trans_loss=3.666, nll_loss=1.864, w2v_ctc_loss=0.631, task_loss=0.88, contrastive_loss=0.269, total=4178.85, n_correct=2256.19, ppl=3.64, accuracy=53.991, wps=13653.3, ups=1.09, wpb=12473.1, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.266, clip=0, loss_scale=8, train_wall=91, gb_free=17.7, wall=5676
2023-08-05 13:53:03 | INFO | train_inner | epoch 005:    810 / 1474 loss=1.121, trans_loss=3.664, nll_loss=1.861, w2v_ctc_loss=0.629, task_loss=0.954, contrastive_loss=0.197, total=4127.73, n_correct=2230.55, ppl=3.63, accuracy=54.038, wps=13416.4, ups=1.09, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.26, clip=0, loss_scale=8, train_wall=91, gb_free=15.1, wall=5768
2023-08-05 13:54:34 | INFO | train_inner | epoch 005:    910 / 1474 loss=1.108, trans_loss=3.656, nll_loss=1.853, w2v_ctc_loss=0.624, task_loss=0.963, contrastive_loss=0.158, total=4095.48, n_correct=2224.13, ppl=3.61, accuracy=54.307, wps=13424.9, ups=1.1, wpb=12229.5, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.262, clip=0, loss_scale=8, train_wall=91, gb_free=15.5, wall=5859
2023-08-05 13:56:05 | INFO | train_inner | epoch 005:   1010 / 1474 loss=1.113, trans_loss=3.658, nll_loss=1.855, w2v_ctc_loss=0.622, task_loss=0.918, contrastive_loss=0.238, total=4165.12, n_correct=2259.54, ppl=3.62, accuracy=54.249, wps=13661.7, ups=1.1, wpb=12433.6, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.258, clip=0, loss_scale=8, train_wall=91, gb_free=15.6, wall=5950
2023-08-05 13:57:38 | INFO | train_inner | epoch 005:   1110 / 1474 loss=1.124, trans_loss=3.66, nll_loss=1.856, w2v_ctc_loss=0.627, task_loss=0.921, contrastive_loss=0.24, total=4176.72, n_correct=2271.86, ppl=3.62, accuracy=54.393, wps=13489.6, ups=1.08, wpb=12459.2, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.262, clip=0, loss_scale=8, train_wall=92, gb_free=16.7, wall=6042
2023-08-05 13:59:09 | INFO | train_inner | epoch 005:   1210 / 1474 loss=1.1, trans_loss=3.654, nll_loss=1.848, w2v_ctc_loss=0.616, task_loss=0.947, contrastive_loss=0.144, total=4164.13, n_correct=2275.92, ppl=3.6, accuracy=54.655, wps=13635.4, ups=1.1, wpb=12420.9, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.259, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=6133
2023-08-05 14:00:41 | INFO | train_inner | epoch 005:   1310 / 1474 loss=1.09, trans_loss=3.652, nll_loss=1.847, w2v_ctc_loss=0.61, task_loss=0.945, contrastive_loss=0.12, total=4134.91, n_correct=2259.18, ppl=3.6, accuracy=54.637, wps=13425.9, ups=1.09, wpb=12341.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.257, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=6225
2023-08-05 14:02:12 | INFO | train_inner | epoch 005:   1410 / 1474 loss=1.09, trans_loss=3.651, nll_loss=1.848, w2v_ctc_loss=0.604, task_loss=0.938, contrastive_loss=0.177, total=4134.37, n_correct=2258.66, ppl=3.6, accuracy=54.631, wps=13499.2, ups=1.09, wpb=12347.5, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.258, clip=0, loss_scale=16, train_wall=91, gb_free=17.8, wall=6317
2023-08-05 14:03:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 14:03:35 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 1.603 | trans_loss 5.866 | nll_loss 3.23 | w2v_ctc_loss 0.529 | task_loss 4.448 | contrastive_loss 0.301 | total 4003.4 | n_correct 2287.5 | ppl 9.38 | accuracy 57.139 | uer 23.024 | wer 24.66 | raw_wer 24.66 | bleu 16.65 | wps 2033.9 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 16.65
2023-08-05 14:03:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-08-05 14:03:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 14:03:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 14:04:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 5 @ 7364 updates, score 16.65) (writing took 25.871767902746797 seconds)
2023-08-05 14:04:01 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-05 14:04:01 | INFO | train | epoch 005 | loss 1.122 | trans_loss 3.661 | nll_loss 1.858 | w2v_ctc_loss 0.629 | task_loss 0.929 | contrastive_loss 0.222 | total 4138.65 | n_correct 2236.52 | ppl 3.63 | accuracy 54.04 | wps 12513.9 | ups 1.01 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.265 | clip 0 | loss_scale 16 | train_wall 1337 | gb_free 16.2 | wall 6425
2023-08-05 14:04:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 14:04:01 | INFO | fairseq.trainer | begin training epoch 6
2023-08-05 14:04:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 14:04:42 | INFO | train_inner | epoch 006:     36 / 1474 loss=1.09, trans_loss=3.627, nll_loss=1.815, w2v_ctc_loss=0.605, task_loss=0.955, contrastive_loss=0.175, total=4115.45, n_correct=2275.96, ppl=3.52, accuracy=55.303, wps=8227.4, ups=0.67, wpb=12281.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.262, clip=0, loss_scale=16, train_wall=91, gb_free=16.4, wall=6466
2023-08-05 14:06:12 | INFO | train_inner | epoch 006:    136 / 1474 loss=1.071, trans_loss=3.598, nll_loss=1.778, w2v_ctc_loss=0.584, task_loss=0.926, contrastive_loss=0.219, total=4154.25, n_correct=2322.52, ppl=3.43, accuracy=55.907, wps=13666.4, ups=1.1, wpb=12407.4, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.266, clip=0, loss_scale=16, train_wall=90, gb_free=15.5, wall=6557
2023-08-05 14:07:44 | INFO | train_inner | epoch 006:    236 / 1474 loss=1.069, trans_loss=3.608, nll_loss=1.792, w2v_ctc_loss=0.597, task_loss=0.998, contrastive_loss=0.127, total=4112.66, n_correct=2292.77, ppl=3.46, accuracy=55.749, wps=13419.1, ups=1.09, wpb=12287.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.257, clip=0, loss_scale=16, train_wall=91, gb_free=16.1, wall=6648
2023-08-05 14:09:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-05 14:09:18 | INFO | train_inner | epoch 006:    337 / 1474 loss=1.069, trans_loss=3.595, nll_loss=1.775, w2v_ctc_loss=0.573, task_loss=0.902, contrastive_loss=0.28, total=4140.92, n_correct=2331.41, ppl=3.42, accuracy=56.302, wps=13199.7, ups=1.07, wpb=12364.6, bsz=473.5, num_updates=7700, lr=0.000161165, gnorm=0.261, clip=0, loss_scale=8, train_wall=93, gb_free=15.6, wall=6742
2023-08-05 14:10:48 | INFO | train_inner | epoch 006:    437 / 1474 loss=1.059, trans_loss=3.599, nll_loss=1.78, w2v_ctc_loss=0.579, task_loss=0.894, contrastive_loss=0.139, total=4154.89, n_correct=2340.66, ppl=3.43, accuracy=56.335, wps=13698, ups=1.1, wpb=12405.6, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.255, clip=0, loss_scale=8, train_wall=90, gb_free=16.4, wall=6832
2023-08-05 14:12:19 | INFO | train_inner | epoch 006:    537 / 1474 loss=1.059, trans_loss=3.604, nll_loss=1.786, w2v_ctc_loss=0.584, task_loss=0.925, contrastive_loss=0.13, total=4174.46, n_correct=2347.47, ppl=3.45, accuracy=56.234, wps=13690.2, ups=1.1, wpb=12460.1, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.258, clip=0, loss_scale=8, train_wall=91, gb_free=17.2, wall=6924
2023-08-05 14:13:50 | INFO | train_inner | epoch 006:    637 / 1474 loss=1.057, trans_loss=3.605, nll_loss=1.788, w2v_ctc_loss=0.572, task_loss=0.883, contrastive_loss=0.183, total=4145.19, n_correct=2331.99, ppl=3.45, accuracy=56.258, wps=13592.9, ups=1.1, wpb=12372.7, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.253, clip=0, loss_scale=8, train_wall=91, gb_free=15.8, wall=7015
2023-08-05 14:13:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 14:14:14 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 1.566 | trans_loss 5.79 | nll_loss 3.127 | w2v_ctc_loss 0.52 | task_loss 4.52 | contrastive_loss 0.271 | total 4003.4 | n_correct 2326.1 | ppl 8.73 | accuracy 58.103 | uer 21.923 | wer 23.735 | raw_wer 23.735 | bleu 17.48 | wps 2119.5 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.48
2023-08-05 14:14:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-05 14:14:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_6_8000.pt
2023-08-05 14:14:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_6_8000.pt
2023-08-05 14:15:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.48) (writing took 45.79190433397889 seconds)
2023-08-05 14:16:32 | INFO | train_inner | epoch 006:    737 / 1474 loss=1.056, trans_loss=3.609, nll_loss=1.794, w2v_ctc_loss=0.581, task_loss=0.95, contrastive_loss=0.137, total=4151.01, n_correct=2327.8, ppl=3.47, accuracy=56.078, wps=7682.9, ups=0.62, wpb=12393.7, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.255, clip=0, loss_scale=8, train_wall=91, gb_free=12.9, wall=7176
2023-08-05 14:18:03 | INFO | train_inner | epoch 006:    837 / 1474 loss=1.057, trans_loss=3.618, nll_loss=1.805, w2v_ctc_loss=0.581, task_loss=0.985, contrastive_loss=0.121, total=4108.83, n_correct=2297.64, ppl=3.49, accuracy=55.92, wps=13427.6, ups=1.09, wpb=12267.1, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.252, clip=0, loss_scale=8, train_wall=91, gb_free=17.1, wall=7267
2023-08-05 14:19:34 | INFO | train_inner | epoch 006:    937 / 1474 loss=1.072, trans_loss=3.616, nll_loss=1.802, w2v_ctc_loss=0.581, task_loss=0.977, contrastive_loss=0.219, total=4076.46, n_correct=2285.34, ppl=3.49, accuracy=56.062, wps=13422.1, ups=1.1, wpb=12166, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.259, clip=0, loss_scale=8, train_wall=90, gb_free=12.5, wall=7358
2023-08-05 14:21:05 | INFO | train_inner | epoch 006:   1037 / 1474 loss=1.069, trans_loss=3.6, nll_loss=1.784, w2v_ctc_loss=0.57, task_loss=0.873, contrastive_loss=0.288, total=4175.9, n_correct=2356.66, ppl=3.44, accuracy=56.435, wps=13630.5, ups=1.09, wpb=12465, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.258, clip=0, loss_scale=8, train_wall=91, gb_free=14.1, wall=7449
2023-08-05 14:22:36 | INFO | train_inner | epoch 006:   1137 / 1474 loss=1.056, trans_loss=3.605, nll_loss=1.789, w2v_ctc_loss=0.579, task_loss=1.021, contrastive_loss=0.127, total=4077.2, n_correct=2292.69, ppl=3.45, accuracy=56.232, wps=13359.2, ups=1.1, wpb=12172.7, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.253, clip=0, loss_scale=8, train_wall=91, gb_free=16.2, wall=7540
2023-08-05 14:24:08 | INFO | train_inner | epoch 006:   1237 / 1474 loss=1.085, trans_loss=3.599, nll_loss=1.784, w2v_ctc_loss=0.567, task_loss=0.914, contrastive_loss=0.436, total=4133.46, n_correct=2330.93, ppl=3.44, accuracy=56.392, wps=13473, ups=1.09, wpb=12346.4, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.254, clip=0, loss_scale=8, train_wall=91, gb_free=12.2, wall=7632
2023-08-05 14:25:38 | INFO | train_inner | epoch 006:   1337 / 1474 loss=1.044, trans_loss=3.604, nll_loss=1.787, w2v_ctc_loss=0.569, task_loss=0.922, contrastive_loss=0.113, total=4127.77, n_correct=2338.07, ppl=3.45, accuracy=56.642, wps=13624.1, ups=1.11, wpb=12312.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.251, clip=0, loss_scale=8, train_wall=90, gb_free=17, wall=7722
2023-08-05 14:27:10 | INFO | train_inner | epoch 006:   1437 / 1474 loss=1.043, trans_loss=3.597, nll_loss=1.779, w2v_ctc_loss=0.569, task_loss=0.934, contrastive_loss=0.117, total=4190.32, n_correct=2378.55, ppl=3.43, accuracy=56.763, wps=13621.8, ups=1.09, wpb=12507.6, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.245, clip=0, loss_scale=8, train_wall=91, gb_free=16.8, wall=7814
2023-08-05 14:27:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 14:28:06 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 1.54 | trans_loss 5.743 | nll_loss 3.07 | w2v_ctc_loss 0.494 | task_loss 4.555 | contrastive_loss 0.262 | total 4003.4 | n_correct 2351.6 | ppl 8.4 | accuracy 58.74 | uer 20.274 | wer 21.99 | raw_wer 21.99 | bleu 18.09 | wps 2137.4 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 18.09
2023-08-05 14:28:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-08-05 14:28:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 14:28:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 14:28:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 6 @ 8837 updates, score 18.09) (writing took 24.186979807913303 seconds)
2023-08-05 14:28:31 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-05 14:28:31 | INFO | train | epoch 006 | loss 1.061 | trans_loss 3.604 | nll_loss 1.787 | w2v_ctc_loss 0.577 | task_loss 0.933 | contrastive_loss 0.187 | total 4136.5 | n_correct 2326.92 | ppl 3.45 | accuracy 56.253 | wps 12373.7 | ups 1 | wpb 12349.4 | bsz 457.4 | num_updates 8837 | lr 0.00015044 | gnorm 0.255 | clip 0 | loss_scale 8 | train_wall 1338 | gb_free 15 | wall 7895
2023-08-05 14:28:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 14:28:31 | INFO | fairseq.trainer | begin training epoch 7
2023-08-05 14:28:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 14:29:37 | INFO | train_inner | epoch 007:     63 / 1474 loss=1.027, trans_loss=3.574, nll_loss=1.751, w2v_ctc_loss=0.553, task_loss=0.908, contrastive_loss=0.131, total=4110.43, n_correct=2355.1, ppl=3.37, accuracy=57.296, wps=8367.5, ups=0.68, wpb=12272.9, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.255, clip=0, loss_scale=8, train_wall=91, gb_free=17.3, wall=7961
2023-08-05 14:31:07 | INFO | train_inner | epoch 007:    163 / 1474 loss=1.025, trans_loss=3.563, nll_loss=1.735, w2v_ctc_loss=0.544, task_loss=0.946, contrastive_loss=0.203, total=4109.53, n_correct=2366, ppl=3.33, accuracy=57.573, wps=13533.3, ups=1.1, wpb=12269.6, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.246, clip=0, loss_scale=8, train_wall=90, gb_free=13.5, wall=8052
2023-08-05 14:32:39 | INFO | train_inner | epoch 007:    263 / 1474 loss=1.017, trans_loss=3.559, nll_loss=1.729, w2v_ctc_loss=0.548, task_loss=0.931, contrastive_loss=0.112, total=4133.29, n_correct=2388.26, ppl=3.31, accuracy=57.781, wps=13516.4, ups=1.1, wpb=12335.8, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.249, clip=0, loss_scale=8, train_wall=91, gb_free=15.2, wall=8143
2023-08-05 14:34:11 | INFO | train_inner | epoch 007:    363 / 1474 loss=1.05, trans_loss=3.568, nll_loss=1.741, w2v_ctc_loss=0.544, task_loss=0.906, contrastive_loss=0.368, total=4194.76, n_correct=2414.33, ppl=3.34, accuracy=57.556, wps=13574.3, ups=1.08, wpb=12518.2, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.248, clip=0, loss_scale=8, train_wall=92, gb_free=12.9, wall=8235
2023-08-05 14:35:42 | INFO | train_inner | epoch 007:    463 / 1474 loss=1.038, trans_loss=3.568, nll_loss=1.743, w2v_ctc_loss=0.543, task_loss=0.921, contrastive_loss=0.3, total=4153.22, n_correct=2385.39, ppl=3.35, accuracy=57.435, wps=13586, ups=1.1, wpb=12403.3, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.252, clip=0, loss_scale=8, train_wall=91, gb_free=16.8, wall=8326
2023-08-05 14:37:13 | INFO | train_inner | epoch 007:    563 / 1474 loss=1.016, trans_loss=3.567, nll_loss=1.738, w2v_ctc_loss=0.543, task_loss=0.91, contrastive_loss=0.118, total=4168.14, n_correct=2407, ppl=3.34, accuracy=57.748, wps=13690.4, ups=1.1, wpb=12434.7, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.243, clip=0, loss_scale=8, train_wall=90, gb_free=16.8, wall=8417
2023-08-05 14:38:45 | INFO | train_inner | epoch 007:    663 / 1474 loss=1.012, trans_loss=3.564, nll_loss=1.736, w2v_ctc_loss=0.54, task_loss=0.922, contrastive_loss=0.108, total=4157.82, n_correct=2407.75, ppl=3.33, accuracy=57.909, wps=13531.2, ups=1.09, wpb=12406.4, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.242, clip=0, loss_scale=8, train_wall=91, gb_free=15.5, wall=8509
2023-08-05 14:40:17 | INFO | train_inner | epoch 007:    763 / 1474 loss=1.012, trans_loss=3.562, nll_loss=1.734, w2v_ctc_loss=0.541, task_loss=0.974, contrastive_loss=0.106, total=4122.1, n_correct=2379.42, ppl=3.33, accuracy=57.723, wps=13303.9, ups=1.08, wpb=12308.4, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.246, clip=0, loss_scale=8, train_wall=92, gb_free=15.6, wall=8601
2023-08-05 14:41:49 | INFO | train_inner | epoch 007:    863 / 1474 loss=1.015, trans_loss=3.571, nll_loss=1.746, w2v_ctc_loss=0.541, task_loss=0.938, contrastive_loss=0.124, total=4147.23, n_correct=2389.49, ppl=3.35, accuracy=57.617, wps=13453.1, ups=1.09, wpb=12377.6, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.247, clip=0, loss_scale=8, train_wall=91, gb_free=17.5, wall=8693
2023-08-05 14:43:20 | INFO | train_inner | epoch 007:    963 / 1474 loss=1.023, trans_loss=3.564, nll_loss=1.738, w2v_ctc_loss=0.534, task_loss=0.885, contrastive_loss=0.214, total=4140.14, n_correct=2394.77, ppl=3.34, accuracy=57.843, wps=13538.8, ups=1.1, wpb=12359.1, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.251, clip=0, loss_scale=16, train_wall=91, gb_free=15.9, wall=8785
2023-08-05 14:44:52 | INFO | train_inner | epoch 007:   1063 / 1474 loss=1.012, trans_loss=3.577, nll_loss=1.754, w2v_ctc_loss=0.544, task_loss=0.976, contrastive_loss=0.093, total=4103.51, n_correct=2360.27, ppl=3.37, accuracy=57.518, wps=13411.8, ups=1.09, wpb=12251.1, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.248, clip=0, loss_scale=16, train_wall=91, gb_free=16.8, wall=8876
2023-08-05 14:46:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-05 14:46:24 | INFO | train_inner | epoch 007:   1164 / 1474 loss=1.031, trans_loss=3.559, nll_loss=1.735, w2v_ctc_loss=0.534, task_loss=0.928, contrastive_loss=0.294, total=4115.79, n_correct=2386.58, ppl=3.33, accuracy=57.986, wps=13276.2, ups=1.08, wpb=12298, bsz=460.5, num_updates=10000, lr=0.000141421, gnorm=0.248, clip=0, loss_scale=8, train_wall=92, gb_free=16.6, wall=8969
2023-08-05 14:46:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 14:46:48 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 1.521 | trans_loss 5.701 | nll_loss 3.02 | w2v_ctc_loss 0.472 | task_loss 4.577 | contrastive_loss 0.264 | total 4003.4 | n_correct 2382.8 | ppl 8.11 | accuracy 59.519 | uer 19.507 | wer 21.263 | raw_wer 21.263 | bleu 18.59 | wps 2252.9 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.59
2023-08-05 14:46:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-05 14:46:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_7_10000.pt
2023-08-05 14:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_7_10000.pt
2023-08-05 14:47:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.59) (writing took 45.88750849105418 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:0')
2023-08-05 14:49:05 | INFO | train_inner | epoch 007:   1264 / 1474 loss=1.009, trans_loss=3.568, nll_loss=1.746, w2v_ctc_loss=0.535, task_loss=0.949, contrastive_loss=0.117, total=4129.16, n_correct=2383.3, ppl=3.35, accuracy=57.719, wps=7702.8, ups=0.62, wpb=12331, bsz=448.9, num_updates=10100, lr=0.00014072, gnorm=0.193, clip=0, loss_scale=8, train_wall=90, gb_free=16.7, wall=9129
2023-08-05 14:50:35 | INFO | train_inner | epoch 007:   1364 / 1474 loss=1.018, trans_loss=3.559, nll_loss=1.733, w2v_ctc_loss=0.539, task_loss=0.869, contrastive_loss=0.151, total=4177.71, n_correct=2427.71, ppl=3.32, accuracy=58.111, wps=13779.2, ups=1.1, wpb=12473.7, bsz=478.6, num_updates=10200, lr=0.000140028, gnorm=0.194, clip=0, loss_scale=8, train_wall=90, gb_free=16.7, wall=9219
2023-08-05 14:52:08 | INFO | train_inner | epoch 007:   1464 / 1474 loss=1.02, trans_loss=3.566, nll_loss=1.744, w2v_ctc_loss=0.536, task_loss=1.005, contrastive_loss=0.217, total=4107.01, n_correct=2371.55, ppl=3.35, accuracy=57.744, wps=13236.4, ups=1.08, wpb=12270.2, bsz=442.8, num_updates=10300, lr=0.000139347, gnorm=0.2, clip=0, loss_scale=8, train_wall=92, gb_free=13.1, wall=9312
2023-08-05 14:52:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:7')
2023-08-05 14:52:40 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 1.516 | trans_loss 5.695 | nll_loss 3.01 | w2v_ctc_loss 0.474 | task_loss 4.586 | contrastive_loss 0.257 | total 4003.4 | n_correct 2386.8 | ppl 8.05 | accuracy 59.619 | uer 19.815 | wer 21.819 | raw_wer 21.819 | bleu 18.2 | wps 2146.9 | wpb 4003.4 | bsz 141.8 | num_updates 10310 | best_bleu 18.59
2023-08-05 14:52:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10310 updates
2023-08-05 14:52:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_18.2009.pt
2023-08-05 14:52:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_18.2009.pt
2023-08-05 14:52:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_18.2009.pt (epoch 7 @ 10310 updates, score 18.2) (writing took 13.90587204694748 seconds)
2023-08-05 14:52:55 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-05 14:52:55 | INFO | train | epoch 007 | loss 1.021 | trans_loss 3.565 | nll_loss 1.739 | w2v_ctc_loss 0.541 | task_loss 0.933 | contrastive_loss 0.179 | total 4137.22 | n_correct 2388.42 | ppl 3.34 | accuracy 57.73 | wps 12430.9 | ups 1.01 | wpb 12351.6 | bsz 457.8 | num_updates 10310 | lr 0.000139279 | gnorm 0.237 | clip 0 | loss_scale 8 | train_wall 1341 | gb_free 13.1 | wall 9359
2023-08-05 14:52:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 14:52:55 | INFO | fairseq.trainer | begin training epoch 8
2023-08-05 14:52:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 14:54:25 | INFO | train_inner | epoch 008:     90 / 1474 loss=0.993, trans_loss=3.542, nll_loss=1.706, w2v_ctc_loss=0.522, task_loss=0.99, contrastive_loss=0.11, total=4106.01, n_correct=2407.62, ppl=3.26, accuracy=58.636, wps=8911.4, ups=0.73, wpb=12242.2, bsz=440.9, num_updates=10400, lr=0.000138675, gnorm=0.199, clip=0, loss_scale=8, train_wall=91, gb_free=17.1, wall=9449
2023-08-05 14:55:56 | INFO | train_inner | epoch 008:    190 / 1474 loss=0.994, trans_loss=3.533, nll_loss=1.694, w2v_ctc_loss=0.52, task_loss=1.008, contrastive_loss=0.132, total=4043.12, n_correct=2379.47, ppl=3.24, accuracy=58.852, wps=13289.9, ups=1.1, wpb=12058.4, bsz=430, num_updates=10500, lr=0.000138013, gnorm=0.197, clip=0, loss_scale=8, train_wall=90, gb_free=13.1, wall=9540
2023-08-05 14:57:27 | INFO | train_inner | epoch 008:    290 / 1474 loss=0.993, trans_loss=3.53, nll_loss=1.694, w2v_ctc_loss=0.52, task_loss=0.874, contrastive_loss=0.126, total=4207.9, n_correct=2475.31, ppl=3.24, accuracy=58.825, wps=13814.6, ups=1.1, wpb=12558.3, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.196, clip=0, loss_scale=8, train_wall=90, gb_free=14, wall=9631
2023-08-05 14:58:59 | INFO | train_inner | epoch 008:    390 / 1474 loss=0.999, trans_loss=3.538, nll_loss=1.702, w2v_ctc_loss=0.525, task_loss=0.98, contrastive_loss=0.154, total=4134.6, n_correct=2426.58, ppl=3.25, accuracy=58.69, wps=13336.4, ups=1.08, wpb=12337.2, bsz=444.7, num_updates=10700, lr=0.000136717, gnorm=0.195, clip=0, loss_scale=8, train_wall=92, gb_free=17.3, wall=9724
2023-08-05 15:00:31 | INFO | train_inner | epoch 008:    490 / 1474 loss=1.032, trans_loss=3.533, nll_loss=1.7, w2v_ctc_loss=0.516, task_loss=0.842, contrastive_loss=0.41, total=4196.6, n_correct=2470.09, ppl=3.25, accuracy=58.859, wps=13655.9, ups=1.09, wpb=12528.1, bsz=501.4, num_updates=10800, lr=0.000136083, gnorm=0.202, clip=0, loss_scale=8, train_wall=91, gb_free=12.7, wall=9815
2023-08-05 15:02:02 | INFO | train_inner | epoch 008:    590 / 1474 loss=0.99, trans_loss=3.536, nll_loss=1.705, w2v_ctc_loss=0.526, task_loss=1.014, contrastive_loss=0.09, total=4065.55, n_correct=2378.93, ppl=3.26, accuracy=58.514, wps=13395.3, ups=1.1, wpb=12153.4, bsz=428.3, num_updates=10900, lr=0.000135457, gnorm=0.194, clip=0, loss_scale=8, train_wall=90, gb_free=16.1, wall=9906
2023-08-05 15:03:33 | INFO | train_inner | epoch 008:    690 / 1474 loss=0.989, trans_loss=3.53, nll_loss=1.695, w2v_ctc_loss=0.525, task_loss=0.965, contrastive_loss=0.099, total=4135.41, n_correct=2443.43, ppl=3.24, accuracy=59.086, wps=13475.3, ups=1.09, wpb=12343.8, bsz=447.2, num_updates=11000, lr=0.00013484, gnorm=0.195, clip=0, loss_scale=8, train_wall=91, gb_free=15.9, wall=9998
2023-08-05 15:05:04 | INFO | train_inner | epoch 008:    790 / 1474 loss=0.994, trans_loss=3.532, nll_loss=1.701, w2v_ctc_loss=0.518, task_loss=0.944, contrastive_loss=0.185, total=4128.86, n_correct=2430.26, ppl=3.25, accuracy=58.86, wps=13579.6, ups=1.1, wpb=12339, bsz=452.1, num_updates=11100, lr=0.000134231, gnorm=0.196, clip=0, loss_scale=8, train_wall=90, gb_free=16.2, wall=10089
2023-08-05 15:06:36 | INFO | train_inner | epoch 008:    890 / 1474 loss=0.995, trans_loss=3.533, nll_loss=1.702, w2v_ctc_loss=0.513, task_loss=0.897, contrastive_loss=0.193, total=4166.92, n_correct=2458.27, ppl=3.25, accuracy=58.995, wps=13634.3, ups=1.1, wpb=12446.8, bsz=471.5, num_updates=11200, lr=0.000133631, gnorm=0.202, clip=0, loss_scale=8, train_wall=91, gb_free=14.4, wall=10180
2023-08-05 15:08:06 | INFO | train_inner | epoch 008:    990 / 1474 loss=0.982, trans_loss=3.534, nll_loss=1.702, w2v_ctc_loss=0.515, task_loss=0.898, contrastive_loss=0.098, total=4150.39, n_correct=2450.37, ppl=3.25, accuracy=59.04, wps=13707.3, ups=1.11, wpb=12390.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.192, clip=0, loss_scale=8, train_wall=90, gb_free=17.3, wall=10270
2023-08-05 15:09:38 | INFO | train_inner | epoch 008:   1090 / 1474 loss=1.011, trans_loss=3.539, nll_loss=1.707, w2v_ctc_loss=0.515, task_loss=0.924, contrastive_loss=0.321, total=4197.39, n_correct=2469.83, ppl=3.27, accuracy=58.842, wps=13644, ups=1.09, wpb=12529.5, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.194, clip=0, loss_scale=8, train_wall=91, gb_free=16.8, wall=10362
2023-08-05 15:11:09 | INFO | train_inner | epoch 008:   1190 / 1474 loss=0.981, trans_loss=3.532, nll_loss=1.701, w2v_ctc_loss=0.513, task_loss=0.882, contrastive_loss=0.106, total=4180.55, n_correct=2469.7, ppl=3.25, accuracy=59.076, wps=13724.9, ups=1.1, wpb=12487.2, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.192, clip=0, loss_scale=8, train_wall=91, gb_free=17.3, wall=10453
2023-08-05 15:12:39 | INFO | train_inner | epoch 008:   1290 / 1474 loss=0.993, trans_loss=3.54, nll_loss=1.71, w2v_ctc_loss=0.523, task_loss=0.974, contrastive_loss=0.127, total=4062.6, n_correct=2386.85, ppl=3.27, accuracy=58.752, wps=13394.7, ups=1.1, wpb=12135.3, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.198, clip=0, loss_scale=8, train_wall=90, gb_free=12.9, wall=10544
2023-08-05 15:14:09 | INFO | train_inner | epoch 008:   1390 / 1474 loss=0.992, trans_loss=3.538, nll_loss=1.708, w2v_ctc_loss=0.511, task_loss=0.904, contrastive_loss=0.191, total=4159.11, n_correct=2451.18, ppl=3.27, accuracy=58.935, wps=13789.3, ups=1.11, wpb=12419, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.193, clip=0, loss_scale=8, train_wall=89, gb_free=13.2, wall=10634
2023-08-05 15:15:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 15:15:49 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 1.497 | trans_loss 5.657 | nll_loss 2.956 | w2v_ctc_loss 0.465 | task_loss 4.614 | contrastive_loss 0.244 | total 4003.4 | n_correct 2410.2 | ppl 7.76 | accuracy 60.204 | uer 18.937 | wer 20.764 | raw_wer 20.764 | bleu 18.91 | wps 2138.4 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 18.91
2023-08-05 15:15:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-08-05 15:15:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 15:16:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 15:16:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 8 @ 11784 updates, score 18.91) (writing took 23.49770398437977 seconds)
2023-08-05 15:16:13 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-05 15:16:13 | INFO | train | epoch 008 | loss 0.996 | trans_loss 3.535 | nll_loss 1.702 | w2v_ctc_loss 0.518 | task_loss 0.932 | contrastive_loss 0.173 | total 4138.65 | n_correct 2436.12 | ppl 3.25 | accuracy 58.863 | wps 13020.1 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 11784 | lr 0.000130277 | gnorm 0.196 | clip 0 | loss_scale 8 | train_wall 1336 | gb_free 16.8 | wall 10758
2023-08-05 15:16:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 15:16:14 | INFO | fairseq.trainer | begin training epoch 9
2023-08-05 15:16:14 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 15:16:36 | INFO | train_inner | epoch 009:     16 / 1474 loss=0.996, trans_loss=3.533, nll_loss=1.7, w2v_ctc_loss=0.506, task_loss=0.91, contrastive_loss=0.287, total=4121.25, n_correct=2432.19, ppl=3.25, accuracy=59.016, wps=8379.1, ups=0.68, wpb=12298.5, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.198, clip=0, loss_scale=8, train_wall=91, gb_free=17.7, wall=10781
2023-08-05 15:18:07 | INFO | train_inner | epoch 009:    116 / 1474 loss=0.965, trans_loss=3.496, nll_loss=1.653, w2v_ctc_loss=0.496, task_loss=0.878, contrastive_loss=0.124, total=4191.82, n_correct=2520.99, ppl=3.14, accuracy=60.141, wps=13766.4, ups=1.1, wpb=12518.2, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.191, clip=0, loss_scale=8, train_wall=90, gb_free=15.9, wall=10871
2023-08-05 15:19:39 | INFO | train_inner | epoch 009:    216 / 1474 loss=0.961, trans_loss=3.503, nll_loss=1.661, w2v_ctc_loss=0.498, task_loss=1.004, contrastive_loss=0.083, total=4061.27, n_correct=2431.77, ppl=3.16, accuracy=59.877, wps=13224, ups=1.09, wpb=12126.5, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.191, clip=0, loss_scale=8, train_wall=91, gb_free=17.6, wall=10963
2023-08-05 15:19:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 15:20:01 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 1.513 | trans_loss 5.659 | nll_loss 2.959 | w2v_ctc_loss 0.465 | task_loss 4.545 | contrastive_loss 0.253 | total 4003.4 | n_correct 2410.9 | ppl 7.77 | accuracy 60.221 | uer 18.724 | wer 20.547 | raw_wer 20.547 | bleu 19.06 | wps 2257.5 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 19.06
2023-08-05 15:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-05 15:20:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_9_12000.pt
2023-08-05 15:20:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_9_12000.pt
2023-08-05 15:20:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 19.06) (writing took 24.27276373654604 seconds)
2023-08-05 15:21:57 | INFO | train_inner | epoch 009:    316 / 1474 loss=0.962, trans_loss=3.492, nll_loss=1.649, w2v_ctc_loss=0.491, task_loss=0.881, contrastive_loss=0.132, total=4146.43, n_correct=2500.67, ppl=3.14, accuracy=60.309, wps=8955.5, ups=0.72, wpb=12389.9, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.192, clip=0, loss_scale=16, train_wall=90, gb_free=16.2, wall=11102
2023-08-05 15:23:29 | INFO | train_inner | epoch 009:    416 / 1474 loss=0.963, trans_loss=3.508, nll_loss=1.668, w2v_ctc_loss=0.496, task_loss=0.915, contrastive_loss=0.097, total=4194.84, n_correct=2505.72, ppl=3.18, accuracy=59.733, wps=13628.8, ups=1.09, wpb=12524.6, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.189, clip=0, loss_scale=16, train_wall=91, gb_free=16.1, wall=11193
2023-08-05 15:25:00 | INFO | train_inner | epoch 009:    516 / 1474 loss=0.978, trans_loss=3.513, nll_loss=1.674, w2v_ctc_loss=0.506, task_loss=0.978, contrastive_loss=0.149, total=4124.3, n_correct=2458.41, ppl=3.19, accuracy=59.608, wps=13582.1, ups=1.1, wpb=12310.3, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.194, clip=0, loss_scale=16, train_wall=90, gb_free=11.4, wall=11284
2023-08-05 15:26:31 | INFO | train_inner | epoch 009:    616 / 1474 loss=0.962, trans_loss=3.503, nll_loss=1.664, w2v_ctc_loss=0.495, task_loss=0.954, contrastive_loss=0.11, total=4120.96, n_correct=2464.88, ppl=3.17, accuracy=59.813, wps=13481.6, ups=1.09, wpb=12316.4, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.194, clip=0, loss_scale=16, train_wall=91, gb_free=16.1, wall=11375
2023-08-05 15:28:01 | INFO | train_inner | epoch 009:    716 / 1474 loss=0.984, trans_loss=3.515, nll_loss=1.679, w2v_ctc_loss=0.505, task_loss=0.948, contrastive_loss=0.193, total=4088.53, n_correct=2433.47, ppl=3.2, accuracy=59.519, wps=13535, ups=1.11, wpb=12213.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.202, clip=0, loss_scale=16, train_wall=90, gb_free=16.9, wall=11466
2023-08-05 15:29:33 | INFO | train_inner | epoch 009:    816 / 1474 loss=1.001, trans_loss=3.507, nll_loss=1.671, w2v_ctc_loss=0.498, task_loss=0.842, contrastive_loss=0.333, total=4220.43, n_correct=2521.08, ppl=3.18, accuracy=59.735, wps=13745.5, ups=1.09, wpb=12611.1, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.196, clip=0, loss_scale=16, train_wall=91, gb_free=14.3, wall=11557
2023-08-05 15:31:06 | INFO | train_inner | epoch 009:    916 / 1474 loss=0.991, trans_loss=3.512, nll_loss=1.672, w2v_ctc_loss=0.5, task_loss=0.962, contrastive_loss=0.318, total=4146.05, n_correct=2474.2, ppl=3.19, accuracy=59.676, wps=13386.8, ups=1.08, wpb=12371.5, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.191, clip=0, loss_scale=16, train_wall=92, gb_free=17.7, wall=11650
2023-08-05 15:32:37 | INFO | train_inner | epoch 009:   1016 / 1474 loss=0.97, trans_loss=3.522, nll_loss=1.685, w2v_ctc_loss=0.504, task_loss=1.037, contrastive_loss=0.099, total=4101.48, n_correct=2437.75, ppl=3.22, accuracy=59.436, wps=13414.7, ups=1.1, wpb=12241.7, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.192, clip=0, loss_scale=16, train_wall=91, gb_free=15.8, wall=11741
2023-08-05 15:34:07 | INFO | train_inner | epoch 009:   1116 / 1474 loss=0.969, trans_loss=3.517, nll_loss=1.677, w2v_ctc_loss=0.498, task_loss=0.878, contrastive_loss=0.118, total=4179.09, n_correct=2499.84, ppl=3.2, accuracy=59.818, wps=13758.3, ups=1.1, wpb=12457.7, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.194, clip=0, loss_scale=16, train_wall=90, gb_free=15.2, wall=11832
2023-08-05 15:35:39 | INFO | train_inner | epoch 009:   1216 / 1474 loss=0.967, trans_loss=3.516, nll_loss=1.68, w2v_ctc_loss=0.503, task_loss=0.986, contrastive_loss=0.103, total=4140.66, n_correct=2469.24, ppl=3.2, accuracy=59.634, wps=13433.1, ups=1.09, wpb=12363.4, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.193, clip=0, loss_scale=16, train_wall=91, gb_free=17, wall=11924
2023-08-05 15:37:11 | INFO | train_inner | epoch 009:   1316 / 1474 loss=0.985, trans_loss=3.512, nll_loss=1.674, w2v_ctc_loss=0.492, task_loss=0.848, contrastive_loss=0.293, total=4204.43, n_correct=2515.23, ppl=3.19, accuracy=59.823, wps=13767.5, ups=1.1, wpb=12544.9, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.194, clip=0, loss_scale=16, train_wall=91, gb_free=17.7, wall=12015
2023-08-05 15:38:41 | INFO | train_inner | epoch 009:   1416 / 1474 loss=0.967, trans_loss=3.526, nll_loss=1.692, w2v_ctc_loss=0.503, task_loss=1.01, contrastive_loss=0.082, total=4069.19, n_correct=2419.31, ppl=3.23, accuracy=59.454, wps=13457.8, ups=1.11, wpb=12143.2, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.194, clip=0, loss_scale=16, train_wall=90, gb_free=16.5, wall=12105
2023-08-05 15:39:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 15:39:55 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 1.496 | trans_loss 5.631 | nll_loss 2.926 | w2v_ctc_loss 0.462 | task_loss 4.618 | contrastive_loss 0.247 | total 4003.4 | n_correct 2426.2 | ppl 7.6 | accuracy 60.603 | uer 18.4 | wer 20.212 | raw_wer 20.212 | bleu 18.92 | wps 2271.7 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 19.06
2023-08-05 15:39:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-08-05 15:39:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_18.9200.pt
2023-08-05 15:39:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_18.9200.pt
2023-08-05 15:40:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_18.9200.pt (epoch 9 @ 13258 updates, score 18.92) (writing took 13.803852638229728 seconds)
2023-08-05 15:40:09 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-05 15:40:09 | INFO | train | epoch 009 | loss 0.974 | trans_loss 3.51 | nll_loss 1.672 | w2v_ctc_loss 0.499 | task_loss 0.933 | contrastive_loss 0.165 | total 4138.65 | n_correct 2473.22 | ppl 3.19 | accuracy 59.759 | wps 12684.1 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 13258 | lr 0.000122822 | gnorm 0.194 | clip 0 | loss_scale 16 | train_wall 1336 | gb_free 11.5 | wall 12194
2023-08-05 15:40:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 15:40:09 | INFO | fairseq.trainer | begin training epoch 10
2023-08-05 15:40:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 15:40:55 | INFO | train_inner | epoch 010:     42 / 1474 loss=0.967, trans_loss=3.503, nll_loss=1.663, w2v_ctc_loss=0.489, task_loss=0.89, contrastive_loss=0.178, total=4100.8, n_correct=2470.39, ppl=3.17, accuracy=60.242, wps=9136.7, ups=0.75, wpb=12238.2, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.194, clip=0, loss_scale=16, train_wall=89, gb_free=16.2, wall=12239
2023-08-05 15:42:26 | INFO | train_inner | epoch 010:    142 / 1474 loss=0.942, trans_loss=3.476, nll_loss=1.628, w2v_ctc_loss=0.476, task_loss=0.882, contrastive_loss=0.101, total=4247.35, n_correct=2585.98, ppl=3.09, accuracy=60.885, wps=13892.6, ups=1.1, wpb=12684.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.189, clip=0, loss_scale=16, train_wall=91, gb_free=11.4, wall=12330
2023-08-05 15:43:58 | INFO | train_inner | epoch 010:    242 / 1474 loss=0.961, trans_loss=3.478, nll_loss=1.629, w2v_ctc_loss=0.482, task_loss=0.924, contrastive_loss=0.223, total=4122.82, n_correct=2505.05, ppl=3.09, accuracy=60.761, wps=13435.8, ups=1.09, wpb=12303.3, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.191, clip=0, loss_scale=16, train_wall=91, gb_free=16.2, wall=12422
2023-08-05 15:45:28 | INFO | train_inner | epoch 010:    342 / 1474 loss=0.946, trans_loss=3.478, nll_loss=1.635, w2v_ctc_loss=0.478, task_loss=0.944, contrastive_loss=0.137, total=4138.27, n_correct=2510.12, ppl=3.11, accuracy=60.656, wps=13608.4, ups=1.1, wpb=12371, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.192, clip=0, loss_scale=16, train_wall=90, gb_free=16.3, wall=12513
2023-08-05 15:47:00 | INFO | train_inner | epoch 010:    442 / 1474 loss=0.965, trans_loss=3.483, nll_loss=1.637, w2v_ctc_loss=0.472, task_loss=0.897, contrastive_loss=0.309, total=4196.37, n_correct=2546.11, ppl=3.11, accuracy=60.674, wps=13618.5, ups=1.09, wpb=12528, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.19, clip=0, loss_scale=16, train_wall=92, gb_free=16, wall=12605
2023-08-05 15:48:32 | INFO | train_inner | epoch 010:    542 / 1474 loss=0.956, trans_loss=3.498, nll_loss=1.652, w2v_ctc_loss=0.492, task_loss=1.003, contrastive_loss=0.091, total=4102.8, n_correct=2475.03, ppl=3.14, accuracy=60.325, wps=13387.3, ups=1.09, wpb=12234.1, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.194, clip=0, loss_scale=16, train_wall=91, gb_free=16.9, wall=12696
2023-08-05 15:50:04 | INFO | train_inner | epoch 010:    642 / 1474 loss=0.963, trans_loss=3.494, nll_loss=1.651, w2v_ctc_loss=0.484, task_loss=0.888, contrastive_loss=0.204, total=4176.56, n_correct=2527.93, ppl=3.14, accuracy=60.527, wps=13534.9, ups=1.09, wpb=12464, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.199, clip=0, loss_scale=16, train_wall=92, gb_free=16.2, wall=12788
2023-08-05 15:51:34 | INFO | train_inner | epoch 010:    742 / 1474 loss=0.954, trans_loss=3.493, nll_loss=1.65, w2v_ctc_loss=0.492, task_loss=0.935, contrastive_loss=0.09, total=4125.87, n_correct=2491.62, ppl=3.14, accuracy=60.39, wps=13632.9, ups=1.11, wpb=12315.3, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.195, clip=0, loss_scale=16, train_wall=90, gb_free=14.4, wall=12879
2023-08-05 15:51:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 15:51:58 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 1.495 | trans_loss 5.641 | nll_loss 2.931 | w2v_ctc_loss 0.467 | task_loss 4.608 | contrastive_loss 0.248 | total 4003.4 | n_correct 2429 | ppl 7.63 | accuracy 60.673 | uer 18.623 | wer 20.357 | raw_wer 20.357 | bleu 19.06 | wps 2191.6 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.06
2023-08-05 15:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-05 15:51:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_10_14000.pt
2023-08-05 15:52:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_10_14000.pt
2023-08-05 15:52:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.06) (writing took 24.76792781986296 seconds)
2023-08-05 15:53:54 | INFO | train_inner | epoch 010:    842 / 1474 loss=0.942, trans_loss=3.489, nll_loss=1.646, w2v_ctc_loss=0.478, task_loss=0.924, contrastive_loss=0.092, total=4128.44, n_correct=2499.99, ppl=3.13, accuracy=60.555, wps=8803.5, ups=0.71, wpb=12327.8, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.19, clip=0, loss_scale=32, train_wall=91, gb_free=14.6, wall=13019
2023-08-05 15:55:25 | INFO | train_inner | epoch 010:    942 / 1474 loss=0.956, trans_loss=3.492, nll_loss=1.647, w2v_ctc_loss=0.485, task_loss=0.898, contrastive_loss=0.128, total=4160.94, n_correct=2515.68, ppl=3.13, accuracy=60.459, wps=13716.6, ups=1.11, wpb=12411.1, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.196, clip=0, loss_scale=32, train_wall=90, gb_free=15.3, wall=13109
2023-08-05 15:56:56 | INFO | train_inner | epoch 010:   1042 / 1474 loss=0.954, trans_loss=3.495, nll_loss=1.653, w2v_ctc_loss=0.488, task_loss=1.008, contrastive_loss=0.103, total=4067.53, n_correct=2448.65, ppl=3.15, accuracy=60.2, wps=13258.6, ups=1.09, wpb=12145, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.203, clip=0, loss_scale=32, train_wall=91, gb_free=16.9, wall=13201
2023-08-05 15:58:27 | INFO | train_inner | epoch 010:   1142 / 1474 loss=0.953, trans_loss=3.502, nll_loss=1.662, w2v_ctc_loss=0.492, task_loss=1.042, contrastive_loss=0.088, total=4044.03, n_correct=2429.97, ppl=3.17, accuracy=60.088, wps=13320.1, ups=1.1, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.194, clip=0, loss_scale=32, train_wall=90, gb_free=17.3, wall=13291
2023-08-05 15:59:58 | INFO | train_inner | epoch 010:   1242 / 1474 loss=0.949, trans_loss=3.489, nll_loss=1.651, w2v_ctc_loss=0.489, task_loss=0.953, contrastive_loss=0.084, total=4110.41, n_correct=2482.07, ppl=3.14, accuracy=60.385, wps=13527.2, ups=1.1, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.193, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=13382
2023-08-05 16:01:29 | INFO | train_inner | epoch 010:   1342 / 1474 loss=0.951, trans_loss=3.497, nll_loss=1.657, w2v_ctc_loss=0.487, task_loss=0.952, contrastive_loss=0.094, total=4121.38, n_correct=2489.83, ppl=3.15, accuracy=60.413, wps=13466.3, ups=1.09, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.192, clip=0, loss_scale=32, train_wall=91, gb_free=13.9, wall=13474
2023-08-05 16:03:01 | INFO | train_inner | epoch 010:   1442 / 1474 loss=0.986, trans_loss=3.502, nll_loss=1.662, w2v_ctc_loss=0.479, task_loss=0.879, contrastive_loss=0.34, total=4192.39, n_correct=2526.7, ppl=3.16, accuracy=60.269, wps=13641.5, ups=1.09, wpb=12506.1, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.199, clip=0, loss_scale=32, train_wall=91, gb_free=17, wall=13565
2023-08-05 16:03:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 16:03:53 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 1.493 | trans_loss 5.617 | nll_loss 2.91 | w2v_ctc_loss 0.46 | task_loss 4.587 | contrastive_loss 0.245 | total 4003.4 | n_correct 2435.5 | ppl 7.51 | accuracy 60.836 | uer 18.122 | wer 19.884 | raw_wer 19.884 | bleu 18.86 | wps 2273.6 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.06
2023-08-05 16:03:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-08-05 16:03:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_18.8604.pt
2023-08-05 16:03:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_18.8604.pt
2023-08-05 16:04:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_18.8604.pt (epoch 10 @ 14732 updates, score 18.86) (writing took 13.464283559471369 seconds)
2023-08-05 16:04:06 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-05 16:04:06 | INFO | train | epoch 010 | loss 0.956 | trans_loss 3.49 | nll_loss 1.647 | w2v_ctc_loss 0.483 | task_loss 0.934 | contrastive_loss 0.159 | total 4138.65 | n_correct 2503.18 | ppl 3.13 | accuracy 60.483 | wps 12672.8 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.194 | clip 0 | loss_scale 32 | train_wall 1337 | gb_free 17.2 | wall 13631
2023-08-05 16:04:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 16:04:07 | INFO | fairseq.trainer | begin training epoch 11
2023-08-05 16:04:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 16:05:15 | INFO | train_inner | epoch 011:     68 / 1474 loss=0.941, trans_loss=3.466, nll_loss=1.616, w2v_ctc_loss=0.47, task_loss=0.863, contrastive_loss=0.169, total=4175.24, n_correct=2560.38, ppl=3.07, accuracy=61.323, wps=9279.6, ups=0.74, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.193, clip=0, loss_scale=32, train_wall=89, gb_free=16.7, wall=13700
2023-08-05 16:06:47 | INFO | train_inner | epoch 011:    168 / 1474 loss=0.934, trans_loss=3.466, nll_loss=1.618, w2v_ctc_loss=0.473, task_loss=0.961, contrastive_loss=0.088, total=4087.78, n_correct=2501.57, ppl=3.07, accuracy=61.196, wps=13362.1, ups=1.09, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.196, clip=0, loss_scale=32, train_wall=91, gb_free=16.4, wall=13791
2023-08-05 16:08:18 | INFO | train_inner | epoch 011:    268 / 1474 loss=0.927, trans_loss=3.466, nll_loss=1.616, w2v_ctc_loss=0.467, task_loss=0.963, contrastive_loss=0.084, total=4118.77, n_correct=2521.34, ppl=3.07, accuracy=61.216, wps=13524.2, ups=1.1, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.191, clip=0, loss_scale=32, train_wall=90, gb_free=12.2, wall=13882
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:0')
2023-08-05 16:09:25 | INFO | train_inner | epoch 011:    368 / 1474 loss=0.797, trans_loss=5.15, nll_loss=2.404, w2v_ctc_loss=0.282, task_loss=1.428, contrastive_loss=0.066, total=4097.83, n_correct=2507.14, ppl=5.29, accuracy=61.182, wps=12192.9, ups=1.48, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.203, clip=0, loss_scale=32, train_wall=67, gb_free=15.6, wall=13950
2023-08-05 16:10:34 | INFO | train_inner | epoch 011:    468 / 1474 loss=0.804, trans_loss=5.189, nll_loss=2.43, w2v_ctc_loss=0.279, task_loss=1.465, contrastive_loss=0.183, total=4110.64, n_correct=2505.28, ppl=5.39, accuracy=60.946, wps=12015.8, ups=1.46, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.202, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=14018
2023-08-05 16:11:42 | INFO | train_inner | epoch 011:    568 / 1474 loss=0.798, trans_loss=5.187, nll_loss=2.429, w2v_ctc_loss=0.281, task_loss=1.499, contrastive_loss=0.183, total=4071.69, n_correct=2479.66, ppl=5.39, accuracy=60.9, wps=11864.9, ups=1.46, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.205, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=14087
2023-08-05 16:12:51 | INFO | train_inner | epoch 011:    668 / 1474 loss=0.801, trans_loss=5.188, nll_loss=2.431, w2v_ctc_loss=0.28, task_loss=1.37, contrastive_loss=0.242, total=4157.2, n_correct=2529.89, ppl=5.39, accuracy=60.856, wps=12162, ups=1.46, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.203, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=14155
2023-08-05 16:13:59 | INFO | train_inner | epoch 011:    768 / 1474 loss=0.798, trans_loss=5.2, nll_loss=2.447, w2v_ctc_loss=0.286, task_loss=1.405, contrastive_loss=0.066, total=4174.91, n_correct=2542.26, ppl=5.45, accuracy=60.894, wps=12232.5, ups=1.46, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.202, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=14223
2023-08-05 16:15:07 | INFO | train_inner | epoch 011:    868 / 1474 loss=0.798, trans_loss=5.198, nll_loss=2.443, w2v_ctc_loss=0.284, task_loss=1.462, contrastive_loss=0.057, total=4118.44, n_correct=2500.42, ppl=5.44, accuracy=60.713, wps=12201.8, ups=1.48, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.199, clip=0, loss_scale=32, train_wall=67, gb_free=10.6, wall=14291
2023-08-05 16:16:15 | INFO | train_inner | epoch 011:    968 / 1474 loss=0.799, trans_loss=5.197, nll_loss=2.444, w2v_ctc_loss=0.286, task_loss=1.43, contrastive_loss=0.068, total=4140.92, n_correct=2517.07, ppl=5.44, accuracy=60.785, wps=12159, ups=1.47, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.208, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=14359
2023-08-05 16:17:22 | INFO | train_inner | epoch 011:   1068 / 1474 loss=0.797, trans_loss=5.19, nll_loss=2.435, w2v_ctc_loss=0.284, task_loss=1.374, contrastive_loss=0.085, total=4136.99, n_correct=2524.16, ppl=5.41, accuracy=61.014, wps=12284.2, ups=1.48, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.201, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=14426
2023-08-05 16:18:30 | INFO | train_inner | epoch 011:   1168 / 1474 loss=0.801, trans_loss=5.2, nll_loss=2.449, w2v_ctc_loss=0.286, task_loss=1.391, contrastive_loss=0.073, total=4185.65, n_correct=2543.22, ppl=5.46, accuracy=60.76, wps=12297, ups=1.47, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.205, clip=0, loss_scale=32, train_wall=68, gb_free=13.9, wall=14494
2023-08-05 16:19:38 | INFO | train_inner | epoch 011:   1268 / 1474 loss=0.801, trans_loss=5.193, nll_loss=2.44, w2v_ctc_loss=0.285, task_loss=1.347, contrastive_loss=0.138, total=4171.89, n_correct=2537.93, ppl=5.43, accuracy=60.834, wps=12304, ups=1.47, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.204, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=14562
2023-08-05 16:19:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:7')
2023-08-05 16:20:01 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 1.489 | trans_loss 5.611 | nll_loss 2.905 | w2v_ctc_loss 0.475 | task_loss 4.636 | contrastive_loss 0.254 | total 4003.4 | n_correct 2443.9 | ppl 7.49 | accuracy 61.046 | uer 18.254 | wer 19.973 | raw_wer 19.973 | bleu 19.1 | wps 2254 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.1
2023-08-05 16:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-05 16:20:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_11_16000.pt
2023-08-05 16:20:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_11_16000.pt
2023-08-05 16:20:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.1) (writing took 23.363090643659234 seconds)
2023-08-05 16:21:34 | INFO | train_inner | epoch 011:   1368 / 1474 loss=0.804, trans_loss=5.194, nll_loss=2.443, w2v_ctc_loss=0.279, task_loss=1.293, contrastive_loss=0.301, total=4190.34, n_correct=2550.24, ppl=5.44, accuracy=60.86, wps=7212.6, ups=0.86, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.204, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=14678
2023-08-05 16:22:42 | INFO | train_inner | epoch 011:   1468 / 1474 loss=0.797, trans_loss=5.197, nll_loss=2.445, w2v_ctc_loss=0.282, task_loss=1.355, contrastive_loss=0.076, total=4158.39, n_correct=2532.78, ppl=5.45, accuracy=60.908, wps=12198, ups=1.47, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.197, clip=0, loss_scale=64, train_wall=68, gb_free=16.8, wall=14747
2023-08-05 16:22:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 16:23:09 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 1.481 | trans_loss 5.607 | nll_loss 2.9 | w2v_ctc_loss 0.449 | task_loss 4.615 | contrastive_loss 0.243 | total 4003.4 | n_correct 2435.7 | ppl 7.46 | accuracy 60.841 | uer 18.031 | wer 19.79 | raw_wer 19.79 | bleu 19.4 | wps 2292.2 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.4
2023-08-05 16:23:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-08-05 16:23:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 16:23:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 16:23:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.4) (writing took 25.424975590780377 seconds)
2023-08-05 16:23:35 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-05 16:23:35 | INFO | train | epoch 011 | loss 0.827 | trans_loss 4.761 | nll_loss 2.232 | w2v_ctc_loss 0.322 | task_loss 1.283 | contrastive_loss 0.118 | total 4138.65 | n_correct 2523.02 | ppl 4.7 | accuracy 60.962 | wps 11379.7 | ups 1.26 | wpb 9021 | bsz 333.4 | num_updates 16206 | lr 0.000111091 | gnorm 0.202 | clip 0 | loss_scale 64 | train_wall 1057 | gb_free 17.2 | wall 14799
2023-08-05 16:23:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 16:23:35 | INFO | fairseq.trainer | begin training epoch 12
2023-08-05 16:23:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 16:24:46 | INFO | train_inner | epoch 012:     94 / 1474 loss=0.785, trans_loss=5.141, nll_loss=2.371, w2v_ctc_loss=0.276, task_loss=1.341, contrastive_loss=0.108, total=4146.82, n_correct=2565.37, ppl=5.17, accuracy=61.864, wps=6690.4, ups=0.81, wpb=8293.6, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.202, clip=0, loss_scale=64, train_wall=67, gb_free=15.7, wall=14871
2023-08-05 16:25:54 | INFO | train_inner | epoch 012:    194 / 1474 loss=0.784, trans_loss=5.151, nll_loss=2.382, w2v_ctc_loss=0.277, task_loss=1.45, contrastive_loss=0.061, total=4120.68, n_correct=2539.74, ppl=5.21, accuracy=61.634, wps=12236.7, ups=1.48, wpb=8241.4, bsz=294.7, num_updates=16400, lr=0.000110432, gnorm=0.196, clip=0, loss_scale=64, train_wall=67, gb_free=15.6, wall=14938
2023-08-05 16:27:02 | INFO | train_inner | epoch 012:    294 / 1474 loss=0.788, trans_loss=5.149, nll_loss=2.381, w2v_ctc_loss=0.274, task_loss=1.318, contrastive_loss=0.088, total=4199.46, n_correct=2593.52, ppl=5.21, accuracy=61.758, wps=12327.4, ups=1.47, wpb=8398.9, bsz=320.3, num_updates=16500, lr=0.000110096, gnorm=0.196, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=15006
2023-08-05 16:28:10 | INFO | train_inner | epoch 012:    394 / 1474 loss=0.791, trans_loss=5.158, nll_loss=2.394, w2v_ctc_loss=0.279, task_loss=1.369, contrastive_loss=0.074, total=4151.14, n_correct=2556.68, ppl=5.25, accuracy=61.59, wps=12199.6, ups=1.47, wpb=8302.3, bsz=307.8, num_updates=16600, lr=0.000109764, gnorm=0.199, clip=0, loss_scale=64, train_wall=68, gb_free=17.1, wall=15074
2023-08-05 16:29:17 | INFO | train_inner | epoch 012:    494 / 1474 loss=0.796, trans_loss=5.173, nll_loss=2.413, w2v_ctc_loss=0.282, task_loss=1.402, contrastive_loss=0.08, total=4110.49, n_correct=2523.03, ppl=5.33, accuracy=61.38, wps=12169.2, ups=1.48, wpb=8221, bsz=302.2, num_updates=16700, lr=0.000109435, gnorm=0.199, clip=0, loss_scale=64, train_wall=67, gb_free=13.7, wall=15142
2023-08-05 16:30:26 | INFO | train_inner | epoch 012:    594 / 1474 loss=0.79, trans_loss=5.161, nll_loss=2.398, w2v_ctc_loss=0.277, task_loss=1.341, contrastive_loss=0.145, total=4189.92, n_correct=2579.5, ppl=5.27, accuracy=61.564, wps=12263, ups=1.46, wpb=8379.8, bsz=315.1, num_updates=16800, lr=0.000109109, gnorm=0.199, clip=0, loss_scale=64, train_wall=68, gb_free=14.8, wall=15210
2023-08-05 16:31:33 | INFO | train_inner | epoch 012:    694 / 1474 loss=0.795, trans_loss=5.158, nll_loss=2.395, w2v_ctc_loss=0.272, task_loss=1.281, contrastive_loss=0.234, total=4206.3, n_correct=2598.77, ppl=5.26, accuracy=61.783, wps=12440.9, ups=1.48, wpb=8412.6, bsz=325.7, num_updates=16900, lr=0.000108786, gnorm=0.196, clip=0, loss_scale=64, train_wall=67, gb_free=16.2, wall=15278
2023-08-05 16:31:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 16:32:42 | INFO | train_inner | epoch 012:    795 / 1474 loss=0.791, trans_loss=5.159, nll_loss=2.395, w2v_ctc_loss=0.28, task_loss=1.415, contrastive_loss=0.071, total=4095.72, n_correct=2523.55, ppl=5.26, accuracy=61.614, wps=11880.6, ups=1.45, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.201, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=15347
2023-08-05 16:33:50 | INFO | train_inner | epoch 012:    895 / 1474 loss=0.796, trans_loss=5.167, nll_loss=2.406, w2v_ctc_loss=0.279, task_loss=1.434, contrastive_loss=0.119, total=4162.82, n_correct=2559.72, ppl=5.3, accuracy=61.49, wps=12274.9, ups=1.47, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.198, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=15414
2023-08-05 16:34:58 | INFO | train_inner | epoch 012:    995 / 1474 loss=0.794, trans_loss=5.176, nll_loss=2.418, w2v_ctc_loss=0.28, task_loss=1.427, contrastive_loss=0.131, total=4117.63, n_correct=2522.88, ppl=5.34, accuracy=61.27, wps=12108.2, ups=1.47, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.199, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=15482
2023-08-05 16:36:06 | INFO | train_inner | epoch 012:   1095 / 1474 loss=0.801, trans_loss=5.182, nll_loss=2.426, w2v_ctc_loss=0.283, task_loss=1.473, contrastive_loss=0.176, total=4046.48, n_correct=2475.71, ppl=5.37, accuracy=61.182, wps=12002, ups=1.48, wpb=8093, bsz=289.6, num_updates=17300, lr=0.000107521, gnorm=0.204, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=15550
2023-08-05 16:37:14 | INFO | train_inner | epoch 012:   1195 / 1474 loss=0.798, trans_loss=5.189, nll_loss=2.437, w2v_ctc_loss=0.283, task_loss=1.363, contrastive_loss=0.142, total=4201.13, n_correct=2567.49, ppl=5.41, accuracy=61.114, wps=12243.7, ups=1.46, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.198, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=15619
2023-08-05 16:38:22 | INFO | train_inner | epoch 012:   1295 / 1474 loss=0.796, trans_loss=5.183, nll_loss=2.427, w2v_ctc_loss=0.287, task_loss=1.56, contrastive_loss=0.059, total=4070.27, n_correct=2484.92, ppl=5.38, accuracy=61.05, wps=11937.7, ups=1.47, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.209, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=15687
2023-08-05 16:39:30 | INFO | train_inner | epoch 012:   1395 / 1474 loss=0.797, trans_loss=5.18, nll_loss=2.424, w2v_ctc_loss=0.277, task_loss=1.407, contrastive_loss=0.16, total=4139.63, n_correct=2535.3, ppl=5.37, accuracy=61.245, wps=12173.9, ups=1.47, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.198, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=15755
2023-08-05 16:40:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 16:40:48 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 1.489 | trans_loss 5.597 | nll_loss 2.884 | w2v_ctc_loss 0.474 | task_loss 4.608 | contrastive_loss 0.244 | total 4003.4 | n_correct 2455.1 | ppl 7.38 | accuracy 61.325 | uer 18.01 | wer 19.735 | raw_wer 19.735 | bleu 19.54 | wps 2056.3 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.54
2023-08-05 16:40:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-05 16:40:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 16:41:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 16:41:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 12 @ 17679 updates, score 19.54) (writing took 23.123791115358472 seconds)
2023-08-05 16:41:12 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-05 16:41:12 | INFO | train | epoch 012 | loss 0.793 | trans_loss 5.167 | nll_loss 2.406 | w2v_ctc_loss 0.279 | task_loss 1.399 | contrastive_loss 0.116 | total 4138.85 | n_correct 2544.03 | ppl 5.3 | accuracy 61.467 | wps 11534.7 | ups 1.39 | wpb 8277.7 | bsz 305.7 | num_updates 17679 | lr 0.000106362 | gnorm 0.199 | clip 0 | loss_scale 32 | train_wall 994 | gb_free 12.7 | wall 15856
2023-08-05 16:41:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 16:41:12 | INFO | fairseq.trainer | begin training epoch 13
2023-08-05 16:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 16:41:34 | INFO | train_inner | epoch 013:     21 / 1474 loss=0.793, trans_loss=5.178, nll_loss=2.421, w2v_ctc_loss=0.282, task_loss=1.458, contrastive_loss=0.066, total=4096.49, n_correct=2515.55, ppl=5.36, accuracy=61.407, wps=6616.9, ups=0.81, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.199, clip=0, loss_scale=32, train_wall=67, gb_free=14.5, wall=15879
2023-08-05 16:42:42 | INFO | train_inner | epoch 013:    121 / 1474 loss=0.786, trans_loss=5.128, nll_loss=2.355, w2v_ctc_loss=0.275, task_loss=1.402, contrastive_loss=0.077, total=4160.97, n_correct=2590.53, ppl=5.11, accuracy=62.258, wps=12232.3, ups=1.47, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.197, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=15947
2023-08-05 16:43:50 | INFO | train_inner | epoch 013:    221 / 1474 loss=0.791, trans_loss=5.138, nll_loss=2.37, w2v_ctc_loss=0.27, task_loss=1.292, contrastive_loss=0.29, total=4212.08, n_correct=2611.2, ppl=5.17, accuracy=61.993, wps=12384.5, ups=1.47, wpb=8424.2, bsz=329.7, num_updates=17900, lr=0.000105703, gnorm=0.198, clip=0, loss_scale=32, train_wall=68, gb_free=14.5, wall=16015
2023-08-05 16:44:58 | INFO | train_inner | epoch 013:    321 / 1474 loss=0.783, trans_loss=5.13, nll_loss=2.356, w2v_ctc_loss=0.272, task_loss=1.453, contrastive_loss=0.063, total=4102.3, n_correct=2555.24, ppl=5.12, accuracy=62.288, wps=12051.1, ups=1.47, wpb=8204.6, bsz=294.1, num_updates=18000, lr=0.000105409, gnorm=0.198, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=16083
2023-08-05 16:44:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 16:45:22 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 1.491 | trans_loss 5.602 | nll_loss 2.888 | w2v_ctc_loss 0.459 | task_loss 4.59 | contrastive_loss 0.242 | total 4003.4 | n_correct 2446.6 | ppl 7.4 | accuracy 61.113 | uer 18.26 | wer 20.051 | raw_wer 20.051 | bleu 18.96 | wps 2178.1 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.54
2023-08-05 16:45:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-05 16:45:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_13_18000.pt
2023-08-05 16:45:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_13_18000.pt
2023-08-05 16:45:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 18.96) (writing took 23.57035548053682 seconds)
2023-08-05 16:46:54 | INFO | train_inner | epoch 013:    421 / 1474 loss=0.791, trans_loss=5.138, nll_loss=2.369, w2v_ctc_loss=0.277, task_loss=1.31, contrastive_loss=0.109, total=4177.29, n_correct=2595.21, ppl=5.17, accuracy=62.127, wps=7251, ups=0.87, wpb=8354.6, bsz=318.4, num_updates=18100, lr=0.000105118, gnorm=0.201, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=16198
2023-08-05 16:48:02 | INFO | train_inner | epoch 013:    521 / 1474 loss=0.789, trans_loss=5.148, nll_loss=2.382, w2v_ctc_loss=0.275, task_loss=1.355, contrastive_loss=0.145, total=4201.22, n_correct=2598.8, ppl=5.21, accuracy=61.858, wps=12244.4, ups=1.46, wpb=8402.4, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.198, clip=0, loss_scale=32, train_wall=68, gb_free=12.8, wall=16267
2023-08-05 16:49:10 | INFO | train_inner | epoch 013:    621 / 1474 loss=0.786, trans_loss=5.141, nll_loss=2.373, w2v_ctc_loss=0.274, task_loss=1.358, contrastive_loss=0.061, total=4161.98, n_correct=2586.37, ppl=5.18, accuracy=62.143, wps=12294.1, ups=1.48, wpb=8324, bsz=308.3, num_updates=18300, lr=0.000104542, gnorm=0.2, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=16334
2023-08-05 16:50:18 | INFO | train_inner | epoch 013:    721 / 1474 loss=0.79, trans_loss=5.156, nll_loss=2.391, w2v_ctc_loss=0.283, task_loss=1.557, contrastive_loss=0.06, total=4096.76, n_correct=2524.46, ppl=5.24, accuracy=61.621, wps=11966.4, ups=1.46, wpb=8193.5, bsz=284.6, num_updates=18400, lr=0.000104257, gnorm=0.201, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=16403
2023-08-05 16:51:27 | INFO | train_inner | epoch 013:    821 / 1474 loss=0.788, trans_loss=5.151, nll_loss=2.386, w2v_ctc_loss=0.275, task_loss=1.411, contrastive_loss=0.104, total=4121.73, n_correct=2549.02, ppl=5.23, accuracy=61.843, wps=11989.1, ups=1.45, wpb=8243.5, bsz=306.7, num_updates=18500, lr=0.000103975, gnorm=0.202, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=16471
2023-08-05 16:52:35 | INFO | train_inner | epoch 013:    921 / 1474 loss=0.785, trans_loss=5.155, nll_loss=2.391, w2v_ctc_loss=0.277, task_loss=1.432, contrastive_loss=0.069, total=4107.01, n_correct=2540.74, ppl=5.24, accuracy=61.863, wps=12137.8, ups=1.48, wpb=8214, bsz=296.5, num_updates=18600, lr=0.000103695, gnorm=0.204, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=16539
2023-08-05 16:53:42 | INFO | train_inner | epoch 013:   1021 / 1474 loss=0.793, trans_loss=5.157, nll_loss=2.394, w2v_ctc_loss=0.279, task_loss=1.477, contrastive_loss=0.12, total=4081.02, n_correct=2515.37, ppl=5.26, accuracy=61.636, wps=12136.2, ups=1.49, wpb=8162, bsz=293.4, num_updates=18700, lr=0.000103418, gnorm=0.204, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=16606
2023-08-05 16:54:50 | INFO | train_inner | epoch 013:   1121 / 1474 loss=0.784, trans_loss=5.146, nll_loss=2.381, w2v_ctc_loss=0.273, task_loss=1.381, contrastive_loss=0.103, total=4105.62, n_correct=2545.42, ppl=5.21, accuracy=61.998, wps=12133.4, ups=1.48, wpb=8211.2, bsz=305.9, num_updates=18800, lr=0.000103142, gnorm=0.199, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=16674
2023-08-05 16:55:58 | INFO | train_inner | epoch 013:   1221 / 1474 loss=0.788, trans_loss=5.163, nll_loss=2.403, w2v_ctc_loss=0.279, task_loss=1.49, contrastive_loss=0.061, total=4110.35, n_correct=2537.54, ppl=5.29, accuracy=61.735, wps=12082.7, ups=1.47, wpb=8220.7, bsz=295.1, num_updates=18900, lr=0.000102869, gnorm=0.2, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=16742
2023-08-05 16:57:06 | INFO | train_inner | epoch 013:   1321 / 1474 loss=0.787, trans_loss=5.146, nll_loss=2.382, w2v_ctc_loss=0.274, task_loss=1.378, contrastive_loss=0.159, total=4112.2, n_correct=2549.13, ppl=5.21, accuracy=61.989, wps=11980.5, ups=1.46, wpb=8224.4, bsz=308.2, num_updates=19000, lr=0.000102598, gnorm=0.204, clip=0, loss_scale=64, train_wall=68, gb_free=17.6, wall=16811
2023-08-05 16:58:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 16:58:15 | INFO | train_inner | epoch 013:   1422 / 1474 loss=0.79, trans_loss=5.16, nll_loss=2.399, w2v_ctc_loss=0.277, task_loss=1.417, contrastive_loss=0.058, total=4156.59, n_correct=2563.6, ppl=5.28, accuracy=61.676, wps=12171.2, ups=1.46, wpb=8313.2, bsz=303.4, num_updates=19100, lr=0.000102329, gnorm=0.202, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=16879
2023-08-05 16:58:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 16:59:16 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 1.484 | trans_loss 5.592 | nll_loss 2.876 | w2v_ctc_loss 0.465 | task_loss 4.605 | contrastive_loss 0.243 | total 4003.4 | n_correct 2454.1 | ppl 7.34 | accuracy 61.3 | uer 18.22 | wer 20.018 | raw_wer 20.018 | bleu 19.38 | wps 1853.6 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 19.54
2023-08-05 16:59:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-08-05 16:59:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.3809.pt
2023-08-05 16:59:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.3809.pt
2023-08-05 16:59:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.3809.pt (epoch 13 @ 19152 updates, score 19.38) (writing took 19.377368081361055 seconds)
2023-08-05 16:59:36 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-05 16:59:36 | INFO | train | epoch 013 | loss 0.788 | trans_loss 5.146 | nll_loss 2.38 | w2v_ctc_loss 0.276 | task_loss 1.402 | contrastive_loss 0.106 | total 4137.23 | n_correct 2562.61 | ppl 5.21 | accuracy 61.94 | wps 11042.3 | ups 1.33 | wpb 8274.5 | bsz 305.1 | num_updates 19152 | lr 0.00010219 | gnorm 0.2 | clip 0 | loss_scale 32 | train_wall 996 | gb_free 17.6 | wall 16960
2023-08-05 16:59:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 16:59:36 | INFO | fairseq.trainer | begin training epoch 14
2023-08-05 16:59:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 17:00:16 | INFO | train_inner | epoch 014:     48 / 1474 loss=0.776, trans_loss=5.115, nll_loss=2.342, w2v_ctc_loss=0.269, task_loss=1.287, contrastive_loss=0.074, total=4179.66, n_correct=2617.72, ppl=5.07, accuracy=62.63, wps=6913.1, ups=0.83, wpb=8359.3, bsz=322, num_updates=19200, lr=0.000102062, gnorm=0.201, clip=0, loss_scale=32, train_wall=68, gb_free=10.3, wall=17000
2023-08-05 17:01:23 | INFO | train_inner | epoch 014:    148 / 1474 loss=0.779, trans_loss=5.103, nll_loss=2.324, w2v_ctc_loss=0.272, task_loss=1.4, contrastive_loss=0.058, total=4081.01, n_correct=2566.84, ppl=5.01, accuracy=62.897, wps=12073.7, ups=1.48, wpb=8162, bsz=300.6, num_updates=19300, lr=0.000101797, gnorm=0.202, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=17068
2023-08-05 17:02:32 | INFO | train_inner | epoch 014:    248 / 1474 loss=0.788, trans_loss=5.123, nll_loss=2.349, w2v_ctc_loss=0.273, task_loss=1.461, contrastive_loss=0.162, total=4109.83, n_correct=2570.66, ppl=5.09, accuracy=62.549, wps=12047.3, ups=1.47, wpb=8219.7, bsz=295.2, num_updates=19400, lr=0.000101535, gnorm=0.202, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=17136
2023-08-05 17:03:39 | INFO | train_inner | epoch 014:    348 / 1474 loss=0.778, trans_loss=5.117, nll_loss=2.343, w2v_ctc_loss=0.269, task_loss=1.303, contrastive_loss=0.092, total=4171.83, n_correct=2609.32, ppl=5.07, accuracy=62.546, wps=12360.4, ups=1.48, wpb=8343.7, bsz=319.7, num_updates=19500, lr=0.000101274, gnorm=0.206, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=17203
2023-08-05 17:04:47 | INFO | train_inner | epoch 014:    448 / 1474 loss=0.783, trans_loss=5.129, nll_loss=2.358, w2v_ctc_loss=0.271, task_loss=1.405, contrastive_loss=0.067, total=4142.75, n_correct=2582.1, ppl=5.13, accuracy=62.328, wps=12202.5, ups=1.47, wpb=8285.5, bsz=302.2, num_updates=19600, lr=0.000101015, gnorm=0.21, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=17271
2023-08-05 17:05:56 | INFO | train_inner | epoch 014:    548 / 1474 loss=0.785, trans_loss=5.132, nll_loss=2.361, w2v_ctc_loss=0.278, task_loss=1.506, contrastive_loss=0.075, total=4073.76, n_correct=2532.38, ppl=5.14, accuracy=62.163, wps=11877.3, ups=1.46, wpb=8147.5, bsz=290.9, num_updates=19700, lr=0.000100759, gnorm=0.212, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=17340
2023-08-05 17:07:04 | INFO | train_inner | epoch 014:    648 / 1474 loss=0.781, trans_loss=5.131, nll_loss=2.36, w2v_ctc_loss=0.27, task_loss=1.396, contrastive_loss=0.133, total=4158.79, n_correct=2589.58, ppl=5.13, accuracy=62.268, wps=12216, ups=1.47, wpb=8317.6, bsz=306.8, num_updates=19800, lr=0.000100504, gnorm=0.202, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=17408
2023-08-05 17:08:11 | INFO | train_inner | epoch 014:    748 / 1474 loss=0.778, trans_loss=5.118, nll_loss=2.345, w2v_ctc_loss=0.27, task_loss=1.36, contrastive_loss=0.064, total=4145.47, n_correct=2593.93, ppl=5.08, accuracy=62.573, wps=12266.4, ups=1.48, wpb=8290.9, bsz=309.6, num_updates=19900, lr=0.000100251, gnorm=0.203, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=17476
2023-08-05 17:09:19 | INFO | train_inner | epoch 014:    848 / 1474 loss=0.783, trans_loss=5.121, nll_loss=2.35, w2v_ctc_loss=0.269, task_loss=1.328, contrastive_loss=0.175, total=4171.1, n_correct=2608.89, ppl=5.1, accuracy=62.547, wps=12263.4, ups=1.47, wpb=8342.2, bsz=319.7, num_updates=20000, lr=0.0001, gnorm=0.201, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=17544
2023-08-05 17:09:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 17:09:43 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 1.488 | trans_loss 5.585 | nll_loss 2.867 | w2v_ctc_loss 0.468 | task_loss 4.583 | contrastive_loss 0.246 | total 4003.4 | n_correct 2455.6 | ppl 7.3 | accuracy 61.338 | uer 18.124 | wer 19.876 | raw_wer 19.876 | bleu 19.38 | wps 2172.7 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.54
2023-08-05 17:09:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-05 17:09:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_14_20000.pt
2023-08-05 17:09:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_14_20000.pt
2023-08-05 17:10:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.38) (writing took 32.99143774434924 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:0')
2023-08-05 17:11:25 | INFO | train_inner | epoch 014:    948 / 1474 loss=0.778, trans_loss=5.133, nll_loss=2.365, w2v_ctc_loss=0.27, task_loss=1.405, contrastive_loss=0.111, total=4167.75, n_correct=2590.92, ppl=5.15, accuracy=62.166, wps=6625.7, ups=0.79, wpb=8335.5, bsz=310.1, num_updates=20100, lr=9.97509e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=17669
2023-08-05 17:12:34 | INFO | train_inner | epoch 014:   1048 / 1474 loss=0.785, trans_loss=5.137, nll_loss=2.37, w2v_ctc_loss=0.271, task_loss=1.424, contrastive_loss=0.085, total=4143.92, n_correct=2580.64, ppl=5.17, accuracy=62.275, wps=12027.1, ups=1.45, wpb=8287.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.204, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=17738
2023-08-05 17:13:42 | INFO | train_inner | epoch 014:   1148 / 1474 loss=0.794, trans_loss=5.136, nll_loss=2.369, w2v_ctc_loss=0.274, task_loss=1.311, contrastive_loss=0.357, total=4228.69, n_correct=2627.33, ppl=5.17, accuracy=62.131, wps=12378.8, ups=1.46, wpb=8457.4, bsz=327.2, num_updates=20300, lr=9.92583e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=17807
2023-08-05 17:14:51 | INFO | train_inner | epoch 014:   1248 / 1474 loss=0.791, trans_loss=5.156, nll_loss=2.393, w2v_ctc_loss=0.281, task_loss=1.644, contrastive_loss=0.049, total=4021.19, n_correct=2486.22, ppl=5.25, accuracy=61.828, wps=11779.4, ups=1.46, wpb=8042.4, bsz=271.7, num_updates=20400, lr=9.90148e-05, gnorm=0.207, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=17875
2023-08-05 17:15:58 | INFO | train_inner | epoch 014:   1348 / 1474 loss=0.784, trans_loss=5.139, nll_loss=2.373, w2v_ctc_loss=0.271, task_loss=1.317, contrastive_loss=0.064, total=4213.9, n_correct=2621.31, ppl=5.18, accuracy=62.206, wps=12437.4, ups=1.48, wpb=8427.8, bsz=319.4, num_updates=20500, lr=9.8773e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=17943
2023-08-05 17:17:06 | INFO | train_inner | epoch 014:   1448 / 1474 loss=0.785, trans_loss=5.147, nll_loss=2.384, w2v_ctc_loss=0.272, task_loss=1.397, contrastive_loss=0.102, total=4130.28, n_correct=2565.08, ppl=5.22, accuracy=62.104, wps=12166, ups=1.47, wpb=8260.6, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=0.204, clip=0, loss_scale=32, train_wall=67, gb_free=15.3, wall=18011
2023-08-05 17:17:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:1')
2023-08-05 17:17:46 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 1.477 | trans_loss 5.578 | nll_loss 2.861 | w2v_ctc_loss 0.467 | task_loss 4.632 | contrastive_loss 0.243 | total 4003.4 | n_correct 2465.1 | ppl 7.27 | accuracy 61.575 | uer 17.997 | wer 19.977 | raw_wer 19.977 | bleu 19.54 | wps 2211.8 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.54
2023-08-05 17:17:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-08-05 17:17:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 17:17:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 17:18:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 14 @ 20626 updates, score 19.54) (writing took 23.269297245889902 seconds)
2023-08-05 17:18:10 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-05 17:18:10 | INFO | train | epoch 014 | loss 0.784 | trans_loss 5.13 | nll_loss 2.36 | w2v_ctc_loss 0.272 | task_loss 1.399 | contrastive_loss 0.113 | total 4138.65 | n_correct 2579.82 | ppl 5.13 | accuracy 62.335 | wps 10947.5 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.204 | clip 0 | loss_scale 32 | train_wall 997 | gb_free 16.4 | wall 18075
2023-08-05 17:18:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 17:18:11 | INFO | fairseq.trainer | begin training epoch 15
2023-08-05 17:18:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 17:19:08 | INFO | train_inner | epoch 015:     74 / 1474 loss=0.782, trans_loss=5.115, nll_loss=2.341, w2v_ctc_loss=0.269, task_loss=1.404, contrastive_loss=0.154, total=4083.88, n_correct=2557.58, ppl=5.07, accuracy=62.626, wps=6722, ups=0.82, wpb=8167.8, bsz=300.2, num_updates=20700, lr=9.82946e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=18132
2023-08-05 17:20:15 | INFO | train_inner | epoch 015:    174 / 1474 loss=0.781, trans_loss=5.106, nll_loss=2.328, w2v_ctc_loss=0.273, task_loss=1.456, contrastive_loss=0.062, total=4115.73, n_correct=2586.35, ppl=5.02, accuracy=62.841, wps=12158.5, ups=1.48, wpb=8231.5, bsz=297.8, num_updates=20800, lr=9.80581e-05, gnorm=0.21, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=18200
2023-08-05 17:21:23 | INFO | train_inner | epoch 015:    274 / 1474 loss=0.774, trans_loss=5.105, nll_loss=2.327, w2v_ctc_loss=0.266, task_loss=1.344, contrastive_loss=0.054, total=4193.15, n_correct=2641.65, ppl=5.02, accuracy=62.999, wps=12387.8, ups=1.48, wpb=8386.3, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.197, clip=0, loss_scale=32, train_wall=67, gb_free=12.6, wall=18267
2023-08-05 17:22:31 | INFO | train_inner | epoch 015:    374 / 1474 loss=0.776, trans_loss=5.1, nll_loss=2.32, w2v_ctc_loss=0.268, task_loss=1.414, contrastive_loss=0.077, total=4167.66, n_correct=2621.51, ppl=4.99, accuracy=62.901, wps=12283.9, ups=1.47, wpb=8335.3, bsz=306, num_updates=21000, lr=9.759e-05, gnorm=0.205, clip=0, loss_scale=32, train_wall=67, gb_free=16, wall=18335
2023-08-05 17:23:39 | INFO | train_inner | epoch 015:    474 / 1474 loss=0.782, trans_loss=5.11, nll_loss=2.334, w2v_ctc_loss=0.265, task_loss=1.463, contrastive_loss=0.17, total=4074.53, n_correct=2551.03, ppl=5.04, accuracy=62.609, wps=11977.9, ups=1.47, wpb=8149.1, bsz=294.2, num_updates=21100, lr=9.73585e-05, gnorm=0.205, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=18403
2023-08-05 17:24:47 | INFO | train_inner | epoch 015:    574 / 1474 loss=0.773, trans_loss=5.105, nll_loss=2.328, w2v_ctc_loss=0.269, task_loss=1.452, contrastive_loss=0.06, total=4140.59, n_correct=2602.69, ppl=5.02, accuracy=62.858, wps=12269.2, ups=1.48, wpb=8281.2, bsz=298.8, num_updates=21200, lr=9.71286e-05, gnorm=0.196, clip=0, loss_scale=64, train_wall=67, gb_free=12, wall=18471
2023-08-05 17:25:54 | INFO | train_inner | epoch 015:    674 / 1474 loss=0.782, trans_loss=5.109, nll_loss=2.333, w2v_ctc_loss=0.272, task_loss=1.416, contrastive_loss=0.139, total=4134.99, n_correct=2594.45, ppl=5.04, accuracy=62.744, wps=12187.7, ups=1.47, wpb=8270, bsz=307.1, num_updates=21300, lr=9.69003e-05, gnorm=0.205, clip=0, loss_scale=64, train_wall=67, gb_free=10.5, wall=18539
2023-08-05 17:27:03 | INFO | train_inner | epoch 015:    774 / 1474 loss=0.78, trans_loss=5.118, nll_loss=2.345, w2v_ctc_loss=0.272, task_loss=1.419, contrastive_loss=0.063, total=4173.66, n_correct=2613.31, ppl=5.08, accuracy=62.614, wps=12222, ups=1.46, wpb=8347.3, bsz=305, num_updates=21400, lr=9.66736e-05, gnorm=0.199, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=18607
2023-08-05 17:28:10 | INFO | train_inner | epoch 015:    874 / 1474 loss=0.782, trans_loss=5.124, nll_loss=2.353, w2v_ctc_loss=0.274, task_loss=1.507, contrastive_loss=0.06, total=4059.35, n_correct=2535.32, ppl=5.11, accuracy=62.456, wps=11987.9, ups=1.48, wpb=8118.7, bsz=288.3, num_updates=21500, lr=9.64486e-05, gnorm=0.203, clip=0, loss_scale=64, train_wall=67, gb_free=15.5, wall=18675
2023-08-05 17:29:18 | INFO | train_inner | epoch 015:    974 / 1474 loss=0.777, trans_loss=5.118, nll_loss=2.345, w2v_ctc_loss=0.267, task_loss=1.413, contrastive_loss=0.141, total=4122.87, n_correct=2584.08, ppl=5.08, accuracy=62.677, wps=12245.7, ups=1.49, wpb=8245.7, bsz=301.7, num_updates=21600, lr=9.6225e-05, gnorm=0.201, clip=0, loss_scale=64, train_wall=67, gb_free=17.5, wall=18742
2023-08-05 17:30:27 | INFO | train_inner | epoch 015:   1074 / 1474 loss=0.786, trans_loss=5.125, nll_loss=2.355, w2v_ctc_loss=0.269, task_loss=1.312, contrastive_loss=0.3, total=4192.24, n_correct=2617.52, ppl=5.12, accuracy=62.437, wps=12201.1, ups=1.46, wpb=8384.5, bsz=325.2, num_updates=21700, lr=9.60031e-05, gnorm=0.205, clip=0, loss_scale=64, train_wall=68, gb_free=17.1, wall=18811
2023-08-05 17:31:34 | INFO | train_inner | epoch 015:   1174 / 1474 loss=0.77, trans_loss=5.111, nll_loss=2.34, w2v_ctc_loss=0.261, task_loss=1.258, contrastive_loss=0.106, total=4185, n_correct=2637.71, ppl=5.06, accuracy=63.028, wps=12376.5, ups=1.48, wpb=8370, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.198, clip=0, loss_scale=64, train_wall=67, gb_free=16.2, wall=18878
2023-08-05 17:32:43 | INFO | train_inner | epoch 015:   1274 / 1474 loss=0.779, trans_loss=5.12, nll_loss=2.349, w2v_ctc_loss=0.272, task_loss=1.425, contrastive_loss=0.062, total=4152.04, n_correct=2599.26, ppl=5.1, accuracy=62.602, wps=12135.2, ups=1.46, wpb=8304.1, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.203, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=18947
2023-08-05 17:33:50 | INFO | train_inner | epoch 015:   1374 / 1474 loss=0.777, trans_loss=5.118, nll_loss=2.346, w2v_ctc_loss=0.267, task_loss=1.448, contrastive_loss=0.049, total=4100.21, n_correct=2572.82, ppl=5.08, accuracy=62.748, wps=12135, ups=1.48, wpb=8200.4, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.199, clip=0, loss_scale=64, train_wall=67, gb_free=17.5, wall=19014
2023-08-05 17:33:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 17:34:15 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 1.477 | trans_loss 5.581 | nll_loss 2.857 | w2v_ctc_loss 0.453 | task_loss 4.624 | contrastive_loss 0.24 | total 4003.4 | n_correct 2464.4 | ppl 7.25 | accuracy 61.558 | uer 17.742 | wer 19.608 | raw_wer 19.608 | bleu 19.38 | wps 1997.7 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.54
2023-08-05 17:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-05 17:34:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_15_22000.pt
2023-08-05 17:34:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_15_22000.pt
2023-08-05 17:34:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.38) (writing took 30.548453591763973 seconds)
2023-08-05 17:35:55 | INFO | train_inner | epoch 015:   1474 / 1474 loss=0.779, trans_loss=5.124, nll_loss=2.356, w2v_ctc_loss=0.268, task_loss=1.358, contrastive_loss=0.135, total=4141.17, n_correct=2593.34, ppl=5.12, accuracy=62.623, wps=6634.1, ups=0.8, wpb=8282.3, bsz=314.3, num_updates=22100, lr=9.51303e-05, gnorm=0.2, clip=0, loss_scale=64, train_wall=68, gb_free=16.9, wall=19139
2023-08-05 17:35:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 17:36:20 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 1.484 | trans_loss 5.575 | nll_loss 2.854 | w2v_ctc_loss 0.482 | task_loss 4.61 | contrastive_loss 0.241 | total 4003.4 | n_correct 2468.7 | ppl 7.23 | accuracy 61.665 | uer 17.747 | wer 19.645 | raw_wer 19.645 | bleu 19.26 | wps 1801.8 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 19.54
2023-08-05 17:36:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-08-05 17:36:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.2600.pt
2023-08-05 17:36:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.2600.pt
2023-08-05 17:36:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.2600.pt (epoch 15 @ 22100 updates, score 19.26) (writing took 17.74344298429787 seconds)
2023-08-05 17:36:38 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-05 17:36:38 | INFO | train | epoch 015 | loss 0.778 | trans_loss 5.113 | nll_loss 2.339 | w2v_ctc_loss 0.269 | task_loss 1.402 | contrastive_loss 0.111 | total 4138.65 | n_correct 2596.58 | ppl 5.06 | accuracy 62.74 | wps 11010.6 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.202 | clip 0 | loss_scale 64 | train_wall 994 | gb_free 16.9 | wall 19183
2023-08-05 17:36:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 17:36:39 | INFO | fairseq.trainer | begin training epoch 16
2023-08-05 17:36:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 17:37:54 | INFO | train_inner | epoch 016:    100 / 1474 loss=0.768, trans_loss=5.081, nll_loss=2.298, w2v_ctc_loss=0.263, task_loss=1.335, contrastive_loss=0.077, total=4126.22, n_correct=2616.52, ppl=4.92, accuracy=63.412, wps=6949.1, ups=0.84, wpb=8252.4, bsz=315.6, num_updates=22200, lr=9.49158e-05, gnorm=0.2, clip=0, loss_scale=64, train_wall=67, gb_free=16, wall=19258
2023-08-05 17:39:02 | INFO | train_inner | epoch 016:    200 / 1474 loss=0.768, trans_loss=5.08, nll_loss=2.295, w2v_ctc_loss=0.262, task_loss=1.439, contrastive_loss=0.056, total=4100.6, n_correct=2600.16, ppl=4.91, accuracy=63.409, wps=12018, ups=1.47, wpb=8201.2, bsz=296.8, num_updates=22300, lr=9.47027e-05, gnorm=0.2, clip=0, loss_scale=64, train_wall=68, gb_free=12.5, wall=19326
2023-08-05 17:40:10 | INFO | train_inner | epoch 016:    300 / 1474 loss=0.777, trans_loss=5.094, nll_loss=2.314, w2v_ctc_loss=0.267, task_loss=1.387, contrastive_loss=0.128, total=4166.94, n_correct=2629.61, ppl=4.97, accuracy=63.107, wps=12213.3, ups=1.47, wpb=8333.9, bsz=308.9, num_updates=22400, lr=9.44911e-05, gnorm=0.201, clip=0, loss_scale=64, train_wall=68, gb_free=17.1, wall=19395
2023-08-05 17:40:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 17:41:18 | INFO | train_inner | epoch 016:    401 / 1474 loss=0.775, trans_loss=5.094, nll_loss=2.314, w2v_ctc_loss=0.267, task_loss=1.512, contrastive_loss=0.128, total=4060.59, n_correct=2559.01, ppl=4.97, accuracy=63.021, wps=11907.5, ups=1.47, wpb=8121.2, bsz=284, num_updates=22500, lr=9.42809e-05, gnorm=0.208, clip=0, loss_scale=32, train_wall=68, gb_free=12.6, wall=19463
2023-08-05 17:42:27 | INFO | train_inner | epoch 016:    501 / 1474 loss=0.774, trans_loss=5.089, nll_loss=2.309, w2v_ctc_loss=0.265, task_loss=1.345, contrastive_loss=0.084, total=4179.53, n_correct=2648.23, ppl=4.95, accuracy=63.362, wps=12206.1, ups=1.46, wpb=8359.1, bsz=319.5, num_updates=22600, lr=9.40721e-05, gnorm=0.197, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=19531
2023-08-05 17:43:35 | INFO | train_inner | epoch 016:    601 / 1474 loss=0.773, trans_loss=5.095, nll_loss=2.316, w2v_ctc_loss=0.264, task_loss=1.41, contrastive_loss=0.05, total=4121.37, n_correct=2603.82, ppl=4.98, accuracy=63.179, wps=12196.4, ups=1.48, wpb=8242.7, bsz=297.5, num_updates=22700, lr=9.38647e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=67, gb_free=17.8, wall=19599
2023-08-05 17:44:42 | INFO | train_inner | epoch 016:    701 / 1474 loss=0.775, trans_loss=5.099, nll_loss=2.321, w2v_ctc_loss=0.267, task_loss=1.431, contrastive_loss=0.053, total=4099.17, n_correct=2586.58, ppl=5, accuracy=63.1, wps=12205.5, ups=1.49, wpb=8198.3, bsz=297.5, num_updates=22800, lr=9.36586e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=19666
2023-08-05 17:45:50 | INFO | train_inner | epoch 016:    801 / 1474 loss=0.771, trans_loss=5.098, nll_loss=2.32, w2v_ctc_loss=0.261, task_loss=1.337, contrastive_loss=0.112, total=4184.53, n_correct=2638.92, ppl=4.99, accuracy=63.064, wps=12340.2, ups=1.47, wpb=8369.1, bsz=313, num_updates=22900, lr=9.34539e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=67, gb_free=13.3, wall=19734
2023-08-05 17:46:57 | INFO | train_inner | epoch 016:    901 / 1474 loss=0.772, trans_loss=5.097, nll_loss=2.32, w2v_ctc_loss=0.263, task_loss=1.375, contrastive_loss=0.105, total=4151.84, n_correct=2623.93, ppl=4.99, accuracy=63.199, wps=12278.9, ups=1.48, wpb=8303.7, bsz=307, num_updates=23000, lr=9.32505e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=19801
2023-08-05 17:48:05 | INFO | train_inner | epoch 016:   1001 / 1474 loss=0.78, trans_loss=5.112, nll_loss=2.339, w2v_ctc_loss=0.27, task_loss=1.446, contrastive_loss=0.103, total=4112.79, n_correct=2579.52, ppl=5.06, accuracy=62.719, wps=12088.6, ups=1.47, wpb=8225.6, bsz=299.5, num_updates=23100, lr=9.30484e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=19870
2023-08-05 17:49:14 | INFO | train_inner | epoch 016:   1101 / 1474 loss=0.78, trans_loss=5.115, nll_loss=2.343, w2v_ctc_loss=0.271, task_loss=1.487, contrastive_loss=0.079, total=4111.6, n_correct=2578.74, ppl=5.07, accuracy=62.719, wps=12036, ups=1.46, wpb=8223.2, bsz=295.6, num_updates=23200, lr=9.28477e-05, gnorm=0.21, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=19938
2023-08-05 17:50:22 | INFO | train_inner | epoch 016:   1201 / 1474 loss=0.779, trans_loss=5.109, nll_loss=2.336, w2v_ctc_loss=0.262, task_loss=1.429, contrastive_loss=0.172, total=4157.51, n_correct=2613.15, ppl=5.05, accuracy=62.854, wps=12067, ups=1.45, wpb=8315, bsz=306.6, num_updates=23300, lr=9.26482e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=20007
2023-08-05 17:51:31 | INFO | train_inner | epoch 016:   1301 / 1474 loss=0.779, trans_loss=5.108, nll_loss=2.334, w2v_ctc_loss=0.268, task_loss=1.356, contrastive_loss=0.151, total=4151.03, n_correct=2613.13, ppl=5.04, accuracy=62.951, wps=12174.4, ups=1.47, wpb=8302.1, bsz=314.5, num_updates=23400, lr=9.245e-05, gnorm=0.201, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=20075
2023-08-05 17:52:39 | INFO | train_inner | epoch 016:   1401 / 1474 loss=0.776, trans_loss=5.111, nll_loss=2.339, w2v_ctc_loss=0.268, task_loss=1.336, contrastive_loss=0.082, total=4201.47, n_correct=2642.99, ppl=5.06, accuracy=62.906, wps=12307.1, ups=1.46, wpb=8402.9, bsz=320.7, num_updates=23500, lr=9.22531e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=20143
2023-08-05 17:53:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 17:53:52 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 1.474 | trans_loss 5.574 | nll_loss 2.854 | w2v_ctc_loss 0.459 | task_loss 4.612 | contrastive_loss 0.241 | total 4003.4 | n_correct 2469.5 | ppl 7.23 | accuracy 61.685 | uer 17.899 | wer 19.645 | raw_wer 19.645 | bleu 19.84 | wps 2159.3 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 19.84
2023-08-05 17:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-08-05 17:53:52 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 17:54:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 17:54:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 16 @ 23573 updates, score 19.84) (writing took 28.053910173475742 seconds)
2023-08-05 17:54:21 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-05 17:54:21 | INFO | train | epoch 016 | loss 0.775 | trans_loss 5.099 | nll_loss 2.322 | w2v_ctc_loss 0.266 | task_loss 1.4 | contrastive_loss 0.108 | total 4138.2 | n_correct 2609.63 | ppl 5 | accuracy 63.062 | wps 11477.8 | ups 1.39 | wpb 8276.4 | bsz 305.5 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.201 | clip 0 | loss_scale 32 | train_wall 995 | gb_free 15.4 | wall 20245
2023-08-05 17:54:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 17:54:21 | INFO | fairseq.trainer | begin training epoch 17
2023-08-05 17:54:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 17:54:46 | INFO | train_inner | epoch 017:     27 / 1474 loss=0.781, trans_loss=5.092, nll_loss=2.312, w2v_ctc_loss=0.264, task_loss=1.429, contrastive_loss=0.221, total=4145.04, n_correct=2618.16, ppl=4.97, accuracy=63.164, wps=6504.9, ups=0.78, wpb=8290.1, bsz=302.4, num_updates=23600, lr=9.20575e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=20271
2023-08-05 17:55:55 | INFO | train_inner | epoch 017:    127 / 1474 loss=0.771, trans_loss=5.069, nll_loss=2.282, w2v_ctc_loss=0.265, task_loss=1.439, contrastive_loss=0.056, total=4117.27, n_correct=2618.92, ppl=4.86, accuracy=63.608, wps=12082.8, ups=1.47, wpb=8234.5, bsz=296.2, num_updates=23700, lr=9.1863e-05, gnorm=0.205, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=20339
2023-08-05 17:57:03 | INFO | train_inner | epoch 017:    227 / 1474 loss=0.771, trans_loss=5.071, nll_loss=2.286, w2v_ctc_loss=0.256, task_loss=1.326, contrastive_loss=0.22, total=4159.6, n_correct=2646.25, ppl=4.88, accuracy=63.618, wps=12182.3, ups=1.46, wpb=8319.2, bsz=317.6, num_updates=23800, lr=9.16698e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=20407
2023-08-05 17:58:10 | INFO | train_inner | epoch 017:    327 / 1474 loss=0.777, trans_loss=5.079, nll_loss=2.296, w2v_ctc_loss=0.262, task_loss=1.392, contrastive_loss=0.226, total=4156.91, n_correct=2633.83, ppl=4.91, accuracy=63.36, wps=12326.7, ups=1.48, wpb=8313.8, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.201, clip=0, loss_scale=32, train_wall=67, gb_free=17.4, wall=20475
2023-08-05 17:59:19 | INFO | train_inner | epoch 017:    427 / 1474 loss=0.767, trans_loss=5.078, nll_loss=2.295, w2v_ctc_loss=0.26, task_loss=1.39, contrastive_loss=0.054, total=4146.43, n_correct=2635.74, ppl=4.91, accuracy=63.566, wps=12124.5, ups=1.46, wpb=8292.9, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=20543
2023-08-05 17:59:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 17:59:43 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 1.48 | trans_loss 5.582 | nll_loss 2.86 | w2v_ctc_loss 0.461 | task_loss 4.623 | contrastive_loss 0.239 | total 4003.4 | n_correct 2461.4 | ppl 7.26 | accuracy 61.483 | uer 17.739 | wer 19.455 | raw_wer 19.455 | bleu 19.36 | wps 1991.4 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.84
2023-08-05 17:59:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-05 17:59:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_17_24000.pt
2023-08-05 17:59:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_17_24000.pt
2023-08-05 18:00:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.36) (writing took 22.15242637321353 seconds)
2023-08-05 18:01:15 | INFO | train_inner | epoch 017:    527 / 1474 loss=0.775, trans_loss=5.082, nll_loss=2.3, w2v_ctc_loss=0.265, task_loss=1.452, contrastive_loss=0.097, total=4182.1, n_correct=2651.94, ppl=4.93, accuracy=63.412, wps=7162.5, ups=0.86, wpb=8364.2, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=20660
2023-08-05 18:02:24 | INFO | train_inner | epoch 017:    627 / 1474 loss=0.769, trans_loss=5.084, nll_loss=2.302, w2v_ctc_loss=0.262, task_loss=1.41, contrastive_loss=0.05, total=4167.27, n_correct=2645.15, ppl=4.93, accuracy=63.474, wps=12157.4, ups=1.46, wpb=8334.5, bsz=302.2, num_updates=24200, lr=9.09091e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=68, gb_free=10.6, wall=20728
2023-08-05 18:03:32 | INFO | train_inner | epoch 017:    727 / 1474 loss=0.771, trans_loss=5.09, nll_loss=2.31, w2v_ctc_loss=0.266, task_loss=1.385, contrastive_loss=0.095, total=4166.12, n_correct=2637.09, ppl=4.96, accuracy=63.298, wps=12344.7, ups=1.48, wpb=8332.2, bsz=308.1, num_updates=24300, lr=9.07218e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=20796
2023-08-05 18:04:39 | INFO | train_inner | epoch 017:    827 / 1474 loss=0.77, trans_loss=5.089, nll_loss=2.308, w2v_ctc_loss=0.263, task_loss=1.418, contrastive_loss=0.062, total=4091.64, n_correct=2591.48, ppl=4.95, accuracy=63.336, wps=12101.1, ups=1.48, wpb=8183.3, bsz=295.3, num_updates=24400, lr=9.05357e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=20863
2023-08-05 18:05:47 | INFO | train_inner | epoch 017:    927 / 1474 loss=0.771, trans_loss=5.09, nll_loss=2.31, w2v_ctc_loss=0.261, task_loss=1.379, contrastive_loss=0.06, total=4106.83, n_correct=2599.79, ppl=4.96, accuracy=63.304, wps=12173.6, ups=1.48, wpb=8213.7, bsz=304.6, num_updates=24500, lr=9.03508e-05, gnorm=0.203, clip=0, loss_scale=64, train_wall=67, gb_free=15.8, wall=20931
2023-08-05 18:06:55 | INFO | train_inner | epoch 017:   1027 / 1474 loss=0.767, trans_loss=5.087, nll_loss=2.307, w2v_ctc_loss=0.262, task_loss=1.385, contrastive_loss=0.064, total=4115.49, n_correct=2611.33, ppl=4.95, accuracy=63.451, wps=12123.4, ups=1.47, wpb=8231, bsz=305.8, num_updates=24600, lr=9.0167e-05, gnorm=0.202, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=20999
2023-08-05 18:07:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 18:08:02 | INFO | train_inner | epoch 017:   1128 / 1474 loss=0.771, trans_loss=5.086, nll_loss=2.306, w2v_ctc_loss=0.261, task_loss=1.43, contrastive_loss=0.056, total=4090.5, n_correct=2598.07, ppl=4.94, accuracy=63.515, wps=12042.1, ups=1.47, wpb=8181, bsz=298.3, num_updates=24700, lr=8.99843e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=21067
2023-08-05 18:09:12 | INFO | train_inner | epoch 017:   1228 / 1474 loss=0.778, trans_loss=5.1, nll_loss=2.326, w2v_ctc_loss=0.259, task_loss=1.37, contrastive_loss=0.288, total=4162.14, n_correct=2619.19, ppl=5.01, accuracy=62.929, wps=12048.5, ups=1.45, wpb=8324.3, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=21136
2023-08-05 18:10:20 | INFO | train_inner | epoch 017:   1328 / 1474 loss=0.772, trans_loss=5.096, nll_loss=2.319, w2v_ctc_loss=0.258, task_loss=1.394, contrastive_loss=0.132, total=4149.03, n_correct=2621.74, ppl=4.99, accuracy=63.189, wps=12213.2, ups=1.47, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=21204
2023-08-05 18:11:28 | INFO | train_inner | epoch 017:   1428 / 1474 loss=0.767, trans_loss=5.095, nll_loss=2.317, w2v_ctc_loss=0.26, task_loss=1.407, contrastive_loss=0.055, total=4117.13, n_correct=2604.72, ppl=4.98, accuracy=63.265, wps=12100.6, ups=1.47, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=68, gb_free=17.5, wall=21272
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:0')
2023-08-05 18:11:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:2')
2023-08-05 18:12:23 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 1.471 | trans_loss 5.565 | nll_loss 2.846 | w2v_ctc_loss 0.466 | task_loss 4.646 | contrastive_loss 0.246 | total 4003.4 | n_correct 2469.4 | ppl 7.19 | accuracy 61.683 | uer 17.729 | wer 19.544 | raw_wer 19.544 | bleu 19.91 | wps 2089.6 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 19.91
2023-08-05 18:12:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-08-05 18:12:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 18:12:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 18:12:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 17 @ 25046 updates, score 19.91) (writing took 27.10225767455995 seconds)
2023-08-05 18:12:51 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-05 18:12:51 | INFO | train | epoch 017 | loss 0.771 | trans_loss 5.085 | nll_loss 2.304 | w2v_ctc_loss 0.262 | task_loss 1.399 | contrastive_loss 0.107 | total 4138.69 | n_correct 2623.25 | ppl 4.94 | accuracy 63.383 | wps 10983.3 | ups 1.33 | wpb 8277.4 | bsz 305.7 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.201 | clip 0 | loss_scale 32 | train_wall 997 | gb_free 16.3 | wall 21355
2023-08-05 18:12:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 18:12:51 | INFO | fairseq.trainer | begin training epoch 18
2023-08-05 18:12:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 18:13:36 | INFO | train_inner | epoch 018:     54 / 1474 loss=0.771, trans_loss=5.08, nll_loss=2.297, w2v_ctc_loss=0.264, task_loss=1.426, contrastive_loss=0.064, total=4138.21, n_correct=2627.3, ppl=4.91, accuracy=63.489, wps=6447.7, ups=0.78, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.205, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=21400
2023-08-05 18:14:44 | INFO | train_inner | epoch 018:    154 / 1474 loss=0.764, trans_loss=5.055, nll_loss=2.264, w2v_ctc_loss=0.251, task_loss=1.33, contrastive_loss=0.184, total=4158.88, n_correct=2660.96, ppl=4.8, accuracy=63.983, wps=12252.1, ups=1.47, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=21468
2023-08-05 18:15:52 | INFO | train_inner | epoch 018:    254 / 1474 loss=0.762, trans_loss=5.054, nll_loss=2.264, w2v_ctc_loss=0.256, task_loss=1.359, contrastive_loss=0.055, total=4164.11, n_correct=2671.71, ppl=4.8, accuracy=64.16, wps=12150, ups=1.46, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=68, gb_free=14.9, wall=21537
2023-08-05 18:17:01 | INFO | train_inner | epoch 018:    354 / 1474 loss=0.768, trans_loss=5.064, nll_loss=2.276, w2v_ctc_loss=0.26, task_loss=1.421, contrastive_loss=0.069, total=4163.13, n_correct=2655.93, ppl=4.84, accuracy=63.796, wps=12222, ups=1.47, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.197, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=21605
2023-08-05 18:18:09 | INFO | train_inner | epoch 018:    454 / 1474 loss=0.768, trans_loss=5.072, nll_loss=2.286, w2v_ctc_loss=0.257, task_loss=1.496, contrastive_loss=0.16, total=4087.83, n_correct=2599.77, ppl=4.88, accuracy=63.598, wps=11979.3, ups=1.47, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=21673
2023-08-05 18:19:17 | INFO | train_inner | epoch 018:    554 / 1474 loss=0.765, trans_loss=5.056, nll_loss=2.268, w2v_ctc_loss=0.257, task_loss=1.257, contrastive_loss=0.069, total=4204.41, n_correct=2691.63, ppl=4.82, accuracy=64.019, wps=12409.9, ups=1.48, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=67, gb_free=17.4, wall=21741
2023-08-05 18:20:24 | INFO | train_inner | epoch 018:    654 / 1474 loss=0.77, trans_loss=5.082, nll_loss=2.3, w2v_ctc_loss=0.26, task_loss=1.446, contrastive_loss=0.138, total=4096.81, n_correct=2599.86, ppl=4.92, accuracy=63.461, wps=12072.3, ups=1.47, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.207, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=21809
2023-08-05 18:21:33 | INFO | train_inner | epoch 018:    754 / 1474 loss=0.773, trans_loss=5.077, nll_loss=2.295, w2v_ctc_loss=0.261, task_loss=1.334, contrastive_loss=0.226, total=4208.29, n_correct=2672.47, ppl=4.91, accuracy=63.505, wps=12355.1, ups=1.47, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=68, gb_free=17.8, wall=21877
2023-08-05 18:22:41 | INFO | train_inner | epoch 018:    854 / 1474 loss=0.764, trans_loss=5.077, nll_loss=2.293, w2v_ctc_loss=0.258, task_loss=1.42, contrastive_loss=0.047, total=4166.81, n_correct=2652.48, ppl=4.9, accuracy=63.657, wps=12254.7, ups=1.47, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=68, gb_free=12.5, wall=21945
2023-08-05 18:23:47 | INFO | train_inner | epoch 018:    954 / 1474 loss=0.764, trans_loss=5.069, nll_loss=2.284, w2v_ctc_loss=0.255, task_loss=1.3, contrastive_loss=0.067, total=4142.65, n_correct=2642.76, ppl=4.87, accuracy=63.794, wps=12382.7, ups=1.49, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.201, clip=0, loss_scale=32, train_wall=66, gb_free=14.8, wall=22012
2023-08-05 18:23:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 18:24:12 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 1.478 | trans_loss 5.568 | nll_loss 2.841 | w2v_ctc_loss 0.475 | task_loss 4.625 | contrastive_loss 0.234 | total 4003.4 | n_correct 2473.1 | ppl 7.17 | accuracy 61.775 | uer 17.564 | wer 19.336 | raw_wer 19.336 | bleu 19.87 | wps 1800.5 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 19.91
2023-08-05 18:24:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-05 18:24:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_18_26000.pt
2023-08-05 18:24:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_18_26000.pt
2023-08-05 18:24:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.87) (writing took 19.133482975885272 seconds)
2023-08-05 18:25:41 | INFO | train_inner | epoch 018:   1054 / 1474 loss=0.767, trans_loss=5.078, nll_loss=2.296, w2v_ctc_loss=0.257, task_loss=1.456, contrastive_loss=0.057, total=4137.77, n_correct=2632.51, ppl=4.91, accuracy=63.621, wps=7317.5, ups=0.88, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.205, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=22125
2023-08-05 18:26:48 | INFO | train_inner | epoch 018:   1154 / 1474 loss=0.77, trans_loss=5.065, nll_loss=2.28, w2v_ctc_loss=0.258, task_loss=1.326, contrastive_loss=0.164, total=4153.69, n_correct=2648.34, ppl=4.86, accuracy=63.759, wps=12245.8, ups=1.47, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=67, gb_free=15, wall=22193
2023-08-05 18:27:56 | INFO | train_inner | epoch 018:   1254 / 1474 loss=0.766, trans_loss=5.087, nll_loss=2.307, w2v_ctc_loss=0.258, task_loss=1.504, contrastive_loss=0.051, total=4087.62, n_correct=2591.78, ppl=4.95, accuracy=63.406, wps=12093, ups=1.48, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=22260
2023-08-05 18:29:03 | INFO | train_inner | epoch 018:   1354 / 1474 loss=0.773, trans_loss=5.094, nll_loss=2.316, w2v_ctc_loss=0.266, task_loss=1.492, contrastive_loss=0.074, total=4070.69, n_correct=2574.48, ppl=4.98, accuracy=63.244, wps=12081.1, ups=1.48, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=22328
2023-08-05 18:30:11 | INFO | train_inner | epoch 018:   1454 / 1474 loss=0.769, trans_loss=5.087, nll_loss=2.307, w2v_ctc_loss=0.261, task_loss=1.477, contrastive_loss=0.061, total=4113.2, n_correct=2608.21, ppl=4.95, accuracy=63.411, wps=12093.3, ups=1.47, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=22396
2023-08-05 18:30:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 18:30:48 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 1.475 | trans_loss 5.561 | nll_loss 2.838 | w2v_ctc_loss 0.465 | task_loss 4.609 | contrastive_loss 0.237 | total 4003.4 | n_correct 2475.5 | ppl 7.15 | accuracy 61.835 | uer 17.214 | wer 19.011 | raw_wer 19.011 | bleu 19.8 | wps 2221.4 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 19.91
2023-08-05 18:30:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-08-05 18:30:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.8004.pt
2023-08-05 18:30:51 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.8004.pt
2023-08-05 18:31:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.8004.pt (epoch 18 @ 26520 updates, score 19.8) (writing took 13.482756856828928 seconds)
2023-08-05 18:31:02 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-05 18:31:02 | INFO | train | epoch 018 | loss 0.767 | trans_loss 5.072 | nll_loss 2.288 | w2v_ctc_loss 0.258 | task_loss 1.399 | contrastive_loss 0.105 | total 4138.65 | n_correct 2635.21 | ppl 4.88 | accuracy 63.673 | wps 11180.8 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.202 | clip 0 | loss_scale 32 | train_wall 995 | gb_free 15.9 | wall 22446
2023-08-05 18:31:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 18:31:02 | INFO | fairseq.trainer | begin training epoch 19
2023-08-05 18:31:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 18:32:04 | INFO | train_inner | epoch 019:     80 / 1474 loss=0.762, trans_loss=5.049, nll_loss=2.257, w2v_ctc_loss=0.255, task_loss=1.403, contrastive_loss=0.113, total=4102.06, n_correct=2627.29, ppl=4.78, accuracy=64.048, wps=7313.7, ups=0.89, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=67, gb_free=17.4, wall=22508
2023-08-05 18:33:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 18:33:13 | INFO | train_inner | epoch 019:    181 / 1474 loss=0.76, trans_loss=5.04, nll_loss=2.246, w2v_ctc_loss=0.258, task_loss=1.329, contrastive_loss=0.087, total=4210.09, n_correct=2707.58, ppl=4.74, accuracy=64.312, wps=12202.3, ups=1.45, wpb=8420.2, bsz=319.1, num_updates=26700, lr=8.65485e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=69, gb_free=11.5, wall=22577
2023-08-05 18:34:20 | INFO | train_inner | epoch 019:    281 / 1474 loss=0.761, trans_loss=5.044, nll_loss=2.251, w2v_ctc_loss=0.257, task_loss=1.371, contrastive_loss=0.048, total=4187.37, n_correct=2692.27, ppl=4.76, accuracy=64.295, wps=12381.8, ups=1.48, wpb=8374.7, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=22645
2023-08-05 18:35:28 | INFO | train_inner | epoch 019:    381 / 1474 loss=0.762, trans_loss=5.048, nll_loss=2.257, w2v_ctc_loss=0.251, task_loss=1.378, contrastive_loss=0.153, total=4170.67, n_correct=2678.44, ppl=4.78, accuracy=64.221, wps=12267.7, ups=1.47, wpb=8341.3, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.205, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=22713
2023-08-05 18:36:36 | INFO | train_inner | epoch 019:    481 / 1474 loss=0.765, trans_loss=5.057, nll_loss=2.268, w2v_ctc_loss=0.258, task_loss=1.435, contrastive_loss=0.062, total=4115.22, n_correct=2636.73, ppl=4.82, accuracy=64.073, wps=12140.2, ups=1.48, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.204, clip=0, loss_scale=32, train_wall=67, gb_free=15.1, wall=22780
2023-08-05 18:37:44 | INFO | train_inner | epoch 019:    581 / 1474 loss=0.762, trans_loss=5.053, nll_loss=2.264, w2v_ctc_loss=0.255, task_loss=1.37, contrastive_loss=0.125, total=4129.22, n_correct=2650.53, ppl=4.8, accuracy=64.19, wps=12208.9, ups=1.48, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.21, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=22848
2023-08-05 18:38:52 | INFO | train_inner | epoch 019:    681 / 1474 loss=0.762, trans_loss=5.055, nll_loss=2.266, w2v_ctc_loss=0.251, task_loss=1.276, contrastive_loss=0.054, total=4197.2, n_correct=2694.68, ppl=4.81, accuracy=64.202, wps=12376.9, ups=1.47, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.201, clip=0, loss_scale=32, train_wall=67, gb_free=14.6, wall=22916
2023-08-05 18:39:59 | INFO | train_inner | epoch 019:    781 / 1474 loss=0.765, trans_loss=5.058, nll_loss=2.27, w2v_ctc_loss=0.259, task_loss=1.406, contrastive_loss=0.066, total=4142.6, n_correct=2652.09, ppl=4.82, accuracy=64.02, wps=12186.5, ups=1.47, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=22984
2023-08-05 18:41:07 | INFO | train_inner | epoch 019:    881 / 1474 loss=0.766, trans_loss=5.067, nll_loss=2.281, w2v_ctc_loss=0.258, task_loss=1.427, contrastive_loss=0.051, total=4153.47, n_correct=2651.55, ppl=4.86, accuracy=63.839, wps=12229.6, ups=1.47, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=23052
2023-08-05 18:42:16 | INFO | train_inner | epoch 019:    981 / 1474 loss=0.771, trans_loss=5.077, nll_loss=2.295, w2v_ctc_loss=0.255, task_loss=1.4, contrastive_loss=0.282, total=4101.29, n_correct=2610.1, ppl=4.91, accuracy=63.641, wps=11900.8, ups=1.45, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.204, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=23121
2023-08-05 18:43:25 | INFO | train_inner | epoch 019:   1081 / 1474 loss=0.768, trans_loss=5.079, nll_loss=2.298, w2v_ctc_loss=0.257, task_loss=1.492, contrastive_loss=0.092, total=4036.97, n_correct=2566.97, ppl=4.92, accuracy=63.587, wps=11831.5, ups=1.47, wpb=8073.9, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=68, gb_free=14.6, wall=23189
2023-08-05 18:44:33 | INFO | train_inner | epoch 019:   1181 / 1474 loss=0.769, trans_loss=5.076, nll_loss=2.293, w2v_ctc_loss=0.258, task_loss=1.419, contrastive_loss=0.177, total=4137.49, n_correct=2628.71, ppl=4.9, accuracy=63.534, wps=12082.1, ups=1.46, wpb=8275, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=68, gb_free=14.7, wall=23257
2023-08-05 18:45:40 | INFO | train_inner | epoch 019:   1281 / 1474 loss=0.768, trans_loss=5.077, nll_loss=2.295, w2v_ctc_loss=0.256, task_loss=1.415, contrastive_loss=0.074, total=4141.89, n_correct=2638.34, ppl=4.91, accuracy=63.699, wps=12316.3, ups=1.49, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.204, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=23325
2023-08-05 18:46:49 | INFO | train_inner | epoch 019:   1381 / 1474 loss=0.764, trans_loss=5.072, nll_loss=2.289, w2v_ctc_loss=0.257, task_loss=1.429, contrastive_loss=0.059, total=4133.26, n_correct=2638.06, ppl=4.89, accuracy=63.825, wps=12111, ups=1.47, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.21, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=23393
2023-08-05 18:47:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 18:48:14 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 1.468 | trans_loss 5.555 | nll_loss 2.83 | w2v_ctc_loss 0.46 | task_loss 4.629 | contrastive_loss 0.236 | total 4003.4 | n_correct 2477.6 | ppl 7.11 | accuracy 61.887 | uer 17.275 | wer 19 | raw_wer 19 | bleu 19.99 | wps 2321.8 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 19.99
2023-08-05 18:48:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-08-05 18:48:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 18:48:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 18:48:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 19 @ 27993 updates, score 19.99) (writing took 22.743451388552785 seconds)
2023-08-05 18:48:38 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-05 18:48:38 | INFO | train | epoch 019 | loss 0.765 | trans_loss 5.061 | nll_loss 2.274 | w2v_ctc_loss 0.256 | task_loss 1.399 | contrastive_loss 0.103 | total 4137.6 | n_correct 2646.84 | ppl 4.84 | accuracy 63.97 | wps 11544.9 | ups 1.4 | wpb 8275.2 | bsz 305.3 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.204 | clip 0 | loss_scale 32 | train_wall 996 | gb_free 17.3 | wall 23502
2023-08-05 18:48:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 18:48:38 | INFO | fairseq.trainer | begin training epoch 20
2023-08-05 18:48:38 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 18:48:51 | INFO | train_inner | epoch 020:      7 / 1474 loss=0.768, trans_loss=5.065, nll_loss=2.28, w2v_ctc_loss=0.255, task_loss=1.41, contrastive_loss=0.146, total=4119.08, n_correct=2634.88, ppl=4.86, accuracy=63.968, wps=6754.4, ups=0.82, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=23515
2023-08-05 18:48:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 18:49:13 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 1.465 | trans_loss 5.558 | nll_loss 2.831 | w2v_ctc_loss 0.461 | task_loss 4.648 | contrastive_loss 0.232 | total 4003.4 | n_correct 2479.3 | ppl 7.12 | accuracy 61.93 | uer 17.349 | wer 19.116 | raw_wer 19.116 | bleu 20.02 | wps 2284.1 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.02
2023-08-05 18:49:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-05 18:49:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_20_28000.pt
2023-08-05 18:49:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_20_28000.pt
2023-08-05 18:49:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.02) (writing took 23.871842086315155 seconds)
2023-08-05 18:50:46 | INFO | train_inner | epoch 020:    107 / 1474 loss=0.753, trans_loss=5.029, nll_loss=2.232, w2v_ctc_loss=0.249, task_loss=1.349, contrastive_loss=0.065, total=4195.03, n_correct=2710.22, ppl=4.7, accuracy=64.605, wps=7276, ups=0.87, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=67, gb_free=14.9, wall=23630
2023-08-05 18:51:54 | INFO | train_inner | epoch 020:    207 / 1474 loss=0.759, trans_loss=5.036, nll_loss=2.24, w2v_ctc_loss=0.252, task_loss=1.447, contrastive_loss=0.119, total=4154.14, n_correct=2676.63, ppl=4.72, accuracy=64.433, wps=12237.8, ups=1.47, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=23698
2023-08-05 18:53:02 | INFO | train_inner | epoch 020:    307 / 1474 loss=0.757, trans_loss=5.03, nll_loss=2.234, w2v_ctc_loss=0.253, task_loss=1.26, contrastive_loss=0.057, total=4188.05, n_correct=2706.24, ppl=4.7, accuracy=64.618, wps=12293.1, ups=1.47, wpb=8376.1, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.201, clip=0, loss_scale=32, train_wall=68, gb_free=15.5, wall=23766
2023-08-05 18:53:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 18:54:11 | INFO | train_inner | epoch 020:    408 / 1474 loss=0.761, trans_loss=5.038, nll_loss=2.243, w2v_ctc_loss=0.251, task_loss=1.432, contrastive_loss=0.048, total=4106.86, n_correct=2644.87, ppl=4.73, accuracy=64.401, wps=11915.2, ups=1.45, wpb=8213.7, bsz=293.8, num_updates=28400, lr=8.39181e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=68, gb_free=15.2, wall=23835
2023-08-05 18:55:19 | INFO | train_inner | epoch 020:    508 / 1474 loss=0.766, trans_loss=5.052, nll_loss=2.262, w2v_ctc_loss=0.252, task_loss=1.436, contrastive_loss=0.143, total=4108.2, n_correct=2635.75, ppl=4.8, accuracy=64.158, wps=12084.4, ups=1.47, wpb=8216.4, bsz=299.5, num_updates=28500, lr=8.37708e-05, gnorm=0.202, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=23903
2023-08-05 18:56:26 | INFO | train_inner | epoch 020:    608 / 1474 loss=0.764, trans_loss=5.053, nll_loss=2.263, w2v_ctc_loss=0.253, task_loss=1.469, contrastive_loss=0.143, total=4092.44, n_correct=2621.02, ppl=4.8, accuracy=64.045, wps=12155.7, ups=1.49, wpb=8184.9, bsz=295.9, num_updates=28600, lr=8.36242e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=67, gb_free=17.5, wall=23971
2023-08-05 18:57:34 | INFO | train_inner | epoch 020:    708 / 1474 loss=0.76, trans_loss=5.054, nll_loss=2.264, w2v_ctc_loss=0.255, task_loss=1.401, contrastive_loss=0.049, total=4137.06, n_correct=2653.59, ppl=4.8, accuracy=64.142, wps=12215.2, ups=1.48, wpb=8274.1, bsz=300.5, num_updates=28700, lr=8.34784e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=67, gb_free=16.5, wall=24038
2023-08-05 18:58:42 | INFO | train_inner | epoch 020:    808 / 1474 loss=0.758, trans_loss=5.051, nll_loss=2.261, w2v_ctc_loss=0.255, task_loss=1.38, contrastive_loss=0.053, total=4146.78, n_correct=2663.24, ppl=4.79, accuracy=64.224, wps=12168.6, ups=1.47, wpb=8293.6, bsz=307.3, num_updates=28800, lr=8.33333e-05, gnorm=0.207, clip=0, loss_scale=16, train_wall=68, gb_free=15.1, wall=24106
2023-08-05 18:59:51 | INFO | train_inner | epoch 020:    908 / 1474 loss=0.776, trans_loss=5.059, nll_loss=2.273, w2v_ctc_loss=0.254, task_loss=1.331, contrastive_loss=0.341, total=4161, n_correct=2662.07, ppl=4.83, accuracy=63.977, wps=12124.9, ups=1.46, wpb=8322, bsz=323.2, num_updates=28900, lr=8.3189e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=24175
2023-08-05 19:00:59 | INFO | train_inner | epoch 020:   1008 / 1474 loss=0.763, trans_loss=5.055, nll_loss=2.267, w2v_ctc_loss=0.253, task_loss=1.393, contrastive_loss=0.057, total=4168.14, n_correct=2671.44, ppl=4.81, accuracy=64.092, wps=12249.8, ups=1.47, wpb=8336.3, bsz=307.3, num_updates=29000, lr=8.30455e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=24243
2023-08-05 19:02:07 | INFO | train_inner | epoch 020:   1108 / 1474 loss=0.765, trans_loss=5.06, nll_loss=2.274, w2v_ctc_loss=0.252, task_loss=1.348, contrastive_loss=0.193, total=4166.49, n_correct=2669.95, ppl=4.84, accuracy=64.082, wps=12225.7, ups=1.47, wpb=8333, bsz=315.4, num_updates=29100, lr=8.29027e-05, gnorm=0.207, clip=0, loss_scale=16, train_wall=68, gb_free=14.7, wall=24311
2023-08-05 19:03:15 | INFO | train_inner | epoch 020:   1208 / 1474 loss=0.76, trans_loss=5.056, nll_loss=2.267, w2v_ctc_loss=0.258, task_loss=1.544, contrastive_loss=0.047, total=4029.18, n_correct=2580.82, ppl=4.81, accuracy=64.053, wps=11846.9, ups=1.47, wpb=8058.4, bsz=284, num_updates=29200, lr=8.27606e-05, gnorm=0.202, clip=0, loss_scale=16, train_wall=68, gb_free=11.6, wall=24379
2023-08-05 19:04:24 | INFO | train_inner | epoch 020:   1308 / 1474 loss=0.761, trans_loss=5.064, nll_loss=2.278, w2v_ctc_loss=0.254, task_loss=1.469, contrastive_loss=0.052, total=4123.21, n_correct=2641.52, ppl=4.85, accuracy=64.065, wps=11999.5, ups=1.46, wpb=8246.4, bsz=297.1, num_updates=29300, lr=8.26192e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=24448
2023-08-05 19:05:31 | INFO | train_inner | epoch 020:   1408 / 1474 loss=0.764, trans_loss=5.06, nll_loss=2.274, w2v_ctc_loss=0.255, task_loss=1.474, contrastive_loss=0.05, total=4116.28, n_correct=2631.95, ppl=4.84, accuracy=63.94, wps=12188.7, ups=1.48, wpb=8232.6, bsz=295, num_updates=29400, lr=8.24786e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=67, gb_free=17.5, wall=24516
2023-08-05 19:06:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 19:06:40 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 1.469 | trans_loss 5.552 | nll_loss 2.823 | w2v_ctc_loss 0.455 | task_loss 4.618 | contrastive_loss 0.238 | total 4003.4 | n_correct 2480.5 | ppl 7.08 | accuracy 61.96 | uer 17.251 | wer 19.205 | raw_wer 19.205 | bleu 20.06 | wps 2147.6 | wpb 4003.4 | bsz 141.8 | num_updates 29466 | best_bleu 20.06
2023-08-05 19:06:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29466 updates
2023-08-05 19:06:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 19:06:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 19:07:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 20 @ 29466 updates, score 20.06) (writing took 24.323798028752208 seconds)
2023-08-05 19:07:05 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-05 19:07:05 | INFO | train | epoch 020 | loss 0.762 | trans_loss 5.05 | nll_loss 2.26 | w2v_ctc_loss 0.253 | task_loss 1.399 | contrastive_loss 0.102 | total 4138.13 | n_correct 2656.68 | ppl 4.79 | accuracy 64.2 | wps 11015.8 | ups 1.33 | wpb 8276.3 | bsz 305.5 | num_updates 29466 | lr 8.23862e-05 | gnorm 0.203 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 16.1 | wall 24609
2023-08-05 19:07:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 19:07:05 | INFO | fairseq.trainer | begin training epoch 21
2023-08-05 19:07:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 19:07:35 | INFO | train_inner | epoch 021:     34 / 1474 loss=0.764, trans_loss=5.053, nll_loss=2.265, w2v_ctc_loss=0.252, task_loss=1.332, contrastive_loss=0.167, total=4152.26, n_correct=2663.8, ppl=4.81, accuracy=64.153, wps=6687.5, ups=0.81, wpb=8304.5, bsz=316.3, num_updates=29500, lr=8.23387e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=24640
2023-08-05 19:08:43 | INFO | train_inner | epoch 021:    134 / 1474 loss=0.76, trans_loss=5.021, nll_loss=2.222, w2v_ctc_loss=0.25, task_loss=1.307, contrastive_loss=0.162, total=4195.08, n_correct=2716.37, ppl=4.67, accuracy=64.751, wps=12357.6, ups=1.47, wpb=8390.2, bsz=319.6, num_updates=29600, lr=8.21995e-05, gnorm=0.21, clip=0, loss_scale=16, train_wall=67, gb_free=17, wall=24708
2023-08-05 19:09:51 | INFO | train_inner | epoch 021:    234 / 1474 loss=0.751, trans_loss=5.026, nll_loss=2.228, w2v_ctc_loss=0.243, task_loss=1.334, contrastive_loss=0.115, total=4155.31, n_correct=2692.33, ppl=4.68, accuracy=64.793, wps=12334.1, ups=1.48, wpb=8310.6, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.198, clip=0, loss_scale=16, train_wall=67, gb_free=16.7, wall=24775
2023-08-05 19:10:59 | INFO | train_inner | epoch 021:    334 / 1474 loss=0.756, trans_loss=5.028, nll_loss=2.231, w2v_ctc_loss=0.25, task_loss=1.389, contrastive_loss=0.119, total=4151.51, n_correct=2683.14, ppl=4.69, accuracy=64.63, wps=12136.6, ups=1.46, wpb=8303, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.2, clip=0, loss_scale=16, train_wall=68, gb_free=15.5, wall=24843
2023-08-05 19:12:07 | INFO | train_inner | epoch 021:    434 / 1474 loss=0.756, trans_loss=5.028, nll_loss=2.231, w2v_ctc_loss=0.248, task_loss=1.357, contrastive_loss=0.045, total=4180.85, n_correct=2705.69, ppl=4.69, accuracy=64.716, wps=12363.7, ups=1.48, wpb=8361.7, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=67, gb_free=15.7, wall=24911
2023-08-05 19:13:15 | INFO | train_inner | epoch 021:    534 / 1474 loss=0.753, trans_loss=5.029, nll_loss=2.231, w2v_ctc_loss=0.25, task_loss=1.454, contrastive_loss=0.045, total=4083.98, n_correct=2642.97, ppl=4.7, accuracy=64.716, wps=12004, ups=1.47, wpb=8168, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=68, gb_free=12.9, wall=24979
2023-08-05 19:13:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 19:13:38 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 1.471 | trans_loss 5.559 | nll_loss 2.832 | w2v_ctc_loss 0.448 | task_loss 4.609 | contrastive_loss 0.233 | total 4003.4 | n_correct 2484.9 | ppl 7.12 | accuracy 62.07 | uer 17.137 | wer 18.892 | raw_wer 18.892 | bleu 20.02 | wps 2210.7 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.06
2023-08-05 19:13:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-05 19:13:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_21_30000.pt
2023-08-05 19:13:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_21_30000.pt
2023-08-05 19:14:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 20.02) (writing took 32.311900025233626 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:0')
2023-08-05 19:15:19 | INFO | train_inner | epoch 021:    634 / 1474 loss=0.761, trans_loss=5.034, nll_loss=2.239, w2v_ctc_loss=0.247, task_loss=1.384, contrastive_loss=0.215, total=4215.41, n_correct=2719.79, ppl=4.72, accuracy=64.52, wps=6792.3, ups=0.81, wpb=8430.8, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=67, gb_free=11.2, wall=25103
2023-08-05 19:16:27 | INFO | train_inner | epoch 021:    734 / 1474 loss=0.758, trans_loss=5.044, nll_loss=2.253, w2v_ctc_loss=0.25, task_loss=1.39, contrastive_loss=0.076, total=4152.97, n_correct=2675.1, ppl=4.77, accuracy=64.414, wps=12151.2, ups=1.46, wpb=8305.9, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=25172
2023-08-05 19:17:36 | INFO | train_inner | epoch 021:    834 / 1474 loss=0.762, trans_loss=5.05, nll_loss=2.259, w2v_ctc_loss=0.251, task_loss=1.478, contrastive_loss=0.087, total=4066.93, n_correct=2613.32, ppl=4.79, accuracy=64.258, wps=11889.4, ups=1.46, wpb=8133.9, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=25240
2023-08-05 19:18:43 | INFO | train_inner | epoch 021:    934 / 1474 loss=0.758, trans_loss=5.04, nll_loss=2.247, w2v_ctc_loss=0.251, task_loss=1.402, contrastive_loss=0.061, total=4103.34, n_correct=2642.6, ppl=4.75, accuracy=64.401, wps=12144.3, ups=1.48, wpb=8206.7, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.207, clip=0, loss_scale=16, train_wall=67, gb_free=13.9, wall=25308
2023-08-05 19:19:51 | INFO | train_inner | epoch 021:   1034 / 1474 loss=0.758, trans_loss=5.054, nll_loss=2.266, w2v_ctc_loss=0.251, task_loss=1.427, contrastive_loss=0.059, total=4099.86, n_correct=2632.63, ppl=4.81, accuracy=64.213, wps=12105.7, ups=1.48, wpb=8199.7, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=67, gb_free=11.2, wall=25375
2023-08-05 19:20:59 | INFO | train_inner | epoch 021:   1134 / 1474 loss=0.763, trans_loss=5.045, nll_loss=2.253, w2v_ctc_loss=0.253, task_loss=1.502, contrastive_loss=0.062, total=4120.75, n_correct=2652.8, ppl=4.77, accuracy=64.377, wps=12095.2, ups=1.47, wpb=8241.5, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.201, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=25444
2023-08-05 19:22:06 | INFO | train_inner | epoch 021:   1234 / 1474 loss=0.759, trans_loss=5.045, nll_loss=2.255, w2v_ctc_loss=0.249, task_loss=1.327, contrastive_loss=0.112, total=4154.73, n_correct=2671.71, ppl=4.77, accuracy=64.305, wps=12368.6, ups=1.49, wpb=8309.5, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.205, clip=0, loss_scale=32, train_wall=67, gb_free=12.5, wall=25511
2023-08-05 19:22:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 19:23:15 | INFO | train_inner | epoch 021:   1335 / 1474 loss=0.756, trans_loss=5.048, nll_loss=2.259, w2v_ctc_loss=0.25, task_loss=1.356, contrastive_loss=0.073, total=4147.08, n_correct=2672.3, ppl=4.79, accuracy=64.438, wps=12089.7, ups=1.46, wpb=8294.2, bsz=312.1, num_updates=30800, lr=8.05823e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=25579
2023-08-05 19:24:23 | INFO | train_inner | epoch 021:   1435 / 1474 loss=0.764, trans_loss=5.057, nll_loss=2.27, w2v_ctc_loss=0.256, task_loss=1.462, contrastive_loss=0.122, total=4136.27, n_correct=2646.25, ppl=4.82, accuracy=63.977, wps=12116.5, ups=1.46, wpb=8272.5, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=25648
2023-08-05 19:24:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:2')
2023-08-05 19:25:15 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 1.476 | trans_loss 5.57 | nll_loss 2.848 | w2v_ctc_loss 0.463 | task_loss 4.613 | contrastive_loss 0.242 | total 4003.4 | n_correct 2476.5 | ppl 7.2 | accuracy 61.86 | uer 17.62 | wer 19.47 | raw_wer 19.47 | bleu 19.63 | wps 1941.1 | wpb 4003.4 | bsz 141.8 | num_updates 30939 | best_bleu 20.06
2023-08-05 19:25:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30939 updates
2023-08-05 19:25:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.6307.pt
2023-08-05 19:25:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.6307.pt
2023-08-05 19:25:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.6307.pt (epoch 21 @ 30939 updates, score 19.63) (writing took 32.168160853907466 seconds)
2023-08-05 19:25:48 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-05 19:25:48 | INFO | train | epoch 021 | loss 0.758 | trans_loss 5.039 | nll_loss 2.246 | w2v_ctc_loss 0.25 | task_loss 1.399 | contrastive_loss 0.101 | total 4138.83 | n_correct 2667.86 | ppl 4.74 | accuracy 64.459 | wps 10856.2 | ups 1.31 | wpb 8277.7 | bsz 305.7 | num_updates 30939 | lr 8.04011e-05 | gnorm 0.204 | clip 0 | loss_scale 16 | train_wall 995 | gb_free 15.4 | wall 25732
2023-08-05 19:25:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 19:25:48 | INFO | fairseq.trainer | begin training epoch 22
2023-08-05 19:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 19:26:37 | INFO | train_inner | epoch 022:     61 / 1474 loss=0.753, trans_loss=5.024, nll_loss=2.227, w2v_ctc_loss=0.249, task_loss=1.406, contrastive_loss=0.045, total=4133.81, n_correct=2679.82, ppl=4.68, accuracy=64.827, wps=6186.3, ups=0.75, wpb=8267.6, bsz=300.5, num_updates=31000, lr=8.03219e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=25781
2023-08-05 19:27:45 | INFO | train_inner | epoch 022:    161 / 1474 loss=0.755, trans_loss=5.016, nll_loss=2.215, w2v_ctc_loss=0.248, task_loss=1.432, contrastive_loss=0.123, total=4116.11, n_correct=2669.22, ppl=4.64, accuracy=64.848, wps=12066.1, ups=1.47, wpb=8232.2, bsz=306.9, num_updates=31100, lr=8.01927e-05, gnorm=0.2, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=25849
2023-08-05 19:28:53 | INFO | train_inner | epoch 022:    261 / 1474 loss=0.75, trans_loss=5.008, nll_loss=2.206, w2v_ctc_loss=0.243, task_loss=1.222, contrastive_loss=0.066, total=4272.11, n_correct=2786.48, ppl=4.61, accuracy=65.225, wps=12554.2, ups=1.47, wpb=8544.2, bsz=331.4, num_updates=31200, lr=8.00641e-05, gnorm=0.198, clip=0, loss_scale=16, train_wall=68, gb_free=17.8, wall=25918
2023-08-05 19:30:02 | INFO | train_inner | epoch 022:    361 / 1474 loss=0.764, trans_loss=5.026, nll_loss=2.229, w2v_ctc_loss=0.248, task_loss=1.417, contrastive_loss=0.221, total=4178.4, n_correct=2703.72, ppl=4.69, accuracy=64.707, wps=12088.2, ups=1.45, wpb=8356.8, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=25987
2023-08-05 19:31:11 | INFO | train_inner | epoch 022:    461 / 1474 loss=0.759, trans_loss=5.03, nll_loss=2.232, w2v_ctc_loss=0.249, task_loss=1.469, contrastive_loss=0.105, total=4132.96, n_correct=2674.09, ppl=4.7, accuracy=64.702, wps=12124.4, ups=1.47, wpb=8265.9, bsz=297.5, num_updates=31400, lr=7.98087e-05, gnorm=0.208, clip=0, loss_scale=16, train_wall=68, gb_free=16.9, wall=26055
2023-08-05 19:32:19 | INFO | train_inner | epoch 022:    561 / 1474 loss=0.755, trans_loss=5.022, nll_loss=2.224, w2v_ctc_loss=0.248, task_loss=1.399, contrastive_loss=0.054, total=4158.17, n_correct=2696.91, ppl=4.67, accuracy=64.858, wps=12129.7, ups=1.46, wpb=8316.3, bsz=307.8, num_updates=31500, lr=7.96819e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=26123
2023-08-05 19:33:27 | INFO | train_inner | epoch 022:    661 / 1474 loss=0.753, trans_loss=5.019, nll_loss=2.221, w2v_ctc_loss=0.243, task_loss=1.336, contrastive_loss=0.138, total=4139.66, n_correct=2691.63, ppl=4.66, accuracy=65.021, wps=12264.4, ups=1.48, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=67, gb_free=16.1, wall=26191
2023-08-05 19:34:35 | INFO | train_inner | epoch 022:    761 / 1474 loss=0.753, trans_loss=5.024, nll_loss=2.227, w2v_ctc_loss=0.249, task_loss=1.44, contrastive_loss=0.056, total=4167.89, n_correct=2699.84, ppl=4.68, accuracy=64.777, wps=12203.6, ups=1.46, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.202, clip=0, loss_scale=16, train_wall=68, gb_free=12.7, wall=26259
2023-08-05 19:35:43 | INFO | train_inner | epoch 022:    861 / 1474 loss=0.756, trans_loss=5.036, nll_loss=2.242, w2v_ctc_loss=0.25, task_loss=1.515, contrastive_loss=0.044, total=4075.79, n_correct=2629.89, ppl=4.73, accuracy=64.525, wps=11891.6, ups=1.46, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=26328
2023-08-05 19:36:52 | INFO | train_inner | epoch 022:    961 / 1474 loss=0.754, trans_loss=5.031, nll_loss=2.236, w2v_ctc_loss=0.246, task_loss=1.407, contrastive_loss=0.045, total=4134.72, n_correct=2680.29, ppl=4.71, accuracy=64.824, wps=12140.2, ups=1.47, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.208, clip=0, loss_scale=16, train_wall=68, gb_free=14.1, wall=26396
2023-08-05 19:37:59 | INFO | train_inner | epoch 022:   1061 / 1474 loss=0.761, trans_loss=5.029, nll_loss=2.234, w2v_ctc_loss=0.246, task_loss=1.333, contrastive_loss=0.213, total=4160.57, n_correct=2691.64, ppl=4.7, accuracy=64.694, wps=12313.2, ups=1.48, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=67, gb_free=17.2, wall=26463
2023-08-05 19:37:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 19:38:24 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 1.47 | trans_loss 5.56 | nll_loss 2.835 | w2v_ctc_loss 0.459 | task_loss 4.61 | contrastive_loss 0.233 | total 4003.4 | n_correct 2484.2 | ppl 7.14 | accuracy 62.052 | uer 17.453 | wer 19.254 | raw_wer 19.254 | bleu 19.68 | wps 1992.4 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.06
2023-08-05 19:38:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-05 19:38:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_22_32000.pt
2023-08-05 19:38:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_22_32000.pt
2023-08-05 19:38:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.68) (writing took 19.86509494110942 seconds)
2023-08-05 19:39:52 | INFO | train_inner | epoch 022:   1161 / 1474 loss=0.758, trans_loss=5.052, nll_loss=2.264, w2v_ctc_loss=0.252, task_loss=1.444, contrastive_loss=0.095, total=4099.59, n_correct=2634.39, ppl=4.8, accuracy=64.26, wps=7256.3, ups=0.89, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=67, gb_free=14.9, wall=26576
2023-08-05 19:41:00 | INFO | train_inner | epoch 022:   1261 / 1474 loss=0.756, trans_loss=5.043, nll_loss=2.253, w2v_ctc_loss=0.248, task_loss=1.296, contrastive_loss=0.088, total=4182.05, n_correct=2693.6, ppl=4.77, accuracy=64.409, wps=12317.9, ups=1.47, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.215, clip=0, loss_scale=16, train_wall=67, gb_free=15.5, wall=26644
2023-08-05 19:42:08 | INFO | train_inner | epoch 022:   1361 / 1474 loss=0.75, trans_loss=5.034, nll_loss=2.24, w2v_ctc_loss=0.243, task_loss=1.403, contrastive_loss=0.113, total=4062.31, n_correct=2624.79, ppl=4.72, accuracy=64.613, wps=12001.7, ups=1.48, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.2, clip=0, loss_scale=16, train_wall=67, gb_free=15, wall=26712
2023-08-05 19:43:16 | INFO | train_inner | epoch 022:   1461 / 1474 loss=0.758, trans_loss=5.054, nll_loss=2.265, w2v_ctc_loss=0.252, task_loss=1.498, contrastive_loss=0.059, total=4081.88, n_correct=2622.62, ppl=4.81, accuracy=64.25, wps=12041.6, ups=1.48, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=67, gb_free=17.2, wall=26780
2023-08-05 19:43:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 19:43:48 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 1.47 | trans_loss 5.554 | nll_loss 2.828 | w2v_ctc_loss 0.456 | task_loss 4.613 | contrastive_loss 0.232 | total 4003.4 | n_correct 2485.6 | ppl 7.1 | accuracy 62.087 | uer 17.532 | wer 19.295 | raw_wer 19.295 | bleu 19.78 | wps 2102.9 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.06
2023-08-05 19:43:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-08-05 19:43:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.7800.pt
2023-08-05 19:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.7800.pt
2023-08-05 19:44:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_19.7800.pt (epoch 22 @ 32413 updates, score 19.78) (writing took 13.338512880727649 seconds)
2023-08-05 19:44:02 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-05 19:44:02 | INFO | train | epoch 022 | loss 0.756 | trans_loss 5.029 | nll_loss 2.234 | w2v_ctc_loss 0.248 | task_loss 1.399 | contrastive_loss 0.099 | total 4138.65 | n_correct 2678.16 | ppl 4.7 | accuracy 64.711 | wps 11147.9 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.205 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 11.6 | wall 26826
2023-08-05 19:44:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 19:44:02 | INFO | fairseq.trainer | begin training epoch 23
2023-08-05 19:44:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 19:45:09 | INFO | train_inner | epoch 023:     87 / 1474 loss=0.747, trans_loss=5.006, nll_loss=2.202, w2v_ctc_loss=0.247, task_loss=1.431, contrastive_loss=0.05, total=4096.09, n_correct=2668.59, ppl=4.6, accuracy=65.15, wps=7232.7, ups=0.88, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=26893
2023-08-05 19:46:17 | INFO | train_inner | epoch 023:    187 / 1474 loss=0.751, trans_loss=5.003, nll_loss=2.199, w2v_ctc_loss=0.244, task_loss=1.491, contrastive_loss=0.048, total=4107.77, n_correct=2683.16, ppl=4.59, accuracy=65.319, wps=12054.5, ups=1.47, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=26961
2023-08-05 19:47:25 | INFO | train_inner | epoch 023:    287 / 1474 loss=0.753, trans_loss=5.012, nll_loss=2.211, w2v_ctc_loss=0.242, task_loss=1.401, contrastive_loss=0.125, total=4153.12, n_correct=2701.39, ppl=4.63, accuracy=65.045, wps=12181.7, ups=1.47, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.207, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=27029
2023-08-05 19:48:33 | INFO | train_inner | epoch 023:    387 / 1474 loss=0.748, trans_loss=5.013, nll_loss=2.211, w2v_ctc_loss=0.243, task_loss=1.455, contrastive_loss=0.042, total=4116.7, n_correct=2680.95, ppl=4.63, accuracy=65.124, wps=12165.7, ups=1.48, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.2, clip=0, loss_scale=16, train_wall=67, gb_free=15.2, wall=27097
2023-08-05 19:49:40 | INFO | train_inner | epoch 023:    487 / 1474 loss=0.75, trans_loss=5.016, nll_loss=2.216, w2v_ctc_loss=0.245, task_loss=1.358, contrastive_loss=0.098, total=4157.6, n_correct=2701.15, ppl=4.65, accuracy=64.969, wps=12318.1, ups=1.48, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.21, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=27165
2023-08-05 19:50:48 | INFO | train_inner | epoch 023:    587 / 1474 loss=0.747, trans_loss=5.005, nll_loss=2.202, w2v_ctc_loss=0.242, task_loss=1.323, contrastive_loss=0.046, total=4173.42, n_correct=2723.83, ppl=4.6, accuracy=65.266, wps=12293.8, ups=1.47, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=67, gb_free=12.5, wall=27233
2023-08-05 19:51:56 | INFO | train_inner | epoch 023:    687 / 1474 loss=0.753, trans_loss=5.014, nll_loss=2.214, w2v_ctc_loss=0.245, task_loss=1.399, contrastive_loss=0.084, total=4137.82, n_correct=2690.87, ppl=4.64, accuracy=65.031, wps=12214.5, ups=1.48, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.21, clip=0, loss_scale=32, train_wall=67, gb_free=17.1, wall=27300
2023-08-05 19:53:04 | INFO | train_inner | epoch 023:    787 / 1474 loss=0.753, trans_loss=5.024, nll_loss=2.227, w2v_ctc_loss=0.246, task_loss=1.41, contrastive_loss=0.063, total=4150.99, n_correct=2695.95, ppl=4.68, accuracy=64.947, wps=12263.9, ups=1.48, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=27368
2023-08-05 19:54:11 | INFO | train_inner | epoch 023:    887 / 1474 loss=0.751, trans_loss=5.017, nll_loss=2.219, w2v_ctc_loss=0.243, task_loss=1.277, contrastive_loss=0.142, total=4181.99, n_correct=2720.08, ppl=4.66, accuracy=65.043, wps=12369.5, ups=1.48, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=27436
2023-08-05 19:55:20 | INFO | train_inner | epoch 023:    987 / 1474 loss=0.761, trans_loss=5.022, nll_loss=2.224, w2v_ctc_loss=0.242, task_loss=1.395, contrastive_loss=0.302, total=4168.73, n_correct=2704.95, ppl=4.67, accuracy=64.887, wps=12228.5, ups=1.47, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=68, gb_free=10.7, wall=27504
2023-08-05 19:56:28 | INFO | train_inner | epoch 023:   1087 / 1474 loss=0.755, trans_loss=5.03, nll_loss=2.234, w2v_ctc_loss=0.25, task_loss=1.491, contrastive_loss=0.053, total=4088.49, n_correct=2644.26, ppl=4.71, accuracy=64.676, wps=11940.1, ups=1.46, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.205, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=27572
2023-08-05 19:57:37 | INFO | train_inner | epoch 023:   1187 / 1474 loss=0.752, trans_loss=5.027, nll_loss=2.232, w2v_ctc_loss=0.246, task_loss=1.388, contrastive_loss=0.046, total=4162.7, n_correct=2699.55, ppl=4.7, accuracy=64.851, wps=12143.3, ups=1.46, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=27641
2023-08-05 19:58:44 | INFO | train_inner | epoch 023:   1287 / 1474 loss=0.751, trans_loss=5.026, nll_loss=2.231, w2v_ctc_loss=0.243, task_loss=1.358, contrastive_loss=0.057, total=4135.53, n_correct=2686.43, ppl=4.69, accuracy=64.96, wps=12276.2, ups=1.48, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.201, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=27708
2023-08-05 19:59:52 | INFO | train_inner | epoch 023:   1387 / 1474 loss=0.758, trans_loss=5.046, nll_loss=2.256, w2v_ctc_loss=0.247, task_loss=1.413, contrastive_loss=0.112, total=4143.98, n_correct=2669.53, ppl=4.78, accuracy=64.419, wps=12169.2, ups=1.47, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.209, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=27776
2023-08-05 20:00:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 20:01:16 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 1.468 | trans_loss 5.555 | nll_loss 2.829 | w2v_ctc_loss 0.466 | task_loss 4.651 | contrastive_loss 0.234 | total 4003.4 | n_correct 2482.1 | ppl 7.11 | accuracy 62 | uer 17.294 | wer 19.026 | raw_wer 19.026 | bleu 20.05 | wps 2004.2 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.06
2023-08-05 20:01:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-08-05 20:01:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.0509.pt
2023-08-05 20:01:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.0509.pt
2023-08-05 20:01:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.0509.pt (epoch 23 @ 33887 updates, score 20.05) (writing took 34.83236329071224 seconds)
2023-08-05 20:01:54 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-05 20:01:54 | INFO | train | epoch 023 | loss 0.753 | trans_loss 5.02 | nll_loss 2.222 | w2v_ctc_loss 0.245 | task_loss 1.399 | contrastive_loss 0.098 | total 4138.65 | n_correct 2688.24 | ppl 4.66 | accuracy 64.955 | wps 11382.4 | ups 1.38 | wpb 8277.3 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.205 | clip 0 | loss_scale 32 | train_wall 994 | gb_free 13.6 | wall 27898
2023-08-05 20:01:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 20:01:54 | INFO | fairseq.trainer | begin training epoch 24
2023-08-05 20:01:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 20:02:11 | INFO | train_inner | epoch 024:     13 / 1474 loss=0.76, trans_loss=5.036, nll_loss=2.245, w2v_ctc_loss=0.244, task_loss=1.406, contrastive_loss=0.189, total=4085.11, n_correct=2639.91, ppl=4.74, accuracy=64.623, wps=5877.4, ups=0.72, wpb=8170.2, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.208, clip=0, loss_scale=32, train_wall=68, gb_free=12.5, wall=27915
2023-08-05 20:03:19 | INFO | train_inner | epoch 024:    113 / 1474 loss=0.748, trans_loss=4.99, nll_loss=2.183, w2v_ctc_loss=0.239, task_loss=1.294, contrastive_loss=0.208, total=4171.44, n_correct=2732.77, ppl=4.54, accuracy=65.511, wps=12311.4, ups=1.48, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=27983
2023-08-05 20:03:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 20:03:43 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 1.469 | trans_loss 5.565 | nll_loss 2.835 | w2v_ctc_loss 0.446 | task_loss 4.614 | contrastive_loss 0.227 | total 4003.4 | n_correct 2475.9 | ppl 7.14 | accuracy 61.845 | uer 16.994 | wer 18.937 | raw_wer 18.937 | bleu 19.8 | wps 2055.2 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.06
2023-08-05 20:03:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-05 20:03:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_24_34000.pt
2023-08-05 20:03:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_24_34000.pt
2023-08-05 20:04:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.8) (writing took 25.014331409707665 seconds)
2023-08-05 20:05:19 | INFO | train_inner | epoch 024:    213 / 1474 loss=0.752, trans_loss=4.995, nll_loss=2.19, w2v_ctc_loss=0.235, task_loss=1.224, contrastive_loss=0.258, total=4251.29, n_correct=2783.4, ppl=4.56, accuracy=65.472, wps=7065.6, ups=0.83, wpb=8502.6, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=28104
2023-08-05 20:06:27 | INFO | train_inner | epoch 024:    313 / 1474 loss=0.747, trans_loss=4.998, nll_loss=2.193, w2v_ctc_loss=0.242, task_loss=1.371, contrastive_loss=0.042, total=4128.18, n_correct=2698.85, ppl=4.57, accuracy=65.376, wps=12180.5, ups=1.48, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.207, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=28171
2023-08-05 20:07:36 | INFO | train_inner | epoch 024:    413 / 1474 loss=0.76, trans_loss=5.009, nll_loss=2.207, w2v_ctc_loss=0.247, task_loss=1.465, contrastive_loss=0.184, total=4158.92, n_correct=2704.51, ppl=4.62, accuracy=65.029, wps=12079.1, ups=1.45, wpb=8317.8, bsz=299.7, num_updates=34300, lr=7.63604e-05, gnorm=0.209, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=28240
2023-08-05 20:08:44 | INFO | train_inner | epoch 024:    513 / 1474 loss=0.745, trans_loss=5.004, nll_loss=2.2, w2v_ctc_loss=0.241, task_loss=1.422, contrastive_loss=0.112, total=4144.91, n_correct=2705.42, ppl=4.59, accuracy=65.271, wps=12122, ups=1.46, wpb=8289.8, bsz=303.3, num_updates=34400, lr=7.62493e-05, gnorm=0.198, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=28309
2023-08-05 20:09:52 | INFO | train_inner | epoch 024:    613 / 1474 loss=0.748, trans_loss=5.002, nll_loss=2.199, w2v_ctc_loss=0.24, task_loss=1.407, contrastive_loss=0.073, total=4165.3, n_correct=2718.75, ppl=4.59, accuracy=65.271, wps=12245.2, ups=1.47, wpb=8330.6, bsz=307.7, num_updates=34500, lr=7.61387e-05, gnorm=0.204, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=28377
2023-08-05 20:11:00 | INFO | train_inner | epoch 024:    713 / 1474 loss=0.751, trans_loss=5.018, nll_loss=2.218, w2v_ctc_loss=0.243, task_loss=1.44, contrastive_loss=0.087, total=4102.21, n_correct=2671.05, ppl=4.65, accuracy=65.112, wps=12115.3, ups=1.48, wpb=8204.4, bsz=295.1, num_updates=34600, lr=7.60286e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=28444
2023-08-05 20:12:08 | INFO | train_inner | epoch 024:    813 / 1474 loss=0.75, trans_loss=5.015, nll_loss=2.217, w2v_ctc_loss=0.242, task_loss=1.412, contrastive_loss=0.062, total=4110.6, n_correct=2673, ppl=4.65, accuracy=65.027, wps=12008, ups=1.46, wpb=8221.2, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=28513
2023-08-05 20:13:16 | INFO | train_inner | epoch 024:    913 / 1474 loss=0.75, trans_loss=5.026, nll_loss=2.228, w2v_ctc_loss=0.245, task_loss=1.554, contrastive_loss=0.04, total=4043.03, n_correct=2618.49, ppl=4.68, accuracy=64.766, wps=11995, ups=1.48, wpb=8086.1, bsz=281, num_updates=34800, lr=7.58098e-05, gnorm=0.204, clip=0, loss_scale=32, train_wall=67, gb_free=11.1, wall=28580
2023-08-05 20:14:24 | INFO | train_inner | epoch 024:   1013 / 1474 loss=0.748, trans_loss=5.02, nll_loss=2.221, w2v_ctc_loss=0.242, task_loss=1.446, contrastive_loss=0.043, total=4136.81, n_correct=2690.19, ppl=4.66, accuracy=65.031, wps=12151.5, ups=1.47, wpb=8273.6, bsz=298.4, num_updates=34900, lr=7.57011e-05, gnorm=0.2, clip=0, loss_scale=64, train_wall=68, gb_free=16.8, wall=28648
2023-08-05 20:15:32 | INFO | train_inner | epoch 024:   1113 / 1474 loss=0.754, trans_loss=5.008, nll_loss=2.206, w2v_ctc_loss=0.245, task_loss=1.347, contrastive_loss=0.084, total=4135.73, n_correct=2696.67, ppl=4.61, accuracy=65.204, wps=12234.7, ups=1.48, wpb=8271.5, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.205, clip=0, loss_scale=64, train_wall=67, gb_free=17, wall=28716
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:0')
2023-08-05 20:16:40 | INFO | train_inner | epoch 024:   1213 / 1474 loss=0.752, trans_loss=5.018, nll_loss=2.221, w2v_ctc_loss=0.243, task_loss=1.386, contrastive_loss=0.072, total=4148.3, n_correct=2700.58, ppl=4.66, accuracy=65.101, wps=12195.8, ups=1.47, wpb=8296.6, bsz=310.8, num_updates=35100, lr=7.54851e-05, gnorm=0.207, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=28784
2023-08-05 20:17:48 | INFO | train_inner | epoch 024:   1313 / 1474 loss=0.753, trans_loss=5.028, nll_loss=2.232, w2v_ctc_loss=0.248, task_loss=1.487, contrastive_loss=0.047, total=4110.05, n_correct=2664.43, ppl=4.7, accuracy=64.827, wps=12089.9, ups=1.47, wpb=8220.1, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.206, clip=0, loss_scale=64, train_wall=67, gb_free=17.2, wall=28852
2023-08-05 20:18:55 | INFO | train_inner | epoch 024:   1413 / 1474 loss=0.753, trans_loss=5.027, nll_loss=2.232, w2v_ctc_loss=0.248, task_loss=1.462, contrastive_loss=0.046, total=4090.91, n_correct=2649.87, ppl=4.7, accuracy=64.775, wps=12104.8, ups=1.48, wpb=8181.8, bsz=292.7, num_updates=35300, lr=7.5271e-05, gnorm=0.201, clip=0, loss_scale=64, train_wall=67, gb_free=16, wall=28920
2023-08-05 20:19:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:2')
2023-08-05 20:20:02 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 1.465 | trans_loss 5.55 | nll_loss 2.821 | w2v_ctc_loss 0.446 | task_loss 4.627 | contrastive_loss 0.235 | total 4003.4 | n_correct 2489.2 | ppl 7.06 | accuracy 62.177 | uer 16.861 | wer 18.847 | raw_wer 18.847 | bleu 20.25 | wps 1903.3 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.25
2023-08-05 20:20:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-08-05 20:20:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 20:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 20:20:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 24 @ 35361 updates, score 20.25) (writing took 24.194805800914764 seconds)
2023-08-05 20:20:27 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-05 20:20:27 | INFO | train | epoch 024 | loss 0.75 | trans_loss 5.011 | nll_loss 2.211 | w2v_ctc_loss 0.243 | task_loss 1.399 | contrastive_loss 0.097 | total 4138.65 | n_correct 2695.64 | ppl 4.63 | accuracy 65.133 | wps 10963.8 | ups 1.32 | wpb 8277.3 | bsz 305.7 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.203 | clip 0 | loss_scale 64 | train_wall 995 | gb_free 16.1 | wall 29011
2023-08-05 20:20:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 20:20:27 | INFO | fairseq.trainer | begin training epoch 25
2023-08-05 20:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 20:21:00 | INFO | train_inner | epoch 025:     39 / 1474 loss=0.745, trans_loss=5.002, nll_loss=2.199, w2v_ctc_loss=0.24, task_loss=1.34, contrastive_loss=0.052, total=4166.95, n_correct=2725.95, ppl=4.59, accuracy=65.418, wps=6652.6, ups=0.8, wpb=8333.9, bsz=312, num_updates=35400, lr=7.51646e-05, gnorm=0.199, clip=0, loss_scale=64, train_wall=67, gb_free=16.4, wall=29045
2023-08-05 20:22:08 | INFO | train_inner | epoch 025:    139 / 1474 loss=0.742, trans_loss=4.983, nll_loss=2.174, w2v_ctc_loss=0.238, task_loss=1.368, contrastive_loss=0.051, total=4133.64, n_correct=2719.24, ppl=4.51, accuracy=65.783, wps=12231, ups=1.48, wpb=8267.3, bsz=307.7, num_updates=35500, lr=7.50587e-05, gnorm=0.197, clip=0, loss_scale=64, train_wall=67, gb_free=15.8, wall=29112
2023-08-05 20:23:16 | INFO | train_inner | epoch 025:    239 / 1474 loss=0.743, trans_loss=4.987, nll_loss=2.179, w2v_ctc_loss=0.239, task_loss=1.437, contrastive_loss=0.054, total=4114.53, n_correct=2701.9, ppl=4.53, accuracy=65.667, wps=12064.8, ups=1.47, wpb=8229.1, bsz=302.7, num_updates=35600, lr=7.49532e-05, gnorm=0.2, clip=0, loss_scale=64, train_wall=68, gb_free=17, wall=29181
2023-08-05 20:24:25 | INFO | train_inner | epoch 025:    339 / 1474 loss=0.747, trans_loss=4.994, nll_loss=2.186, w2v_ctc_loss=0.239, task_loss=1.489, contrastive_loss=0.084, total=4148.7, n_correct=2709.68, ppl=4.55, accuracy=65.314, wps=12139.6, ups=1.46, wpb=8297.4, bsz=295.1, num_updates=35700, lr=7.48481e-05, gnorm=0.201, clip=0, loss_scale=64, train_wall=68, gb_free=16.3, wall=29249
2023-08-05 20:24:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-05 20:25:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 20:25:35 | INFO | train_inner | epoch 025:    441 / 1474 loss=0.751, trans_loss=4.998, nll_loss=2.192, w2v_ctc_loss=0.248, task_loss=1.495, contrastive_loss=0.044, total=4144.19, n_correct=2709.42, ppl=4.57, accuracy=65.379, wps=11841.8, ups=1.43, wpb=8288.4, bsz=290.3, num_updates=35800, lr=7.47435e-05, gnorm=0.202, clip=0, loss_scale=16, train_wall=70, gb_free=16.8, wall=29319
2023-08-05 20:26:43 | INFO | train_inner | epoch 025:    541 / 1474 loss=0.748, trans_loss=5.004, nll_loss=2.202, w2v_ctc_loss=0.241, task_loss=1.365, contrastive_loss=0.054, total=4154.79, n_correct=2717.11, ppl=4.6, accuracy=65.397, wps=12229.6, ups=1.47, wpb=8309.6, bsz=313.5, num_updates=35900, lr=7.46393e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=67, gb_free=17.6, wall=29387
2023-08-05 20:27:50 | INFO | train_inner | epoch 025:    641 / 1474 loss=0.747, trans_loss=4.997, nll_loss=2.193, w2v_ctc_loss=0.242, task_loss=1.388, contrastive_loss=0.12, total=4156.33, n_correct=2718.04, ppl=4.57, accuracy=65.395, wps=12294.4, ups=1.48, wpb=8312.7, bsz=309.3, num_updates=36000, lr=7.45356e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=67, gb_free=16.2, wall=29455
2023-08-05 20:27:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 20:28:16 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 1.467 | trans_loss 5.552 | nll_loss 2.823 | w2v_ctc_loss 0.453 | task_loss 4.63 | contrastive_loss 0.246 | total 4003.4 | n_correct 2488.2 | ppl 7.08 | accuracy 62.152 | uer 17.161 | wer 18.985 | raw_wer 18.985 | bleu 20.18 | wps 1872.3 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.25
2023-08-05 20:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-05 20:28:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_25_36000.pt
2023-08-05 20:28:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_25_36000.pt
2023-08-05 20:28:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.18) (writing took 21.477858893573284 seconds)
2023-08-05 20:29:47 | INFO | train_inner | epoch 025:    741 / 1474 loss=0.749, trans_loss=5.001, nll_loss=2.198, w2v_ctc_loss=0.241, task_loss=1.411, contrastive_loss=0.114, total=4133.94, n_correct=2704.38, ppl=4.59, accuracy=65.419, wps=7098.5, ups=0.86, wpb=8267.9, bsz=303.3, num_updates=36100, lr=7.44323e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=68, gb_free=15, wall=29571
2023-08-05 20:30:55 | INFO | train_inner | epoch 025:    841 / 1474 loss=0.744, trans_loss=5.001, nll_loss=2.199, w2v_ctc_loss=0.239, task_loss=1.297, contrastive_loss=0.062, total=4174.24, n_correct=2735.72, ppl=4.59, accuracy=65.538, wps=12190.8, ups=1.46, wpb=8348.5, bsz=324, num_updates=36200, lr=7.43294e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=29639
2023-08-05 20:32:03 | INFO | train_inner | epoch 025:    941 / 1474 loss=0.748, trans_loss=5.007, nll_loss=2.208, w2v_ctc_loss=0.241, task_loss=1.332, contrastive_loss=0.119, total=4154.13, n_correct=2711.13, ppl=4.62, accuracy=65.263, wps=12180.7, ups=1.47, wpb=8308.3, bsz=316.7, num_updates=36300, lr=7.4227e-05, gnorm=0.2, clip=0, loss_scale=16, train_wall=68, gb_free=10.8, wall=29708
2023-08-05 20:33:11 | INFO | train_inner | epoch 025:   1041 / 1474 loss=0.756, trans_loss=5.013, nll_loss=2.214, w2v_ctc_loss=0.238, task_loss=1.39, contrastive_loss=0.228, total=4178.3, n_correct=2722.73, ppl=4.64, accuracy=65.164, wps=12316.8, ups=1.47, wpb=8356.6, bsz=309.7, num_updates=36400, lr=7.41249e-05, gnorm=0.202, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=29776
2023-08-05 20:34:19 | INFO | train_inner | epoch 025:   1141 / 1474 loss=0.746, trans_loss=5.008, nll_loss=2.206, w2v_ctc_loss=0.238, task_loss=1.5, contrastive_loss=0.038, total=4042.33, n_correct=2640.33, ppl=4.61, accuracy=65.317, wps=11938.9, ups=1.48, wpb=8084.7, bsz=286.5, num_updates=36500, lr=7.40233e-05, gnorm=0.202, clip=0, loss_scale=16, train_wall=67, gb_free=17.8, wall=29843
2023-08-05 20:35:26 | INFO | train_inner | epoch 025:   1241 / 1474 loss=0.748, trans_loss=5.013, nll_loss=2.214, w2v_ctc_loss=0.24, task_loss=1.426, contrastive_loss=0.047, total=4087.78, n_correct=2664.43, ppl=4.64, accuracy=65.18, wps=12128.8, ups=1.48, wpb=8175.6, bsz=295.1, num_updates=36600, lr=7.39221e-05, gnorm=0.211, clip=0, loss_scale=16, train_wall=67, gb_free=17.7, wall=29911
2023-08-05 20:36:34 | INFO | train_inner | epoch 025:   1341 / 1474 loss=0.752, trans_loss=5.012, nll_loss=2.213, w2v_ctc_loss=0.242, task_loss=1.369, contrastive_loss=0.14, total=4166.64, n_correct=2712.81, ppl=4.64, accuracy=65.108, wps=12259.5, ups=1.47, wpb=8333.3, bsz=309.3, num_updates=36700, lr=7.38213e-05, gnorm=0.207, clip=0, loss_scale=16, train_wall=67, gb_free=16.5, wall=29979
2023-08-05 20:37:43 | INFO | train_inner | epoch 025:   1441 / 1474 loss=0.753, trans_loss=5.028, nll_loss=2.233, w2v_ctc_loss=0.243, task_loss=1.426, contrastive_loss=0.106, total=4114.64, n_correct=2665.84, ppl=4.7, accuracy=64.789, wps=12047.6, ups=1.46, wpb=8229.3, bsz=304.3, num_updates=36800, lr=7.3721e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=30047
2023-08-05 20:38:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 20:38:30 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 1.463 | trans_loss 5.542 | nll_loss 2.813 | w2v_ctc_loss 0.45 | task_loss 4.621 | contrastive_loss 0.241 | total 4003.4 | n_correct 2488.4 | ppl 7.03 | accuracy 62.157 | uer 16.871 | wer 18.959 | raw_wer 18.959 | bleu 20.16 | wps 2089 | wpb 4003.4 | bsz 141.8 | num_updates 36833 | best_bleu 20.25
2023-08-05 20:38:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-08-05 20:38:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1605.pt
2023-08-05 20:38:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1605.pt
2023-08-05 20:38:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1605.pt (epoch 25 @ 36833 updates, score 20.16) (writing took 13.42835272103548 seconds)
2023-08-05 20:38:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-05 20:38:44 | INFO | train | epoch 025 | loss 0.748 | trans_loss 5.003 | nll_loss 2.2 | w2v_ctc_loss 0.241 | task_loss 1.401 | contrastive_loss 0.088 | total 4137.19 | n_correct 2703.47 | ppl 4.6 | accuracy 65.346 | wps 11104.8 | ups 1.34 | wpb 8274.4 | bsz 305.2 | num_updates 36833 | lr 7.36879e-05 | gnorm 0.203 | clip 0 | loss_scale 16 | train_wall 997 | gb_free 14.2 | wall 30108
2023-08-05 20:38:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 20:38:44 | INFO | fairseq.trainer | begin training epoch 26
2023-08-05 20:38:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 20:39:36 | INFO | train_inner | epoch 026:     67 / 1474 loss=0.739, trans_loss=4.979, nll_loss=2.169, w2v_ctc_loss=0.236, task_loss=1.325, contrastive_loss=0.07, total=4172.16, n_correct=2746.74, ppl=4.5, accuracy=65.835, wps=7347.9, ups=0.88, wpb=8344.3, bsz=316.9, num_updates=36900, lr=7.3621e-05, gnorm=0.2, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=30161
2023-08-05 20:40:45 | INFO | train_inner | epoch 026:    167 / 1474 loss=0.747, trans_loss=4.977, nll_loss=2.168, w2v_ctc_loss=0.232, task_loss=1.235, contrastive_loss=0.246, total=4265.22, n_correct=2812.02, ppl=4.49, accuracy=65.929, wps=12483.3, ups=1.46, wpb=8530.4, bsz=338.7, num_updates=37000, lr=7.35215e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=30229
2023-08-05 20:41:52 | INFO | train_inner | epoch 026:    267 / 1474 loss=0.744, trans_loss=4.985, nll_loss=2.177, w2v_ctc_loss=0.239, task_loss=1.391, contrastive_loss=0.131, total=4123.94, n_correct=2701.23, ppl=4.52, accuracy=65.501, wps=12168.5, ups=1.48, wpb=8247.9, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.208, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=30297
2023-08-05 20:43:00 | INFO | train_inner | epoch 026:    367 / 1474 loss=0.746, trans_loss=4.986, nll_loss=2.178, w2v_ctc_loss=0.239, task_loss=1.335, contrastive_loss=0.09, total=4168.11, n_correct=2738.21, ppl=4.53, accuracy=65.694, wps=12295.4, ups=1.47, wpb=8336.2, bsz=315.2, num_updates=37200, lr=7.33236e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=67, gb_free=17.2, wall=30364
2023-08-05 20:44:08 | INFO | train_inner | epoch 026:    467 / 1474 loss=0.748, trans_loss=4.981, nll_loss=2.171, w2v_ctc_loss=0.238, task_loss=1.343, contrastive_loss=0.139, total=4167.53, n_correct=2741.14, ppl=4.5, accuracy=65.774, wps=12348, ups=1.48, wpb=8335.1, bsz=314.6, num_updates=37300, lr=7.32252e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=67, gb_free=14, wall=30432
2023-08-05 20:45:16 | INFO | train_inner | epoch 026:    567 / 1474 loss=0.742, trans_loss=4.993, nll_loss=2.187, w2v_ctc_loss=0.241, task_loss=1.406, contrastive_loss=0.059, total=4158.48, n_correct=2727.91, ppl=4.55, accuracy=65.599, wps=12142.4, ups=1.46, wpb=8317, bsz=304.4, num_updates=37400, lr=7.31272e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=68, gb_free=12.7, wall=30500
2023-08-05 20:46:24 | INFO | train_inner | epoch 026:    667 / 1474 loss=0.746, trans_loss=4.994, nll_loss=2.189, w2v_ctc_loss=0.238, task_loss=1.436, contrastive_loss=0.044, total=4129.11, n_correct=2708.14, ppl=4.56, accuracy=65.587, wps=12156.6, ups=1.47, wpb=8258.2, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=67, gb_free=13.8, wall=30568
2023-08-05 20:47:31 | INFO | train_inner | epoch 026:    767 / 1474 loss=0.751, trans_loss=4.999, nll_loss=2.196, w2v_ctc_loss=0.238, task_loss=1.409, contrastive_loss=0.157, total=4096.84, n_correct=2676.04, ppl=4.58, accuracy=65.32, wps=12199.9, ups=1.49, wpb=8193.7, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=30636
2023-08-05 20:48:39 | INFO | train_inner | epoch 026:    867 / 1474 loss=0.748, trans_loss=4.995, nll_loss=2.19, w2v_ctc_loss=0.241, task_loss=1.396, contrastive_loss=0.058, total=4176.27, n_correct=2731.98, ppl=4.56, accuracy=65.417, wps=12382.3, ups=1.48, wpb=8352.5, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=30703
2023-08-05 20:49:47 | INFO | train_inner | epoch 026:    967 / 1474 loss=0.746, trans_loss=5.006, nll_loss=2.205, w2v_ctc_loss=0.235, task_loss=1.444, contrastive_loss=0.112, total=4141.01, n_correct=2701.58, ppl=4.61, accuracy=65.24, wps=12126.4, ups=1.46, wpb=8282, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=68, gb_free=15.5, wall=30771
2023-08-05 20:50:55 | INFO | train_inner | epoch 026:   1067 / 1474 loss=0.744, trans_loss=5.001, nll_loss=2.198, w2v_ctc_loss=0.238, task_loss=1.478, contrastive_loss=0.044, total=4113.69, n_correct=2693.81, ppl=4.59, accuracy=65.484, wps=12110.7, ups=1.47, wpb=8227.4, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.2, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=30839
2023-08-05 20:52:03 | INFO | train_inner | epoch 026:   1167 / 1474 loss=0.747, trans_loss=5.008, nll_loss=2.207, w2v_ctc_loss=0.239, task_loss=1.462, contrastive_loss=0.083, total=4116.78, n_correct=2686.36, ppl=4.62, accuracy=65.254, wps=12064.1, ups=1.47, wpb=8233.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.205, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=30908
2023-08-05 20:52:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 20:52:28 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 1.472 | trans_loss 5.548 | nll_loss 2.819 | w2v_ctc_loss 0.463 | task_loss 4.608 | contrastive_loss 0.234 | total 4003.4 | n_correct 2483.5 | ppl 7.06 | accuracy 62.035 | uer 17.339 | wer 19.097 | raw_wer 19.097 | bleu 20.25 | wps 2031.6 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.25
2023-08-05 20:52:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-05 20:52:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_26_38000.pt
2023-08-05 20:52:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_26_38000.pt
2023-08-05 20:52:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 20.25) (writing took 24.522851787507534 seconds)
2023-08-05 20:54:01 | INFO | train_inner | epoch 026:   1267 / 1474 loss=0.749, trans_loss=5.017, nll_loss=2.219, w2v_ctc_loss=0.245, task_loss=1.551, contrastive_loss=0.046, total=4001.06, n_correct=2603.04, ppl=4.65, accuracy=65.059, wps=6812.4, ups=0.85, wpb=8002.1, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=67, gb_free=15.6, wall=31025
2023-08-05 20:55:10 | INFO | train_inner | epoch 026:   1367 / 1474 loss=0.744, trans_loss=5.009, nll_loss=2.209, w2v_ctc_loss=0.236, task_loss=1.403, contrastive_loss=0.059, total=4157.69, n_correct=2717.08, ppl=4.62, accuracy=65.351, wps=12074.2, ups=1.45, wpb=8315.4, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=31094
2023-08-05 20:56:17 | INFO | train_inner | epoch 026:   1467 / 1474 loss=0.744, trans_loss=5.003, nll_loss=2.202, w2v_ctc_loss=0.236, task_loss=1.327, contrastive_loss=0.052, total=4158.47, n_correct=2725, ppl=4.6, accuracy=65.529, wps=12337.6, ups=1.48, wpb=8316.9, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.201, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=31161
2023-08-05 20:56:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 20:56:45 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 1.472 | trans_loss 5.552 | nll_loss 2.826 | w2v_ctc_loss 0.455 | task_loss 4.608 | contrastive_loss 0.236 | total 4003.4 | n_correct 2486.4 | ppl 7.09 | accuracy 62.107 | uer 17.068 | wer 18.911 | raw_wer 18.911 | bleu 20.12 | wps 2128.6 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 20.25
2023-08-05 20:56:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-08-05 20:56:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1203.pt
2023-08-05 20:56:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1203.pt
2023-08-05 20:56:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1203.pt (epoch 26 @ 38307 updates, score 20.12) (writing took 13.474590172991157 seconds)
2023-08-05 20:56:59 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-05 20:56:59 | INFO | train | epoch 026 | loss 0.746 | trans_loss 4.995 | nll_loss 2.19 | w2v_ctc_loss 0.238 | task_loss 1.399 | contrastive_loss 0.095 | total 4138.65 | n_correct 2711.32 | ppl 4.56 | accuracy 65.512 | wps 11138.5 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.204 | clip 0 | loss_scale 32 | train_wall 994 | gb_free 15.9 | wall 31203
2023-08-05 20:56:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 20:56:59 | INFO | fairseq.trainer | begin training epoch 27
2023-08-05 20:56:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 20:58:09 | INFO | train_inner | epoch 027:     93 / 1474 loss=0.74, trans_loss=4.962, nll_loss=2.146, w2v_ctc_loss=0.235, task_loss=1.495, contrastive_loss=0.036, total=4067.62, n_correct=2692.1, ppl=4.43, accuracy=66.184, wps=7252.4, ups=0.89, wpb=8135.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.209, clip=0, loss_scale=32, train_wall=67, gb_free=14.8, wall=31273
2023-08-05 20:59:18 | INFO | train_inner | epoch 027:    193 / 1474 loss=0.736, trans_loss=4.967, nll_loss=2.153, w2v_ctc_loss=0.235, task_loss=1.339, contrastive_loss=0.06, total=4185.52, n_correct=2767.62, ppl=4.45, accuracy=66.124, wps=12193.3, ups=1.46, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.203, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=31342
2023-08-05 21:00:26 | INFO | train_inner | epoch 027:    293 / 1474 loss=0.74, trans_loss=4.975, nll_loss=2.164, w2v_ctc_loss=0.236, task_loss=1.396, contrastive_loss=0.046, total=4167.92, n_correct=2750.7, ppl=4.48, accuracy=65.997, wps=12175.1, ups=1.46, wpb=8335.8, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=31411
2023-08-05 21:01:35 | INFO | train_inner | epoch 027:    393 / 1474 loss=0.749, trans_loss=4.983, nll_loss=2.174, w2v_ctc_loss=0.234, task_loss=1.47, contrastive_loss=0.227, total=4075.21, n_correct=2676.73, ppl=4.51, accuracy=65.683, wps=11822.5, ups=1.45, wpb=8150.4, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.208, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=31480
2023-08-05 21:02:44 | INFO | train_inner | epoch 027:    493 / 1474 loss=0.744, trans_loss=4.988, nll_loss=2.181, w2v_ctc_loss=0.234, task_loss=1.282, contrastive_loss=0.161, total=4249.35, n_correct=2790.25, ppl=4.54, accuracy=65.663, wps=12436.5, ups=1.46, wpb=8498.7, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.199, clip=0, loss_scale=32, train_wall=68, gb_free=11.9, wall=31548
2023-08-05 21:03:52 | INFO | train_inner | epoch 027:    593 / 1474 loss=0.746, trans_loss=4.986, nll_loss=2.178, w2v_ctc_loss=0.238, task_loss=1.372, contrastive_loss=0.101, total=4133.39, n_correct=2718.47, ppl=4.53, accuracy=65.769, wps=12146.5, ups=1.47, wpb=8266.8, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.207, clip=0, loss_scale=32, train_wall=68, gb_free=11.9, wall=31616
2023-08-05 21:04:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 21:05:00 | INFO | train_inner | epoch 027:    694 / 1474 loss=0.742, trans_loss=4.989, nll_loss=2.183, w2v_ctc_loss=0.238, task_loss=1.42, contrastive_loss=0.043, total=4152.57, n_correct=2730.94, ppl=4.54, accuracy=65.765, wps=12077.5, ups=1.45, wpb=8305.1, bsz=301, num_updates=39000, lr=7.16115e-05, gnorm=0.2, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=31685
2023-08-05 21:06:08 | INFO | train_inner | epoch 027:    794 / 1474 loss=0.745, trans_loss=4.991, nll_loss=2.184, w2v_ctc_loss=0.238, task_loss=1.47, contrastive_loss=0.046, total=4107.17, n_correct=2694.14, ppl=4.55, accuracy=65.596, wps=12173.2, ups=1.48, wpb=8214.3, bsz=294.3, num_updates=39100, lr=7.15199e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=67, gb_free=11.4, wall=31752
2023-08-05 21:07:16 | INFO | train_inner | epoch 027:    894 / 1474 loss=0.745, trans_loss=4.995, nll_loss=2.189, w2v_ctc_loss=0.235, task_loss=1.452, contrastive_loss=0.038, total=4101.4, n_correct=2695.18, ppl=4.56, accuracy=65.714, wps=12126.2, ups=1.48, wpb=8202.8, bsz=292.8, num_updates=39200, lr=7.14286e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=31820
2023-08-05 21:08:24 | INFO | train_inner | epoch 027:    994 / 1474 loss=0.748, trans_loss=4.989, nll_loss=2.183, w2v_ctc_loss=0.235, task_loss=1.354, contrastive_loss=0.222, total=4195.5, n_correct=2755.29, ppl=4.54, accuracy=65.673, wps=12253.1, ups=1.46, wpb=8391, bsz=315.9, num_updates=39300, lr=7.13376e-05, gnorm=0.197, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=31888
2023-08-05 21:09:32 | INFO | train_inner | epoch 027:   1094 / 1474 loss=0.741, trans_loss=4.988, nll_loss=2.181, w2v_ctc_loss=0.234, task_loss=1.409, contrastive_loss=0.055, total=4147.99, n_correct=2725.58, ppl=4.53, accuracy=65.708, wps=12168, ups=1.47, wpb=8296, bsz=304.7, num_updates=39400, lr=7.1247e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=68, gb_free=16.1, wall=31956
2023-08-05 21:10:40 | INFO | train_inner | epoch 027:   1194 / 1474 loss=0.744, trans_loss=5, nll_loss=2.196, w2v_ctc_loss=0.24, task_loss=1.466, contrastive_loss=0.058, total=4104.84, n_correct=2684.71, ppl=4.58, accuracy=65.404, wps=12091.8, ups=1.47, wpb=8209.7, bsz=297.2, num_updates=39500, lr=7.11568e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=67, gb_free=12.1, wall=32024
2023-08-05 21:11:48 | INFO | train_inner | epoch 027:   1294 / 1474 loss=0.747, trans_loss=5.005, nll_loss=2.203, w2v_ctc_loss=0.238, task_loss=1.484, contrastive_loss=0.11, total=4062.86, n_correct=2650.42, ppl=4.61, accuracy=65.235, wps=12011.7, ups=1.48, wpb=8125.7, bsz=293.6, num_updates=39600, lr=7.10669e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=67, gb_free=16.5, wall=32092
2023-08-05 21:12:55 | INFO | train_inner | epoch 027:   1394 / 1474 loss=0.744, trans_loss=4.996, nll_loss=2.193, w2v_ctc_loss=0.234, task_loss=1.315, contrastive_loss=0.096, total=4157.6, n_correct=2728.14, ppl=4.57, accuracy=65.618, wps=12390.3, ups=1.49, wpb=8315.2, bsz=314, num_updates=39700, lr=7.09773e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=67, gb_free=17.6, wall=32159
2023-08-05 21:13:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 21:14:12 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 1.465 | trans_loss 5.54 | nll_loss 2.807 | w2v_ctc_loss 0.464 | task_loss 4.639 | contrastive_loss 0.232 | total 4003.4 | n_correct 2498.3 | ppl 7 | accuracy 62.404 | uer 17.025 | wer 18.937 | raw_wer 18.937 | bleu 20.51 | wps 2204.9 | wpb 4003.4 | bsz 141.8 | num_updates 39780 | best_bleu 20.51
2023-08-05 21:14:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39780 updates
2023-08-05 21:14:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 21:14:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt
2023-08-05 21:14:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_best.pt (epoch 27 @ 39780 updates, score 20.51) (writing took 22.46945176832378 seconds)
2023-08-05 21:14:36 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-05 21:14:36 | INFO | train | epoch 027 | loss 0.743 | trans_loss 4.987 | nll_loss 2.179 | w2v_ctc_loss 0.236 | task_loss 1.401 | contrastive_loss 0.091 | total 4137.89 | n_correct 2719.73 | ppl 4.53 | accuracy 65.727 | wps 11539.1 | ups 1.39 | wpb 8275.8 | bsz 305.4 | num_updates 39780 | lr 7.09059e-05 | gnorm 0.204 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 17.8 | wall 32260
2023-08-05 21:14:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 21:14:36 | INFO | fairseq.trainer | begin training epoch 28
2023-08-05 21:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 21:14:56 | INFO | train_inner | epoch 028:     20 / 1474 loss=0.739, trans_loss=4.986, nll_loss=2.179, w2v_ctc_loss=0.232, task_loss=1.36, contrastive_loss=0.044, total=4107.3, n_correct=2703.37, ppl=4.53, accuracy=65.819, wps=6770, ups=0.82, wpb=8214.6, bsz=304.5, num_updates=39800, lr=7.08881e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=67, gb_free=17.3, wall=32281
2023-08-05 21:16:04 | INFO | train_inner | epoch 028:    120 / 1474 loss=0.739, trans_loss=4.956, nll_loss=2.139, w2v_ctc_loss=0.233, task_loss=1.463, contrastive_loss=0.04, total=4112.44, n_correct=2729.03, ppl=4.4, accuracy=66.36, wps=12221.4, ups=1.49, wpb=8224.9, bsz=292.7, num_updates=39900, lr=7.07992e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=67, gb_free=13.7, wall=32348
2023-08-05 21:17:11 | INFO | train_inner | epoch 028:    220 / 1474 loss=0.735, trans_loss=4.965, nll_loss=2.152, w2v_ctc_loss=0.231, task_loss=1.32, contrastive_loss=0.049, total=4193.3, n_correct=2779, ppl=4.44, accuracy=66.272, wps=12367.1, ups=1.47, wpb=8386.6, bsz=316.4, num_updates=40000, lr=7.07107e-05, gnorm=0.199, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=32416
2023-08-05 21:17:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 21:17:35 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 1.473 | trans_loss 5.553 | nll_loss 2.824 | w2v_ctc_loss 0.461 | task_loss 4.611 | contrastive_loss 0.23 | total 4003.4 | n_correct 2490.7 | ppl 7.08 | accuracy 62.215 | uer 17.073 | wer 18.94 | raw_wer 18.94 | bleu 20.05 | wps 2208.9 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.51
2023-08-05 21:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-05 21:17:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_28_40000.pt
2023-08-05 21:17:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_28_40000.pt
2023-08-05 21:17:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 20.05) (writing took 20.78739154152572 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:0')
2023-08-05 21:19:05 | INFO | train_inner | epoch 028:    320 / 1474 loss=0.754, trans_loss=4.976, nll_loss=2.166, w2v_ctc_loss=0.231, task_loss=1.397, contrastive_loss=0.38, total=4138.69, n_correct=2722.55, ppl=4.49, accuracy=65.783, wps=7299, ups=0.88, wpb=8277.4, bsz=314.4, num_updates=40100, lr=7.06225e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=68, gb_free=13.2, wall=32529
2023-08-05 21:20:12 | INFO | train_inner | epoch 028:    420 / 1474 loss=0.738, trans_loss=4.973, nll_loss=2.161, w2v_ctc_loss=0.235, task_loss=1.442, contrastive_loss=0.038, total=4089.84, n_correct=2702.11, ppl=4.47, accuracy=66.069, wps=12099.6, ups=1.48, wpb=8179.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=32597
2023-08-05 21:21:20 | INFO | train_inner | epoch 028:    520 / 1474 loss=0.738, trans_loss=4.972, nll_loss=2.16, w2v_ctc_loss=0.232, task_loss=1.454, contrastive_loss=0.049, total=4098.92, n_correct=2705.43, ppl=4.47, accuracy=66.003, wps=12110.4, ups=1.48, wpb=8197.8, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=32664
2023-08-05 21:22:28 | INFO | train_inner | epoch 028:    620 / 1474 loss=0.743, trans_loss=4.985, nll_loss=2.178, w2v_ctc_loss=0.235, task_loss=1.408, contrastive_loss=0.048, total=4180.1, n_correct=2749.47, ppl=4.52, accuracy=65.775, wps=12271.6, ups=1.47, wpb=8360.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=32732
2023-08-05 21:23:36 | INFO | train_inner | epoch 028:    720 / 1474 loss=0.744, trans_loss=4.982, nll_loss=2.176, w2v_ctc_loss=0.232, task_loss=1.262, contrastive_loss=0.157, total=4191.62, n_correct=2764.29, ppl=4.52, accuracy=65.948, wps=12368.6, ups=1.48, wpb=8383.2, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=67, gb_free=17, wall=32800
2023-08-05 21:24:44 | INFO | train_inner | epoch 028:    820 / 1474 loss=0.739, trans_loss=4.978, nll_loss=2.169, w2v_ctc_loss=0.233, task_loss=1.384, contrastive_loss=0.04, total=4088.91, n_correct=2702.23, ppl=4.5, accuracy=66.087, wps=12044.5, ups=1.47, wpb=8177.8, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.212, clip=0, loss_scale=16, train_wall=67, gb_free=17, wall=32868
2023-08-05 21:25:52 | INFO | train_inner | epoch 028:    920 / 1474 loss=0.742, trans_loss=4.991, nll_loss=2.184, w2v_ctc_loss=0.235, task_loss=1.45, contrastive_loss=0.102, total=4117.01, n_correct=2701.41, ppl=4.55, accuracy=65.616, wps=12063.4, ups=1.47, wpb=8234, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=32936
2023-08-05 21:26:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-05 21:27:01 | INFO | train_inner | epoch 028:   1021 / 1474 loss=0.745, trans_loss=4.989, nll_loss=2.182, w2v_ctc_loss=0.237, task_loss=1.385, contrastive_loss=0.141, total=4166.71, n_correct=2736.25, ppl=4.54, accuracy=65.669, wps=12120.4, ups=1.45, wpb=8333.4, bsz=307.4, num_updates=40800, lr=7.0014e-05, gnorm=0.211, clip=0, loss_scale=8, train_wall=68, gb_free=17, wall=33005
2023-08-05 21:28:09 | INFO | train_inner | epoch 028:   1121 / 1474 loss=0.737, trans_loss=4.978, nll_loss=2.17, w2v_ctc_loss=0.232, task_loss=1.344, contrastive_loss=0.059, total=4222.19, n_correct=2786.22, ppl=4.5, accuracy=65.99, wps=12384.9, ups=1.47, wpb=8444.4, bsz=321.5, num_updates=40900, lr=6.99284e-05, gnorm=0.217, clip=0, loss_scale=8, train_wall=68, gb_free=17.8, wall=33073
2023-08-05 21:29:17 | INFO | train_inner | epoch 028:   1221 / 1474 loss=0.74, trans_loss=4.985, nll_loss=2.179, w2v_ctc_loss=0.232, task_loss=1.379, contrastive_loss=0.048, total=4104.72, n_correct=2702.99, ppl=4.53, accuracy=65.851, wps=12130.9, ups=1.48, wpb=8209.4, bsz=305.5, num_updates=41000, lr=6.9843e-05, gnorm=0.205, clip=0, loss_scale=8, train_wall=67, gb_free=15.5, wall=33141
2023-08-05 21:30:25 | INFO | train_inner | epoch 028:   1321 / 1474 loss=0.748, trans_loss=4.999, nll_loss=2.196, w2v_ctc_loss=0.242, task_loss=1.546, contrastive_loss=0.061, total=4074.43, n_correct=2667.88, ppl=4.58, accuracy=65.479, wps=11952.2, ups=1.47, wpb=8148.9, bsz=282.9, num_updates=41100, lr=6.9758e-05, gnorm=0.207, clip=0, loss_scale=8, train_wall=68, gb_free=17.8, wall=33209
2023-08-05 21:31:33 | INFO | train_inner | epoch 028:   1421 / 1474 loss=0.742, trans_loss=4.989, nll_loss=2.182, w2v_ctc_loss=0.234, task_loss=1.446, contrastive_loss=0.085, total=4156.52, n_correct=2733.89, ppl=4.54, accuracy=65.774, wps=12155.8, ups=1.46, wpb=8313, bsz=300.8, num_updates=41200, lr=6.96733e-05, gnorm=0.202, clip=0, loss_scale=8, train_wall=68, gb_free=17.7, wall=33278
2023-08-05 21:32:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:3')
2023-08-05 21:32:35 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 1.468 | trans_loss 5.549 | nll_loss 2.818 | w2v_ctc_loss 0.457 | task_loss 4.62 | contrastive_loss 0.231 | total 4003.4 | n_correct 2496.9 | ppl 7.05 | accuracy 62.369 | uer 17.004 | wer 18.829 | raw_wer 18.829 | bleu 20.15 | wps 1864.2 | wpb 4003.4 | bsz 141.8 | num_updates 41253 | best_bleu 20.51
2023-08-05 21:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41253 updates
2023-08-05 21:32:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1500.pt
2023-08-05 21:32:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1500.pt
2023-08-05 21:32:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1500.pt (epoch 28 @ 41253 updates, score 20.15) (writing took 13.896016193553805 seconds)
2023-08-05 21:32:49 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-05 21:32:49 | INFO | train | epoch 028 | loss 0.742 | trans_loss 4.98 | nll_loss 2.171 | w2v_ctc_loss 0.234 | task_loss 1.4 | contrastive_loss 0.092 | total 4138.04 | n_correct 2727.41 | ppl 4.5 | accuracy 65.911 | wps 11147.2 | ups 1.35 | wpb 8276.1 | bsz 305.4 | num_updates 41253 | lr 6.96285e-05 | gnorm 0.206 | clip 0 | loss_scale 8 | train_wall 994 | gb_free 16.4 | wall 33353
2023-08-05 21:32:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 21:32:49 | INFO | fairseq.trainer | begin training epoch 29
2023-08-05 21:32:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 21:33:28 | INFO | train_inner | epoch 029:     47 / 1474 loss=0.737, trans_loss=4.965, nll_loss=2.152, w2v_ctc_loss=0.234, task_loss=1.353, contrastive_loss=0.058, total=4169.02, n_correct=2761.31, ppl=4.45, accuracy=66.234, wps=7250.8, ups=0.87, wpb=8338, bsz=315.1, num_updates=41300, lr=6.95889e-05, gnorm=0.205, clip=0, loss_scale=8, train_wall=67, gb_free=15.9, wall=33393
2023-08-05 21:34:37 | INFO | train_inner | epoch 029:    147 / 1474 loss=0.738, trans_loss=4.963, nll_loss=2.148, w2v_ctc_loss=0.233, task_loss=1.394, contrastive_loss=0.074, total=4110.03, n_correct=2722.12, ppl=4.43, accuracy=66.231, wps=12033.2, ups=1.46, wpb=8220.1, bsz=305.5, num_updates=41400, lr=6.95048e-05, gnorm=0.212, clip=0, loss_scale=8, train_wall=68, gb_free=16.4, wall=33461
2023-08-05 21:35:45 | INFO | train_inner | epoch 029:    247 / 1474 loss=0.741, trans_loss=4.954, nll_loss=2.139, w2v_ctc_loss=0.228, task_loss=1.269, contrastive_loss=0.158, total=4197.89, n_correct=2789.27, ppl=4.4, accuracy=66.445, wps=12239.5, ups=1.46, wpb=8395.8, bsz=329.5, num_updates=41500, lr=6.9421e-05, gnorm=0.203, clip=0, loss_scale=8, train_wall=68, gb_free=17.5, wall=33530
2023-08-05 21:36:53 | INFO | train_inner | epoch 029:    347 / 1474 loss=0.74, trans_loss=4.976, nll_loss=2.165, w2v_ctc_loss=0.236, task_loss=1.501, contrastive_loss=0.044, total=4094.4, n_correct=2703.31, ppl=4.49, accuracy=66.025, wps=12029.4, ups=1.47, wpb=8188.8, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.204, clip=0, loss_scale=8, train_wall=68, gb_free=16.5, wall=33598
2023-08-05 21:38:01 | INFO | train_inner | epoch 029:    447 / 1474 loss=0.734, trans_loss=4.951, nll_loss=2.132, w2v_ctc_loss=0.23, task_loss=1.341, contrastive_loss=0.038, total=4157.41, n_correct=2764.89, ppl=4.38, accuracy=66.505, wps=12218.7, ups=1.47, wpb=8314.8, bsz=308.5, num_updates=41700, lr=6.92543e-05, gnorm=0.199, clip=0, loss_scale=8, train_wall=68, gb_free=14.6, wall=33666
2023-08-05 21:39:09 | INFO | train_inner | epoch 029:    547 / 1474 loss=0.744, trans_loss=4.976, nll_loss=2.165, w2v_ctc_loss=0.232, task_loss=1.503, contrastive_loss=0.133, total=4149.27, n_correct=2730.04, ppl=4.49, accuracy=65.796, wps=12225.1, ups=1.47, wpb=8298.5, bsz=293.3, num_updates=41800, lr=6.91714e-05, gnorm=0.203, clip=0, loss_scale=8, train_wall=67, gb_free=15.4, wall=33734
2023-08-05 21:40:17 | INFO | train_inner | epoch 029:    647 / 1474 loss=0.738, trans_loss=4.964, nll_loss=2.151, w2v_ctc_loss=0.229, task_loss=1.319, contrastive_loss=0.202, total=4145.39, n_correct=2743.99, ppl=4.44, accuracy=66.194, wps=12183.9, ups=1.47, wpb=8290.8, bsz=319.3, num_updates=41900, lr=6.90889e-05, gnorm=0.203, clip=0, loss_scale=8, train_wall=68, gb_free=17.4, wall=33802
2023-08-05 21:41:26 | INFO | train_inner | epoch 029:    747 / 1474 loss=0.733, trans_loss=4.965, nll_loss=2.151, w2v_ctc_loss=0.228, task_loss=1.291, contrastive_loss=0.118, total=4242.46, n_correct=2807.94, ppl=4.44, accuracy=66.187, wps=12374.5, ups=1.46, wpb=8484.9, bsz=329.9, num_updates=42000, lr=6.90066e-05, gnorm=0.199, clip=0, loss_scale=8, train_wall=68, gb_free=16.6, wall=33870
2023-08-05 21:41:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 21:41:50 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 1.475 | trans_loss 5.548 | nll_loss 2.817 | w2v_ctc_loss 0.466 | task_loss 4.604 | contrastive_loss 0.235 | total 4003.4 | n_correct 2494.1 | ppl 7.05 | accuracy 62.3 | uer 17.012 | wer 18.81 | raw_wer 18.81 | bleu 20.02 | wps 2137.7 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.51
2023-08-05 21:41:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-05 21:41:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_29_42000.pt
2023-08-05 21:41:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_29_42000.pt
2023-08-05 21:42:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.02) (writing took 14.712921787053347 seconds)
2023-08-05 21:43:13 | INFO | train_inner | epoch 029:    847 / 1474 loss=0.744, trans_loss=4.988, nll_loss=2.18, w2v_ctc_loss=0.235, task_loss=1.551, contrastive_loss=0.038, total=4027.03, n_correct=2649.83, ppl=4.53, accuracy=65.801, wps=7533.1, ups=0.94, wpb=8054.1, bsz=280.3, num_updates=42100, lr=6.89246e-05, gnorm=0.206, clip=0, loss_scale=8, train_wall=67, gb_free=17.3, wall=33977
2023-08-05 21:44:20 | INFO | train_inner | epoch 029:    947 / 1474 loss=0.741, trans_loss=4.986, nll_loss=2.179, w2v_ctc_loss=0.235, task_loss=1.429, contrastive_loss=0.048, total=4086.72, n_correct=2691.33, ppl=4.53, accuracy=65.856, wps=12162.8, ups=1.49, wpb=8173.4, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.208, clip=0, loss_scale=8, train_wall=67, gb_free=15.3, wall=34044
2023-08-05 21:45:28 | INFO | train_inner | epoch 029:   1047 / 1474 loss=0.74, trans_loss=4.972, nll_loss=2.162, w2v_ctc_loss=0.23, task_loss=1.398, contrastive_loss=0.119, total=4139.4, n_correct=2735.87, ppl=4.47, accuracy=66.093, wps=12232.1, ups=1.48, wpb=8278.8, bsz=307.4, num_updates=42300, lr=6.87614e-05, gnorm=0.206, clip=0, loss_scale=8, train_wall=67, gb_free=15.5, wall=34112
2023-08-05 21:46:35 | INFO | train_inner | epoch 029:   1147 / 1474 loss=0.739, trans_loss=4.989, nll_loss=2.183, w2v_ctc_loss=0.234, task_loss=1.526, contrastive_loss=0.035, total=4072.33, n_correct=2679.18, ppl=4.54, accuracy=65.79, wps=12079.6, ups=1.48, wpb=8144.7, bsz=284.1, num_updates=42400, lr=6.86803e-05, gnorm=0.201, clip=0, loss_scale=8, train_wall=67, gb_free=16.9, wall=34179
2023-08-05 21:47:44 | INFO | train_inner | epoch 029:   1247 / 1474 loss=0.74, trans_loss=4.988, nll_loss=2.182, w2v_ctc_loss=0.235, task_loss=1.42, contrastive_loss=0.042, total=4160.52, n_correct=2737.6, ppl=4.54, accuracy=65.799, wps=12127, ups=1.46, wpb=8321, bsz=301.5, num_updates=42500, lr=6.85994e-05, gnorm=0.204, clip=0, loss_scale=8, train_wall=68, gb_free=15.5, wall=34248
2023-08-05 21:48:52 | INFO | train_inner | epoch 029:   1347 / 1474 loss=0.743, trans_loss=4.981, nll_loss=2.173, w2v_ctc_loss=0.232, task_loss=1.379, contrastive_loss=0.105, total=4168.02, n_correct=2749.61, ppl=4.51, accuracy=65.969, wps=12225.6, ups=1.47, wpb=8336, bsz=310.2, num_updates=42600, lr=6.85189e-05, gnorm=0.206, clip=0, loss_scale=8, train_wall=68, gb_free=16.5, wall=34316
2023-08-05 21:50:00 | INFO | train_inner | epoch 029:   1447 / 1474 loss=0.743, trans_loss=4.976, nll_loss=2.168, w2v_ctc_loss=0.234, task_loss=1.363, contrastive_loss=0.133, total=4166.06, n_correct=2746.8, ppl=4.49, accuracy=65.933, wps=12286.7, ups=1.47, wpb=8332.1, bsz=313.1, num_updates=42700, lr=6.84386e-05, gnorm=0.211, clip=0, loss_scale=8, train_wall=67, gb_free=16.8, wall=34384
2023-08-05 21:50:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 21:50:40 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 1.468 | trans_loss 5.541 | nll_loss 2.81 | w2v_ctc_loss 0.469 | task_loss 4.627 | contrastive_loss 0.24 | total 4003.4 | n_correct 2495 | ppl 7.01 | accuracy 62.322 | uer 16.818 | wer 18.642 | raw_wer 18.642 | bleu 20.32 | wps 2259.4 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 20.51
2023-08-05 21:50:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-08-05 21:50:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.3207.pt
2023-08-05 21:50:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.3207.pt
2023-08-05 21:50:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.3207.pt (epoch 29 @ 42727 updates, score 20.32) (writing took 18.213085068389773 seconds)
2023-08-05 21:50:59 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-05 21:50:59 | INFO | train | epoch 029 | loss 0.74 | trans_loss 4.973 | nll_loss 2.162 | w2v_ctc_loss 0.232 | task_loss 1.399 | contrastive_loss 0.092 | total 4138.65 | n_correct 2734.05 | ppl 4.47 | accuracy 66.061 | wps 11195.6 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.205 | clip 0 | loss_scale 8 | train_wall 996 | gb_free 16 | wall 34443
2023-08-05 21:50:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 21:50:59 | INFO | fairseq.trainer | begin training epoch 30
2023-08-05 21:50:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 21:51:56 | INFO | train_inner | epoch 030:     73 / 1474 loss=0.731, trans_loss=4.958, nll_loss=2.143, w2v_ctc_loss=0.225, task_loss=1.333, contrastive_loss=0.149, total=4175.11, n_correct=2769.69, ppl=4.42, accuracy=66.338, wps=7191.1, ups=0.86, wpb=8350.2, bsz=318.6, num_updates=42800, lr=6.83586e-05, gnorm=0.201, clip=0, loss_scale=8, train_wall=67, gb_free=17.1, wall=34500
2023-08-05 21:53:04 | INFO | train_inner | epoch 030:    173 / 1474 loss=0.736, trans_loss=4.941, nll_loss=2.121, w2v_ctc_loss=0.231, task_loss=1.308, contrastive_loss=0.08, total=4202.64, n_correct=2805.15, ppl=4.35, accuracy=66.747, wps=12286.3, ups=1.46, wpb=8405.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.201, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=34569
2023-08-05 21:54:12 | INFO | train_inner | epoch 030:    273 / 1474 loss=0.736, trans_loss=4.957, nll_loss=2.14, w2v_ctc_loss=0.234, task_loss=1.444, contrastive_loss=0.037, total=4120.21, n_correct=2738.63, ppl=4.41, accuracy=66.468, wps=12217.5, ups=1.48, wpb=8240.4, bsz=294.9, num_updates=43000, lr=6.81994e-05, gnorm=0.207, clip=0, loss_scale=16, train_wall=67, gb_free=15.2, wall=34636
2023-08-05 21:55:20 | INFO | train_inner | epoch 030:    373 / 1474 loss=0.734, trans_loss=4.947, nll_loss=2.128, w2v_ctc_loss=0.229, task_loss=1.396, contrastive_loss=0.041, total=4178.23, n_correct=2784.01, ppl=4.37, accuracy=66.631, wps=12207.2, ups=1.46, wpb=8356.5, bsz=307.5, num_updates=43100, lr=6.81203e-05, gnorm=0.208, clip=0, loss_scale=16, train_wall=68, gb_free=9.8, wall=34704
2023-08-05 21:56:27 | INFO | train_inner | epoch 030:    473 / 1474 loss=0.736, trans_loss=4.957, nll_loss=2.142, w2v_ctc_loss=0.229, task_loss=1.344, contrastive_loss=0.101, total=4124.47, n_correct=2740.08, ppl=4.41, accuracy=66.435, wps=12293.1, ups=1.49, wpb=8248.9, bsz=312.6, num_updates=43200, lr=6.80414e-05, gnorm=0.228, clip=0, loss_scale=16, train_wall=67, gb_free=17.5, wall=34772
2023-08-05 21:57:35 | INFO | train_inner | epoch 030:    573 / 1474 loss=0.735, trans_loss=4.966, nll_loss=2.154, w2v_ctc_loss=0.23, task_loss=1.359, contrastive_loss=0.064, total=4168.41, n_correct=2764.27, ppl=4.45, accuracy=66.315, wps=12247.4, ups=1.47, wpb=8336.8, bsz=312.4, num_updates=43300, lr=6.79628e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=34840
2023-08-05 21:58:44 | INFO | train_inner | epoch 030:    673 / 1474 loss=0.74, trans_loss=4.964, nll_loss=2.15, w2v_ctc_loss=0.234, task_loss=1.382, contrastive_loss=0.077, total=4187.95, n_correct=2772.84, ppl=4.44, accuracy=66.21, wps=12291.3, ups=1.47, wpb=8375.9, bsz=315, num_updates=43400, lr=6.78844e-05, gnorm=0.214, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=34908
2023-08-05 21:59:52 | INFO | train_inner | epoch 030:    773 / 1474 loss=0.745, trans_loss=4.976, nll_loss=2.166, w2v_ctc_loss=0.236, task_loss=1.433, contrastive_loss=0.157, total=4105.32, n_correct=2707.58, ppl=4.49, accuracy=65.953, wps=12073.7, ups=1.47, wpb=8210.6, bsz=302.6, num_updates=43500, lr=6.78064e-05, gnorm=0.211, clip=0, loss_scale=16, train_wall=68, gb_free=12.9, wall=34976
2023-08-05 22:00:59 | INFO | train_inner | epoch 030:    873 / 1474 loss=0.738, trans_loss=4.972, nll_loss=2.161, w2v_ctc_loss=0.231, task_loss=1.445, contrastive_loss=0.05, total=4102.11, n_correct=2712.82, ppl=4.47, accuracy=66.132, wps=12128.7, ups=1.48, wpb=8204.2, bsz=295.6, num_updates=43600, lr=6.77285e-05, gnorm=0.207, clip=0, loss_scale=16, train_wall=67, gb_free=17.4, wall=35043
2023-08-05 22:02:07 | INFO | train_inner | epoch 030:    973 / 1474 loss=0.738, trans_loss=4.976, nll_loss=2.165, w2v_ctc_loss=0.233, task_loss=1.434, contrastive_loss=0.051, total=4129.98, n_correct=2725.58, ppl=4.49, accuracy=65.995, wps=12168.3, ups=1.47, wpb=8260, bsz=300.4, num_updates=43700, lr=6.7651e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=35111
2023-08-05 22:03:16 | INFO | train_inner | epoch 030:   1073 / 1474 loss=0.744, trans_loss=4.984, nll_loss=2.176, w2v_ctc_loss=0.235, task_loss=1.566, contrastive_loss=0.13, total=4101.17, n_correct=2699.23, ppl=4.52, accuracy=65.816, wps=11986, ups=1.46, wpb=8202.3, bsz=282.3, num_updates=43800, lr=6.75737e-05, gnorm=0.21, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=35180
2023-08-05 22:04:24 | INFO | train_inner | epoch 030:   1173 / 1474 loss=0.736, trans_loss=4.971, nll_loss=2.16, w2v_ctc_loss=0.226, task_loss=1.346, contrastive_loss=0.111, total=4168.36, n_correct=2758.91, ppl=4.47, accuracy=66.187, wps=12222.5, ups=1.47, wpb=8336.7, bsz=314, num_updates=43900, lr=6.74967e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=35248
2023-08-05 22:05:32 | INFO | train_inner | epoch 030:   1273 / 1474 loss=0.743, trans_loss=4.981, nll_loss=2.171, w2v_ctc_loss=0.235, task_loss=1.543, contrastive_loss=0.045, total=4036.17, n_correct=2659.58, ppl=4.5, accuracy=65.894, wps=11767.9, ups=1.46, wpb=8072.3, bsz=284.3, num_updates=44000, lr=6.742e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=35317
2023-08-05 22:05:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 22:05:56 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 1.471 | trans_loss 5.547 | nll_loss 2.818 | w2v_ctc_loss 0.463 | task_loss 4.598 | contrastive_loss 0.225 | total 4003.4 | n_correct 2495.1 | ppl 7.05 | accuracy 62.325 | uer 16.951 | wer 18.825 | raw_wer 18.825 | bleu 19.96 | wps 2163.2 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.51
2023-08-05 22:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-05 22:05:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_30_44000.pt
2023-08-05 22:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_30_44000.pt
2023-08-05 22:06:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 19.96) (writing took 12.86255674622953 seconds)
2023-08-05 22:07:17 | INFO | train_inner | epoch 030:   1373 / 1474 loss=0.732, trans_loss=4.97, nll_loss=2.161, w2v_ctc_loss=0.229, task_loss=1.319, contrastive_loss=0.054, total=4165.07, n_correct=2757.64, ppl=4.47, accuracy=66.209, wps=7942.6, ups=0.95, wpb=8330.1, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=35421
2023-08-05 22:08:25 | INFO | train_inner | epoch 030:   1473 / 1474 loss=0.744, trans_loss=4.974, nll_loss=2.166, w2v_ctc_loss=0.227, task_loss=1.315, contrastive_loss=0.201, total=4141.76, n_correct=2737.54, ppl=4.49, accuracy=66.096, wps=12276.2, ups=1.48, wpb=8283.5, bsz=314.3, num_updates=44200, lr=6.72673e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=35489
2023-08-05 22:08:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 22:08:49 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 1.469 | trans_loss 5.55 | nll_loss 2.82 | w2v_ctc_loss 0.466 | task_loss 4.634 | contrastive_loss 0.232 | total 4003.4 | n_correct 2497.8 | ppl 7.06 | accuracy 62.392 | uer 16.967 | wer 18.843 | raw_wer 18.843 | bleu 20.05 | wps 2182.6 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.51
2023-08-05 22:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-08-05 22:08:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_last.pt
2023-08-05 22:09:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_last.pt
2023-08-05 22:09:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_last.pt (epoch 30 @ 44201 updates, score 20.05) (writing took 12.311172723770142 seconds)
2023-08-05 22:09:01 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-05 22:09:01 | INFO | train | epoch 030 | loss 0.738 | trans_loss 4.966 | nll_loss 2.153 | w2v_ctc_loss 0.231 | task_loss 1.399 | contrastive_loss 0.091 | total 4138.65 | n_correct 2741.24 | ppl 4.45 | accuracy 66.235 | wps 11274.9 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.208 | clip 0 | loss_scale 16 | train_wall 996 | gb_free 17.1 | wall 35525
2023-08-05 22:09:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 22:09:01 | INFO | fairseq.trainer | begin training epoch 31
2023-08-05 22:09:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 22:10:16 | INFO | train_inner | epoch 031:     99 / 1474 loss=0.732, trans_loss=4.947, nll_loss=2.126, w2v_ctc_loss=0.231, task_loss=1.493, contrastive_loss=0.039, total=4054.44, n_correct=2699.92, ppl=4.37, accuracy=66.592, wps=7316.6, ups=0.9, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.208, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=35600
2023-08-05 22:11:23 | INFO | train_inner | epoch 031:    199 / 1474 loss=0.736, trans_loss=4.951, nll_loss=2.132, w2v_ctc_loss=0.231, task_loss=1.433, contrastive_loss=0.065, total=4147.4, n_correct=2759.53, ppl=4.38, accuracy=66.536, wps=12276.5, ups=1.48, wpb=8294.8, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.205, clip=0, loss_scale=16, train_wall=67, gb_free=16.8, wall=35667
2023-08-05 22:12:32 | INFO | train_inner | epoch 031:    299 / 1474 loss=0.734, trans_loss=4.947, nll_loss=2.128, w2v_ctc_loss=0.227, task_loss=1.43, contrastive_loss=0.106, total=4149.21, n_correct=2765.62, ppl=4.37, accuracy=66.654, wps=12021.9, ups=1.45, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=35736
2023-08-05 22:13:40 | INFO | train_inner | epoch 031:    399 / 1474 loss=0.739, trans_loss=4.96, nll_loss=2.143, w2v_ctc_loss=0.231, task_loss=1.527, contrastive_loss=0.043, total=4092.62, n_correct=2713.91, ppl=4.42, accuracy=66.312, wps=12003.5, ups=1.47, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.208, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=35805
2023-08-05 22:14:48 | INFO | train_inner | epoch 031:    499 / 1474 loss=0.734, trans_loss=4.956, nll_loss=2.139, w2v_ctc_loss=0.233, task_loss=1.46, contrastive_loss=0.05, total=4111.85, n_correct=2727.82, ppl=4.41, accuracy=66.34, wps=12082.9, ups=1.47, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.21, clip=0, loss_scale=16, train_wall=68, gb_free=10.8, wall=35873
2023-08-05 22:15:56 | INFO | train_inner | epoch 031:    599 / 1474 loss=0.734, trans_loss=4.954, nll_loss=2.137, w2v_ctc_loss=0.228, task_loss=1.46, contrastive_loss=0.041, total=4083.44, n_correct=2715.01, ppl=4.4, accuracy=66.488, wps=12031, ups=1.47, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=67, gb_free=16.7, wall=35941
2023-08-05 22:17:04 | INFO | train_inner | epoch 031:    699 / 1474 loss=0.73, trans_loss=4.95, nll_loss=2.132, w2v_ctc_loss=0.225, task_loss=1.332, contrastive_loss=0.042, total=4213.98, n_correct=2809.23, ppl=4.38, accuracy=66.665, wps=12424.5, ups=1.47, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.202, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=36008
2023-08-05 22:18:12 | INFO | train_inner | epoch 031:    799 / 1474 loss=0.736, trans_loss=4.968, nll_loss=2.155, w2v_ctc_loss=0.229, task_loss=1.465, contrastive_loss=0.111, total=4097.37, n_correct=2709.56, ppl=4.45, accuracy=66.129, wps=12018.3, ups=1.47, wpb=8194.7, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.207, clip=0, loss_scale=32, train_wall=68, gb_free=12.9, wall=36077
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:0')
2023-08-05 22:19:20 | INFO | train_inner | epoch 031:    899 / 1474 loss=0.738, trans_loss=4.958, nll_loss=2.142, w2v_ctc_loss=0.231, task_loss=1.455, contrastive_loss=0.056, total=4096.72, n_correct=2718.84, ppl=4.42, accuracy=66.366, wps=12083, ups=1.47, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.212, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=36144
2023-08-05 22:20:28 | INFO | train_inner | epoch 031:    999 / 1474 loss=0.739, trans_loss=4.967, nll_loss=2.156, w2v_ctc_loss=0.229, task_loss=1.32, contrastive_loss=0.139, total=4187.84, n_correct=2779.61, ppl=4.46, accuracy=66.373, wps=12304.9, ups=1.47, wpb=8375.7, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.204, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=36212
2023-08-05 22:21:36 | INFO | train_inner | epoch 031:   1099 / 1474 loss=0.739, trans_loss=4.961, nll_loss=2.148, w2v_ctc_loss=0.229, task_loss=1.366, contrastive_loss=0.086, total=4149.44, n_correct=2754.69, ppl=4.43, accuracy=66.387, wps=12239.9, ups=1.47, wpb=8298.9, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=36280
2023-08-05 22:22:44 | INFO | train_inner | epoch 031:   1199 / 1474 loss=0.742, trans_loss=4.966, nll_loss=2.155, w2v_ctc_loss=0.228, task_loss=1.312, contrastive_loss=0.202, total=4189.76, n_correct=2776.42, ppl=4.45, accuracy=66.267, wps=12333.1, ups=1.47, wpb=8379.5, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.208, clip=0, loss_scale=32, train_wall=67, gb_free=13.1, wall=36348
2023-08-05 22:23:51 | INFO | train_inner | epoch 031:   1299 / 1474 loss=0.734, trans_loss=4.966, nll_loss=2.155, w2v_ctc_loss=0.229, task_loss=1.255, contrastive_loss=0.047, total=4227.44, n_correct=2805.4, ppl=4.45, accuracy=66.362, wps=12576.5, ups=1.49, wpb=8454.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.208, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=36415
2023-08-05 22:24:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 22:25:00 | INFO | train_inner | epoch 031:   1400 / 1474 loss=0.731, trans_loss=4.966, nll_loss=2.155, w2v_ctc_loss=0.227, task_loss=1.309, contrastive_loss=0.149, total=4162.83, n_correct=2756.13, ppl=4.45, accuracy=66.208, wps=12056, ups=1.45, wpb=8325.7, bsz=319.1, num_updates=45600, lr=6.62266e-05, gnorm=0.208, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=36485
2023-08-05 22:25:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2532, device='cuda:7')
2023-08-05 22:26:14 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 1.467 | trans_loss 5.546 | nll_loss 2.815 | w2v_ctc_loss 0.465 | task_loss 4.633 | contrastive_loss 0.223 | total 4003.4 | n_correct 2496.3 | ppl 7.04 | accuracy 62.354 | uer 16.842 | wer 18.687 | raw_wer 18.687 | bleu 20.12 | wps 2175.2 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 20.51
2023-08-05 22:26:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-08-05 22:26:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1203.pt
2023-08-05 22:26:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1203.pt
2023-08-05 22:26:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1203.pt (epoch 31 @ 45674 updates, score 20.12) (writing took 21.66295951977372 seconds)
2023-08-05 22:26:35 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-05 22:26:35 | INFO | train | epoch 031 | loss 0.736 | trans_loss 4.959 | nll_loss 2.144 | w2v_ctc_loss 0.229 | task_loss 1.401 | contrastive_loss 0.083 | total 4136.77 | n_correct 2746.41 | ppl 4.42 | accuracy 66.39 | wps 11559.8 | ups 1.4 | wpb 8273.5 | bsz 305.1 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.207 | clip 0 | loss_scale 16 | train_wall 995 | gb_free 12 | wall 36580
2023-08-05 22:26:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 22:26:36 | INFO | fairseq.trainer | begin training epoch 32
2023-08-05 22:26:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 22:27:01 | INFO | train_inner | epoch 032:     26 / 1474 loss=0.736, trans_loss=4.961, nll_loss=2.147, w2v_ctc_loss=0.23, task_loss=1.477, contrastive_loss=0.039, total=4040.88, n_correct=2681.08, ppl=4.43, accuracy=66.349, wps=6695.4, ups=0.83, wpb=8081.8, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=67, gb_free=15.5, wall=36605
2023-08-05 22:28:09 | INFO | train_inner | epoch 032:    126 / 1474 loss=0.726, trans_loss=4.922, nll_loss=2.096, w2v_ctc_loss=0.221, task_loss=1.292, contrastive_loss=0.047, total=4222.14, n_correct=2838.39, ppl=4.28, accuracy=67.226, wps=12384.7, ups=1.47, wpb=8444.3, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=36673
2023-08-05 22:29:18 | INFO | train_inner | epoch 032:    226 / 1474 loss=0.732, trans_loss=4.941, nll_loss=2.121, w2v_ctc_loss=0.226, task_loss=1.328, contrastive_loss=0.056, total=4159.77, n_correct=2777.01, ppl=4.35, accuracy=66.759, wps=12149.2, ups=1.46, wpb=8319.5, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=36742
2023-08-05 22:30:25 | INFO | train_inner | epoch 032:    326 / 1474 loss=0.73, trans_loss=4.93, nll_loss=2.107, w2v_ctc_loss=0.222, task_loss=1.321, contrastive_loss=0.049, total=4179.65, n_correct=2802.79, ppl=4.31, accuracy=67.058, wps=12361.3, ups=1.48, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=67, gb_free=16.2, wall=36810
2023-08-05 22:30:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 22:30:50 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 1.473 | trans_loss 5.557 | nll_loss 2.829 | w2v_ctc_loss 0.462 | task_loss 4.605 | contrastive_loss 0.228 | total 4003.4 | n_correct 2491.2 | ppl 7.11 | accuracy 62.227 | uer 16.728 | wer 18.59 | raw_wer 18.59 | bleu 19.76 | wps 2006 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.51
2023-08-05 22:30:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-05 22:30:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_32_46000.pt
2023-08-05 22:30:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_32_46000.pt
2023-08-05 22:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 19.76) (writing took 12.888516446575522 seconds)
2023-08-05 22:32:12 | INFO | train_inner | epoch 032:    426 / 1474 loss=0.731, trans_loss=4.94, nll_loss=2.119, w2v_ctc_loss=0.227, task_loss=1.367, contrastive_loss=0.049, total=4172.34, n_correct=2791.08, ppl=4.34, accuracy=66.895, wps=7819.1, ups=0.94, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.213, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=36916
2023-08-05 22:33:20 | INFO | train_inner | epoch 032:    526 / 1474 loss=0.732, trans_loss=4.949, nll_loss=2.131, w2v_ctc_loss=0.227, task_loss=1.368, contrastive_loss=0.127, total=4191.15, n_correct=2795.42, ppl=4.38, accuracy=66.698, wps=12249.7, ups=1.46, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.211, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=36985
2023-08-05 22:34:29 | INFO | train_inner | epoch 032:    626 / 1474 loss=0.732, trans_loss=4.956, nll_loss=2.139, w2v_ctc_loss=0.228, task_loss=1.464, contrastive_loss=0.054, total=4138.05, n_correct=2750.91, ppl=4.41, accuracy=66.478, wps=12092, ups=1.46, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=68, gb_free=13.3, wall=37053
2023-08-05 22:35:37 | INFO | train_inner | epoch 032:    726 / 1474 loss=0.73, trans_loss=4.957, nll_loss=2.141, w2v_ctc_loss=0.229, task_loss=1.419, contrastive_loss=0.04, total=4156.23, n_correct=2762.87, ppl=4.41, accuracy=66.475, wps=12107.9, ups=1.46, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=37122
2023-08-05 22:36:45 | INFO | train_inner | epoch 032:    826 / 1474 loss=0.733, trans_loss=4.953, nll_loss=2.136, w2v_ctc_loss=0.227, task_loss=1.451, contrastive_loss=0.037, total=4112.3, n_correct=2737.14, ppl=4.4, accuracy=66.56, wps=12192.2, ups=1.48, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.214, clip=0, loss_scale=16, train_wall=67, gb_free=15.8, wall=37189
2023-08-05 22:37:53 | INFO | train_inner | epoch 032:    926 / 1474 loss=0.733, trans_loss=4.956, nll_loss=2.14, w2v_ctc_loss=0.226, task_loss=1.451, contrastive_loss=0.036, total=4139.37, n_correct=2748.95, ppl=4.41, accuracy=66.41, wps=12116.4, ups=1.46, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.21, clip=0, loss_scale=16, train_wall=68, gb_free=12.7, wall=37258
2023-08-05 22:39:01 | INFO | train_inner | epoch 032:   1026 / 1474 loss=0.738, trans_loss=4.964, nll_loss=2.15, w2v_ctc_loss=0.229, task_loss=1.38, contrastive_loss=0.131, total=4121.85, n_correct=2732.78, ppl=4.44, accuracy=66.3, wps=12196.5, ups=1.48, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.207, clip=0, loss_scale=16, train_wall=67, gb_free=16.8, wall=37325
2023-08-05 22:40:10 | INFO | train_inner | epoch 032:   1126 / 1474 loss=0.741, trans_loss=4.971, nll_loss=2.158, w2v_ctc_loss=0.231, task_loss=1.659, contrastive_loss=0.072, total=4015.59, n_correct=2653, ppl=4.46, accuracy=66.068, wps=11688.3, ups=1.46, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.21, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=37394
2023-08-05 22:41:18 | INFO | train_inner | epoch 032:   1226 / 1474 loss=0.742, trans_loss=4.972, nll_loss=2.163, w2v_ctc_loss=0.228, task_loss=1.38, contrastive_loss=0.176, total=4153.44, n_correct=2745.53, ppl=4.48, accuracy=66.103, wps=12170.2, ups=1.47, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.213, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=37462
2023-08-05 22:42:26 | INFO | train_inner | epoch 032:   1326 / 1474 loss=0.734, trans_loss=4.964, nll_loss=2.151, w2v_ctc_loss=0.23, task_loss=1.441, contrastive_loss=0.037, total=4075.86, n_correct=2703.21, ppl=4.44, accuracy=66.322, wps=11954.1, ups=1.47, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.21, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=37530
2023-08-05 22:43:36 | INFO | train_inner | epoch 032:   1426 / 1474 loss=0.745, trans_loss=4.966, nll_loss=2.154, w2v_ctc_loss=0.231, task_loss=1.395, contrastive_loss=0.268, total=4116.4, n_correct=2726.64, ppl=4.45, accuracy=66.238, wps=11817.5, ups=1.44, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=37600
2023-08-05 22:44:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 22:44:35 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 1.47 | trans_loss 5.548 | nll_loss 2.819 | w2v_ctc_loss 0.473 | task_loss 4.624 | contrastive_loss 0.237 | total 4003.4 | n_correct 2498.9 | ppl 7.06 | accuracy 62.419 | uer 16.967 | wer 18.765 | raw_wer 18.765 | bleu 20.11 | wps 1854.4 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.51
2023-08-05 22:44:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-08-05 22:44:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1100.pt
2023-08-05 22:44:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1100.pt
2023-08-05 22:44:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint.best_bleu_20.1100.pt (epoch 32 @ 47148 updates, score 20.11) (writing took 13.002448802813888 seconds)
2023-08-05 22:44:49 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-05 22:44:49 | INFO | train | epoch 032 | loss 0.734 | trans_loss 4.953 | nll_loss 2.136 | w2v_ctc_loss 0.227 | task_loss 1.399 | contrastive_loss 0.089 | total 4138.65 | n_correct 2754.13 | ppl 4.4 | accuracy 66.547 | wps 11155.6 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.208 | clip 0 | loss_scale 16 | train_wall 1001 | gb_free 16.4 | wall 37673
2023-08-05 22:44:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 22:44:49 | INFO | fairseq.trainer | begin training epoch 33
2023-08-05 22:44:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 22:45:34 | INFO | train_inner | epoch 033:     52 / 1474 loss=0.729, trans_loss=4.949, nll_loss=2.133, w2v_ctc_loss=0.222, task_loss=1.323, contrastive_loss=0.139, total=4149.21, n_correct=2763.43, ppl=4.39, accuracy=66.601, wps=6991.8, ups=0.84, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=70, gb_free=17, wall=37719
2023-08-05 22:46:44 | INFO | train_inner | epoch 033:    152 / 1474 loss=0.73, trans_loss=4.931, nll_loss=2.105, w2v_ctc_loss=0.222, task_loss=1.502, contrastive_loss=0.03, total=4073.9, n_correct=2729.31, ppl=4.3, accuracy=66.995, wps=11745.9, ups=1.44, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=37788
2023-08-05 22:47:54 | INFO | train_inner | epoch 033:    252 / 1474 loss=0.729, trans_loss=4.93, nll_loss=2.109, w2v_ctc_loss=0.221, task_loss=1.194, contrastive_loss=0.196, total=4280.14, n_correct=2867.07, ppl=4.31, accuracy=66.985, wps=12111.9, ups=1.41, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=70, gb_free=16.4, wall=37859
2023-08-05 22:49:04 | INFO | train_inner | epoch 033:    352 / 1474 loss=0.736, trans_loss=4.941, nll_loss=2.121, w2v_ctc_loss=0.227, task_loss=1.43, contrastive_loss=0.055, total=4120.27, n_correct=2753.46, ppl=4.35, accuracy=66.827, wps=11824.8, ups=1.43, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=37928
2023-08-05 22:50:14 | INFO | train_inner | epoch 033:    452 / 1474 loss=0.725, trans_loss=4.928, nll_loss=2.104, w2v_ctc_loss=0.223, task_loss=1.326, contrastive_loss=0.036, total=4141.22, n_correct=2776.05, ppl=4.3, accuracy=67.035, wps=11806.1, ups=1.43, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=37999
2023-08-05 22:51:25 | INFO | train_inner | epoch 033:    552 / 1474 loss=0.736, trans_loss=4.95, nll_loss=2.131, w2v_ctc_loss=0.228, task_loss=1.455, contrastive_loss=0.056, total=4133.59, n_correct=2750.59, ppl=4.38, accuracy=66.542, wps=11760.5, ups=1.42, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.205, clip=0, loss_scale=32, train_wall=70, gb_free=15.2, wall=38069
2023-08-05 22:52:35 | INFO | train_inner | epoch 033:    652 / 1474 loss=0.733, trans_loss=4.959, nll_loss=2.144, w2v_ctc_loss=0.226, task_loss=1.43, contrastive_loss=0.09, total=4157.63, n_correct=2758.99, ppl=4.42, accuracy=66.36, wps=11758.3, ups=1.41, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=70, gb_free=17.7, wall=38140
2023-08-05 22:53:45 | INFO | train_inner | epoch 033:    752 / 1474 loss=0.736, trans_loss=4.955, nll_loss=2.138, w2v_ctc_loss=0.233, task_loss=1.52, contrastive_loss=0.038, total=4070.75, n_correct=2704.44, ppl=4.4, accuracy=66.436, wps=11626.8, ups=1.43, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.214, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=38210
2023-08-05 22:54:56 | INFO | train_inner | epoch 033:    852 / 1474 loss=0.726, trans_loss=4.941, nll_loss=2.122, w2v_ctc_loss=0.218, task_loss=1.33, contrastive_loss=0.105, total=4130.24, n_correct=2761.73, ppl=4.35, accuracy=66.866, wps=11771.9, ups=1.43, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=70, gb_free=16.7, wall=38280
2023-08-05 22:54:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 22:55:20 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 1.472 | trans_loss 5.552 | nll_loss 2.821 | w2v_ctc_loss 0.472 | task_loss 4.619 | contrastive_loss 0.233 | total 4003.4 | n_correct 2489.3 | ppl 7.07 | accuracy 62.18 | uer 16.871 | wer 18.761 | raw_wer 18.761 | bleu 20.19 | wps 2070 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.51
2023-08-05 22:55:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-05 22:55:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_33_48000.pt
2023-08-05 22:55:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_33_48000.pt
2023-08-05 22:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.19) (writing took 35.19826613366604 seconds)
2023-08-05 22:57:06 | INFO | train_inner | epoch 033:    952 / 1474 loss=0.733, trans_loss=4.951, nll_loss=2.135, w2v_ctc_loss=0.23, task_loss=1.398, contrastive_loss=0.048, total=4151.18, n_correct=2764.77, ppl=4.39, accuracy=66.602, wps=6340.3, ups=0.76, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.204, clip=0, loss_scale=32, train_wall=69, gb_free=11.1, wall=38411
2023-08-05 22:58:17 | INFO | train_inner | epoch 033:   1052 / 1474 loss=0.738, trans_loss=4.95, nll_loss=2.133, w2v_ctc_loss=0.226, task_loss=1.405, contrastive_loss=0.151, total=4140.1, n_correct=2755.35, ppl=4.39, accuracy=66.553, wps=11741.7, ups=1.42, wpb=8280.2, bsz=307.6, num_updates=48200, lr=6.44157e-05, gnorm=0.21, clip=0, loss_scale=32, train_wall=70, gb_free=11.6, wall=38481
2023-08-05 22:59:27 | INFO | train_inner | epoch 033:   1152 / 1474 loss=0.736, trans_loss=4.959, nll_loss=2.145, w2v_ctc_loss=0.225, task_loss=1.4, contrastive_loss=0.141, total=4182.67, n_correct=2777.12, ppl=4.42, accuracy=66.396, wps=11946.2, ups=1.43, wpb=8365.3, bsz=309.5, num_updates=48300, lr=6.43489e-05, gnorm=0.209, clip=0, loss_scale=32, train_wall=70, gb_free=17.5, wall=38551
2023-08-05 23:00:38 | INFO | train_inner | epoch 033:   1252 / 1474 loss=0.732, trans_loss=4.951, nll_loss=2.134, w2v_ctc_loss=0.229, task_loss=1.472, contrastive_loss=0.041, total=4110.02, n_correct=2735.88, ppl=4.39, accuracy=66.566, wps=11580.4, ups=1.41, wpb=8220, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.206, clip=0, loss_scale=32, train_wall=70, gb_free=16.8, wall=38622
2023-08-05 23:01:48 | INFO | train_inner | epoch 033:   1352 / 1474 loss=0.73, trans_loss=4.956, nll_loss=2.142, w2v_ctc_loss=0.226, task_loss=1.371, contrastive_loss=0.059, total=4128.82, n_correct=2746.17, ppl=4.41, accuracy=66.512, wps=11767.8, ups=1.43, wpb=8257.6, bsz=312.4, num_updates=48500, lr=6.42161e-05, gnorm=0.209, clip=0, loss_scale=32, train_wall=70, gb_free=16.1, wall=38693
2023-08-05 23:02:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-05 23:02:59 | INFO | train_inner | epoch 033:   1453 / 1474 loss=0.731, trans_loss=4.954, nll_loss=2.139, w2v_ctc_loss=0.227, task_loss=1.456, contrastive_loss=0.041, total=4091.88, n_correct=2724.33, ppl=4.4, accuracy=66.579, wps=11510.5, ups=1.41, wpb=8183.8, bsz=296.8, num_updates=48600, lr=6.415e-05, gnorm=0.208, clip=0, loss_scale=16, train_wall=71, gb_free=16.9, wall=38764
2023-08-05 23:03:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 23:03:39 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 1.472 | trans_loss 5.552 | nll_loss 2.82 | w2v_ctc_loss 0.474 | task_loss 4.62 | contrastive_loss 0.233 | total 4003.4 | n_correct 2500.1 | ppl 7.06 | accuracy 62.449 | uer 16.911 | wer 18.631 | raw_wer 18.631 | bleu 20.08 | wps 2001.6 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.51
2023-08-05 23:03:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-08-05 23:03:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_last.pt
2023-08-05 23:03:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_last.pt
2023-08-05 23:03:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_last.pt (epoch 33 @ 48621 updates, score 20.08) (writing took 13.40406428463757 seconds)
2023-08-05 23:03:52 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-05 23:03:52 | INFO | train | epoch 033 | loss 0.732 | trans_loss 4.947 | nll_loss 2.128 | w2v_ctc_loss 0.226 | task_loss 1.403 | contrastive_loss 0.078 | total 4136.56 | n_correct 2757.83 | ppl 4.37 | accuracy 66.67 | wps 10660.5 | ups 1.29 | wpb 8273.1 | bsz 304.9 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.207 | clip 0 | loss_scale 16 | train_wall 1026 | gb_free 17.8 | wall 38817
2023-08-05 23:03:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-05 23:03:52 | INFO | fairseq.trainer | begin training epoch 34
2023-08-05 23:03:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-05 23:04:57 | INFO | train_inner | epoch 034:     79 / 1474 loss=0.73, trans_loss=4.928, nll_loss=2.105, w2v_ctc_loss=0.226, task_loss=1.383, contrastive_loss=0.043, total=4131.47, n_correct=2769.17, ppl=4.3, accuracy=67.026, wps=7034.6, ups=0.85, wpb=8262.9, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.213, clip=0, loss_scale=16, train_wall=70, gb_free=16.6, wall=38881
2023-08-05 23:06:07 | INFO | train_inner | epoch 034:    179 / 1474 loss=0.726, trans_loss=4.922, nll_loss=2.096, w2v_ctc_loss=0.223, task_loss=1.461, contrastive_loss=0.044, total=4065.88, n_correct=2731.09, ppl=4.27, accuracy=67.171, wps=11611.7, ups=1.43, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.207, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=38951
2023-08-05 23:07:17 | INFO | train_inner | epoch 034:    279 / 1474 loss=0.74, trans_loss=4.94, nll_loss=2.12, w2v_ctc_loss=0.223, task_loss=1.307, contrastive_loss=0.248, total=4246.3, n_correct=2835.45, ppl=4.35, accuracy=66.775, wps=12068.8, ups=1.42, wpb=8492.6, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=70, gb_free=17.8, wall=39021
2023-08-05 23:08:27 | INFO | train_inner | epoch 034:    379 / 1474 loss=0.727, trans_loss=4.924, nll_loss=2.099, w2v_ctc_loss=0.219, task_loss=1.331, contrastive_loss=0.14, total=4156.17, n_correct=2792.32, ppl=4.28, accuracy=67.185, wps=11864.3, ups=1.43, wpb=8312.3, bsz=316.7, num_updates=49000, lr=6.38877e-05, gnorm=0.203, clip=0, loss_scale=16, train_wall=70, gb_free=17.7, wall=39092
2023-08-05 23:09:38 | INFO | train_inner | epoch 034:    479 / 1474 loss=0.733, trans_loss=4.944, nll_loss=2.123, w2v_ctc_loss=0.229, task_loss=1.535, contrastive_loss=0.038, total=4070.55, n_correct=2716.78, ppl=4.36, accuracy=66.742, wps=11557.9, ups=1.42, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.211, clip=0, loss_scale=16, train_wall=70, gb_free=17.4, wall=39162
2023-08-05 23:10:47 | INFO | train_inner | epoch 034:    579 / 1474 loss=0.731, trans_loss=4.932, nll_loss=2.11, w2v_ctc_loss=0.225, task_loss=1.42, contrastive_loss=0.041, total=4119.38, n_correct=2761.49, ppl=4.32, accuracy=67.037, wps=11837.1, ups=1.44, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.213, clip=0, loss_scale=16, train_wall=69, gb_free=13, wall=39232
2023-08-05 23:11:57 | INFO | train_inner | epoch 034:    679 / 1474 loss=0.729, trans_loss=4.936, nll_loss=2.115, w2v_ctc_loss=0.223, task_loss=1.42, contrastive_loss=0.036, total=4124.83, n_correct=2761.11, ppl=4.33, accuracy=66.939, wps=11834.4, ups=1.43, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=69, gb_free=14.2, wall=39301
2023-08-05 23:13:07 | INFO | train_inner | epoch 034:    779 / 1474 loss=0.731, trans_loss=4.955, nll_loss=2.139, w2v_ctc_loss=0.22, task_loss=1.473, contrastive_loss=0.103, total=4082.07, n_correct=2720.85, ppl=4.41, accuracy=66.654, wps=11687.9, ups=1.43, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.21, clip=0, loss_scale=16, train_wall=69, gb_free=15.5, wall=39371
2023-08-05 23:14:17 | INFO | train_inner | epoch 034:    879 / 1474 loss=0.732, trans_loss=4.948, nll_loss=2.13, w2v_ctc_loss=0.226, task_loss=1.477, contrastive_loss=0.06, total=4100.9, n_correct=2735.98, ppl=4.38, accuracy=66.717, wps=11660.9, ups=1.42, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.214, clip=0, loss_scale=16, train_wall=70, gb_free=12.1, wall=39442
2023-08-05 23:15:27 | INFO | train_inner | epoch 034:    979 / 1474 loss=0.73, trans_loss=4.947, nll_loss=2.13, w2v_ctc_loss=0.227, task_loss=1.374, contrastive_loss=0.056, total=4168.39, n_correct=2779.48, ppl=4.38, accuracy=66.68, wps=11871.6, ups=1.42, wpb=8336.8, bsz=311.9, num_updates=49600, lr=6.35001e-05, gnorm=0.204, clip=0, loss_scale=16, train_wall=70, gb_free=15.8, wall=39512
2023-08-05 23:16:36 | INFO | train_inner | epoch 034:   1079 / 1474 loss=0.73, trans_loss=4.951, nll_loss=2.135, w2v_ctc_loss=0.227, task_loss=1.355, contrastive_loss=0.041, total=4150.57, n_correct=2767.73, ppl=4.39, accuracy=66.683, wps=12046.1, ups=1.45, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.207, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=39581
2023-08-05 23:17:46 | INFO | train_inner | epoch 034:   1179 / 1474 loss=0.728, trans_loss=4.948, nll_loss=2.131, w2v_ctc_loss=0.224, task_loss=1.444, contrastive_loss=0.051, total=4098.77, n_correct=2734.08, ppl=4.38, accuracy=66.705, wps=11747, ups=1.43, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.208, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=39650
2023-08-05 23:18:56 | INFO | train_inner | epoch 034:   1279 / 1474 loss=0.731, trans_loss=4.946, nll_loss=2.128, w2v_ctc_loss=0.225, task_loss=1.407, contrastive_loss=0.037, total=4150.54, n_correct=2769.89, ppl=4.37, accuracy=66.736, wps=11886.7, ups=1.43, wpb=8301.1, bsz=301, num_updates=49900, lr=6.33089e-05, gnorm=0.209, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=39720
2023-08-05 23:20:06 | INFO | train_inner | epoch 034:   1379 / 1474 loss=0.732, trans_loss=4.951, nll_loss=2.136, w2v_ctc_loss=0.228, task_loss=1.34, contrastive_loss=0.099, total=4196.91, n_correct=2791.46, ppl=4.39, accuracy=66.512, wps=11918.2, ups=1.42, wpb=8393.8, bsz=321.4, num_updates=50000, lr=6.32456e-05, gnorm=0.206, clip=0, loss_scale=16, train_wall=70, gb_free=16, wall=39791
2023-08-05 23:20:06 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-05 23:20:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-05 23:20:31 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 1.467 | trans_loss 5.55 | nll_loss 2.819 | w2v_ctc_loss 0.461 | task_loss 4.62 | contrastive_loss 0.228 | total 4003.4 | n_correct 2489.4 | ppl 7.06 | accuracy 62.182 | uer 16.93 | wer 18.754 | raw_wer 18.754 | bleu 20.32 | wps 2060.7 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.51
2023-08-05 23:20:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-05 23:20:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_34_50000.pt
2023-08-05 23:20:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_34_50000.pt
2023-08-05 23:21:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0805_token_at/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.32) (writing took 51.51630608737469 seconds)
2023-08-05 23:21:23 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-05 23:21:23 | INFO | train | epoch 034 | loss 0.731 | trans_loss 4.941 | nll_loss 2.121 | w2v_ctc_loss 0.225 | task_loss 1.408 | contrastive_loss 0.076 | total 4133.04 | n_correct 2762.01 | ppl 4.35 | accuracy 66.828 | wps 10844.9 | ups 1.31 | wpb 8266.1 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.209 | clip 0 | loss_scale 16 | train_wall 958 | gb_free 16 | wall 39868
2023-08-05 23:21:23 | INFO | fairseq_cli.train | done training in 39817.0 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    raise EOFError
EOFError
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
