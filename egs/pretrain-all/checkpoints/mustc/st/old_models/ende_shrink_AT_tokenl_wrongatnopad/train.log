2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11307
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11307
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11307
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11307
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11307
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11307
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11307
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11307
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | initialized host capios as rank 1
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | initialized host capios as rank 4
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | initialized host capios as rank 5
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | initialized host capios as rank 3
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | initialized host capios as rank 6
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | initialized host capios as rank 2
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | initialized host capios as rank 0
2023-07-10 15:24:41 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-10 15:24:41 | INFO | fairseq.distributed.utils | initialized host capios as rank 7
2023-07-10 15:24:43 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_AT_tokenl', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11307', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_AT_tokenl', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='token', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='token', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='token', attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, simul_type=None, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_AT_tokenl', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/workspace/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/workspace/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-07-10 15:24:43 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-10 15:24:43 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-10 15:24:43 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-10 15:24:43 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-10 15:24:43 | INFO | root | load pretrained embeddings: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-10 15:24:48 | INFO | fairseq.tasks.hubert_pretraining | current directory is /workspace/fairseq-AT/egs/pretrain-all
2023-07-10 15:24:48 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-10 15:24:48 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-10 15:24:49 | INFO | root | load pretrained hubert
2023-07-10 15:24:51 | INFO | root | load pretrained embedding as ctc proj: /workspace/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-10 15:24:53 | INFO | root | load pretrained encoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-10 15:24:55 | INFO | root | load pretrained decoder: /workspace/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-10 15:24:55 | INFO | root | share the sematic adapter and textual encoder
2023-07-10 15:24:55 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1-4): 4 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5-6): 2 x Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0-11): 12 x TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0-5): 6 x TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-10 15:24:55 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-10 15:24:55 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-10 15:24:55 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-10 15:24:55 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-10 15:24:55 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-10 15:24:55 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-10 15:24:55 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 15:24:55 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 15:24:55 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-10 15:25:03 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-10 15:25:06 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-10 15:25:06 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-10 15:25:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-10 15:25:06 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 15:25:06 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 15:25:06 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 15:25:06 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 15:25:06 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 15:25:06 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 15:25:06 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 15:25:06 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-10 15:25:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-10 15:25:06 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-10 15:25:06 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-10 15:25:06 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-10 15:25:06 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-10 15:25:06 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-10 15:25:06 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-10 15:25:06 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 15:25:06 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/workspace/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-10 15:25:08 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-10 15:25:10 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-10 15:25:12 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-10 15:26:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 15:26:16 | INFO | fairseq.trainer | begin training epoch 1
2023-07-10 15:26:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 15:26:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-10 15:27:29 | INFO | train_inner | epoch 001:    101 / 1474 loss=8.858, trans_loss=5.64, nll_loss=4.216, w2v_ctc_loss=9.594, task_loss=1.761, contrastive_loss=3.31, total=4200.41, n_correct=212.12, ppl=18.58, accuracy=5.05, wps=19984.8, ups=1.59, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=0.398, clip=0, loss_scale=64, train_wall=65, gb_free=19, wall=142
2023-07-10 15:28:30 | INFO | train_inner | epoch 001:    201 / 1474 loss=7.921, trans_loss=5.44, nll_loss=4.026, w2v_ctc_loss=8.265, task_loss=1.735, contrastive_loss=3.286, total=4127.38, n_correct=250.38, ppl=16.29, accuracy=6.066, wps=20276.7, ups=1.64, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=1.55, clip=0, loss_scale=64, train_wall=60, gb_free=19.2, wall=203
2023-07-10 15:29:30 | INFO | train_inner | epoch 001:    301 / 1474 loss=4.942, trans_loss=5.407, nll_loss=4.044, w2v_ctc_loss=3.742, task_loss=1.819, contrastive_loss=3.201, total=4079.62, n_correct=249.18, ppl=16.49, accuracy=6.108, wps=20117, ups=1.65, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=1.974, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=264
2023-07-10 15:30:31 | INFO | train_inner | epoch 001:    401 / 1474 loss=4.425, trans_loss=5.455, nll_loss=4.123, w2v_ctc_loss=2.909, task_loss=1.571, contrastive_loss=3.236, total=4174.14, n_correct=232.52, ppl=17.42, accuracy=5.57, wps=20580.4, ups=1.65, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=1.279, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=324
2023-07-10 15:31:32 | INFO | train_inner | epoch 001:    501 / 1474 loss=4.238, trans_loss=5.453, nll_loss=4.129, w2v_ctc_loss=2.629, task_loss=1.423, contrastive_loss=3.23, total=4176.18, n_correct=217.41, ppl=17.49, accuracy=5.206, wps=20352.8, ups=1.63, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=0.611, clip=0, loss_scale=64, train_wall=61, gb_free=19.2, wall=386
2023-07-10 15:32:33 | INFO | train_inner | epoch 001:    601 / 1474 loss=4.146, trans_loss=5.482, nll_loss=4.171, w2v_ctc_loss=2.485, task_loss=1.335, contrastive_loss=3.282, total=4147.79, n_correct=214.36, ppl=18.01, accuracy=5.168, wps=20372.8, ups=1.65, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.315, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=446
2023-07-10 15:33:33 | INFO | train_inner | epoch 001:    701 / 1474 loss=4.062, trans_loss=5.469, nll_loss=4.162, w2v_ctc_loss=2.428, task_loss=1.365, contrastive_loss=3.031, total=4152.1, n_correct=229.97, ppl=17.91, accuracy=5.539, wps=20515.3, ups=1.66, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.258, clip=0, loss_scale=64, train_wall=60, gb_free=19.5, wall=507
2023-07-10 15:34:33 | INFO | train_inner | epoch 001:    801 / 1474 loss=3.953, trans_loss=5.424, nll_loss=4.109, w2v_ctc_loss=2.335, task_loss=1.3, contrastive_loss=2.93, total=4123.83, n_correct=254.53, ppl=17.26, accuracy=6.172, wps=20418.3, ups=1.66, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.36, clip=0, loss_scale=64, train_wall=60, gb_free=19.1, wall=567
2023-07-10 15:35:34 | INFO | train_inner | epoch 001:    901 / 1474 loss=3.845, trans_loss=5.403, nll_loss=4.1, w2v_ctc_loss=2.263, task_loss=1.31, contrastive_loss=2.674, total=4163.61, n_correct=279.24, ppl=17.15, accuracy=6.707, wps=20612.2, ups=1.66, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=627
2023-07-10 15:36:35 | INFO | train_inner | epoch 001:   1001 / 1474 loss=3.725, trans_loss=5.386, nll_loss=4.083, w2v_ctc_loss=2.16, task_loss=1.315, contrastive_loss=2.534, total=4135.34, n_correct=299.33, ppl=16.95, accuracy=7.238, wps=20215.3, ups=1.64, wpb=12363.9, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=0.638, clip=0, loss_scale=64, train_wall=61, gb_free=19, wall=688
2023-07-10 15:37:35 | INFO | train_inner | epoch 001:   1101 / 1474 loss=3.621, trans_loss=5.379, nll_loss=4.077, w2v_ctc_loss=2.082, task_loss=1.324, contrastive_loss=2.315, total=4147.38, n_correct=315.45, ppl=16.88, accuracy=7.606, wps=20469, ups=1.66, wpb=12356.9, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=0.735, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=749
2023-07-10 15:38:36 | INFO | train_inner | epoch 001:   1201 / 1474 loss=3.508, trans_loss=5.359, nll_loss=4.056, w2v_ctc_loss=1.997, task_loss=1.37, contrastive_loss=2.102, total=4139.9, n_correct=327.41, ppl=16.64, accuracy=7.909, wps=20518.7, ups=1.66, wpb=12386.7, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=0.717, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=809
2023-07-10 15:39:36 | INFO | train_inner | epoch 001:   1301 / 1474 loss=3.417, trans_loss=5.362, nll_loss=4.063, w2v_ctc_loss=1.915, task_loss=1.313, contrastive_loss=1.923, total=4046.58, n_correct=319.68, ppl=16.71, accuracy=7.9, wps=20140.6, ups=1.67, wpb=12092.5, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=0.735, clip=0, loss_scale=64, train_wall=60, gb_free=19.7, wall=869
2023-07-10 15:40:36 | INFO | train_inner | epoch 001:   1401 / 1474 loss=3.36, trans_loss=5.358, nll_loss=4.07, w2v_ctc_loss=1.85, task_loss=1.29, contrastive_loss=2.007, total=4133.18, n_correct=329.84, ppl=16.79, accuracy=7.98, wps=20352.6, ups=1.65, wpb=12300.7, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=0.804, clip=0, loss_scale=64, train_wall=60, gb_free=19.9, wall=930
2023-07-10 15:41:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-07-10 15:41:54 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 2.56 | trans_loss 10.957 | nll_loss 9.949 | w2v_ctc_loss 1.497 | task_loss 7.416 | contrastive_loss 2.325 | total 4003.4 | n_correct 370.3 | ppl 988.43 | accuracy 9.25 | uer 71.502 | wer 69.464 | raw_wer 69.464 | bleu 0.02 | wps 1458.8 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-10 15:41:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-10 15:41:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 15:41:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 15:41:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 4.7218111619586125 seconds)
2023-07-10 15:41:59 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-10 15:41:59 | INFO | train | epoch 001 | loss 4.513 | trans_loss 5.426 | nll_loss 4.1 | w2v_ctc_loss 3.261 | task_loss 1.435 | contrastive_loss 2.749 | total 4138.32 | n_correct 270.141 | ppl 17.15 | accuracy 6.528 | wps 19503.8 | ups 1.58 | wpb 12354.6 | bsz 458.3 | num_updates 1473 | lr 5.89905e-05 | gnorm 0.773 | clip 0 | loss_scale 64 | train_wall 891 | gb_free 19.2 | wall 1013
2023-07-10 15:41:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 15:41:59 | INFO | fairseq.trainer | begin training epoch 2
2023-07-10 15:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 15:42:23 | INFO | train_inner | epoch 002:     27 / 1474 loss=3.277, trans_loss=5.353, nll_loss=4.053, w2v_ctc_loss=1.764, task_loss=1.229, contrastive_loss=1.838, total=4162.95, n_correct=339.86, ppl=16.6, accuracy=8.164, wps=11623.3, ups=0.94, wpb=12414, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=0.68, clip=0, loss_scale=64, train_wall=60, gb_free=19.6, wall=1036
2023-07-10 15:43:23 | INFO | train_inner | epoch 002:    127 / 1474 loss=3.197, trans_loss=5.352, nll_loss=4.054, w2v_ctc_loss=1.706, task_loss=1.313, contrastive_loss=1.637, total=4155.98, n_correct=339.03, ppl=16.6, accuracy=8.158, wps=20620, ups=1.66, wpb=12390, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=0.694, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1097
2023-07-10 15:44:24 | INFO | train_inner | epoch 002:    227 / 1474 loss=3.132, trans_loss=5.324, nll_loss=4.022, w2v_ctc_loss=1.626, task_loss=1.137, contrastive_loss=1.667, total=4179.21, n_correct=348.92, ppl=16.24, accuracy=8.349, wps=20605.4, ups=1.65, wpb=12488.1, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=0.638, clip=0, loss_scale=64, train_wall=60, gb_free=19, wall=1157
2023-07-10 15:45:24 | INFO | train_inner | epoch 002:    327 / 1474 loss=3.056, trans_loss=5.327, nll_loss=4.021, w2v_ctc_loss=1.58, task_loss=1.307, contrastive_loss=1.379, total=4146.1, n_correct=351.3, ppl=16.23, accuracy=8.473, wps=20347.3, ups=1.64, wpb=12381, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=0.602, clip=0, loss_scale=64, train_wall=60, gb_free=18.8, wall=1218
2023-07-10 15:46:25 | INFO | train_inner | epoch 002:    427 / 1474 loss=2.984, trans_loss=5.315, nll_loss=4.011, w2v_ctc_loss=1.532, task_loss=1.435, contrastive_loss=1.201, total=4037.99, n_correct=343.89, ppl=16.12, accuracy=8.516, wps=20079.8, ups=1.66, wpb=12079.4, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=0.606, clip=0, loss_scale=64, train_wall=60, gb_free=18.9, wall=1278
2023-07-10 15:47:25 | INFO | train_inner | epoch 002:    527 / 1474 loss=2.965, trans_loss=5.312, nll_loss=4.002, w2v_ctc_loss=1.476, task_loss=1.247, contrastive_loss=1.305, total=4176.97, n_correct=362.11, ppl=16.02, accuracy=8.669, wps=20710.2, ups=1.66, wpb=12475.1, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=0.588, clip=0, loss_scale=64, train_wall=60, gb_free=19.6, wall=1338
2023-07-10 15:47:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 15:47:59 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 2.405 | trans_loss 10.82 | nll_loss 9.771 | w2v_ctc_loss 1.208 | task_loss 7.415 | contrastive_loss 1.647 | total 4003.4 | n_correct 395.7 | ppl 873.42 | accuracy 9.884 | uer 61.776 | wer 59.409 | raw_wer 59.409 | bleu 0.04 | wps 1431.7 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-07-10 15:47:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-10 15:47:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_2_2000.pt
2023-07-10 15:48:02 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_2_2000.pt
2023-07-10 15:48:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 9.292186114005744 seconds)
2023-07-10 15:49:08 | INFO | train_inner | epoch 002:    627 / 1474 loss=2.893, trans_loss=5.305, nll_loss=3.998, w2v_ctc_loss=1.426, task_loss=1.292, contrastive_loss=1.092, total=4126.49, n_correct=360.18, ppl=15.97, accuracy=8.728, wps=11869.3, ups=0.97, wpb=12299.1, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=0.488, clip=0, loss_scale=128, train_wall=59, gb_free=19.2, wall=1442
2023-07-10 15:50:09 | INFO | train_inner | epoch 002:    727 / 1474 loss=2.868, trans_loss=5.288, nll_loss=3.98, w2v_ctc_loss=1.391, task_loss=1.264, contrastive_loss=1.198, total=4149.06, n_correct=369.79, ppl=15.78, accuracy=8.913, wps=20613.8, ups=1.67, wpb=12372.9, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=0.494, clip=0, loss_scale=128, train_wall=60, gb_free=19.2, wall=1502
2023-07-10 15:51:09 | INFO | train_inner | epoch 002:    827 / 1474 loss=2.836, trans_loss=5.271, nll_loss=3.957, w2v_ctc_loss=1.364, task_loss=1.298, contrastive_loss=1.145, total=4175.4, n_correct=379.06, ppl=15.53, accuracy=9.078, wps=20557.6, ups=1.65, wpb=12477.6, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=0.438, clip=0, loss_scale=128, train_wall=60, gb_free=19.8, wall=1563
2023-07-10 15:52:10 | INFO | train_inner | epoch 002:    927 / 1474 loss=2.791, trans_loss=5.259, nll_loss=3.943, w2v_ctc_loss=1.321, task_loss=1.324, contrastive_loss=1.126, total=4104.2, n_correct=377.02, ppl=15.38, accuracy=9.186, wps=20295.2, ups=1.66, wpb=12243.8, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=0.429, clip=0, loss_scale=128, train_wall=60, gb_free=19, wall=1623
2023-07-10 15:53:09 | INFO | train_inner | epoch 002:   1027 / 1474 loss=2.758, trans_loss=5.256, nll_loss=3.937, w2v_ctc_loss=1.289, task_loss=1.287, contrastive_loss=0.983, total=4102.5, n_correct=379.02, ppl=15.32, accuracy=9.239, wps=20464.5, ups=1.67, wpb=12270.3, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.391, clip=0, loss_scale=128, train_wall=60, gb_free=19.2, wall=1683
2023-07-10 15:54:11 | INFO | train_inner | epoch 002:   1127 / 1474 loss=2.755, trans_loss=5.245, nll_loss=3.926, w2v_ctc_loss=1.262, task_loss=1.169, contrastive_loss=1.194, total=4187.61, n_correct=395.71, ppl=15.2, accuracy=9.45, wps=20391.8, ups=1.63, wpb=12484.3, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.359, clip=0, loss_scale=128, train_wall=61, gb_free=19.5, wall=1744
2023-07-10 15:55:12 | INFO | train_inner | epoch 002:   1227 / 1474 loss=2.725, trans_loss=5.238, nll_loss=3.917, w2v_ctc_loss=1.239, task_loss=1.178, contrastive_loss=1.116, total=4221.06, n_correct=407.24, ppl=15.11, accuracy=9.648, wps=20696.1, ups=1.64, wpb=12590.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.352, clip=0, loss_scale=128, train_wall=60, gb_free=19.4, wall=1805
2023-07-10 15:56:12 | INFO | train_inner | epoch 002:   1327 / 1474 loss=2.673, trans_loss=5.224, nll_loss=3.903, w2v_ctc_loss=1.218, task_loss=1.241, contrastive_loss=0.831, total=4157.86, n_correct=407.59, ppl=14.96, accuracy=9.803, wps=20576.6, ups=1.66, wpb=12422.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.335, clip=0, loss_scale=128, train_wall=60, gb_free=19.5, wall=1865
2023-07-10 15:57:13 | INFO | train_inner | epoch 002:   1427 / 1474 loss=2.651, trans_loss=5.221, nll_loss=3.895, w2v_ctc_loss=1.196, task_loss=1.394, contrastive_loss=0.917, total=4054.34, n_correct=397.64, ppl=14.87, accuracy=9.808, wps=19749, ups=1.63, wpb=12128.6, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.316, clip=0, loss_scale=128, train_wall=61, gb_free=19.4, wall=1927
2023-07-10 15:57:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 15:58:16 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 2.19 | trans_loss 10.274 | nll_loss 9.083 | w2v_ctc_loss 0.96 | task_loss 7.415 | contrastive_loss 0.98 | total 4003.4 | n_correct 506.1 | ppl 542.14 | accuracy 12.642 | uer 51.374 | wer 50.405 | raw_wer 50.405 | bleu 0.12 | wps 1445.7 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.12
2023-07-10 15:58:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-10 15:58:16 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 15:58:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 15:58:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.12) (writing took 8.36731179797789 seconds)
2023-07-10 15:58:24 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-10 15:58:24 | INFO | train | epoch 002 | loss 2.877 | trans_loss 5.281 | nll_loss 3.968 | w2v_ctc_loss 1.402 | task_loss 1.274 | contrastive_loss 1.202 | total 4138.65 | n_correct 372.993 | ppl 15.65 | accuracy 9.012 | wps 18490.3 | ups 1.5 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 0.48 | clip 0 | loss_scale 128 | train_wall 885 | gb_free 19.3 | wall 1998
2023-07-10 15:58:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 15:58:24 | INFO | fairseq.trainer | begin training epoch 3
2023-07-10 15:58:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 15:59:04 | INFO | train_inner | epoch 003:     53 / 1474 loss=2.628, trans_loss=5.202, nll_loss=3.873, w2v_ctc_loss=1.177, task_loss=1.304, contrastive_loss=0.815, total=4071.2, n_correct=412.5, ppl=14.65, accuracy=10.132, wps=10971.2, ups=0.9, wpb=12148.3, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.305, clip=0, loss_scale=128, train_wall=60, gb_free=19.1, wall=2038
2023-07-10 15:59:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-10 15:59:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-10 15:59:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 15:59:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-10 15:59:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-10 16:00:34 | INFO | train_inner | epoch 003:    158 / 1474 loss=2.793, trans_loss=4.467, nll_loss=2.912, w2v_ctc_loss=1.253, task_loss=0.741, contrastive_loss=0.687, total=4144.18, n_correct=1070.45, ppl=7.53, accuracy=25.83, wps=13731.3, ups=1.11, wpb=12381.7, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=0.894, clip=0, loss_scale=4, train_wall=90, gb_free=16.7, wall=2128
2023-07-10 16:02:02 | INFO | train_inner | epoch 003:    258 / 1474 loss=2.581, trans_loss=4.188, nll_loss=2.544, w2v_ctc_loss=1.117, task_loss=0.751, contrastive_loss=0.601, total=4161.13, n_correct=1381.13, ppl=5.83, accuracy=33.191, wps=14220, ups=1.14, wpb=12444.3, bsz=467, num_updates=3200, lr=0.000128036, gnorm=0.592, clip=0, loss_scale=4, train_wall=87, gb_free=17.3, wall=2215
2023-07-10 16:03:28 | INFO | train_inner | epoch 003:    358 / 1474 loss=2.506, trans_loss=4.097, nll_loss=2.424, w2v_ctc_loss=1.062, task_loss=0.754, contrastive_loss=0.632, total=4150.02, n_correct=1502.43, ppl=5.37, accuracy=36.203, wps=14283.5, ups=1.15, wpb=12369, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=0.588, clip=0, loss_scale=4, train_wall=86, gb_free=17.3, wall=2302
2023-07-10 16:04:56 | INFO | train_inner | epoch 003:    458 / 1474 loss=2.432, trans_loss=4.019, nll_loss=2.324, w2v_ctc_loss=1.015, task_loss=0.731, contrastive_loss=0.49, total=4209.57, n_correct=1637.98, ppl=5.01, accuracy=38.911, wps=14345.1, ups=1.14, wpb=12537.6, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=0.544, clip=0, loss_scale=4, train_wall=87, gb_free=16.2, wall=2389
2023-07-10 16:06:22 | INFO | train_inner | epoch 003:    558 / 1474 loss=2.376, trans_loss=3.98, nll_loss=2.267, w2v_ctc_loss=0.967, task_loss=0.803, contrastive_loss=0.457, total=4088.48, n_correct=1658.15, ppl=4.81, accuracy=40.557, wps=14148.7, ups=1.16, wpb=12237.1, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=0.522, clip=0, loss_scale=4, train_wall=86, gb_free=17.8, wall=2476
2023-07-10 16:07:51 | INFO | train_inner | epoch 003:    658 / 1474 loss=2.341, trans_loss=3.933, nll_loss=2.207, w2v_ctc_loss=0.935, task_loss=0.719, contrastive_loss=0.566, total=4221.58, n_correct=1790.78, ppl=4.62, accuracy=42.42, wps=14187.5, ups=1.13, wpb=12558.6, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=0.497, clip=0, loss_scale=4, train_wall=88, gb_free=16.5, wall=2564
2023-07-10 16:09:17 | INFO | train_inner | epoch 003:    758 / 1474 loss=2.296, trans_loss=3.901, nll_loss=2.166, w2v_ctc_loss=0.915, task_loss=0.719, contrastive_loss=0.331, total=4167.41, n_correct=1811.07, ppl=4.49, accuracy=43.458, wps=14459.4, ups=1.16, wpb=12462.8, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=0.499, clip=0, loss_scale=4, train_wall=86, gb_free=16.5, wall=2651
2023-07-10 16:10:44 | INFO | train_inner | epoch 003:    858 / 1474 loss=2.274, trans_loss=3.881, nll_loss=2.138, w2v_ctc_loss=0.894, task_loss=0.759, contrastive_loss=0.296, total=4165.53, n_correct=1843.2, ppl=4.4, accuracy=44.249, wps=14310.4, ups=1.15, wpb=12445.3, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=0.476, clip=0, loss_scale=4, train_wall=87, gb_free=17.2, wall=2738
2023-07-10 16:12:28 | INFO | train_inner | epoch 003:    958 / 1474 loss=2.26, trans_loss=3.855, nll_loss=2.105, w2v_ctc_loss=0.884, task_loss=0.729, contrastive_loss=0.33, total=4162.3, n_correct=1889.1, ppl=4.3, accuracy=45.386, wps=11886.8, ups=0.96, wpb=12408.5, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=0.479, clip=0, loss_scale=4, train_wall=86, gb_free=16.9, wall=2842
2023-07-10 16:13:55 | INFO | train_inner | epoch 003:   1058 / 1474 loss=2.243, trans_loss=3.846, nll_loss=2.093, w2v_ctc_loss=0.874, task_loss=0.803, contrastive_loss=0.287, total=4069.95, n_correct=1866.33, ppl=4.27, accuracy=45.856, wps=14025.7, ups=1.15, wpb=12168.2, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=0.476, clip=0, loss_scale=4, train_wall=86, gb_free=16.5, wall=2929
2023-07-10 16:13:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 16:14:28 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 2.184 | trans_loss 6.446 | nll_loss 4.001 | w2v_ctc_loss 0.859 | task_loss 3.385 | contrastive_loss 0.411 | total 4003.4 | n_correct 1932.6 | ppl 16.01 | accuracy 48.274 | uer 29.358 | wer 30.092 | raw_wer 30.092 | bleu 6.98 | wps 1529.9 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 6.98
2023-07-10 16:14:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-10 16:14:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_3_4000.pt
2023-07-10 16:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_3_4000.pt
2023-07-10 16:14:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 6.98) (writing took 9.22826033696765 seconds)
2023-07-10 16:16:03 | INFO | train_inner | epoch 003:   1158 / 1474 loss=2.223, trans_loss=3.837, nll_loss=2.081, w2v_ctc_loss=0.854, task_loss=0.817, contrastive_loss=0.265, total=4038.49, n_correct=1868.04, ppl=4.23, accuracy=46.256, wps=9453.2, ups=0.78, wpb=12064, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=0.466, clip=0, loss_scale=4, train_wall=85, gb_free=16.6, wall=3056
2023-07-10 16:17:29 | INFO | train_inner | epoch 003:   1258 / 1474 loss=2.208, trans_loss=3.819, nll_loss=2.058, w2v_ctc_loss=0.838, task_loss=0.8, contrastive_loss=0.25, total=4064.31, n_correct=1914.22, ppl=4.16, accuracy=47.098, wps=14131.5, ups=1.16, wpb=12147.9, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.456, clip=0, loss_scale=4, train_wall=86, gb_free=17.5, wall=3142
2023-07-10 16:18:56 | INFO | train_inner | epoch 003:   1358 / 1474 loss=2.199, trans_loss=3.798, nll_loss=2.034, w2v_ctc_loss=0.828, task_loss=0.765, contrastive_loss=0.367, total=4134.58, n_correct=1970.1, ppl=4.1, accuracy=47.649, wps=14151.3, ups=1.15, wpb=12326.9, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.466, clip=0, loss_scale=4, train_wall=87, gb_free=17.9, wall=3229
2023-07-10 16:20:23 | INFO | train_inner | epoch 003:   1458 / 1474 loss=2.18, trans_loss=3.783, nll_loss=2.014, w2v_ctc_loss=0.811, task_loss=0.715, contrastive_loss=0.343, total=4209.94, n_correct=2032.26, ppl=4.04, accuracy=48.273, wps=14410, ups=1.15, wpb=12573.7, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.453, clip=0, loss_scale=4, train_wall=87, gb_free=17.2, wall=3317
2023-07-10 16:20:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 16:21:08 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 2.117 | trans_loss 6.299 | nll_loss 3.807 | w2v_ctc_loss 0.771 | task_loss 3.372 | contrastive_loss 0.378 | total 4003.4 | n_correct 2028.7 | ppl 13.99 | accuracy 50.674 | uer 27.704 | wer 28.403 | raw_wer 28.403 | bleu 8.67 | wps 1575.3 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 8.67
2023-07-10 16:21:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-10 16:21:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 16:21:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 16:21:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 3 @ 4416 updates, score 8.67) (writing took 8.373401923978236 seconds)
2023-07-10 16:21:17 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-10 16:21:17 | INFO | train | epoch 003 | loss 2.362 | trans_loss 4.001 | nll_loss 2.297 | w2v_ctc_loss 0.955 | task_loss 0.776 | contrastive_loss 0.439 | total 4140.05 | n_correct 1685.83 | ppl 4.92 | accuracy 40.72 | wps 13226.1 | ups 1.07 | wpb 12360.2 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 0.52 | clip 0 | loss_scale 4 | train_wall 1259 | gb_free 16.8 | wall 3370
2023-07-10 16:21:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 16:21:17 | INFO | fairseq.trainer | begin training epoch 4
2023-07-10 16:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 16:22:37 | INFO | train_inner | epoch 004:     84 / 1474 loss=2.144, trans_loss=3.756, nll_loss=1.979, w2v_ctc_loss=0.792, task_loss=0.783, contrastive_loss=0.201, total=4099.41, n_correct=2008.45, ppl=3.94, accuracy=48.994, wps=9104.5, ups=0.75, wpb=12215.8, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.442, clip=0, loss_scale=4, train_wall=86, gb_free=16.6, wall=3451
2023-07-10 16:24:03 | INFO | train_inner | epoch 004:    184 / 1474 loss=2.129, trans_loss=3.739, nll_loss=1.954, w2v_ctc_loss=0.778, task_loss=0.717, contrastive_loss=0.226, total=4175.15, n_correct=2078.13, ppl=3.87, accuracy=49.774, wps=14557.1, ups=1.17, wpb=12466.1, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.448, clip=0, loss_scale=4, train_wall=85, gb_free=16.8, wall=3536
2023-07-10 16:25:31 | INFO | train_inner | epoch 004:    284 / 1474 loss=2.14, trans_loss=3.739, nll_loss=1.956, w2v_ctc_loss=0.778, task_loss=0.758, contrastive_loss=0.352, total=4145.23, n_correct=2062.69, ppl=3.88, accuracy=49.761, wps=14106.2, ups=1.14, wpb=12387.3, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.44, clip=0, loss_scale=4, train_wall=87, gb_free=16.1, wall=3624
2023-07-10 16:26:57 | INFO | train_inner | epoch 004:    384 / 1474 loss=2.123, trans_loss=3.739, nll_loss=1.955, w2v_ctc_loss=0.771, task_loss=0.786, contrastive_loss=0.196, total=4127.66, n_correct=2062.29, ppl=3.88, accuracy=49.963, wps=14234.3, ups=1.16, wpb=12298.8, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.439, clip=0, loss_scale=4, train_wall=86, gb_free=17.6, wall=3711
2023-07-10 16:28:24 | INFO | train_inner | epoch 004:    484 / 1474 loss=2.136, trans_loss=3.72, nll_loss=1.934, w2v_ctc_loss=0.752, task_loss=0.686, contrastive_loss=0.593, total=4218.78, n_correct=2133.99, ppl=3.82, accuracy=50.583, wps=14410.3, ups=1.15, wpb=12578.2, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.433, clip=0, loss_scale=4, train_wall=87, gb_free=16.7, wall=3798
2023-07-10 16:29:51 | INFO | train_inner | epoch 004:    584 / 1474 loss=2.108, trans_loss=3.718, nll_loss=1.93, w2v_ctc_loss=0.762, task_loss=0.715, contrastive_loss=0.268, total=4217.52, n_correct=2139.1, ppl=3.81, accuracy=50.719, wps=14492.9, ups=1.15, wpb=12583.6, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.431, clip=0, loss_scale=4, train_wall=86, gb_free=16.3, wall=3885
tensor(0.8523, device='cuda:0')
tensor(0.8223, device='cuda:0')
2023-07-10 16:31:19 | INFO | train_inner | epoch 004:    684 / 1474 loss=2.111, trans_loss=3.722, nll_loss=1.931, w2v_ctc_loss=0.75, task_loss=0.778, contrastive_loss=0.318, total=4176.39, n_correct=2125.77, ppl=3.81, accuracy=50.9, wps=14101.1, ups=1.13, wpb=12440.1, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.373, clip=0, loss_scale=8, train_wall=88, gb_free=17.2, wall=3973
2023-07-10 16:32:46 | INFO | train_inner | epoch 004:    784 / 1474 loss=2.098, trans_loss=3.716, nll_loss=1.924, w2v_ctc_loss=0.751, task_loss=0.84, contrastive_loss=0.188, total=4026.63, n_correct=2054.12, ppl=3.79, accuracy=51.013, wps=13881.8, ups=1.15, wpb=12049.9, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.374, clip=0, loss_scale=8, train_wall=86, gb_free=13.5, wall=4060
2023-07-10 16:34:14 | INFO | train_inner | epoch 004:    884 / 1474 loss=2.099, trans_loss=3.7, nll_loss=1.909, w2v_ctc_loss=0.743, task_loss=0.758, contrastive_loss=0.367, total=4186.04, n_correct=2157.53, ppl=3.76, accuracy=51.541, wps=14221.3, ups=1.14, wpb=12493.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.37, clip=0, loss_scale=8, train_wall=87, gb_free=17.8, wall=4148
2023-07-10 16:35:41 | INFO | train_inner | epoch 004:    984 / 1474 loss=2.078, trans_loss=3.693, nll_loss=1.899, w2v_ctc_loss=0.732, task_loss=0.768, contrastive_loss=0.229, total=4125.02, n_correct=2139.94, ppl=3.73, accuracy=51.877, wps=14176.2, ups=1.15, wpb=12319.9, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.367, clip=0, loss_scale=8, train_wall=86, gb_free=13.1, wall=4235
2023-07-10 16:37:08 | INFO | train_inner | epoch 004:   1084 / 1474 loss=2.086, trans_loss=3.699, nll_loss=1.905, w2v_ctc_loss=0.738, task_loss=0.818, contrastive_loss=0.206, total=4075.6, n_correct=2113.4, ppl=3.74, accuracy=51.855, wps=14039.3, ups=1.15, wpb=12166.1, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.367, clip=0, loss_scale=8, train_wall=86, gb_free=16.2, wall=4321
2023-07-10 16:38:34 | INFO | train_inner | epoch 004:   1184 / 1474 loss=2.083, trans_loss=3.69, nll_loss=1.894, w2v_ctc_loss=0.726, task_loss=0.712, contrastive_loss=0.316, total=4161.18, n_correct=2176.9, ppl=3.72, accuracy=52.314, wps=14389.8, ups=1.16, wpb=12451.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.363, clip=0, loss_scale=8, train_wall=86, gb_free=16.9, wall=4408
2023-07-10 16:40:01 | INFO | train_inner | epoch 004:   1284 / 1474 loss=2.074, trans_loss=3.684, nll_loss=1.887, w2v_ctc_loss=0.72, task_loss=0.727, contrastive_loss=0.278, total=4156.53, n_correct=2190.56, ppl=3.7, accuracy=52.702, wps=14397.4, ups=1.16, wpb=12424.6, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.364, clip=0, loss_scale=8, train_wall=86, gb_free=16.2, wall=4494
2023-07-10 16:41:26 | INFO | train_inner | epoch 004:   1384 / 1474 loss=2.06, trans_loss=3.68, nll_loss=1.882, w2v_ctc_loss=0.721, task_loss=0.783, contrastive_loss=0.159, total=4101.23, n_correct=2159.48, ppl=3.69, accuracy=52.654, wps=14380, ups=1.17, wpb=12255, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.35, clip=0, loss_scale=8, train_wall=85, gb_free=15.9, wall=4579
2023-07-10 16:42:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.8523, device='cuda:5')
tensor(0.8223, device='cuda:5')
tensor(0.8523, device='cuda:6')
tensor(0.8223, device='cuda:6')
tensor(0.8523, device='cuda:4')
tensor(0.8223, device='cuda:4')
tensor(0.8523, device='cuda:2')
tensor(0.8223, device='cuda:2')
tensor(0.8523, device='cuda:3')
tensor(0.8223, device='cuda:3')
tensor(0.8523, device='cuda:1')
tensor(0.8223, device='cuda:1')
tensor(0.8523, device='cuda:7')
tensor(0.8223, device='cuda:7')
2023-07-10 16:43:13 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 1.922 | trans_loss 5.953 | nll_loss 3.343 | w2v_ctc_loss 0.654 | task_loss 3.543 | contrastive_loss 0.309 | total 4003.4 | n_correct 2241.2 | ppl 10.15 | accuracy 55.982 | uer 22.586 | wer 24.026 | raw_wer 24.026 | bleu 13.7 | wps 1752.9 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 13.7
2023-07-10 16:43:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-10 16:43:13 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 16:43:17 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 16:43:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 4 @ 5890 updates, score 13.7) (writing took 8.477897960983682 seconds)
2023-07-10 16:43:21 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-10 16:43:21 | INFO | train | epoch 004 | loss 2.101 | trans_loss 3.711 | nll_loss 1.92 | w2v_ctc_loss 0.748 | task_loss 0.759 | contrastive_loss 0.277 | total 4138.65 | n_correct 2118.57 | ppl 3.79 | accuracy 51.19 | wps 13752 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.394 | clip 0 | loss_scale 8 | train_wall 1272 | gb_free 15 | wall 4695
2023-07-10 16:43:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 16:43:21 | INFO | fairseq.trainer | begin training epoch 5
2023-07-10 16:43:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 16:43:37 | INFO | train_inner | epoch 005:     10 / 1474 loss=2.055, trans_loss=3.673, nll_loss=1.873, w2v_ctc_loss=0.71, task_loss=0.789, contrastive_loss=0.177, total=4037.7, n_correct=2140.71, ppl=3.66, accuracy=53.018, wps=9171.5, ups=0.76, wpb=12062.8, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.362, clip=0, loss_scale=8, train_wall=85, gb_free=17, wall=4711
2023-07-10 16:45:04 | INFO | train_inner | epoch 005:    110 / 1474 loss=2.002, trans_loss=3.62, nll_loss=1.805, w2v_ctc_loss=0.665, task_loss=0.685, contrastive_loss=0.184, total=4247.37, n_correct=2317.41, ppl=3.49, accuracy=54.561, wps=14581.6, ups=1.15, wpb=12683.8, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.339, clip=0, loss_scale=8, train_wall=87, gb_free=16.9, wall=4798
2023-07-10 16:45:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 16:45:34 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 1.899 | trans_loss 5.914 | nll_loss 3.287 | w2v_ctc_loss 0.634 | task_loss 3.555 | contrastive_loss 0.301 | total 4003.4 | n_correct 2260.2 | ppl 9.76 | accuracy 56.457 | uer 22.045 | wer 23.556 | raw_wer 23.556 | bleu 15.25 | wps 1765 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 15.25
2023-07-10 16:45:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-10 16:45:34 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_5_6000.pt
2023-07-10 16:45:36 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_5_6000.pt
2023-07-10 16:45:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 15.25) (writing took 9.254027177987155 seconds)
2023-07-10 16:47:09 | INFO | train_inner | epoch 005:    210 / 1474 loss=2.025, trans_loss=3.629, nll_loss=1.815, w2v_ctc_loss=0.674, task_loss=0.701, contrastive_loss=0.407, total=4189.85, n_correct=2274.42, ppl=3.52, accuracy=54.284, wps=10026.2, ups=0.8, wpb=12492.8, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.343, clip=0, loss_scale=8, train_wall=86, gb_free=17.9, wall=4922
2023-07-10 16:48:35 | INFO | train_inner | epoch 005:    310 / 1474 loss=2.023, trans_loss=3.629, nll_loss=1.818, w2v_ctc_loss=0.685, task_loss=0.777, contrastive_loss=0.253, total=4090.1, n_correct=2212.8, ppl=3.53, accuracy=54.101, wps=14242, ups=1.16, wpb=12240, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.354, clip=0, loss_scale=8, train_wall=86, gb_free=16.4, wall=5008
2023-07-10 16:50:02 | INFO | train_inner | epoch 005:    410 / 1474 loss=2.015, trans_loss=3.622, nll_loss=1.812, w2v_ctc_loss=0.665, task_loss=0.733, contrastive_loss=0.339, total=4147.17, n_correct=2261.23, ppl=3.51, accuracy=54.525, wps=14277.6, ups=1.15, wpb=12381.8, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.353, clip=0, loss_scale=8, train_wall=86, gb_free=15.1, wall=5095
2023-07-10 16:51:28 | INFO | train_inner | epoch 005:    510 / 1474 loss=2.006, trans_loss=3.636, nll_loss=1.823, w2v_ctc_loss=0.671, task_loss=0.857, contrastive_loss=0.133, total=4026.81, n_correct=2183.68, ppl=3.54, accuracy=54.229, wps=13939.4, ups=1.16, wpb=12047.2, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.35, clip=0, loss_scale=8, train_wall=86, gb_free=17.5, wall=5182
2023-07-10 16:52:55 | INFO | train_inner | epoch 005:    610 / 1474 loss=2.019, trans_loss=3.632, nll_loss=1.819, w2v_ctc_loss=0.666, task_loss=0.782, contrastive_loss=0.313, total=4107.75, n_correct=2228, ppl=3.53, accuracy=54.239, wps=14010.6, ups=1.14, wpb=12245.3, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.361, clip=0, loss_scale=8, train_wall=87, gb_free=16.3, wall=5269
2023-07-10 16:54:22 | INFO | train_inner | epoch 005:    710 / 1474 loss=2.007, trans_loss=3.623, nll_loss=1.809, w2v_ctc_loss=0.668, task_loss=0.722, contrastive_loss=0.285, total=4178.85, n_correct=2281.91, ppl=3.5, accuracy=54.606, wps=14341.1, ups=1.15, wpb=12462.3, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.352, clip=0, loss_scale=8, train_wall=86, gb_free=17.8, wall=5356
2023-07-10 16:55:50 | INFO | train_inner | epoch 005:    810 / 1474 loss=2.003, trans_loss=3.627, nll_loss=1.813, w2v_ctc_loss=0.662, task_loss=0.784, contrastive_loss=0.208, total=4127.73, n_correct=2255.95, ppl=3.51, accuracy=54.654, wps=14087.5, ups=1.14, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.343, clip=0, loss_scale=8, train_wall=87, gb_free=15.4, wall=5443
2023-07-10 16:57:17 | INFO | train_inner | epoch 005:    910 / 1474 loss=1.995, trans_loss=3.62, nll_loss=1.806, w2v_ctc_loss=0.657, task_loss=0.786, contrastive_loss=0.167, total=4095.48, n_correct=2245.26, ppl=3.5, accuracy=54.823, wps=14104, ups=1.15, wpb=12237.9, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.344, clip=0, loss_scale=8, train_wall=86, gb_free=15.8, wall=5530
2023-07-10 16:58:43 | INFO | train_inner | epoch 005:   1010 / 1474 loss=2.006, trans_loss=3.623, nll_loss=1.81, w2v_ctc_loss=0.663, task_loss=0.751, contrastive_loss=0.251, total=4165.12, n_correct=2287.52, ppl=3.51, accuracy=54.921, wps=14401.7, ups=1.16, wpb=12426.3, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.34, clip=0, loss_scale=8, train_wall=86, gb_free=15.9, wall=5616
2023-07-10 17:00:10 | INFO | train_inner | epoch 005:   1110 / 1474 loss=2.006, trans_loss=3.621, nll_loss=1.805, w2v_ctc_loss=0.66, task_loss=0.753, contrastive_loss=0.25, total=4176.72, n_correct=2303.25, ppl=3.49, accuracy=55.145, wps=14217.6, ups=1.14, wpb=12467.3, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.338, clip=0, loss_scale=8, train_wall=87, gb_free=16.9, wall=5704
2023-07-10 17:01:37 | INFO | train_inner | epoch 005:   1210 / 1474 loss=1.989, trans_loss=3.62, nll_loss=1.805, w2v_ctc_loss=0.651, task_loss=0.775, contrastive_loss=0.153, total=4164.13, n_correct=2299.16, ppl=3.49, accuracy=55.213, wps=14278.8, ups=1.15, wpb=12416.1, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.341, clip=0, loss_scale=16, train_wall=87, gb_free=17.1, wall=5791
2023-07-10 17:03:04 | INFO | train_inner | epoch 005:   1310 / 1474 loss=1.98, trans_loss=3.616, nll_loss=1.799, w2v_ctc_loss=0.644, task_loss=0.773, contrastive_loss=0.125, total=4134.91, n_correct=2288.36, ppl=3.48, accuracy=55.342, wps=14199.2, ups=1.15, wpb=12356.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.335, clip=0, loss_scale=16, train_wall=87, gb_free=16.6, wall=5878
2023-07-10 17:04:31 | INFO | train_inner | epoch 005:   1410 / 1474 loss=1.985, trans_loss=3.611, nll_loss=1.797, w2v_ctc_loss=0.647, task_loss=0.763, contrastive_loss=0.186, total=4134.37, n_correct=2278.66, ppl=3.48, accuracy=55.115, wps=14263.4, ups=1.16, wpb=12339.9, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.337, clip=0, loss_scale=16, train_wall=86, gb_free=17.9, wall=5965
2023-07-10 17:05:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 17:05:56 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 1.874 | trans_loss 5.854 | nll_loss 3.215 | w2v_ctc_loss 0.598 | task_loss 3.546 | contrastive_loss 0.286 | total 4003.4 | n_correct 2304.1 | ppl 9.28 | accuracy 57.554 | uer 21.344 | wer 23.012 | raw_wer 23.012 | bleu 15.66 | wps 1769.7 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 15.66
2023-07-10 17:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-10 17:05:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 17:06:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 17:06:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 5 @ 7364 updates, score 15.66) (writing took 8.185385548043996 seconds)
2023-07-10 17:06:04 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-10 17:06:04 | INFO | train | epoch 005 | loss 2.003 | trans_loss 3.623 | nll_loss 1.809 | w2v_ctc_loss 0.662 | task_loss 0.76 | contrastive_loss 0.233 | total 4138.65 | n_correct 2265.06 | ppl 3.5 | accuracy 54.729 | wps 13360.8 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.345 | clip 0 | loss_scale 16 | train_wall 1273 | gb_free 16.4 | wall 6058
2023-07-10 17:06:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 17:06:05 | INFO | fairseq.trainer | begin training epoch 6
2023-07-10 17:06:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 17:06:44 | INFO | train_inner | epoch 006:     36 / 1474 loss=1.968, trans_loss=3.594, nll_loss=1.772, w2v_ctc_loss=0.636, task_loss=0.779, contrastive_loss=0.182, total=4115.45, n_correct=2303.21, ppl=3.41, accuracy=55.965, wps=9249.2, ups=0.75, wpb=12279.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.342, clip=0, loss_scale=16, train_wall=87, gb_free=16.6, wall=6097
2023-07-10 17:08:10 | INFO | train_inner | epoch 006:    136 / 1474 loss=1.941, trans_loss=3.568, nll_loss=1.738, w2v_ctc_loss=0.609, task_loss=0.76, contrastive_loss=0.228, total=4154.25, n_correct=2347.14, ppl=3.34, accuracy=56.5, wps=14318.4, ups=1.15, wpb=12409.6, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.335, clip=0, loss_scale=16, train_wall=86, gb_free=15.7, wall=6184
2023-07-10 17:09:38 | INFO | train_inner | epoch 006:    236 / 1474 loss=1.955, trans_loss=3.578, nll_loss=1.753, w2v_ctc_loss=0.63, task_loss=0.816, contrastive_loss=0.136, total=4112.66, n_correct=2306.49, ppl=3.37, accuracy=56.083, wps=14096.8, ups=1.15, wpb=12281.7, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.336, clip=0, loss_scale=16, train_wall=87, gb_free=16.3, wall=6271
2023-07-10 17:11:06 | INFO | train_inner | epoch 006:    336 / 1474 loss=1.965, trans_loss=3.567, nll_loss=1.74, w2v_ctc_loss=0.609, task_loss=0.704, contrastive_loss=0.441, total=4177.51, n_correct=2362.69, ppl=3.34, accuracy=56.557, wps=14048.6, ups=1.13, wpb=12463.7, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.339, clip=0, loss_scale=16, train_wall=88, gb_free=16.3, wall=6360
2023-07-10 17:12:32 | INFO | train_inner | epoch 006:    436 / 1474 loss=1.939, trans_loss=3.57, nll_loss=1.743, w2v_ctc_loss=0.609, task_loss=0.729, contrastive_loss=0.152, total=4154.57, n_correct=2354.34, ppl=3.35, accuracy=56.669, wps=14405, ups=1.16, wpb=12407.2, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.331, clip=0, loss_scale=16, train_wall=86, gb_free=16.3, wall=6446
2023-07-10 17:13:59 | INFO | train_inner | epoch 006:    536 / 1474 loss=1.942, trans_loss=3.571, nll_loss=1.744, w2v_ctc_loss=0.616, task_loss=0.767, contrastive_loss=0.137, total=4167.79, n_correct=2361.19, ppl=3.35, accuracy=56.653, wps=14320.4, ups=1.15, wpb=12419.2, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.333, clip=0, loss_scale=16, train_wall=86, gb_free=15.9, wall=6533
2023-07-10 17:15:25 | INFO | train_inner | epoch 006:    636 / 1474 loss=1.941, trans_loss=3.574, nll_loss=1.745, w2v_ctc_loss=0.606, task_loss=0.72, contrastive_loss=0.193, total=4146.17, n_correct=2351.08, ppl=3.35, accuracy=56.705, wps=14354.6, ups=1.16, wpb=12395.5, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.332, clip=0, loss_scale=16, train_wall=86, gb_free=16.7, wall=6619
2023-07-10 17:15:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 17:15:54 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 1.837 | trans_loss 5.804 | nll_loss 3.147 | w2v_ctc_loss 0.579 | task_loss 3.601 | contrastive_loss 0.27 | total 4003.4 | n_correct 2330.3 | ppl 8.86 | accuracy 58.208 | uer 20.158 | wer 21.89 | raw_wer 21.89 | bleu 16.22 | wps 1879.5 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 16.22
2023-07-10 17:15:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-10 17:15:54 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_6_8000.pt
2023-07-10 17:15:56 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_6_8000.pt
2023-07-10 17:16:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 16.22) (writing took 9.438291278958786 seconds)
2023-07-10 17:17:30 | INFO | train_inner | epoch 006:    736 / 1474 loss=1.946, trans_loss=3.575, nll_loss=1.75, w2v_ctc_loss=0.618, task_loss=0.773, contrastive_loss=0.147, total=4148.65, n_correct=2350, ppl=3.36, accuracy=56.645, wps=9931.6, ups=0.8, wpb=12378.4, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.336, clip=0, loss_scale=16, train_wall=87, gb_free=15.8, wall=6744
2023-07-10 17:18:58 | INFO | train_inner | epoch 006:    836 / 1474 loss=1.948, trans_loss=3.581, nll_loss=1.755, w2v_ctc_loss=0.612, task_loss=0.799, contrastive_loss=0.13, total=4114.34, n_correct=2318.99, ppl=3.37, accuracy=56.364, wps=14028.1, ups=1.14, wpb=12292.5, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.334, clip=0, loss_scale=16, train_wall=87, gb_free=15.3, wall=6831
2023-07-10 17:20:25 | INFO | train_inner | epoch 006:    936 / 1474 loss=1.952, trans_loss=3.578, nll_loss=1.753, w2v_ctc_loss=0.615, task_loss=0.793, contrastive_loss=0.226, total=4081.53, n_correct=2305.37, ppl=3.37, accuracy=56.483, wps=13961.1, ups=1.15, wpb=12166.1, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.337, clip=0, loss_scale=16, train_wall=87, gb_free=17.9, wall=6918
2023-07-10 17:21:52 | INFO | train_inner | epoch 006:   1036 / 1474 loss=1.951, trans_loss=3.571, nll_loss=1.744, w2v_ctc_loss=0.607, task_loss=0.722, contrastive_loss=0.302, total=4165.84, n_correct=2367.65, ppl=3.35, accuracy=56.835, wps=14322.8, ups=1.15, wpb=12437.3, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.338, clip=0, loss_scale=16, train_wall=86, gb_free=17, wall=7005
2023-07-10 17:23:18 | INFO | train_inner | epoch 006:   1136 / 1474 loss=1.94, trans_loss=3.578, nll_loss=1.752, w2v_ctc_loss=0.609, task_loss=0.846, contrastive_loss=0.132, total=4072.29, n_correct=2308.52, ppl=3.37, accuracy=56.688, wps=14099.8, ups=1.16, wpb=12165.1, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.333, clip=0, loss_scale=16, train_wall=86, gb_free=17.1, wall=7092
2023-07-10 17:24:45 | INFO | train_inner | epoch 006:   1236 / 1474 loss=1.957, trans_loss=3.569, nll_loss=1.743, w2v_ctc_loss=0.602, task_loss=0.737, contrastive_loss=0.447, total=4141.55, n_correct=2357.06, ppl=3.35, accuracy=56.913, wps=14175.2, ups=1.14, wpb=12385.8, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.331, clip=0, loss_scale=16, train_wall=87, gb_free=13.5, wall=7179
2023-07-10 17:26:11 | INFO | train_inner | epoch 006:   1336 / 1474 loss=1.937, trans_loss=3.577, nll_loss=1.748, w2v_ctc_loss=0.602, task_loss=0.758, contrastive_loss=0.119, total=4125.31, n_correct=2353.99, ppl=3.36, accuracy=57.062, wps=14314.2, ups=1.16, wpb=12316, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.33, clip=0, loss_scale=16, train_wall=86, gb_free=17.8, wall=7265
2023-07-10 17:27:39 | INFO | train_inner | epoch 006:   1436 / 1474 loss=1.93, trans_loss=3.566, nll_loss=1.739, w2v_ctc_loss=0.604, task_loss=0.759, contrastive_loss=0.126, total=4196.2, n_correct=2399.52, ppl=3.34, accuracy=57.183, wps=14287.8, ups=1.14, wpb=12515.5, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.326, clip=0, loss_scale=16, train_wall=87, gb_free=11.8, wall=7353
2023-07-10 17:28:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 17:28:40 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 1.821 | trans_loss 5.78 | nll_loss 3.107 | w2v_ctc_loss 0.561 | task_loss 3.616 | contrastive_loss 0.28 | total 4003.4 | n_correct 2348.4 | ppl 8.62 | accuracy 58.66 | uer 19.555 | wer 21.17 | raw_wer 21.17 | bleu 16.75 | wps 1898.9 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 16.75
2023-07-10 17:28:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-10 17:28:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 17:28:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 17:28:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 6 @ 8838 updates, score 16.75) (writing took 8.319620313006453 seconds)
2023-07-10 17:28:48 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-10 17:28:48 | INFO | train | epoch 006 | loss 1.945 | trans_loss 3.572 | nll_loss 1.746 | w2v_ctc_loss 0.61 | task_loss 0.76 | contrastive_loss 0.208 | total 4138.65 | n_correct 2346.15 | ppl 3.35 | accuracy 56.689 | wps 13353.5 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.334 | clip 0 | loss_scale 16 | train_wall 1275 | gb_free 15.3 | wall 7422
2023-07-10 17:28:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 17:28:48 | INFO | fairseq.trainer | begin training epoch 7
2023-07-10 17:28:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 17:29:50 | INFO | train_inner | epoch 007:     62 / 1474 loss=1.909, trans_loss=3.542, nll_loss=1.707, w2v_ctc_loss=0.584, task_loss=0.741, contrastive_loss=0.14, total=4108.19, n_correct=2373.83, ppl=3.26, accuracy=57.783, wps=9342.3, ups=0.76, wpb=12269.7, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.328, clip=0, loss_scale=16, train_wall=86, gb_free=17.2, wall=7484
2023-07-10 17:31:17 | INFO | train_inner | epoch 007:    162 / 1474 loss=1.91, trans_loss=3.535, nll_loss=1.699, w2v_ctc_loss=0.576, task_loss=0.77, contrastive_loss=0.213, total=4106.05, n_correct=2374.33, ppl=3.25, accuracy=57.825, wps=14201.4, ups=1.16, wpb=12254.3, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.33, clip=0, loss_scale=16, train_wall=86, gb_free=16.9, wall=7570
2023-07-10 17:32:43 | INFO | train_inner | epoch 007:    262 / 1474 loss=1.896, trans_loss=3.533, nll_loss=1.693, w2v_ctc_loss=0.575, task_loss=0.77, contrastive_loss=0.122, total=4129.3, n_correct=2398.05, ppl=3.23, accuracy=58.074, wps=14262.6, ups=1.16, wpb=12322.9, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.326, clip=0, loss_scale=16, train_wall=86, gb_free=17.4, wall=7657
2023-07-10 17:34:10 | INFO | train_inner | epoch 007:    362 / 1474 loss=1.913, trans_loss=3.538, nll_loss=1.703, w2v_ctc_loss=0.57, task_loss=0.733, contrastive_loss=0.382, total=4201.67, n_correct=2427.44, ppl=3.25, accuracy=57.773, wps=14385.6, ups=1.15, wpb=12533.1, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.325, clip=0, loss_scale=32, train_wall=87, gb_free=15.6, wall=7744
2023-07-10 17:35:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-10 17:35:38 | INFO | train_inner | epoch 007:    463 / 1474 loss=1.911, trans_loss=3.538, nll_loss=1.705, w2v_ctc_loss=0.578, task_loss=0.769, contrastive_loss=0.246, total=4140.2, n_correct=2387.53, ppl=3.26, accuracy=57.667, wps=14139.8, ups=1.14, wpb=12352.1, bsz=456.1, num_updates=9300, lr=0.000146647, gnorm=0.328, clip=0, loss_scale=16, train_wall=87, gb_free=17, wall=7831
2023-07-10 17:37:05 | INFO | train_inner | epoch 007:    563 / 1474 loss=1.899, trans_loss=3.537, nll_loss=1.702, w2v_ctc_loss=0.575, task_loss=0.743, contrastive_loss=0.131, total=4168.14, n_correct=2421.23, ppl=3.25, accuracy=58.089, wps=14274.6, ups=1.15, wpb=12410.5, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.328, clip=0, loss_scale=16, train_wall=87, gb_free=17, wall=7918
2023-07-10 17:38:32 | INFO | train_inner | epoch 007:    663 / 1474 loss=1.898, trans_loss=3.541, nll_loss=1.702, w2v_ctc_loss=0.568, task_loss=0.756, contrastive_loss=0.116, total=4157.82, n_correct=2420.04, ppl=3.25, accuracy=58.205, wps=14270, ups=1.15, wpb=12417.8, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.325, clip=0, loss_scale=16, train_wall=87, gb_free=15.8, wall=8005
2023-07-10 17:39:58 | INFO | train_inner | epoch 007:    763 / 1474 loss=1.903, trans_loss=3.54, nll_loss=1.704, w2v_ctc_loss=0.575, task_loss=0.796, contrastive_loss=0.114, total=4122.1, n_correct=2391.82, ppl=3.26, accuracy=58.024, wps=14172, ups=1.15, wpb=12321.9, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.326, clip=0, loss_scale=16, train_wall=87, gb_free=15.8, wall=8092
2023-07-10 17:41:26 | INFO | train_inner | epoch 007:    863 / 1474 loss=1.902, trans_loss=3.538, nll_loss=1.701, w2v_ctc_loss=0.572, task_loss=0.769, contrastive_loss=0.134, total=4147.23, n_correct=2406.39, ppl=3.25, accuracy=58.024, wps=14224.1, ups=1.15, wpb=12392, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.33, clip=0, loss_scale=16, train_wall=87, gb_free=17.6, wall=8179
2023-07-10 17:42:52 | INFO | train_inner | epoch 007:    963 / 1474 loss=1.905, trans_loss=3.536, nll_loss=1.701, w2v_ctc_loss=0.569, task_loss=0.725, contrastive_loss=0.229, total=4140.14, n_correct=2410.08, ppl=3.25, accuracy=58.213, wps=14260, ups=1.15, wpb=12360, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.331, clip=0, loss_scale=16, train_wall=86, gb_free=16.1, wall=8266
2023-07-10 17:44:19 | INFO | train_inner | epoch 007:   1063 / 1474 loss=1.896, trans_loss=3.546, nll_loss=1.712, w2v_ctc_loss=0.572, task_loss=0.801, contrastive_loss=0.098, total=4103.51, n_correct=2373.8, ppl=3.28, accuracy=57.848, wps=14144.9, ups=1.15, wpb=12263.4, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.326, clip=0, loss_scale=16, train_wall=86, gb_free=17, wall=8353
2023-07-10 17:45:47 | INFO | train_inner | epoch 007:   1163 / 1474 loss=1.912, trans_loss=3.536, nll_loss=1.705, w2v_ctc_loss=0.569, task_loss=0.739, contrastive_loss=0.362, total=4137.04, n_correct=2401.92, ppl=3.26, accuracy=58.059, wps=14109.7, ups=1.14, wpb=12348.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.332, clip=0, loss_scale=16, train_wall=87, gb_free=16.2, wall=8440
2023-07-10 17:45:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 17:46:14 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 1.798 | trans_loss 5.735 | nll_loss 3.057 | w2v_ctc_loss 0.554 | task_loss 3.647 | contrastive_loss 0.279 | total 4003.4 | n_correct 2368.7 | ppl 8.32 | accuracy 59.167 | uer 18.939 | wer 20.737 | raw_wer 20.737 | bleu 17.05 | wps 1983.3 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 17.05
2023-07-10 17:46:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-10 17:46:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_7_10000.pt
2023-07-10 17:46:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_7_10000.pt
2023-07-10 17:46:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 17.05) (writing took 9.405341056990437 seconds)
tensor(0.6075, device='cuda:0')
tensor(0.5417, device='cuda:0')
2023-07-10 17:47:50 | INFO | train_inner | epoch 007:   1263 / 1474 loss=1.888, trans_loss=3.533, nll_loss=1.698, w2v_ctc_loss=0.563, task_loss=0.772, contrastive_loss=0.125, total=4129.52, n_correct=2403.15, ppl=3.24, accuracy=58.194, wps=10016.5, ups=0.81, wpb=12329.2, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.254, clip=0, loss_scale=16, train_wall=86, gb_free=17, wall=8563
2023-07-10 17:49:16 | INFO | train_inner | epoch 007:   1363 / 1474 loss=1.898, trans_loss=3.529, nll_loss=1.693, w2v_ctc_loss=0.57, task_loss=0.713, contrastive_loss=0.162, total=4172.87, n_correct=2440.59, ppl=3.23, accuracy=58.487, wps=14445.3, ups=1.16, wpb=12453.5, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.257, clip=0, loss_scale=16, train_wall=86, gb_free=17.3, wall=8649
2023-07-10 17:50:44 | INFO | train_inner | epoch 007:   1463 / 1474 loss=1.906, trans_loss=3.541, nll_loss=1.709, w2v_ctc_loss=0.571, task_loss=0.824, contrastive_loss=0.226, total=4109.42, n_correct=2388.82, ppl=3.27, accuracy=58.13, wps=13967.9, ups=1.14, wpb=12285.7, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.262, clip=0, loss_scale=16, train_wall=88, gb_free=16.6, wall=8737
2023-07-10 17:50:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.6075, device='cuda:4')
tensor(0.5417, device='cuda:4')
tensor(0.6075, device='cuda:6')
tensor(0.5417, device='cuda:6')
tensor(0.6075, device='cuda:2')
tensor(0.5417, device='cuda:2')
tensor(0.6075, device='cuda:5')
tensor(0.5417, device='cuda:5')
tensor(0.6075, device='cuda:3')
tensor(0.5417, device='cuda:3')
tensor(0.6075, device='cuda:1')
tensor(0.5417, device='cuda:1')
tensor(0.6075, device='cuda:7')
tensor(0.5417, device='cuda:7')
2023-07-10 17:51:22 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 1.789 | trans_loss 5.727 | nll_loss 3.048 | w2v_ctc_loss 0.559 | task_loss 3.665 | contrastive_loss 0.269 | total 4003.4 | n_correct 2373.8 | ppl 8.27 | accuracy 59.295 | uer 18.992 | wer 20.715 | raw_wer 20.715 | bleu 17.18 | wps 1865.1 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 17.18
2023-07-10 17:51:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-10 17:51:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 17:51:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 17:51:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 7 @ 10311 updates, score 17.18) (writing took 8.216782583971508 seconds)
2023-07-10 17:51:30 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-10 17:51:30 | INFO | train | epoch 007 | loss 1.903 | trans_loss 3.537 | nll_loss 1.701 | w2v_ctc_loss 0.572 | task_loss 0.763 | contrastive_loss 0.188 | total 4137.82 | n_correct 2401.78 | ppl 3.25 | accuracy 58.045 | wps 13361.6 | ups 1.08 | wpb 12353.7 | bsz 458 | num_updates 10311 | lr 0.000139272 | gnorm 0.313 | clip 0 | loss_scale 16 | train_wall 1274 | gb_free 13.5 | wall 8784
2023-07-10 17:51:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 17:51:30 | INFO | fairseq.trainer | begin training epoch 8
2023-07-10 17:51:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 17:52:55 | INFO | train_inner | epoch 008:     89 / 1474 loss=1.87, trans_loss=3.512, nll_loss=1.665, w2v_ctc_loss=0.547, task_loss=0.807, contrastive_loss=0.119, total=4116.25, n_correct=2427.86, ppl=3.17, accuracy=58.982, wps=9317.9, ups=0.76, wpb=12265.9, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.255, clip=0, loss_scale=16, train_wall=86, gb_free=17.1, wall=8869
2023-07-10 17:54:22 | INFO | train_inner | epoch 008:    189 / 1474 loss=1.877, trans_loss=3.515, nll_loss=1.67, w2v_ctc_loss=0.549, task_loss=0.828, contrastive_loss=0.142, total=4037.23, n_correct=2382.15, ppl=3.18, accuracy=59.005, wps=13914.7, ups=1.16, wpb=12033.3, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.26, clip=0, loss_scale=16, train_wall=86, gb_free=13.1, wall=8955
2023-07-10 17:55:49 | INFO | train_inner | epoch 008:    289 / 1474 loss=1.863, trans_loss=3.503, nll_loss=1.656, w2v_ctc_loss=0.541, task_loss=0.714, contrastive_loss=0.139, total=4207.78, n_correct=2498.01, ppl=3.15, accuracy=59.366, wps=14463.6, ups=1.15, wpb=12570.1, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.255, clip=0, loss_scale=16, train_wall=86, gb_free=13.3, wall=9042
2023-07-10 17:57:17 | INFO | train_inner | epoch 008:    389 / 1474 loss=1.88, trans_loss=3.512, nll_loss=1.668, w2v_ctc_loss=0.556, task_loss=0.81, contrastive_loss=0.161, total=4127.24, n_correct=2432.45, ppl=3.18, accuracy=58.936, wps=13980, ups=1.13, wpb=12318.5, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.258, clip=0, loss_scale=16, train_wall=88, gb_free=12.1, wall=9130
2023-07-10 17:58:44 | INFO | train_inner | epoch 008:    489 / 1474 loss=1.898, trans_loss=3.511, nll_loss=1.667, w2v_ctc_loss=0.545, task_loss=0.682, contrastive_loss=0.422, total=4203.76, n_correct=2482.71, ppl=3.18, accuracy=59.059, wps=14380.7, ups=1.14, wpb=12567.7, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.259, clip=0, loss_scale=16, train_wall=87, gb_free=14.7, wall=9218
2023-07-10 18:00:11 | INFO | train_inner | epoch 008:    589 / 1474 loss=1.868, trans_loss=3.51, nll_loss=1.667, w2v_ctc_loss=0.549, task_loss=0.832, contrastive_loss=0.094, total=4062.5, n_correct=2391.51, ppl=3.18, accuracy=58.868, wps=14015.1, ups=1.15, wpb=12171.9, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.254, clip=0, loss_scale=16, train_wall=86, gb_free=11.7, wall=9305
2023-07-10 18:01:38 | INFO | train_inner | epoch 008:    689 / 1474 loss=1.867, trans_loss=3.508, nll_loss=1.665, w2v_ctc_loss=0.552, task_loss=0.787, contrastive_loss=0.107, total=4142.78, n_correct=2455.98, ppl=3.17, accuracy=59.283, wps=14192.6, ups=1.15, wpb=12347.9, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.257, clip=0, loss_scale=16, train_wall=87, gb_free=16, wall=9392
2023-07-10 18:03:05 | INFO | train_inner | epoch 008:    789 / 1474 loss=1.87, trans_loss=3.505, nll_loss=1.663, w2v_ctc_loss=0.544, task_loss=0.782, contrastive_loss=0.194, total=4118.9, n_correct=2436.12, ppl=3.17, accuracy=59.145, wps=14238.3, ups=1.15, wpb=12327.8, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.26, clip=0, loss_scale=16, train_wall=86, gb_free=15.3, wall=9478
2023-07-10 18:04:32 | INFO | train_inner | epoch 008:    889 / 1474 loss=1.871, trans_loss=3.507, nll_loss=1.665, w2v_ctc_loss=0.541, task_loss=0.729, contrastive_loss=0.204, total=4169.01, n_correct=2473.6, ppl=3.17, accuracy=59.333, wps=14246, ups=1.14, wpb=12455.3, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.258, clip=0, loss_scale=16, train_wall=87, gb_free=16.3, wall=9566
2023-07-10 18:05:58 | INFO | train_inner | epoch 008:    989 / 1474 loss=1.857, trans_loss=3.502, nll_loss=1.658, w2v_ctc_loss=0.536, task_loss=0.728, contrastive_loss=0.102, total=4154.69, n_correct=2468.56, ppl=3.16, accuracy=59.416, wps=14389.3, ups=1.16, wpb=12398.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.254, clip=0, loss_scale=16, train_wall=86, gb_free=17.8, wall=9652
2023-07-10 18:07:26 | INFO | train_inner | epoch 008:   1089 / 1474 loss=1.88, trans_loss=3.509, nll_loss=1.669, w2v_ctc_loss=0.543, task_loss=0.761, contrastive_loss=0.327, total=4199.1, n_correct=2479.05, ppl=3.18, accuracy=59.038, wps=14300.8, ups=1.14, wpb=12520.7, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.254, clip=0, loss_scale=32, train_wall=87, gb_free=13, wall=9739
2023-07-10 18:08:52 | INFO | train_inner | epoch 008:   1189 / 1474 loss=1.866, trans_loss=3.508, nll_loss=1.667, w2v_ctc_loss=0.544, task_loss=0.716, contrastive_loss=0.113, total=4177.31, n_correct=2477.28, ppl=3.18, accuracy=59.303, wps=14460.8, ups=1.16, wpb=12476.4, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.254, clip=0, loss_scale=32, train_wall=86, gb_free=15.1, wall=9826
2023-07-10 18:10:18 | INFO | train_inner | epoch 008:   1289 / 1474 loss=1.869, trans_loss=3.509, nll_loss=1.669, w2v_ctc_loss=0.547, task_loss=0.796, contrastive_loss=0.133, total=4063.85, n_correct=2400.46, ppl=3.18, accuracy=59.069, wps=14112.5, ups=1.16, wpb=12141.2, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.257, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=9912
2023-07-10 18:11:45 | INFO | train_inner | epoch 008:   1389 / 1474 loss=1.872, trans_loss=3.509, nll_loss=1.67, w2v_ctc_loss=0.544, task_loss=0.755, contrastive_loss=0.187, total=4141.5, n_correct=2455.3, ppl=3.18, accuracy=59.285, wps=14270.5, ups=1.16, wpb=12351.9, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.254, clip=0, loss_scale=32, train_wall=86, gb_free=16.7, wall=9998
2023-07-10 18:12:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 18:13:28 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 1.772 | trans_loss 5.687 | nll_loss 2.989 | w2v_ctc_loss 0.54 | task_loss 3.668 | contrastive_loss 0.264 | total 4003.4 | n_correct 2398.4 | ppl 7.94 | accuracy 59.909 | uer 18.22 | wer 19.958 | raw_wer 19.958 | bleu 17.87 | wps 1826.4 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 17.87
2023-07-10 18:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-10 18:13:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 18:13:32 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 18:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 8 @ 11785 updates, score 17.87) (writing took 8.408999861974735 seconds)
2023-07-10 18:13:36 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-10 18:13:36 | INFO | train | epoch 008 | loss 1.872 | trans_loss 3.509 | nll_loss 1.666 | w2v_ctc_loss 0.545 | task_loss 0.762 | contrastive_loss 0.182 | total 4138.65 | n_correct 2448.64 | ppl 3.17 | accuracy 59.165 | wps 13731.2 | ups 1.11 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.256 | clip 0 | loss_scale 32 | train_wall 1275 | gb_free 17.1 | wall 10110
2023-07-10 18:13:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 18:13:37 | INFO | fairseq.trainer | begin training epoch 9
2023-07-10 18:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 18:13:58 | INFO | train_inner | epoch 009:     15 / 1474 loss=1.876, trans_loss=3.504, nll_loss=1.661, w2v_ctc_loss=0.536, task_loss=0.735, contrastive_loss=0.316, total=4139.35, n_correct=2462.66, ppl=3.16, accuracy=59.494, wps=9270.2, ups=0.75, wpb=12332.8, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.255, clip=0, loss_scale=32, train_wall=87, gb_free=16.4, wall=10131
2023-07-10 18:15:24 | INFO | train_inner | epoch 009:    115 / 1474 loss=1.837, trans_loss=3.475, nll_loss=1.622, w2v_ctc_loss=0.517, task_loss=0.72, contrastive_loss=0.13, total=4181.9, n_correct=2523.62, ppl=3.08, accuracy=60.346, wps=14464.3, ups=1.16, wpb=12493.2, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.251, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=10218
2023-07-10 18:16:51 | INFO | train_inner | epoch 009:    215 / 1474 loss=1.838, trans_loss=3.487, nll_loss=1.637, w2v_ctc_loss=0.52, task_loss=0.824, contrastive_loss=0.092, total=4062.07, n_correct=2437.08, ppl=3.11, accuracy=59.996, wps=13946.1, ups=1.15, wpb=12136.5, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.254, clip=0, loss_scale=32, train_wall=87, gb_free=15.8, wall=10305
2023-07-10 18:16:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 18:17:18 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 1.78 | trans_loss 5.702 | nll_loss 3.012 | w2v_ctc_loss 0.532 | task_loss 3.651 | contrastive_loss 0.266 | total 4003.4 | n_correct 2396.6 | ppl 8.07 | accuracy 59.864 | uer 18.472 | wer 20.286 | raw_wer 20.286 | bleu 18.33 | wps 2063.4 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.33
2023-07-10 18:17:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-10 18:17:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_9_12000.pt
2023-07-10 18:17:20 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_9_12000.pt
2023-07-10 18:17:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.33) (writing took 9.460367974999826 seconds)
2023-07-10 18:18:54 | INFO | train_inner | epoch 009:    315 / 1474 loss=1.837, trans_loss=3.475, nll_loss=1.623, w2v_ctc_loss=0.514, task_loss=0.712, contrastive_loss=0.138, total=4152.1, n_correct=2511.52, ppl=3.08, accuracy=60.488, wps=10114.6, ups=0.81, wpb=12422.8, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.252, clip=0, loss_scale=32, train_wall=86, gb_free=16.5, wall=10428
2023-07-10 18:20:22 | INFO | train_inner | epoch 009:    415 / 1474 loss=1.838, trans_loss=3.481, nll_loss=1.631, w2v_ctc_loss=0.52, task_loss=0.747, contrastive_loss=0.107, total=4203.78, n_correct=2524.94, ppl=3.1, accuracy=60.064, wps=14261.1, ups=1.14, wpb=12545.5, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.25, clip=0, loss_scale=32, train_wall=88, gb_free=17.2, wall=10516
2023-07-10 18:21:49 | INFO | train_inner | epoch 009:    515 / 1474 loss=1.856, trans_loss=3.491, nll_loss=1.644, w2v_ctc_loss=0.533, task_loss=0.795, contrastive_loss=0.158, total=4112.78, n_correct=2463.47, ppl=3.13, accuracy=59.898, wps=14170, ups=1.16, wpb=12260.1, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.258, clip=0, loss_scale=32, train_wall=86, gb_free=16.3, wall=10602
2023-07-10 18:23:15 | INFO | train_inner | epoch 009:    615 / 1474 loss=1.838, trans_loss=3.483, nll_loss=1.636, w2v_ctc_loss=0.519, task_loss=0.78, contrastive_loss=0.118, total=4131.32, n_correct=2481.78, ppl=3.11, accuracy=60.072, wps=14237.8, ups=1.15, wpb=12355.3, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.257, clip=0, loss_scale=32, train_wall=86, gb_free=17.9, wall=10689
2023-07-10 18:24:42 | INFO | train_inner | epoch 009:    715 / 1474 loss=1.855, trans_loss=3.49, nll_loss=1.643, w2v_ctc_loss=0.529, task_loss=0.783, contrastive_loss=0.198, total=4082.11, n_correct=2442.17, ppl=3.12, accuracy=59.826, wps=14167.1, ups=1.16, wpb=12206.9, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.259, clip=0, loss_scale=32, train_wall=86, gb_free=17.1, wall=10775
2023-07-10 18:26:09 | INFO | train_inner | epoch 009:    815 / 1474 loss=1.864, trans_loss=3.477, nll_loss=1.632, w2v_ctc_loss=0.528, task_loss=0.688, contrastive_loss=0.339, total=4221.08, n_correct=2533.77, ppl=3.1, accuracy=60.027, wps=14407.8, ups=1.14, wpb=12600.2, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.257, clip=0, loss_scale=32, train_wall=87, gb_free=17.7, wall=10863
2023-07-10 18:27:37 | INFO | train_inner | epoch 009:    915 / 1474 loss=1.855, trans_loss=3.489, nll_loss=1.642, w2v_ctc_loss=0.523, task_loss=0.789, contrastive_loss=0.324, total=4142.34, n_correct=2486.65, ppl=3.12, accuracy=60.03, wps=14048.4, ups=1.14, wpb=12345.3, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.253, clip=0, loss_scale=32, train_wall=87, gb_free=17.4, wall=10950
2023-07-10 18:29:04 | INFO | train_inner | epoch 009:   1015 / 1474 loss=1.848, trans_loss=3.497, nll_loss=1.65, w2v_ctc_loss=0.526, task_loss=0.859, contrastive_loss=0.104, total=4097.15, n_correct=2446.19, ppl=3.14, accuracy=59.705, wps=14034.8, ups=1.15, wpb=12230.8, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.255, clip=0, loss_scale=32, train_wall=87, gb_free=16.9, wall=11038
2023-07-10 18:30:31 | INFO | train_inner | epoch 009:   1115 / 1474 loss=1.844, trans_loss=3.486, nll_loss=1.637, w2v_ctc_loss=0.524, task_loss=0.711, contrastive_loss=0.128, total=4182.29, n_correct=2517.94, ppl=3.11, accuracy=60.205, wps=14302.6, ups=1.15, wpb=12446.8, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.257, clip=0, loss_scale=32, train_wall=87, gb_free=17.3, wall=11125
2023-07-10 18:31:59 | INFO | train_inner | epoch 009:   1215 / 1474 loss=1.85, trans_loss=3.496, nll_loss=1.646, w2v_ctc_loss=0.527, task_loss=0.809, contrastive_loss=0.11, total=4141.43, n_correct=2480.76, ppl=3.13, accuracy=59.901, wps=14130.5, ups=1.14, wpb=12406.5, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.254, clip=0, loss_scale=32, train_wall=87, gb_free=17.6, wall=11212
2023-07-10 18:33:25 | INFO | train_inner | epoch 009:   1315 / 1474 loss=1.851, trans_loss=3.483, nll_loss=1.634, w2v_ctc_loss=0.514, task_loss=0.692, contrastive_loss=0.306, total=4203.91, n_correct=2533.53, ppl=3.1, accuracy=60.266, wps=14555.5, ups=1.16, wpb=12540.7, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.259, clip=0, loss_scale=32, train_wall=86, gb_free=17.4, wall=11299
2023-07-10 18:34:51 | INFO | train_inner | epoch 009:   1415 / 1474 loss=1.848, trans_loss=3.498, nll_loss=1.651, w2v_ctc_loss=0.528, task_loss=0.825, contrastive_loss=0.087, total=4077.08, n_correct=2437.38, ppl=3.14, accuracy=59.782, wps=14092.2, ups=1.16, wpb=12171.4, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.258, clip=0, loss_scale=32, train_wall=86, gb_free=17.4, wall=11385
2023-07-10 18:35:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 18:36:08 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 1.763 | trans_loss 5.66 | nll_loss 2.957 | w2v_ctc_loss 0.533 | task_loss 3.674 | contrastive_loss 0.264 | total 4003.4 | n_correct 2419.4 | ppl 7.77 | accuracy 60.434 | uer 17.665 | wer 19.41 | raw_wer 19.41 | bleu 18.42 | wps 2104.4 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 18.42
2023-07-10 18:36:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-07-10 18:36:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 18:36:12 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 18:36:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 9 @ 13259 updates, score 18.42) (writing took 8.424906829022802 seconds)
2023-07-10 18:36:17 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-10 18:36:17 | INFO | train | epoch 009 | loss 1.847 | trans_loss 3.486 | nll_loss 1.638 | w2v_ctc_loss 0.523 | task_loss 0.763 | contrastive_loss 0.173 | total 4138.65 | n_correct 2485.54 | ppl 3.11 | accuracy 60.057 | wps 13390.4 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.255 | clip 0 | loss_scale 32 | train_wall 1274 | gb_free 12 | wall 11470
2023-07-10 18:36:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 18:36:17 | INFO | fairseq.trainer | begin training epoch 10
2023-07-10 18:36:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 18:37:00 | INFO | train_inner | epoch 010:     41 / 1474 loss=1.838, trans_loss=3.478, nll_loss=1.628, w2v_ctc_loss=0.514, task_loss=0.726, contrastive_loss=0.187, total=4100.86, n_correct=2480.62, ppl=3.09, accuracy=60.49, wps=9513.4, ups=0.78, wpb=12244.8, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.256, clip=0, loss_scale=32, train_wall=85, gb_free=16.7, wall=11514
2023-07-10 18:38:27 | INFO | train_inner | epoch 010:    141 / 1474 loss=1.815, trans_loss=3.46, nll_loss=1.601, w2v_ctc_loss=0.496, task_loss=0.72, contrastive_loss=0.107, total=4240.18, n_correct=2587.79, ppl=3.03, accuracy=61.03, wps=14538.9, ups=1.14, wpb=12698.4, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.249, clip=0, loss_scale=64, train_wall=87, gb_free=15.1, wall=11601
2023-07-10 18:38:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-10 18:39:55 | INFO | train_inner | epoch 010:    242 / 1474 loss=1.814, trans_loss=3.455, nll_loss=1.598, w2v_ctc_loss=0.503, task_loss=0.77, contrastive_loss=0.101, total=4108.62, n_correct=2513.08, ppl=3.03, accuracy=61.166, wps=13927.8, ups=1.14, wpb=12240, bsz=451.2, num_updates=13500, lr=0.000121716, gnorm=0.252, clip=0, loss_scale=32, train_wall=87, gb_free=16.4, wall=11689
2023-07-10 18:41:23 | INFO | train_inner | epoch 010:    342 / 1474 loss=1.818, trans_loss=3.458, nll_loss=1.604, w2v_ctc_loss=0.501, task_loss=0.771, contrastive_loss=0.142, total=4138.27, n_correct=2519.93, ppl=3.04, accuracy=60.893, wps=14149, ups=1.14, wpb=12378.7, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.253, clip=0, loss_scale=32, train_wall=87, gb_free=16.6, wall=11776
2023-07-10 18:42:51 | INFO | train_inner | epoch 010:    442 / 1474 loss=1.826, trans_loss=3.462, nll_loss=1.607, w2v_ctc_loss=0.494, task_loss=0.735, contrastive_loss=0.318, total=4196.37, n_correct=2554.73, ppl=3.05, accuracy=60.88, wps=14204.6, ups=1.13, wpb=12523.5, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.251, clip=0, loss_scale=32, train_wall=88, gb_free=16.6, wall=11865
2023-07-10 18:44:18 | INFO | train_inner | epoch 010:    542 / 1474 loss=1.83, trans_loss=3.472, nll_loss=1.617, w2v_ctc_loss=0.512, task_loss=0.822, contrastive_loss=0.097, total=4102.8, n_correct=2488.52, ppl=3.07, accuracy=60.654, wps=14097.8, ups=1.15, wpb=12224.8, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.256, clip=0, loss_scale=32, train_wall=86, gb_free=17.1, wall=11951
2023-07-10 18:45:45 | INFO | train_inner | epoch 010:    642 / 1474 loss=1.834, trans_loss=3.47, nll_loss=1.616, w2v_ctc_loss=0.507, task_loss=0.722, contrastive_loss=0.211, total=4176.56, n_correct=2536.03, ppl=3.07, accuracy=60.721, wps=14346.8, ups=1.15, wpb=12467.5, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.254, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=12038
2023-07-10 18:47:11 | INFO | train_inner | epoch 010:    742 / 1474 loss=1.832, trans_loss=3.471, nll_loss=1.619, w2v_ctc_loss=0.518, task_loss=0.761, contrastive_loss=0.095, total=4125.87, n_correct=2497.05, ppl=3.07, accuracy=60.522, wps=14235, ups=1.16, wpb=12315.5, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.262, clip=0, loss_scale=32, train_wall=86, gb_free=14.7, wall=12125
2023-07-10 18:47:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 18:47:39 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 1.766 | trans_loss 5.665 | nll_loss 2.962 | w2v_ctc_loss 0.554 | task_loss 3.681 | contrastive_loss 0.258 | total 4003.4 | n_correct 2417.3 | ppl 7.79 | accuracy 60.381 | uer 18.055 | wer 19.69 | raw_wer 19.69 | bleu 18.59 | wps 1966.8 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 18.59
2023-07-10 18:47:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-10 18:47:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_10_14000.pt
2023-07-10 18:47:41 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_10_14000.pt
2023-07-10 18:47:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 18.59) (writing took 9.520421107008588 seconds)
2023-07-10 18:49:16 | INFO | train_inner | epoch 010:    842 / 1474 loss=1.822, trans_loss=3.469, nll_loss=1.615, w2v_ctc_loss=0.503, task_loss=0.751, contrastive_loss=0.097, total=4128.44, n_correct=2512.51, ppl=3.06, accuracy=60.859, wps=9858.6, ups=0.8, wpb=12345, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.254, clip=0, loss_scale=32, train_wall=87, gb_free=14.9, wall=12250
2023-07-10 18:50:43 | INFO | train_inner | epoch 010:    942 / 1474 loss=1.829, trans_loss=3.466, nll_loss=1.613, w2v_ctc_loss=0.511, task_loss=0.734, contrastive_loss=0.135, total=4160.94, n_correct=2532.57, ppl=3.06, accuracy=60.865, wps=14338.4, ups=1.16, wpb=12380.2, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.257, clip=0, loss_scale=32, train_wall=86, gb_free=15.6, wall=12336
2023-07-10 18:52:10 | INFO | train_inner | epoch 010:   1042 / 1474 loss=1.823, trans_loss=3.472, nll_loss=1.621, w2v_ctc_loss=0.509, task_loss=0.829, contrastive_loss=0.109, total=4067.53, n_correct=2461.53, ppl=3.08, accuracy=60.517, wps=13944.9, ups=1.15, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.257, clip=0, loss_scale=32, train_wall=87, gb_free=17, wall=12423
2023-07-10 18:53:36 | INFO | train_inner | epoch 010:   1142 / 1474 loss=1.827, trans_loss=3.474, nll_loss=1.623, w2v_ctc_loss=0.512, task_loss=0.849, contrastive_loss=0.09, total=4044.03, n_correct=2447.97, ppl=3.08, accuracy=60.533, wps=14031.5, ups=1.16, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.257, clip=0, loss_scale=32, train_wall=86, gb_free=17.4, wall=12509
2023-07-10 18:55:03 | INFO | train_inner | epoch 010:   1242 / 1474 loss=1.823, trans_loss=3.467, nll_loss=1.618, w2v_ctc_loss=0.51, task_loss=0.781, contrastive_loss=0.084, total=4110.41, n_correct=2495.63, ppl=3.07, accuracy=60.715, wps=14113.4, ups=1.15, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.256, clip=0, loss_scale=32, train_wall=87, gb_free=16.6, wall=12597
2023-07-10 18:56:31 | INFO | train_inner | epoch 010:   1342 / 1474 loss=1.822, trans_loss=3.468, nll_loss=1.616, w2v_ctc_loss=0.505, task_loss=0.779, contrastive_loss=0.098, total=4121.38, n_correct=2507.85, ppl=3.07, accuracy=60.85, wps=14008.3, ups=1.14, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.256, clip=0, loss_scale=32, train_wall=87, gb_free=14.3, wall=12684
2023-07-10 18:57:59 | INFO | train_inner | epoch 010:   1442 / 1474 loss=1.842, trans_loss=3.473, nll_loss=1.624, w2v_ctc_loss=0.501, task_loss=0.719, contrastive_loss=0.349, total=4192.39, n_correct=2541.79, ppl=3.08, accuracy=60.629, wps=14152.4, ups=1.13, wpb=12477.9, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.254, clip=0, loss_scale=32, train_wall=88, gb_free=17.2, wall=12773
2023-07-10 18:58:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 18:58:55 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 1.756 | trans_loss 5.65 | nll_loss 2.942 | w2v_ctc_loss 0.54 | task_loss 3.692 | contrastive_loss 0.264 | total 4003.4 | n_correct 2428.4 | ppl 7.68 | accuracy 60.658 | uer 17.498 | wer 19.302 | raw_wer 19.302 | bleu 18.41 | wps 1900.5 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 18.59
2023-07-10 18:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-10 18:58:55 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.4101.pt
2023-07-10 18:58:57 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.4101.pt
2023-07-10 18:59:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.4101.pt (epoch 10 @ 14732 updates, score 18.41) (writing took 5.47906664502807 seconds)
2023-07-10 18:59:01 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-10 18:59:01 | INFO | train | epoch 010 | loss 1.826 | trans_loss 3.467 | nll_loss 1.614 | w2v_ctc_loss 0.505 | task_loss 0.764 | contrastive_loss 0.157 | total 4137.54 | n_correct 2514.67 | ppl 3.06 | accuracy 60.777 | wps 13339.4 | ups 1.08 | wpb 12352.8 | bsz 457.8 | num_updates 14732 | lr 0.000116516 | gnorm 0.255 | clip 0 | loss_scale 32 | train_wall 1278 | gb_free 17.4 | wall 12834
2023-07-10 18:59:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 18:59:01 | INFO | fairseq.trainer | begin training epoch 11
2023-07-10 18:59:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 19:00:07 | INFO | train_inner | epoch 011:     68 / 1474 loss=1.809, trans_loss=3.449, nll_loss=1.591, w2v_ctc_loss=0.49, task_loss=0.704, contrastive_loss=0.172, total=4175.24, n_correct=2570.66, ppl=3.01, accuracy=61.569, wps=9740.6, ups=0.78, wpb=12460.8, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.25, clip=0, loss_scale=32, train_wall=86, gb_free=16.9, wall=12901
2023-07-10 19:01:34 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.799, trans_loss=3.447, nll_loss=1.589, w2v_ctc_loss=0.49, task_loss=0.79, contrastive_loss=0.093, total=4087.78, n_correct=2510.77, ppl=3.01, accuracy=61.421, wps=14051.5, ups=1.15, wpb=12225.8, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.255, clip=0, loss_scale=32, train_wall=87, gb_free=16.7, wall=12988
2023-07-10 19:03:01 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.798, trans_loss=3.446, nll_loss=1.588, w2v_ctc_loss=0.487, task_loss=0.787, contrastive_loss=0.087, total=4118.77, n_correct=2529.06, ppl=3.01, accuracy=61.403, wps=14199.4, ups=1.16, wpb=12285.5, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.254, clip=0, loss_scale=32, train_wall=86, gb_free=12.7, wall=13074
tensor(0.2551, device='cuda:0')
tensor(0.1711, device='cuda:0')
2023-07-10 19:04:27 | INFO | train_inner | epoch 011:    368 / 1474 loss=1.801, trans_loss=3.445, nll_loss=1.584, w2v_ctc_loss=0.485, task_loss=0.786, contrastive_loss=0.092, total=4097.83, n_correct=2526.81, ppl=3, accuracy=61.662, wps=14155.1, ups=1.16, wpb=12202.1, bsz=444.2, num_updates=15100, lr=0.000115087, gnorm=0.19, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=13160
2023-07-10 19:05:55 | INFO | train_inner | epoch 011:    468 / 1474 loss=1.821, trans_loss=3.459, nll_loss=1.6, w2v_ctc_loss=0.489, task_loss=0.803, contrastive_loss=0.25, total=4110.64, n_correct=2516.43, ppl=3.03, accuracy=61.217, wps=13923.4, ups=1.14, wpb=12265.6, bsz=450.5, num_updates=15200, lr=0.000114708, gnorm=0.189, clip=0, loss_scale=32, train_wall=88, gb_free=16.5, wall=13248
2023-07-10 19:07:23 | INFO | train_inner | epoch 011:    568 / 1474 loss=1.824, trans_loss=3.456, nll_loss=1.602, w2v_ctc_loss=0.497, task_loss=0.817, contrastive_loss=0.249, total=4071.69, n_correct=2492.56, ppl=3.03, accuracy=61.217, wps=13820, ups=1.13, wpb=12176.5, bsz=440.6, num_updates=15300, lr=0.000114332, gnorm=0.19, clip=0, loss_scale=32, train_wall=88, gb_free=16.5, wall=13336
2023-07-10 19:08:50 | INFO | train_inner | epoch 011:    668 / 1474 loss=1.824, trans_loss=3.451, nll_loss=1.593, w2v_ctc_loss=0.492, task_loss=0.755, contrastive_loss=0.328, total=4157.2, n_correct=2549.61, ppl=3.02, accuracy=61.33, wps=14227, ups=1.15, wpb=12400.2, bsz=464.4, num_updates=15400, lr=0.000113961, gnorm=0.191, clip=0, loss_scale=32, train_wall=87, gb_free=16.9, wall=13424
2023-07-10 19:10:18 | INFO | train_inner | epoch 011:    768 / 1474 loss=1.811, trans_loss=3.454, nll_loss=1.597, w2v_ctc_loss=0.495, task_loss=0.767, contrastive_loss=0.091, total=4174.91, n_correct=2565.87, ppl=3.02, accuracy=61.459, wps=14264.8, ups=1.14, wpb=12472.8, bsz=460.4, num_updates=15500, lr=0.000113592, gnorm=0.188, clip=0, loss_scale=64, train_wall=87, gb_free=17.1, wall=13511
2023-07-10 19:11:44 | INFO | train_inner | epoch 011:    868 / 1474 loss=1.804, trans_loss=3.455, nll_loss=1.601, w2v_ctc_loss=0.494, task_loss=0.804, contrastive_loss=0.075, total=4118.44, n_correct=2513.32, ppl=3.03, accuracy=61.026, wps=14140.8, ups=1.15, wpb=12290.5, bsz=440.6, num_updates=15600, lr=0.000113228, gnorm=0.188, clip=0, loss_scale=64, train_wall=87, gb_free=11.2, wall=13598
2023-07-10 19:13:11 | INFO | train_inner | epoch 011:    968 / 1474 loss=1.806, trans_loss=3.456, nll_loss=1.601, w2v_ctc_loss=0.493, task_loss=0.784, contrastive_loss=0.09, total=4140.92, n_correct=2536.89, ppl=3.03, accuracy=61.264, wps=14196.4, ups=1.15, wpb=12353.7, bsz=452.9, num_updates=15700, lr=0.000112867, gnorm=0.188, clip=0, loss_scale=64, train_wall=87, gb_free=15.8, wall=13685
2023-07-10 19:14:38 | INFO | train_inner | epoch 011:   1068 / 1474 loss=1.811, trans_loss=3.452, nll_loss=1.597, w2v_ctc_loss=0.496, task_loss=0.756, contrastive_loss=0.113, total=4136.99, n_correct=2543.76, ppl=3.02, accuracy=61.488, wps=14311, ups=1.16, wpb=12367, bsz=463.2, num_updates=15800, lr=0.000112509, gnorm=0.187, clip=0, loss_scale=64, train_wall=86, gb_free=17.7, wall=13771
2023-07-10 19:16:06 | INFO | train_inner | epoch 011:   1168 / 1474 loss=1.809, trans_loss=3.456, nll_loss=1.605, w2v_ctc_loss=0.497, task_loss=0.764, contrastive_loss=0.095, total=4185.65, n_correct=2561.43, ppl=3.04, accuracy=61.196, wps=14203.1, ups=1.14, wpb=12477.8, bsz=464.7, num_updates=15900, lr=0.000112154, gnorm=0.187, clip=0, loss_scale=64, train_wall=87, gb_free=14.3, wall=13859
2023-07-10 19:17:33 | INFO | train_inner | epoch 011:   1268 / 1474 loss=1.824, trans_loss=3.455, nll_loss=1.601, w2v_ctc_loss=0.502, task_loss=0.739, contrastive_loss=0.188, total=4171.89, n_correct=2558.38, ppl=3.03, accuracy=61.324, wps=14260.6, ups=1.14, wpb=12466.6, bsz=471.1, num_updates=16000, lr=0.000111803, gnorm=0.189, clip=0, loss_scale=64, train_wall=87, gb_free=16.1, wall=13947
2023-07-10 19:17:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.2551, device='cuda:3')
tensor(0.1711, device='cuda:3')
tensor(0.2551, device='cuda:6')
tensor(0.1711, device='cuda:6')
tensor(0.2551, device='cuda:5')
tensor(0.1711, device='cuda:5')
tensor(0.2551, device='cuda:7')
tensor(0.1711, device='cuda:7')
tensor(0.2551, device='cuda:1')
tensor(0.1711, device='cuda:1')
tensor(0.2551, device='cuda:2')
tensor(0.1711, device='cuda:2')
tensor(0.2551, device='cuda:4')
tensor(0.1711, device='cuda:4')
2023-07-10 19:18:01 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 1.748 | trans_loss 5.64 | nll_loss 2.928 | w2v_ctc_loss 0.554 | task_loss 3.736 | contrastive_loss 0.251 | total 4003.4 | n_correct 2434.2 | ppl 7.61 | accuracy 60.803 | uer 17.355 | wer 19.093 | raw_wer 19.093 | bleu 19.63 | wps 1959.6 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.63
2023-07-10 19:18:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-10 19:18:01 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_11_16000.pt
2023-07-10 19:18:03 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_11_16000.pt
2023-07-10 19:18:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.63) (writing took 9.388284456974361 seconds)
2023-07-10 19:19:38 | INFO | train_inner | epoch 011:   1368 / 1474 loss=1.824, trans_loss=3.454, nll_loss=1.598, w2v_ctc_loss=0.489, task_loss=0.708, contrastive_loss=0.402, total=4190.34, n_correct=2566.56, ppl=3.03, accuracy=61.249, wps=9991.7, ups=0.8, wpb=12512.8, bsz=491.8, num_updates=16100, lr=0.000111456, gnorm=0.186, clip=0, loss_scale=64, train_wall=87, gb_free=17.1, wall=14072
2023-07-10 19:21:05 | INFO | train_inner | epoch 011:   1468 / 1474 loss=1.805, trans_loss=3.454, nll_loss=1.599, w2v_ctc_loss=0.491, task_loss=0.742, contrastive_loss=0.098, total=4158.39, n_correct=2551.11, ppl=3.03, accuracy=61.349, wps=14273.9, ups=1.15, wpb=12421.8, bsz=468, num_updates=16200, lr=0.000111111, gnorm=0.186, clip=0, loss_scale=64, train_wall=87, gb_free=17.1, wall=14159
2023-07-10 19:21:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 19:21:38 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 1.739 | trans_loss 5.627 | nll_loss 2.914 | w2v_ctc_loss 0.528 | task_loss 3.729 | contrastive_loss 0.253 | total 4003.4 | n_correct 2433.7 | ppl 7.54 | accuracy 60.791 | uer 17.238 | wer 18.959 | raw_wer 18.959 | bleu 19.31 | wps 1951.1 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.63
2023-07-10 19:21:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-10 19:21:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.3108.pt
2023-07-10 19:21:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.3108.pt
2023-07-10 19:21:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.3108.pt (epoch 11 @ 16206 updates, score 19.31) (writing took 5.3297128939884715 seconds)
2023-07-10 19:21:44 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-10 19:21:44 | INFO | train | epoch 011 | loss 1.811 | trans_loss 3.452 | nll_loss 1.596 | w2v_ctc_loss 0.492 | task_loss 0.767 | contrastive_loss 0.158 | total 4138.65 | n_correct 2539.25 | ppl 3.02 | accuracy 61.355 | wps 13362.8 | ups 1.08 | wpb 12355.8 | bsz 458.5 | num_updates 16206 | lr 0.000111091 | gnorm 0.2 | clip 0 | loss_scale 64 | train_wall 1278 | gb_free 17.3 | wall 14197
2023-07-10 19:21:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 19:21:44 | INFO | fairseq.trainer | begin training epoch 12
2023-07-10 19:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 19:23:13 | INFO | train_inner | epoch 012:     94 / 1474 loss=1.791, trans_loss=3.43, nll_loss=1.565, w2v_ctc_loss=0.479, task_loss=0.736, contrastive_loss=0.141, total=4146.82, n_correct=2584.05, ppl=2.96, accuracy=62.314, wps=9676.4, ups=0.78, wpb=12379.4, bsz=470.8, num_updates=16300, lr=0.00011077, gnorm=0.185, clip=0, loss_scale=64, train_wall=86, gb_free=15.9, wall=14287
2023-07-10 19:24:41 | INFO | train_inner | epoch 012:    194 / 1474 loss=1.789, trans_loss=3.432, nll_loss=1.569, w2v_ctc_loss=0.482, task_loss=0.796, contrastive_loss=0.076, total=4120.68, n_correct=2563.12, ppl=2.97, accuracy=62.201, wps=14035.9, ups=1.14, wpb=12345.4, bsz=442.1, num_updates=16400, lr=0.000110432, gnorm=0.186, clip=0, loss_scale=64, train_wall=88, gb_free=15.8, wall=14375
2023-07-10 19:26:09 | INFO | train_inner | epoch 012:    294 / 1474 loss=1.785, trans_loss=3.431, nll_loss=1.57, w2v_ctc_loss=0.473, task_loss=0.728, contrastive_loss=0.117, total=4199.46, n_correct=2614.29, ppl=2.97, accuracy=62.253, wps=14246, ups=1.14, wpb=12539.6, bsz=480.4, num_updates=16500, lr=0.000110096, gnorm=0.184, clip=0, loss_scale=64, train_wall=88, gb_free=16.7, wall=14463
2023-07-10 19:27:37 | INFO | train_inner | epoch 012:    394 / 1474 loss=1.789, trans_loss=3.434, nll_loss=1.574, w2v_ctc_loss=0.478, task_loss=0.768, contrastive_loss=0.094, total=4151.14, n_correct=2585.06, ppl=2.98, accuracy=62.273, wps=14183, ups=1.14, wpb=12410, bsz=461.6, num_updates=16600, lr=0.000109764, gnorm=0.185, clip=0, loss_scale=64, train_wall=87, gb_free=17.2, wall=14550
2023-07-10 19:29:04 | INFO | train_inner | epoch 012:    494 / 1474 loss=1.807, trans_loss=3.447, nll_loss=1.587, w2v_ctc_loss=0.491, task_loss=0.792, contrastive_loss=0.106, total=4110.49, n_correct=2543.18, ppl=3, accuracy=61.87, wps=14057.8, ups=1.15, wpb=12226.9, bsz=453.3, num_updates=16700, lr=0.000109435, gnorm=0.188, clip=0, loss_scale=64, train_wall=87, gb_free=14.1, wall=14637
2023-07-10 19:30:32 | INFO | train_inner | epoch 012:    594 / 1474 loss=1.805, trans_loss=3.435, nll_loss=1.577, w2v_ctc_loss=0.485, task_loss=0.752, contrastive_loss=0.189, total=4189.92, n_correct=2597.52, ppl=2.98, accuracy=61.995, wps=14252.1, ups=1.14, wpb=12531.1, bsz=472.7, num_updates=16800, lr=0.000109109, gnorm=0.187, clip=0, loss_scale=64, train_wall=88, gb_free=15.1, wall=14725
2023-07-10 19:31:58 | INFO | train_inner | epoch 012:    694 / 1474 loss=1.799, trans_loss=3.433, nll_loss=1.573, w2v_ctc_loss=0.474, task_loss=0.713, contrastive_loss=0.309, total=4206.3, n_correct=2613.32, ppl=2.98, accuracy=62.129, wps=14428.7, ups=1.15, wpb=12501.9, bsz=488.5, num_updates=16900, lr=0.000108786, gnorm=0.186, clip=0, loss_scale=64, train_wall=86, gb_free=16.4, wall=14812
2023-07-10 19:33:26 | INFO | train_inner | epoch 012:    794 / 1474 loss=1.793, trans_loss=3.44, nll_loss=1.578, w2v_ctc_loss=0.484, task_loss=0.794, contrastive_loss=0.091, total=4085.96, n_correct=2536.24, ppl=2.98, accuracy=62.072, wps=14002.5, ups=1.15, wpb=12212.6, bsz=445.7, num_updates=17000, lr=0.000108465, gnorm=0.19, clip=0, loss_scale=64, train_wall=87, gb_free=16.6, wall=14899
2023-07-10 19:34:54 | INFO | train_inner | epoch 012:    894 / 1474 loss=1.8, trans_loss=3.436, nll_loss=1.577, w2v_ctc_loss=0.481, task_loss=0.795, contrastive_loss=0.156, total=4169.74, n_correct=2589.72, ppl=2.98, accuracy=62.107, wps=14114.8, ups=1.13, wpb=12453, bsz=459.6, num_updates=17100, lr=0.000108148, gnorm=0.186, clip=0, loss_scale=64, train_wall=88, gb_free=16.2, wall=14987
2023-07-10 19:36:21 | INFO | train_inner | epoch 012:    994 / 1474 loss=1.804, trans_loss=3.442, nll_loss=1.584, w2v_ctc_loss=0.487, task_loss=0.807, contrastive_loss=0.172, total=4117.67, n_correct=2544.58, ppl=3, accuracy=61.797, wps=14149.2, ups=1.15, wpb=12288, bsz=452.1, num_updates=17200, lr=0.000107833, gnorm=0.188, clip=0, loss_scale=64, train_wall=86, gb_free=17.7, wall=15074
2023-07-10 19:37:47 | INFO | train_inner | epoch 012:   1094 / 1474 loss=1.819, trans_loss=3.447, nll_loss=1.59, w2v_ctc_loss=0.491, task_loss=0.862, contrastive_loss=0.231, total=4047.61, n_correct=2499.68, ppl=3.01, accuracy=61.757, wps=13957.3, ups=1.15, wpb=12086.1, bsz=435.6, num_updates=17300, lr=0.000107521, gnorm=0.192, clip=0, loss_scale=64, train_wall=86, gb_free=16.9, wall=15161
2023-07-10 19:39:15 | INFO | train_inner | epoch 012:   1194 / 1474 loss=1.81, trans_loss=3.449, nll_loss=1.595, w2v_ctc_loss=0.495, task_loss=0.82, contrastive_loss=0.172, total=4184.55, n_correct=2574.78, ppl=3.02, accuracy=61.531, wps=14290.7, ups=1.14, wpb=12497.1, bsz=471.4, num_updates=17400, lr=0.000107211, gnorm=0.189, clip=0, loss_scale=64, train_wall=87, gb_free=16.9, wall=15248
2023-07-10 19:40:42 | INFO | train_inner | epoch 012:   1294 / 1474 loss=1.803, trans_loss=3.45, nll_loss=1.597, w2v_ctc_loss=0.492, task_loss=0.88, contrastive_loss=0.098, total=4086.33, n_correct=2522.3, ppl=3.03, accuracy=61.725, wps=14043, ups=1.15, wpb=12210.8, bsz=437.2, num_updates=17500, lr=0.000106904, gnorm=0.191, clip=0, loss_scale=64, train_wall=87, gb_free=17, wall=15335
2023-07-10 19:41:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-10 19:42:10 | INFO | train_inner | epoch 012:   1395 / 1474 loss=1.797, trans_loss=3.444, nll_loss=1.587, w2v_ctc_loss=0.482, task_loss=0.839, contrastive_loss=0.087, total=4126.63, n_correct=2555.03, ppl=3, accuracy=61.916, wps=13899.6, ups=1.13, wpb=12303.1, bsz=448.2, num_updates=17600, lr=0.0001066, gnorm=0.188, clip=0, loss_scale=64, train_wall=88, gb_free=17.2, wall=15424
2023-07-10 19:43:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 19:43:47 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 1.752 | trans_loss 5.63 | nll_loss 2.919 | w2v_ctc_loss 0.541 | task_loss 3.894 | contrastive_loss 0.266 | total 4003.4 | n_correct 2434.4 | ppl 7.56 | accuracy 60.808 | uer 17.782 | wer 19.515 | raw_wer 19.515 | bleu 18.84 | wps 1957.4 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.63
2023-07-10 19:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-07-10 19:43:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.8406.pt
2023-07-10 19:43:50 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.8406.pt
2023-07-10 19:43:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_18.8406.pt (epoch 12 @ 17679 updates, score 18.84) (writing took 5.061017281026579 seconds)
2023-07-10 19:43:53 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-10 19:43:53 | INFO | train | epoch 012 | loss 1.799 | trans_loss 3.44 | nll_loss 1.581 | w2v_ctc_loss 0.484 | task_loss 0.796 | contrastive_loss 0.143 | total 4137.82 | n_correct 2565.03 | ppl 2.99 | accuracy 61.99 | wps 13690.6 | ups 1.11 | wpb 12353.8 | bsz 457.9 | num_updates 17679 | lr 0.000106362 | gnorm 0.187 | clip 0 | loss_scale 64 | train_wall 1282 | gb_free 13.2 | wall 15526
2023-07-10 19:43:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 19:43:53 | INFO | fairseq.trainer | begin training epoch 13
2023-07-10 19:43:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 19:44:19 | INFO | train_inner | epoch 013:     21 / 1474 loss=1.802, trans_loss=3.444, nll_loss=1.589, w2v_ctc_loss=0.491, task_loss=0.904, contrastive_loss=0.087, total=4096.49, n_correct=2534.51, ppl=3.01, accuracy=61.87, wps=9487, ups=0.77, wpb=12243.5, bsz=443.1, num_updates=17700, lr=0.000106299, gnorm=0.189, clip=0, loss_scale=64, train_wall=87, gb_free=14.8, wall=15553
2023-07-10 19:45:47 | INFO | train_inner | epoch 013:    121 / 1474 loss=1.779, trans_loss=3.421, nll_loss=1.557, w2v_ctc_loss=0.469, task_loss=0.906, contrastive_loss=0.103, total=4160.97, n_correct=2608.78, ppl=2.94, accuracy=62.696, wps=14168.8, ups=1.14, wpb=12418.2, bsz=454.3, num_updates=17800, lr=0.000106, gnorm=0.185, clip=0, loss_scale=64, train_wall=87, gb_free=16.5, wall=15641
2023-07-10 19:47:15 | INFO | train_inner | epoch 013:    221 / 1474 loss=1.803, trans_loss=3.425, nll_loss=1.565, w2v_ctc_loss=0.471, task_loss=0.816, contrastive_loss=0.395, total=4212.08, n_correct=2631.96, ppl=2.96, accuracy=62.486, wps=14164.9, ups=1.13, wpb=12529.8, bsz=494.6, num_updates=17900, lr=0.000105703, gnorm=0.186, clip=0, loss_scale=64, train_wall=88, gb_free=14.9, wall=15729
2023-07-10 19:48:42 | INFO | train_inner | epoch 013:    321 / 1474 loss=1.784, trans_loss=3.427, nll_loss=1.562, w2v_ctc_loss=0.469, task_loss=0.945, contrastive_loss=0.096, total=4102.3, n_correct=2575.54, ppl=2.95, accuracy=62.783, wps=14055.5, ups=1.15, wpb=12230, bsz=441.1, num_updates=18000, lr=0.000105409, gnorm=0.188, clip=0, loss_scale=64, train_wall=87, gb_free=17.4, wall=15816
2023-07-10 19:48:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 19:49:11 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 1.752 | trans_loss 5.631 | nll_loss 2.916 | w2v_ctc_loss 0.53 | task_loss 3.956 | contrastive_loss 0.265 | total 4003.4 | n_correct 2437.6 | ppl 7.55 | accuracy 60.888 | uer 17.477 | wer 19.298 | raw_wer 19.298 | bleu 19.18 | wps 1955.6 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.63
2023-07-10 19:49:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-10 19:49:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_13_18000.pt
2023-07-10 19:49:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_13_18000.pt
2023-07-10 19:49:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.18) (writing took 6.38770071399631 seconds)
2023-07-10 19:50:44 | INFO | train_inner | epoch 013:    421 / 1474 loss=1.795, trans_loss=3.432, nll_loss=1.571, w2v_ctc_loss=0.473, task_loss=0.887, contrastive_loss=0.16, total=4177.29, n_correct=2619.04, ppl=2.97, accuracy=62.697, wps=10276.2, ups=0.82, wpb=12461.8, bsz=477.6, num_updates=18100, lr=0.000105118, gnorm=0.187, clip=0, loss_scale=64, train_wall=86, gb_free=17.6, wall=15937
2023-07-10 19:52:12 | INFO | train_inner | epoch 013:    521 / 1474 loss=1.804, trans_loss=3.435, nll_loss=1.574, w2v_ctc_loss=0.476, task_loss=0.947, contrastive_loss=0.211, total=4201.22, n_correct=2621.43, ppl=2.98, accuracy=62.397, wps=14131.3, ups=1.13, wpb=12536.9, bsz=478.4, num_updates=18200, lr=0.000104828, gnorm=0.187, clip=0, loss_scale=64, train_wall=88, gb_free=13.2, wall=16026
2023-07-10 19:53:40 | INFO | train_inner | epoch 013:    621 / 1474 loss=1.783, trans_loss=3.425, nll_loss=1.562, w2v_ctc_loss=0.469, task_loss=0.953, contrastive_loss=0.094, total=4161.98, n_correct=2614.97, ppl=2.95, accuracy=62.83, wps=14272.7, ups=1.15, wpb=12435.5, bsz=462.4, num_updates=18300, lr=0.000104542, gnorm=0.185, clip=0, loss_scale=64, train_wall=87, gb_free=16, wall=16113
2023-07-10 19:55:07 | INFO | train_inner | epoch 013:    721 / 1474 loss=1.799, trans_loss=3.433, nll_loss=1.572, w2v_ctc_loss=0.487, task_loss=1.077, contrastive_loss=0.091, total=4096.76, n_correct=2554.31, ppl=2.97, accuracy=62.35, wps=13990, ups=1.14, wpb=12226.1, bsz=426.8, num_updates=18400, lr=0.000104257, gnorm=0.189, clip=0, loss_scale=64, train_wall=87, gb_free=16.8, wall=16201
2023-07-10 19:56:35 | INFO | train_inner | epoch 013:    821 / 1474 loss=1.794, trans_loss=3.431, nll_loss=1.57, w2v_ctc_loss=0.474, task_loss=0.941, contrastive_loss=0.148, total=4121.73, n_correct=2571.44, ppl=2.97, accuracy=62.387, wps=13963.3, ups=1.13, wpb=12319.8, bsz=460, num_updates=18500, lr=0.000103975, gnorm=0.19, clip=0, loss_scale=64, train_wall=88, gb_free=15, wall=16289
2023-07-10 19:58:02 | INFO | train_inner | epoch 013:    921 / 1474 loss=1.786, trans_loss=3.432, nll_loss=1.573, w2v_ctc_loss=0.474, task_loss=0.943, contrastive_loss=0.098, total=4107.01, n_correct=2564.6, ppl=2.98, accuracy=62.444, wps=14138.8, ups=1.15, wpb=12264.1, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.189, clip=0, loss_scale=64, train_wall=86, gb_free=16.1, wall=16375
2023-07-10 19:59:28 | INFO | train_inner | epoch 013:   1021 / 1474 loss=1.798, trans_loss=3.431, nll_loss=1.574, w2v_ctc_loss=0.481, task_loss=0.959, contrastive_loss=0.162, total=4081.02, n_correct=2535.16, ppl=2.98, accuracy=62.121, wps=14103.1, ups=1.16, wpb=12208.8, bsz=440.1, num_updates=18700, lr=0.000103418, gnorm=0.189, clip=0, loss_scale=64, train_wall=86, gb_free=16.4, wall=16462
2023-07-10 20:00:55 | INFO | train_inner | epoch 013:   1121 / 1474 loss=1.79, trans_loss=3.431, nll_loss=1.569, w2v_ctc_loss=0.472, task_loss=0.938, contrastive_loss=0.146, total=4105.62, n_correct=2569.65, ppl=2.97, accuracy=62.589, wps=14211.7, ups=1.16, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.19, clip=0, loss_scale=64, train_wall=86, gb_free=16.9, wall=16548
2023-07-10 20:02:22 | INFO | train_inner | epoch 013:   1221 / 1474 loss=1.799, trans_loss=3.441, nll_loss=1.582, w2v_ctc_loss=0.482, task_loss=1.031, contrastive_loss=0.096, total=4110.35, n_correct=2561.08, ppl=2.99, accuracy=62.308, wps=14120, ups=1.15, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.19, clip=0, loss_scale=64, train_wall=87, gb_free=15.1, wall=16635
2023-07-10 20:03:49 | INFO | train_inner | epoch 013:   1321 / 1474 loss=1.794, trans_loss=3.429, nll_loss=1.57, w2v_ctc_loss=0.473, task_loss=0.932, contrastive_loss=0.218, total=4112.2, n_correct=2574.38, ppl=2.97, accuracy=62.603, wps=14110.1, ups=1.15, wpb=12280.4, bsz=462.3, num_updates=19000, lr=0.000102598, gnorm=0.191, clip=0, loss_scale=64, train_wall=87, gb_free=17.7, wall=16722
2023-07-10 20:05:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-10 20:05:17 | INFO | train_inner | epoch 013:   1422 / 1474 loss=1.788, trans_loss=3.439, nll_loss=1.58, w2v_ctc_loss=0.476, task_loss=0.936, contrastive_loss=0.077, total=4156.59, n_correct=2591.06, ppl=2.99, accuracy=62.336, wps=14103.3, ups=1.14, wpb=12408.2, bsz=455, num_updates=19100, lr=0.000102329, gnorm=0.187, clip=0, loss_scale=32, train_wall=88, gb_free=16.2, wall=16810
2023-07-10 20:06:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 20:06:31 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 1.743 | trans_loss 5.611 | nll_loss 2.894 | w2v_ctc_loss 0.532 | task_loss 3.97 | contrastive_loss 0.261 | total 4003.4 | n_correct 2446.9 | ppl 7.43 | accuracy 61.121 | uer 17.195 | wer 18.795 | raw_wer 18.795 | bleu 19.21 | wps 1832.4 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 19.63
2023-07-10 20:06:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-07-10 20:06:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.2101.pt
2023-07-10 20:06:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.2101.pt
2023-07-10 20:06:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.2101.pt (epoch 13 @ 19152 updates, score 19.21) (writing took 5.239489630970638 seconds)
2023-07-10 20:06:36 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-10 20:06:36 | INFO | train | epoch 013 | loss 1.792 | trans_loss 3.431 | nll_loss 1.57 | w2v_ctc_loss 0.475 | task_loss 0.938 | contrastive_loss 0.15 | total 4137.23 | n_correct 2586.07 | ppl 2.97 | accuracy 62.507 | wps 13343.6 | ups 1.08 | wpb 12352.2 | bsz 457.7 | num_updates 19152 | lr 0.00010219 | gnorm 0.188 | clip 0 | loss_scale 32 | train_wall 1280 | gb_free 17.7 | wall 16890
2023-07-10 20:06:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 20:06:37 | INFO | fairseq.trainer | begin training epoch 14
2023-07-10 20:06:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 20:07:26 | INFO | train_inner | epoch 014:     48 / 1474 loss=1.771, trans_loss=3.414, nll_loss=1.55, w2v_ctc_loss=0.463, task_loss=0.852, contrastive_loss=0.102, total=4179.66, n_correct=2637.63, ppl=2.93, accuracy=63.106, wps=9657.7, ups=0.77, wpb=12495.5, bsz=483, num_updates=19200, lr=0.000102062, gnorm=0.184, clip=0, loss_scale=32, train_wall=86, gb_free=11, wall=16940
2023-07-10 20:08:53 | INFO | train_inner | epoch 014:    148 / 1474 loss=1.768, trans_loss=3.41, nll_loss=1.542, w2v_ctc_loss=0.461, task_loss=0.922, contrastive_loss=0.079, total=4081.01, n_correct=2591.47, ppl=2.91, accuracy=63.501, wps=14104.8, ups=1.16, wpb=12201.4, bsz=450.9, num_updates=19300, lr=0.000101797, gnorm=0.186, clip=0, loss_scale=32, train_wall=86, gb_free=16.1, wall=17026
2023-07-10 20:10:20 | INFO | train_inner | epoch 014:    248 / 1474 loss=1.783, trans_loss=3.421, nll_loss=1.556, w2v_ctc_loss=0.463, task_loss=0.996, contrastive_loss=0.209, total=4109.83, n_correct=2593.58, ppl=2.94, accuracy=63.107, wps=13981.4, ups=1.14, wpb=12237.8, bsz=442.7, num_updates=19400, lr=0.000101535, gnorm=0.187, clip=0, loss_scale=32, train_wall=87, gb_free=15.9, wall=17114
2023-07-10 20:11:47 | INFO | train_inner | epoch 014:    348 / 1474 loss=1.77, trans_loss=3.407, nll_loss=1.547, w2v_ctc_loss=0.462, task_loss=0.889, contrastive_loss=0.124, total=4171.83, n_correct=2638.53, ppl=2.92, accuracy=63.246, wps=14284.1, ups=1.15, wpb=12430.7, bsz=479.5, num_updates=19500, lr=0.000101274, gnorm=0.188, clip=0, loss_scale=32, train_wall=87, gb_free=16.8, wall=17201
2023-07-10 20:13:15 | INFO | train_inner | epoch 014:    448 / 1474 loss=1.774, trans_loss=3.416, nll_loss=1.553, w2v_ctc_loss=0.464, task_loss=0.952, contrastive_loss=0.086, total=4142.75, n_correct=2610.57, ppl=2.93, accuracy=63.015, wps=14145.2, ups=1.15, wpb=12340.5, bsz=453.3, num_updates=19600, lr=0.000101015, gnorm=0.188, clip=0, loss_scale=32, train_wall=87, gb_free=16.8, wall=17288
2023-07-10 20:14:42 | INFO | train_inner | epoch 014:    548 / 1474 loss=1.783, trans_loss=3.426, nll_loss=1.563, w2v_ctc_loss=0.471, task_loss=0.987, contrastive_loss=0.097, total=4073.76, n_correct=2557.81, ppl=2.95, accuracy=62.787, wps=13921, ups=1.14, wpb=12222.1, bsz=436.3, num_updates=19700, lr=0.000100759, gnorm=0.187, clip=0, loss_scale=32, train_wall=87, gb_free=15.6, wall=17376
2023-07-10 20:16:10 | INFO | train_inner | epoch 014:    648 / 1474 loss=1.781, trans_loss=3.422, nll_loss=1.559, w2v_ctc_loss=0.463, task_loss=0.887, contrastive_loss=0.174, total=4158.79, n_correct=2616.36, ppl=2.95, accuracy=62.912, wps=14239.4, ups=1.15, wpb=12412.4, bsz=460.2, num_updates=19800, lr=0.000100504, gnorm=0.188, clip=0, loss_scale=32, train_wall=87, gb_free=17.3, wall=17463
2023-07-10 20:17:36 | INFO | train_inner | epoch 014:    748 / 1474 loss=1.77, trans_loss=3.414, nll_loss=1.551, w2v_ctc_loss=0.464, task_loss=0.883, contrastive_loss=0.083, total=4145.47, n_correct=2619.42, ppl=2.93, accuracy=63.188, wps=14333.4, ups=1.16, wpb=12397.1, bsz=464.3, num_updates=19900, lr=0.000100251, gnorm=0.186, clip=0, loss_scale=32, train_wall=86, gb_free=16.4, wall=17550
2023-07-10 20:19:03 | INFO | train_inner | epoch 014:    848 / 1474 loss=1.78, trans_loss=3.411, nll_loss=1.549, w2v_ctc_loss=0.46, task_loss=0.882, contrastive_loss=0.231, total=4171.1, n_correct=2633.53, ppl=2.93, accuracy=63.138, wps=14236.7, ups=1.14, wpb=12447.1, bsz=479.5, num_updates=20000, lr=0.0001, gnorm=0.186, clip=0, loss_scale=32, train_wall=87, gb_free=16.9, wall=17637
2023-07-10 20:19:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 20:19:31 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 1.743 | trans_loss 5.608 | nll_loss 2.886 | w2v_ctc_loss 0.544 | task_loss 3.899 | contrastive_loss 0.247 | total 4003.4 | n_correct 2447.1 | ppl 7.39 | accuracy 61.126 | uer 17.203 | wer 19.134 | raw_wer 19.134 | bleu 19.39 | wps 1965.9 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.63
2023-07-10 20:19:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-10 20:19:31 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_14_20000.pt
2023-07-10 20:19:33 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_14_20000.pt
2023-07-10 20:19:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.39) (writing took 6.266433656041045 seconds)
tensor(0.0287, device='cuda:0')
tensor(0.0016, device='cuda:0')
2023-07-10 20:20:39 | INFO | train_inner | epoch 014:    948 / 1474 loss=1.098, trans_loss=5.364, nll_loss=2.709, w2v_ctc_loss=0.357, task_loss=2.717, contrastive_loss=0.218, total=4167.75, n_correct=2608.21, ppl=6.54, accuracy=62.581, wps=4449.4, ups=1.04, wpb=4260.9, bsz=157.9, num_updates=20100, lr=9.97509e-05, gnorm=0.266, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=17733
2023-07-10 20:21:41 | INFO | train_inner | epoch 014:   1048 / 1474 loss=1.09, trans_loss=5.435, nll_loss=2.757, w2v_ctc_loss=0.359, task_loss=2.76, contrastive_loss=0.173, total=4143.92, n_correct=2593.66, ppl=6.76, accuracy=62.59, wps=6730.5, ups=1.62, wpb=4143.9, bsz=150.4, num_updates=20200, lr=9.95037e-05, gnorm=0.267, clip=0, loss_scale=32, train_wall=61, gb_free=16.2, wall=17794
2023-07-10 20:22:42 | INFO | train_inner | epoch 014:   1148 / 1474 loss=1.104, trans_loss=5.441, nll_loss=2.764, w2v_ctc_loss=0.363, task_loss=2.614, contrastive_loss=0.72, total=4228.69, n_correct=2641.8, ppl=6.79, accuracy=62.473, wps=6881.6, ups=1.63, wpb=4228.7, bsz=163.6, num_updates=20300, lr=9.92583e-05, gnorm=0.269, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=17856
2023-07-10 20:23:42 | INFO | train_inner | epoch 014:   1248 / 1474 loss=1.094, trans_loss=5.444, nll_loss=2.765, w2v_ctc_loss=0.367, task_loss=3.365, contrastive_loss=0.099, total=4021.19, n_correct=2512, ppl=6.8, accuracy=62.469, wps=6679.2, ups=1.66, wpb=4021.2, bsz=135.8, num_updates=20400, lr=9.90148e-05, gnorm=0.27, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=17916
2023-07-10 20:24:44 | INFO | train_inner | epoch 014:   1348 / 1474 loss=1.08, trans_loss=5.425, nll_loss=2.744, w2v_ctc_loss=0.351, task_loss=2.689, contrastive_loss=0.135, total=4213.9, n_correct=2642.79, ppl=6.7, accuracy=62.716, wps=6856.1, ups=1.63, wpb=4213.9, bsz=159.7, num_updates=20500, lr=9.8773e-05, gnorm=0.259, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=17977
2023-07-10 20:25:45 | INFO | train_inner | epoch 014:   1448 / 1474 loss=1.09, trans_loss=5.445, nll_loss=2.769, w2v_ctc_loss=0.359, task_loss=2.721, contrastive_loss=0.209, total=4130.28, n_correct=2581.3, ppl=6.82, accuracy=62.497, wps=6778.8, ups=1.64, wpb=4130.3, bsz=152, num_updates=20600, lr=9.85329e-05, gnorm=0.267, clip=0, loss_scale=32, train_wall=61, gb_free=15.6, wall=18038
2023-07-10 20:26:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0287, device='cuda:2')
tensor(0.0016, device='cuda:2')
tensor(0.0287, device='cuda:5')
tensor(0.0016, device='cuda:5')
tensor(0.0287, device='cuda:7')
tensor(0.0016, device='cuda:7')
tensor(0.0287, device='cuda:1')
tensor(0.0016, device='cuda:1')
tensor(0.0287, device='cuda:3')
tensor(0.0016, device='cuda:3')
tensor(0.0287, device='cuda:6')
tensor(0.0016, device='cuda:6')
tensor(0.0287, device='cuda:4')
tensor(0.0016, device='cuda:4')
2023-07-10 20:26:28 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 1.743 | trans_loss 5.608 | nll_loss 2.893 | w2v_ctc_loss 0.545 | task_loss 3.864 | contrastive_loss 0.252 | total 4003.4 | n_correct 2454.2 | ppl 7.43 | accuracy 61.303 | uer 17.495 | wer 19.373 | raw_wer 19.373 | bleu 19.28 | wps 1972 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.63
2023-07-10 20:26:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-07-10 20:26:28 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.2802.pt
2023-07-10 20:26:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.2802.pt
2023-07-10 20:26:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.2802.pt (epoch 14 @ 20626 updates, score 19.28) (writing took 5.149225361994468 seconds)
2023-07-10 20:26:34 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-10 20:26:34 | INFO | train | epoch 014 | loss 1.551 | trans_loss 3.815 | nll_loss 1.791 | w2v_ctc_loss 0.429 | task_loss 1.291 | contrastive_loss 0.158 | total 4138.65 | n_correct 2602.46 | ppl 3.46 | accuracy 62.882 | wps 10916.3 | ups 1.23 | wpb 8868.8 | bsz 329.4 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.221 | clip 0 | loss_scale 32 | train_wall 1116 | gb_free 16.6 | wall 18087
2023-07-10 20:26:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 20:26:34 | INFO | fairseq.trainer | begin training epoch 15
2023-07-10 20:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 20:27:26 | INFO | train_inner | epoch 015:     74 / 1474 loss=1.082, trans_loss=5.401, nll_loss=2.711, w2v_ctc_loss=0.35, task_loss=2.792, contrastive_loss=0.308, total=4083.88, n_correct=2581.2, ppl=6.55, accuracy=63.205, wps=4042.3, ups=0.99, wpb=4083.9, bsz=150.1, num_updates=20700, lr=9.82946e-05, gnorm=0.268, clip=0, loss_scale=32, train_wall=59, gb_free=16.4, wall=18139
2023-07-10 20:28:26 | INFO | train_inner | epoch 015:    174 / 1474 loss=1.08, trans_loss=5.391, nll_loss=2.697, w2v_ctc_loss=0.355, task_loss=2.981, contrastive_loss=0.122, total=4115.73, n_correct=2604.57, ppl=6.49, accuracy=63.283, wps=6792.7, ups=1.65, wpb=4115.7, bsz=148.9, num_updates=20800, lr=9.80581e-05, gnorm=0.265, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=18200
2023-07-10 20:29:27 | INFO | train_inner | epoch 015:    274 / 1474 loss=1.071, trans_loss=5.38, nll_loss=2.684, w2v_ctc_loss=0.348, task_loss=2.754, contrastive_loss=0.107, total=4193.15, n_correct=2666.13, ppl=6.42, accuracy=63.583, wps=6909.9, ups=1.65, wpb=4193.1, bsz=156.3, num_updates=20900, lr=9.78232e-05, gnorm=0.261, clip=0, loss_scale=32, train_wall=60, gb_free=13.1, wall=18261
2023-07-10 20:30:28 | INFO | train_inner | epoch 015:    374 / 1474 loss=1.08, trans_loss=5.386, nll_loss=2.692, w2v_ctc_loss=0.351, task_loss=2.784, contrastive_loss=0.16, total=4167.66, n_correct=2640.62, ppl=6.46, accuracy=63.36, wps=6896.1, ups=1.65, wpb=4167.7, bsz=153, num_updates=21000, lr=9.759e-05, gnorm=0.266, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=18321
2023-07-10 20:31:29 | INFO | train_inner | epoch 015:    474 / 1474 loss=1.085, trans_loss=5.399, nll_loss=2.708, w2v_ctc_loss=0.353, task_loss=2.843, contrastive_loss=0.342, total=4074.53, n_correct=2572.45, ppl=6.54, accuracy=63.135, wps=6628.9, ups=1.63, wpb=4074.5, bsz=147.1, num_updates=21100, lr=9.73585e-05, gnorm=0.27, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=18383
2023-07-10 20:32:30 | INFO | train_inner | epoch 015:    574 / 1474 loss=1.081, trans_loss=5.4, nll_loss=2.71, w2v_ctc_loss=0.356, task_loss=2.918, contrastive_loss=0.128, total=4140.59, n_correct=2610.6, ppl=6.54, accuracy=63.049, wps=6808.4, ups=1.64, wpb=4140.6, bsz=149.4, num_updates=21200, lr=9.71286e-05, gnorm=0.264, clip=0, loss_scale=64, train_wall=60, gb_free=12.6, wall=18443
2023-07-10 20:33:31 | INFO | train_inner | epoch 015:    674 / 1474 loss=1.084, trans_loss=5.399, nll_loss=2.709, w2v_ctc_loss=0.356, task_loss=2.892, contrastive_loss=0.293, total=4134.99, n_correct=2615.72, ppl=6.54, accuracy=63.258, wps=6806.8, ups=1.65, wpb=4135, bsz=153.5, num_updates=21300, lr=9.69003e-05, gnorm=0.268, clip=0, loss_scale=64, train_wall=60, gb_free=11.1, wall=18504
2023-07-10 20:34:32 | INFO | train_inner | epoch 015:    774 / 1474 loss=1.084, trans_loss=5.405, nll_loss=2.717, w2v_ctc_loss=0.357, task_loss=2.835, contrastive_loss=0.135, total=4173.66, n_correct=2628.96, ppl=6.58, accuracy=62.989, wps=6847.8, ups=1.64, wpb=4173.7, bsz=152.5, num_updates=21400, lr=9.66736e-05, gnorm=0.268, clip=0, loss_scale=64, train_wall=61, gb_free=16.9, wall=18565
2023-07-10 20:35:32 | INFO | train_inner | epoch 015:    874 / 1474 loss=1.079, trans_loss=5.414, nll_loss=2.73, w2v_ctc_loss=0.356, task_loss=2.9, contrastive_loss=0.124, total=4059.35, n_correct=2551.77, ppl=6.64, accuracy=62.862, wps=6744.4, ups=1.66, wpb=4059.3, bsz=144.1, num_updates=21500, lr=9.64486e-05, gnorm=0.269, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=18625
2023-07-10 20:36:32 | INFO | train_inner | epoch 015:    974 / 1474 loss=1.083, trans_loss=5.401, nll_loss=2.713, w2v_ctc_loss=0.351, task_loss=2.705, contrastive_loss=0.299, total=4122.87, n_correct=2601.83, ppl=6.56, accuracy=63.107, wps=6846.8, ups=1.66, wpb=4122.9, bsz=150.8, num_updates=21600, lr=9.6225e-05, gnorm=0.264, clip=0, loss_scale=64, train_wall=60, gb_free=17.7, wall=18686
2023-07-10 20:37:33 | INFO | train_inner | epoch 015:   1074 / 1474 loss=1.092, trans_loss=5.412, nll_loss=2.728, w2v_ctc_loss=0.354, task_loss=2.638, contrastive_loss=0.616, total=4192.24, n_correct=2637.91, ppl=6.62, accuracy=62.924, wps=6824.5, ups=1.63, wpb=4192.2, bsz=162.6, num_updates=21700, lr=9.60031e-05, gnorm=0.266, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=18747
2023-07-10 20:38:34 | INFO | train_inner | epoch 015:   1174 / 1474 loss=1.074, trans_loss=5.384, nll_loss=2.693, w2v_ctc_loss=0.345, task_loss=2.705, contrastive_loss=0.241, total=4185, n_correct=2657.6, ppl=6.47, accuracy=63.503, wps=6879.5, ups=1.64, wpb=4185, bsz=164.6, num_updates=21800, lr=9.57826e-05, gnorm=0.261, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=18808
2023-07-10 20:39:35 | INFO | train_inner | epoch 015:   1274 / 1474 loss=1.082, trans_loss=5.402, nll_loss=2.715, w2v_ctc_loss=0.358, task_loss=2.997, contrastive_loss=0.153, total=4152.04, n_correct=2620.5, ppl=6.56, accuracy=63.114, wps=6823.9, ups=1.64, wpb=4152, bsz=151.8, num_updates=21900, lr=9.55637e-05, gnorm=0.264, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=18869
2023-07-10 20:40:36 | INFO | train_inner | epoch 015:   1374 / 1474 loss=1.085, trans_loss=5.404, nll_loss=2.717, w2v_ctc_loss=0.356, task_loss=3.034, contrastive_loss=0.125, total=4100.21, n_correct=2588.93, ppl=6.57, accuracy=63.141, wps=6788, ups=1.66, wpb=4100.2, bsz=146.8, num_updates=22000, lr=9.53463e-05, gnorm=0.265, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=18929
2023-07-10 20:40:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 20:41:02 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 1.732 | trans_loss 5.596 | nll_loss 2.874 | w2v_ctc_loss 0.514 | task_loss 3.768 | contrastive_loss 0.266 | total 4003.4 | n_correct 2460.4 | ppl 7.33 | accuracy 61.458 | uer 17.097 | wer 18.881 | raw_wer 18.881 | bleu 19.88 | wps 1989.9 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.88
2023-07-10 20:41:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-10 20:41:02 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_15_22000.pt
2023-07-10 20:41:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_15_22000.pt
2023-07-10 20:41:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.88) (writing took 8.950172487995587 seconds)
2023-07-10 20:42:13 | INFO | train_inner | epoch 015:   1474 / 1474 loss=1.083, trans_loss=5.412, nll_loss=2.731, w2v_ctc_loss=0.357, task_loss=2.848, contrastive_loss=0.3, total=4141.17, n_correct=2608.45, ppl=6.64, accuracy=62.988, wps=4230.6, ups=1.02, wpb=4141.2, bsz=157.2, num_updates=22100, lr=9.51303e-05, gnorm=0.263, clip=0, loss_scale=64, train_wall=61, gb_free=17.2, wall=19027
2023-07-10 20:42:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 20:42:41 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 1.734 | trans_loss 5.594 | nll_loss 2.875 | w2v_ctc_loss 0.532 | task_loss 3.832 | contrastive_loss 0.263 | total 4003.4 | n_correct 2457.7 | ppl 7.34 | accuracy 61.39 | uer 17.482 | wer 19.302 | raw_wer 19.302 | bleu 19.69 | wps 1823.3 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 19.88
2023-07-10 20:42:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-07-10 20:42:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6900.pt
2023-07-10 20:42:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6900.pt
2023-07-10 20:42:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6900.pt (epoch 15 @ 22100 updates, score 19.69) (writing took 5.166272125032265 seconds)
2023-07-10 20:42:47 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-10 20:42:47 | INFO | train | epoch 015 | loss 1.081 | trans_loss 5.398 | nll_loss 2.709 | w2v_ctc_loss 0.353 | task_loss 2.836 | contrastive_loss 0.234 | total 4138.65 | n_correct 2614.91 | ppl 6.54 | accuracy 63.183 | wps 6269 | ups 1.51 | wpb 4138.6 | bsz 152.8 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.265 | clip 0 | loss_scale 64 | train_wall 889 | gb_free 17.2 | wall 19060
2023-07-10 20:42:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 20:42:47 | INFO | fairseq.trainer | begin training epoch 16
2023-07-10 20:42:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 20:43:55 | INFO | train_inner | epoch 016:    100 / 1474 loss=1.067, trans_loss=5.349, nll_loss=2.646, w2v_ctc_loss=0.341, task_loss=2.72, contrastive_loss=0.178, total=4126.22, n_correct=2642.92, ppl=6.26, accuracy=64.052, wps=4045.6, ups=0.98, wpb=4126.2, bsz=157.8, num_updates=22200, lr=9.49158e-05, gnorm=0.26, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=19129
2023-07-10 20:44:56 | INFO | train_inner | epoch 016:    200 / 1474 loss=1.062, trans_loss=5.351, nll_loss=2.647, w2v_ctc_loss=0.34, task_loss=2.949, contrastive_loss=0.124, total=4100.6, n_correct=2620.11, ppl=6.26, accuracy=63.896, wps=6766.3, ups=1.65, wpb=4100.6, bsz=148.4, num_updates=22300, lr=9.47027e-05, gnorm=0.261, clip=0, loss_scale=64, train_wall=60, gb_free=13, wall=19190
2023-07-10 20:45:57 | INFO | train_inner | epoch 016:    300 / 1474 loss=1.08, trans_loss=5.369, nll_loss=2.672, w2v_ctc_loss=0.351, task_loss=2.857, contrastive_loss=0.28, total=4166.94, n_correct=2654.15, ppl=6.37, accuracy=63.695, wps=6812.9, ups=1.63, wpb=4166.9, bsz=154.5, num_updates=22400, lr=9.44911e-05, gnorm=0.264, clip=0, loss_scale=64, train_wall=61, gb_free=17.3, wall=19251
2023-07-10 20:46:57 | INFO | train_inner | epoch 016:    400 / 1474 loss=1.077, trans_loss=5.375, nll_loss=2.678, w2v_ctc_loss=0.35, task_loss=3.194, contrastive_loss=0.298, total=4073.3, n_correct=2592.74, ppl=6.4, accuracy=63.652, wps=6769.2, ups=1.66, wpb=4073.3, bsz=144, num_updates=22500, lr=9.42809e-05, gnorm=0.269, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=19311
2023-07-10 20:47:58 | INFO | train_inner | epoch 016:    500 / 1474 loss=1.074, trans_loss=5.367, nll_loss=2.67, w2v_ctc_loss=0.348, task_loss=3.059, contrastive_loss=0.197, total=4174.67, n_correct=2665.04, ppl=6.36, accuracy=63.838, wps=6841.8, ups=1.64, wpb=4174.7, bsz=159.5, num_updates=22600, lr=9.40721e-05, gnorm=0.265, clip=0, loss_scale=64, train_wall=61, gb_free=16.1, wall=19372
2023-07-10 20:48:58 | INFO | train_inner | epoch 016:    600 / 1474 loss=1.077, trans_loss=5.373, nll_loss=2.678, w2v_ctc_loss=0.35, task_loss=3.121, contrastive_loss=0.121, total=4124.65, n_correct=2625.42, ppl=6.4, accuracy=63.652, wps=6870.9, ups=1.67, wpb=4124.6, bsz=148.8, num_updates=22700, lr=9.38647e-05, gnorm=0.264, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=19432
2023-07-10 20:49:58 | INFO | train_inner | epoch 016:    700 / 1474 loss=1.077, trans_loss=5.377, nll_loss=2.683, w2v_ctc_loss=0.353, task_loss=3.027, contrastive_loss=0.118, total=4095.49, n_correct=2600.3, ppl=6.42, accuracy=63.492, wps=6827.8, ups=1.67, wpb=4095.5, bsz=148.2, num_updates=22800, lr=9.36586e-05, gnorm=0.266, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=19492
2023-07-10 20:50:59 | INFO | train_inner | epoch 016:    800 / 1474 loss=1.073, trans_loss=5.367, nll_loss=2.671, w2v_ctc_loss=0.342, task_loss=2.86, contrastive_loss=0.238, total=4174.94, n_correct=2654.27, ppl=6.37, accuracy=63.576, wps=6867.9, ups=1.65, wpb=4174.9, bsz=155.4, num_updates=22900, lr=9.34539e-05, gnorm=0.26, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=19553
2023-07-10 20:52:00 | INFO | train_inner | epoch 016:    900 / 1474 loss=1.074, trans_loss=5.368, nll_loss=2.673, w2v_ctc_loss=0.347, task_loss=2.866, contrastive_loss=0.228, total=4163.19, n_correct=2651.82, ppl=6.38, accuracy=63.697, wps=6820.9, ups=1.64, wpb=4163.2, bsz=155.3, num_updates=23000, lr=9.32505e-05, gnorm=0.264, clip=0, loss_scale=64, train_wall=61, gb_free=17.1, wall=19614
2023-07-10 20:53:01 | INFO | train_inner | epoch 016:   1000 / 1474 loss=1.081, trans_loss=5.388, nll_loss=2.697, w2v_ctc_loss=0.355, task_loss=3.164, contrastive_loss=0.22, total=4103.45, n_correct=2598.45, ppl=6.48, accuracy=63.324, wps=6755.2, ups=1.65, wpb=4103.4, bsz=149, num_updates=23100, lr=9.30484e-05, gnorm=0.266, clip=0, loss_scale=64, train_wall=60, gb_free=15.1, wall=19675
2023-07-10 20:54:02 | INFO | train_inner | epoch 016:   1100 / 1474 loss=1.084, trans_loss=5.397, nll_loss=2.71, w2v_ctc_loss=0.358, task_loss=3.361, contrastive_loss=0.184, total=4119.27, n_correct=2604.07, ppl=6.54, accuracy=63.217, wps=6706.4, ups=1.63, wpb=4119.3, bsz=147.7, num_updates=23200, lr=9.28477e-05, gnorm=0.269, clip=0, loss_scale=128, train_wall=61, gb_free=17.9, wall=19736
2023-07-10 20:54:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-10 20:55:04 | INFO | train_inner | epoch 016:   1201 / 1474 loss=1.077, trans_loss=5.386, nll_loss=2.696, w2v_ctc_loss=0.35, task_loss=3.221, contrastive_loss=0.149, total=4132.57, n_correct=2614.09, ppl=6.48, accuracy=63.256, wps=6671.9, ups=1.61, wpb=4132.6, bsz=149.4, num_updates=23300, lr=9.26482e-05, gnorm=0.267, clip=0, loss_scale=64, train_wall=61, gb_free=15.1, wall=19798
2023-07-10 20:56:05 | INFO | train_inner | epoch 016:   1301 / 1474 loss=1.082, trans_loss=5.386, nll_loss=2.697, w2v_ctc_loss=0.353, task_loss=2.863, contrastive_loss=0.333, total=4151.03, n_correct=2631.99, ppl=6.48, accuracy=63.406, wps=6799.1, ups=1.64, wpb=4151, bsz=157.2, num_updates=23400, lr=9.245e-05, gnorm=0.262, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=19859
2023-07-10 20:57:07 | INFO | train_inner | epoch 016:   1401 / 1474 loss=1.079, trans_loss=5.384, nll_loss=2.694, w2v_ctc_loss=0.353, task_loss=2.797, contrastive_loss=0.188, total=4201.47, n_correct=2663.86, ppl=6.47, accuracy=63.403, wps=6829.2, ups=1.63, wpb=4201.5, bsz=160.4, num_updates=23500, lr=9.22531e-05, gnorm=0.265, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=19920
2023-07-10 20:57:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 20:58:19 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 1.738 | trans_loss 5.588 | nll_loss 2.868 | w2v_ctc_loss 0.542 | task_loss 4.216 | contrastive_loss 0.262 | total 4003.4 | n_correct 2462.4 | ppl 7.3 | accuracy 61.508 | uer 17.288 | wer 19.067 | raw_wer 19.067 | bleu 19.98 | wps 1886.4 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 19.98
2023-07-10 20:58:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-07-10 20:58:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 20:58:23 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 20:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 16 @ 23573 updates, score 19.98) (writing took 8.239788303966634 seconds)
2023-07-10 20:58:27 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-10 20:58:27 | INFO | train | epoch 016 | loss 1.076 | trans_loss 5.375 | nll_loss 2.68 | w2v_ctc_loss 0.349 | task_loss 3.006 | contrastive_loss 0.223 | total 4137.02 | n_correct 2630.22 | ppl 6.41 | accuracy 63.578 | wps 6479.9 | ups 1.57 | wpb 4137 | bsz 152.5 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.265 | clip 0 | loss_scale 64 | train_wall 890 | gb_free 15.6 | wall 20001
2023-07-10 20:58:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 20:58:28 | INFO | fairseq.trainer | begin training epoch 17
2023-07-10 20:58:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 20:58:52 | INFO | train_inner | epoch 017:     27 / 1474 loss=1.079, trans_loss=5.363, nll_loss=2.665, w2v_ctc_loss=0.345, task_loss=3.192, contrastive_loss=0.466, total=4145.04, n_correct=2644.37, ppl=6.34, accuracy=63.796, wps=3947, ups=0.95, wpb=4145, bsz=151.2, num_updates=23600, lr=9.20575e-05, gnorm=0.265, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=20026
2023-07-10 20:59:53 | INFO | train_inner | epoch 017:    127 / 1474 loss=1.072, trans_loss=5.341, nll_loss=2.635, w2v_ctc_loss=0.35, task_loss=3.294, contrastive_loss=0.134, total=4117.27, n_correct=2639.28, ppl=6.21, accuracy=64.103, wps=6793.1, ups=1.65, wpb=4117.3, bsz=148.1, num_updates=23700, lr=9.1863e-05, gnorm=0.264, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=20086
2023-07-10 21:00:53 | INFO | train_inner | epoch 017:    227 / 1474 loss=1.074, trans_loss=5.343, nll_loss=2.64, w2v_ctc_loss=0.342, task_loss=2.833, contrastive_loss=0.471, total=4159.6, n_correct=2663.06, ppl=6.23, accuracy=64.022, wps=6858, ups=1.65, wpb=4159.6, bsz=158.8, num_updates=23800, lr=9.16698e-05, gnorm=0.264, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=20147
2023-07-10 21:01:53 | INFO | train_inner | epoch 017:    327 / 1474 loss=1.074, trans_loss=5.342, nll_loss=2.638, w2v_ctc_loss=0.343, task_loss=2.96, contrastive_loss=0.474, total=4156.91, n_correct=2661.36, ppl=6.22, accuracy=64.023, wps=6917.9, ups=1.66, wpb=4156.9, bsz=152.9, num_updates=23900, lr=9.14779e-05, gnorm=0.262, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=20207
2023-07-10 21:02:54 | INFO | train_inner | epoch 017:    427 / 1474 loss=1.067, trans_loss=5.342, nll_loss=2.638, w2v_ctc_loss=0.345, task_loss=2.953, contrastive_loss=0.135, total=4146.43, n_correct=2660.25, ppl=6.23, accuracy=64.158, wps=6810.7, ups=1.64, wpb=4146.4, bsz=154, num_updates=24000, lr=9.12871e-05, gnorm=0.265, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=20268
2023-07-10 21:02:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 21:03:22 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 1.736 | trans_loss 5.588 | nll_loss 2.861 | w2v_ctc_loss 0.55 | task_loss 4.378 | contrastive_loss 0.26 | total 4003.4 | n_correct 2466.4 | ppl 7.26 | accuracy 61.608 | uer 17.108 | wer 18.952 | raw_wer 18.952 | bleu 20.13 | wps 1869.2 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.13
2023-07-10 21:03:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-10 21:03:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_17_24000.pt
2023-07-10 21:03:24 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_17_24000.pt
2023-07-10 21:03:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 20.13) (writing took 9.30140645604115 seconds)
2023-07-10 21:04:34 | INFO | train_inner | epoch 017:    527 / 1474 loss=1.077, trans_loss=5.354, nll_loss=2.654, w2v_ctc_loss=0.352, task_loss=3.336, contrastive_loss=0.235, total=4182.1, n_correct=2669.43, ppl=6.29, accuracy=63.83, wps=4209.2, ups=1.01, wpb=4182.1, bsz=153.9, num_updates=24100, lr=9.10975e-05, gnorm=0.266, clip=0, loss_scale=64, train_wall=62, gb_free=17, wall=20367
2023-07-10 21:05:35 | INFO | train_inner | epoch 017:    627 / 1474 loss=1.068, trans_loss=5.348, nll_loss=2.647, w2v_ctc_loss=0.344, task_loss=3.237, contrastive_loss=0.128, total=4167.27, n_correct=2666.52, ppl=6.26, accuracy=63.987, wps=6821, ups=1.64, wpb=4167.3, bsz=151.1, num_updates=24200, lr=9.09091e-05, gnorm=0.261, clip=0, loss_scale=64, train_wall=61, gb_free=11.3, wall=20428
2023-07-10 21:06:36 | INFO | train_inner | epoch 017:    727 / 1474 loss=1.076, trans_loss=5.362, nll_loss=2.664, w2v_ctc_loss=0.352, task_loss=3.134, contrastive_loss=0.224, total=4166.12, n_correct=2658.34, ppl=6.34, accuracy=63.809, wps=6841.4, ups=1.64, wpb=4166.1, bsz=154.1, num_updates=24300, lr=9.07218e-05, gnorm=0.265, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=20489
2023-07-10 21:07:36 | INFO | train_inner | epoch 017:    827 / 1474 loss=1.076, trans_loss=5.357, nll_loss=2.658, w2v_ctc_loss=0.351, task_loss=3.197, contrastive_loss=0.151, total=4091.64, n_correct=2611.83, ppl=6.31, accuracy=63.833, wps=6822.9, ups=1.67, wpb=4091.6, bsz=147.7, num_updates=24400, lr=9.05357e-05, gnorm=0.265, clip=0, loss_scale=64, train_wall=59, gb_free=17.4, wall=20549
2023-07-10 21:08:35 | INFO | train_inner | epoch 017:    927 / 1474 loss=1.07, trans_loss=5.349, nll_loss=2.649, w2v_ctc_loss=0.343, task_loss=3.141, contrastive_loss=0.147, total=4106.83, n_correct=2625.33, ppl=6.27, accuracy=63.926, wps=6889.7, ups=1.68, wpb=4106.8, bsz=152.3, num_updates=24500, lr=9.03508e-05, gnorm=0.266, clip=0, loss_scale=64, train_wall=59, gb_free=16, wall=20609
2023-07-10 21:09:35 | INFO | train_inner | epoch 017:   1027 / 1474 loss=1.07, trans_loss=5.349, nll_loss=2.649, w2v_ctc_loss=0.346, task_loss=2.992, contrastive_loss=0.155, total=4115.49, n_correct=2634.12, ppl=6.27, accuracy=64.005, wps=6863.4, ups=1.67, wpb=4115.5, bsz=152.9, num_updates=24600, lr=9.0167e-05, gnorm=0.264, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=20669
2023-07-10 21:10:35 | INFO | train_inner | epoch 017:   1127 / 1474 loss=1.067, trans_loss=5.351, nll_loss=2.651, w2v_ctc_loss=0.341, task_loss=3.109, contrastive_loss=0.128, total=4078.39, n_correct=2607.75, ppl=6.28, accuracy=63.941, wps=6767.7, ups=1.66, wpb=4078.4, bsz=146.9, num_updates=24700, lr=8.99843e-05, gnorm=0.265, clip=0, loss_scale=64, train_wall=60, gb_free=15.8, wall=20729
2023-07-10 21:11:37 | INFO | train_inner | epoch 017:   1227 / 1474 loss=1.083, trans_loss=5.369, nll_loss=2.676, w2v_ctc_loss=0.345, task_loss=2.885, contrastive_loss=0.622, total=4173.49, n_correct=2656.93, ppl=6.39, accuracy=63.662, wps=6806.4, ups=1.63, wpb=4173.5, bsz=161.9, num_updates=24800, lr=8.98027e-05, gnorm=0.263, clip=0, loss_scale=64, train_wall=61, gb_free=16.3, wall=20790
2023-07-10 21:12:37 | INFO | train_inner | epoch 017:   1327 / 1474 loss=1.071, trans_loss=5.359, nll_loss=2.662, w2v_ctc_loss=0.341, task_loss=2.909, contrastive_loss=0.296, total=4156.28, n_correct=2650.57, ppl=6.33, accuracy=63.773, wps=6838.6, ups=1.65, wpb=4156.3, bsz=154, num_updates=24900, lr=8.96221e-05, gnorm=0.262, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=20851
2023-07-10 21:13:38 | INFO | train_inner | epoch 017:   1427 / 1474 loss=1.06, trans_loss=5.353, nll_loss=2.654, w2v_ctc_loss=0.341, task_loss=3.084, contrastive_loss=0.145, total=4112.95, n_correct=2625.12, ppl=6.29, accuracy=63.826, wps=6759.6, ups=1.64, wpb=4112.9, bsz=151.6, num_updates=25000, lr=8.94427e-05, gnorm=0.26, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=20912
tensor(0.0287, device='cuda:0')
tensor(0.0016, device='cuda:0')
2023-07-10 21:14:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0287, device='cuda:7')
tensor(0.0016, device='cuda:7')
tensor(0.0287, device='cuda:5')
tensor(0.0016, device='cuda:5')
tensor(0.0287, device='cuda:2')
tensor(0.0016, device='cuda:2')
tensor(0.0287, device='cuda:6')
tensor(0.0016, device='cuda:6')
tensor(0.0287, device='cuda:3')
tensor(0.0016, device='cuda:3')
tensor(0.0287, device='cuda:4')
tensor(0.0016, device='cuda:4')
tensor(0.0287, device='cuda:1')
tensor(0.0016, device='cuda:1')
2023-07-10 21:14:35 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 1.733 | trans_loss 5.577 | nll_loss 2.855 | w2v_ctc_loss 0.541 | task_loss 4.345 | contrastive_loss 0.276 | total 4003.4 | n_correct 2471.4 | ppl 7.24 | accuracy 61.733 | uer 17.049 | wer 18.773 | raw_wer 18.773 | bleu 19.74 | wps 1936.6 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 20.13
2023-07-10 21:14:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-07-10 21:14:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.7401.pt
2023-07-10 21:14:37 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.7401.pt
2023-07-10 21:14:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.7401.pt (epoch 17 @ 25047 updates, score 19.74) (writing took 5.546457711956464 seconds)
2023-07-10 21:14:41 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-10 21:14:41 | INFO | train | epoch 017 | loss 1.072 | trans_loss 5.351 | nll_loss 2.651 | w2v_ctc_loss 0.345 | task_loss 3.083 | contrastive_loss 0.245 | total 4138.65 | n_correct 2645.84 | ppl 6.28 | accuracy 63.93 | wps 6266.1 | ups 1.51 | wpb 4138.6 | bsz 152.8 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.264 | clip 0 | loss_scale 64 | train_wall 888 | gb_free 16.6 | wall 20974
2023-07-10 21:14:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 21:14:41 | INFO | fairseq.trainer | begin training epoch 18
2023-07-10 21:14:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 21:15:22 | INFO | train_inner | epoch 018:     53 / 1474 loss=1.072, trans_loss=5.348, nll_loss=2.648, w2v_ctc_loss=0.349, task_loss=3.285, contrastive_loss=0.178, total=4139.04, n_correct=2649.69, ppl=6.27, accuracy=64.017, wps=3995.5, ups=0.97, wpb=4139, bsz=151.7, num_updates=25100, lr=8.92644e-05, gnorm=0.265, clip=0, loss_scale=64, train_wall=61, gb_free=17.2, wall=21015
2023-07-10 21:16:22 | INFO | train_inner | epoch 018:    153 / 1474 loss=1.067, trans_loss=5.311, nll_loss=2.598, w2v_ctc_loss=0.334, task_loss=3.059, contrastive_loss=0.42, total=4154.85, n_correct=2683.61, ppl=6.05, accuracy=64.59, wps=6901.2, ups=1.66, wpb=4154.9, bsz=156.4, num_updates=25200, lr=8.90871e-05, gnorm=0.259, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=21076
2023-07-10 21:17:24 | INFO | train_inner | epoch 018:    253 / 1474 loss=1.061, trans_loss=5.309, nll_loss=2.596, w2v_ctc_loss=0.338, task_loss=2.961, contrastive_loss=0.156, total=4162.72, n_correct=2692.45, ppl=6.05, accuracy=64.68, wps=6782.7, ups=1.63, wpb=4162.7, bsz=156.5, num_updates=25300, lr=8.89108e-05, gnorm=0.259, clip=0, loss_scale=128, train_wall=61, gb_free=16.4, wall=21137
2023-07-10 21:18:24 | INFO | train_inner | epoch 018:    353 / 1474 loss=1.063, trans_loss=5.322, nll_loss=2.612, w2v_ctc_loss=0.34, task_loss=3.023, contrastive_loss=0.181, total=4161.22, n_correct=2680.3, ppl=6.11, accuracy=64.411, wps=6824.7, ups=1.64, wpb=4161.2, bsz=150.7, num_updates=25400, lr=8.87357e-05, gnorm=0.262, clip=0, loss_scale=128, train_wall=61, gb_free=14.7, wall=21198
2023-07-10 21:19:26 | INFO | train_inner | epoch 018:    453 / 1474 loss=1.072, trans_loss=5.338, nll_loss=2.634, w2v_ctc_loss=0.343, task_loss=3.119, contrastive_loss=0.353, total=4092.36, n_correct=2624.55, ppl=6.21, accuracy=64.133, wps=6698.2, ups=1.64, wpb=4092.4, bsz=147.7, num_updates=25500, lr=8.85615e-05, gnorm=0.267, clip=0, loss_scale=128, train_wall=61, gb_free=16.9, wall=21259
2023-07-10 21:20:26 | INFO | train_inner | epoch 018:    553 / 1474 loss=1.055, trans_loss=5.311, nll_loss=2.601, w2v_ctc_loss=0.336, task_loss=2.638, contrastive_loss=0.155, total=4206.45, n_correct=2719.42, ppl=6.07, accuracy=64.649, wps=6945.8, ups=1.65, wpb=4206.4, bsz=164.5, num_updates=25600, lr=8.83883e-05, gnorm=0.257, clip=0, loss_scale=128, train_wall=60, gb_free=17.9, wall=21320
2023-07-10 21:21:27 | INFO | train_inner | epoch 018:    653 / 1474 loss=1.072, trans_loss=5.345, nll_loss=2.643, w2v_ctc_loss=0.345, task_loss=3.021, contrastive_loss=0.289, total=4097.96, n_correct=2625.21, ppl=6.25, accuracy=64.061, wps=6784.6, ups=1.66, wpb=4098, bsz=149.3, num_updates=25700, lr=8.82162e-05, gnorm=0.266, clip=0, loss_scale=128, train_wall=60, gb_free=12.7, wall=21380
2023-07-10 21:22:27 | INFO | train_inner | epoch 018:    753 / 1474 loss=1.072, trans_loss=5.342, nll_loss=2.64, w2v_ctc_loss=0.346, task_loss=2.937, contrastive_loss=0.472, total=4208.5, n_correct=2697.68, ppl=6.23, accuracy=64.101, wps=6931.7, ups=1.65, wpb=4208.5, bsz=161.3, num_updates=25800, lr=8.80451e-05, gnorm=0.262, clip=0, loss_scale=128, train_wall=60, gb_free=16.4, wall=21441
2023-07-10 21:23:28 | INFO | train_inner | epoch 018:    853 / 1474 loss=1.063, trans_loss=5.333, nll_loss=2.627, w2v_ctc_loss=0.342, task_loss=3.2, contrastive_loss=0.116, total=4166.07, n_correct=2676.72, ppl=6.18, accuracy=64.25, wps=6871.9, ups=1.65, wpb=4166.1, bsz=151.2, num_updates=25900, lr=8.7875e-05, gnorm=0.262, clip=0, loss_scale=128, train_wall=60, gb_free=16.5, wall=21501
2023-07-10 21:24:28 | INFO | train_inner | epoch 018:    953 / 1474 loss=1.06, trans_loss=5.318, nll_loss=2.609, w2v_ctc_loss=0.335, task_loss=3, contrastive_loss=0.161, total=4141.27, n_correct=2670.37, ppl=6.1, accuracy=64.482, wps=6889, ups=1.66, wpb=4141.3, bsz=158, num_updates=26000, lr=8.77058e-05, gnorm=0.261, clip=0, loss_scale=128, train_wall=60, gb_free=16.2, wall=21562
2023-07-10 21:24:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 21:24:53 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 1.736 | trans_loss 5.579 | nll_loss 2.855 | w2v_ctc_loss 0.553 | task_loss 4.275 | contrastive_loss 0.258 | total 4003.4 | n_correct 2475.4 | ppl 7.24 | accuracy 61.832 | uer 17.328 | wer 19.246 | raw_wer 19.246 | bleu 20.01 | wps 2102.2 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.13
2023-07-10 21:24:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-10 21:24:53 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_18_26000.pt
2023-07-10 21:24:55 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_18_26000.pt
2023-07-10 21:24:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 20.01) (writing took 6.117380790994503 seconds)
2023-07-10 21:26:01 | INFO | train_inner | epoch 018:   1053 / 1474 loss=1.061, trans_loss=5.333, nll_loss=2.629, w2v_ctc_loss=0.338, task_loss=3.148, contrastive_loss=0.14, total=4134.55, n_correct=2655.38, ppl=6.18, accuracy=64.224, wps=4447.7, ups=1.08, wpb=4134.6, bsz=150.4, num_updates=26100, lr=8.75376e-05, gnorm=0.264, clip=0, loss_scale=128, train_wall=61, gb_free=16.6, wall=21655
2023-07-10 21:27:02 | INFO | train_inner | epoch 018:   1153 / 1474 loss=1.068, trans_loss=5.322, nll_loss=2.614, w2v_ctc_loss=0.341, task_loss=2.844, contrastive_loss=0.349, total=4157.63, n_correct=2677.31, ppl=6.12, accuracy=64.395, wps=6865, ups=1.65, wpb=4157.6, bsz=157, num_updates=26200, lr=8.73704e-05, gnorm=0.264, clip=0, loss_scale=128, train_wall=60, gb_free=17.2, wall=21715
2023-07-10 21:28:02 | INFO | train_inner | epoch 018:   1253 / 1474 loss=1.067, trans_loss=5.345, nll_loss=2.643, w2v_ctc_loss=0.343, task_loss=3.211, contrastive_loss=0.127, total=4085.66, n_correct=2611.57, ppl=6.25, accuracy=63.92, wps=6769.5, ups=1.66, wpb=4085.7, bsz=143.3, num_updates=26300, lr=8.72041e-05, gnorm=0.262, clip=0, loss_scale=128, train_wall=60, gb_free=17.6, wall=21775
2023-07-10 21:29:02 | INFO | train_inner | epoch 018:   1353 / 1474 loss=1.071, trans_loss=5.352, nll_loss=2.654, w2v_ctc_loss=0.35, task_loss=3.147, contrastive_loss=0.172, total=4065.6, n_correct=2601.61, ppl=6.3, accuracy=63.991, wps=6815.1, ups=1.68, wpb=4065.6, bsz=145.6, num_updates=26400, lr=8.70388e-05, gnorm=0.264, clip=0, loss_scale=128, train_wall=59, gb_free=13.5, wall=21835
2023-07-10 21:30:02 | INFO | train_inner | epoch 018:   1453 / 1474 loss=1.068, trans_loss=5.346, nll_loss=2.646, w2v_ctc_loss=0.346, task_loss=3.046, contrastive_loss=0.138, total=4122.48, n_correct=2637.73, ppl=6.26, accuracy=63.984, wps=6766.7, ups=1.64, wpb=4122.5, bsz=149.7, num_updates=26500, lr=8.68744e-05, gnorm=0.265, clip=0, loss_scale=128, train_wall=61, gb_free=17.3, wall=21896
2023-07-10 21:30:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-10 21:30:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 21:30:44 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 1.731 | trans_loss 5.573 | nll_loss 2.851 | w2v_ctc_loss 0.541 | task_loss 3.766 | contrastive_loss 0.244 | total 4003.4 | n_correct 2472.4 | ppl 7.22 | accuracy 61.758 | uer 17.094 | wer 19.007 | raw_wer 19.007 | bleu 19.61 | wps 1899.5 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 20.13
2023-07-10 21:30:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-07-10 21:30:44 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6106.pt
2023-07-10 21:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6106.pt
2023-07-10 21:30:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.6106.pt (epoch 18 @ 26520 updates, score 19.61) (writing took 5.053227062977385 seconds)
2023-07-10 21:30:49 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-10 21:30:49 | INFO | train | epoch 018 | loss 1.066 | trans_loss 5.331 | nll_loss 2.625 | w2v_ctc_loss 0.342 | task_loss 3.033 | contrastive_loss 0.229 | total 4137.62 | n_correct 2659.36 | ppl 6.17 | accuracy 64.273 | wps 6294.7 | ups 1.52 | wpb 4137.6 | bsz 152.6 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.263 | clip 0 | loss_scale 64 | train_wall 888 | gb_free 16.1 | wall 21943
2023-07-10 21:30:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 21:30:49 | INFO | fairseq.trainer | begin training epoch 19
2023-07-10 21:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 21:31:46 | INFO | train_inner | epoch 019:     80 / 1474 loss=1.06, trans_loss=5.299, nll_loss=2.583, w2v_ctc_loss=0.338, task_loss=2.996, contrastive_loss=0.101, total=4081.68, n_correct=2641.59, ppl=5.99, accuracy=64.718, wps=3959.5, ups=0.97, wpb=4081.7, bsz=145.1, num_updates=26600, lr=8.6711e-05, gnorm=0.266, clip=0, loss_scale=64, train_wall=61, gb_free=17.6, wall=21999
2023-07-10 21:32:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-10 21:32:48 | INFO | train_inner | epoch 019:    181 / 1474 loss=1.056, trans_loss=5.292, nll_loss=2.575, w2v_ctc_loss=0.34, task_loss=2.806, contrastive_loss=0.193, total=4210.09, n_correct=2733.5, ppl=5.96, accuracy=64.927, wps=6785.5, ups=1.61, wpb=4210.1, bsz=159.6, num_updates=26700, lr=8.65485e-05, gnorm=0.259, clip=0, loss_scale=32, train_wall=62, gb_free=12.1, wall=22061
2023-07-10 21:33:48 | INFO | train_inner | epoch 019:    281 / 1474 loss=1.057, trans_loss=5.296, nll_loss=2.579, w2v_ctc_loss=0.337, task_loss=3.126, contrastive_loss=0.118, total=4187.37, n_correct=2713.75, ppl=5.97, accuracy=64.808, wps=6908.9, ups=1.65, wpb=4187.4, bsz=153.5, num_updates=26800, lr=8.63868e-05, gnorm=0.26, clip=0, loss_scale=32, train_wall=60, gb_free=17.6, wall=22122
2023-07-10 21:34:49 | INFO | train_inner | epoch 019:    381 / 1474 loss=1.063, trans_loss=5.302, nll_loss=2.589, w2v_ctc_loss=0.335, task_loss=3.16, contrastive_loss=0.34, total=4170.67, n_correct=2698.06, ppl=6.02, accuracy=64.691, wps=6853.6, ups=1.64, wpb=4170.7, bsz=155.3, num_updates=26900, lr=8.62261e-05, gnorm=0.267, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=22183
2023-07-10 21:35:49 | INFO | train_inner | epoch 019:    481 / 1474 loss=1.06, trans_loss=5.31, nll_loss=2.598, w2v_ctc_loss=0.34, task_loss=3.288, contrastive_loss=0.154, total=4115.22, n_correct=2659.7, ppl=6.05, accuracy=64.631, wps=6843, ups=1.66, wpb=4115.2, bsz=150.9, num_updates=27000, lr=8.60663e-05, gnorm=0.267, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=22243
2023-07-10 21:36:50 | INFO | train_inner | epoch 019:    581 / 1474 loss=1.058, trans_loss=5.305, nll_loss=2.593, w2v_ctc_loss=0.335, task_loss=3.138, contrastive_loss=0.282, total=4129.22, n_correct=2672.15, ppl=6.03, accuracy=64.713, wps=6829.9, ups=1.65, wpb=4129.2, bsz=153, num_updates=27100, lr=8.59074e-05, gnorm=0.262, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=22303
2023-07-10 21:37:51 | INFO | train_inner | epoch 019:    681 / 1474 loss=1.053, trans_loss=5.302, nll_loss=2.589, w2v_ctc_loss=0.33, task_loss=2.815, contrastive_loss=0.137, total=4197.2, n_correct=2717.71, ppl=6.02, accuracy=64.751, wps=6901.5, ups=1.64, wpb=4197.2, bsz=160.4, num_updates=27200, lr=8.57493e-05, gnorm=0.26, clip=0, loss_scale=32, train_wall=60, gb_free=14.9, wall=22364
2023-07-10 21:38:51 | INFO | train_inner | epoch 019:    781 / 1474 loss=1.06, trans_loss=5.31, nll_loss=2.598, w2v_ctc_loss=0.341, task_loss=3.022, contrastive_loss=0.155, total=4142.6, n_correct=2674.93, ppl=6.06, accuracy=64.571, wps=6816, ups=1.65, wpb=4142.6, bsz=152.5, num_updates=27300, lr=8.55921e-05, gnorm=0.262, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=22425
2023-07-10 21:39:52 | INFO | train_inner | epoch 019:    881 / 1474 loss=1.061, trans_loss=5.318, nll_loss=2.61, w2v_ctc_loss=0.34, task_loss=3.066, contrastive_loss=0.124, total=4153.47, n_correct=2676.64, ppl=6.1, accuracy=64.443, wps=6868.8, ups=1.65, wpb=4153.5, bsz=151.5, num_updates=27400, lr=8.54358e-05, gnorm=0.261, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=22485
2023-07-10 21:40:53 | INFO | train_inner | epoch 019:    981 / 1474 loss=1.071, trans_loss=5.332, nll_loss=2.629, w2v_ctc_loss=0.339, task_loss=2.985, contrastive_loss=0.592, total=4101.29, n_correct=2635.53, ppl=6.18, accuracy=64.261, wps=6718.6, ups=1.64, wpb=4101.3, bsz=155, num_updates=27500, lr=8.52803e-05, gnorm=0.267, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=22546
2023-07-10 21:41:54 | INFO | train_inner | epoch 019:   1081 / 1474 loss=1.065, trans_loss=5.336, nll_loss=2.633, w2v_ctc_loss=0.34, task_loss=3.196, contrastive_loss=0.212, total=4036.97, n_correct=2591.53, ppl=6.2, accuracy=64.195, wps=6652.3, ups=1.65, wpb=4037, bsz=145.5, num_updates=27600, lr=8.51257e-05, gnorm=0.269, clip=0, loss_scale=32, train_wall=60, gb_free=14.9, wall=22607
2023-07-10 21:42:56 | INFO | train_inner | epoch 019:   1181 / 1474 loss=1.074, trans_loss=5.331, nll_loss=2.627, w2v_ctc_loss=0.343, task_loss=2.99, contrastive_loss=0.376, total=4137.49, n_correct=2659.57, ppl=6.18, accuracy=64.28, wps=6668.2, ups=1.61, wpb=4137.5, bsz=153.8, num_updates=27700, lr=8.49719e-05, gnorm=0.274, clip=0, loss_scale=32, train_wall=62, gb_free=15.1, wall=22669
2023-07-10 21:43:56 | INFO | train_inner | epoch 019:   1281 / 1474 loss=1.069, trans_loss=5.334, nll_loss=2.631, w2v_ctc_loss=0.34, task_loss=2.976, contrastive_loss=0.174, total=4141.89, n_correct=2657.35, ppl=6.2, accuracy=64.158, wps=6828.6, ups=1.65, wpb=4141.9, bsz=150.1, num_updates=27800, lr=8.48189e-05, gnorm=0.265, clip=0, loss_scale=32, train_wall=60, gb_free=15.9, wall=22730
2023-07-10 21:44:57 | INFO | train_inner | epoch 019:   1381 / 1474 loss=1.063, trans_loss=5.318, nll_loss=2.61, w2v_ctc_loss=0.342, task_loss=2.986, contrastive_loss=0.147, total=4133.26, n_correct=2663.89, ppl=6.11, accuracy=64.45, wps=6810, ups=1.65, wpb=4133.3, bsz=150.5, num_updates=27900, lr=8.46668e-05, gnorm=0.262, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=22790
2023-07-10 21:45:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 21:46:21 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 1.732 | trans_loss 5.57 | nll_loss 2.852 | w2v_ctc_loss 0.555 | task_loss 4.29 | contrastive_loss 0.264 | total 4003.4 | n_correct 2470.9 | ppl 7.22 | accuracy 61.72 | uer 17.126 | wer 19.004 | raw_wer 19.004 | bleu 20.13 | wps 1966.1 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.13
2023-07-10 21:46:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-07-10 21:46:21 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 21:46:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 21:46:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 19 @ 27993 updates, score 20.13) (writing took 8.397147028008476 seconds)
2023-07-10 21:46:30 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-10 21:46:30 | INFO | train | epoch 019 | loss 1.062 | trans_loss 5.313 | nll_loss 2.603 | w2v_ctc_loss 0.339 | task_loss 3.052 | contrastive_loss 0.232 | total 4137.6 | n_correct 2670.47 | ppl 6.08 | accuracy 64.541 | wps 6477 | ups 1.57 | wpb 4137.6 | bsz 152.7 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.265 | clip 0 | loss_scale 32 | train_wall 890 | gb_free 17.5 | wall 22884
2023-07-10 21:46:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 21:46:30 | INFO | fairseq.trainer | begin training epoch 20
2023-07-10 21:46:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 21:46:43 | INFO | train_inner | epoch 020:      7 / 1474 loss=1.067, trans_loss=5.319, nll_loss=2.612, w2v_ctc_loss=0.34, task_loss=3.22, contrastive_loss=0.319, total=4119.08, n_correct=2654.47, ppl=6.11, accuracy=64.443, wps=3885.5, ups=0.94, wpb=4119.1, bsz=152.1, num_updates=28000, lr=8.45154e-05, gnorm=0.267, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=22897
2023-07-10 21:46:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 21:47:12 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 1.728 | trans_loss 5.574 | nll_loss 2.853 | w2v_ctc_loss 0.54 | task_loss 4.303 | contrastive_loss 0.261 | total 4003.4 | n_correct 2470.2 | ppl 7.23 | accuracy 61.703 | uer 16.858 | wer 18.799 | raw_wer 18.799 | bleu 19.96 | wps 1866.9 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.13
2023-07-10 21:47:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-10 21:47:12 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_20_28000.pt
2023-07-10 21:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_20_28000.pt
2023-07-10 21:47:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 19.96) (writing took 6.082386591995601 seconds)
2023-07-10 21:48:19 | INFO | train_inner | epoch 020:    107 / 1474 loss=1.051, trans_loss=5.274, nll_loss=2.552, w2v_ctc_loss=0.33, task_loss=3.113, contrastive_loss=0.171, total=4195.03, n_correct=2735.59, ppl=5.87, accuracy=65.21, wps=4364.9, ups=1.04, wpb=4195, bsz=156.8, num_updates=28100, lr=8.43649e-05, gnorm=0.262, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=22993
2023-07-10 21:49:21 | INFO | train_inner | epoch 020:    207 / 1474 loss=1.059, trans_loss=5.285, nll_loss=2.566, w2v_ctc_loss=0.333, task_loss=3.308, contrastive_loss=0.275, total=4154.14, n_correct=2700.88, ppl=5.92, accuracy=65.017, wps=6760, ups=1.63, wpb=4154.1, bsz=150.5, num_updates=28200, lr=8.42152e-05, gnorm=0.262, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=23054
2023-07-10 21:50:21 | INFO | train_inner | epoch 020:    307 / 1474 loss=1.049, trans_loss=5.272, nll_loss=2.551, w2v_ctc_loss=0.329, task_loss=2.712, contrastive_loss=0.155, total=4188.05, n_correct=2730.88, ppl=5.86, accuracy=65.206, wps=6933.1, ups=1.66, wpb=4188.1, bsz=163.1, num_updates=28300, lr=8.40663e-05, gnorm=0.26, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=23114
2023-07-10 21:51:21 | INFO | train_inner | epoch 020:    407 / 1474 loss=1.049, trans_loss=5.279, nll_loss=2.558, w2v_ctc_loss=0.328, task_loss=3.04, contrastive_loss=0.15, total=4115.16, n_correct=2678.1, ppl=5.89, accuracy=65.079, wps=6827.4, ups=1.66, wpb=4115.2, bsz=148.5, num_updates=28400, lr=8.39181e-05, gnorm=0.264, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=23175
2023-07-10 21:52:22 | INFO | train_inner | epoch 020:    507 / 1474 loss=1.064, trans_loss=5.301, nll_loss=2.587, w2v_ctc_loss=0.335, task_loss=3.051, contrastive_loss=0.322, total=4108.46, n_correct=2660.45, ppl=6.01, accuracy=64.755, wps=6755.5, ups=1.64, wpb=4108.5, bsz=150.2, num_updates=28500, lr=8.37708e-05, gnorm=0.267, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=23236
2023-07-10 21:53:23 | INFO | train_inner | epoch 020:    607 / 1474 loss=1.063, trans_loss=5.302, nll_loss=2.589, w2v_ctc_loss=0.337, task_loss=3.084, contrastive_loss=0.311, total=4094.9, n_correct=2648.14, ppl=6.02, accuracy=64.669, wps=6759.2, ups=1.65, wpb=4094.9, bsz=148, num_updates=28600, lr=8.36242e-05, gnorm=0.265, clip=0, loss_scale=32, train_wall=60, gb_free=12.4, wall=23296
2023-07-10 21:54:23 | INFO | train_inner | epoch 020:    707 / 1474 loss=1.061, trans_loss=5.303, nll_loss=2.59, w2v_ctc_loss=0.34, task_loss=2.936, contrastive_loss=0.118, total=4140.23, n_correct=2678.98, ppl=6.02, accuracy=64.706, wps=6884.6, ups=1.66, wpb=4140.2, bsz=150.3, num_updates=28700, lr=8.34784e-05, gnorm=0.264, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=23356
2023-07-10 21:55:23 | INFO | train_inner | epoch 020:    807 / 1474 loss=1.053, trans_loss=5.29, nll_loss=2.574, w2v_ctc_loss=0.335, task_loss=2.913, contrastive_loss=0.132, total=4140.66, n_correct=2689.71, ppl=5.96, accuracy=64.958, wps=6824.6, ups=1.65, wpb=4140.7, bsz=152.8, num_updates=28800, lr=8.33333e-05, gnorm=0.261, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=23417
2023-07-10 21:56:25 | INFO | train_inner | epoch 020:    907 / 1474 loss=1.079, trans_loss=5.314, nll_loss=2.605, w2v_ctc_loss=0.338, task_loss=2.778, contrastive_loss=0.729, total=4157.15, n_correct=2684.19, ppl=6.09, accuracy=64.568, wps=6756.5, ups=1.63, wpb=4157.1, bsz=161.3, num_updates=28900, lr=8.3189e-05, gnorm=0.268, clip=0, loss_scale=64, train_wall=61, gb_free=17.8, wall=23479
2023-07-10 21:57:26 | INFO | train_inner | epoch 020:   1007 / 1474 loss=1.058, trans_loss=5.299, nll_loss=2.585, w2v_ctc_loss=0.332, task_loss=2.914, contrastive_loss=0.139, total=4171.86, n_correct=2702.93, ppl=6, accuracy=64.79, wps=6803.4, ups=1.63, wpb=4171.9, bsz=154.3, num_updates=29000, lr=8.30455e-05, gnorm=0.264, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=23540
2023-07-10 21:58:27 | INFO | train_inner | epoch 020:   1107 / 1474 loss=1.066, trans_loss=5.307, nll_loss=2.598, w2v_ctc_loss=0.335, task_loss=2.774, contrastive_loss=0.415, total=4162.96, n_correct=2692.19, ppl=6.05, accuracy=64.67, wps=6866, ups=1.65, wpb=4163, bsz=157.5, num_updates=29100, lr=8.29027e-05, gnorm=0.265, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=23600
2023-07-10 21:59:27 | INFO | train_inner | epoch 020:   1207 / 1474 loss=1.055, trans_loss=5.303, nll_loss=2.59, w2v_ctc_loss=0.339, task_loss=3.324, contrastive_loss=0.116, total=4033.74, n_correct=2607.21, ppl=6.02, accuracy=64.635, wps=6687.2, ups=1.66, wpb=4033.7, bsz=142.6, num_updates=29200, lr=8.27606e-05, gnorm=0.267, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=23661
2023-07-10 22:00:28 | INFO | train_inner | epoch 020:   1307 / 1474 loss=1.057, trans_loss=5.311, nll_loss=2.602, w2v_ctc_loss=0.337, task_loss=3.348, contrastive_loss=0.133, total=4124.42, n_correct=2663.27, ppl=6.07, accuracy=64.573, wps=6736.5, ups=1.63, wpb=4124.4, bsz=148.5, num_updates=29300, lr=8.26192e-05, gnorm=0.263, clip=0, loss_scale=64, train_wall=61, gb_free=16.2, wall=23722
2023-07-10 22:01:29 | INFO | train_inner | epoch 020:   1407 / 1474 loss=1.061, trans_loss=5.31, nll_loss=2.6, w2v_ctc_loss=0.338, task_loss=3.43, contrastive_loss=0.137, total=4114.1, n_correct=2657.15, ppl=6.06, accuracy=64.586, wps=6758.4, ups=1.64, wpb=4114.1, bsz=146.8, num_updates=29400, lr=8.24786e-05, gnorm=0.266, clip=0, loss_scale=64, train_wall=60, gb_free=14.7, wall=23783
2023-07-10 22:02:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 22:02:37 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 1.734 | trans_loss 5.569 | nll_loss 2.848 | w2v_ctc_loss 0.539 | task_loss 4.267 | contrastive_loss 0.268 | total 4003.4 | n_correct 2471.9 | ppl 7.2 | accuracy 61.745 | uer 16.959 | wer 18.743 | raw_wer 18.743 | bleu 19.72 | wps 1920.8 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.13
2023-07-10 22:02:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-07-10 22:02:37 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.7208.pt
2023-07-10 22:02:39 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.7208.pt
2023-07-10 22:02:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.7208.pt (epoch 20 @ 29467 updates, score 19.72) (writing took 5.168463927984703 seconds)
2023-07-10 22:02:42 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-10 22:02:42 | INFO | train | epoch 020 | loss 1.059 | trans_loss 5.297 | nll_loss 2.583 | w2v_ctc_loss 0.335 | task_loss 3.036 | contrastive_loss 0.238 | total 4138.65 | n_correct 2682.18 | ppl 5.99 | accuracy 64.808 | wps 6276.8 | ups 1.52 | wpb 4138.6 | bsz 152.8 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.264 | clip 0 | loss_scale 64 | train_wall 889 | gb_free 16.8 | wall 23856
2023-07-10 22:02:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 22:02:42 | INFO | fairseq.trainer | begin training epoch 21
2023-07-10 22:02:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 22:03:10 | INFO | train_inner | epoch 021:     33 / 1474 loss=1.061, trans_loss=5.303, nll_loss=2.593, w2v_ctc_loss=0.334, task_loss=3.049, contrastive_loss=0.386, total=4155.01, n_correct=2689.4, ppl=6.03, accuracy=64.727, wps=4109.3, ups=0.99, wpb=4155, bsz=158.8, num_updates=29500, lr=8.23387e-05, gnorm=0.267, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=23884
2023-07-10 22:03:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-10 22:04:12 | INFO | train_inner | epoch 021:    134 / 1474 loss=1.047, trans_loss=5.259, nll_loss=2.533, w2v_ctc_loss=0.33, task_loss=3.13, contrastive_loss=0.147, total=4168.09, n_correct=2726.67, ppl=5.79, accuracy=65.418, wps=6761.5, ups=1.62, wpb=4168.1, bsz=155.1, num_updates=29600, lr=8.21995e-05, gnorm=0.262, clip=0, loss_scale=32, train_wall=61, gb_free=17.2, wall=23946
2023-07-10 22:05:12 | INFO | train_inner | epoch 021:    234 / 1474 loss=1.05, trans_loss=5.264, nll_loss=2.541, w2v_ctc_loss=0.324, task_loss=2.861, contrastive_loss=0.277, total=4155.31, n_correct=2713.6, ppl=5.82, accuracy=65.304, wps=6922.1, ups=1.67, wpb=4155.3, bsz=156.3, num_updates=29700, lr=8.2061e-05, gnorm=0.263, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=24006
2023-07-10 22:06:13 | INFO | train_inner | epoch 021:    334 / 1474 loss=1.054, trans_loss=5.276, nll_loss=2.556, w2v_ctc_loss=0.334, task_loss=2.97, contrastive_loss=0.28, total=4151.51, n_correct=2701.82, ppl=5.88, accuracy=65.08, wps=6821.8, ups=1.64, wpb=4151.5, bsz=155.4, num_updates=29800, lr=8.19232e-05, gnorm=0.264, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=24067
2023-07-10 22:07:14 | INFO | train_inner | epoch 021:    434 / 1474 loss=1.052, trans_loss=5.271, nll_loss=2.549, w2v_ctc_loss=0.329, task_loss=2.901, contrastive_loss=0.129, total=4180.85, n_correct=2726.12, ppl=5.85, accuracy=65.205, wps=6902, ups=1.65, wpb=4180.9, bsz=153.4, num_updates=29900, lr=8.17861e-05, gnorm=0.264, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=24127
2023-07-10 22:08:14 | INFO | train_inner | epoch 021:    534 / 1474 loss=1.047, trans_loss=5.267, nll_loss=2.544, w2v_ctc_loss=0.332, task_loss=3.107, contrastive_loss=0.127, total=4083.98, n_correct=2666.32, ppl=5.83, accuracy=65.287, wps=6741, ups=1.65, wpb=4084, bsz=147.5, num_updates=30000, lr=8.16497e-05, gnorm=0.263, clip=0, loss_scale=32, train_wall=60, gb_free=13.4, wall=24188
2023-07-10 22:08:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 22:08:41 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 1.733 | trans_loss 5.572 | nll_loss 2.848 | w2v_ctc_loss 0.546 | task_loss 3.707 | contrastive_loss 0.259 | total 4003.4 | n_correct 2472 | ppl 7.2 | accuracy 61.748 | uer 16.986 | wer 18.795 | raw_wer 18.795 | bleu 20.01 | wps 1955.1 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.13
2023-07-10 22:08:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-10 22:08:41 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_21_30000.pt
2023-07-10 22:08:43 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_21_30000.pt
2023-07-10 22:08:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 20.01) (writing took 6.073340939008631 seconds)
tensor(0.0287, device='cuda:0')
tensor(0.0016, device='cuda:0')
2023-07-10 22:09:48 | INFO | train_inner | epoch 021:    634 / 1474 loss=1.062, trans_loss=5.278, nll_loss=2.559, w2v_ctc_loss=0.33, task_loss=2.943, contrastive_loss=0.472, total=4215.41, n_correct=2747.86, ppl=5.89, accuracy=65.186, wps=4482.3, ups=1.06, wpb=4215.4, bsz=157.7, num_updates=30100, lr=8.15139e-05, gnorm=0.263, clip=0, loss_scale=32, train_wall=60, gb_free=11.8, wall=24282
2023-07-10 22:10:49 | INFO | train_inner | epoch 021:    734 / 1474 loss=1.051, trans_loss=5.279, nll_loss=2.56, w2v_ctc_loss=0.328, task_loss=2.92, contrastive_loss=0.182, total=4152.97, n_correct=2700.56, ppl=5.9, accuracy=65.027, wps=6798.6, ups=1.64, wpb=4153, bsz=154.7, num_updates=30200, lr=8.13788e-05, gnorm=0.264, clip=0, loss_scale=32, train_wall=61, gb_free=16.5, wall=24343
2023-07-10 22:11:50 | INFO | train_inner | epoch 021:    834 / 1474 loss=1.056, trans_loss=5.293, nll_loss=2.578, w2v_ctc_loss=0.333, task_loss=3.096, contrastive_loss=0.195, total=4066.93, n_correct=2639.9, ppl=5.97, accuracy=64.911, wps=6696.3, ups=1.65, wpb=4066.9, bsz=147.2, num_updates=30300, lr=8.12444e-05, gnorm=0.27, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=24404
2023-07-10 22:12:50 | INFO | train_inner | epoch 021:    934 / 1474 loss=1.057, trans_loss=5.28, nll_loss=2.561, w2v_ctc_loss=0.333, task_loss=2.928, contrastive_loss=0.143, total=4103.34, n_correct=2666.62, ppl=5.9, accuracy=64.987, wps=6831.9, ups=1.66, wpb=4103.3, bsz=150.5, num_updates=30400, lr=8.11107e-05, gnorm=0.267, clip=0, loss_scale=32, train_wall=60, gb_free=14.3, wall=24464
2023-07-10 22:13:50 | INFO | train_inner | epoch 021:   1034 / 1474 loss=1.058, trans_loss=5.298, nll_loss=2.585, w2v_ctc_loss=0.336, task_loss=2.974, contrastive_loss=0.145, total=4099.86, n_correct=2657.37, ppl=6, accuracy=64.816, wps=6807.6, ups=1.66, wpb=4099.9, bsz=149.4, num_updates=30500, lr=8.09776e-05, gnorm=0.268, clip=0, loss_scale=32, train_wall=60, gb_free=11.8, wall=24524
2023-07-10 22:14:51 | INFO | train_inner | epoch 021:   1134 / 1474 loss=1.06, trans_loss=5.287, nll_loss=2.57, w2v_ctc_loss=0.335, task_loss=3.168, contrastive_loss=0.188, total=4120.75, n_correct=2675.47, ppl=5.94, accuracy=64.927, wps=6832.6, ups=1.66, wpb=4120.8, bsz=146.7, num_updates=30600, lr=8.08452e-05, gnorm=0.268, clip=0, loss_scale=32, train_wall=60, gb_free=16, wall=24584
2023-07-10 22:15:51 | INFO | train_inner | epoch 021:   1234 / 1474 loss=1.063, trans_loss=5.286, nll_loss=2.57, w2v_ctc_loss=0.333, task_loss=3.065, contrastive_loss=0.326, total=4154.73, n_correct=2699.77, ppl=5.94, accuracy=64.981, wps=6880.3, ups=1.66, wpb=4154.7, bsz=155.8, num_updates=30700, lr=8.07134e-05, gnorm=0.264, clip=0, loss_scale=32, train_wall=60, gb_free=13, wall=24645
2023-07-10 22:16:51 | INFO | train_inner | epoch 021:   1334 / 1474 loss=1.062, trans_loss=5.284, nll_loss=2.568, w2v_ctc_loss=0.331, task_loss=3.125, contrastive_loss=0.3, total=4147.17, n_correct=2698.53, ppl=5.93, accuracy=65.069, wps=6866, ups=1.66, wpb=4147.2, bsz=155.9, num_updates=30800, lr=8.05823e-05, gnorm=0.267, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=24705
2023-07-10 22:17:53 | INFO | train_inner | epoch 021:   1434 / 1474 loss=1.084, trans_loss=5.309, nll_loss=2.6, w2v_ctc_loss=0.344, task_loss=3.38, contrastive_loss=0.52, total=4133.93, n_correct=2670.09, ppl=6.06, accuracy=64.59, wps=6740.5, ups=1.63, wpb=4133.9, bsz=152.2, num_updates=30900, lr=8.04518e-05, gnorm=0.273, clip=0, loss_scale=32, train_wall=61, gb_free=15.7, wall=24766
2023-07-10 22:18:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0287, device='cuda:1')
tensor(0.0016, device='cuda:1')
tensor(0.0287, device='cuda:5')
tensor(0.0016, device='cuda:5')
tensor(0.0287, device='cuda:4')
tensor(0.0016, device='cuda:4')
tensor(0.0287, device='cuda:3')
tensor(0.0016, device='cuda:3')
tensor(0.0287, device='cuda:6')
tensor(0.0016, device='cuda:6')
tensor(0.0287, device='cuda:7')
tensor(0.0016, device='cuda:7')
tensor(0.0287, device='cuda:2')
tensor(0.0016, device='cuda:2')
2023-07-10 22:18:45 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 1.786 | trans_loss 5.58 | nll_loss 2.86 | w2v_ctc_loss 0.549 | task_loss 4.323 | contrastive_loss 0.68 | total 4003.4 | n_correct 2470.7 | ppl 7.26 | accuracy 61.715 | uer 17.007 | wer 18.944 | raw_wer 18.944 | bleu 19.64 | wps 1951.1 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.13
2023-07-10 22:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-10 22:18:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-10 22:18:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-10 22:18:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt (epoch 21 @ 30940 updates, score 19.64) (writing took 4.117907951003872 seconds)
2023-07-10 22:18:49 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-10 22:18:49 | INFO | train | epoch 021 | loss 1.058 | trans_loss 5.281 | nll_loss 2.563 | w2v_ctc_loss 0.332 | task_loss 3.053 | contrastive_loss 0.265 | total 4137.02 | n_correct 2691.13 | ppl 5.91 | accuracy 65.05 | wps 6300.7 | ups 1.52 | wpb 4137 | bsz 152.5 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.266 | clip 0 | loss_scale 32 | train_wall 887 | gb_free 15.6 | wall 24823
2023-07-10 22:18:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 22:18:49 | INFO | fairseq.trainer | begin training epoch 22
2023-07-10 22:18:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 22:19:33 | INFO | train_inner | epoch 022:     60 / 1474 loss=1.088, trans_loss=5.268, nll_loss=2.546, w2v_ctc_loss=0.329, task_loss=3.275, contrastive_loss=0.645, total=4128.84, n_correct=2694.38, ppl=5.84, accuracy=65.258, wps=4103.9, ups=0.99, wpb=4128.8, bsz=148.8, num_updates=31000, lr=8.03219e-05, gnorm=0.271, clip=0, loss_scale=32, train_wall=60, gb_free=14.4, wall=24867
2023-07-10 22:20:35 | INFO | train_inner | epoch 022:    160 / 1474 loss=1.113, trans_loss=5.264, nll_loss=2.541, w2v_ctc_loss=0.33, task_loss=3.238, contrastive_loss=1.116, total=4123.35, n_correct=2694.02, ppl=5.82, accuracy=65.336, wps=6721.3, ups=1.63, wpb=4123.4, bsz=155.1, num_updates=31100, lr=8.01927e-05, gnorm=0.274, clip=0, loss_scale=32, train_wall=61, gb_free=14.9, wall=24928
2023-07-10 22:21:36 | INFO | train_inner | epoch 022:    260 / 1474 loss=1.113, trans_loss=5.255, nll_loss=2.53, w2v_ctc_loss=0.322, task_loss=2.805, contrastive_loss=1.132, total=4267.16, n_correct=2793.55, ppl=5.78, accuracy=65.466, wps=6987.2, ups=1.64, wpb=4267.2, bsz=165, num_updates=31200, lr=8.00641e-05, gnorm=0.268, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=24989
2023-07-10 22:22:38 | INFO | train_inner | epoch 022:    360 / 1474 loss=1.115, trans_loss=5.284, nll_loss=2.566, w2v_ctc_loss=0.33, task_loss=3.177, contrastive_loss=1.214, total=4180.09, n_correct=2718.43, ppl=5.92, accuracy=65.033, wps=6748.7, ups=1.61, wpb=4180.1, bsz=155, num_updates=31300, lr=7.99361e-05, gnorm=0.277, clip=0, loss_scale=32, train_wall=62, gb_free=17.7, wall=25051
2023-07-10 22:23:39 | INFO | train_inner | epoch 022:    460 / 1474 loss=1.108, trans_loss=5.289, nll_loss=2.572, w2v_ctc_loss=0.332, task_loss=3.156, contrastive_loss=0.909, total=4132.62, n_correct=2683.76, ppl=5.95, accuracy=64.941, wps=6772, ups=1.64, wpb=4132.6, bsz=148.6, num_updates=31400, lr=7.98087e-05, gnorm=0.276, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=25112
2023-07-10 22:24:40 | INFO | train_inner | epoch 022:    560 / 1474 loss=1.096, trans_loss=5.278, nll_loss=2.558, w2v_ctc_loss=0.332, task_loss=3.021, contrastive_loss=0.759, total=4155.5, n_correct=2707.33, ppl=5.89, accuracy=65.151, wps=6821.3, ups=1.64, wpb=4155.5, bsz=153.7, num_updates=31500, lr=7.96819e-05, gnorm=0.275, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=25173
2023-07-10 22:25:39 | INFO | train_inner | epoch 022:    660 / 1474 loss=1.087, trans_loss=5.264, nll_loss=2.541, w2v_ctc_loss=0.32, task_loss=2.833, contrastive_loss=0.86, total=4147.84, n_correct=2708.07, ppl=5.82, accuracy=65.289, wps=6980.4, ups=1.68, wpb=4147.8, bsz=156.6, num_updates=31600, lr=7.95557e-05, gnorm=0.271, clip=0, loss_scale=64, train_wall=59, gb_free=13.5, wall=25233
2023-07-10 22:26:40 | INFO | train_inner | epoch 022:    760 / 1474 loss=1.092, trans_loss=5.283, nll_loss=2.564, w2v_ctc_loss=0.332, task_loss=3.065, contrastive_loss=0.695, total=4166.89, n_correct=2711.32, ppl=5.91, accuracy=65.068, wps=6853.1, ups=1.64, wpb=4166.9, bsz=152.2, num_updates=31700, lr=7.94301e-05, gnorm=0.277, clip=0, loss_scale=64, train_wall=60, gb_free=16.1, wall=25293
2023-07-10 22:27:41 | INFO | train_inner | epoch 022:    860 / 1474 loss=1.085, trans_loss=5.287, nll_loss=2.571, w2v_ctc_loss=0.329, task_loss=3.267, contrastive_loss=0.621, total=4074.75, n_correct=2641.92, ppl=5.94, accuracy=64.836, wps=6672, ups=1.64, wpb=4074.8, bsz=144.2, num_updates=31800, lr=7.93052e-05, gnorm=0.274, clip=0, loss_scale=64, train_wall=61, gb_free=17.6, wall=25355
2023-07-10 22:28:41 | INFO | train_inner | epoch 022:    960 / 1474 loss=1.083, trans_loss=5.279, nll_loss=2.561, w2v_ctc_loss=0.324, task_loss=3.009, contrastive_loss=0.593, total=4136.34, n_correct=2689.87, ppl=5.9, accuracy=65.03, wps=6843.8, ups=1.65, wpb=4136.3, bsz=151.8, num_updates=31900, lr=7.91808e-05, gnorm=0.271, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=25415
2023-07-10 22:29:41 | INFO | train_inner | epoch 022:   1060 / 1474 loss=1.086, trans_loss=5.279, nll_loss=2.561, w2v_ctc_loss=0.324, task_loss=2.839, contrastive_loss=0.891, total=4157.21, n_correct=2710.23, ppl=5.9, accuracy=65.193, wps=6934.8, ups=1.67, wpb=4157.2, bsz=157.7, num_updates=32000, lr=7.90569e-05, gnorm=0.273, clip=0, loss_scale=64, train_wall=60, gb_free=12.5, wall=25475
2023-07-10 22:29:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 22:30:07 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 1.772 | trans_loss 5.577 | nll_loss 2.858 | w2v_ctc_loss 0.535 | task_loss 3.708 | contrastive_loss 0.652 | total 4003.4 | n_correct 2467.9 | ppl 7.25 | accuracy 61.645 | uer 17.055 | wer 18.873 | raw_wer 18.873 | bleu 19.83 | wps 2047.6 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.13
2023-07-10 22:30:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-10 22:30:07 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_22_32000.pt
2023-07-10 22:30:09 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_22_32000.pt
2023-07-10 22:30:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.83) (writing took 6.206347316969186 seconds)
2023-07-10 22:31:13 | INFO | train_inner | epoch 022:   1160 / 1474 loss=1.088, trans_loss=5.304, nll_loss=2.593, w2v_ctc_loss=0.332, task_loss=3.111, contrastive_loss=0.627, total=4092.91, n_correct=2648.69, ppl=6.04, accuracy=64.714, wps=4446.4, ups=1.09, wpb=4092.9, bsz=147.2, num_updates=32100, lr=7.89337e-05, gnorm=0.274, clip=0, loss_scale=64, train_wall=59, gb_free=16.2, wall=25567
2023-07-10 22:32:14 | INFO | train_inner | epoch 022:   1260 / 1474 loss=1.084, trans_loss=5.295, nll_loss=2.583, w2v_ctc_loss=0.332, task_loss=2.774, contrastive_loss=0.615, total=4182.65, n_correct=2710.98, ppl=5.99, accuracy=64.815, wps=6915.6, ups=1.65, wpb=4182.6, bsz=161.8, num_updates=32200, lr=7.8811e-05, gnorm=0.269, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=25627
2023-07-10 22:33:14 | INFO | train_inner | epoch 022:   1360 / 1474 loss=1.079, trans_loss=5.285, nll_loss=2.569, w2v_ctc_loss=0.326, task_loss=2.969, contrastive_loss=0.636, total=4071.58, n_correct=2646.2, ppl=5.93, accuracy=64.992, wps=6724.9, ups=1.65, wpb=4071.6, bsz=150.3, num_updates=32300, lr=7.86889e-05, gnorm=0.275, clip=0, loss_scale=64, train_wall=60, gb_free=16.9, wall=25688
2023-07-10 22:34:15 | INFO | train_inner | epoch 022:   1460 / 1474 loss=1.087, trans_loss=5.305, nll_loss=2.594, w2v_ctc_loss=0.335, task_loss=3.188, contrastive_loss=0.535, total=4077.83, n_correct=2635.54, ppl=6.04, accuracy=64.631, wps=6763.5, ups=1.66, wpb=4077.8, bsz=144, num_updates=32400, lr=7.85674e-05, gnorm=0.275, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=25748
2023-07-10 22:34:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 22:34:49 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 1.768 | trans_loss 5.576 | nll_loss 2.852 | w2v_ctc_loss 0.537 | task_loss 3.702 | contrastive_loss 0.601 | total 4003.4 | n_correct 2475.6 | ppl 7.22 | accuracy 61.837 | uer 16.996 | wer 18.888 | raw_wer 18.888 | bleu 19.84 | wps 2113.4 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 20.13
2023-07-10 22:34:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-07-10 22:34:49 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.8408.pt
2023-07-10 22:34:51 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.8408.pt
2023-07-10 22:34:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_19.8408.pt (epoch 22 @ 32414 updates, score 19.84) (writing took 5.128010876011103 seconds)
2023-07-10 22:34:54 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-10 22:34:54 | INFO | train | epoch 022 | loss 1.094 | trans_loss 5.281 | nll_loss 2.563 | w2v_ctc_loss 0.329 | task_loss 3.04 | contrastive_loss 0.799 | total 4138.65 | n_correct 2692.48 | ppl 5.91 | accuracy 65.057 | wps 6320.9 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.274 | clip 0 | loss_scale 64 | train_wall 887 | gb_free 12.2 | wall 25788
2023-07-10 22:34:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 22:34:55 | INFO | fairseq.trainer | begin training epoch 23
2023-07-10 22:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 22:35:55 | INFO | train_inner | epoch 023:     86 / 1474 loss=1.076, trans_loss=5.258, nll_loss=2.532, w2v_ctc_loss=0.33, task_loss=3.088, contrastive_loss=0.512, total=4089.8, n_correct=2675.48, ppl=5.79, accuracy=65.418, wps=4092.1, ups=1, wpb=4089.8, bsz=149.7, num_updates=32500, lr=7.84465e-05, gnorm=0.272, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=25848
2023-07-10 22:36:55 | INFO | train_inner | epoch 023:    186 / 1474 loss=1.071, trans_loss=5.252, nll_loss=2.525, w2v_ctc_loss=0.324, task_loss=3.15, contrastive_loss=0.48, total=4117.76, n_correct=2698.07, ppl=5.76, accuracy=65.523, wps=6780.3, ups=1.65, wpb=4117.8, bsz=148, num_updates=32600, lr=7.8326e-05, gnorm=0.272, clip=0, loss_scale=64, train_wall=60, gb_free=15.7, wall=25909
2023-07-10 22:37:56 | INFO | train_inner | epoch 023:    286 / 1474 loss=1.072, trans_loss=5.261, nll_loss=2.537, w2v_ctc_loss=0.321, task_loss=3.045, contrastive_loss=0.619, total=4144.73, n_correct=2708.31, ppl=5.8, accuracy=65.343, wps=6793.1, ups=1.64, wpb=4144.7, bsz=152, num_updates=32700, lr=7.82062e-05, gnorm=0.27, clip=0, loss_scale=64, train_wall=61, gb_free=17.6, wall=25970
2023-07-10 22:38:57 | INFO | train_inner | epoch 023:    386 / 1474 loss=1.069, trans_loss=5.258, nll_loss=2.532, w2v_ctc_loss=0.323, task_loss=3.07, contrastive_loss=0.435, total=4126.79, n_correct=2700.64, ppl=5.79, accuracy=65.442, wps=6870.8, ups=1.66, wpb=4126.8, bsz=148.2, num_updates=32800, lr=7.80869e-05, gnorm=0.269, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=26030
2023-07-10 22:39:57 | INFO | train_inner | epoch 023:    486 / 1474 loss=1.071, trans_loss=5.262, nll_loss=2.538, w2v_ctc_loss=0.323, task_loss=2.918, contrastive_loss=0.541, total=4150.15, n_correct=2712.68, ppl=5.81, accuracy=65.363, wps=6831.9, ups=1.65, wpb=4150.1, bsz=156, num_updates=32900, lr=7.79681e-05, gnorm=0.271, clip=0, loss_scale=64, train_wall=60, gb_free=16.4, wall=26091
2023-07-10 22:40:58 | INFO | train_inner | epoch 023:    586 / 1474 loss=1.063, trans_loss=5.249, nll_loss=2.522, w2v_ctc_loss=0.321, task_loss=2.814, contrastive_loss=0.427, total=4174.6, n_correct=2739.19, ppl=5.74, accuracy=65.616, wps=6932.8, ups=1.66, wpb=4174.6, bsz=158.2, num_updates=33000, lr=7.78499e-05, gnorm=0.272, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=26151
2023-07-10 22:41:58 | INFO | train_inner | epoch 023:    686 / 1474 loss=1.071, trans_loss=5.26, nll_loss=2.536, w2v_ctc_loss=0.326, task_loss=3.014, contrastive_loss=0.492, total=4136.6, n_correct=2704.2, ppl=5.8, accuracy=65.373, wps=6876.6, ups=1.66, wpb=4136.6, bsz=150.6, num_updates=33100, lr=7.77322e-05, gnorm=0.273, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=26211
2023-07-10 22:42:58 | INFO | train_inner | epoch 023:    786 / 1474 loss=1.075, trans_loss=5.272, nll_loss=2.552, w2v_ctc_loss=0.329, task_loss=3.008, contrastive_loss=0.455, total=4147.22, n_correct=2705.63, ppl=5.86, accuracy=65.24, wps=6865.2, ups=1.66, wpb=4147.2, bsz=152.6, num_updates=33200, lr=7.76151e-05, gnorm=0.274, clip=0, loss_scale=64, train_wall=60, gb_free=17.4, wall=26272
2023-07-10 22:43:58 | INFO | train_inner | epoch 023:    886 / 1474 loss=1.071, trans_loss=5.258, nll_loss=2.535, w2v_ctc_loss=0.325, task_loss=2.715, contrastive_loss=0.602, total=4193.16, n_correct=2742.97, ppl=5.79, accuracy=65.415, wps=7006.3, ups=1.67, wpb=4193.2, bsz=163.6, num_updates=33300, lr=7.74984e-05, gnorm=0.271, clip=0, loss_scale=64, train_wall=59, gb_free=16.2, wall=26331
2023-07-10 22:44:59 | INFO | train_inner | epoch 023:    986 / 1474 loss=1.079, trans_loss=5.27, nll_loss=2.55, w2v_ctc_loss=0.323, task_loss=2.979, contrastive_loss=0.887, total=4164.33, n_correct=2714.06, ppl=5.86, accuracy=65.174, wps=6872.7, ups=1.65, wpb=4164.3, bsz=155.1, num_updates=33400, lr=7.73823e-05, gnorm=0.271, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=26392
2023-07-10 22:46:00 | INFO | train_inner | epoch 023:   1086 / 1474 loss=1.079, trans_loss=5.276, nll_loss=2.557, w2v_ctc_loss=0.332, task_loss=3.176, contrastive_loss=0.535, total=4088.37, n_correct=2663.35, ppl=5.88, accuracy=65.145, wps=6666, ups=1.63, wpb=4088.4, bsz=144.8, num_updates=33500, lr=7.72667e-05, gnorm=0.275, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=26453
2023-07-10 22:47:01 | INFO | train_inner | epoch 023:   1186 / 1474 loss=1.089, trans_loss=5.279, nll_loss=2.561, w2v_ctc_loss=0.328, task_loss=3.191, contrastive_loss=0.75, total=4162.3, n_correct=2709.33, ppl=5.9, accuracy=65.092, wps=6809.9, ups=1.64, wpb=4162.3, bsz=154.5, num_updates=33600, lr=7.71517e-05, gnorm=0.273, clip=0, loss_scale=64, train_wall=61, gb_free=15.8, wall=26515
2023-07-10 22:48:01 | INFO | train_inner | epoch 023:   1286 / 1474 loss=1.096, trans_loss=5.275, nll_loss=2.556, w2v_ctc_loss=0.322, task_loss=3.173, contrastive_loss=0.887, total=4131.74, n_correct=2692.64, ppl=5.88, accuracy=65.17, wps=6884.8, ups=1.67, wpb=4131.7, bsz=154.4, num_updates=33700, lr=7.70371e-05, gnorm=0.271, clip=0, loss_scale=128, train_wall=60, gb_free=17.2, wall=26575
2023-07-10 22:49:02 | INFO | train_inner | epoch 023:   1386 / 1474 loss=1.122, trans_loss=5.304, nll_loss=2.594, w2v_ctc_loss=0.327, task_loss=3.289, contrastive_loss=1.208, total=4141.25, n_correct=2678.08, ppl=6.04, accuracy=64.668, wps=6808.1, ups=1.64, wpb=4141.2, bsz=152.4, num_updates=33800, lr=7.69231e-05, gnorm=0.276, clip=0, loss_scale=128, train_wall=60, gb_free=17, wall=26635
2023-07-10 22:49:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-10 22:49:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 22:50:22 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 1.869 | trans_loss 5.57 | nll_loss 2.845 | w2v_ctc_loss 0.554 | task_loss 4.343 | contrastive_loss 1.587 | total 4003.4 | n_correct 2480.6 | ppl 7.18 | accuracy 61.962 | uer 16.898 | wer 18.858 | raw_wer 18.858 | bleu 20.21 | wps 2113.7 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.21
2023-07-10 22:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-07-10 22:50:22 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 22:50:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 22:50:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 23 @ 33887 updates, score 20.21) (writing took 8.350279743026476 seconds)
2023-07-10 22:50:30 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-10 22:50:30 | INFO | train | epoch 023 | loss 1.082 | trans_loss 5.269 | nll_loss 2.548 | w2v_ctc_loss 0.325 | task_loss 3.064 | contrastive_loss 0.673 | total 4136.71 | n_correct 2699.31 | ppl 5.85 | accuracy 65.253 | wps 6508.9 | ups 1.57 | wpb 4136.7 | bsz 152.5 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.272 | clip 0 | loss_scale 64 | train_wall 886 | gb_free 14.1 | wall 26724
2023-07-10 22:50:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 22:50:31 | INFO | fairseq.trainer | begin training epoch 24
2023-07-10 22:50:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 22:50:47 | INFO | train_inner | epoch 024:     13 / 1474 loss=1.13, trans_loss=5.299, nll_loss=2.588, w2v_ctc_loss=0.325, task_loss=3.4, contrastive_loss=1.35, total=4062.78, n_correct=2631.56, ppl=6.01, accuracy=64.772, wps=3878.2, ups=0.95, wpb=4062.8, bsz=147.6, num_updates=33900, lr=7.68095e-05, gnorm=0.277, clip=0, loss_scale=64, train_wall=61, gb_free=13, wall=26740
2023-07-10 22:51:47 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.14, trans_loss=5.262, nll_loss=2.538, w2v_ctc_loss=0.32, task_loss=2.998, contrastive_loss=1.718, total=4171.44, n_correct=2727.99, ppl=5.81, accuracy=65.397, wps=6881.8, ups=1.65, wpb=4171.4, bsz=162.3, num_updates=34000, lr=7.66965e-05, gnorm=0.279, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=26801
2023-07-10 22:51:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 22:52:14 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 1.865 | trans_loss 5.583 | nll_loss 2.857 | w2v_ctc_loss 0.548 | task_loss 4.332 | contrastive_loss 1.537 | total 4003.4 | n_correct 2473.4 | ppl 7.25 | accuracy 61.782 | uer 16.837 | wer 18.732 | raw_wer 18.732 | bleu 19.87 | wps 2116.6 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.21
2023-07-10 22:52:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-10 22:52:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_24_34000.pt
2023-07-10 22:52:16 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_24_34000.pt
2023-07-10 22:52:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.87) (writing took 6.198072338011116 seconds)
2023-07-10 22:53:22 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.138, trans_loss=5.262, nll_loss=2.539, w2v_ctc_loss=0.315, task_loss=2.762, contrastive_loss=1.808, total=4251.29, n_correct=2782.21, ppl=5.81, accuracy=65.444, wps=4477.5, ups=1.05, wpb=4251.3, bsz=170.4, num_updates=34100, lr=7.6584e-05, gnorm=0.277, clip=0, loss_scale=64, train_wall=61, gb_free=17, wall=26896
2023-07-10 22:54:22 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.124, trans_loss=5.263, nll_loss=2.538, w2v_ctc_loss=0.32, task_loss=2.929, contrastive_loss=1.343, total=4128.18, n_correct=2698.6, ppl=5.81, accuracy=65.37, wps=6853.1, ups=1.66, wpb=4128.2, bsz=152.8, num_updates=34200, lr=7.64719e-05, gnorm=0.276, clip=0, loss_scale=64, train_wall=60, gb_free=16.3, wall=26956
2023-07-10 22:55:24 | INFO | train_inner | epoch 024:    413 / 1474 loss=1.136, trans_loss=5.29, nll_loss=2.574, w2v_ctc_loss=0.329, task_loss=3.135, contrastive_loss=1.52, total=4158.92, n_correct=2700.82, ppl=5.96, accuracy=64.94, wps=6787.2, ups=1.63, wpb=4158.9, bsz=149.9, num_updates=34300, lr=7.63604e-05, gnorm=0.282, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=27017
2023-07-10 22:56:25 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.123, trans_loss=5.285, nll_loss=2.568, w2v_ctc_loss=0.325, task_loss=3.024, contrastive_loss=1.3, total=4144.91, n_correct=2696.23, ppl=5.93, accuracy=65.049, wps=6815.9, ups=1.64, wpb=4144.9, bsz=151.6, num_updates=34400, lr=7.62493e-05, gnorm=0.278, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=27078
2023-07-10 22:57:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-10 22:57:25 | INFO | train_inner | epoch 024:    614 / 1474 loss=1.12, trans_loss=5.281, nll_loss=2.563, w2v_ctc_loss=0.321, task_loss=3.023, contrastive_loss=1.266, total=4155.87, n_correct=2703.61, ppl=5.91, accuracy=65.055, wps=6829.6, ups=1.64, wpb=4155.9, bsz=152.7, num_updates=34500, lr=7.61387e-05, gnorm=0.276, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=27139
2023-07-10 22:58:26 | INFO | train_inner | epoch 024:    714 / 1474 loss=1.138, trans_loss=5.291, nll_loss=2.574, w2v_ctc_loss=0.324, task_loss=3.079, contrastive_loss=1.453, total=4097.35, n_correct=2660.66, ppl=5.96, accuracy=64.936, wps=6805.9, ups=1.66, wpb=4097.4, bsz=146.9, num_updates=34600, lr=7.60286e-05, gnorm=0.283, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=27199
2023-07-10 22:59:27 | INFO | train_inner | epoch 024:    814 / 1474 loss=1.143, trans_loss=5.288, nll_loss=2.572, w2v_ctc_loss=0.322, task_loss=2.962, contrastive_loss=1.53, total=4124.25, n_correct=2681.75, ppl=5.95, accuracy=65.024, wps=6706.6, ups=1.63, wpb=4124.2, bsz=154.1, num_updates=34700, lr=7.5919e-05, gnorm=0.281, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=27261
2023-07-10 23:00:27 | INFO | train_inner | epoch 024:    914 / 1474 loss=1.141, trans_loss=5.303, nll_loss=2.591, w2v_ctc_loss=0.326, task_loss=3.302, contrastive_loss=1.421, total=4041.44, n_correct=2610.51, ppl=6.03, accuracy=64.594, wps=6761.2, ups=1.67, wpb=4041.4, bsz=140.3, num_updates=34800, lr=7.58098e-05, gnorm=0.283, clip=0, loss_scale=32, train_wall=59, gb_free=16.4, wall=27320
2023-07-10 23:01:28 | INFO | train_inner | epoch 024:   1014 / 1474 loss=1.14, trans_loss=5.301, nll_loss=2.589, w2v_ctc_loss=0.318, task_loss=3.101, contrastive_loss=1.488, total=4128.8, n_correct=2675.9, ppl=6.02, accuracy=64.811, wps=6799.4, ups=1.65, wpb=4128.8, bsz=148.2, num_updates=34900, lr=7.57011e-05, gnorm=0.281, clip=0, loss_scale=32, train_wall=60, gb_free=15.3, wall=27381
2023-07-10 23:02:28 | INFO | train_inner | epoch 024:   1114 / 1474 loss=1.14, trans_loss=5.294, nll_loss=2.58, w2v_ctc_loss=0.325, task_loss=2.894, contrastive_loss=1.538, total=4130.49, n_correct=2673.5, ppl=5.98, accuracy=64.726, wps=6817.4, ups=1.65, wpb=4130.5, bsz=154.4, num_updates=35000, lr=7.55929e-05, gnorm=0.281, clip=0, loss_scale=32, train_wall=60, gb_free=16.3, wall=27442
tensor(0.0287, device='cuda:0')
tensor(0.0016, device='cuda:0')
2023-07-10 23:03:29 | INFO | train_inner | epoch 024:   1214 / 1474 loss=1.153, trans_loss=5.307, nll_loss=2.598, w2v_ctc_loss=0.322, task_loss=2.958, contrastive_loss=1.642, total=4157.47, n_correct=2688.13, ppl=6.05, accuracy=64.658, wps=6823.7, ups=1.64, wpb=4157.5, bsz=155.6, num_updates=35100, lr=7.54851e-05, gnorm=0.289, clip=0, loss_scale=32, train_wall=61, gb_free=13.1, wall=27503
2023-07-10 23:04:30 | INFO | train_inner | epoch 024:   1314 / 1474 loss=1.153, trans_loss=5.316, nll_loss=2.608, w2v_ctc_loss=0.328, task_loss=3.169, contrastive_loss=1.572, total=4107.23, n_correct=2646.86, ppl=6.1, accuracy=64.444, wps=6797.6, ups=1.66, wpb=4107.2, bsz=147.2, num_updates=35200, lr=7.53778e-05, gnorm=0.292, clip=0, loss_scale=32, train_wall=60, gb_free=17.7, wall=27563
2023-07-10 23:05:30 | INFO | train_inner | epoch 024:   1414 / 1474 loss=1.159, trans_loss=5.318, nll_loss=2.612, w2v_ctc_loss=0.328, task_loss=3.117, contrastive_loss=1.658, total=4094.39, n_correct=2638.09, ppl=6.11, accuracy=64.432, wps=6772.4, ups=1.65, wpb=4094.4, bsz=146.4, num_updates=35300, lr=7.5271e-05, gnorm=0.288, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=27624
2023-07-10 23:06:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0287, device='cuda:4')
tensor(0.0016, device='cuda:4')
tensor(0.0287, device='cuda:1')
tensor(0.0016, device='cuda:1')
tensor(0.0287, device='cuda:6')
tensor(0.0016, device='cuda:6')
tensor(0.0287, device='cuda:7')
tensor(0.0016, device='cuda:7')
tensor(0.0287, device='cuda:3')
tensor(0.0016, device='cuda:3')
tensor(0.0287, device='cuda:2')
tensor(0.0016, device='cuda:2')
tensor(0.0287, device='cuda:5')
tensor(0.0016, device='cuda:5')
2023-07-10 23:06:30 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 1.868 | trans_loss 5.578 | nll_loss 2.85 | w2v_ctc_loss 0.54 | task_loss 3.771 | contrastive_loss 1.651 | total 4003.4 | n_correct 2473.3 | ppl 7.21 | accuracy 61.78 | uer 16.948 | wer 18.702 | raw_wer 18.702 | bleu 19.71 | wps 2195.7 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 20.21
2023-07-10 23:06:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-07-10 23:06:30 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-10 23:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-10 23:06:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt (epoch 24 @ 35360 updates, score 19.71) (writing took 4.155809981981292 seconds)
2023-07-10 23:06:34 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-10 23:06:34 | INFO | train | epoch 024 | loss 1.139 | trans_loss 5.29 | nll_loss 2.575 | w2v_ctc_loss 0.323 | task_loss 3.015 | contrastive_loss 1.526 | total 4138.21 | n_correct 2686.47 | ppl 5.96 | accuracy 64.919 | wps 6324.6 | ups 1.53 | wpb 4138.2 | bsz 152.8 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.282 | clip 0 | loss_scale 32 | train_wall 888 | gb_free 16.3 | wall 27688
2023-07-10 23:06:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 23:06:34 | INFO | fairseq.trainer | begin training epoch 25
2023-07-10 23:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 23:07:06 | INFO | train_inner | epoch 025:     40 / 1474 loss=1.14, trans_loss=5.291, nll_loss=2.577, w2v_ctc_loss=0.319, task_loss=2.874, contrastive_loss=1.588, total=4165.57, n_correct=2705.27, ppl=5.97, accuracy=64.944, wps=4326.6, ups=1.04, wpb=4165.6, bsz=155.6, num_updates=35400, lr=7.51646e-05, gnorm=0.284, clip=0, loss_scale=32, train_wall=60, gb_free=13.5, wall=27720
2023-07-10 23:08:06 | INFO | train_inner | epoch 025:    140 / 1474 loss=1.139, trans_loss=5.278, nll_loss=2.559, w2v_ctc_loss=0.314, task_loss=3.152, contrastive_loss=1.688, total=4135.43, n_correct=2691.89, ppl=5.89, accuracy=65.093, wps=6864.9, ups=1.66, wpb=4135.4, bsz=154.5, num_updates=35500, lr=7.50587e-05, gnorm=0.288, clip=0, loss_scale=32, train_wall=60, gb_free=17.8, wall=27780
2023-07-10 23:09:08 | INFO | train_inner | epoch 025:    240 / 1474 loss=1.144, trans_loss=5.286, nll_loss=2.57, w2v_ctc_loss=0.321, task_loss=3.378, contrastive_loss=1.624, total=4116.13, n_correct=2672.05, ppl=5.94, accuracy=64.917, wps=6675.7, ups=1.62, wpb=4116.1, bsz=151.5, num_updates=35600, lr=7.49532e-05, gnorm=0.295, clip=0, loss_scale=32, train_wall=61, gb_free=17.4, wall=27842
2023-07-10 23:10:09 | INFO | train_inner | epoch 025:    340 / 1474 loss=1.159, trans_loss=5.284, nll_loss=2.565, w2v_ctc_loss=0.32, task_loss=3.43, contrastive_loss=1.8, total=4141.49, n_correct=2688.9, ppl=5.92, accuracy=64.926, wps=6779.9, ups=1.64, wpb=4141.5, bsz=147.1, num_updates=35700, lr=7.48481e-05, gnorm=0.286, clip=0, loss_scale=32, train_wall=61, gb_free=15.4, wall=27903
2023-07-10 23:11:10 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.176, trans_loss=5.294, nll_loss=2.579, w2v_ctc_loss=0.33, task_loss=3.256, contrastive_loss=2.025, total=4167.4, n_correct=2705.69, ppl=5.97, accuracy=64.925, wps=6827, ups=1.64, wpb=4167.4, bsz=148.8, num_updates=35800, lr=7.47435e-05, gnorm=0.288, clip=0, loss_scale=32, train_wall=61, gb_free=16, wall=27964
2023-07-10 23:12:12 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.154, trans_loss=5.293, nll_loss=2.58, w2v_ctc_loss=0.323, task_loss=2.919, contrastive_loss=1.729, total=4160.61, n_correct=2701.22, ppl=5.98, accuracy=64.924, wps=6767.9, ups=1.63, wpb=4160.6, bsz=157, num_updates=35900, lr=7.46393e-05, gnorm=0.289, clip=0, loss_scale=32, train_wall=61, gb_free=17.7, wall=28025
2023-07-10 23:13:12 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.139, trans_loss=5.28, nll_loss=2.564, w2v_ctc_loss=0.319, task_loss=2.981, contrastive_loss=1.642, total=4153.68, n_correct=2702.54, ppl=5.91, accuracy=65.064, wps=6937.8, ups=1.67, wpb=4153.7, bsz=154.8, num_updates=36000, lr=7.45356e-05, gnorm=0.29, clip=0, loss_scale=32, train_wall=59, gb_free=16.6, wall=28085
2023-07-10 23:13:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 23:13:39 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 1.856 | trans_loss 5.575 | nll_loss 2.846 | w2v_ctc_loss 0.553 | task_loss 3.727 | contrastive_loss 1.523 | total 4003.4 | n_correct 2482.1 | ppl 7.19 | accuracy 62 | uer 16.948 | wer 18.825 | raw_wer 18.825 | bleu 20.03 | wps 1870.6 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.21
2023-07-10 23:13:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-10 23:13:39 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_25_36000.pt
2023-07-10 23:13:41 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_25_36000.pt
2023-07-10 23:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.03) (writing took 6.171561391965952 seconds)
2023-07-10 23:14:47 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.133, trans_loss=5.284, nll_loss=2.568, w2v_ctc_loss=0.319, task_loss=3.046, contrastive_loss=1.527, total=4128.34, n_correct=2682.21, ppl=5.93, accuracy=64.971, wps=4351.7, ups=1.05, wpb=4128.3, bsz=150.6, num_updates=36100, lr=7.44323e-05, gnorm=0.291, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=28180
2023-07-10 23:15:47 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.129, trans_loss=5.288, nll_loss=2.573, w2v_ctc_loss=0.32, task_loss=2.753, contrastive_loss=1.418, total=4182.4, n_correct=2719.51, ppl=5.95, accuracy=65.023, wps=6872.6, ups=1.64, wpb=4182.4, bsz=163, num_updates=36200, lr=7.43294e-05, gnorm=0.291, clip=0, loss_scale=32, train_wall=60, gb_free=17.8, wall=28241
2023-07-10 23:16:48 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.126, trans_loss=5.286, nll_loss=2.571, w2v_ctc_loss=0.322, task_loss=2.846, contrastive_loss=1.401, total=4155.21, n_correct=2697.7, ppl=5.94, accuracy=64.923, wps=6818, ups=1.64, wpb=4155.2, bsz=158.5, num_updates=36300, lr=7.4227e-05, gnorm=0.289, clip=0, loss_scale=32, train_wall=61, gb_free=14.4, wall=28302
2023-07-10 23:17:50 | INFO | train_inner | epoch 025:   1040 / 1474 loss=1.13, trans_loss=5.301, nll_loss=2.59, w2v_ctc_loss=0.32, task_loss=2.982, contrastive_loss=1.533, total=4177.7, n_correct=2701.35, ppl=6.02, accuracy=64.661, wps=6828, ups=1.63, wpb=4177.7, bsz=154.9, num_updates=36400, lr=7.41249e-05, gnorm=0.291, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=28363
2023-07-10 23:18:50 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.117, trans_loss=5.293, nll_loss=2.579, w2v_ctc_loss=0.322, task_loss=3.232, contrastive_loss=1.127, total=4039.24, n_correct=2617.73, ppl=5.97, accuracy=64.807, wps=6678.3, ups=1.65, wpb=4039.2, bsz=142.6, num_updates=36500, lr=7.40233e-05, gnorm=0.3, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=28424
2023-07-10 23:19:49 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.117, trans_loss=5.294, nll_loss=2.582, w2v_ctc_loss=0.322, task_loss=3.042, contrastive_loss=1.123, total=4090.59, n_correct=2652, ppl=5.99, accuracy=64.832, wps=6896, ups=1.69, wpb=4090.6, bsz=147.8, num_updates=36600, lr=7.39221e-05, gnorm=0.296, clip=0, loss_scale=64, train_wall=59, gb_free=17.4, wall=28483
2023-07-10 23:20:50 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.115, trans_loss=5.281, nll_loss=2.564, w2v_ctc_loss=0.319, task_loss=2.919, contrastive_loss=1.264, total=4164.34, n_correct=2711.77, ppl=5.91, accuracy=65.119, wps=6865.9, ups=1.65, wpb=4164.3, bsz=155.1, num_updates=36700, lr=7.38213e-05, gnorm=0.291, clip=0, loss_scale=64, train_wall=60, gb_free=17.1, wall=28544
2023-07-10 23:21:51 | INFO | train_inner | epoch 025:   1440 / 1474 loss=1.115, trans_loss=5.312, nll_loss=2.604, w2v_ctc_loss=0.326, task_loss=3.122, contrastive_loss=1.145, total=4099.11, n_correct=2643.91, ppl=6.08, accuracy=64.5, wps=6703.1, ups=1.64, wpb=4099.1, bsz=149.7, num_updates=36800, lr=7.3721e-05, gnorm=0.298, clip=0, loss_scale=64, train_wall=61, gb_free=12.6, wall=28605
2023-07-10 23:22:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 23:22:38 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 1.803 | trans_loss 5.562 | nll_loss 2.835 | w2v_ctc_loss 0.532 | task_loss 3.72 | contrastive_loss 1.076 | total 4003.4 | n_correct 2485.5 | ppl 7.13 | accuracy 62.085 | uer 16.662 | wer 18.5 | raw_wer 18.5 | bleu 20.29 | wps 2069.6 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.29
2023-07-10 23:22:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-07-10 23:22:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 23:22:42 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-10 23:22:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 25 @ 36834 updates, score 20.29) (writing took 8.202260777004994 seconds)
2023-07-10 23:22:46 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-10 23:22:46 | INFO | train | epoch 025 | loss 1.135 | trans_loss 5.289 | nll_loss 2.575 | w2v_ctc_loss 0.321 | task_loss 3.057 | contrastive_loss 1.497 | total 4138.65 | n_correct 2686.28 | ppl 5.96 | accuracy 64.907 | wps 6275.5 | ups 1.52 | wpb 4138.6 | bsz 152.8 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.292 | clip 0 | loss_scale 64 | train_wall 890 | gb_free 14.6 | wall 28660
2023-07-10 23:22:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 23:22:47 | INFO | fairseq.trainer | begin training epoch 26
2023-07-10 23:22:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 23:23:34 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.103, trans_loss=5.265, nll_loss=2.544, w2v_ctc_loss=0.316, task_loss=2.806, contrastive_loss=1.101, total=4180.21, n_correct=2729.02, ppl=5.83, accuracy=65.284, wps=4063.1, ups=0.97, wpb=4180.2, bsz=159.2, num_updates=36900, lr=7.3621e-05, gnorm=0.292, clip=0, loss_scale=64, train_wall=60, gb_free=17.2, wall=28708
2023-07-10 23:24:35 | INFO | train_inner | epoch 026:    166 / 1474 loss=1.107, trans_loss=5.253, nll_loss=2.529, w2v_ctc_loss=0.309, task_loss=2.618, contrastive_loss=1.412, total=4270.78, n_correct=2800.79, ppl=5.77, accuracy=65.58, wps=7017.6, ups=1.64, wpb=4270.8, bsz=170.2, num_updates=37000, lr=7.35215e-05, gnorm=0.291, clip=0, loss_scale=64, train_wall=60, gb_free=15.5, wall=28768
2023-07-10 23:25:36 | INFO | train_inner | epoch 026:    266 / 1474 loss=1.103, trans_loss=5.269, nll_loss=2.549, w2v_ctc_loss=0.321, task_loss=2.976, contrastive_loss=1.152, total=4125.04, n_correct=2691.77, ppl=5.85, accuracy=65.254, wps=6795.1, ups=1.65, wpb=4125, bsz=153.6, num_updates=37100, lr=7.34223e-05, gnorm=0.297, clip=0, loss_scale=64, train_wall=60, gb_free=15.4, wall=28829
2023-07-10 23:26:36 | INFO | train_inner | epoch 026:    366 / 1474 loss=1.097, trans_loss=5.265, nll_loss=2.544, w2v_ctc_loss=0.317, task_loss=2.875, contrastive_loss=1.061, total=4165.74, n_correct=2719.98, ppl=5.83, accuracy=65.294, wps=6866.2, ups=1.65, wpb=4165.7, bsz=157.3, num_updates=37200, lr=7.33236e-05, gnorm=0.294, clip=0, loss_scale=64, train_wall=60, gb_free=17, wall=28890
2023-07-10 23:27:36 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.1, trans_loss=5.257, nll_loss=2.533, w2v_ctc_loss=0.318, task_loss=2.846, contrastive_loss=1.103, total=4170.23, n_correct=2733.41, ppl=5.79, accuracy=65.546, wps=6955.1, ups=1.67, wpb=4170.2, bsz=157.7, num_updates=37300, lr=7.32252e-05, gnorm=0.296, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=28950
2023-07-10 23:28:37 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.096, trans_loss=5.274, nll_loss=2.554, w2v_ctc_loss=0.324, task_loss=3.015, contrastive_loss=0.936, total=4155.02, n_correct=2704.76, ppl=5.87, accuracy=65.096, wps=6839.7, ups=1.65, wpb=4155, bsz=151.9, num_updates=37400, lr=7.31272e-05, gnorm=0.297, clip=0, loss_scale=64, train_wall=60, gb_free=17.9, wall=29011
2023-07-10 23:29:37 | INFO | train_inner | epoch 026:    666 / 1474 loss=1.095, trans_loss=5.27, nll_loss=2.55, w2v_ctc_loss=0.318, task_loss=3.053, contrastive_loss=0.864, total=4136.96, n_correct=2699.53, ppl=5.86, accuracy=65.254, wps=6846.5, ups=1.65, wpb=4137, bsz=149.6, num_updates=37500, lr=7.30297e-05, gnorm=0.296, clip=0, loss_scale=64, train_wall=60, gb_free=15.6, wall=29071
2023-07-10 23:30:38 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.104, trans_loss=5.283, nll_loss=2.566, w2v_ctc_loss=0.321, task_loss=3.047, contrastive_loss=1.127, total=4086.28, n_correct=2655.2, ppl=5.92, accuracy=64.978, wps=6791.5, ups=1.66, wpb=4086.3, bsz=149.2, num_updates=37600, lr=7.29325e-05, gnorm=0.304, clip=0, loss_scale=64, train_wall=60, gb_free=15.3, wall=29131
2023-07-10 23:31:38 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.124, trans_loss=5.281, nll_loss=2.563, w2v_ctc_loss=0.321, task_loss=2.958, contrastive_loss=1.328, total=4183.26, n_correct=2715.77, ppl=5.91, accuracy=64.92, wps=6937, ups=1.66, wpb=4183.3, bsz=154.1, num_updates=37700, lr=7.28357e-05, gnorm=0.303, clip=0, loss_scale=64, train_wall=60, gb_free=17.5, wall=29191
2023-07-10 23:32:39 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.128, trans_loss=5.292, nll_loss=2.579, w2v_ctc_loss=0.318, task_loss=3.105, contrastive_loss=1.439, total=4137.96, n_correct=2679.34, ppl=5.97, accuracy=64.75, wps=6789.9, ups=1.64, wpb=4138, bsz=149.5, num_updates=37800, lr=7.27393e-05, gnorm=0.302, clip=0, loss_scale=64, train_wall=61, gb_free=17.1, wall=29252
2023-07-10 23:33:39 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.134, trans_loss=5.292, nll_loss=2.578, w2v_ctc_loss=0.324, task_loss=3.192, contrastive_loss=1.4, total=4120.53, n_correct=2671.74, ppl=5.97, accuracy=64.84, wps=6819.2, ups=1.65, wpb=4120.5, bsz=147.1, num_updates=37900, lr=7.26433e-05, gnorm=0.308, clip=0, loss_scale=64, train_wall=60, gb_free=16.8, wall=29313
2023-07-10 23:34:40 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.149, trans_loss=5.3, nll_loss=2.589, w2v_ctc_loss=0.324, task_loss=3.459, contrastive_loss=1.672, total=4113.86, n_correct=2662.96, ppl=6.02, accuracy=64.731, wps=6736.1, ups=1.64, wpb=4113.9, bsz=149.2, num_updates=38000, lr=7.25476e-05, gnorm=0.302, clip=0, loss_scale=64, train_wall=61, gb_free=16.8, wall=29374
2023-07-10 23:34:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 23:35:08 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 1.877 | trans_loss 5.575 | nll_loss 2.848 | w2v_ctc_loss 0.558 | task_loss 4.337 | contrastive_loss 1.695 | total 4003.4 | n_correct 2473.3 | ppl 7.2 | accuracy 61.78 | uer 17.129 | wer 19.067 | raw_wer 19.067 | bleu 19.83 | wps 1978.6 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.29
2023-07-10 23:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-10 23:35:08 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_26_38000.pt
2023-07-10 23:35:10 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_26_38000.pt
2023-07-10 23:35:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 19.83) (writing took 4.893243062950205 seconds)
2023-07-10 23:36:14 | INFO | train_inner | epoch 026:   1266 / 1474 loss=1.151, trans_loss=5.314, nll_loss=2.606, w2v_ctc_loss=0.329, task_loss=3.539, contrastive_loss=1.582, total=3996.19, n_correct=2574.44, ppl=6.09, accuracy=64.422, wps=4276.4, ups=1.07, wpb=3996.2, bsz=139.6, num_updates=38100, lr=7.24524e-05, gnorm=0.308, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=29467
2023-07-10 23:37:16 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.134, trans_loss=5.298, nll_loss=2.587, w2v_ctc_loss=0.318, task_loss=2.992, contrastive_loss=1.442, total=4159.74, n_correct=2696.38, ppl=6.01, accuracy=64.821, wps=6707.7, ups=1.61, wpb=4159.7, bsz=155.7, num_updates=38200, lr=7.23575e-05, gnorm=0.303, clip=0, loss_scale=64, train_wall=62, gb_free=17.4, wall=29529
2023-07-10 23:38:17 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.118, trans_loss=5.29, nll_loss=2.577, w2v_ctc_loss=0.317, task_loss=2.85, contrastive_loss=1.268, total=4165.66, n_correct=2703.88, ppl=5.97, accuracy=64.909, wps=6856.1, ups=1.65, wpb=4165.7, bsz=158.7, num_updates=38300, lr=7.22629e-05, gnorm=0.308, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=29590
2023-07-10 23:38:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 23:38:47 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 1.823 | trans_loss 5.56 | nll_loss 2.828 | w2v_ctc_loss 0.547 | task_loss 3.734 | contrastive_loss 1.255 | total 4003.4 | n_correct 2485.3 | ppl 7.1 | accuracy 62.08 | uer 16.688 | wer 18.504 | raw_wer 18.504 | bleu 20 | wps 2122.2 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.29
2023-07-10 23:38:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-07-10 23:38:47 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0005.pt
2023-07-10 23:38:49 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0005.pt
2023-07-10 23:38:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0005.pt (epoch 26 @ 38308 updates, score 20.0) (writing took 5.0172250650357455 seconds)
2023-07-10 23:38:52 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-10 23:38:52 | INFO | train | epoch 026 | loss 1.116 | trans_loss 5.279 | nll_loss 2.562 | w2v_ctc_loss 0.32 | task_loss 3.031 | contrastive_loss 1.258 | total 4138.65 | n_correct 2692.5 | ppl 5.91 | accuracy 65.057 | wps 6316.6 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.3 | clip 0 | loss_scale 64 | train_wall 888 | gb_free 16.3 | wall 29626
2023-07-10 23:38:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 23:38:52 | INFO | fairseq.trainer | begin training epoch 27
2023-07-10 23:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 23:39:56 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.105, trans_loss=5.244, nll_loss=2.514, w2v_ctc_loss=0.313, task_loss=3.231, contrastive_loss=1.066, total=4054.57, n_correct=2661.28, ppl=5.71, accuracy=65.637, wps=4090.3, ups=1.01, wpb=4054.6, bsz=141.2, num_updates=38400, lr=7.21688e-05, gnorm=0.308, clip=0, loss_scale=64, train_wall=60, gb_free=16.5, wall=29689
2023-07-10 23:40:56 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.102, trans_loss=5.253, nll_loss=2.528, w2v_ctc_loss=0.316, task_loss=2.831, contrastive_loss=1.144, total=4195.2, n_correct=2747.16, ppl=5.77, accuracy=65.483, wps=6917.8, ups=1.65, wpb=4195.2, bsz=161.6, num_updates=38500, lr=7.2075e-05, gnorm=0.302, clip=0, loss_scale=64, train_wall=60, gb_free=17.3, wall=29750
2023-07-10 23:41:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-10 23:41:58 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.102, trans_loss=5.265, nll_loss=2.543, w2v_ctc_loss=0.318, task_loss=2.987, contrastive_loss=1.031, total=4172.15, n_correct=2725.56, ppl=5.83, accuracy=65.327, wps=6766.4, ups=1.62, wpb=4172.1, bsz=153.8, num_updates=38600, lr=7.19816e-05, gnorm=0.304, clip=0, loss_scale=32, train_wall=61, gb_free=17, wall=29812
2023-07-10 23:43:00 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.108, trans_loss=5.275, nll_loss=2.557, w2v_ctc_loss=0.318, task_loss=3.146, contrastive_loss=1.281, total=4075.21, n_correct=2655.94, ppl=5.88, accuracy=65.173, wps=6615.1, ups=1.62, wpb=4075.2, bsz=148, num_updates=38700, lr=7.18885e-05, gnorm=0.309, clip=0, loss_scale=32, train_wall=61, gb_free=17.8, wall=29873
2023-07-10 23:44:01 | INFO | train_inner | epoch 027:    493 / 1474 loss=1.107, trans_loss=5.281, nll_loss=2.566, w2v_ctc_loss=0.318, task_loss=2.735, contrastive_loss=1.192, total=4249.35, n_correct=2764.2, ppl=5.92, accuracy=65.05, wps=6962.5, ups=1.64, wpb=4249.4, bsz=166, num_updates=38800, lr=7.17958e-05, gnorm=0.302, clip=0, loss_scale=32, train_wall=61, gb_free=12.4, wall=29934
2023-07-10 23:45:01 | INFO | train_inner | epoch 027:    593 / 1474 loss=1.099, trans_loss=5.273, nll_loss=2.555, w2v_ctc_loss=0.32, task_loss=2.949, contrastive_loss=1.033, total=4133.39, n_correct=2694.79, ppl=5.87, accuracy=65.196, wps=6839.5, ups=1.65, wpb=4133.4, bsz=156, num_updates=38900, lr=7.17035e-05, gnorm=0.307, clip=0, loss_scale=32, train_wall=60, gb_free=12.5, wall=29995
2023-07-10 23:46:01 | INFO | train_inner | epoch 027:    693 / 1474 loss=1.1, trans_loss=5.282, nll_loss=2.566, w2v_ctc_loss=0.321, task_loss=2.984, contrastive_loss=0.961, total=4162.71, n_correct=2707.25, ppl=5.92, accuracy=65.036, wps=6894.3, ups=1.66, wpb=4162.7, bsz=152.7, num_updates=39000, lr=7.16115e-05, gnorm=0.308, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=30055
2023-07-10 23:47:02 | INFO | train_inner | epoch 027:    793 / 1474 loss=1.093, trans_loss=5.275, nll_loss=2.557, w2v_ctc_loss=0.32, task_loss=3.147, contrastive_loss=0.865, total=4103.81, n_correct=2672.42, ppl=5.88, accuracy=65.12, wps=6832.7, ups=1.66, wpb=4103.8, bsz=147.1, num_updates=39100, lr=7.15199e-05, gnorm=0.307, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=30115
2023-07-10 23:48:02 | INFO | train_inner | epoch 027:    893 / 1474 loss=1.094, trans_loss=5.279, nll_loss=2.56, w2v_ctc_loss=0.316, task_loss=3.122, contrastive_loss=0.803, total=4101.56, n_correct=2667.64, ppl=5.9, accuracy=65.04, wps=6816.4, ups=1.66, wpb=4101.6, bsz=146.1, num_updates=39200, lr=7.14286e-05, gnorm=0.307, clip=0, loss_scale=32, train_wall=60, gb_free=17.8, wall=30175
2023-07-10 23:49:03 | INFO | train_inner | epoch 027:    993 / 1474 loss=1.097, trans_loss=5.284, nll_loss=2.57, w2v_ctc_loss=0.32, task_loss=2.893, contrastive_loss=1.157, total=4199.56, n_correct=2729.99, ppl=5.94, accuracy=65.007, wps=6873.1, ups=1.64, wpb=4199.6, bsz=158.4, num_updates=39300, lr=7.13376e-05, gnorm=0.31, clip=0, loss_scale=32, train_wall=61, gb_free=12.1, wall=30236
2023-07-10 23:50:03 | INFO | train_inner | epoch 027:   1093 / 1474 loss=1.088, trans_loss=5.277, nll_loss=2.56, w2v_ctc_loss=0.319, task_loss=3.023, contrastive_loss=0.834, total=4150.97, n_correct=2699.25, ppl=5.9, accuracy=65.027, wps=6851.2, ups=1.65, wpb=4151, bsz=152.5, num_updates=39400, lr=7.1247e-05, gnorm=0.3, clip=0, loss_scale=32, train_wall=60, gb_free=12.4, wall=30297
2023-07-10 23:51:04 | INFO | train_inner | epoch 027:   1193 / 1474 loss=1.09, trans_loss=5.283, nll_loss=2.567, w2v_ctc_loss=0.32, task_loss=3.126, contrastive_loss=0.831, total=4103.06, n_correct=2663.11, ppl=5.92, accuracy=64.905, wps=6762.9, ups=1.65, wpb=4103.1, bsz=148.8, num_updates=39500, lr=7.11568e-05, gnorm=0.311, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=30358
2023-07-10 23:52:04 | INFO | train_inner | epoch 027:   1293 / 1474 loss=1.091, trans_loss=5.297, nll_loss=2.585, w2v_ctc_loss=0.321, task_loss=3.207, contrastive_loss=0.888, total=4062.52, n_correct=2632.04, ppl=6, accuracy=64.788, wps=6745, ups=1.66, wpb=4062.5, bsz=146.1, num_updates=39600, lr=7.10669e-05, gnorm=0.314, clip=0, loss_scale=32, train_wall=60, gb_free=16.7, wall=30418
2023-07-10 23:53:05 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.092, trans_loss=5.285, nll_loss=2.572, w2v_ctc_loss=0.32, task_loss=2.838, contrastive_loss=0.871, total=4152, n_correct=2694.6, ppl=5.95, accuracy=64.899, wps=6893.1, ups=1.66, wpb=4152, bsz=156.2, num_updates=39700, lr=7.09773e-05, gnorm=0.311, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=30478
2023-07-10 23:53:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 23:54:17 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 1.789 | trans_loss 5.561 | nll_loss 2.826 | w2v_ctc_loss 0.557 | task_loss 3.71 | contrastive_loss 0.856 | total 4003.4 | n_correct 2490.3 | ppl 7.09 | accuracy 62.205 | uer 16.72 | wer 18.523 | raw_wer 18.523 | bleu 19.95 | wps 2435.8 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.29
2023-07-10 23:54:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-07-10 23:54:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-10 23:54:21 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-10 23:54:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt (epoch 27 @ 39781 updates, score 19.95) (writing took 4.108138041046914 seconds)
2023-07-10 23:54:21 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-10 23:54:21 | INFO | train | epoch 027 | loss 1.097 | trans_loss 5.275 | nll_loss 2.557 | w2v_ctc_loss 0.318 | task_loss 2.995 | contrastive_loss 0.988 | total 4139.15 | n_correct 2695.65 | ppl 5.88 | accuracy 65.126 | wps 6563 | ups 1.59 | wpb 4139.2 | bsz 152.9 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.308 | clip 0 | loss_scale 32 | train_wall 887 | gb_free 17.9 | wall 30555
2023-07-10 23:54:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-10 23:54:21 | INFO | fairseq.trainer | begin training epoch 28
2023-07-10 23:54:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-10 23:54:41 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.084, trans_loss=5.266, nll_loss=2.546, w2v_ctc_loss=0.313, task_loss=2.898, contrastive_loss=0.767, total=4108.43, n_correct=2680.35, ppl=5.84, accuracy=65.24, wps=4277.9, ups=1.04, wpb=4108.4, bsz=152.6, num_updates=39800, lr=7.08881e-05, gnorm=0.321, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=30574
2023-07-10 23:55:41 | INFO | train_inner | epoch 028:    119 / 1474 loss=1.083, trans_loss=5.245, nll_loss=2.517, w2v_ctc_loss=0.318, task_loss=3.123, contrastive_loss=0.724, total=4113.41, n_correct=2699.88, ppl=5.72, accuracy=65.636, wps=6811, ups=1.66, wpb=4113.4, bsz=147, num_updates=39900, lr=7.07992e-05, gnorm=0.308, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=30635
2023-07-10 23:56:42 | INFO | train_inner | epoch 028:    219 / 1474 loss=1.08, trans_loss=5.246, nll_loss=2.519, w2v_ctc_loss=0.314, task_loss=2.828, contrastive_loss=0.746, total=4191.56, n_correct=2750.47, ppl=5.73, accuracy=65.619, wps=6914.1, ups=1.65, wpb=4191.6, bsz=157.6, num_updates=40000, lr=7.07107e-05, gnorm=0.3, clip=0, loss_scale=32, train_wall=60, gb_free=15.4, wall=30695
2023-07-10 23:56:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-10 23:57:06 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 1.775 | trans_loss 5.564 | nll_loss 2.831 | w2v_ctc_loss 0.542 | task_loss 3.732 | contrastive_loss 0.799 | total 4003.4 | n_correct 2489.7 | ppl 7.12 | accuracy 62.19 | uer 16.662 | wer 18.392 | raw_wer 18.392 | bleu 19.97 | wps 2239.6 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.29
2023-07-10 23:57:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-10 23:57:06 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_28_40000.pt
2023-07-10 23:57:08 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_28_40000.pt
2023-07-10 23:57:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 19.97) (writing took 6.167616976017598 seconds)
tensor(0.0287, device='cuda:0')
tensor(0.0016, device='cuda:0')
2023-07-10 23:58:13 | INFO | train_inner | epoch 028:    319 / 1474 loss=1.095, trans_loss=5.262, nll_loss=2.54, w2v_ctc_loss=0.312, task_loss=2.973, contrastive_loss=1.337, total=4145.32, n_correct=2709.22, ppl=5.82, accuracy=65.356, wps=4511.8, ups=1.09, wpb=4145.3, bsz=158.1, num_updates=40100, lr=7.06225e-05, gnorm=0.307, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=30787
2023-07-10 23:59:14 | INFO | train_inner | epoch 028:    419 / 1474 loss=1.078, trans_loss=5.26, nll_loss=2.537, w2v_ctc_loss=0.317, task_loss=3.092, contrastive_loss=0.679, total=4092.14, n_correct=2674.65, ppl=5.8, accuracy=65.361, wps=6808.1, ups=1.66, wpb=4092.1, bsz=147.8, num_updates=40200, lr=7.05346e-05, gnorm=0.314, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=30847
2023-07-11 00:00:14 | INFO | train_inner | epoch 028:    519 / 1474 loss=1.081, trans_loss=5.261, nll_loss=2.538, w2v_ctc_loss=0.319, task_loss=3.112, contrastive_loss=0.695, total=4096.35, n_correct=2675.2, ppl=5.81, accuracy=65.307, wps=6771.5, ups=1.65, wpb=4096.4, bsz=147.8, num_updates=40300, lr=7.0447e-05, gnorm=0.311, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=30908
2023-07-11 00:01:15 | INFO | train_inner | epoch 028:    619 / 1474 loss=1.08, trans_loss=5.263, nll_loss=2.541, w2v_ctc_loss=0.316, task_loss=3.006, contrastive_loss=0.691, total=4178.12, n_correct=2728.26, ppl=5.82, accuracy=65.299, wps=6905.2, ups=1.65, wpb=4178.1, bsz=152.7, num_updates=40400, lr=7.03598e-05, gnorm=0.309, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=30968
2023-07-11 00:02:15 | INFO | train_inner | epoch 028:    719 / 1474 loss=1.086, trans_loss=5.266, nll_loss=2.547, w2v_ctc_loss=0.315, task_loss=2.726, contrastive_loss=0.917, total=4185.82, n_correct=2731.51, ppl=5.84, accuracy=65.256, wps=6938.6, ups=1.66, wpb=4185.8, bsz=163.2, num_updates=40500, lr=7.02728e-05, gnorm=0.316, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=31029
2023-07-11 00:03:15 | INFO | train_inner | epoch 028:    819 / 1474 loss=1.078, trans_loss=5.258, nll_loss=2.536, w2v_ctc_loss=0.314, task_loss=2.929, contrastive_loss=0.664, total=4096.2, n_correct=2679.45, ppl=5.8, accuracy=65.413, wps=6838.9, ups=1.67, wpb=4096.2, bsz=153.5, num_updates=40600, lr=7.01862e-05, gnorm=0.311, clip=0, loss_scale=64, train_wall=59, gb_free=15.9, wall=31088
2023-07-11 00:04:16 | INFO | train_inner | epoch 028:    919 / 1474 loss=1.08, trans_loss=5.278, nll_loss=2.56, w2v_ctc_loss=0.319, task_loss=3.089, contrastive_loss=0.773, total=4120.27, n_correct=2680, ppl=5.9, accuracy=65.044, wps=6725, ups=1.63, wpb=4120.3, bsz=150.4, num_updates=40700, lr=7.01e-05, gnorm=0.31, clip=0, loss_scale=64, train_wall=61, gb_free=17.5, wall=31150
2023-07-11 00:05:17 | INFO | train_inner | epoch 028:   1019 / 1474 loss=1.084, trans_loss=5.275, nll_loss=2.558, w2v_ctc_loss=0.32, task_loss=2.926, contrastive_loss=0.852, total=4177.86, n_correct=2718.69, ppl=5.89, accuracy=65.074, wps=6910.6, ups=1.65, wpb=4177.9, bsz=155.5, num_updates=40800, lr=7.0014e-05, gnorm=0.31, clip=0, loss_scale=64, train_wall=60, gb_free=16.6, wall=31210
2023-07-11 00:06:17 | INFO | train_inner | epoch 028:   1119 / 1474 loss=1.074, trans_loss=5.258, nll_loss=2.536, w2v_ctc_loss=0.315, task_loss=2.911, contrastive_loss=0.698, total=4210.86, n_correct=2753.76, ppl=5.8, accuracy=65.397, wps=6928.1, ups=1.65, wpb=4210.9, bsz=159.4, num_updates=40900, lr=6.99284e-05, gnorm=0.304, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=31271
2023-07-11 00:07:18 | INFO | train_inner | epoch 028:   1219 / 1474 loss=1.073, trans_loss=5.266, nll_loss=2.546, w2v_ctc_loss=0.315, task_loss=2.955, contrastive_loss=0.649, total=4104.61, n_correct=2678.15, ppl=5.84, accuracy=65.247, wps=6815, ups=1.66, wpb=4104.6, bsz=152.8, num_updates=41000, lr=6.9843e-05, gnorm=0.304, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=31331
2023-07-11 00:08:19 | INFO | train_inner | epoch 028:   1319 / 1474 loss=1.081, trans_loss=5.278, nll_loss=2.56, w2v_ctc_loss=0.323, task_loss=3.275, contrastive_loss=0.643, total=4087.78, n_correct=2662.68, ppl=5.9, accuracy=65.138, wps=6708.9, ups=1.64, wpb=4087.8, bsz=142.6, num_updates=41100, lr=6.9758e-05, gnorm=0.314, clip=0, loss_scale=64, train_wall=61, gb_free=15.3, wall=31392
2023-07-11 00:09:19 | INFO | train_inner | epoch 028:   1419 / 1474 loss=1.08, trans_loss=5.278, nll_loss=2.56, w2v_ctc_loss=0.319, task_loss=3.149, contrastive_loss=0.683, total=4145.03, n_correct=2694.04, ppl=5.9, accuracy=64.994, wps=6848, ups=1.65, wpb=4145, bsz=148.8, num_updates=41200, lr=6.96733e-05, gnorm=0.31, clip=0, loss_scale=64, train_wall=60, gb_free=17.8, wall=31453
2023-07-11 00:09:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0287, device='cuda:5')
tensor(0.0016, device='cuda:5')
tensor(0.0287, device='cuda:6')
tensor(0.0016, device='cuda:6')
tensor(0.0287, device='cuda:7')
tensor(0.0016, device='cuda:7')
tensor(0.0287, device='cuda:3')
tensor(0.0016, device='cuda:3')
tensor(0.0287, device='cuda:4')
tensor(0.0016, device='cuda:4')
tensor(0.0287, device='cuda:1')
tensor(0.0016, device='cuda:1')
tensor(0.0287, device='cuda:2')
tensor(0.0016, device='cuda:2')
2023-07-11 00:10:17 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 1.772 | trans_loss 5.562 | nll_loss 2.829 | w2v_ctc_loss 0.564 | task_loss 3.725 | contrastive_loss 0.72 | total 4003.4 | n_correct 2487 | ppl 7.11 | accuracy 62.122 | uer 16.787 | wer 18.739 | raw_wer 18.739 | bleu 20.13 | wps 2180 | wpb 4003.4 | bsz 141.8 | num_updates 41255 | best_bleu 20.29
2023-07-11 00:10:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41255 updates
2023-07-11 00:10:17 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1303.pt
2023-07-11 00:10:19 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1303.pt
2023-07-11 00:10:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1303.pt (epoch 28 @ 41255 updates, score 20.13) (writing took 5.2151196239865385 seconds)
2023-07-11 00:10:22 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-11 00:10:22 | INFO | train | epoch 028 | loss 1.081 | trans_loss 5.263 | nll_loss 2.542 | w2v_ctc_loss 0.317 | task_loss 2.993 | contrastive_loss 0.766 | total 4138.65 | n_correct 2702.62 | ppl 5.82 | accuracy 65.302 | wps 6345.6 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 41255 | lr 6.96268e-05 | gnorm 0.31 | clip 0 | loss_scale 64 | train_wall 886 | gb_free 16.7 | wall 31516
2023-07-11 00:10:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 00:10:23 | INFO | fairseq.trainer | begin training epoch 29
2023-07-11 00:10:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 00:10:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-11 00:10:58 | INFO | train_inner | epoch 029:     46 / 1474 loss=1.071, trans_loss=5.247, nll_loss=2.522, w2v_ctc_loss=0.318, task_loss=2.888, contrastive_loss=0.659, total=4160.3, n_correct=2726.93, ppl=5.74, accuracy=65.546, wps=4184.6, ups=1.01, wpb=4160.3, bsz=157.1, num_updates=41300, lr=6.95889e-05, gnorm=0.313, clip=0, loss_scale=32, train_wall=61, gb_free=16.6, wall=31552
2023-07-11 00:11:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-11 00:12:00 | INFO | train_inner | epoch 029:    147 / 1474 loss=1.072, trans_loss=5.242, nll_loss=2.514, w2v_ctc_loss=0.315, task_loss=2.992, contrastive_loss=0.68, total=4108.58, n_correct=2698.79, ppl=5.71, accuracy=65.687, wps=6680.9, ups=1.63, wpb=4108.6, bsz=152.5, num_updates=41400, lr=6.95048e-05, gnorm=0.315, clip=0, loss_scale=16, train_wall=61, gb_free=16.6, wall=31614
2023-07-11 00:13:01 | INFO | train_inner | epoch 029:    247 / 1474 loss=1.072, trans_loss=5.241, nll_loss=2.514, w2v_ctc_loss=0.309, task_loss=2.736, contrastive_loss=0.854, total=4197.89, n_correct=2755.24, ppl=5.71, accuracy=65.634, wps=6861.5, ups=1.63, wpb=4197.9, bsz=164.8, num_updates=41500, lr=6.9421e-05, gnorm=0.312, clip=0, loss_scale=16, train_wall=61, gb_free=17.6, wall=31675
2023-07-11 00:14:02 | INFO | train_inner | epoch 029:    347 / 1474 loss=1.08, trans_loss=5.262, nll_loss=2.54, w2v_ctc_loss=0.324, task_loss=3.202, contrastive_loss=0.594, total=4094.4, n_correct=2673.58, ppl=5.82, accuracy=65.298, wps=6753.8, ups=1.65, wpb=4094.4, bsz=145.6, num_updates=41600, lr=6.93375e-05, gnorm=0.312, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=31735
2023-07-11 00:15:02 | INFO | train_inner | epoch 029:    447 / 1474 loss=1.066, trans_loss=5.229, nll_loss=2.496, w2v_ctc_loss=0.311, task_loss=2.87, contrastive_loss=0.569, total=4157.41, n_correct=2740.72, ppl=5.64, accuracy=65.924, wps=6872.5, ups=1.65, wpb=4157.4, bsz=154.3, num_updates=41700, lr=6.92543e-05, gnorm=0.309, clip=0, loss_scale=16, train_wall=60, gb_free=15, wall=31796
2023-07-11 00:16:03 | INFO | train_inner | epoch 029:    547 / 1474 loss=1.084, trans_loss=5.272, nll_loss=2.553, w2v_ctc_loss=0.322, task_loss=3.201, contrastive_loss=0.753, total=4149.27, n_correct=2701.43, ppl=5.87, accuracy=65.106, wps=6817.1, ups=1.64, wpb=4149.3, bsz=146.6, num_updates=41800, lr=6.91714e-05, gnorm=0.316, clip=0, loss_scale=16, train_wall=60, gb_free=15.6, wall=31857
2023-07-11 00:17:03 | INFO | train_inner | epoch 029:    647 / 1474 loss=1.074, trans_loss=5.246, nll_loss=2.521, w2v_ctc_loss=0.315, task_loss=2.8, contrastive_loss=0.877, total=4145.39, n_correct=2713.89, ppl=5.74, accuracy=65.468, wps=6892.5, ups=1.66, wpb=4145.4, bsz=159.6, num_updates=41900, lr=6.90889e-05, gnorm=0.32, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=31917
2023-07-11 00:18:04 | INFO | train_inner | epoch 029:    747 / 1474 loss=1.071, trans_loss=5.244, nll_loss=2.517, w2v_ctc_loss=0.313, task_loss=2.755, contrastive_loss=0.751, total=4242.46, n_correct=2784.98, ppl=5.72, accuracy=65.645, wps=6932.5, ups=1.63, wpb=4242.5, bsz=164.9, num_updates=42000, lr=6.90066e-05, gnorm=0.308, clip=0, loss_scale=16, train_wall=61, gb_free=16.8, wall=31978
2023-07-11 00:18:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 00:18:29 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 1.77 | trans_loss 5.562 | nll_loss 2.828 | w2v_ctc_loss 0.552 | task_loss 3.712 | contrastive_loss 0.678 | total 4003.4 | n_correct 2480.1 | ppl 7.1 | accuracy 61.95 | uer 16.574 | wer 18.389 | raw_wer 18.389 | bleu 19.96 | wps 2229.1 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.29
2023-07-11 00:18:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-11 00:18:29 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_29_42000.pt
2023-07-11 00:18:31 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_29_42000.pt
2023-07-11 00:18:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 19.96) (writing took 4.948048360005487 seconds)
2023-07-11 00:19:34 | INFO | train_inner | epoch 029:    847 / 1474 loss=1.074, trans_loss=5.27, nll_loss=2.55, w2v_ctc_loss=0.317, task_loss=3.318, contrastive_loss=0.525, total=4027.03, n_correct=2622.12, ppl=5.86, accuracy=65.113, wps=4487, ups=1.11, wpb=4027, bsz=140.2, num_updates=42100, lr=6.89246e-05, gnorm=0.315, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=32068
2023-07-11 00:20:34 | INFO | train_inner | epoch 029:    947 / 1474 loss=1.071, trans_loss=5.261, nll_loss=2.539, w2v_ctc_loss=0.318, task_loss=3.064, contrastive_loss=0.567, total=4086.72, n_correct=2670.76, ppl=5.81, accuracy=65.352, wps=6842.6, ups=1.67, wpb=4086.7, bsz=148.2, num_updates=42200, lr=6.88428e-05, gnorm=0.321, clip=0, loss_scale=16, train_wall=59, gb_free=15.6, wall=32128
2023-07-11 00:21:35 | INFO | train_inner | epoch 029:   1047 / 1474 loss=1.072, trans_loss=5.253, nll_loss=2.528, w2v_ctc_loss=0.314, task_loss=2.995, contrastive_loss=0.727, total=4139.4, n_correct=2709.67, ppl=5.77, accuracy=65.46, wps=6836.9, ups=1.65, wpb=4139.4, bsz=153.7, num_updates=42300, lr=6.87614e-05, gnorm=0.308, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=32188
2023-07-11 00:22:35 | INFO | train_inner | epoch 029:   1147 / 1474 loss=1.07, trans_loss=5.267, nll_loss=2.547, w2v_ctc_loss=0.319, task_loss=3.256, contrastive_loss=0.499, total=4072.33, n_correct=2656.43, ppl=5.84, accuracy=65.231, wps=6717.2, ups=1.65, wpb=4072.3, bsz=142, num_updates=42400, lr=6.86803e-05, gnorm=0.312, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=32249
2023-07-11 00:23:36 | INFO | train_inner | epoch 029:   1247 / 1474 loss=1.073, trans_loss=5.268, nll_loss=2.549, w2v_ctc_loss=0.32, task_loss=3.035, contrastive_loss=0.55, total=4160.52, n_correct=2713.77, ppl=5.85, accuracy=65.227, wps=6874.5, ups=1.65, wpb=4160.5, bsz=150.8, num_updates=42500, lr=6.85994e-05, gnorm=0.316, clip=0, loss_scale=16, train_wall=60, gb_free=15.8, wall=32309
2023-07-11 00:24:37 | INFO | train_inner | epoch 029:   1347 / 1474 loss=1.072, trans_loss=5.253, nll_loss=2.53, w2v_ctc_loss=0.315, task_loss=2.958, contrastive_loss=0.681, total=4168.02, n_correct=2727.38, ppl=5.77, accuracy=65.436, wps=6837.2, ups=1.64, wpb=4168, bsz=155.1, num_updates=42600, lr=6.85189e-05, gnorm=0.315, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=32370
2023-07-11 00:25:37 | INFO | train_inner | epoch 029:   1447 / 1474 loss=1.076, trans_loss=5.254, nll_loss=2.532, w2v_ctc_loss=0.315, task_loss=2.917, contrastive_loss=0.731, total=4166.06, n_correct=2725.57, ppl=5.78, accuracy=65.423, wps=6950.8, ups=1.67, wpb=4166.1, bsz=156.6, num_updates=42700, lr=6.84386e-05, gnorm=0.318, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=32430
2023-07-11 00:25:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 00:26:19 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 1.765 | trans_loss 5.56 | nll_loss 2.824 | w2v_ctc_loss 0.545 | task_loss 3.715 | contrastive_loss 0.65 | total 4003.4 | n_correct 2491.4 | ppl 7.08 | accuracy 62.232 | uer 16.723 | wer 18.564 | raw_wer 18.564 | bleu 20.01 | wps 2179.4 | wpb 4003.4 | bsz 141.8 | num_updates 42727 | best_bleu 20.29
2023-07-11 00:26:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42727 updates
2023-07-11 00:26:19 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0103.pt
2023-07-11 00:26:21 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0103.pt
2023-07-11 00:26:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.0103.pt (epoch 29 @ 42727 updates, score 20.01) (writing took 5.109815146017354 seconds)
2023-07-11 00:26:24 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-11 00:26:24 | INFO | train | epoch 029 | loss 1.073 | trans_loss 5.254 | nll_loss 2.53 | w2v_ctc_loss 0.316 | task_loss 2.993 | contrastive_loss 0.671 | total 4137.77 | n_correct 2707.83 | ppl 5.77 | accuracy 65.442 | wps 6333.7 | ups 1.53 | wpb 4137.8 | bsz 152.7 | num_updates 42727 | lr 6.8417e-05 | gnorm 0.314 | clip 0 | loss_scale 16 | train_wall 886 | gb_free 16.4 | wall 32478
2023-07-11 00:26:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 00:26:24 | INFO | fairseq.trainer | begin training epoch 30
2023-07-11 00:26:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 00:27:17 | INFO | train_inner | epoch 030:     73 / 1474 loss=1.067, trans_loss=5.237, nll_loss=2.508, w2v_ctc_loss=0.309, task_loss=2.848, contrastive_loss=0.756, total=4175.11, n_correct=2742.84, ppl=5.69, accuracy=65.695, wps=4171.2, ups=1, wpb=4175.1, bsz=159.3, num_updates=42800, lr=6.83586e-05, gnorm=0.314, clip=0, loss_scale=16, train_wall=60, gb_free=17.3, wall=32530
2023-07-11 00:28:17 | INFO | train_inner | epoch 030:    173 / 1474 loss=1.062, trans_loss=5.217, nll_loss=2.483, w2v_ctc_loss=0.312, task_loss=2.814, contrastive_loss=0.624, total=4202.64, n_correct=2779.88, ppl=5.59, accuracy=66.146, wps=6940.9, ups=1.65, wpb=4202.6, bsz=159.2, num_updates=42900, lr=6.82789e-05, gnorm=0.306, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=32591
2023-07-11 00:29:17 | INFO | train_inner | epoch 030:    273 / 1474 loss=1.065, trans_loss=5.233, nll_loss=2.502, w2v_ctc_loss=0.317, task_loss=3.086, contrastive_loss=0.508, total=4120.21, n_correct=2713.1, ppl=5.67, accuracy=65.849, wps=6841.3, ups=1.66, wpb=4120.2, bsz=147.5, num_updates=43000, lr=6.81994e-05, gnorm=0.313, clip=0, loss_scale=16, train_wall=60, gb_free=15.6, wall=32651
2023-07-11 00:30:18 | INFO | train_inner | epoch 030:    373 / 1474 loss=1.061, trans_loss=5.22, nll_loss=2.486, w2v_ctc_loss=0.31, task_loss=2.991, contrastive_loss=0.531, total=4178.23, n_correct=2759.55, ppl=5.6, accuracy=66.046, wps=6868.9, ups=1.64, wpb=4178.2, bsz=153.8, num_updates=43100, lr=6.81203e-05, gnorm=0.311, clip=0, loss_scale=16, train_wall=60, gb_free=10.6, wall=32712
2023-07-11 00:31:18 | INFO | train_inner | epoch 030:    473 / 1474 loss=1.066, trans_loss=5.237, nll_loss=2.508, w2v_ctc_loss=0.312, task_loss=2.862, contrastive_loss=0.656, total=4124.47, n_correct=2712.56, ppl=5.69, accuracy=65.767, wps=6901.4, ups=1.67, wpb=4124.5, bsz=156.3, num_updates=43200, lr=6.80414e-05, gnorm=0.316, clip=0, loss_scale=16, train_wall=59, gb_free=17.7, wall=32772
2023-07-11 00:32:18 | INFO | train_inner | epoch 030:    573 / 1474 loss=1.065, trans_loss=5.236, nll_loss=2.508, w2v_ctc_loss=0.31, task_loss=2.906, contrastive_loss=0.584, total=4168.41, n_correct=2744.54, ppl=5.69, accuracy=65.841, wps=6922, ups=1.66, wpb=4168.4, bsz=156.2, num_updates=43300, lr=6.79628e-05, gnorm=0.308, clip=0, loss_scale=16, train_wall=60, gb_free=17.4, wall=32832
2023-07-11 00:33:19 | INFO | train_inner | epoch 030:    673 / 1474 loss=1.067, trans_loss=5.241, nll_loss=2.514, w2v_ctc_loss=0.316, task_loss=2.962, contrastive_loss=0.631, total=4187.95, n_correct=2749.18, ppl=5.71, accuracy=65.645, wps=6875.3, ups=1.64, wpb=4187.9, bsz=157.5, num_updates=43400, lr=6.78844e-05, gnorm=0.323, clip=0, loss_scale=32, train_wall=61, gb_free=16.1, wall=32893
2023-07-11 00:34:20 | INFO | train_inner | epoch 030:    773 / 1474 loss=1.077, trans_loss=5.259, nll_loss=2.537, w2v_ctc_loss=0.321, task_loss=3.049, contrastive_loss=0.748, total=4105.32, n_correct=2687.48, ppl=5.81, accuracy=65.463, wps=6757, ups=1.65, wpb=4105.3, bsz=151.3, num_updates=43500, lr=6.78064e-05, gnorm=0.323, clip=0, loss_scale=32, train_wall=60, gb_free=13.4, wall=32954
2023-07-11 00:35:21 | INFO | train_inner | epoch 030:    873 / 1474 loss=1.067, trans_loss=5.249, nll_loss=2.524, w2v_ctc_loss=0.315, task_loss=3.073, contrastive_loss=0.53, total=4102.11, n_correct=2690.31, ppl=5.75, accuracy=65.584, wps=6749.1, ups=1.65, wpb=4102.1, bsz=147.8, num_updates=43600, lr=6.77285e-05, gnorm=0.315, clip=0, loss_scale=32, train_wall=60, gb_free=17.5, wall=33014
2023-07-11 00:36:21 | INFO | train_inner | epoch 030:    973 / 1474 loss=1.07, trans_loss=5.26, nll_loss=2.537, w2v_ctc_loss=0.321, task_loss=3.077, contrastive_loss=0.537, total=4129.98, n_correct=2697.71, ppl=5.8, accuracy=65.32, wps=6808.5, ups=1.65, wpb=4130, bsz=150.2, num_updates=43700, lr=6.7651e-05, gnorm=0.325, clip=0, loss_scale=32, train_wall=60, gb_free=16.8, wall=33075
2023-07-11 00:37:23 | INFO | train_inner | epoch 030:   1073 / 1474 loss=1.072, trans_loss=5.257, nll_loss=2.533, w2v_ctc_loss=0.316, task_loss=3.344, contrastive_loss=0.639, total=4101.17, n_correct=2678.65, ppl=5.79, accuracy=65.314, wps=6681.9, ups=1.63, wpb=4101.2, bsz=141.2, num_updates=43800, lr=6.75737e-05, gnorm=0.316, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=33136
2023-07-11 00:38:23 | INFO | train_inner | epoch 030:   1173 / 1474 loss=1.068, trans_loss=5.247, nll_loss=2.522, w2v_ctc_loss=0.312, task_loss=2.88, contrastive_loss=0.644, total=4168.36, n_correct=2732.7, ppl=5.74, accuracy=65.558, wps=6892.7, ups=1.65, wpb=4168.4, bsz=157, num_updates=43900, lr=6.74967e-05, gnorm=0.321, clip=0, loss_scale=32, train_wall=60, gb_free=16.2, wall=33197
2023-07-11 00:39:25 | INFO | train_inner | epoch 030:   1273 / 1474 loss=1.073, trans_loss=5.26, nll_loss=2.538, w2v_ctc_loss=0.321, task_loss=3.303, contrastive_loss=0.509, total=4036.17, n_correct=2636.77, ppl=5.81, accuracy=65.329, wps=6555.2, ups=1.62, wpb=4036.2, bsz=142.1, num_updates=44000, lr=6.742e-05, gnorm=0.327, clip=0, loss_scale=32, train_wall=61, gb_free=15.9, wall=33258
2023-07-11 00:39:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 00:39:52 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 1.767 | trans_loss 5.554 | nll_loss 2.818 | w2v_ctc_loss 0.567 | task_loss 3.706 | contrastive_loss 0.622 | total 4003.4 | n_correct 2490.1 | ppl 7.05 | accuracy 62.2 | uer 16.752 | wer 18.638 | raw_wer 18.638 | bleu 20.21 | wps 1963.2 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.29
2023-07-11 00:39:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-11 00:39:52 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_30_44000.pt
2023-07-11 00:39:54 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_30_44000.pt
2023-07-11 00:39:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.21) (writing took 6.282862310006749 seconds)
2023-07-11 00:40:58 | INFO | train_inner | epoch 030:   1373 / 1474 loss=1.059, trans_loss=5.243, nll_loss=2.518, w2v_ctc_loss=0.31, task_loss=2.809, contrastive_loss=0.561, total=4165.07, n_correct=2735.4, ppl=5.73, accuracy=65.675, wps=4455.6, ups=1.07, wpb=4165.1, bsz=160.8, num_updates=44100, lr=6.73435e-05, gnorm=0.313, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=33352
2023-07-11 00:41:59 | INFO | train_inner | epoch 030:   1473 / 1474 loss=1.071, trans_loss=5.249, nll_loss=2.525, w2v_ctc_loss=0.311, task_loss=2.812, contrastive_loss=0.81, total=4141.76, n_correct=2715.29, ppl=5.76, accuracy=65.559, wps=6862.7, ups=1.66, wpb=4141.8, bsz=157.2, num_updates=44200, lr=6.72673e-05, gnorm=0.331, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=33412
2023-07-11 00:41:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 00:42:26 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 1.77 | trans_loss 5.558 | nll_loss 2.824 | w2v_ctc_loss 0.538 | task_loss 3.668 | contrastive_loss 0.618 | total 4003.4 | n_correct 2492.6 | ppl 7.08 | accuracy 62.262 | uer 16.789 | wer 18.709 | raw_wer 18.709 | bleu 20.22 | wps 1990.1 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.29
2023-07-11 00:42:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-07-11 00:42:26 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2203.pt
2023-07-11 00:42:28 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2203.pt
2023-07-11 00:42:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2203.pt (epoch 30 @ 44201 updates, score 20.22) (writing took 5.249010173953138 seconds)
2023-07-11 00:42:31 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-11 00:42:31 | INFO | train | epoch 030 | loss 1.067 | trans_loss 5.243 | nll_loss 2.516 | w2v_ctc_loss 0.314 | task_loss 2.99 | contrastive_loss 0.619 | total 4138.65 | n_correct 2717.38 | ppl 5.72 | accuracy 65.659 | wps 6308.8 | ups 1.52 | wpb 4138.6 | bsz 152.8 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.318 | clip 0 | loss_scale 32 | train_wall 887 | gb_free 17.2 | wall 33445
2023-07-11 00:42:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 00:42:31 | INFO | fairseq.trainer | begin training epoch 31
2023-07-11 00:42:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 00:43:40 | INFO | train_inner | epoch 031:     99 / 1474 loss=1.064, trans_loss=5.231, nll_loss=2.499, w2v_ctc_loss=0.318, task_loss=3.17, contrastive_loss=0.478, total=4054.44, n_correct=2671.17, ppl=5.65, accuracy=65.883, wps=4017.8, ups=0.99, wpb=4054.4, bsz=144.1, num_updates=44300, lr=6.71913e-05, gnorm=0.325, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=33513
2023-07-11 00:44:40 | INFO | train_inner | epoch 031:    199 / 1474 loss=1.064, trans_loss=5.229, nll_loss=2.496, w2v_ctc_loss=0.313, task_loss=3.049, contrastive_loss=0.547, total=4147.4, n_correct=2734.57, ppl=5.64, accuracy=65.935, wps=6847.3, ups=1.65, wpb=4147.4, bsz=151.1, num_updates=44400, lr=6.71156e-05, gnorm=0.316, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=33574
2023-07-11 00:45:41 | INFO | train_inner | epoch 031:    299 / 1474 loss=1.063, trans_loss=5.231, nll_loss=2.5, w2v_ctc_loss=0.314, task_loss=3.067, contrastive_loss=0.609, total=4149.21, n_correct=2733.19, ppl=5.66, accuracy=65.873, wps=6780.6, ups=1.63, wpb=4149.2, bsz=150.8, num_updates=44500, lr=6.70402e-05, gnorm=0.317, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=33635
2023-07-11 00:46:42 | INFO | train_inner | epoch 031:    399 / 1474 loss=1.061, trans_loss=5.235, nll_loss=2.504, w2v_ctc_loss=0.311, task_loss=3.273, contrastive_loss=0.462, total=4092.62, n_correct=2690.93, ppl=5.67, accuracy=65.751, wps=6743.1, ups=1.65, wpb=4092.6, bsz=142.8, num_updates=44600, lr=6.6965e-05, gnorm=0.321, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=33696
2023-07-11 00:47:43 | INFO | train_inner | epoch 031:    499 / 1474 loss=1.062, trans_loss=5.229, nll_loss=2.498, w2v_ctc_loss=0.316, task_loss=3.12, contrastive_loss=0.513, total=4111.85, n_correct=2707.66, ppl=5.65, accuracy=65.85, wps=6764.6, ups=1.65, wpb=4111.9, bsz=150.1, num_updates=44700, lr=6.689e-05, gnorm=0.317, clip=0, loss_scale=32, train_wall=60, gb_free=11.5, wall=33756
2023-07-11 00:48:43 | INFO | train_inner | epoch 031:    599 / 1474 loss=1.059, trans_loss=5.232, nll_loss=2.501, w2v_ctc_loss=0.313, task_loss=3.135, contrastive_loss=0.49, total=4083.44, n_correct=2689.27, ppl=5.66, accuracy=65.858, wps=6776.5, ups=1.66, wpb=4083.4, bsz=147.3, num_updates=44800, lr=6.68153e-05, gnorm=0.318, clip=0, loss_scale=32, train_wall=60, gb_free=16.9, wall=33817
2023-07-11 00:49:44 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.057, trans_loss=5.222, nll_loss=2.49, w2v_ctc_loss=0.307, task_loss=2.846, contrastive_loss=0.501, total=4213.98, n_correct=2777.63, ppl=5.62, accuracy=65.915, wps=6974.8, ups=1.66, wpb=4214, bsz=157.8, num_updates=44900, lr=6.67409e-05, gnorm=0.311, clip=0, loss_scale=32, train_wall=60, gb_free=16.6, wall=33877
2023-07-11 00:50:44 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.056, trans_loss=5.238, nll_loss=2.509, w2v_ctc_loss=0.31, task_loss=3.142, contrastive_loss=0.627, total=4097.37, n_correct=2688.52, ppl=5.69, accuracy=65.616, wps=6772.7, ups=1.65, wpb=4097.4, bsz=147.9, num_updates=45000, lr=6.66667e-05, gnorm=0.313, clip=0, loss_scale=32, train_wall=60, gb_free=13.3, wall=33938
tensor(0.0287, device='cuda:0')
tensor(0.0016, device='cuda:0')
2023-07-11 00:51:45 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.058, trans_loss=5.223, nll_loss=2.49, w2v_ctc_loss=0.309, task_loss=3.129, contrastive_loss=0.524, total=4096.72, n_correct=2700.81, ppl=5.62, accuracy=65.926, wps=6757.3, ups=1.65, wpb=4096.7, bsz=148, num_updates=45100, lr=6.65927e-05, gnorm=0.316, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=33998
2023-07-11 00:52:45 | INFO | train_inner | epoch 031:    999 / 1474 loss=1.068, trans_loss=5.238, nll_loss=2.511, w2v_ctc_loss=0.311, task_loss=2.825, contrastive_loss=0.701, total=4187.84, n_correct=2755.39, ppl=5.7, accuracy=65.795, wps=6933.8, ups=1.66, wpb=4187.8, bsz=159.7, num_updates=45200, lr=6.6519e-05, gnorm=0.321, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=34059
2023-07-11 00:53:46 | INFO | train_inner | epoch 031:   1099 / 1474 loss=1.064, trans_loss=5.237, nll_loss=2.51, w2v_ctc_loss=0.31, task_loss=2.934, contrastive_loss=0.609, total=4149.44, n_correct=2726.9, ppl=5.7, accuracy=65.717, wps=6863.4, ups=1.65, wpb=4149.4, bsz=157.5, num_updates=45300, lr=6.64455e-05, gnorm=0.322, clip=0, loss_scale=32, train_wall=60, gb_free=17.7, wall=34119
2023-07-11 00:54:46 | INFO | train_inner | epoch 031:   1199 / 1474 loss=1.073, trans_loss=5.243, nll_loss=2.519, w2v_ctc_loss=0.316, task_loss=2.783, contrastive_loss=0.807, total=4189.76, n_correct=2750.17, ppl=5.73, accuracy=65.64, wps=6959, ups=1.66, wpb=4189.8, bsz=160.6, num_updates=45400, lr=6.63723e-05, gnorm=0.317, clip=0, loss_scale=32, train_wall=60, gb_free=13.6, wall=34179
2023-07-11 00:55:46 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.061, trans_loss=5.237, nll_loss=2.51, w2v_ctc_loss=0.312, task_loss=2.676, contrastive_loss=0.515, total=4227.44, n_correct=2780.35, ppl=5.7, accuracy=65.769, wps=6980.3, ups=1.65, wpb=4227.4, bsz=163.2, num_updates=45500, lr=6.62994e-05, gnorm=0.323, clip=0, loss_scale=64, train_wall=60, gb_free=16.7, wall=34240
2023-07-11 00:56:47 | INFO | train_inner | epoch 031:   1399 / 1474 loss=1.069, trans_loss=5.24, nll_loss=2.514, w2v_ctc_loss=0.311, task_loss=2.738, contrastive_loss=0.889, total=4186.05, n_correct=2747.2, ppl=5.71, accuracy=65.628, wps=6931.2, ups=1.66, wpb=4186.1, bsz=163.3, num_updates=45600, lr=6.62266e-05, gnorm=0.313, clip=0, loss_scale=64, train_wall=60, gb_free=17.6, wall=34300
2023-07-11 00:57:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0287, device='cuda:4')
tensor(0.0016, device='cuda:4')
tensor(0.0287, device='cuda:1')
tensor(0.0016, device='cuda:1')
tensor(0.0287, device='cuda:7')
tensor(0.0016, device='cuda:7')
tensor(0.0287, device='cuda:6')
tensor(0.0016, device='cuda:6')
tensor(0.0287, device='cuda:3')
tensor(0.0016, device='cuda:3')
tensor(0.0287, device='cuda:2')
tensor(0.0016, device='cuda:2')
tensor(0.0287, device='cuda:5')
tensor(0.0016, device='cuda:5')
2023-07-11 00:57:56 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 1.759 | trans_loss 5.555 | nll_loss 2.821 | w2v_ctc_loss 0.56 | task_loss 3.721 | contrastive_loss 0.587 | total 4003.4 | n_correct 2495 | ppl 7.06 | accuracy 62.322 | uer 17.017 | wer 18.896 | raw_wer 18.896 | bleu 20.13 | wps 2224.1 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 20.29
2023-07-11 00:57:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-07-11 00:57:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1304.pt
2023-07-11 00:57:59 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1304.pt
2023-07-11 00:58:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1304.pt (epoch 31 @ 45675 updates, score 20.13) (writing took 5.216868830029853 seconds)
2023-07-11 00:58:02 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-11 00:58:02 | INFO | train | epoch 031 | loss 1.063 | trans_loss 5.233 | nll_loss 2.504 | w2v_ctc_loss 0.312 | task_loss 2.991 | contrastive_loss 0.588 | total 4138.65 | n_correct 2722.93 | ppl 5.67 | accuracy 65.793 | wps 6554.1 | ups 1.58 | wpb 4138.6 | bsz 152.8 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.319 | clip 0 | loss_scale 64 | train_wall 886 | gb_free 12.5 | wall 34375
2023-07-11 00:58:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 00:58:02 | INFO | fairseq.trainer | begin training epoch 32
2023-07-11 00:58:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 00:58:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-11 00:58:26 | INFO | train_inner | epoch 032:     26 / 1474 loss=1.057, trans_loss=5.227, nll_loss=2.495, w2v_ctc_loss=0.31, task_loss=3.139, contrastive_loss=0.452, total=4047.75, n_correct=2668.95, ppl=5.64, accuracy=65.937, wps=4095.6, ups=1.01, wpb=4047.8, bsz=145, num_updates=45700, lr=6.61541e-05, gnorm=0.33, clip=0, loss_scale=32, train_wall=60, gb_free=15.7, wall=34399
2023-07-11 00:59:26 | INFO | train_inner | epoch 032:    126 / 1474 loss=1.05, trans_loss=5.19, nll_loss=2.448, w2v_ctc_loss=0.302, task_loss=2.77, contrastive_loss=0.5, total=4222.14, n_correct=2807.56, ppl=5.46, accuracy=66.496, wps=6982.6, ups=1.65, wpb=4222.1, bsz=161.3, num_updates=45800, lr=6.60819e-05, gnorm=0.317, clip=0, loss_scale=32, train_wall=60, gb_free=15.8, wall=34460
2023-07-11 01:00:27 | INFO | train_inner | epoch 032:    226 / 1474 loss=1.055, trans_loss=5.216, nll_loss=2.481, w2v_ctc_loss=0.31, task_loss=2.852, contrastive_loss=0.534, total=4159.77, n_correct=2749.09, ppl=5.58, accuracy=66.088, wps=6869.1, ups=1.65, wpb=4159.8, bsz=160.4, num_updates=45900, lr=6.60098e-05, gnorm=0.336, clip=0, loss_scale=32, train_wall=60, gb_free=16.4, wall=34520
2023-07-11 01:01:27 | INFO | train_inner | epoch 032:    326 / 1474 loss=1.051, trans_loss=5.201, nll_loss=2.461, w2v_ctc_loss=0.306, task_loss=2.844, contrastive_loss=0.495, total=4179.65, n_correct=2770.6, ppl=5.51, accuracy=66.288, wps=6940.4, ups=1.66, wpb=4179.6, bsz=156.9, num_updates=46000, lr=6.5938e-05, gnorm=0.313, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=34580
2023-07-11 01:01:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 01:01:51 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 1.767 | trans_loss 5.558 | nll_loss 2.826 | w2v_ctc_loss 0.565 | task_loss 3.705 | contrastive_loss 0.593 | total 4003.4 | n_correct 2499.4 | ppl 7.09 | accuracy 62.432 | uer 16.909 | wer 18.545 | raw_wer 18.545 | bleu 19.99 | wps 2305.3 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.29
2023-07-11 01:01:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-11 01:01:51 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_32_46000.pt
2023-07-11 01:01:53 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_32_46000.pt
2023-07-11 01:01:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 19.99) (writing took 5.022421748028137 seconds)
2023-07-11 01:02:57 | INFO | train_inner | epoch 032:    426 / 1474 loss=1.055, trans_loss=5.213, nll_loss=2.478, w2v_ctc_loss=0.31, task_loss=2.922, contrastive_loss=0.493, total=4172.34, n_correct=2759.93, ppl=5.57, accuracy=66.148, wps=4621.9, ups=1.11, wpb=4172.3, bsz=155, num_updates=46100, lr=6.58665e-05, gnorm=0.321, clip=0, loss_scale=32, train_wall=60, gb_free=17.2, wall=34671
2023-07-11 01:03:58 | INFO | train_inner | epoch 032:    526 / 1474 loss=1.064, trans_loss=5.224, nll_loss=2.492, w2v_ctc_loss=0.313, task_loss=2.926, contrastive_loss=0.656, total=4191.15, n_correct=2766.8, ppl=5.63, accuracy=66.015, wps=6837, ups=1.63, wpb=4191.1, bsz=157.5, num_updates=46200, lr=6.57952e-05, gnorm=0.317, clip=0, loss_scale=32, train_wall=61, gb_free=15.3, wall=34732
2023-07-11 01:05:00 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.061, trans_loss=5.232, nll_loss=2.502, w2v_ctc_loss=0.313, task_loss=3.123, contrastive_loss=0.509, total=4138.05, n_correct=2724.37, ppl=5.67, accuracy=65.837, wps=6745.8, ups=1.63, wpb=4138.1, bsz=149.8, num_updates=46300, lr=6.57241e-05, gnorm=0.322, clip=0, loss_scale=32, train_wall=61, gb_free=13.7, wall=34793
2023-07-11 01:06:01 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.058, trans_loss=5.225, nll_loss=2.493, w2v_ctc_loss=0.314, task_loss=3.029, contrastive_loss=0.45, total=4156.23, n_correct=2740.42, ppl=5.63, accuracy=65.935, wps=6822.1, ups=1.64, wpb=4156.2, bsz=151.5, num_updates=46400, lr=6.56532e-05, gnorm=0.311, clip=0, loss_scale=32, train_wall=61, gb_free=16.8, wall=34854
2023-07-11 01:07:01 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.052, trans_loss=5.217, nll_loss=2.483, w2v_ctc_loss=0.307, task_loss=3.111, contrastive_loss=0.445, total=4112.3, n_correct=2715.44, ppl=5.59, accuracy=66.032, wps=6841, ups=1.66, wpb=4112.3, bsz=147, num_updates=46500, lr=6.55826e-05, gnorm=0.316, clip=0, loss_scale=32, train_wall=60, gb_free=16.1, wall=34914
2023-07-11 01:08:02 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.057, trans_loss=5.228, nll_loss=2.497, w2v_ctc_loss=0.31, task_loss=3.101, contrastive_loss=0.454, total=4139.37, n_correct=2725.62, ppl=5.65, accuracy=65.846, wps=6789.3, ups=1.64, wpb=4139.4, bsz=149.3, num_updates=46600, lr=6.55122e-05, gnorm=0.319, clip=0, loss_scale=32, train_wall=61, gb_free=13.2, wall=34975
2023-07-11 01:09:02 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.056, trans_loss=5.225, nll_loss=2.493, w2v_ctc_loss=0.305, task_loss=2.947, contrastive_loss=0.615, total=4121.85, n_correct=2714.36, ppl=5.63, accuracy=65.853, wps=6827.3, ups=1.66, wpb=4121.9, bsz=153, num_updates=46700, lr=6.5442e-05, gnorm=0.313, clip=0, loss_scale=32, train_wall=60, gb_free=17.1, wall=35036
2023-07-11 01:10:03 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.062, trans_loss=5.242, nll_loss=2.513, w2v_ctc_loss=0.313, task_loss=3.566, contrastive_loss=0.499, total=4015.59, n_correct=2633.44, ppl=5.71, accuracy=65.58, wps=6634.8, ups=1.65, wpb=4015.6, bsz=135.1, num_updates=46800, lr=6.5372e-05, gnorm=0.325, clip=0, loss_scale=32, train_wall=60, gb_free=17.4, wall=35096
2023-07-11 01:10:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-11 01:11:04 | INFO | train_inner | epoch 032:   1227 / 1474 loss=1.067, trans_loss=5.242, nll_loss=2.517, w2v_ctc_loss=0.313, task_loss=2.986, contrastive_loss=0.713, total=4142.15, n_correct=2716.91, ppl=5.72, accuracy=65.592, wps=6752, ups=1.63, wpb=4142.1, bsz=153.5, num_updates=46900, lr=6.53023e-05, gnorm=0.338, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=35158
2023-07-11 01:12:04 | INFO | train_inner | epoch 032:   1327 / 1474 loss=1.062, trans_loss=5.234, nll_loss=2.505, w2v_ctc_loss=0.314, task_loss=3.042, contrastive_loss=0.456, total=4079.56, n_correct=2681.59, ppl=5.68, accuracy=65.732, wps=6804.7, ups=1.67, wpb=4079.6, bsz=149, num_updates=47000, lr=6.52328e-05, gnorm=0.338, clip=0, loss_scale=16, train_wall=60, gb_free=17.3, wall=35217
2023-07-11 01:13:04 | INFO | train_inner | epoch 032:   1427 / 1474 loss=1.07, trans_loss=5.244, nll_loss=2.518, w2v_ctc_loss=0.315, task_loss=3.025, contrastive_loss=0.892, total=4107.37, n_correct=2696.04, ppl=5.73, accuracy=65.639, wps=6805.8, ups=1.66, wpb=4107.4, bsz=152.1, num_updates=47100, lr=6.51635e-05, gnorm=0.314, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=35278
2023-07-11 01:13:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 01:13:56 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 1.756 | trans_loss 5.553 | nll_loss 2.815 | w2v_ctc_loss 0.557 | task_loss 3.727 | contrastive_loss 0.575 | total 4003.4 | n_correct 2498.3 | ppl 7.04 | accuracy 62.404 | uer 16.733 | wer 18.609 | raw_wer 18.609 | bleu 20.13 | wps 2277.4 | wpb 4003.4 | bsz 141.8 | num_updates 47147 | best_bleu 20.29
2023-07-11 01:13:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47147 updates
2023-07-11 01:13:56 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1300.pt
2023-07-11 01:14:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1300.pt
2023-07-11 01:14:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1300.pt (epoch 32 @ 47147 updates, score 20.13) (writing took 7.147886569960974 seconds)
2023-07-11 01:14:04 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-11 01:14:04 | INFO | train | epoch 032 | loss 1.059 | trans_loss 5.224 | nll_loss 2.491 | w2v_ctc_loss 0.31 | task_loss 2.995 | contrastive_loss 0.562 | total 4138.02 | n_correct 2728.78 | ppl 5.62 | accuracy 65.944 | wps 6333.2 | ups 1.53 | wpb 4138 | bsz 152.7 | num_updates 47147 | lr 6.5131e-05 | gnorm 0.321 | clip 0 | loss_scale 16 | train_wall 887 | gb_free 16.8 | wall 35337
2023-07-11 01:14:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 01:14:04 | INFO | fairseq.trainer | begin training epoch 33
2023-07-11 01:14:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 01:14:44 | INFO | train_inner | epoch 033:     53 / 1474 loss=1.06, trans_loss=5.221, nll_loss=2.489, w2v_ctc_loss=0.31, task_loss=2.831, contrastive_loss=0.668, total=4146.91, n_correct=2735.91, ppl=5.61, accuracy=65.975, wps=4146.6, ups=1, wpb=4146.9, bsz=159.9, num_updates=47200, lr=6.50945e-05, gnorm=0.321, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=35378
2023-07-11 01:15:44 | INFO | train_inner | epoch 033:    153 / 1474 loss=1.046, trans_loss=5.198, nll_loss=2.455, w2v_ctc_loss=0.302, task_loss=3.215, contrastive_loss=0.401, total=4073.36, n_correct=2699.2, ppl=5.48, accuracy=66.265, wps=6786.9, ups=1.67, wpb=4073.4, bsz=142.6, num_updates=47300, lr=6.50256e-05, gnorm=0.315, clip=0, loss_scale=16, train_wall=60, gb_free=16.9, wall=35438
2023-07-11 01:16:45 | INFO | train_inner | epoch 033:    253 / 1474 loss=1.058, trans_loss=5.206, nll_loss=2.471, w2v_ctc_loss=0.305, task_loss=2.542, contrastive_loss=0.817, total=4283.64, n_correct=2841.89, ppl=5.54, accuracy=66.343, wps=7054.7, ups=1.65, wpb=4283.6, bsz=173.8, num_updates=47400, lr=6.4957e-05, gnorm=0.315, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=35499
2023-07-11 01:17:46 | INFO | train_inner | epoch 033:    353 / 1474 loss=1.061, trans_loss=5.217, nll_loss=2.484, w2v_ctc_loss=0.312, task_loss=3.051, contrastive_loss=0.5, total=4131.27, n_correct=2727.61, ppl=5.59, accuracy=66.024, wps=6787.9, ups=1.64, wpb=4131.3, bsz=151.1, num_updates=47500, lr=6.48886e-05, gnorm=0.324, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=35559
2023-07-11 01:18:45 | INFO | train_inner | epoch 033:    453 / 1474 loss=1.044, trans_loss=5.191, nll_loss=2.449, w2v_ctc_loss=0.302, task_loss=2.846, contrastive_loss=0.43, total=4135.1, n_correct=2745.08, ppl=5.46, accuracy=66.385, wps=6971.1, ups=1.69, wpb=4135.1, bsz=154.8, num_updates=47600, lr=6.48204e-05, gnorm=0.316, clip=0, loss_scale=16, train_wall=59, gb_free=15.8, wall=35619
2023-07-11 01:19:46 | INFO | train_inner | epoch 033:    553 / 1474 loss=1.061, trans_loss=5.219, nll_loss=2.484, w2v_ctc_loss=0.311, task_loss=3.103, contrastive_loss=0.478, total=4132.78, n_correct=2725.34, ppl=5.6, accuracy=65.944, wps=6846, ups=1.66, wpb=4132.8, bsz=147.1, num_updates=47700, lr=6.47524e-05, gnorm=0.323, clip=0, loss_scale=16, train_wall=60, gb_free=17.9, wall=35679
2023-07-11 01:20:46 | INFO | train_inner | epoch 033:    653 / 1474 loss=1.058, trans_loss=5.226, nll_loss=2.494, w2v_ctc_loss=0.309, task_loss=3.082, contrastive_loss=0.537, total=4156.26, n_correct=2737.49, ppl=5.63, accuracy=65.864, wps=6838.7, ups=1.65, wpb=4156.3, bsz=150.4, num_updates=47800, lr=6.46846e-05, gnorm=0.32, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=35740
2023-07-11 01:21:47 | INFO | train_inner | epoch 033:    753 / 1474 loss=1.06, trans_loss=5.228, nll_loss=2.496, w2v_ctc_loss=0.317, task_loss=3.211, contrastive_loss=0.427, total=4074.99, n_correct=2684.19, ppl=5.64, accuracy=65.87, wps=6761.2, ups=1.66, wpb=4075, bsz=144.1, num_updates=47900, lr=6.46171e-05, gnorm=0.328, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=35800
2023-07-11 01:22:47 | INFO | train_inner | epoch 033:    853 / 1474 loss=1.054, trans_loss=5.206, nll_loss=2.47, w2v_ctc_loss=0.302, task_loss=2.868, contrastive_loss=0.579, total=4127.6, n_correct=2736.81, ppl=5.54, accuracy=66.305, wps=6889.7, ups=1.67, wpb=4127.6, bsz=157.7, num_updates=48000, lr=6.45497e-05, gnorm=0.316, clip=0, loss_scale=16, train_wall=59, gb_free=16.4, wall=35860
2023-07-11 01:22:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 01:23:11 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 1.76 | trans_loss 5.557 | nll_loss 2.818 | w2v_ctc_loss 0.57 | task_loss 3.714 | contrastive_loss 0.563 | total 4003.4 | n_correct 2492.5 | ppl 7.05 | accuracy 62.26 | uer 16.869 | wer 18.676 | raw_wer 18.676 | bleu 20.04 | wps 2274.3 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.29
2023-07-11 01:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-11 01:23:11 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_33_48000.pt
2023-07-11 01:23:13 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_33_48000.pt
2023-07-11 01:23:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.04) (writing took 6.233503361989278 seconds)
2023-07-11 01:24:18 | INFO | train_inner | epoch 033:    953 / 1474 loss=1.055, trans_loss=5.219, nll_loss=2.485, w2v_ctc_loss=0.311, task_loss=2.955, contrastive_loss=0.472, total=4157.37, n_correct=2747.5, ppl=5.6, accuracy=66.087, wps=4559.2, ups=1.1, wpb=4157.4, bsz=155, num_updates=48100, lr=6.44826e-05, gnorm=0.319, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=35951
2023-07-11 01:25:19 | INFO | train_inner | epoch 033:   1053 / 1474 loss=1.063, trans_loss=5.225, nll_loss=2.493, w2v_ctc_loss=0.312, task_loss=3.028, contrastive_loss=0.665, total=4134.8, n_correct=2723.74, ppl=5.63, accuracy=65.874, wps=6752.6, ups=1.63, wpb=4134.8, bsz=153, num_updates=48200, lr=6.44157e-05, gnorm=0.326, clip=0, loss_scale=16, train_wall=61, gb_free=15.9, wall=36013
2023-07-11 01:26:21 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.063, trans_loss=5.224, nll_loss=2.493, w2v_ctc_loss=0.308, task_loss=2.971, contrastive_loss=0.646, total=4181.58, n_correct=2755.56, ppl=5.63, accuracy=65.898, wps=6792.8, ups=1.62, wpb=4181.6, bsz=155, num_updates=48300, lr=6.43489e-05, gnorm=0.335, clip=0, loss_scale=16, train_wall=61, gb_free=15.4, wall=36074
2023-07-11 01:27:21 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.06, trans_loss=5.227, nll_loss=2.495, w2v_ctc_loss=0.316, task_loss=3.146, contrastive_loss=0.449, total=4115.76, n_correct=2711.95, ppl=5.64, accuracy=65.892, wps=6790, ups=1.65, wpb=4115.8, bsz=147.3, num_updates=48400, lr=6.42824e-05, gnorm=0.318, clip=0, loss_scale=16, train_wall=60, gb_free=16.9, wall=36135
2023-07-11 01:28:22 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.05, trans_loss=5.22, nll_loss=2.488, w2v_ctc_loss=0.31, task_loss=2.938, contrastive_loss=0.524, total=4120.69, n_correct=2720.54, ppl=5.61, accuracy=66.021, wps=6797.8, ups=1.65, wpb=4120.7, bsz=156, num_updates=48500, lr=6.42161e-05, gnorm=0.323, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=36195
2023-07-11 01:29:22 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.062, trans_loss=5.226, nll_loss=2.496, w2v_ctc_loss=0.308, task_loss=2.976, contrastive_loss=0.774, total=4125.28, n_correct=2720.58, ppl=5.64, accuracy=65.949, wps=6808.2, ups=1.65, wpb=4125.3, bsz=154.3, num_updates=48600, lr=6.415e-05, gnorm=0.325, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=36256
2023-07-11 01:29:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 01:29:59 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 1.759 | trans_loss 5.554 | nll_loss 2.816 | w2v_ctc_loss 0.584 | task_loss 3.736 | contrastive_loss 0.575 | total 4003.4 | n_correct 2497.8 | ppl 7.04 | accuracy 62.392 | uer 16.871 | wer 18.769 | raw_wer 18.769 | bleu 20.67 | wps 2344.1 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.67
2023-07-11 01:29:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-07-11 01:29:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-11 01:30:03 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt
2023-07-11 01:30:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_best.pt (epoch 33 @ 48621 updates, score 20.67) (writing took 8.479171551007312 seconds)
2023-07-11 01:30:07 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-11 01:30:07 | INFO | train | epoch 033 | loss 1.057 | trans_loss 5.216 | nll_loss 2.482 | w2v_ctc_loss 0.309 | task_loss 2.99 | contrastive_loss 0.548 | total 4138.65 | n_correct 2733.86 | ppl 5.59 | accuracy 66.057 | wps 6330.4 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.322 | clip 0 | loss_scale 16 | train_wall 886 | gb_free 18 | wall 36301
2023-07-11 01:30:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 01:30:08 | INFO | fairseq.trainer | begin training epoch 34
2023-07-11 01:30:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 01:31:05 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.049, trans_loss=5.188, nll_loss=2.445, w2v_ctc_loss=0.306, task_loss=2.959, contrastive_loss=0.444, total=4131.47, n_correct=2747.12, ppl=5.44, accuracy=66.493, wps=4044.9, ups=0.98, wpb=4131.5, bsz=150.8, num_updates=48700, lr=6.40841e-05, gnorm=0.327, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=36358
2023-07-11 01:32:05 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.047, trans_loss=5.194, nll_loss=2.452, w2v_ctc_loss=0.307, task_loss=3.13, contrastive_loss=0.452, total=4065.88, n_correct=2701.77, ppl=5.47, accuracy=66.45, wps=6740, ups=1.66, wpb=4065.9, bsz=147.5, num_updates=48800, lr=6.40184e-05, gnorm=0.317, clip=0, loss_scale=16, train_wall=60, gb_free=16.2, wall=36418
2023-07-11 01:33:06 | INFO | train_inner | epoch 034:    279 / 1474 loss=1.067, trans_loss=5.217, nll_loss=2.484, w2v_ctc_loss=0.307, task_loss=2.794, contrastive_loss=0.873, total=4246.3, n_correct=2807.67, ppl=5.59, accuracy=66.12, wps=6961.8, ups=1.64, wpb=4246.3, bsz=164.4, num_updates=48900, lr=6.39529e-05, gnorm=0.316, clip=0, loss_scale=32, train_wall=60, gb_free=17.9, wall=36479
2023-07-11 01:34:07 | INFO | train_inner | epoch 034:    379 / 1474 loss=1.052, trans_loss=5.191, nll_loss=2.45, w2v_ctc_loss=0.303, task_loss=2.84, contrastive_loss=0.637, total=4156.17, n_correct=2765.35, ppl=5.46, accuracy=66.536, wps=6843.4, ups=1.65, wpb=4156.2, bsz=158.4, num_updates=49000, lr=6.38877e-05, gnorm=0.313, clip=0, loss_scale=32, train_wall=60, gb_free=17.9, wall=36540
2023-07-11 01:35:07 | INFO | train_inner | epoch 034:    479 / 1474 loss=1.052, trans_loss=5.207, nll_loss=2.468, w2v_ctc_loss=0.31, task_loss=3.274, contrastive_loss=0.41, total=4070.55, n_correct=2690.08, ppl=5.53, accuracy=66.086, wps=6755.2, ups=1.66, wpb=4070.6, bsz=142.3, num_updates=49100, lr=6.38226e-05, gnorm=0.326, clip=0, loss_scale=32, train_wall=60, gb_free=17.6, wall=36600
2023-07-11 01:36:07 | INFO | train_inner | epoch 034:    579 / 1474 loss=1.048, trans_loss=5.193, nll_loss=2.451, w2v_ctc_loss=0.306, task_loss=3.042, contrastive_loss=0.427, total=4119.38, n_correct=2740.17, ppl=5.47, accuracy=66.519, wps=6845.9, ups=1.66, wpb=4119.4, bsz=150.1, num_updates=49200, lr=6.37577e-05, gnorm=0.315, clip=0, loss_scale=32, train_wall=60, gb_free=13.5, wall=36661
2023-07-11 01:37:08 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.047, trans_loss=5.199, nll_loss=2.46, w2v_ctc_loss=0.305, task_loss=3.041, contrastive_loss=0.403, total=4124.83, n_correct=2739.41, ppl=5.5, accuracy=66.413, wps=6811.1, ups=1.65, wpb=4124.8, bsz=150.1, num_updates=49300, lr=6.3693e-05, gnorm=0.317, clip=0, loss_scale=32, train_wall=60, gb_free=14.6, wall=36721
2023-07-11 01:37:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-11 01:38:08 | INFO | train_inner | epoch 034:    780 / 1474 loss=1.059, trans_loss=5.221, nll_loss=2.488, w2v_ctc_loss=0.305, task_loss=3.106, contrastive_loss=0.543, total=4088.4, n_correct=2699.83, ppl=5.61, accuracy=66.036, wps=6752.7, ups=1.65, wpb=4088.4, bsz=148.3, num_updates=49400, lr=6.36285e-05, gnorm=0.325, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=36782
2023-07-11 01:39:09 | INFO | train_inner | epoch 034:    880 / 1474 loss=1.056, trans_loss=5.218, nll_loss=2.485, w2v_ctc_loss=0.31, task_loss=3.181, contrastive_loss=0.471, total=4088.94, n_correct=2703.83, ppl=5.6, accuracy=66.125, wps=6719.9, ups=1.64, wpb=4088.9, bsz=147.1, num_updates=49500, lr=6.35642e-05, gnorm=0.326, clip=0, loss_scale=16, train_wall=60, gb_free=15.1, wall=36843
2023-07-11 01:40:09 | INFO | train_inner | epoch 034:    980 / 1474 loss=1.053, trans_loss=5.212, nll_loss=2.478, w2v_ctc_loss=0.31, task_loss=2.924, contrastive_loss=0.477, total=4175.9, n_correct=2761.52, ppl=5.57, accuracy=66.13, wps=6910.6, ups=1.65, wpb=4175.9, bsz=156.3, num_updates=49600, lr=6.35001e-05, gnorm=0.32, clip=0, loss_scale=16, train_wall=60, gb_free=14.1, wall=36903
2023-07-11 01:41:09 | INFO | train_inner | epoch 034:   1080 / 1474 loss=1.056, trans_loss=5.217, nll_loss=2.483, w2v_ctc_loss=0.312, task_loss=2.886, contrastive_loss=0.425, total=4152.17, n_correct=2743.1, ppl=5.59, accuracy=66.064, wps=6944.3, ups=1.67, wpb=4152.2, bsz=154.5, num_updates=49700, lr=6.34361e-05, gnorm=0.327, clip=0, loss_scale=16, train_wall=59, gb_free=14.8, wall=36963
2023-07-11 01:42:10 | INFO | train_inner | epoch 034:   1180 / 1474 loss=1.053, trans_loss=5.213, nll_loss=2.478, w2v_ctc_loss=0.307, task_loss=3.07, contrastive_loss=0.455, total=4101.68, n_correct=2710.02, ppl=5.57, accuracy=66.071, wps=6796.1, ups=1.66, wpb=4101.7, bsz=149, num_updates=49800, lr=6.33724e-05, gnorm=0.318, clip=0, loss_scale=16, train_wall=60, gb_free=16.4, wall=37023
2023-07-11 01:43:10 | INFO | train_inner | epoch 034:   1280 / 1474 loss=1.05, trans_loss=5.21, nll_loss=2.475, w2v_ctc_loss=0.306, task_loss=3.019, contrastive_loss=0.409, total=4146.01, n_correct=2739.04, ppl=5.56, accuracy=66.064, wps=6871.1, ups=1.66, wpb=4146, bsz=150.3, num_updates=49900, lr=6.33089e-05, gnorm=0.325, clip=0, loss_scale=16, train_wall=60, gb_free=17.4, wall=37083
2023-07-11 01:44:11 | INFO | train_inner | epoch 034:   1380 / 1474 loss=1.056, trans_loss=5.217, nll_loss=2.483, w2v_ctc_loss=0.311, task_loss=2.85, contrastive_loss=0.567, total=4197.99, n_correct=2774.52, ppl=5.59, accuracy=66.092, wps=6872.5, ups=1.64, wpb=4198, bsz=160.6, num_updates=50000, lr=6.32456e-05, gnorm=0.328, clip=0, loss_scale=16, train_wall=61, gb_free=17.4, wall=37145
2023-07-11 01:44:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 01:44:36 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 1.754 | trans_loss 5.549 | nll_loss 2.813 | w2v_ctc_loss 0.555 | task_loss 3.723 | contrastive_loss 0.565 | total 4003.4 | n_correct 2497.1 | ppl 7.03 | accuracy 62.374 | uer 16.893 | wer 18.877 | raw_wer 18.877 | bleu 20.45 | wps 2222.3 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.67
2023-07-11 01:44:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-11 01:44:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_34_50000.pt
2023-07-11 01:44:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_34_50000.pt
2023-07-11 01:44:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 20.45) (writing took 6.250738012022339 seconds)
tensor(0.0287, device='cuda:0')
tensor(0.0016, device='cuda:0')
2023-07-11 01:45:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0287, device='cuda:6')
tensor(0.0016, device='cuda:6')
tensor(0.0287, device='cuda:1')
tensor(0.0016, device='cuda:1')
tensor(0.0287, device='cuda:3')
tensor(0.0016, device='cuda:3')
tensor(0.0287, device='cuda:7')
tensor(0.0016, device='cuda:7')
tensor(0.0287, device='cuda:4')
tensor(0.0016, device='cuda:4')
tensor(0.0287, device='cuda:2')
tensor(0.0016, device='cuda:2')
tensor(0.0287, device='cuda:5')
tensor(0.0016, device='cuda:5')
2023-07-11 01:46:03 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 1.757 | trans_loss 5.551 | nll_loss 2.818 | w2v_ctc_loss 0.553 | task_loss 3.709 | contrastive_loss 0.568 | total 4003.4 | n_correct 2496.7 | ppl 7.05 | accuracy 62.364 | uer 16.938 | wer 18.724 | raw_wer 18.724 | bleu 20.25 | wps 2281.7 | wpb 4003.4 | bsz 141.8 | num_updates 50094 | best_bleu 20.67
2023-07-11 01:46:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50094 updates
2023-07-11 01:46:03 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2503.pt
2023-07-11 01:46:05 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2503.pt
2023-07-11 01:46:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.2503.pt (epoch 34 @ 50094 updates, score 20.25) (writing took 5.274060573021416 seconds)
2023-07-11 01:46:09 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-11 01:46:09 | INFO | train | epoch 034 | loss 1.054 | trans_loss 5.208 | nll_loss 2.471 | w2v_ctc_loss 0.307 | task_loss 2.989 | contrastive_loss 0.528 | total 4138.87 | n_correct 2740.44 | ppl 5.55 | accuracy 66.212 | wps 6341.7 | ups 1.53 | wpb 4138.9 | bsz 152.9 | num_updates 50094 | lr 6.31862e-05 | gnorm 0.323 | clip 0 | loss_scale 16 | train_wall 884 | gb_free 17.5 | wall 37262
2023-07-11 01:46:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 01:46:09 | INFO | fairseq.trainer | begin training epoch 35
2023-07-11 01:46:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 01:46:21 | INFO | train_inner | epoch 035:      6 / 1474 loss=1.061, trans_loss=5.218, nll_loss=2.486, w2v_ctc_loss=0.307, task_loss=2.774, contrastive_loss=0.83, total=4206.43, n_correct=2776.76, ppl=5.6, accuracy=66.012, wps=3239.1, ups=0.77, wpb=4206.4, bsz=162.4, num_updates=50100, lr=6.31824e-05, gnorm=0.345, clip=0, loss_scale=16, train_wall=60, gb_free=17.9, wall=37274
2023-07-11 01:47:22 | INFO | train_inner | epoch 035:    106 / 1474 loss=1.051, trans_loss=5.191, nll_loss=2.449, w2v_ctc_loss=0.303, task_loss=2.879, contrastive_loss=0.697, total=4171.34, n_correct=2770.72, ppl=5.46, accuracy=66.423, wps=6880.5, ups=1.65, wpb=4171.3, bsz=156.8, num_updates=50200, lr=6.31194e-05, gnorm=0.317, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=37335
2023-07-11 01:48:22 | INFO | train_inner | epoch 035:    206 / 1474 loss=1.04, trans_loss=5.179, nll_loss=2.435, w2v_ctc_loss=0.298, task_loss=2.825, contrastive_loss=0.429, total=4167.37, n_correct=2781.09, ppl=5.41, accuracy=66.735, wps=6899.9, ups=1.66, wpb=4167.4, bsz=158, num_updates=50300, lr=6.30567e-05, gnorm=0.323, clip=0, loss_scale=16, train_wall=60, gb_free=13.9, wall=37395
2023-07-11 01:49:24 | INFO | train_inner | epoch 035:    306 / 1474 loss=1.051, trans_loss=5.196, nll_loss=2.455, w2v_ctc_loss=0.305, task_loss=3.123, contrastive_loss=0.731, total=4114.35, n_correct=2732.03, ppl=5.48, accuracy=66.402, wps=6616.3, ups=1.61, wpb=4114.4, bsz=150, num_updates=50400, lr=6.29941e-05, gnorm=0.335, clip=0, loss_scale=16, train_wall=62, gb_free=12.8, wall=37458
2023-07-11 01:50:25 | INFO | train_inner | epoch 035:    406 / 1474 loss=1.052, trans_loss=5.2, nll_loss=2.46, w2v_ctc_loss=0.312, task_loss=3.32, contrastive_loss=0.418, total=4069.11, n_correct=2698.63, ppl=5.5, accuracy=66.32, wps=6728.3, ups=1.65, wpb=4069.1, bsz=141.8, num_updates=50500, lr=6.29317e-05, gnorm=0.324, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=37518
2023-07-11 01:51:26 | INFO | train_inner | epoch 035:    506 / 1474 loss=1.052, trans_loss=5.198, nll_loss=2.458, w2v_ctc_loss=0.303, task_loss=3.036, contrastive_loss=0.583, total=4158.81, n_correct=2761.56, ppl=5.49, accuracy=66.403, wps=6783.3, ups=1.63, wpb=4158.8, bsz=152.5, num_updates=50600, lr=6.28695e-05, gnorm=0.331, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=37579
2023-07-11 01:52:26 | INFO | train_inner | epoch 035:    606 / 1474 loss=1.046, trans_loss=5.189, nll_loss=2.447, w2v_ctc_loss=0.299, task_loss=2.959, contrastive_loss=0.588, total=4167.77, n_correct=2772.72, ppl=5.45, accuracy=66.528, wps=6940.2, ups=1.67, wpb=4167.8, bsz=154.8, num_updates=50700, lr=6.28074e-05, gnorm=0.319, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=37640
2023-07-11 01:53:26 | INFO | train_inner | epoch 035:    706 / 1474 loss=1.055, trans_loss=5.206, nll_loss=2.469, w2v_ctc_loss=0.314, task_loss=3.133, contrastive_loss=0.458, total=4084.16, n_correct=2707.86, ppl=5.54, accuracy=66.302, wps=6754.9, ups=1.65, wpb=4084.2, bsz=147.4, num_updates=50800, lr=6.27456e-05, gnorm=0.34, clip=0, loss_scale=16, train_wall=60, gb_free=17.2, wall=37700
2023-07-11 01:54:27 | INFO | train_inner | epoch 035:    806 / 1474 loss=1.049, trans_loss=5.198, nll_loss=2.459, w2v_ctc_loss=0.308, task_loss=2.939, contrastive_loss=0.482, total=4151.07, n_correct=2754.19, ppl=5.5, accuracy=66.349, wps=6843.7, ups=1.65, wpb=4151.1, bsz=155.8, num_updates=50900, lr=6.26839e-05, gnorm=0.317, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=37761
2023-07-11 01:55:28 | INFO | train_inner | epoch 035:    906 / 1474 loss=1.052, trans_loss=5.205, nll_loss=2.467, w2v_ctc_loss=0.312, task_loss=3.164, contrastive_loss=0.423, total=4097.72, n_correct=2712.37, ppl=5.53, accuracy=66.192, wps=6711.2, ups=1.64, wpb=4097.7, bsz=146.5, num_updates=51000, lr=6.26224e-05, gnorm=0.331, clip=0, loss_scale=16, train_wall=61, gb_free=16.2, wall=37822
2023-07-11 01:56:29 | INFO | train_inner | epoch 035:   1006 / 1474 loss=1.059, trans_loss=5.206, nll_loss=2.47, w2v_ctc_loss=0.305, task_loss=3.03, contrastive_loss=0.682, total=4141.74, n_correct=2741.94, ppl=5.54, accuracy=66.203, wps=6769.4, ups=1.63, wpb=4141.7, bsz=153.1, num_updates=51100, lr=6.25611e-05, gnorm=0.324, clip=0, loss_scale=16, train_wall=61, gb_free=17.7, wall=37883
2023-07-11 01:57:30 | INFO | train_inner | epoch 035:   1106 / 1474 loss=1.054, trans_loss=5.207, nll_loss=2.471, w2v_ctc_loss=0.309, task_loss=2.853, contrastive_loss=0.446, total=4182.91, n_correct=2774.24, ppl=5.54, accuracy=66.323, wps=6925.4, ups=1.66, wpb=4182.9, bsz=155.7, num_updates=51200, lr=6.25e-05, gnorm=0.332, clip=0, loss_scale=16, train_wall=60, gb_free=10.7, wall=37943
2023-07-11 01:58:30 | INFO | train_inner | epoch 035:   1206 / 1474 loss=1.059, trans_loss=5.205, nll_loss=2.469, w2v_ctc_loss=0.307, task_loss=2.76, contrastive_loss=0.56, total=4207.87, n_correct=2788.18, ppl=5.54, accuracy=66.261, wps=7000.9, ups=1.66, wpb=4207.9, bsz=160.2, num_updates=51300, lr=6.24391e-05, gnorm=0.332, clip=0, loss_scale=16, train_wall=60, gb_free=15.1, wall=38003
2023-07-11 01:59:31 | INFO | train_inner | epoch 035:   1306 / 1474 loss=1.049, trans_loss=5.201, nll_loss=2.465, w2v_ctc_loss=0.305, task_loss=2.856, contrastive_loss=0.463, total=4141.67, n_correct=2744.44, ppl=5.52, accuracy=66.264, wps=6817.4, ups=1.65, wpb=4141.7, bsz=157, num_updates=51400, lr=6.23783e-05, gnorm=0.342, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=38064
2023-07-11 02:00:31 | INFO | train_inner | epoch 035:   1406 / 1474 loss=1.052, trans_loss=5.213, nll_loss=2.478, w2v_ctc_loss=0.308, task_loss=3.269, contrastive_loss=0.411, total=4057.93, n_correct=2681.6, ppl=5.57, accuracy=66.083, wps=6728.5, ups=1.66, wpb=4057.9, bsz=142.8, num_updates=51500, lr=6.23177e-05, gnorm=0.326, clip=0, loss_scale=32, train_wall=60, gb_free=15.6, wall=38124
2023-07-11 02:01:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 02:01:36 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 1.753 | trans_loss 5.545 | nll_loss 2.804 | w2v_ctc_loss 0.557 | task_loss 3.718 | contrastive_loss 0.549 | total 4003.4 | n_correct 2496.6 | ppl 6.99 | accuracy 62.362 | uer 16.829 | wer 18.541 | raw_wer 18.541 | bleu 20.01 | wps 2332.3 | wpb 4003.4 | bsz 141.8 | num_updates 51568 | best_bleu 20.67
2023-07-11 02:01:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51568 updates
2023-07-11 02:01:36 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-11 02:01:40 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-11 02:01:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt (epoch 35 @ 51568 updates, score 20.01) (writing took 4.210651963017881 seconds)
2023-07-11 02:01:40 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-11 02:01:40 | INFO | train | epoch 035 | loss 1.052 | trans_loss 5.2 | nll_loss 2.461 | w2v_ctc_loss 0.306 | task_loss 2.99 | contrastive_loss 0.53 | total 4138.65 | n_correct 2745.62 | ppl 5.51 | accuracy 66.341 | wps 6548.3 | ups 1.58 | wpb 4138.6 | bsz 152.8 | num_updates 51568 | lr 6.22766e-05 | gnorm 0.328 | clip 0 | loss_scale 32 | train_wall 888 | gb_free 17.4 | wall 38194
2023-07-11 02:01:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 02:01:41 | INFO | fairseq.trainer | begin training epoch 36
2023-07-11 02:01:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 02:02:08 | INFO | train_inner | epoch 036:     32 / 1474 loss=1.053, trans_loss=5.194, nll_loss=2.455, w2v_ctc_loss=0.305, task_loss=2.899, contrastive_loss=0.514, total=4128.66, n_correct=2742.04, ppl=5.48, accuracy=66.415, wps=4272.1, ups=1.03, wpb=4128.7, bsz=154.5, num_updates=51600, lr=6.22573e-05, gnorm=0.331, clip=0, loss_scale=32, train_wall=60, gb_free=16.5, wall=38221
2023-07-11 02:03:09 | INFO | train_inner | epoch 036:    132 / 1474 loss=1.046, trans_loss=5.18, nll_loss=2.435, w2v_ctc_loss=0.304, task_loss=3.12, contrastive_loss=0.449, total=4101.15, n_correct=2733.35, ppl=5.41, accuracy=66.648, wps=6706.1, ups=1.64, wpb=4101.1, bsz=149.4, num_updates=51700, lr=6.2197e-05, gnorm=0.329, clip=0, loss_scale=32, train_wall=61, gb_free=16.7, wall=38282
2023-07-11 02:04:10 | INFO | train_inner | epoch 036:    232 / 1474 loss=1.049, trans_loss=5.179, nll_loss=2.434, w2v_ctc_loss=0.302, task_loss=3.027, contrastive_loss=0.472, total=4153.27, n_correct=2770.56, ppl=5.4, accuracy=66.708, wps=6815.2, ups=1.64, wpb=4153.3, bsz=151.8, num_updates=51800, lr=6.2137e-05, gnorm=0.331, clip=0, loss_scale=32, train_wall=60, gb_free=17, wall=38343
2023-07-11 02:05:09 | INFO | train_inner | epoch 036:    332 / 1474 loss=1.041, trans_loss=5.177, nll_loss=2.431, w2v_ctc_loss=0.297, task_loss=2.844, contrastive_loss=0.415, total=4162.11, n_correct=2778.07, ppl=5.39, accuracy=66.747, wps=6971.6, ups=1.68, wpb=4162.1, bsz=155.1, num_updates=51900, lr=6.20771e-05, gnorm=0.317, clip=0, loss_scale=32, train_wall=59, gb_free=16.9, wall=38403
2023-07-11 02:06:10 | INFO | train_inner | epoch 036:    432 / 1474 loss=1.051, trans_loss=5.179, nll_loss=2.436, w2v_ctc_loss=0.299, task_loss=2.622, contrastive_loss=0.677, total=4234.05, n_correct=2823.87, ppl=5.41, accuracy=66.694, wps=6937.9, ups=1.64, wpb=4234.1, bsz=166.6, num_updates=52000, lr=6.20174e-05, gnorm=0.333, clip=0, loss_scale=32, train_wall=61, gb_free=16.3, wall=38464
2023-07-11 02:06:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 02:06:35 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 1.765 | trans_loss 5.556 | nll_loss 2.821 | w2v_ctc_loss 0.567 | task_loss 3.697 | contrastive_loss 0.567 | total 4003.4 | n_correct 2493.1 | ppl 7.07 | accuracy 62.275 | uer 16.972 | wer 18.829 | raw_wer 18.829 | bleu 20.19 | wps 2154.1 | wpb 4003.4 | bsz 141.8 | num_updates 52000 | best_bleu 20.67
2023-07-11 02:06:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-11 02:06:35 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_36_52000.pt
2023-07-11 02:06:38 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_36_52000.pt
2023-07-11 02:06:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 20.19) (writing took 6.2159395850030705 seconds)
2023-07-11 02:07:44 | INFO | train_inner | epoch 036:    532 / 1474 loss=1.058, trans_loss=5.196, nll_loss=2.457, w2v_ctc_loss=0.301, task_loss=2.98, contrastive_loss=0.917, total=4149.22, n_correct=2755.57, ppl=5.49, accuracy=66.412, wps=4455.7, ups=1.07, wpb=4149.2, bsz=156.2, num_updates=52100, lr=6.19578e-05, gnorm=0.328, clip=0, loss_scale=32, train_wall=61, gb_free=17.9, wall=38557
2023-07-11 02:08:44 | INFO | train_inner | epoch 036:    632 / 1474 loss=1.045, trans_loss=5.175, nll_loss=2.428, w2v_ctc_loss=0.301, task_loss=2.882, contrastive_loss=0.58, total=4179.05, n_correct=2788.04, ppl=5.38, accuracy=66.715, wps=6927.4, ups=1.66, wpb=4179.1, bsz=158.4, num_updates=52200, lr=6.18984e-05, gnorm=0.309, clip=0, loss_scale=32, train_wall=60, gb_free=17.3, wall=38617
2023-07-11 02:09:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-11 02:09:46 | INFO | train_inner | epoch 036:    733 / 1474 loss=1.054, trans_loss=5.199, nll_loss=2.461, w2v_ctc_loss=0.309, task_loss=2.887, contrastive_loss=0.453, total=4181.12, n_correct=2773.2, ppl=5.5, accuracy=66.327, wps=6767.2, ups=1.62, wpb=4181.1, bsz=157.9, num_updates=52300, lr=6.18392e-05, gnorm=0.328, clip=0, loss_scale=16, train_wall=61, gb_free=16.7, wall=38679
2023-07-11 02:10:46 | INFO | train_inner | epoch 036:    833 / 1474 loss=1.062, trans_loss=5.214, nll_loss=2.481, w2v_ctc_loss=0.306, task_loss=2.792, contrastive_loss=0.799, total=4183.16, n_correct=2767.72, ppl=5.58, accuracy=66.163, wps=6914.1, ups=1.65, wpb=4183.2, bsz=161.7, num_updates=52400, lr=6.17802e-05, gnorm=0.323, clip=0, loss_scale=16, train_wall=60, gb_free=15.2, wall=38740
2023-07-11 02:11:47 | INFO | train_inner | epoch 036:    933 / 1474 loss=1.046, trans_loss=5.187, nll_loss=2.445, w2v_ctc_loss=0.305, task_loss=3.045, contrastive_loss=0.406, total=4164.3, n_correct=2770.16, ppl=5.45, accuracy=66.522, wps=6864.8, ups=1.65, wpb=4164.3, bsz=151.4, num_updates=52500, lr=6.17213e-05, gnorm=0.344, clip=0, loss_scale=16, train_wall=60, gb_free=17.3, wall=38800
2023-07-11 02:12:48 | INFO | train_inner | epoch 036:   1033 / 1474 loss=1.05, trans_loss=5.194, nll_loss=2.454, w2v_ctc_loss=0.305, task_loss=3.06, contrastive_loss=0.403, total=4190.15, n_correct=2785.08, ppl=5.48, accuracy=66.467, wps=6899.8, ups=1.65, wpb=4190.1, bsz=151.7, num_updates=52600, lr=6.16626e-05, gnorm=0.315, clip=0, loss_scale=16, train_wall=60, gb_free=12.9, wall=38861
2023-07-11 02:13:48 | INFO | train_inner | epoch 036:   1133 / 1474 loss=1.047, trans_loss=5.19, nll_loss=2.448, w2v_ctc_loss=0.306, task_loss=3.011, contrastive_loss=0.453, total=4122.99, n_correct=2738.53, ppl=5.46, accuracy=66.421, wps=6848, ups=1.66, wpb=4123, bsz=152.4, num_updates=52700, lr=6.16041e-05, gnorm=0.322, clip=0, loss_scale=16, train_wall=60, gb_free=16.9, wall=38921
2023-07-11 02:14:48 | INFO | train_inner | epoch 036:   1233 / 1474 loss=1.046, trans_loss=5.196, nll_loss=2.455, w2v_ctc_loss=0.308, task_loss=3.319, contrastive_loss=0.376, total=4050.06, n_correct=2690.41, ppl=5.48, accuracy=66.429, wps=6717, ups=1.66, wpb=4050.1, bsz=140, num_updates=52800, lr=6.15457e-05, gnorm=0.329, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=38982
2023-07-11 02:15:48 | INFO | train_inner | epoch 036:   1333 / 1474 loss=1.045, trans_loss=5.193, nll_loss=2.453, w2v_ctc_loss=0.302, task_loss=2.975, contrastive_loss=0.434, total=4110.28, n_correct=2730.24, ppl=5.47, accuracy=66.425, wps=6813.2, ups=1.66, wpb=4110.3, bsz=153.2, num_updates=52900, lr=6.14875e-05, gnorm=0.318, clip=0, loss_scale=16, train_wall=60, gb_free=16.6, wall=39042
2023-07-11 02:16:49 | INFO | train_inner | epoch 036:   1433 / 1474 loss=1.056, trans_loss=5.211, nll_loss=2.475, w2v_ctc_loss=0.311, task_loss=3.396, contrastive_loss=0.514, total=4043.82, n_correct=2673.47, ppl=5.56, accuracy=66.112, wps=6648.7, ups=1.64, wpb=4043.8, bsz=138.5, num_updates=53000, lr=6.14295e-05, gnorm=0.324, clip=0, loss_scale=16, train_wall=60, gb_free=17.5, wall=39103
2023-07-11 02:17:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-11 02:17:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 02:17:38 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 1.759 | trans_loss 5.551 | nll_loss 2.816 | w2v_ctc_loss 0.584 | task_loss 3.729 | contrastive_loss 0.568 | total 4003.4 | n_correct 2492 | ppl 7.04 | accuracy 62.247 | uer 17.121 | wer 18.94 | raw_wer 18.94 | bleu 20.15 | wps 2171.2 | wpb 4003.4 | bsz 141.8 | num_updates 53040 | best_bleu 20.67
2023-07-11 02:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53040 updates
2023-07-11 02:17:38 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1504.pt
2023-07-11 02:17:41 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1504.pt
2023-07-11 02:17:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.1504.pt (epoch 36 @ 53040 updates, score 20.15) (writing took 5.430841274035629 seconds)
2023-07-11 02:17:44 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-11 02:17:44 | INFO | train | epoch 036 | loss 1.05 | trans_loss 5.19 | nll_loss 2.449 | w2v_ctc_loss 0.304 | task_loss 2.99 | contrastive_loss 0.523 | total 4138.27 | n_correct 2751.52 | ppl 5.46 | accuracy 66.49 | wps 6321.6 | ups 1.53 | wpb 4138.3 | bsz 152.8 | num_updates 53040 | lr 6.14063e-05 | gnorm 0.325 | clip 0 | loss_scale 8 | train_wall 886 | gb_free 17 | wall 39157
2023-07-11 02:17:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 02:17:44 | INFO | fairseq.trainer | begin training epoch 37
2023-07-11 02:17:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 02:18:29 | INFO | train_inner | epoch 037:     60 / 1474 loss=1.042, trans_loss=5.172, nll_loss=2.425, w2v_ctc_loss=0.301, task_loss=3.031, contrastive_loss=0.428, total=4088.31, n_correct=2731.83, ppl=5.37, accuracy=66.821, wps=4085.5, ups=1, wpb=4088.3, bsz=149.1, num_updates=53100, lr=6.13716e-05, gnorm=0.323, clip=0, loss_scale=8, train_wall=60, gb_free=10.7, wall=39203
2023-07-11 02:19:30 | INFO | train_inner | epoch 037:    160 / 1474 loss=1.048, trans_loss=5.178, nll_loss=2.432, w2v_ctc_loss=0.3, task_loss=3.048, contrastive_loss=0.561, total=4127.23, n_correct=2756.07, ppl=5.4, accuracy=66.778, wps=6802.9, ups=1.65, wpb=4127.2, bsz=153.3, num_updates=53200, lr=6.13139e-05, gnorm=0.321, clip=0, loss_scale=8, train_wall=60, gb_free=13.5, wall=39264
2023-07-11 02:20:30 | INFO | train_inner | epoch 037:    260 / 1474 loss=1.036, trans_loss=5.161, nll_loss=2.411, w2v_ctc_loss=0.291, task_loss=2.749, contrastive_loss=0.448, total=4201.31, n_correct=2813.66, ppl=5.32, accuracy=66.971, wps=6992.2, ups=1.66, wpb=4201.3, bsz=161.6, num_updates=53300, lr=6.12564e-05, gnorm=0.339, clip=0, loss_scale=8, train_wall=60, gb_free=16.7, wall=39324
2023-07-11 02:21:31 | INFO | train_inner | epoch 037:    360 / 1474 loss=1.047, trans_loss=5.17, nll_loss=2.422, w2v_ctc_loss=0.303, task_loss=3.008, contrastive_loss=0.449, total=4168.69, n_correct=2788.01, ppl=5.36, accuracy=66.88, wps=6885.2, ups=1.65, wpb=4168.7, bsz=153.3, num_updates=53400, lr=6.1199e-05, gnorm=0.311, clip=0, loss_scale=8, train_wall=60, gb_free=16.3, wall=39384
2023-07-11 02:22:33 | INFO | train_inner | epoch 037:    460 / 1474 loss=1.059, trans_loss=5.197, nll_loss=2.457, w2v_ctc_loss=0.301, task_loss=2.923, contrastive_loss=0.863, total=4167.04, n_correct=2766.24, ppl=5.49, accuracy=66.384, wps=6704.5, ups=1.61, wpb=4167, bsz=157.1, num_updates=53500, lr=6.11418e-05, gnorm=0.326, clip=0, loss_scale=8, train_wall=62, gb_free=16.6, wall=39446
2023-07-11 02:23:33 | INFO | train_inner | epoch 037:    560 / 1474 loss=1.04, trans_loss=5.178, nll_loss=2.432, w2v_ctc_loss=0.302, task_loss=3.088, contrastive_loss=0.424, total=4097.13, n_correct=2733.96, ppl=5.4, accuracy=66.729, wps=6767.3, ups=1.65, wpb=4097.1, bsz=150.3, num_updates=53600, lr=6.10847e-05, gnorm=0.319, clip=0, loss_scale=8, train_wall=60, gb_free=16.6, wall=39507
2023-07-11 02:24:34 | INFO | train_inner | epoch 037:    660 / 1474 loss=1.049, trans_loss=5.187, nll_loss=2.445, w2v_ctc_loss=0.309, task_loss=3.141, contrastive_loss=0.435, total=4099.41, n_correct=2725.03, ppl=5.45, accuracy=66.474, wps=6763.6, ups=1.65, wpb=4099.4, bsz=145.5, num_updates=53700, lr=6.10278e-05, gnorm=0.321, clip=0, loss_scale=8, train_wall=60, gb_free=16.8, wall=39567
2023-07-11 02:25:34 | INFO | train_inner | epoch 037:    760 / 1474 loss=1.045, trans_loss=5.173, nll_loss=2.427, w2v_ctc_loss=0.298, task_loss=2.962, contrastive_loss=0.544, total=4124.83, n_correct=2752.79, ppl=5.38, accuracy=66.737, wps=6843.6, ups=1.66, wpb=4124.8, bsz=153, num_updates=53800, lr=6.09711e-05, gnorm=0.321, clip=0, loss_scale=8, train_wall=60, gb_free=16.4, wall=39628
2023-07-11 02:26:34 | INFO | train_inner | epoch 037:    860 / 1474 loss=1.044, trans_loss=5.176, nll_loss=2.431, w2v_ctc_loss=0.298, task_loss=2.817, contrastive_loss=0.433, total=4155.6, n_correct=2772.98, ppl=5.39, accuracy=66.729, wps=6923.2, ups=1.67, wpb=4155.6, bsz=157.6, num_updates=53900, lr=6.09145e-05, gnorm=0.323, clip=0, loss_scale=8, train_wall=60, gb_free=16.7, wall=39688
2023-07-11 02:27:35 | INFO | train_inner | epoch 037:    960 / 1474 loss=1.05, trans_loss=5.194, nll_loss=2.453, w2v_ctc_loss=0.307, task_loss=3.182, contrastive_loss=0.435, total=4096.58, n_correct=2722.55, ppl=5.47, accuracy=66.459, wps=6766.6, ups=1.65, wpb=4096.6, bsz=145.9, num_updates=54000, lr=6.08581e-05, gnorm=0.331, clip=0, loss_scale=8, train_wall=60, gb_free=16.5, wall=39748
2023-07-11 02:27:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 02:27:59 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 1.762 | trans_loss 5.551 | nll_loss 2.816 | w2v_ctc_loss 0.563 | task_loss 3.7 | contrastive_loss 0.568 | total 4003.4 | n_correct 2497.6 | ppl 7.04 | accuracy 62.387 | uer 16.643 | wer 18.512 | raw_wer 18.512 | bleu 20.06 | wps 2340 | wpb 4003.4 | bsz 141.8 | num_updates 54000 | best_bleu 20.67
2023-07-11 02:27:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-11 02:27:59 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_37_54000.pt
2023-07-11 02:28:01 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_37_54000.pt
2023-07-11 02:28:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 20.06) (writing took 5.4206458639819175 seconds)
2023-07-11 02:29:06 | INFO | train_inner | epoch 037:   1060 / 1474 loss=1.051, trans_loss=5.184, nll_loss=2.442, w2v_ctc_loss=0.3, task_loss=2.77, contrastive_loss=0.706, total=4173.33, n_correct=2781.96, ppl=5.43, accuracy=66.66, wps=4584.7, ups=1.1, wpb=4173.3, bsz=161.3, num_updates=54100, lr=6.08018e-05, gnorm=0.339, clip=0, loss_scale=8, train_wall=61, gb_free=15.7, wall=39839
2023-07-11 02:30:07 | INFO | train_inner | epoch 037:   1160 / 1474 loss=1.054, trans_loss=5.192, nll_loss=2.451, w2v_ctc_loss=0.302, task_loss=2.909, contrastive_loss=0.733, total=4174.23, n_correct=2774.67, ppl=5.47, accuracy=66.471, wps=6851.8, ups=1.64, wpb=4174.2, bsz=155, num_updates=54200, lr=6.07457e-05, gnorm=0.321, clip=0, loss_scale=8, train_wall=60, gb_free=16.8, wall=39900
2023-07-11 02:31:08 | INFO | train_inner | epoch 037:   1260 / 1474 loss=1.046, trans_loss=5.185, nll_loss=2.443, w2v_ctc_loss=0.301, task_loss=2.883, contrastive_loss=0.45, total=4174.81, n_correct=2781.13, ppl=5.44, accuracy=66.617, wps=6846.2, ups=1.64, wpb=4174.8, bsz=156.9, num_updates=54300, lr=6.06897e-05, gnorm=0.333, clip=0, loss_scale=8, train_wall=60, gb_free=15.5, wall=39961
2023-07-11 02:32:08 | INFO | train_inner | epoch 037:   1360 / 1474 loss=1.055, trans_loss=5.201, nll_loss=2.462, w2v_ctc_loss=0.315, task_loss=3.29, contrastive_loss=0.414, total=4061.55, n_correct=2690.25, ppl=5.51, accuracy=66.237, wps=6704.7, ups=1.65, wpb=4061.6, bsz=142.3, num_updates=54400, lr=6.06339e-05, gnorm=0.33, clip=0, loss_scale=8, train_wall=60, gb_free=13.9, wall=40022
2023-07-11 02:33:08 | INFO | train_inner | epoch 037:   1460 / 1474 loss=1.049, trans_loss=5.192, nll_loss=2.451, w2v_ctc_loss=0.303, task_loss=2.985, contrastive_loss=0.485, total=4157.45, n_correct=2760.79, ppl=5.47, accuracy=66.406, wps=6903.6, ups=1.66, wpb=4157.4, bsz=152, num_updates=54500, lr=6.05783e-05, gnorm=0.316, clip=0, loss_scale=8, train_wall=60, gb_free=16.2, wall=40082
2023-07-11 02:33:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 02:33:40 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 1.755 | trans_loss 5.551 | nll_loss 2.812 | w2v_ctc_loss 0.569 | task_loss 3.723 | contrastive_loss 0.556 | total 4003.4 | n_correct 2500.8 | ppl 7.02 | accuracy 62.467 | uer 16.704 | wer 18.668 | raw_wer 18.668 | bleu 19.96 | wps 2410.4 | wpb 4003.4 | bsz 141.8 | num_updates 54514 | best_bleu 20.67
2023-07-11 02:33:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54514 updates
2023-07-11 02:33:40 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-11 02:33:44 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-11 02:33:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt (epoch 37 @ 54514 updates, score 19.96) (writing took 4.131404674029909 seconds)
2023-07-11 02:33:44 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-11 02:33:44 | INFO | train | epoch 037 | loss 1.048 | trans_loss 5.183 | nll_loss 2.439 | w2v_ctc_loss 0.302 | task_loss 2.988 | contrastive_loss 0.525 | total 4138.65 | n_correct 2757.29 | ppl 5.42 | accuracy 66.623 | wps 6350.9 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 54514 | lr 6.05705e-05 | gnorm 0.325 | clip 0 | loss_scale 8 | train_wall 887 | gb_free 13.3 | wall 40118
2023-07-11 02:33:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 02:33:45 | INFO | fairseq.trainer | begin training epoch 38
2023-07-11 02:33:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 02:34:46 | INFO | train_inner | epoch 038:     86 / 1474 loss=1.042, trans_loss=5.161, nll_loss=2.41, w2v_ctc_loss=0.299, task_loss=3.083, contrastive_loss=0.401, total=4088.75, n_correct=2737.92, ppl=5.31, accuracy=66.962, wps=4206.7, ups=1.03, wpb=4088.8, bsz=148.2, num_updates=54600, lr=6.05228e-05, gnorm=0.324, clip=0, loss_scale=8, train_wall=60, gb_free=13.4, wall=40179
2023-07-11 02:35:47 | INFO | train_inner | epoch 038:    186 / 1474 loss=1.038, trans_loss=5.167, nll_loss=2.418, w2v_ctc_loss=0.3, task_loss=3.174, contrastive_loss=0.384, total=4076.35, n_correct=2726.26, ppl=5.34, accuracy=66.88, wps=6701.8, ups=1.64, wpb=4076.3, bsz=145.1, num_updates=54700, lr=6.04674e-05, gnorm=0.33, clip=0, loss_scale=8, train_wall=60, gb_free=17.1, wall=40240
2023-07-11 02:36:47 | INFO | train_inner | epoch 038:    286 / 1474 loss=1.043, trans_loss=5.174, nll_loss=2.428, w2v_ctc_loss=0.301, task_loss=3.106, contrastive_loss=0.437, total=4075.3, n_correct=2725.04, ppl=5.38, accuracy=66.867, wps=6749.8, ups=1.66, wpb=4075.3, bsz=148, num_updates=54800, lr=6.04122e-05, gnorm=0.325, clip=0, loss_scale=8, train_wall=60, gb_free=16.9, wall=40300
2023-07-11 02:37:47 | INFO | train_inner | epoch 038:    386 / 1474 loss=1.043, trans_loss=5.171, nll_loss=2.423, w2v_ctc_loss=0.302, task_loss=2.968, contrastive_loss=0.457, total=4170.21, n_correct=2788.4, ppl=5.36, accuracy=66.865, wps=6915, ups=1.66, wpb=4170.2, bsz=153.6, num_updates=54900, lr=6.03572e-05, gnorm=0.332, clip=0, loss_scale=8, train_wall=60, gb_free=13.2, wall=40361
2023-07-11 02:38:47 | INFO | train_inner | epoch 038:    486 / 1474 loss=1.038, trans_loss=5.162, nll_loss=2.412, w2v_ctc_loss=0.296, task_loss=2.877, contrastive_loss=0.451, total=4194, n_correct=2810.04, ppl=5.32, accuracy=67.001, wps=6967, ups=1.66, wpb=4194, bsz=156.5, num_updates=55000, lr=6.03023e-05, gnorm=0.318, clip=0, loss_scale=8, train_wall=60, gb_free=16.3, wall=40421
tensor(0.0287, device='cuda:0')
tensor(0.0016, device='cuda:0')
2023-07-11 02:39:49 | INFO | train_inner | epoch 038:    586 / 1474 loss=1.053, trans_loss=5.19, nll_loss=2.449, w2v_ctc_loss=0.301, task_loss=2.995, contrastive_loss=0.759, total=4172.06, n_correct=2771.08, ppl=5.46, accuracy=66.42, wps=6776.8, ups=1.62, wpb=4172.1, bsz=154.2, num_updates=55100, lr=6.02475e-05, gnorm=0.329, clip=0, loss_scale=16, train_wall=61, gb_free=15.2, wall=40483
2023-07-11 02:40:50 | INFO | train_inner | epoch 038:    686 / 1474 loss=1.044, trans_loss=5.168, nll_loss=2.42, w2v_ctc_loss=0.296, task_loss=2.828, contrastive_loss=0.74, total=4173.18, n_correct=2788.28, ppl=5.35, accuracy=66.814, wps=6809.2, ups=1.63, wpb=4173.2, bsz=160.9, num_updates=55200, lr=6.01929e-05, gnorm=0.321, clip=0, loss_scale=16, train_wall=61, gb_free=17.1, wall=40544
2023-07-11 02:41:51 | INFO | train_inner | epoch 038:    786 / 1474 loss=1.047, trans_loss=5.164, nll_loss=2.416, w2v_ctc_loss=0.297, task_loss=2.725, contrastive_loss=0.601, total=4187.51, n_correct=2802.47, ppl=5.34, accuracy=66.924, wps=6872.5, ups=1.64, wpb=4187.5, bsz=163.6, num_updates=55300, lr=6.01385e-05, gnorm=0.344, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=40605
2023-07-11 02:42:51 | INFO | train_inner | epoch 038:    886 / 1474 loss=1.037, trans_loss=5.166, nll_loss=2.419, w2v_ctc_loss=0.299, task_loss=2.837, contrastive_loss=0.412, total=4124.92, n_correct=2758.44, ppl=5.35, accuracy=66.873, wps=6911.2, ups=1.68, wpb=4124.9, bsz=155.8, num_updates=55400, lr=6.00842e-05, gnorm=0.331, clip=0, loss_scale=16, train_wall=59, gb_free=13.6, wall=40664
2023-07-11 02:43:51 | INFO | train_inner | epoch 038:    986 / 1474 loss=1.046, trans_loss=5.187, nll_loss=2.444, w2v_ctc_loss=0.304, task_loss=3.015, contrastive_loss=0.466, total=4110.21, n_correct=2736.38, ppl=5.44, accuracy=66.575, wps=6785.9, ups=1.65, wpb=4110.2, bsz=150.3, num_updates=55500, lr=6.003e-05, gnorm=0.316, clip=0, loss_scale=16, train_wall=60, gb_free=17, wall=40725
2023-07-11 02:44:52 | INFO | train_inner | epoch 038:   1086 / 1474 loss=1.05, trans_loss=5.177, nll_loss=2.433, w2v_ctc_loss=0.302, task_loss=2.705, contrastive_loss=0.558, total=4250.47, n_correct=2835.44, ppl=5.4, accuracy=66.709, wps=7026, ups=1.65, wpb=4250.5, bsz=164.7, num_updates=55600, lr=5.9976e-05, gnorm=0.333, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=40786
2023-07-11 02:45:53 | INFO | train_inner | epoch 038:   1186 / 1474 loss=1.049, trans_loss=5.187, nll_loss=2.445, w2v_ctc_loss=0.307, task_loss=3.241, contrastive_loss=0.415, total=4090.6, n_correct=2721, ppl=5.44, accuracy=66.518, wps=6703.4, ups=1.64, wpb=4090.6, bsz=145.1, num_updates=55700, lr=5.99222e-05, gnorm=0.329, clip=0, loss_scale=16, train_wall=61, gb_free=16.4, wall=40847
2023-07-11 02:46:55 | INFO | train_inner | epoch 038:   1286 / 1474 loss=1.049, trans_loss=5.183, nll_loss=2.439, w2v_ctc_loss=0.302, task_loss=3.198, contrastive_loss=0.403, total=4140.1, n_correct=2758.14, ppl=5.42, accuracy=66.62, wps=6720.6, ups=1.62, wpb=4140.1, bsz=147.2, num_updates=55800, lr=5.98684e-05, gnorm=0.32, clip=0, loss_scale=16, train_wall=61, gb_free=15.8, wall=40908
2023-07-11 02:47:55 | INFO | train_inner | epoch 038:   1386 / 1474 loss=1.051, trans_loss=5.189, nll_loss=2.448, w2v_ctc_loss=0.305, task_loss=2.968, contrastive_loss=0.514, total=4145.35, n_correct=2758.35, ppl=5.46, accuracy=66.541, wps=6863.7, ups=1.66, wpb=4145.4, bsz=154.2, num_updates=55900, lr=5.98149e-05, gnorm=0.325, clip=0, loss_scale=16, train_wall=60, gb_free=15.9, wall=40969
2023-07-11 02:48:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
tensor(0.0287, device='cuda:7')
tensor(0.0016, device='cuda:7')
tensor(0.0287, device='cuda:5')
tensor(0.0016, device='cuda:5')
tensor(0.0287, device='cuda:6')
tensor(0.0016, device='cuda:6')
tensor(0.0287, device='cuda:1')
tensor(0.0016, device='cuda:1')
tensor(0.0287, device='cuda:4')
tensor(0.0016, device='cuda:4')
tensor(0.0287, device='cuda:2')
tensor(0.0016, device='cuda:2')
tensor(0.0287, device='cuda:3')
tensor(0.0016, device='cuda:3')
2023-07-11 02:49:14 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 1.761 | trans_loss 5.554 | nll_loss 2.819 | w2v_ctc_loss 0.564 | task_loss 3.697 | contrastive_loss 0.548 | total 4003.4 | n_correct 2498.6 | ppl 7.05 | accuracy 62.412 | uer 16.667 | wer 18.441 | raw_wer 18.441 | bleu 20.13 | wps 2015.5 | wpb 4003.4 | bsz 141.8 | num_updates 55988 | best_bleu 20.67
2023-07-11 02:49:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55988 updates
2023-07-11 02:49:14 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-11 02:49:18 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt
2023-07-11 02:49:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_last.pt (epoch 38 @ 55988 updates, score 20.13) (writing took 4.217230091977399 seconds)
2023-07-11 02:49:18 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-11 02:49:18 | INFO | train | epoch 038 | loss 1.045 | trans_loss 5.175 | nll_loss 2.43 | w2v_ctc_loss 0.301 | task_loss 2.987 | contrastive_loss 0.505 | total 4138.65 | n_correct 2762.18 | ppl 5.39 | accuracy 66.741 | wps 6531.1 | ups 1.58 | wpb 4138.6 | bsz 152.8 | num_updates 55988 | lr 5.97678e-05 | gnorm 0.328 | clip 0 | loss_scale 16 | train_wall 888 | gb_free 16.8 | wall 41052
2023-07-11 02:49:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 02:49:19 | INFO | fairseq.trainer | begin training epoch 39
2023-07-11 02:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 02:49:34 | INFO | train_inner | epoch 039:     12 / 1474 loss=1.049, trans_loss=5.188, nll_loss=2.446, w2v_ctc_loss=0.305, task_loss=3.189, contrastive_loss=0.508, total=4040.68, n_correct=2686.52, ppl=5.45, accuracy=66.487, wps=4092.5, ups=1.01, wpb=4040.7, bsz=143.6, num_updates=56000, lr=5.97614e-05, gnorm=0.347, clip=0, loss_scale=16, train_wall=60, gb_free=16.3, wall=41067
2023-07-11 02:49:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 02:49:58 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 1.761 | trans_loss 5.551 | nll_loss 2.812 | w2v_ctc_loss 0.571 | task_loss 3.712 | contrastive_loss 0.564 | total 4003.4 | n_correct 2504.4 | ppl 7.02 | accuracy 62.557 | uer 16.587 | wer 18.489 | raw_wer 18.489 | bleu 20.35 | wps 2280.3 | wpb 4003.4 | bsz 141.8 | num_updates 56000 | best_bleu 20.67
2023-07-11 02:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-11 02:49:58 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_39_56000.pt
2023-07-11 02:50:00 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_39_56000.pt
2023-07-11 02:50:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 20.35) (writing took 5.99124036997091 seconds)
2023-07-11 02:51:04 | INFO | train_inner | epoch 039:    112 / 1474 loss=1.039, trans_loss=5.152, nll_loss=2.398, w2v_ctc_loss=0.3, task_loss=3.194, contrastive_loss=0.379, total=4056.32, n_correct=2723.82, ppl=5.27, accuracy=67.15, wps=4471.5, ups=1.1, wpb=4056.3, bsz=143, num_updates=56100, lr=5.97081e-05, gnorm=0.325, clip=0, loss_scale=16, train_wall=59, gb_free=15.9, wall=41158
2023-07-11 02:52:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-11 02:52:06 | INFO | train_inner | epoch 039:    213 / 1474 loss=1.04, trans_loss=5.149, nll_loss=2.394, w2v_ctc_loss=0.298, task_loss=3.03, contrastive_loss=0.384, total=4131.4, n_correct=2776.01, ppl=5.26, accuracy=67.193, wps=6765.5, ups=1.64, wpb=4131.4, bsz=150.1, num_updates=56200, lr=5.9655e-05, gnorm=0.319, clip=0, loss_scale=8, train_wall=61, gb_free=16.6, wall=41219
2023-07-11 02:53:07 | INFO | train_inner | epoch 039:    313 / 1474 loss=1.038, trans_loss=5.149, nll_loss=2.395, w2v_ctc_loss=0.3, task_loss=3.044, contrastive_loss=0.422, total=4143.19, n_correct=2785.55, ppl=5.26, accuracy=67.232, wps=6789.3, ups=1.64, wpb=4143.2, bsz=150.4, num_updates=56300, lr=5.9602e-05, gnorm=0.335, clip=0, loss_scale=8, train_wall=61, gb_free=16.7, wall=41280
2023-07-11 02:54:08 | INFO | train_inner | epoch 039:    413 / 1474 loss=1.047, trans_loss=5.162, nll_loss=2.412, w2v_ctc_loss=0.299, task_loss=2.93, contrastive_loss=0.703, total=4129.71, n_correct=2769.49, ppl=5.32, accuracy=67.063, wps=6741.4, ups=1.63, wpb=4129.7, bsz=156.5, num_updates=56400, lr=5.95491e-05, gnorm=0.327, clip=0, loss_scale=8, train_wall=61, gb_free=15.9, wall=41341
2023-07-11 02:55:09 | INFO | train_inner | epoch 039:    513 / 1474 loss=1.044, trans_loss=5.168, nll_loss=2.42, w2v_ctc_loss=0.298, task_loss=2.985, contrastive_loss=0.705, total=4143.24, n_correct=2768.1, ppl=5.35, accuracy=66.81, wps=6738.8, ups=1.63, wpb=4143.2, bsz=154.7, num_updates=56500, lr=5.94964e-05, gnorm=0.323, clip=0, loss_scale=8, train_wall=61, gb_free=13.6, wall=41403
2023-07-11 02:56:10 | INFO | train_inner | epoch 039:    613 / 1474 loss=1.042, trans_loss=5.165, nll_loss=2.415, w2v_ctc_loss=0.297, task_loss=2.98, contrastive_loss=0.515, total=4135.19, n_correct=2771.18, ppl=5.33, accuracy=67.015, wps=6842.1, ups=1.65, wpb=4135.2, bsz=153, num_updates=56600, lr=5.94438e-05, gnorm=0.329, clip=0, loss_scale=8, train_wall=60, gb_free=16.9, wall=41463
2023-07-11 02:57:10 | INFO | train_inner | epoch 039:    713 / 1474 loss=1.047, trans_loss=5.176, nll_loss=2.43, w2v_ctc_loss=0.301, task_loss=2.926, contrastive_loss=0.483, total=4131.39, n_correct=2757.32, ppl=5.39, accuracy=66.741, wps=6894.8, ups=1.67, wpb=4131.4, bsz=151.8, num_updates=56700, lr=5.93914e-05, gnorm=0.329, clip=0, loss_scale=8, train_wall=59, gb_free=17.3, wall=41523
2023-07-11 02:58:11 | INFO | train_inner | epoch 039:    813 / 1474 loss=1.041, trans_loss=5.17, nll_loss=2.422, w2v_ctc_loss=0.301, task_loss=3.026, contrastive_loss=0.427, total=4163.72, n_correct=2779.3, ppl=5.36, accuracy=66.75, wps=6814.6, ups=1.64, wpb=4163.7, bsz=153.8, num_updates=56800, lr=5.93391e-05, gnorm=0.321, clip=0, loss_scale=8, train_wall=61, gb_free=17.5, wall=41584
2023-07-11 02:59:11 | INFO | train_inner | epoch 039:    913 / 1474 loss=1.039, trans_loss=5.167, nll_loss=2.419, w2v_ctc_loss=0.299, task_loss=3.078, contrastive_loss=0.428, total=4130.79, n_correct=2762.28, ppl=5.35, accuracy=66.871, wps=6810.5, ups=1.65, wpb=4130.8, bsz=150.2, num_updates=56900, lr=5.92869e-05, gnorm=0.32, clip=0, loss_scale=8, train_wall=60, gb_free=16.8, wall=41645
2023-07-11 03:00:13 | INFO | train_inner | epoch 039:   1013 / 1474 loss=1.05, trans_loss=5.182, nll_loss=2.439, w2v_ctc_loss=0.3, task_loss=2.917, contrastive_loss=0.667, total=4200.65, n_correct=2796.89, ppl=5.42, accuracy=66.582, wps=6814.4, ups=1.62, wpb=4200.6, bsz=159.6, num_updates=57000, lr=5.92349e-05, gnorm=0.336, clip=0, loss_scale=8, train_wall=61, gb_free=14.1, wall=41707
2023-07-11 03:01:14 | INFO | train_inner | epoch 039:   1113 / 1474 loss=1.048, trans_loss=5.169, nll_loss=2.423, w2v_ctc_loss=0.3, task_loss=2.794, contrastive_loss=0.609, total=4196.16, n_correct=2803.57, ppl=5.36, accuracy=66.813, wps=6886.1, ups=1.64, wpb=4196.2, bsz=161.5, num_updates=57100, lr=5.9183e-05, gnorm=0.334, clip=0, loss_scale=8, train_wall=60, gb_free=16.1, wall=41768
2023-07-11 03:02:15 | INFO | train_inner | epoch 039:   1213 / 1474 loss=1.044, trans_loss=5.181, nll_loss=2.437, w2v_ctc_loss=0.298, task_loss=2.967, contrastive_loss=0.498, total=4129.4, n_correct=2752.34, ppl=5.41, accuracy=66.652, wps=6815.8, ups=1.65, wpb=4129.4, bsz=154.4, num_updates=57200, lr=5.91312e-05, gnorm=0.332, clip=0, loss_scale=8, train_wall=60, gb_free=17.5, wall=41828
2023-07-11 03:03:15 | INFO | train_inner | epoch 039:   1313 / 1474 loss=1.047, trans_loss=5.175, nll_loss=2.43, w2v_ctc_loss=0.302, task_loss=2.876, contrastive_loss=0.471, total=4169.96, n_correct=2783.84, ppl=5.39, accuracy=66.759, wps=6867.7, ups=1.65, wpb=4170, bsz=157, num_updates=57300, lr=5.90796e-05, gnorm=0.323, clip=0, loss_scale=8, train_wall=60, gb_free=12.7, wall=41889
2023-07-11 03:04:16 | INFO | train_inner | epoch 039:   1413 / 1474 loss=1.041, trans_loss=5.175, nll_loss=2.428, w2v_ctc_loss=0.301, task_loss=3.246, contrastive_loss=0.347, total=4062.74, n_correct=2709.9, ppl=5.38, accuracy=66.701, wps=6738.3, ups=1.66, wpb=4062.7, bsz=140.3, num_updates=57400, lr=5.90281e-05, gnorm=0.325, clip=0, loss_scale=8, train_wall=60, gb_free=16.6, wall=41949
2023-07-11 03:04:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 03:05:18 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 1.753 | trans_loss 5.547 | nll_loss 2.809 | w2v_ctc_loss 0.554 | task_loss 3.718 | contrastive_loss 0.547 | total 4003.4 | n_correct 2498.3 | ppl 7.01 | accuracy 62.404 | uer 16.561 | wer 18.396 | raw_wer 18.396 | bleu 20.45 | wps 2108.7 | wpb 4003.4 | bsz 141.8 | num_updates 57461 | best_bleu 20.67
2023-07-11 03:05:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57461 updates
2023-07-11 03:05:18 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.4506.pt
2023-07-11 03:05:22 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.4506.pt
2023-07-11 03:05:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.4506.pt (epoch 39 @ 57461 updates, score 20.45) (writing took 7.036630102957133 seconds)
2023-07-11 03:05:25 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-11 03:05:25 | INFO | train | epoch 039 | loss 1.043 | trans_loss 5.168 | nll_loss 2.419 | w2v_ctc_loss 0.299 | task_loss 2.986 | contrastive_loss 0.502 | total 4138.69 | n_correct 2767.74 | ppl 5.35 | accuracy 66.875 | wps 6305.2 | ups 1.52 | wpb 4138.7 | bsz 152.8 | num_updates 57461 | lr 5.89968e-05 | gnorm 0.326 | clip 0 | loss_scale 8 | train_wall 888 | gb_free 15.7 | wall 42019
2023-07-11 03:05:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 03:05:26 | INFO | fairseq.trainer | begin training epoch 40
2023-07-11 03:05:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 03:05:57 | INFO | train_inner | epoch 040:     39 / 1474 loss=1.039, trans_loss=5.166, nll_loss=2.418, w2v_ctc_loss=0.292, task_loss=2.897, contrastive_loss=0.423, total=4157.73, n_correct=2781.96, ppl=5.35, accuracy=66.911, wps=4090.5, ups=0.98, wpb=4157.7, bsz=155, num_updates=57500, lr=5.89768e-05, gnorm=0.331, clip=0, loss_scale=8, train_wall=60, gb_free=15.6, wall=42051
2023-07-11 03:06:58 | INFO | train_inner | epoch 040:    139 / 1474 loss=1.04, trans_loss=5.138, nll_loss=2.381, w2v_ctc_loss=0.299, task_loss=2.963, contrastive_loss=0.403, total=4158.81, n_correct=2802.48, ppl=5.21, accuracy=67.387, wps=6846.9, ups=1.65, wpb=4158.8, bsz=153.3, num_updates=57600, lr=5.89256e-05, gnorm=0.33, clip=0, loss_scale=8, train_wall=60, gb_free=16.3, wall=42112
2023-07-11 03:07:58 | INFO | train_inner | epoch 040:    239 / 1474 loss=1.035, trans_loss=5.15, nll_loss=2.396, w2v_ctc_loss=0.299, task_loss=3.061, contrastive_loss=0.403, total=4104.08, n_correct=2754.59, ppl=5.26, accuracy=67.118, wps=6803.8, ups=1.66, wpb=4104.1, bsz=150, num_updates=57700, lr=5.88745e-05, gnorm=0.355, clip=0, loss_scale=8, train_wall=60, gb_free=17.7, wall=42172
2023-07-11 03:08:58 | INFO | train_inner | epoch 040:    339 / 1474 loss=1.036, trans_loss=5.151, nll_loss=2.399, w2v_ctc_loss=0.293, task_loss=2.784, contrastive_loss=0.436, total=4149.88, n_correct=2788.58, ppl=5.27, accuracy=67.197, wps=6923.8, ups=1.67, wpb=4149.9, bsz=159.5, num_updates=57800, lr=5.88235e-05, gnorm=0.322, clip=0, loss_scale=8, train_wall=59, gb_free=14.2, wall=42232
2023-07-11 03:09:59 | INFO | train_inner | epoch 040:    439 / 1474 loss=1.042, trans_loss=5.156, nll_loss=2.405, w2v_ctc_loss=0.297, task_loss=2.954, contrastive_loss=0.581, total=4147.99, n_correct=2785.1, ppl=5.29, accuracy=67.143, wps=6826.1, ups=1.65, wpb=4148, bsz=156.2, num_updates=57900, lr=5.87727e-05, gnorm=0.325, clip=0, loss_scale=8, train_wall=60, gb_free=16.9, wall=42293
2023-07-11 03:11:00 | INFO | train_inner | epoch 040:    539 / 1474 loss=1.039, trans_loss=5.151, nll_loss=2.399, w2v_ctc_loss=0.293, task_loss=2.9, contrastive_loss=0.633, total=4166.35, n_correct=2798.17, ppl=5.28, accuracy=67.161, wps=6860.2, ups=1.65, wpb=4166.4, bsz=157.8, num_updates=58000, lr=5.8722e-05, gnorm=0.319, clip=0, loss_scale=8, train_wall=60, gb_free=17.7, wall=42353
2023-07-11 03:11:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 03:11:25 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 1.762 | trans_loss 5.549 | nll_loss 2.812 | w2v_ctc_loss 0.588 | task_loss 3.721 | contrastive_loss 0.548 | total 4003.4 | n_correct 2503.9 | ppl 7.02 | accuracy 62.544 | uer 16.84 | wer 18.769 | raw_wer 18.769 | bleu 20.34 | wps 2209 | wpb 4003.4 | bsz 141.8 | num_updates 58000 | best_bleu 20.67
2023-07-11 03:11:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-11 03:11:25 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_40_58000.pt
2023-07-11 03:11:27 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_40_58000.pt
2023-07-11 03:11:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 20.34) (writing took 6.313150398025755 seconds)
2023-07-11 03:12:33 | INFO | train_inner | epoch 040:    639 / 1474 loss=1.043, trans_loss=5.171, nll_loss=2.423, w2v_ctc_loss=0.304, task_loss=3.117, contrastive_loss=0.442, total=4121.6, n_correct=2751.26, ppl=5.36, accuracy=66.752, wps=4444.1, ups=1.08, wpb=4121.6, bsz=148.6, num_updates=58100, lr=5.86715e-05, gnorm=0.33, clip=0, loss_scale=8, train_wall=61, gb_free=13.1, wall=42446
2023-07-11 03:13:33 | INFO | train_inner | epoch 040:    739 / 1474 loss=1.037, trans_loss=5.156, nll_loss=2.404, w2v_ctc_loss=0.297, task_loss=2.873, contrastive_loss=0.409, total=4135.27, n_correct=2771.6, ppl=5.29, accuracy=67.023, wps=6849.7, ups=1.66, wpb=4135.3, bsz=154.8, num_updates=58200, lr=5.8621e-05, gnorm=0.331, clip=0, loss_scale=8, train_wall=60, gb_free=17.7, wall=42506
2023-07-11 03:14:34 | INFO | train_inner | epoch 040:    839 / 1474 loss=1.045, trans_loss=5.169, nll_loss=2.423, w2v_ctc_loss=0.294, task_loss=2.724, contrastive_loss=0.813, total=4211.77, n_correct=2815.43, ppl=5.36, accuracy=66.847, wps=6878.4, ups=1.63, wpb=4211.8, bsz=164.1, num_updates=58300, lr=5.85707e-05, gnorm=0.324, clip=0, loss_scale=16, train_wall=61, gb_free=15.7, wall=42568
2023-07-11 03:15:35 | INFO | train_inner | epoch 040:    939 / 1474 loss=1.04, trans_loss=5.169, nll_loss=2.421, w2v_ctc_loss=0.301, task_loss=3.147, contrastive_loss=0.45, total=4091.87, n_correct=2735, ppl=5.35, accuracy=66.84, wps=6694.5, ups=1.64, wpb=4091.9, bsz=147.1, num_updates=58400, lr=5.85206e-05, gnorm=0.336, clip=0, loss_scale=16, train_wall=61, gb_free=17.9, wall=42629
2023-07-11 03:16:36 | INFO | train_inner | epoch 040:   1039 / 1474 loss=1.05, trans_loss=5.182, nll_loss=2.438, w2v_ctc_loss=0.303, task_loss=3.243, contrastive_loss=0.482, total=4124.03, n_correct=2748.2, ppl=5.42, accuracy=66.639, wps=6783.2, ups=1.64, wpb=4124, bsz=143.8, num_updates=58500, lr=5.84705e-05, gnorm=0.337, clip=0, loss_scale=16, train_wall=60, gb_free=17.1, wall=42690
2023-07-11 03:17:37 | INFO | train_inner | epoch 040:   1139 / 1474 loss=1.04, trans_loss=5.171, nll_loss=2.424, w2v_ctc_loss=0.301, task_loss=3.102, contrastive_loss=0.42, total=4131.03, n_correct=2757.52, ppl=5.37, accuracy=66.751, wps=6778.7, ups=1.64, wpb=4131, bsz=149.6, num_updates=58600, lr=5.84206e-05, gnorm=0.338, clip=0, loss_scale=16, train_wall=60, gb_free=15.3, wall=42751
2023-07-11 03:18:38 | INFO | train_inner | epoch 040:   1239 / 1474 loss=1.043, trans_loss=5.162, nll_loss=2.413, w2v_ctc_loss=0.297, task_loss=2.966, contrastive_loss=0.555, total=4191.39, n_correct=2804.38, ppl=5.33, accuracy=66.908, wps=6860.8, ups=1.64, wpb=4191.4, bsz=154.6, num_updates=58700, lr=5.83708e-05, gnorm=0.321, clip=0, loss_scale=16, train_wall=61, gb_free=16.6, wall=42812
2023-07-11 03:19:39 | INFO | train_inner | epoch 040:   1339 / 1474 loss=1.043, trans_loss=5.168, nll_loss=2.422, w2v_ctc_loss=0.296, task_loss=3.015, contrastive_loss=0.556, total=4119.9, n_correct=2754.97, ppl=5.36, accuracy=66.87, wps=6808, ups=1.65, wpb=4119.9, bsz=152.7, num_updates=58800, lr=5.83212e-05, gnorm=0.325, clip=0, loss_scale=16, train_wall=60, gb_free=15.4, wall=42872
2023-07-11 03:20:39 | INFO | train_inner | epoch 040:   1439 / 1474 loss=1.048, trans_loss=5.174, nll_loss=2.428, w2v_ctc_loss=0.302, task_loss=2.971, contrastive_loss=0.49, total=4125.85, n_correct=2752.71, ppl=5.38, accuracy=66.719, wps=6794.2, ups=1.65, wpb=4125.9, bsz=152.7, num_updates=58900, lr=5.82717e-05, gnorm=0.323, clip=0, loss_scale=16, train_wall=60, gb_free=18, wall=42933
2023-07-11 03:21:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 03:21:24 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 1.757 | trans_loss 5.554 | nll_loss 2.82 | w2v_ctc_loss 0.579 | task_loss 3.742 | contrastive_loss 0.567 | total 4003.4 | n_correct 2495.8 | ppl 7.06 | accuracy 62.342 | uer 16.757 | wer 18.605 | raw_wer 18.605 | bleu 20.36 | wps 2397.5 | wpb 4003.4 | bsz 141.8 | num_updates 58935 | best_bleu 20.67
2023-07-11 03:21:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58935 updates
2023-07-11 03:21:24 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.3603.pt
2023-07-11 03:21:26 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.3603.pt
2023-07-11 03:21:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint.best_bleu_20.3603.pt (epoch 40 @ 58935 updates, score 20.36) (writing took 5.445301567029674 seconds)
2023-07-11 03:21:29 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-11 03:21:29 | INFO | train | epoch 040 | loss 1.041 | trans_loss 5.162 | nll_loss 2.412 | w2v_ctc_loss 0.298 | task_loss 2.989 | contrastive_loss 0.502 | total 4138.65 | n_correct 2771.27 | ppl 5.32 | accuracy 66.961 | wps 6328.1 | ups 1.53 | wpb 4138.6 | bsz 152.8 | num_updates 58935 | lr 5.82543e-05 | gnorm 0.331 | clip 0 | loss_scale 16 | train_wall 887 | gb_free 16 | wall 42983
2023-07-11 03:21:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-11 03:21:30 | INFO | fairseq.trainer | begin training epoch 41
2023-07-11 03:21:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-11 03:22:17 | INFO | train_inner | epoch 041:     65 / 1474 loss=1.039, trans_loss=5.151, nll_loss=2.399, w2v_ctc_loss=0.296, task_loss=3.057, contrastive_loss=0.445, total=4098.68, n_correct=2754.04, ppl=5.27, accuracy=67.193, wps=4189.2, ups=1.02, wpb=4098.7, bsz=149.7, num_updates=59000, lr=5.82223e-05, gnorm=0.339, clip=0, loss_scale=16, train_wall=60, gb_free=16.6, wall=43031
2023-07-11 03:23:18 | INFO | train_inner | epoch 041:    165 / 1474 loss=1.034, trans_loss=5.131, nll_loss=2.372, w2v_ctc_loss=0.291, task_loss=2.962, contrastive_loss=0.525, total=4132.72, n_correct=2788.72, ppl=5.18, accuracy=67.479, wps=6792.9, ups=1.64, wpb=4132.7, bsz=153.5, num_updates=59100, lr=5.8173e-05, gnorm=0.322, clip=0, loss_scale=16, train_wall=60, gb_free=11.6, wall=43092
2023-07-11 03:24:18 | INFO | train_inner | epoch 041:    265 / 1474 loss=1.042, trans_loss=5.143, nll_loss=2.388, w2v_ctc_loss=0.294, task_loss=2.772, contrastive_loss=0.535, total=4180.79, n_correct=2815.03, ppl=5.23, accuracy=67.332, wps=6976, ups=1.67, wpb=4180.8, bsz=159.4, num_updates=59200, lr=5.81238e-05, gnorm=0.335, clip=0, loss_scale=16, train_wall=59, gb_free=17, wall=43152
2023-07-11 03:25:19 | INFO | train_inner | epoch 041:    365 / 1474 loss=1.04, trans_loss=5.15, nll_loss=2.397, w2v_ctc_loss=0.301, task_loss=2.957, contrastive_loss=0.456, total=4152.45, n_correct=2789.39, ppl=5.27, accuracy=67.175, wps=6827.9, ups=1.64, wpb=4152.4, bsz=153.2, num_updates=59300, lr=5.80748e-05, gnorm=0.331, clip=0, loss_scale=16, train_wall=60, gb_free=15.1, wall=43212
2023-07-11 03:26:19 | INFO | train_inner | epoch 041:    465 / 1474 loss=1.033, trans_loss=5.143, nll_loss=2.388, w2v_ctc_loss=0.294, task_loss=3.007, contrastive_loss=0.41, total=4144.35, n_correct=2789.3, ppl=5.23, accuracy=67.304, wps=6834.5, ups=1.65, wpb=4144.4, bsz=151.8, num_updates=59400, lr=5.80259e-05, gnorm=0.337, clip=0, loss_scale=16, train_wall=60, gb_free=15.3, wall=43273
2023-07-11 03:27:20 | INFO | train_inner | epoch 041:    565 / 1474 loss=1.041, trans_loss=5.153, nll_loss=2.401, w2v_ctc_loss=0.3, task_loss=2.992, contrastive_loss=0.459, total=4145.57, n_correct=2783.35, ppl=5.28, accuracy=67.14, wps=6894.1, ups=1.66, wpb=4145.6, bsz=153.3, num_updates=59500, lr=5.79771e-05, gnorm=0.326, clip=0, loss_scale=16, train_wall=60, gb_free=14.5, wall=43333
2023-07-11 03:28:20 | INFO | train_inner | epoch 041:    665 / 1474 loss=1.033, trans_loss=5.137, nll_loss=2.38, w2v_ctc_loss=0.29, task_loss=2.822, contrastive_loss=0.425, total=4187.21, n_correct=2825.11, ppl=5.21, accuracy=67.47, wps=6906.1, ups=1.65, wpb=4187.2, bsz=158.8, num_updates=59600, lr=5.79284e-05, gnorm=0.329, clip=0, loss_scale=16, train_wall=60, gb_free=16.8, wall=43394
2023-07-11 03:29:21 | INFO | train_inner | epoch 041:    765 / 1474 loss=1.038, trans_loss=5.155, nll_loss=2.403, w2v_ctc_loss=0.295, task_loss=3.042, contrastive_loss=0.404, total=4144.35, n_correct=2776.1, ppl=5.29, accuracy=66.985, wps=6867.4, ups=1.66, wpb=4144.4, bsz=149.6, num_updates=59700, lr=5.78799e-05, gnorm=0.338, clip=0, loss_scale=16, train_wall=60, gb_free=17.7, wall=43454
2023-07-11 03:30:21 | INFO | train_inner | epoch 041:    865 / 1474 loss=1.036, trans_loss=5.146, nll_loss=2.392, w2v_ctc_loss=0.292, task_loss=3.088, contrastive_loss=0.409, total=4112.51, n_correct=2763.32, ppl=5.25, accuracy=67.193, wps=6845.1, ups=1.66, wpb=4112.5, bsz=148.5, num_updates=59800, lr=5.78315e-05, gnorm=0.333, clip=0, loss_scale=16, train_wall=60, gb_free=16, wall=43514
2023-07-11 03:31:22 | INFO | train_inner | epoch 041:    965 / 1474 loss=1.047, trans_loss=5.174, nll_loss=2.427, w2v_ctc_loss=0.304, task_loss=3.114, contrastive_loss=0.596, total=4119.19, n_correct=2747.86, ppl=5.38, accuracy=66.709, wps=6727.6, ups=1.63, wpb=4119.2, bsz=149.5, num_updates=59900, lr=5.77832e-05, gnorm=0.334, clip=0, loss_scale=16, train_wall=61, gb_free=16.5, wall=43575
2023-07-11 03:32:22 | INFO | train_inner | epoch 041:   1065 / 1474 loss=1.04, trans_loss=5.162, nll_loss=2.412, w2v_ctc_loss=0.296, task_loss=2.951, contrastive_loss=0.436, total=4142.3, n_correct=2772.76, ppl=5.32, accuracy=66.938, wps=6837.4, ups=1.65, wpb=4142.3, bsz=152.5, num_updates=60000, lr=5.7735e-05, gnorm=0.331, clip=0, loss_scale=16, train_wall=60, gb_free=16.5, wall=43636
2023-07-11 03:32:22 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-11 03:32:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-11 03:32:45 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 1.762 | trans_loss 5.545 | nll_loss 2.807 | w2v_ctc_loss 0.568 | task_loss 3.696 | contrastive_loss 0.566 | total 4003.4 | n_correct 2504 | ppl 7 | accuracy 62.547 | uer 16.526 | wer 18.348 | raw_wer 18.348 | bleu 20.31 | wps 2444.7 | wpb 4003.4 | bsz 141.8 | num_updates 60000 | best_bleu 20.67
2023-07-11 03:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-11 03:32:45 | INFO | fairseq.trainer | Saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_41_60000.pt
2023-07-11 03:32:48 | INFO | fairseq.trainer | Finished saving checkpoint to /workspace/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_41_60000.pt
2023-07-11 03:32:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_AT_tokenl/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 20.31) (writing took 6.236710324010346 seconds)
2023-07-11 03:32:52 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-11 03:32:52 | INFO | train | epoch 041 | loss 1.039 | trans_loss 5.149 | nll_loss 2.396 | w2v_ctc_loss 0.296 | task_loss 2.971 | contrastive_loss 0.466 | total 4144.74 | n_correct 2784.57 | ppl 5.26 | accuracy 67.183 | wps 6465.4 | ups 1.56 | wpb 4144.7 | bsz 153 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.332 | clip 0 | loss_scale 16 | train_wall 639 | gb_free 16.5 | wall 43666
2023-07-11 03:32:52 | INFO | fairseq_cli.train | done training in 43596.3 seconds
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1776 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
