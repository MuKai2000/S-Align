2023-08-04 00:45:48 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19176
2023-08-04 00:45:48 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19176
2023-08-04 00:45:48 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19176
2023-08-04 00:45:48 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:19176
2023-08-04 00:45:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-04 00:45:48 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:19176
2023-08-04 00:45:48 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-04 00:45:48 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19176
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-04 00:45:49 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:19176
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-04 00:45:49 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:19176
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 00:45:49 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 00:45:49 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-04 00:45:49 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-04 00:45:49 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 00:45:49 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-04 00:45:49 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-04 00:45:49 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-04 00:45:49 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-04 00:45:49 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-04 00:45:53 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19176', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-04 00:45:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-04 00:45:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-04 00:45:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-04 00:45:54 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 1.0
2023-08-04 00:45:54 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-04 00:45:58 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-04 00:45:58 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-04 00:45:58 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-04 00:46:00 | INFO | root | load pretrained hubert
2023-08-04 00:46:03 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-08-04 00:46:04 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-04 00:46:07 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-08-04 00:46:07 | INFO | root | share the sematic adapter and textual encoder
2023-08-04 00:46:07 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-04 00:46:07 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-04 00:46:07 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-04 00:46:07 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-04 00:46:07 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-08-04 00:46:07 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-04 00:46:07 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-04 00:46:07 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 00:46:07 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 00:46:07 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-04 00:46:12 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-04 00:46:12 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-04 00:46:12 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-04 00:46:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-04 00:46:13 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 00:46:13 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 00:46:13 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 00:46:13 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 00:46:13 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 00:46:13 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 00:46:13 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 00:46:13 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-04 00:46:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-04 00:46:13 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-04 00:46:13 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-04 00:46:13 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt
2023-08-04 00:46:13 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt
2023-08-04 00:46:13 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-04 00:46:13 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-04 00:46:13 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 00:46:13 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-04 00:46:15 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-04 00:46:16 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-04 00:47:04 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-04 00:47:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 00:47:04 | INFO | fairseq.trainer | begin training epoch 1
2023-08-04 00:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 00:48:22 | INFO | train_inner | epoch 001:    100 / 1474 loss=19.137, trans_loss=5.598, nll_loss=4.163, w2v_ctc_loss=22.485, task_loss=1.749, contrastive_loss=3.325, total=4207.04, n_correct=209.29, ppl=17.91, accuracy=4.975, wps=19227.2, ups=1.53, wpb=12551.1, bsz=471.4, num_updates=100, lr=4.098e-06, gnorm=0.891, clip=0, loss_scale=128, train_wall=70, gb_free=19.5, wall=129
2023-08-04 00:49:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-04 00:49:27 | INFO | train_inner | epoch 001:    201 / 1474 loss=16.99, trans_loss=5.477, nll_loss=4.065, w2v_ctc_loss=19.358, task_loss=1.706, contrastive_loss=3.278, total=4124.14, n_correct=223.45, ppl=16.73, accuracy=5.418, wps=19082.4, ups=1.55, wpb=12313.4, bsz=461, num_updates=200, lr=8.096e-06, gnorm=3.625, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=194
2023-08-04 00:50:31 | INFO | train_inner | epoch 001:    301 / 1474 loss=10.083, trans_loss=5.475, nll_loss=4.117, w2v_ctc_loss=8.784, task_loss=1.706, contrastive_loss=3.203, total=4079.62, n_correct=209.03, ppl=17.35, accuracy=5.124, wps=19128.8, ups=1.57, wpb=12186.7, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.607, clip=0, loss_scale=64, train_wall=63, gb_free=19.9, wall=258
2023-08-04 00:51:35 | INFO | train_inner | epoch 001:    401 / 1474 loss=8.848, trans_loss=5.516, nll_loss=4.189, w2v_ctc_loss=6.815, task_loss=1.496, contrastive_loss=3.237, total=4174.14, n_correct=193.9, ppl=18.24, accuracy=4.645, wps=19505.1, ups=1.56, wpb=12463.5, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=2.947, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=322
2023-08-04 00:52:39 | INFO | train_inner | epoch 001:    501 / 1474 loss=8.415, trans_loss=5.495, nll_loss=4.178, w2v_ctc_loss=6.176, task_loss=1.369, contrastive_loss=3.233, total=4176.18, n_correct=188.66, ppl=18.11, accuracy=4.518, wps=19395.7, ups=1.55, wpb=12479.7, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.416, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=386
2023-08-04 00:53:44 | INFO | train_inner | epoch 001:    601 / 1474 loss=8.165, trans_loss=5.523, nll_loss=4.213, w2v_ctc_loss=5.809, task_loss=1.274, contrastive_loss=3.288, total=4147.79, n_correct=184.1, ppl=18.55, accuracy=4.439, wps=19111.3, ups=1.54, wpb=12371.6, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.727, clip=0, loss_scale=64, train_wall=64, gb_free=18.9, wall=451
2023-08-04 00:54:47 | INFO | train_inner | epoch 001:    701 / 1474 loss=8.008, trans_loss=5.524, nll_loss=4.22, w2v_ctc_loss=5.69, task_loss=1.325, contrastive_loss=3.039, total=4152.1, n_correct=193.79, ppl=18.63, accuracy=4.667, wps=19500.9, ups=1.57, wpb=12395.5, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=63, gb_free=19.5, wall=514
2023-08-04 00:55:51 | INFO | train_inner | epoch 001:    801 / 1474 loss=7.732, trans_loss=5.461, nll_loss=4.151, w2v_ctc_loss=5.465, task_loss=1.281, contrastive_loss=2.947, total=4123.83, n_correct=238, ppl=17.77, accuracy=5.771, wps=19390.7, ups=1.58, wpb=12306.1, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.818, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=578
2023-08-04 00:56:54 | INFO | train_inner | epoch 001:    901 / 1474 loss=7.472, trans_loss=5.427, nll_loss=4.121, w2v_ctc_loss=5.281, task_loss=1.302, contrastive_loss=2.706, total=4163.61, n_correct=263.54, ppl=17.41, accuracy=6.33, wps=19592.1, ups=1.58, wpb=12433.9, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.33, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=641
2023-08-04 00:57:59 | INFO | train_inner | epoch 001:   1001 / 1474 loss=7.211, trans_loss=5.402, nll_loss=4.099, w2v_ctc_loss=5.07, task_loss=1.311, contrastive_loss=2.556, total=4135.34, n_correct=286.07, ppl=17.14, accuracy=6.918, wps=18920, ups=1.53, wpb=12353.2, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.419, clip=0, loss_scale=64, train_wall=65, gb_free=19, wall=707
2023-08-04 00:59:03 | INFO | train_inner | epoch 001:   1101 / 1474 loss=6.942, trans_loss=5.388, nll_loss=4.087, w2v_ctc_loss=4.872, task_loss=1.322, contrastive_loss=2.334, total=4147.38, n_correct=309, ppl=16.99, accuracy=7.45, wps=19366.5, ups=1.57, wpb=12367, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.657, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=770
2023-08-04 01:00:07 | INFO | train_inner | epoch 001:   1201 / 1474 loss=6.722, trans_loss=5.369, nll_loss=4.07, w2v_ctc_loss=4.706, task_loss=1.377, contrastive_loss=2.131, total=4139.9, n_correct=316.63, ppl=16.79, accuracy=7.648, wps=19457.6, ups=1.57, wpb=12366.5, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.758, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=834
2023-08-04 01:01:10 | INFO | train_inner | epoch 001:   1301 / 1474 loss=6.501, trans_loss=5.367, nll_loss=4.07, w2v_ctc_loss=4.511, task_loss=1.324, contrastive_loss=1.94, total=4046.58, n_correct=318.08, ppl=16.79, accuracy=7.86, wps=19081.3, ups=1.58, wpb=12081.6, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.736, clip=0, loss_scale=64, train_wall=63, gb_free=19.7, wall=897
2023-08-04 01:02:15 | INFO | train_inner | epoch 001:   1401 / 1474 loss=6.295, trans_loss=5.356, nll_loss=4.06, w2v_ctc_loss=4.31, task_loss=1.308, contrastive_loss=2.008, total=4133.18, n_correct=331.76, ppl=16.68, accuracy=8.027, wps=18909.8, ups=1.53, wpb=12350, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.623, clip=0, loss_scale=64, train_wall=65, gb_free=19.9, wall=963
2023-08-04 01:03:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 01:03:41 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.566 | trans_loss 10.917 | nll_loss 9.9 | w2v_ctc_loss 5.605 | task_loss 7.547 | contrastive_loss 2.367 | total 4003.4 | n_correct 384.3 | ppl 955.49 | accuracy 9.599 | uer 71.911 | wer 69.845 | raw_wer 69.845 | bleu 0.02 | wps 1157.8 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-08-04 01:03:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-08-04 01:03:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 01:03:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 01:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.02) (writing took 6.383338529616594 seconds)
2023-08-04 01:03:48 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-04 01:03:48 | INFO | train | epoch 001 | loss 9.041 | trans_loss 5.451 | nll_loss 4.125 | w2v_ctc_loss 7.644 | task_loss 1.41 | contrastive_loss 2.761 | total 4138.55 | n_correct 251.844 | ppl 17.45 | accuracy 6.085 | wps 18375.5 | ups 1.49 | wpb 12355.5 | bsz 458.4 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.788 | clip 0 | loss_scale 64 | train_wall 942 | gb_free 19.2 | wall 1055
2023-08-04 01:03:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 01:03:48 | INFO | fairseq.trainer | begin training epoch 2
2023-08-04 01:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 01:04:14 | INFO | train_inner | epoch 002:     27 / 1474 loss=6.106, trans_loss=5.349, nll_loss=4.047, w2v_ctc_loss=4.118, task_loss=1.246, contrastive_loss=1.855, total=4162.95, n_correct=337.35, ppl=16.53, accuracy=8.104, wps=10494.1, ups=0.85, wpb=12416.8, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.664, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1081
2023-08-04 01:05:17 | INFO | train_inner | epoch 002:    127 / 1474 loss=5.947, trans_loss=5.346, nll_loss=4.042, w2v_ctc_loss=4.002, task_loss=1.33, contrastive_loss=1.652, total=4155.98, n_correct=338.88, ppl=16.47, accuracy=8.154, wps=19552.3, ups=1.58, wpb=12394.8, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.726, clip=0, loss_scale=64, train_wall=63, gb_free=18.9, wall=1144
2023-08-04 01:06:21 | INFO | train_inner | epoch 002:    227 / 1474 loss=5.782, trans_loss=5.325, nll_loss=4.021, w2v_ctc_loss=3.806, task_loss=1.153, contrastive_loss=1.682, total=4179.21, n_correct=347.99, ppl=16.23, accuracy=8.327, wps=19582.7, ups=1.57, wpb=12484.6, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.509, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1208
2023-08-04 01:07:25 | INFO | train_inner | epoch 002:    327 / 1474 loss=5.622, trans_loss=5.323, nll_loss=4.015, w2v_ctc_loss=3.716, task_loss=1.325, contrastive_loss=1.392, total=4146.1, n_correct=353.7, ppl=16.17, accuracy=8.531, wps=19231.6, ups=1.55, wpb=12374.1, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.395, clip=0, loss_scale=64, train_wall=64, gb_free=18.8, wall=1272
2023-08-04 01:08:28 | INFO | train_inner | epoch 002:    427 / 1474 loss=5.482, trans_loss=5.315, nll_loss=4.009, w2v_ctc_loss=3.618, task_loss=1.456, contrastive_loss=1.215, total=4037.99, n_correct=342.63, ppl=16.1, accuracy=8.485, wps=19113.5, ups=1.58, wpb=12069.2, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.439, clip=0, loss_scale=64, train_wall=63, gb_free=19, wall=1336
2023-08-04 01:09:32 | INFO | train_inner | epoch 002:    527 / 1474 loss=5.372, trans_loss=5.305, nll_loss=3.992, w2v_ctc_loss=3.457, task_loss=1.266, contrastive_loss=1.31, total=4176.97, n_correct=360.1, ppl=15.92, accuracy=8.621, wps=19683.1, ups=1.58, wpb=12463.5, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.285, clip=0, loss_scale=64, train_wall=63, gb_free=19.6, wall=1399
2023-08-04 01:09:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 01:10:12 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.957 | trans_loss 10.76 | nll_loss 9.686 | w2v_ctc_loss 4.515 | task_loss 7.546 | contrastive_loss 1.648 | total 4003.4 | n_correct 410.9 | ppl 823.83 | accuracy 10.264 | uer 61.431 | wer 59.282 | raw_wer 59.282 | bleu 0.05 | wps 1140 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.05
2023-08-04 01:10:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-04 01:10:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_2_2000.pt
2023-08-04 01:10:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_2_2000.pt
2023-08-04 01:10:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.05) (writing took 40.96888677403331 seconds)
2023-08-04 01:11:57 | INFO | train_inner | epoch 002:    627 / 1474 loss=5.24, trans_loss=5.297, nll_loss=3.983, w2v_ctc_loss=3.352, task_loss=1.309, contrastive_loss=1.111, total=4126.49, n_correct=366.85, ppl=15.81, accuracy=8.89, wps=8475.9, ups=0.69, wpb=12314.9, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.173, clip=0, loss_scale=64, train_wall=64, gb_free=19.2, wall=1544
2023-08-04 01:13:01 | INFO | train_inner | epoch 002:    727 / 1474 loss=5.167, trans_loss=5.282, nll_loss=3.967, w2v_ctc_loss=3.267, task_loss=1.283, contrastive_loss=1.212, total=4149.06, n_correct=374.23, ppl=15.64, accuracy=9.02, wps=19528.8, ups=1.58, wpb=12386.4, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.139, clip=0, loss_scale=64, train_wall=63, gb_free=19.2, wall=1608
2023-08-04 01:14:04 | INFO | train_inner | epoch 002:    827 / 1474 loss=5.078, trans_loss=5.265, nll_loss=3.948, w2v_ctc_loss=3.198, task_loss=1.317, contrastive_loss=1.161, total=4175.4, n_correct=384.73, ppl=15.44, accuracy=9.214, wps=19566.1, ups=1.57, wpb=12471.9, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.034, clip=0, loss_scale=128, train_wall=63, gb_free=19.8, wall=1671
2023-08-04 01:15:07 | INFO | train_inner | epoch 002:    927 / 1474 loss=4.986, trans_loss=5.254, nll_loss=3.932, w2v_ctc_loss=3.104, task_loss=1.344, contrastive_loss=1.143, total=4104.2, n_correct=380.32, ppl=15.26, accuracy=9.267, wps=19436.9, ups=1.59, wpb=12253.1, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.027, clip=0, loss_scale=128, train_wall=63, gb_free=19, wall=1734
2023-08-04 01:16:11 | INFO | train_inner | epoch 002:   1027 / 1474 loss=4.901, trans_loss=5.246, nll_loss=3.926, w2v_ctc_loss=3.034, task_loss=1.305, contrastive_loss=0.996, total=4102.5, n_correct=386.65, ppl=15.2, accuracy=9.425, wps=19383.7, ups=1.58, wpb=12251.2, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.896, clip=0, loss_scale=128, train_wall=63, gb_free=19.2, wall=1798
2023-08-04 01:17:15 | INFO | train_inner | epoch 002:   1127 / 1474 loss=4.858, trans_loss=5.241, nll_loss=3.917, w2v_ctc_loss=2.943, task_loss=1.187, contrastive_loss=1.207, total=4187.61, n_correct=400.06, ppl=15.11, accuracy=9.553, wps=19288.4, ups=1.54, wpb=12495.7, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.906, clip=0, loss_scale=128, train_wall=64, gb_free=19.5, wall=1862
2023-08-04 01:18:19 | INFO | train_inner | epoch 002:   1227 / 1474 loss=4.801, trans_loss=5.229, nll_loss=3.903, w2v_ctc_loss=2.899, task_loss=1.194, contrastive_loss=1.13, total=4221.06, n_correct=416.79, ppl=14.96, accuracy=9.874, wps=19643.4, ups=1.56, wpb=12596.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.819, clip=0, loss_scale=128, train_wall=64, gb_free=19.5, wall=1927
2023-08-04 01:19:22 | INFO | train_inner | epoch 002:   1327 / 1474 loss=4.708, trans_loss=5.22, nll_loss=3.897, w2v_ctc_loss=2.864, task_loss=1.259, contrastive_loss=0.838, total=4157.86, n_correct=414.67, ppl=14.89, accuracy=9.973, wps=19781.8, ups=1.59, wpb=12425.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.777, clip=0, loss_scale=128, train_wall=62, gb_free=19.5, wall=1989
2023-08-04 01:20:26 | INFO | train_inner | epoch 002:   1427 / 1474 loss=4.671, trans_loss=5.226, nll_loss=3.904, w2v_ctc_loss=2.823, task_loss=1.414, contrastive_loss=0.927, total=4054.34, n_correct=399.85, ppl=14.97, accuracy=9.862, wps=18950.1, ups=1.57, wpb=12107, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.73, clip=0, loss_scale=128, train_wall=63, gb_free=19.4, wall=2053
2023-08-04 01:20:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 01:21:37 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.186 | trans_loss 10.244 | nll_loss 9.059 | w2v_ctc_loss 3.615 | task_loss 7.547 | contrastive_loss 0.99 | total 4003.4 | n_correct 503 | ppl 533.53 | accuracy 12.564 | uer 51.926 | wer 50.725 | raw_wer 50.725 | bleu 0.12 | wps 1113.7 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.12
2023-08-04 01:21:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-08-04 01:21:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 01:21:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 01:22:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.12) (writing took 23.476924885064363 seconds)
2023-08-04 01:22:00 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-04 01:22:00 | INFO | train | epoch 002 | loss 5.185 | trans_loss 5.276 | nll_loss 3.96 | w2v_ctc_loss 3.29 | task_loss 1.292 | contrastive_loss 1.215 | total 4138.65 | n_correct 376.539 | ppl 15.57 | accuracy 9.098 | wps 16665.5 | ups 1.35 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.127 | clip 0 | loss_scale 128 | train_wall 931 | gb_free 19.3 | wall 2147
2023-08-04 01:22:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 01:22:01 | INFO | fairseq.trainer | begin training epoch 3
2023-08-04 01:22:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 01:22:43 | INFO | train_inner | epoch 003:     53 / 1474 loss=4.596, trans_loss=5.198, nll_loss=3.868, w2v_ctc_loss=2.762, task_loss=1.324, contrastive_loss=0.827, total=4071.2, n_correct=417.72, ppl=14.6, accuracy=10.26, wps=8872.4, ups=0.73, wpb=12154.1, bsz=442.6, num_updates=3000, lr=0.00012004, gnorm=0.72, clip=0, loss_scale=128, train_wall=64, gb_free=19.1, wall=2190
2023-08-04 01:22:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-04 01:22:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 01:22:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 01:22:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-04 01:22:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-04 01:24:18 | INFO | train_inner | epoch 003:    158 / 1474 loss=3.838, trans_loss=4.389, nll_loss=2.809, w2v_ctc_loss=2.466, task_loss=0.904, contrastive_loss=0.783, total=4144.18, n_correct=1134.24, ppl=7.01, accuracy=27.369, wps=13021.9, ups=1.05, wpb=12374.6, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=2.339, clip=1, loss_scale=4, train_wall=95, gb_free=16.5, wall=2285
2023-08-04 01:25:50 | INFO | train_inner | epoch 003:    258 / 1474 loss=3.486, trans_loss=4.172, nll_loss=2.528, w2v_ctc_loss=2.27, task_loss=0.917, contrastive_loss=0.677, total=4161.13, n_correct=1389.05, ppl=5.77, accuracy=33.382, wps=13549.4, ups=1.09, wpb=12431.5, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.969, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=2377
2023-08-04 01:27:22 | INFO | train_inner | epoch 003:    358 / 1474 loss=3.364, trans_loss=4.111, nll_loss=2.443, w2v_ctc_loss=2.182, task_loss=0.921, contrastive_loss=0.699, total=4150.02, n_correct=1473.25, ppl=5.44, accuracy=35.5, wps=13476.5, ups=1.09, wpb=12384.9, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.822, clip=0, loss_scale=4, train_wall=91, gb_free=17.1, wall=2469
2023-08-04 01:28:54 | INFO | train_inner | epoch 003:    458 / 1474 loss=3.239, trans_loss=4.057, nll_loss=2.372, w2v_ctc_loss=2.098, task_loss=0.891, contrastive_loss=0.556, total=4209.57, n_correct=1577.84, ppl=5.18, accuracy=37.482, wps=13673, ups=1.09, wpb=12566, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.564, clip=0, loss_scale=4, train_wall=91, gb_free=16.1, wall=2561
2023-08-04 01:30:25 | INFO | train_inner | epoch 003:    558 / 1474 loss=3.116, trans_loss=4.024, nll_loss=2.331, w2v_ctc_loss=1.997, task_loss=0.976, contrastive_loss=0.501, total=4088.48, n_correct=1578.47, ppl=5.03, accuracy=38.608, wps=13440.3, ups=1.1, wpb=12212.5, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=1.248, clip=0, loss_scale=4, train_wall=90, gb_free=17.7, wall=2652
2023-08-04 01:31:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-04 01:31:58 | INFO | train_inner | epoch 003:    659 / 1474 loss=3.033, trans_loss=3.991, nll_loss=2.283, w2v_ctc_loss=1.931, task_loss=0.899, contrastive_loss=0.406, total=4209.07, n_correct=1687.91, ppl=4.87, accuracy=40.102, wps=13481.2, ups=1.07, wpb=12550.8, bsz=470.6, num_updates=3600, lr=0.000144028, gnorm=1.152, clip=0, loss_scale=2, train_wall=93, gb_free=15.9, wall=2745
2023-08-04 01:33:29 | INFO | train_inner | epoch 003:    759 / 1474 loss=2.966, trans_loss=3.956, nll_loss=2.242, w2v_ctc_loss=1.88, task_loss=0.882, contrastive_loss=0.369, total=4160.74, n_correct=1712.61, ppl=4.73, accuracy=41.161, wps=13646.9, ups=1.1, wpb=12428.5, bsz=469.2, num_updates=3700, lr=0.000148026, gnorm=1.154, clip=0, loss_scale=2, train_wall=91, gb_free=16.8, wall=2836
2023-08-04 01:35:00 | INFO | train_inner | epoch 003:    859 / 1474 loss=2.901, trans_loss=3.937, nll_loss=2.215, w2v_ctc_loss=1.824, task_loss=0.934, contrastive_loss=0.336, total=4160.47, n_correct=1752.32, ppl=4.64, accuracy=42.118, wps=13571.1, ups=1.09, wpb=12423.6, bsz=455.4, num_updates=3800, lr=0.000152024, gnorm=1.065, clip=0, loss_scale=2, train_wall=91, gb_free=16.3, wall=2927
2023-08-04 01:36:32 | INFO | train_inner | epoch 003:    959 / 1474 loss=2.874, trans_loss=3.92, nll_loss=2.191, w2v_ctc_loss=1.799, task_loss=0.896, contrastive_loss=0.367, total=4162.26, n_correct=1793.17, ppl=4.57, accuracy=43.082, wps=13557.3, ups=1.09, wpb=12416.1, bsz=467.9, num_updates=3900, lr=0.000156022, gnorm=1.152, clip=0, loss_scale=2, train_wall=91, gb_free=17.9, wall=3019
2023-08-04 01:38:02 | INFO | train_inner | epoch 003:   1059 / 1474 loss=2.854, trans_loss=3.907, nll_loss=2.176, w2v_ctc_loss=1.797, task_loss=0.978, contrastive_loss=0.324, total=4062.67, n_correct=1755.47, ppl=4.52, accuracy=43.21, wps=13461.5, ups=1.11, wpb=12131.7, bsz=443.2, num_updates=4000, lr=0.00016002, gnorm=1.227, clip=0, loss_scale=2, train_wall=90, gb_free=15.6, wall=3109
2023-08-04 01:38:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 01:38:37 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.113 | trans_loss 6.495 | nll_loss 4.072 | w2v_ctc_loss 2.17 | task_loss 4.295 | contrastive_loss 0.448 | total 4003.4 | n_correct 1923.1 | ppl 16.82 | accuracy 48.037 | uer 31.261 | wer 31.8 | raw_wer 31.8 | bleu 10.17 | wps 1351.1 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 10.17
2023-08-04 01:38:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-04 01:38:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_3_4000.pt
2023-08-04 01:38:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_3_4000.pt
2023-08-04 01:39:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 10.17) (writing took 40.39406237192452 seconds)
2023-08-04 01:40:48 | INFO | train_inner | epoch 003:   1159 / 1474 loss=2.794, trans_loss=3.895, nll_loss=2.159, w2v_ctc_loss=1.74, task_loss=0.99, contrastive_loss=0.298, total=4046.76, n_correct=1777.06, ppl=4.46, accuracy=43.913, wps=7283.3, ups=0.6, wpb=12078.6, bsz=433.9, num_updates=4100, lr=0.000164018, gnorm=1.048, clip=0, loss_scale=2, train_wall=90, gb_free=16.2, wall=3275
2023-08-04 01:42:18 | INFO | train_inner | epoch 003:   1259 / 1474 loss=2.742, trans_loss=3.868, nll_loss=2.126, w2v_ctc_loss=1.699, task_loss=0.976, contrastive_loss=0.276, total=4064.26, n_correct=1824.78, ppl=4.37, accuracy=44.898, wps=13463.1, ups=1.11, wpb=12137.6, bsz=434, num_updates=4200, lr=0.000168016, gnorm=0.957, clip=0, loss_scale=2, train_wall=90, gb_free=16.6, wall=3365
2023-08-04 01:43:49 | INFO | train_inner | epoch 003:   1359 / 1474 loss=2.732, trans_loss=3.855, nll_loss=2.108, w2v_ctc_loss=1.667, task_loss=0.928, contrastive_loss=0.391, total=4137.36, n_correct=1883.71, ppl=4.31, accuracy=45.529, wps=13565.7, ups=1.1, wpb=12352.2, bsz=461.5, num_updates=4300, lr=0.000172014, gnorm=1.046, clip=0, loss_scale=2, train_wall=91, gb_free=16.2, wall=3456
2023-08-04 01:45:21 | INFO | train_inner | epoch 003:   1459 / 1474 loss=2.699, trans_loss=3.842, nll_loss=2.093, w2v_ctc_loss=1.642, task_loss=0.881, contrastive_loss=0.369, total=4207.75, n_correct=1937.68, ppl=4.27, accuracy=46.05, wps=13719.7, ups=1.09, wpb=12567.9, bsz=476.7, num_updates=4400, lr=0.000176012, gnorm=0.95, clip=0, loss_scale=2, train_wall=91, gb_free=17.4, wall=3548
2023-08-04 01:45:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 01:46:06 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.926 | trans_loss 6.331 | nll_loss 3.856 | w2v_ctc_loss 1.941 | task_loss 4.179 | contrastive_loss 0.412 | total 4003.4 | n_correct 2022 | ppl 14.48 | accuracy 50.507 | uer 29.698 | wer 30.051 | raw_wer 30.051 | bleu 12.66 | wps 1432.7 | wpb 4003.4 | bsz 141.8 | num_updates 4415 | best_bleu 12.66
2023-08-04 01:46:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4415 updates
2023-08-04 01:46:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 01:46:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 01:46:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 3 @ 4415 updates, score 12.66) (writing took 24.062643637880683 seconds)
2023-08-04 01:46:30 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-04 01:46:30 | INFO | train | epoch 003 | loss 3.098 | trans_loss 4.037 | nll_loss 2.346 | w2v_ctc_loss 1.955 | task_loss 0.94 | contrastive_loss 0.47 | total 4138.48 | n_correct 1619.74 | ppl 5.08 | accuracy 39.139 | wps 12342.3 | ups 1 | wpb 12355.5 | bsz 457.9 | num_updates 4415 | lr 0.000176612 | gnorm 1.309 | clip 0.1 | loss_scale 2 | train_wall 1323 | gb_free 16.4 | wall 3617
2023-08-04 01:46:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 01:46:30 | INFO | fairseq.trainer | begin training epoch 4
2023-08-04 01:46:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 01:47:55 | INFO | train_inner | epoch 004:     85 / 1474 loss=2.618, trans_loss=3.807, nll_loss=2.043, w2v_ctc_loss=1.592, task_loss=0.962, contrastive_loss=0.22, total=4095.18, n_correct=1922.76, ppl=4.12, accuracy=46.952, wps=7920.3, ups=0.65, wpb=12222.9, bsz=437.8, num_updates=4500, lr=0.00018001, gnorm=0.903, clip=0, loss_scale=2, train_wall=90, gb_free=12.5, wall=3702
2023-08-04 01:49:25 | INFO | train_inner | epoch 004:    185 / 1474 loss=2.6, trans_loss=3.788, nll_loss=2.02, w2v_ctc_loss=1.574, task_loss=0.879, contrastive_loss=0.248, total=4178.83, n_correct=1997.54, ppl=4.06, accuracy=47.801, wps=13834.4, ups=1.11, wpb=12476.1, bsz=469.5, num_updates=4600, lr=0.000184008, gnorm=0.946, clip=0, loss_scale=2, train_wall=90, gb_free=14.7, wall=3792
2023-08-04 01:50:57 | INFO | train_inner | epoch 004:    285 / 1474 loss=2.616, trans_loss=3.792, nll_loss=2.028, w2v_ctc_loss=1.574, task_loss=0.935, contrastive_loss=0.37, total=4142.3, n_correct=1973.78, ppl=4.08, accuracy=47.649, wps=13517.9, ups=1.09, wpb=12373.8, bsz=460.7, num_updates=4700, lr=0.000188006, gnorm=0.913, clip=0, loss_scale=2, train_wall=91, gb_free=13.2, wall=3884
2023-08-04 01:52:27 | INFO | train_inner | epoch 004:    385 / 1474 loss=2.566, trans_loss=3.787, nll_loss=2.017, w2v_ctc_loss=1.544, task_loss=0.961, contrastive_loss=0.214, total=4124.92, n_correct=1984.64, ppl=4.05, accuracy=48.113, wps=13570.7, ups=1.1, wpb=12307.7, bsz=444.2, num_updates=4800, lr=0.000192004, gnorm=0.867, clip=0, loss_scale=2, train_wall=90, gb_free=12.3, wall=3975
2023-08-04 01:53:59 | INFO | train_inner | epoch 004:    485 / 1474 loss=2.602, trans_loss=3.77, nll_loss=1.999, w2v_ctc_loss=1.517, task_loss=0.841, contrastive_loss=0.621, total=4216.09, n_correct=2055.33, ppl=4, accuracy=48.75, wps=13717.4, ups=1.09, wpb=12585.8, bsz=497.6, num_updates=4900, lr=0.000196002, gnorm=0.936, clip=0, loss_scale=2, train_wall=91, gb_free=16.8, wall=4066
2023-08-04 01:55:30 | INFO | train_inner | epoch 004:    585 / 1474 loss=2.551, trans_loss=3.761, nll_loss=1.987, w2v_ctc_loss=1.525, task_loss=0.861, contrastive_loss=0.292, total=4231.12, n_correct=2079.49, ppl=3.96, accuracy=49.148, wps=13896.3, ups=1.1, wpb=12629.4, bsz=490.1, num_updates=5000, lr=0.0002, gnorm=0.879, clip=0, loss_scale=2, train_wall=90, gb_free=16, wall=4157
mt_weight tensor(1.)
asr_weight tensor(0.4782, device='cuda:0')
2023-08-04 01:57:03 | INFO | train_inner | epoch 004:    685 / 1474 loss=2.519, trans_loss=3.764, nll_loss=1.986, w2v_ctc_loss=1.487, task_loss=0.957, contrastive_loss=0.331, total=4176.95, n_correct=2059.93, ppl=3.96, accuracy=49.317, wps=13457.1, ups=1.08, wpb=12451, bsz=455.2, num_updates=5100, lr=0.00019803, gnorm=0.573, clip=0, loss_scale=2, train_wall=92, gb_free=15, wall=4250
2023-08-04 01:58:34 | INFO | train_inner | epoch 004:    785 / 1474 loss=2.509, trans_loss=3.756, nll_loss=1.981, w2v_ctc_loss=1.506, task_loss=1.024, contrastive_loss=0.203, total=4016.91, n_correct=1991.24, ppl=3.95, accuracy=49.571, wps=13140.5, ups=1.1, wpb=11995.1, bsz=418.7, num_updates=5200, lr=0.000196116, gnorm=0.592, clip=0, loss_scale=2, train_wall=91, gb_free=16.1, wall=4341
2023-08-04 02:00:06 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.53, trans_loss=3.745, nll_loss=1.967, w2v_ctc_loss=1.5, task_loss=0.928, contrastive_loss=0.384, total=4183.4, n_correct=2083.95, ppl=3.91, accuracy=49.815, wps=13594.6, ups=1.09, wpb=12493.2, bsz=465.4, num_updates=5300, lr=0.000194257, gnorm=0.614, clip=0, loss_scale=2, train_wall=91, gb_free=15.4, wall=4433
2023-08-04 02:01:37 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.481, trans_loss=3.731, nll_loss=1.95, w2v_ctc_loss=1.472, task_loss=0.942, contrastive_loss=0.252, total=4128.78, n_correct=2086.34, ppl=3.86, accuracy=50.532, wps=13513.9, ups=1.1, wpb=12332, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.571, clip=0, loss_scale=2, train_wall=91, gb_free=15.9, wall=4524
2023-08-04 02:03:08 | INFO | train_inner | epoch 004:   1085 / 1474 loss=2.481, trans_loss=3.74, nll_loss=1.96, w2v_ctc_loss=1.477, task_loss=0.994, contrastive_loss=0.225, total=4080.2, n_correct=2056.8, ppl=3.89, accuracy=50.409, wps=13358.2, ups=1.1, wpb=12179.1, bsz=437.7, num_updates=5500, lr=0.000190693, gnorm=0.555, clip=0, loss_scale=2, train_wall=91, gb_free=16.1, wall=4615
2023-08-04 02:04:39 | INFO | train_inner | epoch 004:   1185 / 1474 loss=2.485, trans_loss=3.728, nll_loss=1.948, w2v_ctc_loss=1.464, task_loss=0.865, contrastive_loss=0.34, total=4163.45, n_correct=2111.62, ppl=3.86, accuracy=50.718, wps=13682.6, ups=1.1, wpb=12436, bsz=485.6, num_updates=5600, lr=0.000188982, gnorm=0.573, clip=0, loss_scale=2, train_wall=90, gb_free=15.2, wall=4706
2023-08-04 02:06:10 | INFO | train_inner | epoch 004:   1285 / 1474 loss=2.456, trans_loss=3.717, nll_loss=1.933, w2v_ctc_loss=1.446, task_loss=0.886, contrastive_loss=0.299, total=4152.41, n_correct=2127.1, ppl=3.82, accuracy=51.226, wps=13586.1, ups=1.1, wpb=12401.3, bsz=471.4, num_updates=5700, lr=0.000187317, gnorm=0.54, clip=0, loss_scale=4, train_wall=91, gb_free=12.7, wall=4798
2023-08-04 02:07:40 | INFO | train_inner | epoch 004:   1385 / 1474 loss=2.426, trans_loss=3.716, nll_loss=1.932, w2v_ctc_loss=1.439, task_loss=0.954, contrastive_loss=0.175, total=4103.57, n_correct=2109.03, ppl=3.81, accuracy=51.395, wps=13719.7, ups=1.12, wpb=12255.2, bsz=437.9, num_updates=5800, lr=0.000185695, gnorm=0.533, clip=0, loss_scale=4, train_wall=89, gb_free=16.7, wall=4887
2023-08-04 02:09:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.4782, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.4782, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.4782, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.4782, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.4782, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.4782, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.4782, device='cuda:2')
2023-08-04 02:09:27 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.57 | trans_loss 5.968 | nll_loss 3.364 | w2v_ctc_loss 1.627 | task_loss 4.446 | contrastive_loss 0.323 | total 4003.4 | n_correct 2232.3 | ppl 10.3 | accuracy 55.76 | uer 24.771 | wer 26.319 | raw_wer 26.319 | bleu 15.91 | wps 1826.2 | wpb 4003.4 | bsz 141.8 | num_updates 5889 | best_bleu 15.91
2023-08-04 02:09:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5889 updates
2023-08-04 02:09:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 02:09:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 02:09:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 4 @ 5889 updates, score 15.91) (writing took 25.803954645991325 seconds)
2023-08-04 02:09:52 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-04 02:09:52 | INFO | train | epoch 004 | loss 2.524 | trans_loss 3.754 | nll_loss 1.978 | w2v_ctc_loss 1.502 | task_loss 0.927 | contrastive_loss 0.297 | total 4138.65 | n_correct 2050.49 | ppl 3.94 | accuracy 49.545 | wps 12987.3 | ups 1.05 | wpb 12355.8 | bsz 458.5 | num_updates 5889 | lr 0.000184287 | gnorm 0.702 | clip 0 | loss_scale 4 | train_wall 1335 | gb_free 14.8 | wall 5019
2023-08-04 02:09:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 02:09:53 | INFO | fairseq.trainer | begin training epoch 5
2023-08-04 02:09:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 02:10:11 | INFO | train_inner | epoch 005:     11 / 1474 loss=2.407, trans_loss=3.704, nll_loss=1.916, w2v_ctc_loss=1.412, task_loss=0.972, contrastive_loss=0.195, total=4031.51, n_correct=2086.57, ppl=3.77, accuracy=51.757, wps=7967.5, ups=0.66, wpb=12037.5, bsz=436.7, num_updates=5900, lr=0.000184115, gnorm=0.542, clip=0, loss_scale=4, train_wall=90, gb_free=14.2, wall=5038
2023-08-04 02:11:42 | INFO | train_inner | epoch 005:    111 / 1474 loss=2.337, trans_loss=3.647, nll_loss=1.842, w2v_ctc_loss=1.335, task_loss=0.832, contrastive_loss=0.217, total=4256.63, n_correct=2271.82, ppl=3.59, accuracy=53.371, wps=13902.6, ups=1.09, wpb=12710, bsz=500.1, num_updates=6000, lr=0.000182574, gnorm=0.512, clip=0, loss_scale=4, train_wall=91, gb_free=16.1, wall=5129
2023-08-04 02:11:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 02:12:10 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.554 | trans_loss 5.955 | nll_loss 3.345 | w2v_ctc_loss 1.602 | task_loss 4.411 | contrastive_loss 0.329 | total 4003.4 | n_correct 2235.6 | ppl 10.16 | accuracy 55.843 | uer 24.277 | wer 25.875 | raw_wer 25.875 | bleu 16 | wps 1568.6 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16
2023-08-04 02:12:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-04 02:12:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_5_6000.pt
2023-08-04 02:12:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_5_6000.pt
2023-08-04 02:12:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.0) (writing took 43.565816055983305 seconds)
2023-08-04 02:14:24 | INFO | train_inner | epoch 005:    211 / 1474 loss=2.368, trans_loss=3.658, nll_loss=1.853, w2v_ctc_loss=1.348, task_loss=0.863, contrastive_loss=0.412, total=4186.83, n_correct=2229.87, ppl=3.61, accuracy=53.259, wps=7702.1, ups=0.62, wpb=12492.2, bsz=485.3, num_updates=6100, lr=0.000181071, gnorm=0.52, clip=0, loss_scale=4, train_wall=90, gb_free=16.1, wall=5292
2023-08-04 02:15:54 | INFO | train_inner | epoch 005:    311 / 1474 loss=2.359, trans_loss=3.652, nll_loss=1.85, w2v_ctc_loss=1.367, task_loss=0.951, contrastive_loss=0.271, total=4094.07, n_correct=2173.85, ppl=3.6, accuracy=53.098, wps=13610.7, ups=1.11, wpb=12241.2, bsz=446, num_updates=6200, lr=0.000179605, gnorm=0.529, clip=0, loss_scale=4, train_wall=89, gb_free=16.1, wall=5381
2023-08-04 02:17:26 | INFO | train_inner | epoch 005:    411 / 1474 loss=2.35, trans_loss=3.647, nll_loss=1.844, w2v_ctc_loss=1.332, task_loss=0.91, contrastive_loss=0.355, total=4140.39, n_correct=2211.57, ppl=3.59, accuracy=53.415, wps=13547.2, ups=1.09, wpb=12372.8, bsz=467.9, num_updates=6300, lr=0.000178174, gnorm=0.529, clip=0, loss_scale=4, train_wall=91, gb_free=16, wall=5473
2023-08-04 02:18:56 | INFO | train_inner | epoch 005:    511 / 1474 loss=2.321, trans_loss=3.655, nll_loss=1.853, w2v_ctc_loss=1.341, task_loss=1.038, contrastive_loss=0.148, total=4026.21, n_correct=2143.83, ppl=3.61, accuracy=53.247, wps=13270.5, ups=1.1, wpb=12028.8, bsz=418.1, num_updates=6400, lr=0.000176777, gnorm=0.528, clip=0, loss_scale=4, train_wall=90, gb_free=17, wall=5563
2023-08-04 02:20:28 | INFO | train_inner | epoch 005:    611 / 1474 loss=2.339, trans_loss=3.661, nll_loss=1.857, w2v_ctc_loss=1.327, task_loss=0.959, contrastive_loss=0.324, total=4109.94, n_correct=2191.86, ppl=3.62, accuracy=53.331, wps=13380.1, ups=1.09, wpb=12260.2, bsz=449.8, num_updates=6500, lr=0.000175412, gnorm=0.523, clip=0, loss_scale=4, train_wall=91, gb_free=15.4, wall=5655
2023-08-04 02:21:59 | INFO | train_inner | epoch 005:    711 / 1474 loss=2.336, trans_loss=3.652, nll_loss=1.849, w2v_ctc_loss=1.326, task_loss=0.874, contrastive_loss=0.303, total=4176.83, n_correct=2238.58, ppl=3.6, accuracy=53.595, wps=13680.9, ups=1.1, wpb=12467.5, bsz=483.6, num_updates=6600, lr=0.000174078, gnorm=0.519, clip=0, loss_scale=4, train_wall=91, gb_free=17, wall=5746
2023-08-04 02:23:31 | INFO | train_inner | epoch 005:    811 / 1474 loss=2.319, trans_loss=3.654, nll_loss=1.85, w2v_ctc_loss=1.323, task_loss=0.962, contrastive_loss=0.225, total=4127.9, n_correct=2213.97, ppl=3.6, accuracy=53.634, wps=13451.3, ups=1.09, wpb=12321.2, bsz=447.5, num_updates=6700, lr=0.000172774, gnorm=0.518, clip=0, loss_scale=4, train_wall=91, gb_free=15.7, wall=5838
2023-08-04 02:25:02 | INFO | train_inner | epoch 005:    911 / 1474 loss=2.296, trans_loss=3.643, nll_loss=1.838, w2v_ctc_loss=1.309, task_loss=0.954, contrastive_loss=0.187, total=4101.19, n_correct=2214.54, ppl=3.57, accuracy=53.997, wps=13474.5, ups=1.1, wpb=12245.9, bsz=447.9, num_updates=6800, lr=0.000171499, gnorm=0.512, clip=0, loss_scale=4, train_wall=90, gb_free=17.2, wall=5929
2023-08-04 02:26:33 | INFO | train_inner | epoch 005:   1011 / 1474 loss=2.307, trans_loss=3.645, nll_loss=1.84, w2v_ctc_loss=1.31, task_loss=0.921, contrastive_loss=0.268, total=4164.27, n_correct=2250.77, ppl=3.58, accuracy=54.05, wps=13672.7, ups=1.1, wpb=12430.2, bsz=462, num_updates=6900, lr=0.000170251, gnorm=0.501, clip=0, loss_scale=4, train_wall=90, gb_free=14.9, wall=6020
2023-08-04 02:28:04 | INFO | train_inner | epoch 005:   1111 / 1474 loss=2.319, trans_loss=3.647, nll_loss=1.841, w2v_ctc_loss=1.319, task_loss=0.928, contrastive_loss=0.272, total=4168.94, n_correct=2253.21, ppl=3.58, accuracy=54.048, wps=13578.8, ups=1.09, wpb=12436.1, bsz=464.1, num_updates=7000, lr=0.000169031, gnorm=0.511, clip=0, loss_scale=4, train_wall=91, gb_free=16.6, wall=6111
2023-08-04 02:29:36 | INFO | train_inner | epoch 005:   1211 / 1474 loss=2.28, trans_loss=3.642, nll_loss=1.835, w2v_ctc_loss=1.294, task_loss=0.943, contrastive_loss=0.173, total=4171.16, n_correct=2265.78, ppl=3.57, accuracy=54.32, wps=13616.2, ups=1.09, wpb=12443.2, bsz=456.3, num_updates=7100, lr=0.000167836, gnorm=0.507, clip=0, loss_scale=4, train_wall=91, gb_free=15.8, wall=6203
2023-08-04 02:31:07 | INFO | train_inner | epoch 005:   1311 / 1474 loss=2.263, trans_loss=3.638, nll_loss=1.832, w2v_ctc_loss=1.281, task_loss=0.948, contrastive_loss=0.138, total=4126.97, n_correct=2243.74, ppl=3.56, accuracy=54.368, wps=13494, ups=1.1, wpb=12317.9, bsz=443.4, num_updates=7200, lr=0.000166667, gnorm=0.5, clip=0, loss_scale=4, train_wall=91, gb_free=15.4, wall=6294
2023-08-04 02:32:38 | INFO | train_inner | epoch 005:   1411 / 1474 loss=2.273, trans_loss=3.639, nll_loss=1.835, w2v_ctc_loss=1.278, task_loss=0.937, contrastive_loss=0.209, total=4138.54, n_correct=2251.64, ppl=3.57, accuracy=54.407, wps=13590.2, ups=1.1, wpb=12359.3, bsz=459, num_updates=7300, lr=0.000165521, gnorm=0.504, clip=0, loss_scale=4, train_wall=90, gb_free=16.7, wall=6385
2023-08-04 02:33:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 02:33:59 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.44 | trans_loss 5.854 | nll_loss 3.219 | w2v_ctc_loss 1.447 | task_loss 4.446 | contrastive_loss 0.329 | total 4003.4 | n_correct 2298.5 | ppl 9.31 | accuracy 57.414 | uer 22.523 | wer 24.25 | raw_wer 24.25 | bleu 17.22 | wps 2170.3 | wpb 4003.4 | bsz 141.8 | num_updates 7363 | best_bleu 17.22
2023-08-04 02:33:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7363 updates
2023-08-04 02:33:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 02:34:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 02:34:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 5 @ 7363 updates, score 17.22) (writing took 25.603585904464126 seconds)
2023-08-04 02:34:24 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-04 02:34:24 | INFO | train | epoch 005 | loss 2.318 | trans_loss 3.648 | nll_loss 1.843 | w2v_ctc_loss 1.32 | task_loss 0.929 | contrastive_loss 0.25 | total 4138.65 | n_correct 2224.62 | ppl 3.59 | accuracy 53.752 | wps 12374.5 | ups 1 | wpb 12355.8 | bsz 458.5 | num_updates 7363 | lr 0.000164812 | gnorm 0.516 | clip 0 | loss_scale 4 | train_wall 1335 | gb_free 16.2 | wall 6491
2023-08-04 02:34:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 02:34:24 | INFO | fairseq.trainer | begin training epoch 6
2023-08-04 02:34:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 02:35:05 | INFO | train_inner | epoch 006:     37 / 1474 loss=2.261, trans_loss=3.616, nll_loss=1.802, w2v_ctc_loss=1.276, task_loss=0.955, contrastive_loss=0.204, total=4113.87, n_correct=2262.11, ppl=3.49, accuracy=54.987, wps=8325, ups=0.68, wpb=12276.7, bsz=447.4, num_updates=7400, lr=0.000164399, gnorm=0.522, clip=0, loss_scale=4, train_wall=91, gb_free=17.8, wall=6532
2023-08-04 02:36:36 | INFO | train_inner | epoch 006:    137 / 1474 loss=2.214, trans_loss=3.581, nll_loss=1.758, w2v_ctc_loss=1.221, task_loss=0.919, contrastive_loss=0.245, total=4161.2, n_correct=2320.71, ppl=3.38, accuracy=55.77, wps=13742.6, ups=1.11, wpb=12428.5, bsz=458.1, num_updates=7500, lr=0.000163299, gnorm=0.506, clip=0, loss_scale=4, train_wall=90, gb_free=16.8, wall=6623
2023-08-04 02:38:07 | INFO | train_inner | epoch 006:    237 / 1474 loss=2.226, trans_loss=3.594, nll_loss=1.775, w2v_ctc_loss=1.255, task_loss=0.996, contrastive_loss=0.154, total=4110.12, n_correct=2276.43, ppl=3.42, accuracy=55.386, wps=13505.2, ups=1.1, wpb=12279.2, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.5, clip=0, loss_scale=4, train_wall=90, gb_free=17.1, wall=6714
2023-08-04 02:39:39 | INFO | train_inner | epoch 006:    337 / 1474 loss=2.237, trans_loss=3.584, nll_loss=1.763, w2v_ctc_loss=1.204, task_loss=0.874, contrastive_loss=0.461, total=4170.52, n_correct=2327.23, ppl=3.39, accuracy=55.802, wps=13485.7, ups=1.08, wpb=12453.1, bsz=488.4, num_updates=7700, lr=0.000161165, gnorm=0.515, clip=0, loss_scale=8, train_wall=92, gb_free=15.6, wall=6806
2023-08-04 02:41:09 | INFO | train_inner | epoch 006:    437 / 1474 loss=2.196, trans_loss=3.585, nll_loss=1.764, w2v_ctc_loss=1.213, task_loss=0.893, contrastive_loss=0.17, total=4154.89, n_correct=2327.43, ppl=3.4, accuracy=56.017, wps=13795.8, ups=1.11, wpb=12405.6, bsz=470.4, num_updates=7800, lr=0.000160128, gnorm=0.495, clip=0, loss_scale=8, train_wall=89, gb_free=16.4, wall=6896
2023-08-04 02:42:40 | INFO | train_inner | epoch 006:    537 / 1474 loss=2.201, trans_loss=3.59, nll_loss=1.769, w2v_ctc_loss=1.224, task_loss=0.924, contrastive_loss=0.155, total=4174.46, n_correct=2337.87, ppl=3.41, accuracy=56.004, wps=13714.3, ups=1.1, wpb=12460.1, bsz=458.3, num_updates=7900, lr=0.000159111, gnorm=0.496, clip=0, loss_scale=8, train_wall=90, gb_free=17.2, wall=6987
2023-08-04 02:44:11 | INFO | train_inner | epoch 006:    637 / 1474 loss=2.2, trans_loss=3.592, nll_loss=1.773, w2v_ctc_loss=1.207, task_loss=0.884, contrastive_loss=0.213, total=4145.19, n_correct=2317.99, ppl=3.42, accuracy=55.92, wps=13580.1, ups=1.1, wpb=12372.7, bsz=470.9, num_updates=8000, lr=0.000158114, gnorm=0.499, clip=0, loss_scale=8, train_wall=91, gb_free=15.8, wall=7078
2023-08-04 02:44:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 02:44:34 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.411 | trans_loss 5.804 | nll_loss 3.147 | w2v_ctc_loss 1.482 | task_loss 4.468 | contrastive_loss 0.306 | total 4003.4 | n_correct 2323.7 | ppl 8.86 | accuracy 58.043 | uer 21.596 | wer 23.362 | raw_wer 23.362 | bleu 17.46 | wps 2156.3 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.46
2023-08-04 02:44:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-04 02:44:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_6_8000.pt
2023-08-04 02:44:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_6_8000.pt
2023-08-04 02:45:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.46) (writing took 26.998224154114723 seconds)
2023-08-04 02:46:32 | INFO | train_inner | epoch 006:    737 / 1474 loss=2.204, trans_loss=3.595, nll_loss=1.776, w2v_ctc_loss=1.224, task_loss=0.949, contrastive_loss=0.166, total=4151.01, n_correct=2320.76, ppl=3.43, accuracy=55.908, wps=8765.4, ups=0.71, wpb=12393.7, bsz=454.2, num_updates=8100, lr=0.000157135, gnorm=0.495, clip=0, loss_scale=8, train_wall=91, gb_free=12.9, wall=7219
2023-08-04 02:48:04 | INFO | train_inner | epoch 006:    837 / 1474 loss=2.199, trans_loss=3.603, nll_loss=1.787, w2v_ctc_loss=1.218, task_loss=0.984, contrastive_loss=0.147, total=4108.83, n_correct=2288.1, ppl=3.45, accuracy=55.687, wps=13432.4, ups=1.09, wpb=12267.1, bsz=439.4, num_updates=8200, lr=0.000156174, gnorm=0.497, clip=0, loss_scale=8, train_wall=91, gb_free=17.1, wall=7311
2023-08-04 02:49:34 | INFO | train_inner | epoch 006:    937 / 1474 loss=2.215, trans_loss=3.602, nll_loss=1.786, w2v_ctc_loss=1.221, task_loss=0.977, contrastive_loss=0.244, total=4076.46, n_correct=2275.98, ppl=3.45, accuracy=55.832, wps=13418.6, ups=1.1, wpb=12166, bsz=443, num_updates=8300, lr=0.00015523, gnorm=0.502, clip=0, loss_scale=8, train_wall=90, gb_free=12.5, wall=7401
2023-08-04 02:51:05 | INFO | train_inner | epoch 006:   1037 / 1474 loss=2.203, trans_loss=3.586, nll_loss=1.767, w2v_ctc_loss=1.198, task_loss=0.872, contrastive_loss=0.319, total=4175.9, n_correct=2344.45, ppl=3.4, accuracy=56.142, wps=13680.1, ups=1.1, wpb=12465, bsz=480.4, num_updates=8400, lr=0.000154303, gnorm=0.505, clip=0, loss_scale=8, train_wall=91, gb_free=14.1, wall=7492
2023-08-04 02:52:36 | INFO | train_inner | epoch 006:   1137 / 1474 loss=2.192, trans_loss=3.592, nll_loss=1.773, w2v_ctc_loss=1.213, task_loss=1.022, contrastive_loss=0.152, total=4077.2, n_correct=2284.29, ppl=3.42, accuracy=56.026, wps=13380.5, ups=1.1, wpb=12172.7, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.499, clip=0, loss_scale=8, train_wall=90, gb_free=16.2, wall=7583
2023-08-04 02:54:08 | INFO | train_inner | epoch 006:   1237 / 1474 loss=2.224, trans_loss=3.586, nll_loss=1.769, w2v_ctc_loss=1.198, task_loss=0.916, contrastive_loss=0.468, total=4133.46, n_correct=2321.23, ppl=3.41, accuracy=56.157, wps=13509.2, ups=1.09, wpb=12346.4, bsz=470.3, num_updates=8600, lr=0.000152499, gnorm=0.507, clip=0, loss_scale=8, train_wall=91, gb_free=12.2, wall=7675
2023-08-04 02:55:38 | INFO | train_inner | epoch 006:   1337 / 1474 loss=2.171, trans_loss=3.591, nll_loss=1.771, w2v_ctc_loss=1.194, task_loss=0.922, contrastive_loss=0.135, total=4127.77, n_correct=2323.07, ppl=3.41, accuracy=56.279, wps=13682, ups=1.11, wpb=12312.7, bsz=454.1, num_updates=8700, lr=0.00015162, gnorm=0.491, clip=0, loss_scale=8, train_wall=90, gb_free=17, wall=7765
2023-08-04 02:57:10 | INFO | train_inner | epoch 006:   1437 / 1474 loss=2.171, trans_loss=3.583, nll_loss=1.763, w2v_ctc_loss=1.195, task_loss=0.935, contrastive_loss=0.143, total=4190.32, n_correct=2370.1, ppl=3.39, accuracy=56.561, wps=13625, ups=1.09, wpb=12507.6, bsz=460.5, num_updates=8800, lr=0.000150756, gnorm=0.491, clip=0, loss_scale=8, train_wall=91, gb_free=16.8, wall=7857
2023-08-04 02:57:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 02:58:05 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.355 | trans_loss 5.763 | nll_loss 3.097 | w2v_ctc_loss 1.394 | task_loss 4.535 | contrastive_loss 0.29 | total 4003.4 | n_correct 2349.6 | ppl 8.55 | accuracy 58.69 | uer 20.322 | wer 22.083 | raw_wer 22.083 | bleu 18.16 | wps 1973.2 | wpb 4003.4 | bsz 141.8 | num_updates 8837 | best_bleu 18.16
2023-08-04 02:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8837 updates
2023-08-04 02:58:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 02:58:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 02:58:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 6 @ 8837 updates, score 18.16) (writing took 26.83946337737143 seconds)
2023-08-04 02:58:32 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-04 02:58:32 | INFO | train | epoch 006 | loss 2.203 | trans_loss 3.59 | nll_loss 1.77 | w2v_ctc_loss 1.213 | task_loss 0.93 | contrastive_loss 0.226 | total 4138.65 | n_correct 2316.75 | ppl 3.41 | accuracy 55.978 | wps 12576 | ups 1.02 | wpb 12355.8 | bsz 458.5 | num_updates 8837 | lr 0.00015044 | gnorm 0.5 | clip 0 | loss_scale 8 | train_wall 1334 | gb_free 15.1 | wall 7939
2023-08-04 02:58:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 02:58:33 | INFO | fairseq.trainer | begin training epoch 7
2023-08-04 02:58:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 02:59:38 | INFO | train_inner | epoch 007:     63 / 1474 loss=2.138, trans_loss=3.559, nll_loss=1.732, w2v_ctc_loss=1.16, task_loss=0.906, contrastive_loss=0.16, total=4110.43, n_correct=2347.54, ppl=3.32, accuracy=57.112, wps=8285.4, ups=0.68, wpb=12272.9, bsz=462.8, num_updates=8900, lr=0.000149906, gnorm=0.494, clip=0, loss_scale=8, train_wall=90, gb_free=17.3, wall=8005
2023-08-04 03:01:08 | INFO | train_inner | epoch 007:    163 / 1474 loss=2.138, trans_loss=3.549, nll_loss=1.718, w2v_ctc_loss=1.15, task_loss=0.946, contrastive_loss=0.231, total=4109.53, n_correct=2352.5, ppl=3.29, accuracy=57.245, wps=13570.5, ups=1.11, wpb=12269.6, bsz=454.1, num_updates=9000, lr=0.000149071, gnorm=0.494, clip=0, loss_scale=8, train_wall=90, gb_free=13.5, wall=8095
2023-08-04 03:02:39 | INFO | train_inner | epoch 007:    263 / 1474 loss=2.121, trans_loss=3.544, nll_loss=1.71, w2v_ctc_loss=1.15, task_loss=0.93, contrastive_loss=0.138, total=4133.29, n_correct=2379.13, ppl=3.27, accuracy=57.56, wps=13607.4, ups=1.1, wpb=12335.8, bsz=455.5, num_updates=9100, lr=0.00014825, gnorm=0.494, clip=0, loss_scale=8, train_wall=90, gb_free=15.2, wall=8186
2023-08-04 03:04:11 | INFO | train_inner | epoch 007:    363 / 1474 loss=2.156, trans_loss=3.552, nll_loss=1.722, w2v_ctc_loss=1.143, task_loss=0.906, contrastive_loss=0.404, total=4194.76, n_correct=2404.96, ppl=3.3, accuracy=57.332, wps=13607.8, ups=1.09, wpb=12518.2, bsz=477.6, num_updates=9200, lr=0.000147442, gnorm=0.495, clip=0, loss_scale=8, train_wall=91, gb_free=12.9, wall=8278
2023-08-04 03:05:42 | INFO | train_inner | epoch 007:    463 / 1474 loss=2.143, trans_loss=3.552, nll_loss=1.724, w2v_ctc_loss=1.14, task_loss=0.921, contrastive_loss=0.321, total=4153.22, n_correct=2380.01, ppl=3.3, accuracy=57.305, wps=13650.5, ups=1.1, wpb=12403.3, bsz=463, num_updates=9300, lr=0.000146647, gnorm=0.491, clip=0, loss_scale=8, train_wall=90, gb_free=16.8, wall=8369
2023-08-04 03:07:12 | INFO | train_inner | epoch 007:    563 / 1474 loss=2.118, trans_loss=3.552, nll_loss=1.72, w2v_ctc_loss=1.141, task_loss=0.911, contrastive_loss=0.147, total=4168.14, n_correct=2398.38, ppl=3.29, accuracy=57.541, wps=13796.4, ups=1.11, wpb=12434.7, bsz=459.8, num_updates=9400, lr=0.000145865, gnorm=0.491, clip=0, loss_scale=8, train_wall=90, gb_free=16.8, wall=8459
2023-08-04 03:08:43 | INFO | train_inner | epoch 007:    663 / 1474 loss=2.112, trans_loss=3.55, nll_loss=1.718, w2v_ctc_loss=1.136, task_loss=0.924, contrastive_loss=0.133, total=4157.82, n_correct=2397.41, ppl=3.29, accuracy=57.66, wps=13620.3, ups=1.1, wpb=12406.4, bsz=455.4, num_updates=9500, lr=0.000145095, gnorm=0.49, clip=0, loss_scale=8, train_wall=91, gb_free=15.5, wall=8550
2023-08-04 03:10:14 | INFO | train_inner | epoch 007:    763 / 1474 loss=2.113, trans_loss=3.548, nll_loss=1.717, w2v_ctc_loss=1.137, task_loss=0.974, contrastive_loss=0.129, total=4122.1, n_correct=2368.97, ppl=3.29, accuracy=57.47, wps=13521.7, ups=1.1, wpb=12308.4, bsz=446.2, num_updates=9600, lr=0.000144338, gnorm=0.49, clip=0, loss_scale=8, train_wall=91, gb_free=15.6, wall=8641
2023-08-04 03:11:45 | INFO | train_inner | epoch 007:    863 / 1474 loss=2.117, trans_loss=3.556, nll_loss=1.728, w2v_ctc_loss=1.139, task_loss=0.938, contrastive_loss=0.152, total=4147.23, n_correct=2378.31, ppl=3.31, accuracy=57.347, wps=13571.2, ups=1.1, wpb=12377.6, bsz=460.9, num_updates=9700, lr=0.000143592, gnorm=0.495, clip=0, loss_scale=8, train_wall=91, gb_free=17.5, wall=8732
2023-08-04 03:13:16 | INFO | train_inner | epoch 007:    963 / 1474 loss=2.121, trans_loss=3.549, nll_loss=1.72, w2v_ctc_loss=1.126, task_loss=0.886, contrastive_loss=0.248, total=4140.14, n_correct=2386.8, ppl=3.29, accuracy=57.65, wps=13561.7, ups=1.1, wpb=12359.1, bsz=474.6, num_updates=9800, lr=0.000142857, gnorm=0.492, clip=0, loss_scale=16, train_wall=91, gb_free=15.9, wall=8823
2023-08-04 03:14:47 | INFO | train_inner | epoch 007:   1063 / 1474 loss=2.114, trans_loss=3.562, nll_loss=1.737, w2v_ctc_loss=1.142, task_loss=0.977, contrastive_loss=0.113, total=4103.51, n_correct=2352.21, ppl=3.33, accuracy=57.322, wps=13475.2, ups=1.1, wpb=12251.1, bsz=437.5, num_updates=9900, lr=0.000142134, gnorm=0.493, clip=0, loss_scale=16, train_wall=90, gb_free=16.8, wall=8914
2023-08-04 03:16:19 | INFO | train_inner | epoch 007:   1163 / 1474 loss=2.148, trans_loss=3.548, nll_loss=1.722, w2v_ctc_loss=1.132, task_loss=0.906, contrastive_loss=0.384, total=4137.04, n_correct=2383.83, ppl=3.3, accuracy=57.622, wps=13515, ups=1.09, wpb=12361.6, bsz=470.9, num_updates=10000, lr=0.000141421, gnorm=0.5, clip=0, loss_scale=16, train_wall=91, gb_free=15.9, wall=9006
2023-08-04 03:16:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 03:16:41 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.306 | trans_loss 5.714 | nll_loss 3.036 | w2v_ctc_loss 1.345 | task_loss 4.574 | contrastive_loss 0.286 | total 4003.4 | n_correct 2380.5 | ppl 8.2 | accuracy 59.462 | uer 19.194 | wer 20.998 | raw_wer 20.998 | bleu 19.04 | wps 2287 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 19.04
2023-08-04 03:16:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-04 03:16:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_7_10000.pt
2023-08-04 03:16:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_7_10000.pt
2023-08-04 03:17:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 19.04) (writing took 26.822437377646565 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:0')
2023-08-04 03:18:39 | INFO | train_inner | epoch 007:   1263 / 1474 loss=2.103, trans_loss=3.553, nll_loss=1.727, w2v_ctc_loss=1.125, task_loss=0.941, contrastive_loss=0.143, total=4129.52, n_correct=2375.02, ppl=3.31, accuracy=57.513, wps=8798, ups=0.71, wpb=12331.4, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.408, clip=0, loss_scale=16, train_wall=89, gb_free=16.7, wall=9146
2023-08-04 03:20:09 | INFO | train_inner | epoch 007:   1363 / 1474 loss=2.117, trans_loss=3.547, nll_loss=1.718, w2v_ctc_loss=1.135, task_loss=0.874, contrastive_loss=0.182, total=4172.87, n_correct=2413.39, ppl=3.29, accuracy=57.835, wps=13794.4, ups=1.11, wpb=12458.1, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.409, clip=0, loss_scale=16, train_wall=90, gb_free=17.2, wall=9236
2023-08-04 03:21:41 | INFO | train_inner | epoch 007:   1463 / 1474 loss=2.127, trans_loss=3.553, nll_loss=1.729, w2v_ctc_loss=1.135, task_loss=1.003, contrastive_loss=0.245, total=4109.42, n_correct=2359.17, ppl=3.32, accuracy=57.409, wps=13337.7, ups=1.09, wpb=12278.1, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.418, clip=0, loss_scale=16, train_wall=92, gb_free=16.4, wall=9328
2023-08-04 03:21:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:3')
2023-08-04 03:22:15 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.308 | trans_loss 5.715 | nll_loss 3.034 | w2v_ctc_loss 1.352 | task_loss 4.599 | contrastive_loss 0.287 | total 4003.4 | n_correct 2372.1 | ppl 8.19 | accuracy 59.252 | uer 19.529 | wer 21.371 | raw_wer 21.371 | bleu 18.7 | wps 1987 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 19.04
2023-08-04 03:22:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-08-04 03:22:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_18.7000.pt
2023-08-04 03:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_18.7000.pt
2023-08-04 03:22:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_18.7000.pt (epoch 7 @ 10311 updates, score 18.7) (writing took 13.47885075211525 seconds)
2023-08-04 03:22:29 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-04 03:22:29 | INFO | train | epoch 007 | loss 2.125 | trans_loss 3.551 | nll_loss 1.722 | w2v_ctc_loss 1.138 | task_loss 0.931 | contrastive_loss 0.211 | total 4138.65 | n_correct 2379.2 | ppl 3.3 | accuracy 57.487 | wps 12676.1 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 10311 | lr 0.000139272 | gnorm 0.476 | clip 0 | loss_scale 16 | train_wall 1333 | gb_free 13.1 | wall 9376
2023-08-04 03:22:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 03:22:29 | INFO | fairseq.trainer | begin training epoch 8
2023-08-04 03:22:29 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 03:23:58 | INFO | train_inner | epoch 008:     89 / 1474 loss=2.071, trans_loss=3.527, nll_loss=1.687, w2v_ctc_loss=1.096, task_loss=0.982, contrastive_loss=0.139, total=4116.25, n_correct=2400.87, ppl=3.22, accuracy=58.327, wps=8994.4, ups=0.73, wpb=12273, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.408, clip=0, loss_scale=16, train_wall=90, gb_free=16.9, wall=9465
2023-08-04 03:25:28 | INFO | train_inner | epoch 008:    189 / 1474 loss=2.069, trans_loss=3.518, nll_loss=1.676, w2v_ctc_loss=1.091, task_loss=1.006, contrastive_loss=0.158, total=4037.23, n_correct=2363.78, ppl=3.19, accuracy=58.55, wps=13341.4, ups=1.11, wpb=12041.5, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.415, clip=0, loss_scale=16, train_wall=90, gb_free=12.6, wall=9555
2023-08-04 03:26:58 | INFO | train_inner | epoch 008:    289 / 1474 loss=2.066, trans_loss=3.514, nll_loss=1.674, w2v_ctc_loss=1.089, task_loss=0.874, contrastive_loss=0.16, total=4207.78, n_correct=2473.3, ppl=3.19, accuracy=58.779, wps=13906.4, ups=1.11, wpb=12556.5, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.415, clip=0, loss_scale=16, train_wall=90, gb_free=12.8, wall=9645
2023-08-04 03:28:30 | INFO | train_inner | epoch 008:    389 / 1474 loss=2.084, trans_loss=3.523, nll_loss=1.684, w2v_ctc_loss=1.108, task_loss=0.993, contrastive_loss=0.179, total=4127.24, n_correct=2409.54, ppl=3.21, accuracy=58.381, wps=13466.5, ups=1.09, wpb=12316.2, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.414, clip=0, loss_scale=16, train_wall=91, gb_free=11.6, wall=9737
2023-08-04 03:30:01 | INFO | train_inner | epoch 008:    489 / 1474 loss=2.11, trans_loss=3.517, nll_loss=1.68, w2v_ctc_loss=1.081, task_loss=0.834, contrastive_loss=0.444, total=4203.76, n_correct=2461.75, ppl=3.2, accuracy=58.561, wps=13703.9, ups=1.09, wpb=12548.2, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.41, clip=0, loss_scale=16, train_wall=91, gb_free=14.5, wall=9828
2023-08-04 03:31:32 | INFO | train_inner | epoch 008:    589 / 1474 loss=2.074, trans_loss=3.522, nll_loss=1.688, w2v_ctc_loss=1.108, task_loss=1.018, contrastive_loss=0.114, total=4062.5, n_correct=2366.07, ppl=3.22, accuracy=58.242, wps=13306.9, ups=1.1, wpb=12145.4, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.415, clip=0, loss_scale=16, train_wall=91, gb_free=11.1, wall=9920
2023-08-04 03:33:04 | INFO | train_inner | epoch 008:    689 / 1474 loss=2.066, trans_loss=3.516, nll_loss=1.677, w2v_ctc_loss=1.101, task_loss=0.961, contrastive_loss=0.125, total=4142.78, n_correct=2432.03, ppl=3.2, accuracy=58.705, wps=13537, ups=1.09, wpb=12364.4, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.414, clip=0, loss_scale=16, train_wall=91, gb_free=15.8, wall=10011
2023-08-04 03:34:35 | INFO | train_inner | epoch 008:    789 / 1474 loss=2.076, trans_loss=3.516, nll_loss=1.681, w2v_ctc_loss=1.096, task_loss=0.955, contrastive_loss=0.21, total=4118.9, n_correct=2412.51, ppl=3.21, accuracy=58.572, wps=13494.8, ups=1.1, wpb=12310.9, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.411, clip=0, loss_scale=16, train_wall=91, gb_free=15.1, wall=10102
2023-08-04 03:36:06 | INFO | train_inner | epoch 008:    889 / 1474 loss=2.07, trans_loss=3.518, nll_loss=1.683, w2v_ctc_loss=1.082, task_loss=0.895, contrastive_loss=0.222, total=4169.01, n_correct=2449.48, ppl=3.21, accuracy=58.754, wps=13678.1, ups=1.1, wpb=12452.5, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.411, clip=0, loss_scale=16, train_wall=90, gb_free=16, wall=10193
2023-08-04 03:37:36 | INFO | train_inner | epoch 008:    989 / 1474 loss=2.053, trans_loss=3.52, nll_loss=1.684, w2v_ctc_loss=1.081, task_loss=0.893, contrastive_loss=0.122, total=4154.69, n_correct=2441.8, ppl=3.21, accuracy=58.772, wps=13764.3, ups=1.11, wpb=12403.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.409, clip=0, loss_scale=16, train_wall=90, gb_free=17.7, wall=10283
2023-08-04 03:39:08 | INFO | train_inner | epoch 008:   1089 / 1474 loss=2.084, trans_loss=3.526, nll_loss=1.692, w2v_ctc_loss=1.082, task_loss=0.926, contrastive_loss=0.346, total=4199.1, n_correct=2453.15, ppl=3.23, accuracy=58.421, wps=13723.1, ups=1.09, wpb=12534.3, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.41, clip=0, loss_scale=16, train_wall=91, gb_free=12.5, wall=10375
2023-08-04 03:40:38 | INFO | train_inner | epoch 008:   1189 / 1474 loss=2.059, trans_loss=3.519, nll_loss=1.684, w2v_ctc_loss=1.086, task_loss=0.88, contrastive_loss=0.131, total=4177.31, n_correct=2453.95, ppl=3.21, accuracy=58.745, wps=13799.9, ups=1.11, wpb=12476.3, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.407, clip=0, loss_scale=16, train_wall=90, gb_free=14.8, wall=10465
2023-08-04 03:42:08 | INFO | train_inner | epoch 008:   1289 / 1474 loss=2.07, trans_loss=3.524, nll_loss=1.691, w2v_ctc_loss=1.097, task_loss=0.972, contrastive_loss=0.154, total=4063.85, n_correct=2371.83, ppl=3.23, accuracy=58.364, wps=13467.1, ups=1.11, wpb=12140.6, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.415, clip=0, loss_scale=16, train_wall=90, gb_free=16.7, wall=10555
2023-08-04 03:43:38 | INFO | train_inner | epoch 008:   1389 / 1474 loss=2.073, trans_loss=3.526, nll_loss=1.693, w2v_ctc_loss=1.086, task_loss=0.921, contrastive_loss=0.207, total=4141.5, n_correct=2428.08, ppl=3.23, accuracy=58.628, wps=13761.9, ups=1.11, wpb=12367.2, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.409, clip=0, loss_scale=16, train_wall=89, gb_free=16.3, wall=10645
2023-08-04 03:44:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 03:45:18 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.282 | trans_loss 5.681 | nll_loss 2.99 | w2v_ctc_loss 1.345 | task_loss 4.599 | contrastive_loss 0.277 | total 4003.4 | n_correct 2402.2 | ppl 7.95 | accuracy 60.004 | uer 18.918 | wer 20.514 | raw_wer 20.514 | bleu 19.01 | wps 2258.7 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 19.04
2023-08-04 03:45:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-08-04 03:45:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.0101.pt
2023-08-04 03:45:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.0101.pt
2023-08-04 03:45:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.0101.pt (epoch 8 @ 11785 updates, score 19.01) (writing took 16.426815398037434 seconds)
2023-08-04 03:45:34 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-04 03:45:34 | INFO | train | epoch 008 | loss 2.073 | trans_loss 3.521 | nll_loss 1.684 | w2v_ctc_loss 1.091 | task_loss 0.932 | contrastive_loss 0.201 | total 4138.65 | n_correct 2424.13 | ppl 3.21 | accuracy 58.573 | wps 13146.6 | ups 1.06 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.412 | clip 0 | loss_scale 32 | train_wall 1331 | gb_free 16.8 | wall 10762
2023-08-04 03:45:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 03:45:35 | INFO | fairseq.trainer | begin training epoch 9
2023-08-04 03:45:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 03:45:57 | INFO | train_inner | epoch 009:     15 / 1474 loss=2.073, trans_loss=3.519, nll_loss=1.682, w2v_ctc_loss=1.071, task_loss=0.898, contrastive_loss=0.334, total=4139.35, n_correct=2435.73, ppl=3.21, accuracy=58.843, wps=8886.4, ups=0.72, wpb=12350.9, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.413, clip=0, loss_scale=32, train_wall=91, gb_free=15.4, wall=10784
2023-08-04 03:47:28 | INFO | train_inner | epoch 009:    115 / 1474 loss=2.018, trans_loss=3.482, nll_loss=1.634, w2v_ctc_loss=1.045, task_loss=0.886, contrastive_loss=0.153, total=4181.9, n_correct=2502.86, ppl=3.1, accuracy=59.85, wps=13796.7, ups=1.1, wpb=12488.1, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.405, clip=0, loss_scale=32, train_wall=90, gb_free=16.2, wall=10875
2023-08-04 03:48:59 | INFO | train_inner | epoch 009:    215 / 1474 loss=2.014, trans_loss=3.489, nll_loss=1.643, w2v_ctc_loss=1.046, task_loss=1.005, contrastive_loss=0.109, total=4062.07, n_correct=2419.03, ppl=3.12, accuracy=59.552, wps=13291, ups=1.1, wpb=12129.1, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.412, clip=0, loss_scale=32, train_wall=91, gb_free=15.5, wall=10966
2023-08-04 03:48:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 03:49:22 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.271 | trans_loss 5.682 | nll_loss 2.991 | w2v_ctc_loss 1.309 | task_loss 4.561 | contrastive_loss 0.274 | total 4003.4 | n_correct 2402 | ppl 7.95 | accuracy 59.999 | uer 18.395 | wer 20.066 | raw_wer 20.066 | bleu 18.9 | wps 2205.9 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 19.04
2023-08-04 03:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-04 03:49:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_9_12000.pt
2023-08-04 03:49:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_9_12000.pt
2023-08-04 03:49:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.9) (writing took 22.10779588855803 seconds)
2023-08-04 03:51:15 | INFO | train_inner | epoch 009:    315 / 1474 loss=2.009, trans_loss=3.476, nll_loss=1.629, w2v_ctc_loss=1.033, task_loss=0.871, contrastive_loss=0.159, total=4152.1, n_correct=2487.89, ppl=3.09, accuracy=59.919, wps=9114.1, ups=0.73, wpb=12407.3, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.409, clip=0, loss_scale=32, train_wall=90, gb_free=16.2, wall=11102
2023-08-04 03:52:47 | INFO | train_inner | epoch 009:    415 / 1474 loss=2.016, trans_loss=3.493, nll_loss=1.65, w2v_ctc_loss=1.045, task_loss=0.91, contrastive_loss=0.126, total=4203.78, n_correct=2504.22, ppl=3.14, accuracy=59.571, wps=13623.6, ups=1.09, wpb=12551.8, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.405, clip=0, loss_scale=32, train_wall=92, gb_free=17.1, wall=11194
2023-08-04 03:54:18 | INFO | train_inner | epoch 009:    515 / 1474 loss=2.044, trans_loss=3.499, nll_loss=1.656, w2v_ctc_loss=1.069, task_loss=0.98, contrastive_loss=0.176, total=4112.78, n_correct=2439.4, ppl=3.15, accuracy=59.313, wps=13520.9, ups=1.1, wpb=12275.6, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.412, clip=0, loss_scale=32, train_wall=90, gb_free=16.1, wall=11285
2023-08-04 03:55:49 | INFO | train_inner | epoch 009:    615 / 1474 loss=2.01, trans_loss=3.489, nll_loss=1.647, w2v_ctc_loss=1.037, task_loss=0.947, contrastive_loss=0.138, total=4131.32, n_correct=2463.12, ppl=3.13, accuracy=59.621, wps=13599.2, ups=1.1, wpb=12347.4, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.408, clip=0, loss_scale=32, train_wall=90, gb_free=17.8, wall=11376
2023-08-04 03:57:19 | INFO | train_inner | epoch 009:    715 / 1474 loss=2.045, trans_loss=3.501, nll_loss=1.661, w2v_ctc_loss=1.064, task_loss=0.954, contrastive_loss=0.219, total=4082.11, n_correct=2414.56, ppl=3.16, accuracy=59.15, wps=13552.4, ups=1.11, wpb=12194.8, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.416, clip=0, loss_scale=32, train_wall=90, gb_free=16.9, wall=11466
2023-08-04 03:58:49 | INFO | train_inner | epoch 009:    815 / 1474 loss=2.067, trans_loss=3.494, nll_loss=1.655, w2v_ctc_loss=1.055, task_loss=0.842, contrastive_loss=0.367, total=4221.08, n_correct=2508.79, ppl=3.15, accuracy=59.435, wps=13886.6, ups=1.1, wpb=12613.9, bsz=501.6, num_updates=12600, lr=0.000125988, gnorm=0.413, clip=0, loss_scale=32, train_wall=90, gb_free=17.6, wall=11557
2023-08-04 04:00:22 | INFO | train_inner | epoch 009:    915 / 1474 loss=2.049, trans_loss=3.501, nll_loss=1.658, w2v_ctc_loss=1.051, task_loss=0.964, contrastive_loss=0.344, total=4142.34, n_correct=2456.68, ppl=3.16, accuracy=59.307, wps=13407.6, ups=1.08, wpb=12359.9, bsz=448.9, num_updates=12700, lr=0.000125491, gnorm=0.41, clip=0, loss_scale=32, train_wall=92, gb_free=17.2, wall=11649
2023-08-04 04:01:52 | INFO | train_inner | epoch 009:   1015 / 1474 loss=2.032, trans_loss=3.507, nll_loss=1.667, w2v_ctc_loss=1.061, task_loss=1.045, contrastive_loss=0.122, total=4097.15, n_correct=2421.95, ppl=3.17, accuracy=59.113, wps=13466.6, ups=1.1, wpb=12228.7, bsz=422.6, num_updates=12800, lr=0.000125, gnorm=0.411, clip=0, loss_scale=32, train_wall=90, gb_free=16.8, wall=11740
2023-08-04 04:03:23 | INFO | train_inner | epoch 009:   1115 / 1474 loss=2.025, trans_loss=3.503, nll_loss=1.659, w2v_ctc_loss=1.049, task_loss=0.871, contrastive_loss=0.15, total=4182.29, n_correct=2488.28, ppl=3.16, accuracy=59.496, wps=13750.6, ups=1.1, wpb=12467.1, bsz=477.6, num_updates=12900, lr=0.000124515, gnorm=0.408, clip=0, loss_scale=32, train_wall=90, gb_free=17.2, wall=11830
2023-08-04 04:04:54 | INFO | train_inner | epoch 009:   1215 / 1474 loss=2.035, trans_loss=3.504, nll_loss=1.665, w2v_ctc_loss=1.066, task_loss=0.99, contrastive_loss=0.131, total=4141.43, n_correct=2455.74, ppl=3.17, accuracy=59.297, wps=13606.7, ups=1.1, wpb=12364.7, bsz=446.6, num_updates=13000, lr=0.000124035, gnorm=0.412, clip=0, loss_scale=32, train_wall=90, gb_free=17.5, wall=11921
2023-08-04 04:06:24 | INFO | train_inner | epoch 009:   1315 / 1474 loss=2.045, trans_loss=3.498, nll_loss=1.657, w2v_ctc_loss=1.043, task_loss=0.846, contrastive_loss=0.323, total=4203.91, n_correct=2507.54, ppl=3.15, accuracy=59.648, wps=13877.9, ups=1.11, wpb=12545.2, bsz=492.3, num_updates=13100, lr=0.00012356, gnorm=0.408, clip=0, loss_scale=32, train_wall=90, gb_free=17.3, wall=12011
2023-08-04 04:07:55 | INFO | train_inner | epoch 009:   1415 / 1474 loss=2.027, trans_loss=3.511, nll_loss=1.671, w2v_ctc_loss=1.058, task_loss=1.007, contrastive_loss=0.105, total=4077.08, n_correct=2414.84, ppl=3.19, accuracy=59.23, wps=13409.8, ups=1.1, wpb=12165, bsz=429.1, num_updates=13200, lr=0.000123091, gnorm=0.415, clip=0, loss_scale=32, train_wall=90, gb_free=17.3, wall=12102
2023-08-04 04:08:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 04:09:10 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.261 | trans_loss 5.655 | nll_loss 2.96 | w2v_ctc_loss 1.339 | task_loss 4.578 | contrastive_loss 0.274 | total 4003.4 | n_correct 2413.6 | ppl 7.78 | accuracy 60.289 | uer 18.382 | wer 20.085 | raw_wer 20.085 | bleu 19.08 | wps 2301.6 | wpb 4003.4 | bsz 141.8 | num_updates 13259 | best_bleu 19.08
2023-08-04 04:09:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13259 updates
2023-08-04 04:09:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 04:09:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 04:09:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 9 @ 13259 updates, score 19.08) (writing took 23.83410218730569 seconds)
2023-08-04 04:09:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-04 04:09:34 | INFO | train | epoch 009 | loss 2.032 | trans_loss 3.496 | nll_loss 1.654 | w2v_ctc_loss 1.052 | task_loss 0.932 | contrastive_loss 0.193 | total 4138.65 | n_correct 2461.25 | ppl 3.15 | accuracy 59.47 | wps 12651.4 | ups 1.02 | wpb 12355.8 | bsz 458.5 | num_updates 13259 | lr 0.000122817 | gnorm 0.411 | clip 0 | loss_scale 32 | train_wall 1332 | gb_free 11.5 | wall 12201
2023-08-04 04:09:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 04:09:34 | INFO | fairseq.trainer | begin training epoch 10
2023-08-04 04:09:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 04:10:19 | INFO | train_inner | epoch 010:     41 / 1474 loss=2.017, trans_loss=3.488, nll_loss=1.644, w2v_ctc_loss=1.032, task_loss=0.889, contrastive_loss=0.208, total=4100.86, n_correct=2456.44, ppl=3.12, accuracy=59.901, wps=8524.4, ups=0.7, wpb=12239.9, bsz=470.2, num_updates=13300, lr=0.000122628, gnorm=0.414, clip=0, loss_scale=32, train_wall=89, gb_free=16.4, wall=12246
2023-08-04 04:11:49 | INFO | train_inner | epoch 010:    141 / 1474 loss=1.975, trans_loss=3.461, nll_loss=1.609, w2v_ctc_loss=1.004, task_loss=0.881, contrastive_loss=0.131, total=4240.18, n_correct=2566.6, ppl=3.05, accuracy=60.53, wps=13959.1, ups=1.1, wpb=12664, bsz=479.1, num_updates=13400, lr=0.000122169, gnorm=0.404, clip=0, loss_scale=32, train_wall=90, gb_free=14.8, wall=12337
2023-08-04 04:13:21 | INFO | train_inner | epoch 010:    241 / 1474 loss=2, trans_loss=3.464, nll_loss=1.611, w2v_ctc_loss=1.017, task_loss=0.925, contrastive_loss=0.252, total=4126.3, n_correct=2498.44, ppl=3.05, accuracy=60.549, wps=13521.7, ups=1.1, wpb=12312.3, bsz=460.9, num_updates=13500, lr=0.000121716, gnorm=0.405, clip=0, loss_scale=32, train_wall=91, gb_free=15.4, wall=12428
2023-08-04 04:14:52 | INFO | train_inner | epoch 010:    341 / 1474 loss=1.983, trans_loss=3.463, nll_loss=1.615, w2v_ctc_loss=1.01, task_loss=0.95, contrastive_loss=0.163, total=4132.25, n_correct=2495.88, ppl=3.06, accuracy=60.4, wps=13530.2, ups=1.1, wpb=12352, bsz=452.8, num_updates=13600, lr=0.000121268, gnorm=0.411, clip=0, loss_scale=32, train_wall=91, gb_free=14.6, wall=12519
2023-08-04 04:16:23 | INFO | train_inner | epoch 010:    441 / 1474 loss=1.998, trans_loss=3.468, nll_loss=1.618, w2v_ctc_loss=0.996, task_loss=0.895, contrastive_loss=0.341, total=4203.14, n_correct=2538.86, ppl=3.07, accuracy=60.404, wps=13686.5, ups=1.09, wpb=12548.6, bsz=481.7, num_updates=13700, lr=0.000120824, gnorm=0.404, clip=0, loss_scale=32, train_wall=91, gb_free=16.3, wall=12611
2023-08-04 04:17:54 | INFO | train_inner | epoch 010:    541 / 1474 loss=2.002, trans_loss=3.485, nll_loss=1.635, w2v_ctc_loss=1.036, task_loss=0.994, contrastive_loss=0.118, total=4106.5, n_correct=2465.13, ppl=3.11, accuracy=60.03, wps=13499, ups=1.1, wpb=12244.6, bsz=440, num_updates=13800, lr=0.000120386, gnorm=0.413, clip=0, loss_scale=32, train_wall=90, gb_free=16.3, wall=12701
2023-08-04 04:19:26 | INFO | train_inner | epoch 010:    641 / 1474 loss=2.011, trans_loss=3.478, nll_loss=1.631, w2v_ctc_loss=1.025, task_loss=0.889, contrastive_loss=0.235, total=4170.61, n_correct=2508.24, ppl=3.1, accuracy=60.141, wps=13573.6, ups=1.09, wpb=12448.2, bsz=476.1, num_updates=13900, lr=0.000119952, gnorm=0.412, clip=0, loss_scale=64, train_wall=91, gb_free=10.6, wall=12793
2023-08-04 04:20:56 | INFO | train_inner | epoch 010:    741 / 1474 loss=2.003, trans_loss=3.48, nll_loss=1.634, w2v_ctc_loss=1.04, task_loss=0.939, contrastive_loss=0.115, total=4123.31, n_correct=2477.43, ppl=3.1, accuracy=60.084, wps=13661.5, ups=1.11, wpb=12306.7, bsz=453, num_updates=14000, lr=0.000119523, gnorm=0.414, clip=0, loss_scale=64, train_wall=90, gb_free=17, wall=12883
2023-08-04 04:20:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 04:21:20 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.269 | trans_loss 5.655 | nll_loss 2.955 | w2v_ctc_loss 1.361 | task_loss 4.581 | contrastive_loss 0.277 | total 4003.4 | n_correct 2417.6 | ppl 7.75 | accuracy 60.389 | uer 18.772 | wer 20.488 | raw_wer 20.488 | bleu 19.37 | wps 2177.5 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.37
2023-08-04 04:21:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-04 04:21:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_10_14000.pt
2023-08-04 04:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_10_14000.pt
2023-08-04 04:22:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 19.37) (writing took 44.32334645278752 seconds)
2023-08-04 04:23:36 | INFO | train_inner | epoch 010:    841 / 1474 loss=1.979, trans_loss=3.475, nll_loss=1.628, w2v_ctc_loss=1.011, task_loss=0.921, contrastive_loss=0.117, total=4125.69, n_correct=2488.67, ppl=3.09, accuracy=60.321, wps=7720.1, ups=0.63, wpb=12321, bsz=456.1, num_updates=14100, lr=0.000119098, gnorm=0.406, clip=0, loss_scale=64, train_wall=90, gb_free=15.7, wall=13043
2023-08-04 04:25:05 | INFO | train_inner | epoch 010:    941 / 1474 loss=1.996, trans_loss=3.478, nll_loss=1.629, w2v_ctc_loss=1.019, task_loss=0.89, contrastive_loss=0.158, total=4170.41, n_correct=2516.15, ppl=3.09, accuracy=60.333, wps=13884.3, ups=1.12, wpb=12437.5, bsz=470.8, num_updates=14200, lr=0.000118678, gnorm=0.411, clip=0, loss_scale=64, train_wall=89, gb_free=16, wall=13132
2023-08-04 04:26:37 | INFO | train_inner | epoch 010:   1041 / 1474 loss=1.994, trans_loss=3.481, nll_loss=1.636, w2v_ctc_loss=1.024, task_loss=1.009, contrastive_loss=0.131, total=4072.57, n_correct=2442.72, ppl=3.11, accuracy=59.98, wps=13306, ups=1.09, wpb=12161.8, bsz=434.8, num_updates=14300, lr=0.000118262, gnorm=0.414, clip=0, loss_scale=64, train_wall=91, gb_free=16.8, wall=13224
2023-08-04 04:28:07 | INFO | train_inner | epoch 010:   1141 / 1474 loss=2.004, trans_loss=3.49, nll_loss=1.645, w2v_ctc_loss=1.039, task_loss=1.038, contrastive_loss=0.111, total=4041.97, n_correct=2411.19, ppl=3.13, accuracy=59.654, wps=13405.1, ups=1.11, wpb=12067, bsz=421.9, num_updates=14400, lr=0.000117851, gnorm=0.415, clip=0, loss_scale=64, train_wall=89, gb_free=16.4, wall=13314
2023-08-04 04:29:37 | INFO | train_inner | epoch 010:   1241 / 1474 loss=1.992, trans_loss=3.477, nll_loss=1.635, w2v_ctc_loss=1.031, task_loss=0.959, contrastive_loss=0.106, total=4103.65, n_correct=2464.35, ppl=3.11, accuracy=60.053, wps=13584.6, ups=1.11, wpb=12271.8, bsz=443.9, num_updates=14500, lr=0.000117444, gnorm=0.413, clip=0, loss_scale=64, train_wall=90, gb_free=15.5, wall=13404
2023-08-04 04:31:08 | INFO | train_inner | epoch 010:   1341 / 1474 loss=1.993, trans_loss=3.483, nll_loss=1.64, w2v_ctc_loss=1.027, task_loss=0.952, contrastive_loss=0.12, total=4121.93, n_correct=2479.39, ppl=3.12, accuracy=60.151, wps=13542.9, ups=1.1, wpb=12309.4, bsz=451.2, num_updates=14600, lr=0.000117041, gnorm=0.413, clip=0, loss_scale=64, train_wall=90, gb_free=16.7, wall=13495
2023-08-04 04:31:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 04:32:40 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.003, trans_loss=3.487, nll_loss=1.642, w2v_ctc_loss=1.011, task_loss=0.903, contrastive_loss=0.228, total=4172.44, n_correct=2506.73, ppl=3.12, accuracy=60.078, wps=13469.5, ups=1.08, wpb=12446.1, bsz=470, num_updates=14700, lr=0.000116642, gnorm=0.412, clip=0, loss_scale=32, train_wall=92, gb_free=17, wall=13587
2023-08-04 04:33:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 04:33:31 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.254 | trans_loss 5.639 | nll_loss 2.935 | w2v_ctc_loss 1.35 | task_loss 4.617 | contrastive_loss 0.274 | total 4003.4 | n_correct 2425.2 | ppl 7.65 | accuracy 60.579 | uer 18.063 | wer 19.809 | raw_wer 19.809 | bleu 18.98 | wps 2333.5 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.37
2023-08-04 04:33:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-08-04 04:33:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_18.9801.pt
2023-08-04 04:33:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_18.9801.pt
2023-08-04 04:33:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_18.9801.pt (epoch 10 @ 14732 updates, score 18.98) (writing took 13.543369738385081 seconds)
2023-08-04 04:33:45 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-04 04:33:45 | INFO | train | epoch 010 | loss 1.995 | trans_loss 3.476 | nll_loss 1.629 | w2v_ctc_loss 1.019 | task_loss 0.935 | contrastive_loss 0.177 | total 4137.35 | n_correct 2490.9 | ppl 3.09 | accuracy 60.205 | wps 12537.3 | ups 1.02 | wpb 12351.9 | bsz 457.7 | num_updates 14732 | lr 0.000116516 | gnorm 0.41 | clip 0 | loss_scale 32 | train_wall 1330 | gb_free 17.2 | wall 13652
2023-08-04 04:33:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 04:33:45 | INFO | fairseq.trainer | begin training epoch 11
2023-08-04 04:33:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 04:34:54 | INFO | train_inner | epoch 011:     68 / 1474 loss=1.965, trans_loss=3.451, nll_loss=1.596, w2v_ctc_loss=0.989, task_loss=0.865, contrastive_loss=0.196, total=4175.24, n_correct=2551.96, ppl=3.02, accuracy=61.121, wps=9329.2, ups=0.75, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.402, clip=0, loss_scale=32, train_wall=89, gb_free=16.7, wall=13721
2023-08-04 04:36:25 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.958, trans_loss=3.451, nll_loss=1.598, w2v_ctc_loss=0.995, task_loss=0.961, contrastive_loss=0.115, total=4087.78, n_correct=2492.4, ppl=3.03, accuracy=60.972, wps=13470.7, ups=1.1, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.415, clip=0, loss_scale=32, train_wall=90, gb_free=16.4, wall=13812
2023-08-04 04:37:55 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.949, trans_loss=3.451, nll_loss=1.596, w2v_ctc_loss=0.984, task_loss=0.961, contrastive_loss=0.11, total=4118.77, n_correct=2513.93, ppl=3.02, accuracy=61.036, wps=13538.4, ups=1.1, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.406, clip=0, loss_scale=32, train_wall=90, gb_free=12.2, wall=13902
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:0')
2023-08-04 04:39:03 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.107, trans_loss=5.129, nll_loss=2.376, w2v_ctc_loss=0.74, task_loss=1.429, contrastive_loss=0.089, total=4097.83, n_correct=2494.2, ppl=5.19, accuracy=60.866, wps=12193.1, ups=1.48, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.549, clip=0, loss_scale=32, train_wall=67, gb_free=15.6, wall=13970
2023-08-04 04:40:11 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.124, trans_loss=5.17, nll_loss=2.406, w2v_ctc_loss=0.735, task_loss=1.463, contrastive_loss=0.207, total=4110.64, n_correct=2490.1, ppl=5.3, accuracy=60.577, wps=12156.6, ups=1.48, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.551, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=14038
2023-08-04 04:41:18 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.126, trans_loss=5.166, nll_loss=2.403, w2v_ctc_loss=0.748, task_loss=1.499, contrastive_loss=0.205, total=4071.69, n_correct=2468.12, ppl=5.29, accuracy=60.617, wps=12012.7, ups=1.48, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.554, clip=0, loss_scale=32, train_wall=67, gb_free=16, wall=14105
2023-08-04 04:42:26 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.129, trans_loss=5.168, nll_loss=2.405, w2v_ctc_loss=0.744, task_loss=1.372, contrastive_loss=0.263, total=4157.2, n_correct=2515.89, ppl=5.3, accuracy=60.519, wps=12251.5, ups=1.47, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.547, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=14173
2023-08-04 04:43:35 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.124, trans_loss=5.179, nll_loss=2.419, w2v_ctc_loss=0.758, task_loss=1.407, contrastive_loss=0.087, total=4174.91, n_correct=2529.85, ppl=5.35, accuracy=60.597, wps=12183.6, ups=1.46, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.553, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=14242
2023-08-04 04:44:42 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.123, trans_loss=5.18, nll_loss=2.42, w2v_ctc_loss=0.751, task_loss=1.464, contrastive_loss=0.075, total=4118.44, n_correct=2487.98, ppl=5.35, accuracy=60.411, wps=12225.5, ups=1.48, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.547, clip=0, loss_scale=32, train_wall=67, gb_free=10.7, wall=14309
2023-08-04 04:45:50 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.122, trans_loss=5.177, nll_loss=2.417, w2v_ctc_loss=0.753, task_loss=1.427, contrastive_loss=0.088, total=4140.92, n_correct=2506.95, ppl=5.34, accuracy=60.541, wps=12300.5, ups=1.49, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.551, clip=0, loss_scale=32, train_wall=67, gb_free=15.6, wall=14377
2023-08-04 04:46:57 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.118, trans_loss=5.171, nll_loss=2.411, w2v_ctc_loss=0.75, task_loss=1.374, contrastive_loss=0.109, total=4136.99, n_correct=2509.6, ppl=5.32, accuracy=60.662, wps=12235, ups=1.48, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.545, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=14444
2023-08-04 04:48:05 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.122, trans_loss=5.181, nll_loss=2.423, w2v_ctc_loss=0.752, task_loss=1.391, contrastive_loss=0.095, total=4185.65, n_correct=2529.79, ppl=5.36, accuracy=60.44, wps=12329.3, ups=1.47, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.546, clip=0, loss_scale=32, train_wall=67, gb_free=13.9, wall=14512
2023-08-04 04:49:13 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.124, trans_loss=5.173, nll_loss=2.414, w2v_ctc_loss=0.753, task_loss=1.341, contrastive_loss=0.162, total=4171.89, n_correct=2531.3, ppl=5.33, accuracy=60.675, wps=12309.5, ups=1.48, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.547, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=14580
2023-08-04 04:49:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:5')
2023-08-04 04:49:36 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.269 | trans_loss 5.637 | nll_loss 2.936 | w2v_ctc_loss 1.405 | task_loss 4.609 | contrastive_loss 0.272 | total 4003.4 | n_correct 2433.2 | ppl 7.65 | accuracy 60.778 | uer 18.369 | wer 20.201 | raw_wer 20.201 | bleu 19.3 | wps 2221 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.37
2023-08-04 04:49:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-04 04:49:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_11_16000.pt
2023-08-04 04:49:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_11_16000.pt
2023-08-04 04:50:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.3) (writing took 33.39165774360299 seconds)
2023-08-04 04:51:18 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.13, trans_loss=5.175, nll_loss=2.418, w2v_ctc_loss=0.742, task_loss=1.291, contrastive_loss=0.327, total=4190.34, n_correct=2537.46, ppl=5.34, accuracy=60.555, wps=6676.2, ups=0.8, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.547, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=14705
2023-08-04 04:52:27 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.117, trans_loss=5.18, nll_loss=2.423, w2v_ctc_loss=0.746, task_loss=1.352, contrastive_loss=0.097, total=4158.39, n_correct=2516.58, ppl=5.36, accuracy=60.518, wps=12149.1, ups=1.46, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=14774
2023-08-04 04:52:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 04:52:54 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.23 | trans_loss 5.627 | nll_loss 2.924 | w2v_ctc_loss 1.303 | task_loss 4.584 | contrastive_loss 0.265 | total 4003.4 | n_correct 2436.4 | ppl 7.59 | accuracy 60.858 | uer 18.071 | wer 19.746 | raw_wer 19.746 | bleu 19.79 | wps 2248.2 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.79
2023-08-04 04:52:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-08-04 04:52:54 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 04:53:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 04:53:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.79) (writing took 23.940487464889884 seconds)
2023-08-04 04:53:18 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-04 04:53:18 | INFO | train | epoch 011 | loss 2.08 | trans_loss 4.743 | nll_loss 2.208 | w2v_ctc_loss 0.807 | task_loss 1.282 | contrastive_loss 0.141 | total 4138.65 | n_correct 2511.17 | ppl 4.62 | accuracy 60.676 | wps 11336.6 | ups 1.26 | wpb 9021 | bsz 333.4 | num_updates 16206 | lr 0.000111091 | gnorm 0.523 | clip 0 | loss_scale 32 | train_wall 1052 | gb_free 17.2 | wall 14825
2023-08-04 04:53:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 04:53:18 | INFO | fairseq.trainer | begin training epoch 12
2023-08-04 04:53:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 04:54:29 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.091, trans_loss=5.118, nll_loss=2.34, w2v_ctc_loss=0.73, task_loss=1.338, contrastive_loss=0.129, total=4146.82, n_correct=2555.99, ppl=5.06, accuracy=61.637, wps=6772.7, ups=0.82, wpb=8293.6, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.544, clip=0, loss_scale=32, train_wall=66, gb_free=15.7, wall=14896
2023-08-04 04:55:37 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.099, trans_loss=5.131, nll_loss=2.356, w2v_ctc_loss=0.739, task_loss=1.443, contrastive_loss=0.079, total=4120.68, n_correct=2526.12, ppl=5.12, accuracy=61.303, wps=12233.2, ups=1.48, wpb=8241.4, bsz=294.7, num_updates=16400, lr=0.000110432, gnorm=0.555, clip=0, loss_scale=32, train_wall=67, gb_free=15.6, wall=14964
2023-08-04 04:56:45 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.093, trans_loss=5.128, nll_loss=2.354, w2v_ctc_loss=0.726, task_loss=1.315, contrastive_loss=0.113, total=4199.46, n_correct=2578.2, ppl=5.11, accuracy=61.394, wps=12316.4, ups=1.47, wpb=8398.9, bsz=320.3, num_updates=16500, lr=0.000110096, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=15032
2023-08-04 04:57:53 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.099, trans_loss=5.138, nll_loss=2.367, w2v_ctc_loss=0.736, task_loss=1.366, contrastive_loss=0.096, total=4151.14, n_correct=2543.61, ppl=5.16, accuracy=61.275, wps=12245.1, ups=1.47, wpb=8302.3, bsz=307.8, num_updates=16600, lr=0.000109764, gnorm=0.549, clip=0, loss_scale=32, train_wall=67, gb_free=17.1, wall=15100
2023-08-04 04:59:00 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.108, trans_loss=5.152, nll_loss=2.386, w2v_ctc_loss=0.744, task_loss=1.401, contrastive_loss=0.102, total=4110.49, n_correct=2513.11, ppl=5.23, accuracy=61.139, wps=12200.7, ups=1.48, wpb=8221, bsz=302.2, num_updates=16700, lr=0.000109435, gnorm=0.549, clip=0, loss_scale=64, train_wall=67, gb_free=13.7, wall=15167
2023-08-04 05:00:08 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.104, trans_loss=5.141, nll_loss=2.372, w2v_ctc_loss=0.736, task_loss=1.34, contrastive_loss=0.168, total=4189.92, n_correct=2567.67, ppl=5.18, accuracy=61.282, wps=12319.7, ups=1.47, wpb=8379.8, bsz=315.1, num_updates=16800, lr=0.000109109, gnorm=0.553, clip=0, loss_scale=64, train_wall=67, gb_free=14.8, wall=15235
2023-08-04 05:01:16 | INFO | train_inner | epoch 012:    694 / 1474 loss=2.1, trans_loss=5.14, nll_loss=2.371, w2v_ctc_loss=0.719, task_loss=1.281, contrastive_loss=0.257, total=4206.3, n_correct=2584.34, ppl=5.17, accuracy=61.44, wps=12390.7, ups=1.47, wpb=8412.6, bsz=325.7, num_updates=16900, lr=0.000108786, gnorm=0.542, clip=0, loss_scale=64, train_wall=67, gb_free=16.2, wall=15303
2023-08-04 05:02:24 | INFO | train_inner | epoch 012:    794 / 1474 loss=2.101, trans_loss=5.14, nll_loss=2.37, w2v_ctc_loss=0.74, task_loss=1.429, contrastive_loss=0.091, total=4085.96, n_correct=2504.66, ppl=5.17, accuracy=61.299, wps=12048.9, ups=1.47, wpb=8171.9, bsz=297.1, num_updates=17000, lr=0.000108465, gnorm=0.557, clip=0, loss_scale=64, train_wall=67, gb_free=16.1, wall=15371
2023-08-04 05:03:32 | INFO | train_inner | epoch 012:    894 / 1474 loss=2.106, trans_loss=5.146, nll_loss=2.377, w2v_ctc_loss=0.736, task_loss=1.429, contrastive_loss=0.145, total=4169.74, n_correct=2549.18, ppl=5.2, accuracy=61.135, wps=12242.4, ups=1.47, wpb=8339.5, bsz=306.4, num_updates=17100, lr=0.000108148, gnorm=0.549, clip=0, loss_scale=64, train_wall=68, gb_free=16, wall=15439
2023-08-04 05:04:39 | INFO | train_inner | epoch 012:    994 / 1474 loss=2.113, trans_loss=5.159, nll_loss=2.395, w2v_ctc_loss=0.742, task_loss=1.427, contrastive_loss=0.152, total=4117.67, n_correct=2511.08, ppl=5.26, accuracy=60.983, wps=12194.4, ups=1.48, wpb=8235.3, bsz=301.4, num_updates=17200, lr=0.000107833, gnorm=0.554, clip=0, loss_scale=64, train_wall=67, gb_free=17.6, wall=15507
2023-08-04 05:04:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 05:05:48 | INFO | train_inner | epoch 012:   1095 / 1474 loss=2.113, trans_loss=5.161, nll_loss=2.398, w2v_ctc_loss=0.749, task_loss=1.526, contrastive_loss=0.07, total=4014.56, n_correct=2447.86, ppl=5.27, accuracy=60.975, wps=11693.5, ups=1.46, wpb=8029.1, bsz=279.5, num_updates=17300, lr=0.000107521, gnorm=0.566, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=15575
2023-08-04 05:06:56 | INFO | train_inner | epoch 012:   1195 / 1474 loss=2.122, trans_loss=5.17, nll_loss=2.412, w2v_ctc_loss=0.751, task_loss=1.363, contrastive_loss=0.169, total=4201.13, n_correct=2548.58, ppl=5.32, accuracy=60.664, wps=12349.1, ups=1.47, wpb=8402.3, bsz=319.2, num_updates=17400, lr=0.000107211, gnorm=0.548, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=15643
2023-08-04 05:08:04 | INFO | train_inner | epoch 012:   1295 / 1474 loss=2.118, trans_loss=5.163, nll_loss=2.401, w2v_ctc_loss=0.758, task_loss=1.556, contrastive_loss=0.077, total=4070.27, n_correct=2477.04, ppl=5.28, accuracy=60.857, wps=12087, ups=1.48, wpb=8140.5, bsz=286.1, num_updates=17500, lr=0.000106904, gnorm=0.562, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=15711
2023-08-04 05:09:11 | INFO | train_inner | epoch 012:   1395 / 1474 loss=2.11, trans_loss=5.162, nll_loss=2.4, w2v_ctc_loss=0.731, task_loss=1.409, contrastive_loss=0.182, total=4139.63, n_correct=2525.28, ppl=5.28, accuracy=61.003, wps=12226, ups=1.48, wpb=8279.3, bsz=305.8, num_updates=17600, lr=0.0001066, gnorm=0.55, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=15778
2023-08-04 05:10:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 05:10:30 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.243 | trans_loss 5.616 | nll_loss 2.91 | w2v_ctc_loss 1.365 | task_loss 4.586 | contrastive_loss 0.268 | total 4003.4 | n_correct 2445.9 | ppl 7.52 | accuracy 61.096 | uer 18.443 | wer 20.201 | raw_wer 20.201 | bleu 19.56 | wps 1914.1 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.79
2023-08-04 05:10:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-08-04 05:10:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.5601.pt
2023-08-04 05:10:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.5601.pt
2023-08-04 05:10:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.5601.pt (epoch 12 @ 17679 updates, score 19.56) (writing took 26.88546403311193 seconds)
2023-08-04 05:10:57 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-04 05:10:58 | INFO | train | epoch 012 | loss 2.106 | trans_loss 5.147 | nll_loss 2.38 | w2v_ctc_loss 0.738 | task_loss 1.401 | contrastive_loss 0.13 | total 4136.49 | n_correct 2530.13 | ppl 5.2 | accuracy 61.166 | wps 11504.4 | ups 1.39 | wpb 8273 | bsz 305 | num_updates 17679 | lr 0.000106362 | gnorm 0.551 | clip 0 | loss_scale 32 | train_wall 990 | gb_free 12.7 | wall 15885
2023-08-04 05:10:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 05:10:58 | INFO | fairseq.trainer | begin training epoch 13
2023-08-04 05:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 05:11:19 | INFO | train_inner | epoch 013:     21 / 1474 loss=2.11, trans_loss=5.16, nll_loss=2.397, w2v_ctc_loss=0.747, task_loss=1.454, contrastive_loss=0.087, total=4096.49, n_correct=2501.43, ppl=5.27, accuracy=61.063, wps=6389.8, ups=0.78, wpb=8193, bsz=295.4, num_updates=17700, lr=0.000106299, gnorm=0.552, clip=0, loss_scale=32, train_wall=67, gb_free=14.5, wall=15907
2023-08-04 05:12:27 | INFO | train_inner | epoch 013:    121 / 1474 loss=2.083, trans_loss=5.109, nll_loss=2.329, w2v_ctc_loss=0.723, task_loss=1.402, contrastive_loss=0.099, total=4160.97, n_correct=2576.6, ppl=5.02, accuracy=61.923, wps=12261, ups=1.47, wpb=8321.9, bsz=302.9, num_updates=17800, lr=0.000106, gnorm=0.547, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=15974
2023-08-04 05:12:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 05:13:36 | INFO | train_inner | epoch 013:    222 / 1474 loss=2.1, trans_loss=5.123, nll_loss=2.349, w2v_ctc_loss=0.721, task_loss=1.304, contrastive_loss=0.32, total=4200.06, n_correct=2588.98, ppl=5.09, accuracy=61.642, wps=12219.5, ups=1.45, wpb=8400.1, bsz=326.9, num_updates=17900, lr=0.000105703, gnorm=0.546, clip=0, loss_scale=16, train_wall=68, gb_free=13, wall=16043
2023-08-04 05:14:44 | INFO | train_inner | epoch 013:    322 / 1474 loss=2.08, trans_loss=5.11, nll_loss=2.33, w2v_ctc_loss=0.718, task_loss=1.452, contrastive_loss=0.082, total=4102.53, n_correct=2545.18, ppl=5.03, accuracy=62.039, wps=12159, ups=1.48, wpb=8205.1, bsz=293.9, num_updates=18000, lr=0.000105409, gnorm=0.547, clip=0, loss_scale=16, train_wall=67, gb_free=16, wall=16111
2023-08-04 05:14:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 05:15:07 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.239 | trans_loss 5.627 | nll_loss 2.919 | w2v_ctc_loss 1.331 | task_loss 4.582 | contrastive_loss 0.268 | total 4003.4 | n_correct 2439.4 | ppl 7.56 | accuracy 60.933 | uer 18.106 | wer 19.865 | raw_wer 19.865 | bleu 19.63 | wps 2138.1 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.79
2023-08-04 05:15:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-04 05:15:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_13_18000.pt
2023-08-04 05:15:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_13_18000.pt
2023-08-04 05:15:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.63) (writing took 28.62657485343516 seconds)
2023-08-04 05:16:44 | INFO | train_inner | epoch 013:    422 / 1474 loss=2.086, trans_loss=5.118, nll_loss=2.342, w2v_ctc_loss=0.727, task_loss=1.301, contrastive_loss=0.134, total=4190.45, n_correct=2595.3, ppl=5.07, accuracy=61.934, wps=6947.2, ups=0.83, wpb=8380.9, bsz=320.3, num_updates=18100, lr=0.000105118, gnorm=0.548, clip=0, loss_scale=16, train_wall=67, gb_free=15.8, wall=16231
2023-08-04 05:17:53 | INFO | train_inner | epoch 013:    522 / 1474 loss=2.095, trans_loss=5.128, nll_loss=2.355, w2v_ctc_loss=0.728, task_loss=1.354, contrastive_loss=0.171, total=4194.45, n_correct=2578.01, ppl=5.12, accuracy=61.462, wps=12273.3, ups=1.46, wpb=8388.9, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.551, clip=0, loss_scale=16, train_wall=68, gb_free=17.3, wall=16300
2023-08-04 05:19:00 | INFO | train_inner | epoch 013:    622 / 1474 loss=2.083, trans_loss=5.123, nll_loss=2.348, w2v_ctc_loss=0.724, task_loss=1.367, contrastive_loss=0.08, total=4158.04, n_correct=2569.44, ppl=5.09, accuracy=61.794, wps=12361.5, ups=1.49, wpb=8316.1, bsz=306.7, num_updates=18300, lr=0.000104542, gnorm=0.549, clip=0, loss_scale=16, train_wall=67, gb_free=13.3, wall=16367
2023-08-04 05:20:08 | INFO | train_inner | epoch 013:    722 / 1474 loss=2.103, trans_loss=5.136, nll_loss=2.364, w2v_ctc_loss=0.748, task_loss=1.55, contrastive_loss=0.078, total=4099.91, n_correct=2515.8, ppl=5.15, accuracy=61.362, wps=12113.2, ups=1.48, wpb=8199.8, bsz=285.5, num_updates=18400, lr=0.000104257, gnorm=0.559, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=16435
2023-08-04 05:21:16 | INFO | train_inner | epoch 013:    822 / 1474 loss=2.096, trans_loss=5.132, nll_loss=2.361, w2v_ctc_loss=0.73, task_loss=1.419, contrastive_loss=0.13, total=4122.78, n_correct=2533.21, ppl=5.14, accuracy=61.444, wps=12089.4, ups=1.47, wpb=8245.6, bsz=306, num_updates=18500, lr=0.000103975, gnorm=0.555, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=16503
2023-08-04 05:22:23 | INFO | train_inner | epoch 013:    922 / 1474 loss=2.094, trans_loss=5.134, nll_loss=2.363, w2v_ctc_loss=0.734, task_loss=1.429, contrastive_loss=0.089, total=4102.59, n_correct=2529.06, ppl=5.14, accuracy=61.645, wps=12185.9, ups=1.49, wpb=8205.2, bsz=296.6, num_updates=18600, lr=0.000103695, gnorm=0.559, clip=0, loss_scale=16, train_wall=67, gb_free=17.3, wall=16570
2023-08-04 05:23:31 | INFO | train_inner | epoch 013:   1022 / 1474 loss=2.102, trans_loss=5.139, nll_loss=2.37, w2v_ctc_loss=0.737, task_loss=1.481, contrastive_loss=0.14, total=4087.8, n_correct=2508.05, ppl=5.17, accuracy=61.355, wps=12104.8, ups=1.48, wpb=8175.6, bsz=293.7, num_updates=18700, lr=0.000103418, gnorm=0.56, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=16638
2023-08-04 05:24:38 | INFO | train_inner | epoch 013:   1122 / 1474 loss=2.088, trans_loss=5.127, nll_loss=2.354, w2v_ctc_loss=0.724, task_loss=1.385, contrastive_loss=0.122, total=4098.77, n_correct=2531.38, ppl=5.11, accuracy=61.76, wps=12238.2, ups=1.49, wpb=8197.5, bsz=304.8, num_updates=18800, lr=0.000103142, gnorm=0.551, clip=0, loss_scale=16, train_wall=67, gb_free=13.5, wall=16705
2023-08-04 05:25:46 | INFO | train_inner | epoch 013:   1222 / 1474 loss=2.098, trans_loss=5.143, nll_loss=2.376, w2v_ctc_loss=0.736, task_loss=1.484, contrastive_loss=0.081, total=4115.57, n_correct=2526.8, ppl=5.19, accuracy=61.396, wps=12099.9, ups=1.47, wpb=8231.1, bsz=295.9, num_updates=18900, lr=0.000102869, gnorm=0.552, clip=0, loss_scale=16, train_wall=68, gb_free=15, wall=16773
2023-08-04 05:26:53 | INFO | train_inner | epoch 013:   1322 / 1474 loss=2.093, trans_loss=5.129, nll_loss=2.359, w2v_ctc_loss=0.726, task_loss=1.387, contrastive_loss=0.18, total=4111.02, n_correct=2538.28, ppl=5.13, accuracy=61.743, wps=12167.5, ups=1.48, wpb=8222, bsz=307.8, num_updates=19000, lr=0.000102598, gnorm=0.548, clip=0, loss_scale=16, train_wall=67, gb_free=17.8, wall=16840
2023-08-04 05:28:01 | INFO | train_inner | epoch 013:   1422 / 1474 loss=2.101, trans_loss=5.142, nll_loss=2.375, w2v_ctc_loss=0.726, task_loss=1.372, contrastive_loss=0.194, total=4179.06, n_correct=2562.78, ppl=5.19, accuracy=61.324, wps=12385.4, ups=1.48, wpb=8358.1, bsz=311.9, num_updates=19100, lr=0.000102329, gnorm=0.552, clip=0, loss_scale=16, train_wall=67, gb_free=16, wall=16908
2023-08-04 05:28:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 05:28:59 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.231 | trans_loss 5.617 | nll_loss 2.908 | w2v_ctc_loss 1.322 | task_loss 4.595 | contrastive_loss 0.273 | total 4003.4 | n_correct 2441.9 | ppl 7.51 | accuracy 60.996 | uer 18.156 | wer 20.059 | raw_wer 20.059 | bleu 19.41 | wps 2133 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 19.79
2023-08-04 05:28:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-08-04 05:28:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.4106.pt
2023-08-04 05:29:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.4106.pt
2023-08-04 05:29:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.4106.pt (epoch 13 @ 19152 updates, score 19.41) (writing took 18.844621228054166 seconds)
2023-08-04 05:29:21 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-04 05:29:21 | INFO | train | epoch 013 | loss 2.093 | trans_loss 5.128 | nll_loss 2.355 | w2v_ctc_loss 0.729 | task_loss 1.4 | contrastive_loss 0.136 | total 4138.37 | n_correct 2550.81 | ppl 5.12 | accuracy 61.638 | wps 11053.4 | ups 1.34 | wpb 8276.7 | bsz 305.6 | num_updates 19152 | lr 0.00010219 | gnorm 0.552 | clip 0 | loss_scale 16 | train_wall 990 | gb_free 17.6 | wall 16988
2023-08-04 05:29:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 05:29:21 | INFO | fairseq.trainer | begin training epoch 14
2023-08-04 05:29:21 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 05:30:01 | INFO | train_inner | epoch 014:     48 / 1474 loss=2.07, trans_loss=5.097, nll_loss=2.317, w2v_ctc_loss=0.716, task_loss=1.287, contrastive_loss=0.097, total=4179.66, n_correct=2603.67, ppl=4.98, accuracy=62.294, wps=6974.2, ups=0.83, wpb=8359.3, bsz=322, num_updates=19200, lr=0.000102062, gnorm=0.551, clip=0, loss_scale=16, train_wall=67, gb_free=10.3, wall=17028
2023-08-04 05:31:08 | INFO | train_inner | epoch 014:    148 / 1474 loss=2.067, trans_loss=5.083, nll_loss=2.297, w2v_ctc_loss=0.718, task_loss=1.401, contrastive_loss=0.076, total=4081.01, n_correct=2555.04, ppl=4.91, accuracy=62.608, wps=12113.4, ups=1.48, wpb=8162, bsz=300.6, num_updates=19300, lr=0.000101797, gnorm=0.55, clip=0, loss_scale=16, train_wall=67, gb_free=15.9, wall=17095
2023-08-04 05:32:15 | INFO | train_inner | epoch 014:    248 / 1474 loss=2.082, trans_loss=5.103, nll_loss=2.321, w2v_ctc_loss=0.719, task_loss=1.457, contrastive_loss=0.178, total=4109.83, n_correct=2554.59, ppl=5, accuracy=62.158, wps=12196.8, ups=1.48, wpb=8219.7, bsz=295.2, num_updates=19400, lr=0.000101535, gnorm=0.553, clip=0, loss_scale=16, train_wall=67, gb_free=15.6, wall=17162
2023-08-04 05:33:23 | INFO | train_inner | epoch 014:    348 / 1474 loss=2.07, trans_loss=5.094, nll_loss=2.313, w2v_ctc_loss=0.714, task_loss=1.305, contrastive_loss=0.117, total=4171.83, n_correct=2600.96, ppl=4.97, accuracy=62.346, wps=12367.6, ups=1.48, wpb=8343.7, bsz=319.7, num_updates=19500, lr=0.000101274, gnorm=0.547, clip=0, loss_scale=16, train_wall=67, gb_free=16.7, wall=17230
2023-08-04 05:34:30 | INFO | train_inner | epoch 014:    448 / 1474 loss=2.075, trans_loss=5.107, nll_loss=2.328, w2v_ctc_loss=0.714, task_loss=1.407, contrastive_loss=0.087, total=4142.75, n_correct=2572.54, ppl=5.02, accuracy=62.097, wps=12302.6, ups=1.48, wpb=8285.5, bsz=302.2, num_updates=19600, lr=0.000101015, gnorm=0.552, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=17297
2023-08-04 05:35:38 | INFO | train_inner | epoch 014:    548 / 1474 loss=2.089, trans_loss=5.114, nll_loss=2.335, w2v_ctc_loss=0.736, task_loss=1.506, contrastive_loss=0.094, total=4073.76, n_correct=2520.22, ppl=5.05, accuracy=61.865, wps=11960.2, ups=1.47, wpb=8147.5, bsz=290.9, num_updates=19700, lr=0.000100759, gnorm=0.567, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=17365
2023-08-04 05:36:46 | INFO | train_inner | epoch 014:    648 / 1474 loss=2.084, trans_loss=5.112, nll_loss=2.335, w2v_ctc_loss=0.72, task_loss=1.4, contrastive_loss=0.153, total=4158.79, n_correct=2575.13, ppl=5.05, accuracy=61.92, wps=12213.4, ups=1.47, wpb=8317.6, bsz=306.8, num_updates=19800, lr=0.000100504, gnorm=0.553, clip=0, loss_scale=16, train_wall=68, gb_free=17.2, wall=17434
2023-08-04 05:37:54 | INFO | train_inner | epoch 014:    748 / 1474 loss=2.07, trans_loss=5.1, nll_loss=2.32, w2v_ctc_loss=0.713, task_loss=1.364, contrastive_loss=0.085, total=4145.47, n_correct=2580.97, ppl=4.99, accuracy=62.26, wps=12345.3, ups=1.49, wpb=8290.9, bsz=309.6, num_updates=19900, lr=0.000100251, gnorm=0.546, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=17501
2023-08-04 05:39:01 | INFO | train_inner | epoch 014:    848 / 1474 loss=2.08, trans_loss=5.104, nll_loss=2.325, w2v_ctc_loss=0.713, task_loss=1.329, contrastive_loss=0.196, total=4171.1, n_correct=2593.49, ppl=5.01, accuracy=62.178, wps=12378.9, ups=1.48, wpb=8342.2, bsz=319.7, num_updates=20000, lr=0.0001, gnorm=0.549, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=17568
2023-08-04 05:39:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 05:39:24 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.236 | trans_loss 5.605 | nll_loss 2.893 | w2v_ctc_loss 1.37 | task_loss 4.616 | contrastive_loss 0.267 | total 4003.4 | n_correct 2454.4 | ppl 7.43 | accuracy 61.308 | uer 17.962 | wer 19.783 | raw_wer 19.783 | bleu 19.84 | wps 2238.9 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.84
2023-08-04 05:39:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-04 05:39:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_14_20000.pt
2023-08-04 05:39:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_14_20000.pt
2023-08-04 05:39:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.84) (writing took 24.400333618745208 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:0')
2023-08-04 05:40:58 | INFO | train_inner | epoch 014:    948 / 1474 loss=2.081, trans_loss=5.113, nll_loss=2.337, w2v_ctc_loss=0.719, task_loss=1.406, contrastive_loss=0.129, total=4167.75, n_correct=2581.65, ppl=5.05, accuracy=61.943, wps=7133.3, ups=0.86, wpb=8335.5, bsz=310.1, num_updates=20100, lr=9.97509e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=17685
2023-08-04 05:42:06 | INFO | train_inner | epoch 014:   1048 / 1474 loss=2.081, trans_loss=5.118, nll_loss=2.344, w2v_ctc_loss=0.716, task_loss=1.425, contrastive_loss=0.107, total=4143.92, n_correct=2563.69, ppl=5.08, accuracy=61.866, wps=12139.2, ups=1.46, wpb=8287.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=17753
2023-08-04 05:43:15 | INFO | train_inner | epoch 014:   1148 / 1474 loss=2.101, trans_loss=5.117, nll_loss=2.344, w2v_ctc_loss=0.726, task_loss=1.311, contrastive_loss=0.383, total=4228.69, n_correct=2614.01, ppl=5.08, accuracy=61.816, wps=12347.1, ups=1.46, wpb=8457.4, bsz=327.2, num_updates=20300, lr=9.92583e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=17822
2023-08-04 05:44:22 | INFO | train_inner | epoch 014:   1248 / 1474 loss=2.095, trans_loss=5.135, nll_loss=2.363, w2v_ctc_loss=0.737, task_loss=1.646, contrastive_loss=0.064, total=4021.19, n_correct=2475.7, ppl=5.15, accuracy=61.566, wps=11884.6, ups=1.48, wpb=8042.4, bsz=271.7, num_updates=20400, lr=9.90148e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=17889
2023-08-04 05:45:31 | INFO | train_inner | epoch 014:   1348 / 1474 loss=2.078, trans_loss=5.121, nll_loss=2.349, w2v_ctc_loss=0.716, task_loss=1.318, contrastive_loss=0.086, total=4213.9, n_correct=2607.15, ppl=5.1, accuracy=61.87, wps=12288.4, ups=1.46, wpb=8427.8, bsz=319.4, num_updates=20500, lr=9.8773e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=17958
2023-08-04 05:46:38 | INFO | train_inner | epoch 014:   1448 / 1474 loss=2.086, trans_loss=5.128, nll_loss=2.357, w2v_ctc_loss=0.721, task_loss=1.4, contrastive_loss=0.124, total=4130.28, n_correct=2552.74, ppl=5.12, accuracy=61.805, wps=12241.9, ups=1.48, wpb=8260.6, bsz=304.1, num_updates=20600, lr=9.85329e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=67, gb_free=15.3, wall=18025
2023-08-04 05:46:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:2')
2023-08-04 05:47:18 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.228 | trans_loss 5.606 | nll_loss 2.898 | w2v_ctc_loss 1.336 | task_loss 4.583 | contrastive_loss 0.274 | total 4003.4 | n_correct 2454.5 | ppl 7.45 | accuracy 61.31 | uer 17.944 | wer 19.712 | raw_wer 19.712 | bleu 19.66 | wps 2306.7 | wpb 4003.4 | bsz 141.8 | num_updates 20626 | best_bleu 19.84
2023-08-04 05:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20626 updates
2023-08-04 05:47:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.6605.pt
2023-08-04 05:47:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.6605.pt
2023-08-04 05:47:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.6605.pt (epoch 14 @ 20626 updates, score 19.66) (writing took 14.73628343641758 seconds)
2023-08-04 05:47:34 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-04 05:47:34 | INFO | train | epoch 014 | loss 2.081 | trans_loss 5.11 | nll_loss 2.333 | w2v_ctc_loss 0.72 | task_loss 1.401 | contrastive_loss 0.134 | total 4138.65 | n_correct 2567.16 | ppl 5.04 | accuracy 62.029 | wps 11160.8 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 20626 | lr 9.84708e-05 | gnorm 0.553 | clip 0 | loss_scale 32 | train_wall 992 | gb_free 16.3 | wall 18081
2023-08-04 05:47:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 05:47:34 | INFO | fairseq.trainer | begin training epoch 15
2023-08-04 05:47:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 05:48:31 | INFO | train_inner | epoch 015:     74 / 1474 loss=2.075, trans_loss=5.095, nll_loss=2.313, w2v_ctc_loss=0.713, task_loss=1.406, contrastive_loss=0.172, total=4083.88, n_correct=2549.04, ppl=4.97, accuracy=62.417, wps=7227.1, ups=0.88, wpb=8167.8, bsz=300.2, num_updates=20700, lr=9.82946e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=18138
2023-08-04 05:49:39 | INFO | train_inner | epoch 015:    174 / 1474 loss=2.067, trans_loss=5.086, nll_loss=2.301, w2v_ctc_loss=0.717, task_loss=1.456, contrastive_loss=0.082, total=4115.73, n_correct=2574.33, ppl=4.93, accuracy=62.549, wps=12126.3, ups=1.47, wpb=8231.5, bsz=297.8, num_updates=20800, lr=9.80581e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=18206
2023-08-04 05:50:47 | INFO | train_inner | epoch 015:    274 / 1474 loss=2.06, trans_loss=5.086, nll_loss=2.302, w2v_ctc_loss=0.704, task_loss=1.345, contrastive_loss=0.072, total=4193.15, n_correct=2628.65, ppl=4.93, accuracy=62.689, wps=12391.4, ups=1.48, wpb=8386.3, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=67, gb_free=12.6, wall=18274
2023-08-04 05:51:55 | INFO | train_inner | epoch 015:    374 / 1474 loss=2.064, trans_loss=5.082, nll_loss=2.295, w2v_ctc_loss=0.708, task_loss=1.409, contrastive_loss=0.1, total=4167.66, n_correct=2603.33, ppl=4.91, accuracy=62.465, wps=12339.3, ups=1.48, wpb=8335.3, bsz=306, num_updates=21000, lr=9.759e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=67, gb_free=16, wall=18342
2023-08-04 05:53:02 | INFO | train_inner | epoch 015:    474 / 1474 loss=2.072, trans_loss=5.089, nll_loss=2.305, w2v_ctc_loss=0.702, task_loss=1.461, contrastive_loss=0.187, total=4074.53, n_correct=2538.26, ppl=4.94, accuracy=62.296, wps=12056.2, ups=1.48, wpb=8149.1, bsz=294.2, num_updates=21100, lr=9.73585e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=67, gb_free=15.7, wall=18409
2023-08-04 05:54:10 | INFO | train_inner | epoch 015:    574 / 1474 loss=2.066, trans_loss=5.088, nll_loss=2.305, w2v_ctc_loss=0.714, task_loss=1.45, contrastive_loss=0.081, total=4140.59, n_correct=2586.95, ppl=4.94, accuracy=62.478, wps=12242.6, ups=1.48, wpb=8281.2, bsz=298.8, num_updates=21200, lr=9.71286e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=67, gb_free=12, wall=18477
2023-08-04 05:55:17 | INFO | train_inner | epoch 015:    674 / 1474 loss=2.075, trans_loss=5.09, nll_loss=2.306, w2v_ctc_loss=0.717, task_loss=1.413, contrastive_loss=0.167, total=4134.99, n_correct=2584.41, ppl=4.95, accuracy=62.501, wps=12234.2, ups=1.48, wpb=8270, bsz=307.1, num_updates=21300, lr=9.69003e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=67, gb_free=10.5, wall=18544
2023-08-04 05:56:25 | INFO | train_inner | epoch 015:    774 / 1474 loss=2.071, trans_loss=5.099, nll_loss=2.319, w2v_ctc_loss=0.717, task_loss=1.415, contrastive_loss=0.083, total=4173.66, n_correct=2597.39, ppl=4.99, accuracy=62.233, wps=12307, ups=1.47, wpb=8347.3, bsz=305, num_updates=21400, lr=9.66736e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=18612
2023-08-04 05:57:32 | INFO | train_inner | epoch 015:    874 / 1474 loss=2.077, trans_loss=5.106, nll_loss=2.328, w2v_ctc_loss=0.722, task_loss=1.509, contrastive_loss=0.078, total=4059.35, n_correct=2521.94, ppl=5.02, accuracy=62.127, wps=12071.7, ups=1.49, wpb=8118.7, bsz=288.3, num_updates=21500, lr=9.64486e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=18680
2023-08-04 05:58:40 | INFO | train_inner | epoch 015:    974 / 1474 loss=2.072, trans_loss=5.099, nll_loss=2.319, w2v_ctc_loss=0.708, task_loss=1.41, contrastive_loss=0.161, total=4122.87, n_correct=2568.19, ppl=4.99, accuracy=62.291, wps=12289.4, ups=1.49, wpb=8245.7, bsz=301.7, num_updates=21600, lr=9.6225e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=18747
2023-08-04 05:59:48 | INFO | train_inner | epoch 015:   1074 / 1474 loss=2.086, trans_loss=5.106, nll_loss=2.329, w2v_ctc_loss=0.713, task_loss=1.311, contrastive_loss=0.325, total=4192.24, n_correct=2605.05, ppl=5.03, accuracy=62.14, wps=12224.1, ups=1.46, wpb=8384.5, bsz=325.2, num_updates=21700, lr=9.60031e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=18815
2023-08-04 06:00:55 | INFO | train_inner | epoch 015:   1174 / 1474 loss=2.056, trans_loss=5.092, nll_loss=2.313, w2v_ctc_loss=0.693, task_loss=1.254, contrastive_loss=0.127, total=4185, n_correct=2623.14, ppl=4.97, accuracy=62.68, wps=12488.2, ups=1.49, wpb=8370, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=18882
2023-08-04 06:02:03 | INFO | train_inner | epoch 015:   1274 / 1474 loss=2.073, trans_loss=5.102, nll_loss=2.324, w2v_ctc_loss=0.72, task_loss=1.423, contrastive_loss=0.082, total=4152.04, n_correct=2582.69, ppl=5.01, accuracy=62.203, wps=12297.5, ups=1.48, wpb=8304.1, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=67, gb_free=16.5, wall=18950
2023-08-04 06:03:10 | INFO | train_inner | epoch 015:   1374 / 1474 loss=2.067, trans_loss=5.102, nll_loss=2.323, w2v_ctc_loss=0.708, task_loss=1.445, contrastive_loss=0.066, total=4100.21, n_correct=2555.4, ppl=5, accuracy=62.324, wps=12182.8, ups=1.49, wpb=8200.4, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=67, gb_free=17.5, wall=19017
2023-08-04 06:03:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 06:03:32 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.209 | trans_loss 5.595 | nll_loss 2.879 | w2v_ctc_loss 1.304 | task_loss 4.597 | contrastive_loss 0.26 | total 4003.4 | n_correct 2457.9 | ppl 7.35 | accuracy 61.395 | uer 17.676 | wer 19.466 | raw_wer 19.466 | bleu 19.9 | wps 2329.7 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.9
2023-08-04 06:03:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-04 06:03:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_15_22000.pt
2023-08-04 06:03:37 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_15_22000.pt
2023-08-04 06:04:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.9) (writing took 44.97025647573173 seconds)
2023-08-04 06:05:27 | INFO | train_inner | epoch 015:   1474 / 1474 loss=2.076, trans_loss=5.107, nll_loss=2.332, w2v_ctc_loss=0.712, task_loss=1.356, contrastive_loss=0.162, total=4141.17, n_correct=2575.86, ppl=5.03, accuracy=62.201, wps=6050.3, ups=0.73, wpb=8282.3, bsz=314.3, num_updates=22100, lr=9.51303e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=68, gb_free=16.9, wall=19154
2023-08-04 06:05:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 06:05:50 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.221 | trans_loss 5.595 | nll_loss 2.88 | w2v_ctc_loss 1.348 | task_loss 4.602 | contrastive_loss 0.259 | total 4003.4 | n_correct 2458.5 | ppl 7.36 | accuracy 61.41 | uer 17.644 | wer 19.362 | raw_wer 19.362 | bleu 19.53 | wps 2164.3 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 19.9
2023-08-04 06:05:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-08-04 06:05:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.5308.pt
2023-08-04 06:05:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.5308.pt
2023-08-04 06:06:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.5308.pt (epoch 15 @ 22100 updates, score 19.53) (writing took 13.868192477151752 seconds)
2023-08-04 06:06:05 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-04 06:06:05 | INFO | train | epoch 015 | loss 2.07 | trans_loss 5.094 | nll_loss 2.313 | w2v_ctc_loss 0.71 | task_loss 1.4 | contrastive_loss 0.131 | total 4138.65 | n_correct 2582.27 | ppl 4.97 | accuracy 62.394 | wps 10981.9 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.555 | clip 0 | loss_scale 64 | train_wall 990 | gb_free 16.9 | wall 19192
2023-08-04 06:06:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 06:06:05 | INFO | fairseq.trainer | begin training epoch 16
2023-08-04 06:06:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 06:07:20 | INFO | train_inner | epoch 016:    100 / 1474 loss=2.048, trans_loss=5.062, nll_loss=2.271, w2v_ctc_loss=0.696, task_loss=1.333, contrastive_loss=0.103, total=4126.22, n_correct=2603.27, ppl=4.83, accuracy=63.091, wps=7324.4, ups=0.89, wpb=8252.4, bsz=315.6, num_updates=22200, lr=9.49158e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=66, gb_free=16, wall=19267
2023-08-04 06:08:27 | INFO | train_inner | epoch 016:    200 / 1474 loss=2.047, trans_loss=5.061, nll_loss=2.269, w2v_ctc_loss=0.693, task_loss=1.438, contrastive_loss=0.075, total=4100.6, n_correct=2585.12, ppl=4.82, accuracy=63.042, wps=12159.4, ups=1.48, wpb=8201.2, bsz=296.8, num_updates=22300, lr=9.47027e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=67, gb_free=12.5, wall=19334
2023-08-04 06:09:35 | INFO | train_inner | epoch 016:    300 / 1474 loss=2.06, trans_loss=5.073, nll_loss=2.285, w2v_ctc_loss=0.704, task_loss=1.386, contrastive_loss=0.149, total=4166.94, n_correct=2617.71, ppl=4.87, accuracy=62.821, wps=12298.2, ups=1.48, wpb=8333.9, bsz=308.9, num_updates=22400, lr=9.44911e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=67, gb_free=17.2, wall=19402
2023-08-04 06:10:42 | INFO | train_inner | epoch 016:    400 / 1474 loss=2.066, trans_loss=5.074, nll_loss=2.286, w2v_ctc_loss=0.709, task_loss=1.489, contrastive_loss=0.161, total=4073.3, n_correct=2554.71, ppl=4.88, accuracy=62.718, wps=12087, ups=1.48, wpb=8146.6, bsz=288.1, num_updates=22500, lr=9.42809e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=67, gb_free=17, wall=19469
2023-08-04 06:11:50 | INFO | train_inner | epoch 016:    500 / 1474 loss=2.053, trans_loss=5.07, nll_loss=2.283, w2v_ctc_loss=0.7, task_loss=1.346, contrastive_loss=0.109, total=4174.67, n_correct=2630.33, ppl=4.87, accuracy=63.007, wps=12246.7, ups=1.47, wpb=8349.3, bsz=319.1, num_updates=22600, lr=9.40721e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=68, gb_free=15.9, wall=19537
2023-08-04 06:12:57 | INFO | train_inner | epoch 016:    600 / 1474 loss=2.054, trans_loss=5.075, nll_loss=2.288, w2v_ctc_loss=0.7, task_loss=1.412, contrastive_loss=0.068, total=4124.65, n_correct=2592.51, ppl=4.88, accuracy=62.854, wps=12310.7, ups=1.49, wpb=8249.3, bsz=297.6, num_updates=22700, lr=9.38647e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=67, gb_free=16.2, wall=19604
2023-08-04 06:14:05 | INFO | train_inner | epoch 016:    700 / 1474 loss=2.057, trans_loss=5.08, nll_loss=2.293, w2v_ctc_loss=0.704, task_loss=1.434, contrastive_loss=0.071, total=4095.49, n_correct=2570.73, ppl=4.9, accuracy=62.77, wps=12193, ups=1.49, wpb=8191, bsz=296.3, num_updates=22800, lr=9.36586e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=67, gb_free=16.1, wall=19672
2023-08-04 06:15:12 | INFO | train_inner | epoch 016:    800 / 1474 loss=2.058, trans_loss=5.082, nll_loss=2.298, w2v_ctc_loss=0.696, task_loss=1.346, contrastive_loss=0.134, total=4174.94, n_correct=2617.35, ppl=4.92, accuracy=62.692, wps=12369.9, ups=1.48, wpb=8349.9, bsz=310.9, num_updates=22900, lr=9.34539e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=67, gb_free=16.4, wall=19739
2023-08-04 06:16:20 | INFO | train_inner | epoch 016:    900 / 1474 loss=2.057, trans_loss=5.079, nll_loss=2.295, w2v_ctc_loss=0.698, task_loss=1.358, contrastive_loss=0.127, total=4163.19, n_correct=2614.71, ppl=4.91, accuracy=62.805, wps=12326.2, ups=1.48, wpb=8326.4, bsz=310.6, num_updates=23000, lr=9.32505e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=67, gb_free=16.7, wall=19807
2023-08-04 06:17:27 | INFO | train_inner | epoch 016:   1000 / 1474 loss=2.071, trans_loss=5.093, nll_loss=2.311, w2v_ctc_loss=0.716, task_loss=1.46, contrastive_loss=0.124, total=4103.45, n_correct=2562.79, ppl=4.96, accuracy=62.455, wps=12177.9, ups=1.48, wpb=8206.9, bsz=298.1, num_updates=23100, lr=9.30484e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=67, gb_free=14.8, wall=19874
2023-08-04 06:18:35 | INFO | train_inner | epoch 016:   1100 / 1474 loss=2.074, trans_loss=5.1, nll_loss=2.321, w2v_ctc_loss=0.721, task_loss=1.489, contrastive_loss=0.101, total=4119.27, n_correct=2566.47, ppl=5, accuracy=62.304, wps=12134.5, ups=1.47, wpb=8238.5, bsz=295.3, num_updates=23200, lr=9.28477e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=67, gb_free=17.8, wall=19942
2023-08-04 06:19:44 | INFO | train_inner | epoch 016:   1200 / 1474 loss=2.064, trans_loss=5.088, nll_loss=2.307, w2v_ctc_loss=0.693, task_loss=1.412, contrastive_loss=0.194, total=4165.11, n_correct=2607.79, ppl=4.95, accuracy=62.61, wps=12134.1, ups=1.46, wpb=8330.2, bsz=308.7, num_updates=23300, lr=9.26482e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=20011
2023-08-04 06:20:52 | INFO | train_inner | epoch 016:   1300 / 1474 loss=2.068, trans_loss=5.091, nll_loss=2.31, w2v_ctc_loss=0.709, task_loss=1.375, contrastive_loss=0.173, total=4134.61, n_correct=2588.29, ppl=4.96, accuracy=62.601, wps=12157, ups=1.47, wpb=8269.2, bsz=310.8, num_updates=23400, lr=9.245e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=20079
2023-08-04 06:22:00 | INFO | train_inner | epoch 016:   1400 / 1474 loss=2.062, trans_loss=5.091, nll_loss=2.311, w2v_ctc_loss=0.71, task_loss=1.335, contrastive_loss=0.107, total=4206.33, n_correct=2629.34, ppl=4.96, accuracy=62.509, wps=12364.9, ups=1.47, wpb=8412.7, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=68, gb_free=15.5, wall=20147
2023-08-04 06:22:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 06:23:13 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.219 | trans_loss 5.592 | nll_loss 2.875 | w2v_ctc_loss 1.345 | task_loss 4.628 | contrastive_loss 0.262 | total 4003.4 | n_correct 2467.3 | ppl 7.34 | accuracy 61.63 | uer 17.463 | wer 19.254 | raw_wer 19.254 | bleu 19.91 | wps 2213.7 | wpb 4003.4 | bsz 141.8 | num_updates 23574 | best_bleu 19.91
2023-08-04 06:23:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23574 updates
2023-08-04 06:23:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 06:23:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 06:23:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 16 @ 23574 updates, score 19.91) (writing took 23.419394675642252 seconds)
2023-08-04 06:23:37 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-04 06:23:37 | INFO | train | epoch 016 | loss 2.061 | trans_loss 5.081 | nll_loss 2.296 | w2v_ctc_loss 0.703 | task_loss 1.399 | contrastive_loss 0.13 | total 4138.65 | n_correct 2595.9 | ppl 4.91 | accuracy 62.723 | wps 11598.3 | ups 1.4 | wpb 8277.3 | bsz 305.7 | num_updates 23574 | lr 9.21082e-05 | gnorm 0.557 | clip 0 | loss_scale 64 | train_wall 990 | gb_free 15.4 | wall 20244
2023-08-04 06:23:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 06:23:37 | INFO | fairseq.trainer | begin training epoch 17
2023-08-04 06:23:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 06:24:03 | INFO | train_inner | epoch 017:     26 / 1474 loss=2.063, trans_loss=5.075, nll_loss=2.288, w2v_ctc_loss=0.697, task_loss=1.41, contrastive_loss=0.236, total=4152.31, n_correct=2607.06, ppl=4.89, accuracy=62.786, wps=6810, ups=0.82, wpb=8304.6, bsz=304.6, num_updates=23600, lr=9.20575e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=68, gb_free=13.6, wall=20269
2023-08-04 06:25:10 | INFO | train_inner | epoch 017:    126 / 1474 loss=2.045, trans_loss=5.051, nll_loss=2.256, w2v_ctc_loss=0.699, task_loss=1.444, contrastive_loss=0.075, total=4118.91, n_correct=2606.13, ppl=4.78, accuracy=63.272, wps=12267.3, ups=1.49, wpb=8237.8, bsz=295.8, num_updates=23700, lr=9.1863e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=67, gb_free=16.4, wall=20337
2023-08-04 06:26:17 | INFO | train_inner | epoch 017:    226 / 1474 loss=2.049, trans_loss=5.051, nll_loss=2.258, w2v_ctc_loss=0.682, task_loss=1.341, contrastive_loss=0.24, total=4145.15, n_correct=2624.35, ppl=4.78, accuracy=63.311, wps=12270.9, ups=1.48, wpb=8290.3, bsz=315, num_updates=23800, lr=9.16698e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=67, gb_free=15.6, wall=20404
2023-08-04 06:27:24 | INFO | train_inner | epoch 017:    326 / 1474 loss=2.05, trans_loss=5.056, nll_loss=2.264, w2v_ctc_loss=0.684, task_loss=1.383, contrastive_loss=0.24, total=4169.51, n_correct=2636.77, ppl=4.8, accuracy=63.239, wps=12422.9, ups=1.49, wpb=8339, bsz=308.1, num_updates=23900, lr=9.14779e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=67, gb_free=16.8, wall=20472
2023-08-04 06:28:33 | INFO | train_inner | epoch 017:    426 / 1474 loss=2.041, trans_loss=5.057, nll_loss=2.266, w2v_ctc_loss=0.69, task_loss=1.394, contrastive_loss=0.073, total=4140.49, n_correct=2620.15, ppl=4.81, accuracy=63.281, wps=12152.1, ups=1.47, wpb=8281, bsz=306.9, num_updates=24000, lr=9.12871e-05, gnorm=0.553, clip=0, loss_scale=128, train_wall=68, gb_free=16.9, wall=20540
2023-08-04 06:28:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 06:28:57 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.224 | trans_loss 5.596 | nll_loss 2.88 | w2v_ctc_loss 1.353 | task_loss 4.595 | contrastive_loss 0.262 | total 4003.4 | n_correct 2462.5 | ppl 7.36 | accuracy 61.51 | uer 17.471 | wer 19.336 | raw_wer 19.336 | bleu 19.89 | wps 2020.1 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 19.91
2023-08-04 06:28:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-04 06:28:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_17_24000.pt
2023-08-04 06:29:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_17_24000.pt
2023-08-04 06:29:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.89) (writing took 30.07621005550027 seconds)
2023-08-04 06:29:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-04 06:30:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 06:30:38 | INFO | train_inner | epoch 017:    528 / 1474 loss=2.048, trans_loss=5.064, nll_loss=2.274, w2v_ctc_loss=0.697, task_loss=1.478, contrastive_loss=0.078, total=4165.13, n_correct=2625.79, ppl=4.84, accuracy=63.042, wps=6645.7, ups=0.8, wpb=8330.3, bsz=301.6, num_updates=24100, lr=9.10975e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=70, gb_free=17.1, wall=20665
2023-08-04 06:31:46 | INFO | train_inner | epoch 017:    628 / 1474 loss=2.047, trans_loss=5.069, nll_loss=2.281, w2v_ctc_loss=0.694, task_loss=1.406, contrastive_loss=0.068, total=4166.6, n_correct=2628.18, ppl=4.86, accuracy=63.077, wps=12324, ups=1.48, wpb=8333.2, bsz=302.3, num_updates=24200, lr=9.09091e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=67, gb_free=15.6, wall=20733
2023-08-04 06:32:53 | INFO | train_inner | epoch 017:    728 / 1474 loss=2.058, trans_loss=5.07, nll_loss=2.283, w2v_ctc_loss=0.708, task_loss=1.383, contrastive_loss=0.123, total=4168.97, n_correct=2624.85, ppl=4.87, accuracy=62.962, wps=12356.8, ups=1.48, wpb=8337.9, bsz=308.4, num_updates=24300, lr=9.07218e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=20800
2023-08-04 06:34:00 | INFO | train_inner | epoch 017:    828 / 1474 loss=2.05, trans_loss=5.07, nll_loss=2.282, w2v_ctc_loss=0.696, task_loss=1.407, contrastive_loss=0.082, total=4097.38, n_correct=2580.75, ppl=4.86, accuracy=62.985, wps=12168.3, ups=1.48, wpb=8194.8, bsz=297.3, num_updates=24400, lr=9.05357e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=67, gb_free=10.3, wall=20867
2023-08-04 06:35:07 | INFO | train_inner | epoch 017:    928 / 1474 loss=2.045, trans_loss=5.069, nll_loss=2.282, w2v_ctc_loss=0.689, task_loss=1.382, contrastive_loss=0.079, total=4105.01, n_correct=2587.46, ppl=4.86, accuracy=63.032, wps=12343.8, ups=1.5, wpb=8210, bsz=304.1, num_updates=24500, lr=9.03508e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=66, gb_free=16.6, wall=20934
2023-08-04 06:36:15 | INFO | train_inner | epoch 017:   1028 / 1474 loss=2.05, trans_loss=5.072, nll_loss=2.285, w2v_ctc_loss=0.698, task_loss=1.397, contrastive_loss=0.084, total=4105.88, n_correct=2585.14, ppl=4.87, accuracy=62.962, wps=12135.4, ups=1.48, wpb=8211.8, bsz=303.4, num_updates=24600, lr=9.0167e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=21002
2023-08-04 06:37:22 | INFO | train_inner | epoch 017:   1128 / 1474 loss=2.047, trans_loss=5.071, nll_loss=2.284, w2v_ctc_loss=0.691, task_loss=1.433, contrastive_loss=0.074, total=4095.58, n_correct=2582.19, ppl=4.87, accuracy=63.048, wps=12167.8, ups=1.49, wpb=8191.2, bsz=298.5, num_updates=24700, lr=8.99843e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=21069
2023-08-04 06:38:30 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2.067, trans_loss=5.081, nll_loss=2.299, w2v_ctc_loss=0.69, task_loss=1.37, contrastive_loss=0.317, total=4162.14, n_correct=2605.17, ppl=4.92, accuracy=62.592, wps=12220.2, ups=1.47, wpb=8324.3, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=21137
2023-08-04 06:39:37 | INFO | train_inner | epoch 017:   1328 / 1474 loss=2.055, trans_loss=5.08, nll_loss=2.296, w2v_ctc_loss=0.688, task_loss=1.394, contrastive_loss=0.157, total=4149.03, n_correct=2606.71, ppl=4.91, accuracy=62.827, wps=12316.4, ups=1.48, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=21205
2023-08-04 06:40:45 | INFO | train_inner | epoch 017:   1428 / 1474 loss=2.048, trans_loss=5.077, nll_loss=2.293, w2v_ctc_loss=0.691, task_loss=1.407, contrastive_loss=0.074, total=4117.13, n_correct=2590.37, ppl=4.9, accuracy=62.917, wps=12169.6, ups=1.48, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=21272
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:0')
2023-08-04 06:41:16 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:7')
2023-08-04 06:41:40 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.588 | nll_loss 2.874 | w2v_ctc_loss 1.349 | task_loss 4.583 | contrastive_loss 0.269 | total 4003.4 | n_correct 2463.6 | ppl 7.33 | accuracy 61.538 | uer 17.896 | wer 19.742 | raw_wer 19.742 | bleu 19.87 | wps 2073 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 19.91
2023-08-04 06:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-08-04 06:41:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.8707.pt
2023-08-04 06:41:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.8707.pt
2023-08-04 06:41:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.8707.pt (epoch 17 @ 25046 updates, score 19.87) (writing took 13.692774379625916 seconds)
2023-08-04 06:41:54 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-04 06:41:54 | INFO | train | epoch 017 | loss 2.05 | trans_loss 5.067 | nll_loss 2.279 | w2v_ctc_loss 0.693 | task_loss 1.401 | contrastive_loss 0.125 | total 4137.51 | n_correct 2608.12 | ppl 4.85 | accuracy 63.036 | wps 11098.6 | ups 1.34 | wpb 8275 | bsz 305.3 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.558 | clip 0 | loss_scale 32 | train_wall 989 | gb_free 16.3 | wall 21341
2023-08-04 06:41:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 06:41:54 | INFO | fairseq.trainer | begin training epoch 18
2023-08-04 06:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 06:42:39 | INFO | train_inner | epoch 018:     54 / 1474 loss=2.046, trans_loss=5.061, nll_loss=2.271, w2v_ctc_loss=0.696, task_loss=1.427, contrastive_loss=0.083, total=4138.21, n_correct=2610.58, ppl=4.83, accuracy=63.085, wps=7257, ups=0.88, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=21386
2023-08-04 06:43:47 | INFO | train_inner | epoch 018:    154 / 1474 loss=2.036, trans_loss=5.036, nll_loss=2.238, w2v_ctc_loss=0.669, task_loss=1.333, contrastive_loss=0.208, total=4158.88, n_correct=2644.95, ppl=4.72, accuracy=63.598, wps=12301, ups=1.48, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=21454
2023-08-04 06:44:55 | INFO | train_inner | epoch 018:    254 / 1474 loss=2.026, trans_loss=5.035, nll_loss=2.237, w2v_ctc_loss=0.678, task_loss=1.356, contrastive_loss=0.074, total=4164.11, n_correct=2655.41, ppl=4.72, accuracy=63.769, wps=12290.8, ups=1.48, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=67, gb_free=14.9, wall=21522
2023-08-04 06:46:02 | INFO | train_inner | epoch 018:    354 / 1474 loss=2.037, trans_loss=5.045, nll_loss=2.249, w2v_ctc_loss=0.685, task_loss=1.423, contrastive_loss=0.09, total=4163.13, n_correct=2641.86, ppl=4.75, accuracy=63.459, wps=12286.1, ups=1.48, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=67, gb_free=17.6, wall=21589
2023-08-04 06:47:11 | INFO | train_inner | epoch 018:    454 / 1474 loss=2.047, trans_loss=5.053, nll_loss=2.259, w2v_ctc_loss=0.686, task_loss=1.494, contrastive_loss=0.18, total=4087.83, n_correct=2586.7, ppl=4.79, accuracy=63.278, wps=11965.5, ups=1.46, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=21658
2023-08-04 06:48:19 | INFO | train_inner | epoch 018:    554 / 1474 loss=2.025, trans_loss=5.038, nll_loss=2.242, w2v_ctc_loss=0.675, task_loss=1.257, contrastive_loss=0.092, total=4204.41, n_correct=2679.44, ppl=4.73, accuracy=63.729, wps=12372.7, ups=1.47, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=67, gb_free=17.4, wall=21726
2023-08-04 06:49:26 | INFO | train_inner | epoch 018:    654 / 1474 loss=2.049, trans_loss=5.062, nll_loss=2.272, w2v_ctc_loss=0.69, task_loss=1.447, contrastive_loss=0.158, total=4096.81, n_correct=2588.56, ppl=4.83, accuracy=63.185, wps=12170.6, ups=1.49, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=21793
2023-08-04 06:50:34 | INFO | train_inner | epoch 018:    754 / 1474 loss=2.053, trans_loss=5.059, nll_loss=2.269, w2v_ctc_loss=0.694, task_loss=1.334, contrastive_loss=0.25, total=4208.29, n_correct=2656.03, ppl=4.82, accuracy=63.114, wps=12415.9, ups=1.48, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=67, gb_free=17.8, wall=21861
2023-08-04 06:51:41 | INFO | train_inner | epoch 018:    854 / 1474 loss=2.039, trans_loss=5.057, nll_loss=2.266, w2v_ctc_loss=0.684, task_loss=1.421, contrastive_loss=0.064, total=4166.81, n_correct=2636.7, ppl=4.81, accuracy=63.279, wps=12312.2, ups=1.48, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=67, gb_free=12.5, wall=21928
2023-08-04 06:52:49 | INFO | train_inner | epoch 018:    954 / 1474 loss=2.031, trans_loss=5.05, nll_loss=2.258, w2v_ctc_loss=0.674, task_loss=1.303, contrastive_loss=0.091, total=4142.65, n_correct=2633.07, ppl=4.78, accuracy=63.56, wps=12321.2, ups=1.49, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=67, gb_free=14.8, wall=21996
2023-08-04 06:52:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 06:53:12 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.595 | nll_loss 2.876 | w2v_ctc_loss 1.335 | task_loss 4.61 | contrastive_loss 0.263 | total 4003.4 | n_correct 2465 | ppl 7.34 | accuracy 61.573 | uer 17.519 | wer 19.28 | raw_wer 19.28 | bleu 20.02 | wps 2092.3 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.02
2023-08-04 06:53:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-04 06:53:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_18_26000.pt
2023-08-04 06:53:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_18_26000.pt
2023-08-04 06:53:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 20.02) (writing took 38.075698195025325 seconds)
2023-08-04 06:54:59 | INFO | train_inner | epoch 018:   1054 / 1474 loss=2.037, trans_loss=5.057, nll_loss=2.267, w2v_ctc_loss=0.677, task_loss=1.458, contrastive_loss=0.077, total=4137.77, n_correct=2621.13, ppl=4.81, accuracy=63.346, wps=6334.3, ups=0.77, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=22126
2023-08-04 06:56:07 | INFO | train_inner | epoch 018:   1154 / 1474 loss=2.041, trans_loss=5.048, nll_loss=2.256, w2v_ctc_loss=0.682, task_loss=1.326, contrastive_loss=0.183, total=4153.69, n_correct=2635.71, ppl=4.78, accuracy=63.455, wps=12356.5, ups=1.49, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=67, gb_free=15, wall=22194
2023-08-04 06:57:14 | INFO | train_inner | epoch 018:   1254 / 1474 loss=2.044, trans_loss=5.069, nll_loss=2.282, w2v_ctc_loss=0.686, task_loss=1.503, contrastive_loss=0.069, total=4087.62, n_correct=2577.2, ppl=4.86, accuracy=63.049, wps=12135.5, ups=1.48, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=22261
2023-08-04 06:58:21 | INFO | train_inner | epoch 018:   1354 / 1474 loss=2.056, trans_loss=5.076, nll_loss=2.291, w2v_ctc_loss=0.701, task_loss=1.491, contrastive_loss=0.096, total=4070.69, n_correct=2561.86, ppl=4.9, accuracy=62.934, wps=12059.3, ups=1.48, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=67, gb_free=17.3, wall=22329
2023-08-04 06:59:29 | INFO | train_inner | epoch 018:   1454 / 1474 loss=2.045, trans_loss=5.068, nll_loss=2.281, w2v_ctc_loss=0.69, task_loss=1.475, contrastive_loss=0.082, total=4113.2, n_correct=2592.31, ppl=4.86, accuracy=63.024, wps=12154.3, ups=1.48, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.561, clip=0, loss_scale=64, train_wall=67, gb_free=16.4, wall=22396
2023-08-04 06:59:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 07:00:06 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.227 | trans_loss 5.589 | nll_loss 2.872 | w2v_ctc_loss 1.377 | task_loss 4.605 | contrastive_loss 0.267 | total 4003.4 | n_correct 2471.4 | ppl 7.32 | accuracy 61.733 | uer 17.262 | wer 19.022 | raw_wer 19.022 | bleu 19.85 | wps 2131.4 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 20.02
2023-08-04 07:00:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-08-04 07:00:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.8507.pt
2023-08-04 07:00:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.8507.pt
2023-08-04 07:00:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.8507.pt (epoch 18 @ 26520 updates, score 19.85) (writing took 17.3537590354681 seconds)
2023-08-04 07:00:24 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-04 07:00:24 | INFO | train | epoch 018 | loss 2.04 | trans_loss 5.054 | nll_loss 2.262 | w2v_ctc_loss 0.684 | task_loss 1.4 | contrastive_loss 0.126 | total 4138.65 | n_correct 2621.55 | ppl 4.8 | accuracy 63.343 | wps 10994.2 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.557 | clip 0 | loss_scale 64 | train_wall 991 | gb_free 15.9 | wall 22451
2023-08-04 07:00:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 07:00:24 | INFO | fairseq.trainer | begin training epoch 19
2023-08-04 07:00:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 07:01:25 | INFO | train_inner | epoch 019:     80 / 1474 loss=2.03, trans_loss=5.03, nll_loss=2.23, w2v_ctc_loss=0.678, task_loss=1.403, contrastive_loss=0.13, total=4102.06, n_correct=2614.19, ppl=4.69, accuracy=63.729, wps=7091.7, ups=0.86, wpb=8204.1, bsz=296.9, num_updates=26600, lr=8.6711e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=67, gb_free=17.4, wall=22512
2023-08-04 07:02:33 | INFO | train_inner | epoch 019:    180 / 1474 loss=2.028, trans_loss=5.021, nll_loss=2.22, w2v_ctc_loss=0.686, task_loss=1.303, contrastive_loss=0.127, total=4227.7, n_correct=2704.51, ppl=4.66, accuracy=63.971, wps=12423, ups=1.47, wpb=8455.4, bsz=324.8, num_updates=26700, lr=8.65485e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=68, gb_free=17, wall=22580
2023-08-04 07:03:41 | INFO | train_inner | epoch 019:    280 / 1474 loss=2.022, trans_loss=5.024, nll_loss=2.222, w2v_ctc_loss=0.677, task_loss=1.383, contrastive_loss=0.066, total=4187.34, n_correct=2681.44, ppl=4.67, accuracy=64.037, wps=12380.7, ups=1.48, wpb=8374.7, bsz=306.4, num_updates=26800, lr=8.63868e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=67, gb_free=15.9, wall=22648
2023-08-04 07:04:48 | INFO | train_inner | epoch 019:    380 / 1474 loss=2.03, trans_loss=5.03, nll_loss=2.231, w2v_ctc_loss=0.669, task_loss=1.38, contrastive_loss=0.174, total=4170.52, n_correct=2658.82, ppl=4.7, accuracy=63.753, wps=12381.3, ups=1.48, wpb=8341, bsz=311, num_updates=26900, lr=8.62261e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=67, gb_free=16.3, wall=22715
2023-08-04 07:05:55 | INFO | train_inner | epoch 019:    480 / 1474 loss=2.03, trans_loss=5.037, nll_loss=2.24, w2v_ctc_loss=0.682, task_loss=1.438, contrastive_loss=0.084, total=4113.89, n_correct=2623.02, ppl=4.72, accuracy=63.76, wps=12187.5, ups=1.48, wpb=8227.8, bsz=301.5, num_updates=27000, lr=8.60663e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=67, gb_free=17.1, wall=22782
2023-08-04 07:07:03 | INFO | train_inner | epoch 019:    580 / 1474 loss=2.028, trans_loss=5.034, nll_loss=2.237, w2v_ctc_loss=0.674, task_loss=1.371, contrastive_loss=0.146, total=4128.58, n_correct=2634.95, ppl=4.71, accuracy=63.822, wps=12222.2, ups=1.48, wpb=8257.2, bsz=306.2, num_updates=27100, lr=8.59074e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=22850
2023-08-04 07:08:10 | INFO | train_inner | epoch 019:    680 / 1474 loss=2.016, trans_loss=5.036, nll_loss=2.239, w2v_ctc_loss=0.659, task_loss=1.273, contrastive_loss=0.072, total=4201.56, n_correct=2681.91, ppl=4.72, accuracy=63.831, wps=12452.5, ups=1.48, wpb=8403.1, bsz=321.5, num_updates=27200, lr=8.57493e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=67, gb_free=17.8, wall=22918
2023-08-04 07:09:19 | INFO | train_inner | epoch 019:    780 / 1474 loss=2.031, trans_loss=5.038, nll_loss=2.241, w2v_ctc_loss=0.683, task_loss=1.441, contrastive_loss=0.079, total=4124.03, n_correct=2627.44, ppl=4.73, accuracy=63.71, wps=12121.3, ups=1.47, wpb=8248.1, bsz=299, num_updates=27300, lr=8.55921e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=68, gb_free=17.5, wall=22986
2023-08-04 07:10:26 | INFO | train_inner | epoch 019:    880 / 1474 loss=2.035, trans_loss=5.051, nll_loss=2.259, w2v_ctc_loss=0.683, task_loss=1.395, contrastive_loss=0.077, total=4177.8, n_correct=2651.4, ppl=4.79, accuracy=63.464, wps=12371.7, ups=1.48, wpb=8355.6, bsz=309.6, num_updates=27400, lr=8.54358e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=67, gb_free=14.8, wall=23053
2023-08-04 07:11:35 | INFO | train_inner | epoch 019:    980 / 1474 loss=2.051, trans_loss=5.059, nll_loss=2.27, w2v_ctc_loss=0.68, task_loss=1.421, contrastive_loss=0.306, total=4084.26, n_correct=2584.29, ppl=4.82, accuracy=63.274, wps=11864.4, ups=1.45, wpb=8168.5, bsz=305.8, num_updates=27500, lr=8.52803e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=68, gb_free=16.1, wall=23122
2023-08-04 07:12:42 | INFO | train_inner | epoch 019:   1080 / 1474 loss=2.039, trans_loss=5.058, nll_loss=2.269, w2v_ctc_loss=0.678, task_loss=1.472, contrastive_loss=0.114, total=4042.73, n_correct=2560.09, ppl=4.82, accuracy=63.326, wps=12012.9, ups=1.49, wpb=8085.5, bsz=294, num_updates=27600, lr=8.51257e-05, gnorm=0.568, clip=0, loss_scale=64, train_wall=67, gb_free=17.2, wall=23189
2023-08-04 07:13:51 | INFO | train_inner | epoch 019:   1180 / 1474 loss=2.05, trans_loss=5.06, nll_loss=2.27, w2v_ctc_loss=0.687, task_loss=1.427, contrastive_loss=0.198, total=4140.95, n_correct=2614.62, ppl=4.82, accuracy=63.141, wps=12091.1, ups=1.46, wpb=8281.9, bsz=307.9, num_updates=27700, lr=8.49719e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=68, gb_free=12.6, wall=23258
2023-08-04 07:14:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 07:14:59 | INFO | train_inner | epoch 019:   1281 / 1474 loss=2.038, trans_loss=5.061, nll_loss=2.272, w2v_ctc_loss=0.675, task_loss=1.43, contrastive_loss=0.095, total=4135.34, n_correct=2616.96, ppl=4.83, accuracy=63.283, wps=12192.2, ups=1.47, wpb=8270.7, bsz=298, num_updates=27800, lr=8.48189e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=23326
2023-08-04 07:16:07 | INFO | train_inner | epoch 019:   1381 / 1474 loss=2.034, trans_loss=5.052, nll_loss=2.261, w2v_ctc_loss=0.679, task_loss=1.434, contrastive_loss=0.08, total=4133.26, n_correct=2626.02, ppl=4.79, accuracy=63.534, wps=12118.6, ups=1.47, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=23394
2023-08-04 07:17:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 07:17:33 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.208 | trans_loss 5.578 | nll_loss 2.861 | w2v_ctc_loss 1.342 | task_loss 4.671 | contrastive_loss 0.267 | total 4003.4 | n_correct 2472.8 | ppl 7.27 | accuracy 61.767 | uer 17.368 | wer 19.216 | raw_wer 19.216 | bleu 20.06 | wps 2232.2 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.06
2023-08-04 07:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-08-04 07:17:33 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 07:17:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 07:17:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 19 @ 27993 updates, score 20.06) (writing took 24.589834010228515 seconds)
2023-08-04 07:17:58 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-04 07:17:58 | INFO | train | epoch 019 | loss 2.033 | trans_loss 5.042 | nll_loss 2.247 | w2v_ctc_loss 0.678 | task_loss 1.401 | contrastive_loss 0.124 | total 4138.37 | n_correct 2633.01 | ppl 4.75 | accuracy 63.624 | wps 11566.8 | ups 1.4 | wpb 8276.7 | bsz 305.6 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.56 | clip 0 | loss_scale 32 | train_wall 992 | gb_free 17.3 | wall 23505
2023-08-04 07:17:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 07:17:58 | INFO | fairseq.trainer | begin training epoch 20
2023-08-04 07:17:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 07:18:11 | INFO | train_inner | epoch 020:      7 / 1474 loss=2.033, trans_loss=5.045, nll_loss=2.252, w2v_ctc_loss=0.673, task_loss=1.413, contrastive_loss=0.162, total=4119.08, n_correct=2621.83, ppl=4.76, accuracy=63.651, wps=6640.6, ups=0.81, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=23518
2023-08-04 07:18:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 07:18:34 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.201 | trans_loss 5.574 | nll_loss 2.854 | w2v_ctc_loss 1.327 | task_loss 4.654 | contrastive_loss 0.266 | total 4003.4 | n_correct 2477.8 | ppl 7.23 | accuracy 61.892 | uer 17.203 | wer 19.097 | raw_wer 19.097 | bleu 20.07 | wps 2286.4 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.07
2023-08-04 07:18:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-04 07:18:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_20_28000.pt
2023-08-04 07:18:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_20_28000.pt
2023-08-04 07:18:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 20.07) (writing took 25.28653017617762 seconds)
2023-08-04 07:20:08 | INFO | train_inner | epoch 020:    107 / 1474 loss=2.011, trans_loss=5.009, nll_loss=2.204, w2v_ctc_loss=0.661, task_loss=1.351, contrastive_loss=0.089, total=4195.03, n_correct=2693.39, ppl=4.61, accuracy=64.204, wps=7155.3, ups=0.85, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=67, gb_free=14.9, wall=23635
2023-08-04 07:21:16 | INFO | train_inner | epoch 020:    207 / 1474 loss=2.021, trans_loss=5.019, nll_loss=2.215, w2v_ctc_loss=0.667, task_loss=1.45, contrastive_loss=0.139, total=4154.14, n_correct=2658.99, ppl=4.64, accuracy=64.008, wps=12235, ups=1.47, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=23703
2023-08-04 07:22:24 | INFO | train_inner | epoch 020:    307 / 1474 loss=2.01, trans_loss=5.011, nll_loss=2.206, w2v_ctc_loss=0.668, task_loss=1.259, contrastive_loss=0.078, total=4188.05, n_correct=2693.68, ppl=4.62, accuracy=64.318, wps=12401.9, ups=1.48, wpb=8376.1, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=67, gb_free=15.5, wall=23771
2023-08-04 07:23:31 | INFO | train_inner | epoch 020:    407 / 1474 loss=2.014, trans_loss=5.017, nll_loss=2.214, w2v_ctc_loss=0.662, task_loss=1.417, contrastive_loss=0.073, total=4115.16, n_correct=2639.75, ppl=4.64, accuracy=64.147, wps=12222.5, ups=1.49, wpb=8230.3, bsz=297, num_updates=28400, lr=8.39181e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=67, gb_free=15.4, wall=23838
2023-08-04 07:24:39 | INFO | train_inner | epoch 020:    507 / 1474 loss=2.028, trans_loss=5.033, nll_loss=2.235, w2v_ctc_loss=0.667, task_loss=1.433, contrastive_loss=0.162, total=4108.46, n_correct=2621.05, ppl=4.71, accuracy=63.796, wps=12099.5, ups=1.47, wpb=8216.9, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=23906
2023-08-04 07:25:46 | INFO | train_inner | epoch 020:    607 / 1474 loss=2.034, trans_loss=5.035, nll_loss=2.237, w2v_ctc_loss=0.673, task_loss=1.473, contrastive_loss=0.17, total=4094.9, n_correct=2606.39, ppl=4.72, accuracy=63.65, wps=12192.4, ups=1.49, wpb=8189.8, bsz=296.1, num_updates=28600, lr=8.36242e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=67, gb_free=11.8, wall=23973
2023-08-04 07:26:54 | INFO | train_inner | epoch 020:    707 / 1474 loss=2.024, trans_loss=5.034, nll_loss=2.236, w2v_ctc_loss=0.676, task_loss=1.402, contrastive_loss=0.066, total=4140.23, n_correct=2641.95, ppl=4.71, accuracy=63.812, wps=12258.4, ups=1.48, wpb=8280.5, bsz=300.6, num_updates=28700, lr=8.34784e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=67, gb_free=16.1, wall=24041
2023-08-04 07:28:01 | INFO | train_inner | epoch 020:    807 / 1474 loss=2.023, trans_loss=5.032, nll_loss=2.234, w2v_ctc_loss=0.676, task_loss=1.388, contrastive_loss=0.072, total=4140.66, n_correct=2645.65, ppl=4.71, accuracy=63.894, wps=12188.4, ups=1.47, wpb=8281.3, bsz=305.6, num_updates=28800, lr=8.33333e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=24109
2023-08-04 07:29:10 | INFO | train_inner | epoch 020:    907 / 1474 loss=2.048, trans_loss=5.044, nll_loss=2.25, w2v_ctc_loss=0.674, task_loss=1.338, contrastive_loss=0.369, total=4157.15, n_correct=2640.71, ppl=4.76, accuracy=63.522, wps=12130.3, ups=1.46, wpb=8314.3, bsz=322.6, num_updates=28900, lr=8.3189e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=68, gb_free=17.7, wall=24177
2023-08-04 07:30:18 | INFO | train_inner | epoch 020:   1007 / 1474 loss=2.019, trans_loss=5.033, nll_loss=2.236, w2v_ctc_loss=0.664, task_loss=1.379, contrastive_loss=0.077, total=4171.86, n_correct=2668.26, ppl=4.71, accuracy=63.959, wps=12259.6, ups=1.47, wpb=8343.7, bsz=308.6, num_updates=29000, lr=8.30455e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=24245
2023-08-04 07:31:26 | INFO | train_inner | epoch 020:   1107 / 1474 loss=2.033, trans_loss=5.039, nll_loss=2.245, w2v_ctc_loss=0.669, task_loss=1.352, contrastive_loss=0.218, total=4162.96, n_correct=2653.37, ppl=4.74, accuracy=63.738, wps=12256.6, ups=1.47, wpb=8325.9, bsz=314.9, num_updates=29100, lr=8.29027e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=24313
2023-08-04 07:32:34 | INFO | train_inner | epoch 020:   1207 / 1474 loss=2.03, trans_loss=5.035, nll_loss=2.239, w2v_ctc_loss=0.683, task_loss=1.531, contrastive_loss=0.065, total=4033.74, n_correct=2569.18, ppl=4.72, accuracy=63.692, wps=11829.7, ups=1.47, wpb=8067.5, bsz=285.2, num_updates=29200, lr=8.27606e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=24381
2023-08-04 07:33:42 | INFO | train_inner | epoch 020:   1307 / 1474 loss=2.026, trans_loss=5.045, nll_loss=2.252, w2v_ctc_loss=0.67, task_loss=1.478, contrastive_loss=0.07, total=4124.42, n_correct=2628.08, ppl=4.76, accuracy=63.72, wps=12122.6, ups=1.47, wpb=8248.8, bsz=297, num_updates=29300, lr=8.26192e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=24449
2023-08-04 07:34:50 | INFO | train_inner | epoch 020:   1407 / 1474 loss=2.028, trans_loss=5.044, nll_loss=2.249, w2v_ctc_loss=0.673, task_loss=1.482, contrastive_loss=0.068, total=4114.1, n_correct=2620.22, ppl=4.75, accuracy=63.689, wps=12090.6, ups=1.47, wpb=8228.2, bsz=293.7, num_updates=29400, lr=8.24786e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=68, gb_free=14.4, wall=24517
2023-08-04 07:35:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 07:35:59 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.201 | trans_loss 5.576 | nll_loss 2.854 | w2v_ctc_loss 1.323 | task_loss 4.597 | contrastive_loss 0.261 | total 4003.4 | n_correct 2467.2 | ppl 7.23 | accuracy 61.628 | uer 17.267 | wer 18.966 | raw_wer 18.966 | bleu 19.7 | wps 2207.8 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.07
2023-08-04 07:35:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-08-04 07:35:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt
2023-08-04 07:36:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt
2023-08-04 07:36:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt (epoch 20 @ 29467 updates, score 19.7) (writing took 12.971065159887075 seconds)
2023-08-04 07:36:12 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-04 07:36:12 | INFO | train | epoch 020 | loss 2.025 | trans_loss 5.031 | nll_loss 2.233 | w2v_ctc_loss 0.67 | task_loss 1.399 | contrastive_loss 0.123 | total 4138.65 | n_correct 2643.03 | ppl 4.7 | accuracy 63.862 | wps 11153.4 | ups 1.35 | wpb 8277.3 | bsz 305.7 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.56 | clip 0 | loss_scale 32 | train_wall 993 | gb_free 16.1 | wall 24599
2023-08-04 07:36:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 07:36:12 | INFO | fairseq.trainer | begin training epoch 21
2023-08-04 07:36:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 07:36:42 | INFO | train_inner | epoch 021:     33 / 1474 loss=2.03, trans_loss=5.036, nll_loss=2.242, w2v_ctc_loss=0.669, task_loss=1.324, contrastive_loss=0.193, total=4155.01, n_correct=2648.34, ppl=4.73, accuracy=63.738, wps=7439.3, ups=0.9, wpb=8310, bsz=317.6, num_updates=29500, lr=8.23387e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=24629
2023-08-04 07:37:50 | INFO | train_inner | epoch 021:    133 / 1474 loss=2.012, trans_loss=5.001, nll_loss=2.194, w2v_ctc_loss=0.657, task_loss=1.324, contrastive_loss=0.185, total=4186.67, n_correct=2695.16, ppl=4.58, accuracy=64.375, wps=12367.8, ups=1.48, wpb=8373.3, bsz=317.4, num_updates=29600, lr=8.21995e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=67, gb_free=12.9, wall=24697
2023-08-04 07:38:57 | INFO | train_inner | epoch 021:    233 / 1474 loss=2.004, trans_loss=5.005, nll_loss=2.199, w2v_ctc_loss=0.648, task_loss=1.318, contrastive_loss=0.135, total=4166.37, n_correct=2685.81, ppl=4.59, accuracy=64.464, wps=12399.5, ups=1.49, wpb=8332.7, bsz=315.2, num_updates=29700, lr=8.2061e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=67, gb_free=14, wall=24764
2023-08-04 07:40:05 | INFO | train_inner | epoch 021:    333 / 1474 loss=2.013, trans_loss=5.008, nll_loss=2.202, w2v_ctc_loss=0.663, task_loss=1.418, contrastive_loss=0.136, total=4132.25, n_correct=2657.84, ppl=4.6, accuracy=64.319, wps=12160.4, ups=1.47, wpb=8264.5, bsz=305, num_updates=29800, lr=8.19232e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=67, gb_free=16.6, wall=24832
2023-08-04 07:41:12 | INFO | train_inner | epoch 021:    433 / 1474 loss=2.004, trans_loss=5.008, nll_loss=2.203, w2v_ctc_loss=0.652, task_loss=1.333, contrastive_loss=0.068, total=4195.53, n_correct=2702.75, ppl=4.6, accuracy=64.42, wps=12417.4, ups=1.48, wpb=8391.1, bsz=311.6, num_updates=29900, lr=8.17861e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=67, gb_free=16.4, wall=24900
2023-08-04 07:42:20 | INFO | train_inner | epoch 021:    533 / 1474 loss=2.008, trans_loss=5.007, nll_loss=2.201, w2v_ctc_loss=0.663, task_loss=1.445, contrastive_loss=0.061, total=4085.05, n_correct=2631.57, ppl=4.6, accuracy=64.42, wps=12084.7, ups=1.48, wpb=8170.1, bsz=296.1, num_updates=30000, lr=8.16497e-05, gnorm=0.566, clip=0, loss_scale=64, train_wall=67, gb_free=16.2, wall=24967
2023-08-04 07:42:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 07:42:44 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.211 | trans_loss 5.59 | nll_loss 2.873 | w2v_ctc_loss 1.321 | task_loss 4.604 | contrastive_loss 0.267 | total 4003.4 | n_correct 2464.6 | ppl 7.32 | accuracy 61.563 | uer 17.275 | wer 18.918 | raw_wer 18.918 | bleu 19.6 | wps 2030.1 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.07
2023-08-04 07:42:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-04 07:42:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_21_30000.pt
2023-08-04 07:42:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_21_30000.pt
2023-08-04 07:42:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.6) (writing took 13.238691303879023 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:0')
2023-08-04 07:44:07 | INFO | train_inner | epoch 021:    633 / 1474 loss=2.018, trans_loss=5.014, nll_loss=2.211, w2v_ctc_loss=0.654, task_loss=1.384, contrastive_loss=0.234, total=4220.3, n_correct=2712.31, ppl=4.63, accuracy=64.268, wps=7925.8, ups=0.94, wpb=8440.6, bsz=315.8, num_updates=30100, lr=8.15139e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=68, gb_free=15.7, wall=25074
2023-08-04 07:45:15 | INFO | train_inner | epoch 021:    733 / 1474 loss=2.017, trans_loss=5.026, nll_loss=2.226, w2v_ctc_loss=0.661, task_loss=1.4, contrastive_loss=0.097, total=4148.18, n_correct=2656.99, ppl=4.68, accuracy=64.052, wps=12193, ups=1.47, wpb=8296.4, bsz=308.3, num_updates=30200, lr=8.13788e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=68, gb_free=11.8, wall=25142
2023-08-04 07:46:23 | INFO | train_inner | epoch 021:    833 / 1474 loss=2.022, trans_loss=5.03, nll_loss=2.231, w2v_ctc_loss=0.663, task_loss=1.49, contrastive_loss=0.108, total=4062.56, n_correct=2598.19, ppl=4.69, accuracy=63.955, wps=11957.6, ups=1.47, wpb=8125.1, bsz=293, num_updates=30300, lr=8.12444e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=67, gb_free=16.2, wall=25210
2023-08-04 07:47:30 | INFO | train_inner | epoch 021:    933 / 1474 loss=2.014, trans_loss=5.021, nll_loss=2.22, w2v_ctc_loss=0.662, task_loss=1.396, contrastive_loss=0.082, total=4103.66, n_correct=2630.33, ppl=4.66, accuracy=64.097, wps=12166.7, ups=1.48, wpb=8207.3, bsz=301.5, num_updates=30400, lr=8.11107e-05, gnorm=0.566, clip=0, loss_scale=64, train_wall=67, gb_free=17.1, wall=25277
2023-08-04 07:48:37 | INFO | train_inner | epoch 021:   1033 / 1474 loss=2.021, trans_loss=5.037, nll_loss=2.241, w2v_ctc_loss=0.665, task_loss=1.432, contrastive_loss=0.079, total=4100.54, n_correct=2618.57, ppl=4.73, accuracy=63.859, wps=12184.2, ups=1.49, wpb=8201.1, bsz=298.2, num_updates=30500, lr=8.09776e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=67, gb_free=17.8, wall=25344
2023-08-04 07:49:45 | INFO | train_inner | epoch 021:   1133 / 1474 loss=2.019, trans_loss=5.027, nll_loss=2.227, w2v_ctc_loss=0.664, task_loss=1.502, contrastive_loss=0.082, total=4119.98, n_correct=2637.51, ppl=4.68, accuracy=64.018, wps=12145.7, ups=1.47, wpb=8240, bsz=294, num_updates=30600, lr=8.08452e-05, gnorm=0.561, clip=0, loss_scale=64, train_wall=67, gb_free=17.8, wall=25412
2023-08-04 07:50:53 | INFO | train_inner | epoch 021:   1233 / 1474 loss=2.017, trans_loss=5.027, nll_loss=2.229, w2v_ctc_loss=0.659, task_loss=1.321, contrastive_loss=0.134, total=4161.49, n_correct=2665.21, ppl=4.69, accuracy=64.045, wps=12327.7, ups=1.48, wpb=8323, bsz=313, num_updates=30700, lr=8.07134e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=67, gb_free=16.7, wall=25480
2023-08-04 07:52:00 | INFO | train_inner | epoch 021:   1333 / 1474 loss=2.018, trans_loss=5.026, nll_loss=2.228, w2v_ctc_loss=0.666, task_loss=1.356, contrastive_loss=0.097, total=4141.76, n_correct=2655.25, ppl=4.69, accuracy=64.109, wps=12231, ups=1.48, wpb=8283.5, bsz=311.7, num_updates=30800, lr=8.05823e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=67, gb_free=17.3, wall=25548
2023-08-04 07:53:09 | INFO | train_inner | epoch 021:   1433 / 1474 loss=2.035, trans_loss=5.038, nll_loss=2.243, w2v_ctc_loss=0.682, task_loss=1.477, contrastive_loss=0.146, total=4127.02, n_correct=2627.09, ppl=4.73, accuracy=63.656, wps=12103.4, ups=1.47, wpb=8254, bsz=302.1, num_updates=30900, lr=8.04518e-05, gnorm=0.566, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=25616
2023-08-04 07:53:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:1')
2023-08-04 07:54:03 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.582 | nll_loss 2.864 | w2v_ctc_loss 1.336 | task_loss 4.593 | contrastive_loss 0.266 | total 4003.4 | n_correct 2470.5 | ppl 7.28 | accuracy 61.71 | uer 17.524 | wer 19.313 | raw_wer 19.313 | bleu 19.63 | wps 1827.4 | wpb 4003.4 | bsz 141.8 | num_updates 30941 | best_bleu 20.07
2023-08-04 07:54:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30941 updates
2023-08-04 07:54:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt
2023-08-04 07:54:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt
2023-08-04 07:54:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt (epoch 21 @ 30941 updates, score 19.63) (writing took 12.435069650411606 seconds)
2023-08-04 07:54:15 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-04 07:54:15 | INFO | train | epoch 021 | loss 2.016 | trans_loss 5.02 | nll_loss 2.219 | w2v_ctc_loss 0.661 | task_loss 1.4 | contrastive_loss 0.122 | total 4138.65 | n_correct 2654.64 | ppl 4.65 | accuracy 64.143 | wps 11264.3 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 30941 | lr 8.03985e-05 | gnorm 0.563 | clip 0 | loss_scale 64 | train_wall 991 | gb_free 15.4 | wall 25682
2023-08-04 07:54:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 07:54:15 | INFO | fairseq.trainer | begin training epoch 22
2023-08-04 07:54:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 07:55:03 | INFO | train_inner | epoch 022:     59 / 1474 loss=2.008, trans_loss=5.008, nll_loss=2.203, w2v_ctc_loss=0.663, task_loss=1.41, contrastive_loss=0.061, total=4140.16, n_correct=2666.8, ppl=4.61, accuracy=64.413, wps=7220.1, ups=0.87, wpb=8280.3, bsz=300.1, num_updates=31000, lr=8.03219e-05, gnorm=0.561, clip=0, loss_scale=64, train_wall=68, gb_free=17.7, wall=25730
2023-08-04 07:56:11 | INFO | train_inner | epoch 022:    159 / 1474 loss=2.005, trans_loss=4.995, nll_loss=2.186, w2v_ctc_loss=0.655, task_loss=1.41, contrastive_loss=0.147, total=4115.86, n_correct=2654.45, ppl=4.55, accuracy=64.493, wps=12129.5, ups=1.47, wpb=8231.7, bsz=309.4, num_updates=31100, lr=8.01927e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=67, gb_free=17.3, wall=25798
2023-08-04 07:57:19 | INFO | train_inner | epoch 022:    259 / 1474 loss=1.993, trans_loss=4.992, nll_loss=2.182, w2v_ctc_loss=0.644, task_loss=1.267, contrastive_loss=0.077, total=4247.73, n_correct=2751.74, ppl=4.54, accuracy=64.781, wps=12562.6, ups=1.48, wpb=8495.5, bsz=323.2, num_updates=31200, lr=8.00641e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=67, gb_free=13.8, wall=25866
2023-08-04 07:57:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 07:58:28 | INFO | train_inner | epoch 022:    360 / 1474 loss=2.015, trans_loss=5.004, nll_loss=2.197, w2v_ctc_loss=0.658, task_loss=1.412, contrastive_loss=0.194, total=4186, n_correct=2698.01, ppl=4.59, accuracy=64.453, wps=12043, ups=1.44, wpb=8372, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=25935
2023-08-04 07:59:37 | INFO | train_inner | epoch 022:    460 / 1474 loss=2.015, trans_loss=5.012, nll_loss=2.207, w2v_ctc_loss=0.66, task_loss=1.474, contrastive_loss=0.129, total=4132.62, n_correct=2658.34, ppl=4.62, accuracy=64.326, wps=12066.1, ups=1.46, wpb=8265.2, bsz=297.2, num_updates=31400, lr=7.98087e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=26004
2023-08-04 07:59:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 08:00:46 | INFO | train_inner | epoch 022:    561 / 1474 loss=2.004, trans_loss=5.003, nll_loss=2.197, w2v_ctc_loss=0.658, task_loss=1.398, contrastive_loss=0.074, total=4152.56, n_correct=2677.35, ppl=4.58, accuracy=64.475, wps=12068.8, ups=1.45, wpb=8305.1, bsz=307.5, num_updates=31500, lr=7.96819e-05, gnorm=0.561, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=26073
2023-08-04 08:01:53 | INFO | train_inner | epoch 022:    661 / 1474 loss=2.001, trans_loss=4.999, nll_loss=2.193, w2v_ctc_loss=0.643, task_loss=1.337, contrastive_loss=0.157, total=4139.66, n_correct=2674.74, ppl=4.57, accuracy=64.613, wps=12259.6, ups=1.48, wpb=8279.3, bsz=311.1, num_updates=31600, lr=7.95557e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=67, gb_free=16.1, wall=26140
2023-08-04 08:03:01 | INFO | train_inner | epoch 022:    761 / 1474 loss=2.006, trans_loss=5.005, nll_loss=2.199, w2v_ctc_loss=0.659, task_loss=1.438, contrastive_loss=0.076, total=4167.89, n_correct=2685.09, ppl=4.59, accuracy=64.423, wps=12262.1, ups=1.47, wpb=8335.8, bsz=303.9, num_updates=31700, lr=7.94301e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=68, gb_free=12.7, wall=26208
2023-08-04 08:04:10 | INFO | train_inner | epoch 022:    861 / 1474 loss=2.012, trans_loss=5.017, nll_loss=2.215, w2v_ctc_loss=0.662, task_loss=1.515, contrastive_loss=0.061, total=4075.79, n_correct=2613.23, ppl=4.64, accuracy=64.116, wps=11913.8, ups=1.46, wpb=8151.6, bsz=289, num_updates=31800, lr=7.93052e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=26277
2023-08-04 08:05:17 | INFO | train_inner | epoch 022:    961 / 1474 loss=2.004, trans_loss=5.012, nll_loss=2.209, w2v_ctc_loss=0.649, task_loss=1.405, contrastive_loss=0.063, total=4134.72, n_correct=2663.52, ppl=4.63, accuracy=64.418, wps=12215.8, ups=1.48, wpb=8269.4, bsz=303.2, num_updates=31900, lr=7.91808e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=67, gb_free=14.1, wall=26344
2023-08-04 08:06:25 | INFO | train_inner | epoch 022:   1061 / 1474 loss=2.013, trans_loss=5.01, nll_loss=2.207, w2v_ctc_loss=0.651, task_loss=1.336, contrastive_loss=0.235, total=4160.57, n_correct=2678.06, ppl=4.62, accuracy=64.368, wps=12268.4, ups=1.47, wpb=8321.1, bsz=315.5, num_updates=32000, lr=7.90569e-05, gnorm=0.56, clip=0, loss_scale=16, train_wall=67, gb_free=17.2, wall=26412
2023-08-04 08:06:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 08:06:51 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.209 | trans_loss 5.58 | nll_loss 2.859 | w2v_ctc_loss 1.343 | task_loss 4.604 | contrastive_loss 0.257 | total 4003.4 | n_correct 2477 | ppl 7.25 | accuracy 61.872 | uer 17.248 | wer 18.989 | raw_wer 18.989 | bleu 19.79 | wps 1711.6 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.07
2023-08-04 08:06:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-04 08:06:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_22_32000.pt
2023-08-04 08:06:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_22_32000.pt
2023-08-04 08:07:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.79) (writing took 13.391013789921999 seconds)
2023-08-04 08:08:13 | INFO | train_inner | epoch 022:   1161 / 1474 loss=2.024, trans_loss=5.033, nll_loss=2.236, w2v_ctc_loss=0.668, task_loss=1.444, contrastive_loss=0.115, total=4099.59, n_correct=2620.71, ppl=4.71, accuracy=63.926, wps=7632.4, ups=0.93, wpb=8199.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=67, gb_free=14.9, wall=26520
2023-08-04 08:09:21 | INFO | train_inner | epoch 022:   1261 / 1474 loss=2.015, trans_loss=5.026, nll_loss=2.228, w2v_ctc_loss=0.659, task_loss=1.298, contrastive_loss=0.112, total=4182.05, n_correct=2680.04, ppl=4.69, accuracy=64.084, wps=12309.7, ups=1.47, wpb=8364.1, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=67, gb_free=15.5, wall=26588
2023-08-04 08:10:27 | INFO | train_inner | epoch 022:   1361 / 1474 loss=2.007, trans_loss=5.014, nll_loss=2.212, w2v_ctc_loss=0.648, task_loss=1.404, contrastive_loss=0.13, total=4062.31, n_correct=2615.09, ppl=4.63, accuracy=64.374, wps=12137.9, ups=1.49, wpb=8124.6, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=66, gb_free=15, wall=26655
2023-08-04 08:11:35 | INFO | train_inner | epoch 022:   1461 / 1474 loss=2.022, trans_loss=5.035, nll_loss=2.238, w2v_ctc_loss=0.67, task_loss=1.498, contrastive_loss=0.079, total=4081.88, n_correct=2606.84, ppl=4.72, accuracy=63.864, wps=12044.5, ups=1.48, wpb=8163.8, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=67, gb_free=17.2, wall=26722
2023-08-04 08:11:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 08:12:08 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.191 | trans_loss 5.571 | nll_loss 2.848 | w2v_ctc_loss 1.298 | task_loss 4.575 | contrastive_loss 0.263 | total 4003.4 | n_correct 2481.8 | ppl 7.2 | accuracy 61.992 | uer 17.057 | wer 19.03 | raw_wer 19.03 | bleu 19.89 | wps 2061.8 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.07
2023-08-04 08:12:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-08-04 08:12:08 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.8904.pt
2023-08-04 08:12:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.8904.pt
2023-08-04 08:12:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.8904.pt (epoch 22 @ 32413 updates, score 19.89) (writing took 13.295782724395394 seconds)
2023-08-04 08:12:22 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-04 08:12:22 | INFO | train | epoch 022 | loss 2.01 | trans_loss 5.01 | nll_loss 2.207 | w2v_ctc_loss 0.656 | task_loss 1.402 | contrastive_loss 0.116 | total 4137.04 | n_correct 2662.1 | ppl 4.62 | accuracy 64.348 | wps 11203.2 | ups 1.35 | wpb 8274.1 | bsz 305.1 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.566 | clip 0 | loss_scale 16 | train_wall 994 | gb_free 11.6 | wall 26769
2023-08-04 08:12:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 08:12:22 | INFO | fairseq.trainer | begin training epoch 23
2023-08-04 08:12:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 08:13:29 | INFO | train_inner | epoch 023:     87 / 1474 loss=1.997, trans_loss=4.988, nll_loss=2.177, w2v_ctc_loss=0.655, task_loss=1.432, contrastive_loss=0.07, total=4096.09, n_correct=2654.11, ppl=4.52, accuracy=64.796, wps=7178.3, ups=0.88, wpb=8192.2, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.567, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=26836
2023-08-04 08:14:38 | INFO | train_inner | epoch 023:    187 / 1474 loss=1.994, trans_loss=4.984, nll_loss=2.171, w2v_ctc_loss=0.643, task_loss=1.492, contrastive_loss=0.067, total=4107.77, n_correct=2665.97, ppl=4.5, accuracy=64.901, wps=12023.6, ups=1.46, wpb=8215.5, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.559, clip=0, loss_scale=16, train_wall=68, gb_free=16.3, wall=26905
2023-08-04 08:15:46 | INFO | train_inner | epoch 023:    287 / 1474 loss=1.997, trans_loss=4.99, nll_loss=2.18, w2v_ctc_loss=0.637, task_loss=1.402, contrastive_loss=0.146, total=4153.12, n_correct=2688.59, ppl=4.53, accuracy=64.737, wps=12214, ups=1.47, wpb=8306.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.562, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=26973
2023-08-04 08:16:53 | INFO | train_inner | epoch 023:    387 / 1474 loss=1.997, trans_loss=4.994, nll_loss=2.184, w2v_ctc_loss=0.647, task_loss=1.454, contrastive_loss=0.058, total=4116.7, n_correct=2668.33, ppl=4.54, accuracy=64.817, wps=12174.5, ups=1.48, wpb=8233.4, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.565, clip=0, loss_scale=16, train_wall=67, gb_free=15.2, wall=27040
2023-08-04 08:18:01 | INFO | train_inner | epoch 023:    487 / 1474 loss=2.002, trans_loss=4.996, nll_loss=2.188, w2v_ctc_loss=0.651, task_loss=1.357, contrastive_loss=0.119, total=4157.6, n_correct=2686.72, ppl=4.56, accuracy=64.622, wps=12271.4, ups=1.48, wpb=8315.2, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.564, clip=0, loss_scale=16, train_wall=67, gb_free=17.3, wall=27108
2023-08-04 08:19:08 | INFO | train_inner | epoch 023:    587 / 1474 loss=1.988, trans_loss=4.987, nll_loss=2.176, w2v_ctc_loss=0.64, task_loss=1.319, contrastive_loss=0.064, total=4173.42, n_correct=2711.18, ppl=4.52, accuracy=64.963, wps=12420.9, ups=1.49, wpb=8346.8, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=67, gb_free=12.6, wall=27175
2023-08-04 08:20:16 | INFO | train_inner | epoch 023:    687 / 1474 loss=1.998, trans_loss=4.994, nll_loss=2.185, w2v_ctc_loss=0.644, task_loss=1.4, contrastive_loss=0.105, total=4137.82, n_correct=2678.23, ppl=4.55, accuracy=64.726, wps=12209.6, ups=1.48, wpb=8275.6, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.558, clip=0, loss_scale=16, train_wall=67, gb_free=17.1, wall=27243
2023-08-04 08:21:24 | INFO | train_inner | epoch 023:    787 / 1474 loss=2.004, trans_loss=5.006, nll_loss=2.2, w2v_ctc_loss=0.653, task_loss=1.411, contrastive_loss=0.085, total=4150.99, n_correct=2678.33, ppl=4.6, accuracy=64.523, wps=12289.7, ups=1.48, wpb=8302, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=27311
2023-08-04 08:22:31 | INFO | train_inner | epoch 023:    887 / 1474 loss=2.002, trans_loss=4.998, nll_loss=2.193, w2v_ctc_loss=0.647, task_loss=1.278, contrastive_loss=0.168, total=4181.99, n_correct=2705.77, ppl=4.57, accuracy=64.701, wps=12419.7, ups=1.48, wpb=8364, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.563, clip=0, loss_scale=16, train_wall=67, gb_free=16.4, wall=27378
2023-08-04 08:23:39 | INFO | train_inner | epoch 023:    987 / 1474 loss=2.011, trans_loss=5.002, nll_loss=2.197, w2v_ctc_loss=0.638, task_loss=1.394, contrastive_loss=0.318, total=4168.73, n_correct=2690.81, ppl=4.58, accuracy=64.547, wps=12221.6, ups=1.47, wpb=8337.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.566, clip=0, loss_scale=16, train_wall=68, gb_free=10.7, wall=27446
2023-08-04 08:24:47 | INFO | train_inner | epoch 023:   1087 / 1474 loss=2.009, trans_loss=5.01, nll_loss=2.207, w2v_ctc_loss=0.659, task_loss=1.496, contrastive_loss=0.071, total=4088.49, n_correct=2632.35, ppl=4.62, accuracy=64.384, wps=11995.5, ups=1.47, wpb=8177, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=15.8, wall=27515
2023-08-04 08:25:55 | INFO | train_inner | epoch 023:   1187 / 1474 loss=2.001, trans_loss=5.008, nll_loss=2.204, w2v_ctc_loss=0.653, task_loss=1.389, contrastive_loss=0.064, total=4162.7, n_correct=2684.78, ppl=4.61, accuracy=64.496, wps=12237.8, ups=1.47, wpb=8325.4, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=27583
2023-08-04 08:27:03 | INFO | train_inner | epoch 023:   1287 / 1474 loss=1.997, trans_loss=5.007, nll_loss=2.203, w2v_ctc_loss=0.642, task_loss=1.358, contrastive_loss=0.078, total=4135.53, n_correct=2670.02, ppl=4.6, accuracy=64.563, wps=12271.9, ups=1.48, wpb=8271.1, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=27650
2023-08-04 08:28:11 | INFO | train_inner | epoch 023:   1387 / 1474 loss=2.017, trans_loss=5.027, nll_loss=2.23, w2v_ctc_loss=0.656, task_loss=1.412, contrastive_loss=0.135, total=4143.98, n_correct=2660.09, ppl=4.69, accuracy=64.192, wps=12153.4, ups=1.47, wpb=8288, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=27718
2023-08-04 08:29:10 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 08:29:34 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.204 | trans_loss 5.575 | nll_loss 2.854 | w2v_ctc_loss 1.337 | task_loss 4.624 | contrastive_loss 0.257 | total 4003.4 | n_correct 2481.6 | ppl 7.23 | accuracy 61.987 | uer 16.866 | wer 18.761 | raw_wer 18.761 | bleu 20.07 | wps 2156.6 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.07
2023-08-04 08:29:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-08-04 08:29:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 08:29:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 08:29:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 23 @ 33887 updates, score 20.07) (writing took 22.607714300975204 seconds)
2023-08-04 08:29:57 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-04 08:29:57 | INFO | train | epoch 023 | loss 2.002 | trans_loss 5.001 | nll_loss 2.194 | w2v_ctc_loss 0.647 | task_loss 1.398 | contrastive_loss 0.119 | total 4138.65 | n_correct 2674.14 | ppl 4.58 | accuracy 64.614 | wps 11567.5 | ups 1.4 | wpb 8277.3 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.565 | clip 0 | loss_scale 32 | train_wall 993 | gb_free 13.6 | wall 27824
2023-08-04 08:29:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 08:29:57 | INFO | fairseq.trainer | begin training epoch 24
2023-08-04 08:29:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 08:30:14 | INFO | train_inner | epoch 024:     13 / 1474 loss=2.016, trans_loss=5.017, nll_loss=2.217, w2v_ctc_loss=0.647, task_loss=1.405, contrastive_loss=0.214, total=4085.11, n_correct=2625.8, ppl=4.65, accuracy=64.277, wps=6664.9, ups=0.82, wpb=8170.2, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=12.5, wall=27841
2023-08-04 08:31:22 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.993, trans_loss=4.972, nll_loss=2.156, w2v_ctc_loss=0.636, task_loss=1.289, contrastive_loss=0.231, total=4171.44, n_correct=2717.12, ppl=4.46, accuracy=65.136, wps=12283.8, ups=1.47, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=27909
2023-08-04 08:31:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 08:31:45 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.199 | trans_loss 5.583 | nll_loss 2.859 | w2v_ctc_loss 1.304 | task_loss 4.626 | contrastive_loss 0.259 | total 4003.4 | n_correct 2477.6 | ppl 7.25 | accuracy 61.887 | uer 16.935 | wer 18.974 | raw_wer 18.974 | bleu 19.69 | wps 2187.8 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.07
2023-08-04 08:31:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-04 08:31:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_24_34000.pt
2023-08-04 08:31:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_24_34000.pt
2023-08-04 08:31:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.69) (writing took 13.07738078199327 seconds)
2023-08-04 08:33:07 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.992, trans_loss=4.976, nll_loss=2.163, w2v_ctc_loss=0.625, task_loss=1.226, contrastive_loss=0.289, total=4251.29, n_correct=2770.73, ppl=4.48, accuracy=65.174, wps=8086.9, ups=0.95, wpb=8502.6, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=28014
2023-08-04 08:34:15 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.985, trans_loss=4.979, nll_loss=2.165, w2v_ctc_loss=0.639, task_loss=1.37, contrastive_loss=0.06, total=4128.18, n_correct=2686.26, ppl=4.49, accuracy=65.071, wps=12139.7, ups=1.47, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=28082
2023-08-04 08:35:23 | INFO | train_inner | epoch 024:    413 / 1474 loss=2.01, trans_loss=4.988, nll_loss=2.177, w2v_ctc_loss=0.651, task_loss=1.462, contrastive_loss=0.212, total=4158.92, n_correct=2691.4, ppl=4.52, accuracy=64.714, wps=12195.9, ups=1.47, wpb=8317.8, bsz=299.7, num_updates=34300, lr=7.63604e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=28150
2023-08-04 08:36:31 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.995, trans_loss=4.985, nll_loss=2.174, w2v_ctc_loss=0.644, task_loss=1.42, contrastive_loss=0.13, total=4144.91, n_correct=2692.13, ppl=4.51, accuracy=64.95, wps=12180.2, ups=1.47, wpb=8289.8, bsz=303.3, num_updates=34400, lr=7.62493e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=28218
2023-08-04 08:37:38 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.99, trans_loss=4.984, nll_loss=2.173, w2v_ctc_loss=0.634, task_loss=1.407, contrastive_loss=0.095, total=4165.3, n_correct=2705.18, ppl=4.51, accuracy=64.946, wps=12361.4, ups=1.48, wpb=8330.6, bsz=307.7, num_updates=34500, lr=7.61387e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=67, gb_free=15.6, wall=28285
2023-08-04 08:38:46 | INFO | train_inner | epoch 024:    713 / 1474 loss=2, trans_loss=4.999, nll_loss=2.191, w2v_ctc_loss=0.644, task_loss=1.441, contrastive_loss=0.106, total=4102.21, n_correct=2655.3, ppl=4.57, accuracy=64.729, wps=12079.1, ups=1.47, wpb=8204.4, bsz=295.1, num_updates=34600, lr=7.60286e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=28353
2023-08-04 08:39:54 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.994, trans_loss=4.996, nll_loss=2.19, w2v_ctc_loss=0.639, task_loss=1.41, contrastive_loss=0.084, total=4110.6, n_correct=2659.44, ppl=4.56, accuracy=64.697, wps=12064.9, ups=1.47, wpb=8221.2, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=28422
2023-08-04 08:41:02 | INFO | train_inner | epoch 024:    913 / 1474 loss=2.005, trans_loss=5.007, nll_loss=2.201, w2v_ctc_loss=0.652, task_loss=1.553, contrastive_loss=0.055, total=4043.03, n_correct=2603.24, ppl=4.6, accuracy=64.388, wps=11969.1, ups=1.48, wpb=8086.1, bsz=281, num_updates=34800, lr=7.58098e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=67, gb_free=11.1, wall=28489
2023-08-04 08:42:10 | INFO | train_inner | epoch 024:   1013 / 1474 loss=1.996, trans_loss=5.001, nll_loss=2.195, w2v_ctc_loss=0.642, task_loss=1.444, contrastive_loss=0.061, total=4136.81, n_correct=2675.98, ppl=4.58, accuracy=64.687, wps=12205.5, ups=1.48, wpb=8273.6, bsz=298.4, num_updates=34900, lr=7.57011e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=28557
2023-08-04 08:43:18 | INFO | train_inner | epoch 024:   1113 / 1474 loss=1.996, trans_loss=4.99, nll_loss=2.181, w2v_ctc_loss=0.647, task_loss=1.349, contrastive_loss=0.105, total=4135.73, n_correct=2680.35, ppl=4.53, accuracy=64.81, wps=12190.7, ups=1.47, wpb=8271.5, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=28625
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:0')
2023-08-04 08:44:26 | INFO | train_inner | epoch 024:   1213 / 1474 loss=1.996, trans_loss=4.999, nll_loss=2.193, w2v_ctc_loss=0.641, task_loss=1.386, contrastive_loss=0.096, total=4148.3, n_correct=2684.9, ppl=4.57, accuracy=64.723, wps=12191.8, ups=1.47, wpb=8296.6, bsz=310.8, num_updates=35100, lr=7.54851e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=28693
2023-08-04 08:45:34 | INFO | train_inner | epoch 024:   1313 / 1474 loss=2.006, trans_loss=5.009, nll_loss=2.205, w2v_ctc_loss=0.657, task_loss=1.491, contrastive_loss=0.066, total=4110.05, n_correct=2649, ppl=4.61, accuracy=64.452, wps=12082.7, ups=1.47, wpb=8220.1, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=28761
2023-08-04 08:46:41 | INFO | train_inner | epoch 024:   1413 / 1474 loss=2.005, trans_loss=5.01, nll_loss=2.207, w2v_ctc_loss=0.657, task_loss=1.465, contrastive_loss=0.065, total=4090.91, n_correct=2638.04, ppl=4.62, accuracy=64.485, wps=12176, ups=1.49, wpb=8181.8, bsz=292.7, num_updates=35300, lr=7.5271e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=67, gb_free=16, wall=28828
2023-08-04 08:47:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:6')
2023-08-04 08:47:45 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.197 | trans_loss 5.573 | nll_loss 2.85 | w2v_ctc_loss 1.32 | task_loss 4.628 | contrastive_loss 0.254 | total 4003.4 | n_correct 2482.4 | ppl 7.21 | accuracy 62.007 | uer 16.925 | wer 18.896 | raw_wer 18.896 | bleu 19.97 | wps 2224.3 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 20.07
2023-08-04 08:47:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-08-04 08:47:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.9705.pt
2023-08-04 08:47:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.9705.pt
2023-08-04 08:47:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_19.9705.pt (epoch 24 @ 35361 updates, score 19.97) (writing took 13.665991531684995 seconds)
2023-08-04 08:48:00 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-04 08:48:00 | INFO | train | epoch 024 | loss 1.997 | trans_loss 4.992 | nll_loss 2.184 | w2v_ctc_loss 0.643 | task_loss 1.399 | contrastive_loss 0.118 | total 4138.65 | n_correct 2681.69 | ppl 4.54 | accuracy 64.796 | wps 11269 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.567 | clip 0 | loss_scale 32 | train_wall 994 | gb_free 16.1 | wall 28907
2023-08-04 08:48:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 08:48:00 | INFO | fairseq.trainer | begin training epoch 25
2023-08-04 08:48:00 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 08:48:34 | INFO | train_inner | epoch 025:     39 / 1474 loss=1.983, trans_loss=4.982, nll_loss=2.171, w2v_ctc_loss=0.634, task_loss=1.342, contrastive_loss=0.071, total=4166.95, n_correct=2715.59, ppl=4.5, accuracy=65.17, wps=7393.9, ups=0.89, wpb=8333.9, bsz=312, num_updates=35400, lr=7.51646e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=28941
2023-08-04 08:49:41 | INFO | train_inner | epoch 025:    139 / 1474 loss=1.977, trans_loss=4.964, nll_loss=2.146, w2v_ctc_loss=0.629, task_loss=1.374, contrastive_loss=0.07, total=4133.64, n_correct=2702.36, ppl=4.43, accuracy=65.375, wps=12258.7, ups=1.48, wpb=8267.3, bsz=307.7, num_updates=35500, lr=7.50587e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=29008
2023-08-04 08:50:49 | INFO | train_inner | epoch 025:    239 / 1474 loss=1.98, trans_loss=4.968, nll_loss=2.152, w2v_ctc_loss=0.635, task_loss=1.439, contrastive_loss=0.074, total=4114.53, n_correct=2686.32, ppl=4.45, accuracy=65.289, wps=12045.3, ups=1.46, wpb=8229.1, bsz=302.7, num_updates=35600, lr=7.49532e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=68, gb_free=17, wall=29077
2023-08-04 08:51:58 | INFO | train_inner | epoch 025:    339 / 1474 loss=1.991, trans_loss=4.976, nll_loss=2.16, w2v_ctc_loss=0.638, task_loss=1.491, contrastive_loss=0.102, total=4148.7, n_correct=2694.32, ppl=4.47, accuracy=64.944, wps=12136.4, ups=1.46, wpb=8297.4, bsz=295.1, num_updates=35700, lr=7.48481e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=68, gb_free=16.3, wall=29145
2023-08-04 08:52:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 08:53:07 | INFO | train_inner | epoch 025:    440 / 1474 loss=1.997, trans_loss=4.98, nll_loss=2.167, w2v_ctc_loss=0.657, task_loss=1.509, contrastive_loss=0.06, total=4142.33, n_correct=2690.01, ppl=4.49, accuracy=64.94, wps=12027.3, ups=1.45, wpb=8284.7, bsz=289.3, num_updates=35800, lr=7.47435e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=29214
2023-08-04 08:54:15 | INFO | train_inner | epoch 025:    540 / 1474 loss=1.99, trans_loss=4.987, nll_loss=2.176, w2v_ctc_loss=0.642, task_loss=1.367, contrastive_loss=0.075, total=4160.61, n_correct=2706.1, ppl=4.52, accuracy=65.041, wps=12237.6, ups=1.47, wpb=8321.2, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=67, gb_free=17.5, wall=29282
2023-08-04 08:55:23 | INFO | train_inner | epoch 025:    640 / 1474 loss=1.993, trans_loss=4.978, nll_loss=2.165, w2v_ctc_loss=0.643, task_loss=1.388, contrastive_loss=0.142, total=4153.68, n_correct=2698.68, ppl=4.49, accuracy=64.971, wps=12232.4, ups=1.47, wpb=8307.4, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=29350
2023-08-04 08:55:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 08:55:45 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.569 | nll_loss 2.843 | w2v_ctc_loss 1.358 | task_loss 4.619 | contrastive_loss 0.251 | total 4003.4 | n_correct 2476.1 | ppl 7.17 | accuracy 61.85 | uer 16.882 | wer 18.75 | raw_wer 18.75 | bleu 20.07 | wps 2323.9 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.07
2023-08-04 08:55:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-04 08:55:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_25_36000.pt
2023-08-04 08:55:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_25_36000.pt
2023-08-04 08:56:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 20.07) (writing took 25.396343521773815 seconds)
2023-08-04 08:57:20 | INFO | train_inner | epoch 025:    740 / 1474 loss=1.995, trans_loss=4.982, nll_loss=2.17, w2v_ctc_loss=0.641, task_loss=1.422, contrastive_loss=0.137, total=4128.34, n_correct=2677.62, ppl=4.5, accuracy=64.859, wps=7059.4, ups=0.85, wpb=8256.7, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=29467
2023-08-04 08:58:27 | INFO | train_inner | epoch 025:    840 / 1474 loss=1.983, trans_loss=4.984, nll_loss=2.174, w2v_ctc_loss=0.633, task_loss=1.291, contrastive_loss=0.084, total=4182.4, n_correct=2721.51, ppl=4.51, accuracy=65.071, wps=12371, ups=1.48, wpb=8364.8, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=67, gb_free=17.7, wall=29534
2023-08-04 08:59:35 | INFO | train_inner | epoch 025:    940 / 1474 loss=1.993, trans_loss=4.989, nll_loss=2.182, w2v_ctc_loss=0.64, task_loss=1.33, contrastive_loss=0.141, total=4155.21, n_correct=2699.94, ppl=4.54, accuracy=64.977, wps=12251.9, ups=1.47, wpb=8310.4, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=67, gb_free=14, wall=29602
2023-08-04 09:00:43 | INFO | train_inner | epoch 025:   1040 / 1474 loss=2, trans_loss=4.995, nll_loss=2.187, w2v_ctc_loss=0.63, task_loss=1.388, contrastive_loss=0.251, total=4177.7, n_correct=2705.99, ppl=4.56, accuracy=64.772, wps=12277.5, ups=1.47, wpb=8355.4, bsz=309.8, num_updates=36400, lr=7.41249e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=29670
2023-08-04 09:01:51 | INFO | train_inner | epoch 025:   1140 / 1474 loss=1.988, trans_loss=4.99, nll_loss=2.18, w2v_ctc_loss=0.632, task_loss=1.516, contrastive_loss=0.054, total=4039.24, n_correct=2623.49, ppl=4.53, accuracy=64.95, wps=11893.4, ups=1.47, wpb=8078.5, bsz=285.2, num_updates=36500, lr=7.40233e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=29738
2023-08-04 09:02:58 | INFO | train_inner | epoch 025:   1240 / 1474 loss=1.99, trans_loss=4.994, nll_loss=2.187, w2v_ctc_loss=0.637, task_loss=1.415, contrastive_loss=0.065, total=4090.59, n_correct=2655.13, ppl=4.55, accuracy=64.908, wps=12256.7, ups=1.5, wpb=8181.2, bsz=295.7, num_updates=36600, lr=7.39221e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=66, gb_free=17.2, wall=29805
2023-08-04 09:04:06 | INFO | train_inner | epoch 025:   1340 / 1474 loss=1.996, trans_loss=4.99, nll_loss=2.182, w2v_ctc_loss=0.641, task_loss=1.361, contrastive_loss=0.158, total=4164.34, n_correct=2704.01, ppl=4.54, accuracy=64.932, wps=12232.3, ups=1.47, wpb=8328.7, bsz=310.1, num_updates=36700, lr=7.38213e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=29873
2023-08-04 09:05:14 | INFO | train_inner | epoch 025:   1440 / 1474 loss=2.004, trans_loss=5.009, nll_loss=2.205, w2v_ctc_loss=0.647, task_loss=1.454, contrastive_loss=0.111, total=4099.11, n_correct=2643.24, ppl=4.61, accuracy=64.483, wps=11987.1, ups=1.46, wpb=8198.2, bsz=299.3, num_updates=36800, lr=7.3721e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=12.1, wall=29941
2023-08-04 09:05:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 09:06:00 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.193 | trans_loss 5.567 | nll_loss 2.845 | w2v_ctc_loss 1.319 | task_loss 4.6 | contrastive_loss 0.253 | total 4003.4 | n_correct 2486.8 | ppl 7.19 | accuracy 62.117 | uer 17.094 | wer 18.959 | raw_wer 18.959 | bleu 20.26 | wps 2292.6 | wpb 4003.4 | bsz 141.8 | num_updates 36834 | best_bleu 20.26
2023-08-04 09:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36834 updates
2023-08-04 09:06:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 09:06:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt
2023-08-04 09:06:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_best.pt (epoch 25 @ 36834 updates, score 20.26) (writing took 23.21482552215457 seconds)
2023-08-04 09:06:24 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-04 09:06:24 | INFO | train | epoch 025 | loss 1.991 | trans_loss 4.985 | nll_loss 2.174 | w2v_ctc_loss 0.639 | task_loss 1.403 | contrastive_loss 0.108 | total 4137.25 | n_correct 2687.99 | ppl 4.51 | accuracy 64.97 | wps 11039.2 | ups 1.33 | wpb 8274.5 | bsz 305.1 | num_updates 36834 | lr 7.36869e-05 | gnorm 0.569 | clip 0 | loss_scale 32 | train_wall 994 | gb_free 14.2 | wall 30011
2023-08-04 09:06:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 09:06:24 | INFO | fairseq.trainer | begin training epoch 26
2023-08-04 09:06:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 09:07:17 | INFO | train_inner | epoch 026:     66 / 1474 loss=1.976, trans_loss=4.963, nll_loss=2.146, w2v_ctc_loss=0.627, task_loss=1.316, contrastive_loss=0.096, total=4180.21, n_correct=2733.31, ppl=4.43, accuracy=65.387, wps=6829.2, ups=0.82, wpb=8360.4, bsz=318.3, num_updates=36900, lr=7.3621e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=30064
2023-08-04 09:08:25 | INFO | train_inner | epoch 026:    166 / 1474 loss=1.983, trans_loss=4.96, nll_loss=2.143, w2v_ctc_loss=0.618, task_loss=1.229, contrastive_loss=0.282, total=4270.78, n_correct=2795.77, ppl=4.42, accuracy=65.463, wps=12533.7, ups=1.47, wpb=8541.6, bsz=340.4, num_updates=37000, lr=7.35215e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=68, gb_free=15.2, wall=30132
2023-08-04 09:09:33 | INFO | train_inner | epoch 026:    266 / 1474 loss=1.986, trans_loss=4.963, nll_loss=2.146, w2v_ctc_loss=0.639, task_loss=1.386, contrastive_loss=0.154, total=4125.04, n_correct=2692.81, ppl=4.42, accuracy=65.28, wps=12098.2, ups=1.47, wpb=8250.1, bsz=307.1, num_updates=37100, lr=7.34223e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=68, gb_free=15.1, wall=30200
2023-08-04 09:10:40 | INFO | train_inner | epoch 026:    366 / 1474 loss=1.981, trans_loss=4.967, nll_loss=2.152, w2v_ctc_loss=0.632, task_loss=1.338, contrastive_loss=0.114, total=4165.74, n_correct=2719.71, ppl=4.44, accuracy=65.288, wps=12370.9, ups=1.48, wpb=8331.5, bsz=314.7, num_updates=37200, lr=7.33236e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=30267
2023-08-04 09:11:48 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.98, trans_loss=4.961, nll_loss=2.143, w2v_ctc_loss=0.628, task_loss=1.331, contrastive_loss=0.157, total=4170.23, n_correct=2731.52, ppl=4.42, accuracy=65.5, wps=12330.6, ups=1.48, wpb=8340.5, bsz=315.4, num_updates=37300, lr=7.32252e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=67, gb_free=17.8, wall=30335
2023-08-04 09:12:56 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.99, trans_loss=4.977, nll_loss=2.164, w2v_ctc_loss=0.648, task_loss=1.411, contrastive_loss=0.078, total=4155.02, n_correct=2705.32, ppl=4.48, accuracy=65.11, wps=12219.2, ups=1.47, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=67, gb_free=17.8, wall=30403
2023-08-04 09:14:05 | INFO | train_inner | epoch 026:    666 / 1474 loss=1.981, trans_loss=4.975, nll_loss=2.161, w2v_ctc_loss=0.629, task_loss=1.426, contrastive_loss=0.062, total=4136.96, n_correct=2694.93, ppl=4.47, accuracy=65.143, wps=12088.3, ups=1.46, wpb=8273.9, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=15.3, wall=30472
2023-08-04 09:15:12 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.993, trans_loss=4.98, nll_loss=2.168, w2v_ctc_loss=0.632, task_loss=1.42, contrastive_loss=0.178, total=4086.28, n_correct=2658.84, ppl=4.49, accuracy=65.067, wps=12109, ups=1.48, wpb=8172.6, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=67, gb_free=15, wall=30539
2023-08-04 09:16:19 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.986, trans_loss=4.978, nll_loss=2.164, w2v_ctc_loss=0.637, task_loss=1.382, contrastive_loss=0.078, total=4183.26, n_correct=2725.54, ppl=4.48, accuracy=65.153, wps=12399.9, ups=1.48, wpb=8366.5, bsz=308.1, num_updates=37700, lr=7.28357e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=67, gb_free=17.3, wall=30607
2023-08-04 09:17:28 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.989, trans_loss=4.987, nll_loss=2.176, w2v_ctc_loss=0.626, task_loss=1.447, contrastive_loss=0.13, total=4137.96, n_correct=2685.25, ppl=4.52, accuracy=64.893, wps=12137.5, ups=1.47, wpb=8275.9, bsz=299, num_updates=37800, lr=7.27393e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=30675
2023-08-04 09:18:36 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.983, trans_loss=4.981, nll_loss=2.17, w2v_ctc_loss=0.631, task_loss=1.463, contrastive_loss=0.061, total=4120.53, n_correct=2683.57, ppl=4.5, accuracy=65.127, wps=12072.8, ups=1.46, wpb=8241.1, bsz=294.3, num_updates=37900, lr=7.26433e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=30743
2023-08-04 09:19:44 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.991, trans_loss=4.989, nll_loss=2.179, w2v_ctc_loss=0.634, task_loss=1.465, contrastive_loss=0.1, total=4113.86, n_correct=2670.52, ppl=4.53, accuracy=64.915, wps=12061.3, ups=1.47, wpb=8227.7, bsz=298.5, num_updates=38000, lr=7.25476e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=30811
2023-08-04 09:19:44 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 09:20:09 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.207 | trans_loss 5.575 | nll_loss 2.85 | w2v_ctc_loss 1.348 | task_loss 4.626 | contrastive_loss 0.254 | total 4003.4 | n_correct 2480.7 | ppl 7.21 | accuracy 61.965 | uer 17.057 | wer 18.94 | raw_wer 18.94 | bleu 19.96 | wps 1938 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.26
2023-08-04 09:20:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-04 09:20:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_26_38000.pt
2023-08-04 09:20:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_26_38000.pt
2023-08-04 09:20:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 19.96) (writing took 31.267645798623562 seconds)
2023-08-04 09:21:49 | INFO | train_inner | epoch 026:   1266 / 1474 loss=2, trans_loss=5.002, nll_loss=2.196, w2v_ctc_loss=0.651, task_loss=1.562, contrastive_loss=0.063, total=3996.19, n_correct=2578.94, ppl=4.58, accuracy=64.535, wps=6382, ups=0.8, wpb=7992.4, bsz=279.3, num_updates=38100, lr=7.24524e-05, gnorm=0.584, clip=0, loss_scale=64, train_wall=67, gb_free=17.7, wall=30936
2023-08-04 09:22:58 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.984, trans_loss=4.989, nll_loss=2.18, w2v_ctc_loss=0.626, task_loss=1.394, contrastive_loss=0.08, total=4159.74, n_correct=2706.44, ppl=4.53, accuracy=65.063, wps=12159.7, ups=1.46, wpb=8319.5, bsz=311.4, num_updates=38200, lr=7.23575e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=68, gb_free=17.2, wall=31005
2023-08-04 09:24:06 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.979, trans_loss=4.985, nll_loss=2.176, w2v_ctc_loss=0.623, task_loss=1.326, contrastive_loss=0.073, total=4165.66, n_correct=2715.63, ppl=4.52, accuracy=65.191, wps=12287.1, ups=1.47, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=67, gb_free=16.2, wall=31073
2023-08-04 09:24:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 09:24:34 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.201 | trans_loss 5.577 | nll_loss 2.855 | w2v_ctc_loss 1.324 | task_loss 4.602 | contrastive_loss 0.254 | total 4003.4 | n_correct 2481 | ppl 7.23 | accuracy 61.972 | uer 17.209 | wer 19.049 | raw_wer 19.049 | bleu 20.02 | wps 2167.6 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 20.26
2023-08-04 09:24:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-08-04 09:24:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.0201.pt
2023-08-04 09:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.0201.pt
2023-08-04 09:25:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.0201.pt (epoch 26 @ 38308 updates, score 20.02) (writing took 31.552897300571203 seconds)
2023-08-04 09:25:06 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-04 09:25:06 | INFO | train | epoch 026 | loss 1.985 | trans_loss 4.976 | nll_loss 2.163 | w2v_ctc_loss 0.632 | task_loss 1.398 | contrastive_loss 0.115 | total 4138.65 | n_correct 2696.54 | ppl 4.48 | accuracy 65.155 | wps 10867.8 | ups 1.31 | wpb 8277.3 | bsz 305.7 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.57 | clip 0 | loss_scale 64 | train_wall 994 | gb_free 15.9 | wall 31134
2023-08-04 09:25:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 09:25:07 | INFO | fairseq.trainer | begin training epoch 27
2023-08-04 09:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 09:25:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 09:26:17 | INFO | train_inner | epoch 027:     93 / 1474 loss=1.967, trans_loss=4.942, nll_loss=2.117, w2v_ctc_loss=0.62, task_loss=1.514, contrastive_loss=0.049, total=4054.72, n_correct=2667.65, ppl=4.34, accuracy=65.791, wps=6156.7, ups=0.76, wpb=8109.4, bsz=281.9, num_updates=38400, lr=7.21688e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=67, gb_free=14.8, wall=31204
2023-08-04 09:27:26 | INFO | train_inner | epoch 027:    193 / 1474 loss=1.967, trans_loss=4.948, nll_loss=2.127, w2v_ctc_loss=0.624, task_loss=1.339, contrastive_loss=0.083, total=4185.52, n_correct=2749.67, ppl=4.37, accuracy=65.695, wps=12265.1, ups=1.47, wpb=8371, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=31273
2023-08-04 09:28:34 | INFO | train_inner | epoch 027:    293 / 1474 loss=1.972, trans_loss=4.956, nll_loss=2.136, w2v_ctc_loss=0.627, task_loss=1.398, contrastive_loss=0.064, total=4167.92, n_correct=2733.78, ppl=4.4, accuracy=65.591, wps=12216.1, ups=1.47, wpb=8335.8, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=31341
2023-08-04 09:29:43 | INFO | train_inner | epoch 027:    393 / 1474 loss=1.988, trans_loss=4.964, nll_loss=2.147, w2v_ctc_loss=0.621, task_loss=1.467, contrastive_loss=0.246, total=4075.21, n_correct=2662.36, ppl=4.43, accuracy=65.331, wps=11850.5, ups=1.45, wpb=8150.4, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=31410
2023-08-04 09:30:51 | INFO | train_inner | epoch 027:    493 / 1474 loss=1.981, trans_loss=4.969, nll_loss=2.155, w2v_ctc_loss=0.623, task_loss=1.28, contrastive_loss=0.186, total=4249.35, n_correct=2771.57, ppl=4.45, accuracy=65.223, wps=12446, ups=1.46, wpb=8498.7, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=68, gb_free=11.9, wall=31478
2023-08-04 09:31:59 | INFO | train_inner | epoch 027:    593 / 1474 loss=1.981, trans_loss=4.967, nll_loss=2.151, w2v_ctc_loss=0.63, task_loss=1.368, contrastive_loss=0.124, total=4133.39, n_correct=2702.06, ppl=4.44, accuracy=65.372, wps=12135.2, ups=1.47, wpb=8266.8, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=11.9, wall=31546
2023-08-04 09:33:07 | INFO | train_inner | epoch 027:    693 / 1474 loss=1.982, trans_loss=4.97, nll_loss=2.155, w2v_ctc_loss=0.631, task_loss=1.398, contrastive_loss=0.102, total=4162.71, n_correct=2717.56, ppl=4.45, accuracy=65.283, wps=12260.3, ups=1.47, wpb=8325.4, bsz=305.4, num_updates=39000, lr=7.16115e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=31614
2023-08-04 09:34:14 | INFO | train_inner | epoch 027:    793 / 1474 loss=1.981, trans_loss=4.971, nll_loss=2.156, w2v_ctc_loss=0.633, task_loss=1.474, contrastive_loss=0.065, total=4103.81, n_correct=2677.77, ppl=4.46, accuracy=65.251, wps=12194.7, ups=1.49, wpb=8207.6, bsz=294.2, num_updates=39100, lr=7.15199e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=31681
2023-08-04 09:35:22 | INFO | train_inner | epoch 027:    893 / 1474 loss=1.976, trans_loss=4.975, nll_loss=2.161, w2v_ctc_loss=0.62, task_loss=1.46, contrastive_loss=0.053, total=4101.56, n_correct=2682.75, ppl=4.47, accuracy=65.408, wps=12195.7, ups=1.49, wpb=8203.1, bsz=292.1, num_updates=39200, lr=7.14286e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=67, gb_free=17.7, wall=31749
2023-08-04 09:36:31 | INFO | train_inner | epoch 027:    993 / 1474 loss=1.985, trans_loss=4.971, nll_loss=2.157, w2v_ctc_loss=0.622, task_loss=1.354, contrastive_loss=0.243, total=4199.56, n_correct=2742.33, ppl=4.46, accuracy=65.3, wps=12150.8, ups=1.45, wpb=8399.1, bsz=316.8, num_updates=39300, lr=7.13376e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=69, gb_free=11.5, wall=31818
2023-08-04 09:37:39 | INFO | train_inner | epoch 027:   1093 / 1474 loss=1.973, trans_loss=4.97, nll_loss=2.155, w2v_ctc_loss=0.619, task_loss=1.408, contrastive_loss=0.075, total=4150.97, n_correct=2712.42, ppl=4.45, accuracy=65.344, wps=12214.5, ups=1.47, wpb=8301.9, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=67, gb_free=11.9, wall=31886
2023-08-04 09:38:46 | INFO | train_inner | epoch 027:   1193 / 1474 loss=1.986, trans_loss=4.978, nll_loss=2.166, w2v_ctc_loss=0.638, task_loss=1.463, contrastive_loss=0.08, total=4103.06, n_correct=2674.06, ppl=4.49, accuracy=65.172, wps=12122.7, ups=1.48, wpb=8206.1, bsz=297.7, num_updates=39500, lr=7.11568e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=67, gb_free=16.5, wall=31953
2023-08-04 09:39:54 | INFO | train_inner | epoch 027:   1293 / 1474 loss=1.992, trans_loss=4.985, nll_loss=2.174, w2v_ctc_loss=0.634, task_loss=1.497, contrastive_loss=0.13, total=4062.52, n_correct=2637.57, ppl=4.51, accuracy=64.924, wps=11966.8, ups=1.47, wpb=8125, bsz=292.2, num_updates=39600, lr=7.10669e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=67, gb_free=16.5, wall=32021
2023-08-04 09:41:02 | INFO | train_inner | epoch 027:   1393 / 1474 loss=1.98, trans_loss=4.978, nll_loss=2.167, w2v_ctc_loss=0.623, task_loss=1.321, contrastive_loss=0.112, total=4152, n_correct=2706.62, ppl=4.49, accuracy=65.188, wps=12331.4, ups=1.48, wpb=8304, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=67, gb_free=16.6, wall=32089
2023-08-04 09:41:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 09:42:20 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.202 | trans_loss 5.566 | nll_loss 2.844 | w2v_ctc_loss 1.35 | task_loss 4.605 | contrastive_loss 0.257 | total 4003.4 | n_correct 2483.6 | ppl 7.18 | accuracy 62.037 | uer 17.049 | wer 18.884 | raw_wer 18.884 | bleu 20.1 | wps 2157.2 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.26
2023-08-04 09:42:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-08-04 09:42:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1005.pt
2023-08-04 09:42:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1005.pt
2023-08-04 09:42:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1005.pt (epoch 27 @ 39781 updates, score 20.1) (writing took 15.517886126413941 seconds)
2023-08-04 09:42:36 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-04 09:42:36 | INFO | train | epoch 027 | loss 1.979 | trans_loss 4.968 | nll_loss 2.152 | w2v_ctc_loss 0.626 | task_loss 1.401 | contrastive_loss 0.114 | total 4138.22 | n_correct 2704.56 | ppl 4.44 | accuracy 65.356 | wps 11613.3 | ups 1.4 | wpb 8276.4 | bsz 305.6 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.571 | clip 0 | loss_scale 32 | train_wall 995 | gb_free 17.8 | wall 32183
2023-08-04 09:42:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 09:42:36 | INFO | fairseq.trainer | begin training epoch 28
2023-08-04 09:42:36 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 09:42:56 | INFO | train_inner | epoch 028:     19 / 1474 loss=1.971, trans_loss=4.969, nll_loss=2.154, w2v_ctc_loss=0.618, task_loss=1.355, contrastive_loss=0.064, total=4108.43, n_correct=2691.92, ppl=4.45, accuracy=65.522, wps=7158.7, ups=0.87, wpb=8216.9, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=32203
2023-08-04 09:44:03 | INFO | train_inner | epoch 028:    119 / 1474 loss=1.961, trans_loss=4.937, nll_loss=2.111, w2v_ctc_loss=0.615, task_loss=1.459, contrastive_loss=0.059, total=4113.41, n_correct=2714.73, ppl=4.32, accuracy=65.997, wps=12263, ups=1.49, wpb=8226.8, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=67, gb_free=16.9, wall=32271
2023-08-04 09:45:11 | INFO | train_inner | epoch 028:    219 / 1474 loss=1.963, trans_loss=4.947, nll_loss=2.125, w2v_ctc_loss=0.616, task_loss=1.327, contrastive_loss=0.068, total=4191.56, n_correct=2760.75, ppl=4.36, accuracy=65.864, wps=12340.9, ups=1.47, wpb=8383.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=67, gb_free=15.1, wall=32338
2023-08-04 09:45:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 09:45:35 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.58 | nll_loss 2.859 | w2v_ctc_loss 1.361 | task_loss 4.59 | contrastive_loss 0.248 | total 4003.4 | n_correct 2481.1 | ppl 7.26 | accuracy 61.975 | uer 16.93 | wer 18.81 | raw_wer 18.81 | bleu 19.84 | wps 2125.6 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.26
2023-08-04 09:45:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-04 09:45:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_28_40000.pt
2023-08-04 09:45:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_28_40000.pt
2023-08-04 09:45:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 19.84) (writing took 13.212850147858262 seconds)
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:0')
2023-08-04 09:46:57 | INFO | train_inner | epoch 028:    319 / 1474 loss=1.989, trans_loss=4.956, nll_loss=2.136, w2v_ctc_loss=0.612, task_loss=1.388, contrastive_loss=0.399, total=4145.32, n_correct=2713.35, ppl=4.4, accuracy=65.456, wps=7826.7, ups=0.94, wpb=8290.6, bsz=316.1, num_updates=40100, lr=7.06225e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=32444
2023-08-04 09:48:05 | INFO | train_inner | epoch 028:    419 / 1474 loss=1.971, trans_loss=4.953, nll_loss=2.132, w2v_ctc_loss=0.626, task_loss=1.446, contrastive_loss=0.054, total=4092.14, n_correct=2686.56, ppl=4.38, accuracy=65.652, wps=12119.3, ups=1.48, wpb=8184.3, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=32512
2023-08-04 09:49:12 | INFO | train_inner | epoch 028:    519 / 1474 loss=1.971, trans_loss=4.956, nll_loss=2.137, w2v_ctc_loss=0.622, task_loss=1.456, contrastive_loss=0.067, total=4096.35, n_correct=2686.08, ppl=4.4, accuracy=65.573, wps=12149.6, ups=1.48, wpb=8192.7, bsz=295.5, num_updates=40300, lr=7.0447e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=67, gb_free=16, wall=32579
2023-08-04 09:50:20 | INFO | train_inner | epoch 028:    619 / 1474 loss=1.974, trans_loss=4.967, nll_loss=2.151, w2v_ctc_loss=0.622, task_loss=1.408, contrastive_loss=0.068, total=4178.12, n_correct=2732.77, ppl=4.44, accuracy=65.407, wps=12311.9, ups=1.47, wpb=8356.2, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.568, clip=0, loss_scale=64, train_wall=67, gb_free=15.8, wall=32647
2023-08-04 09:51:28 | INFO | train_inner | epoch 028:    719 / 1474 loss=1.975, trans_loss=4.963, nll_loss=2.147, w2v_ctc_loss=0.618, task_loss=1.27, contrastive_loss=0.181, total=4185.82, n_correct=2744.62, ppl=4.43, accuracy=65.569, wps=12340.1, ups=1.47, wpb=8371.6, bsz=326.4, num_updates=40500, lr=7.02728e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=67, gb_free=15.9, wall=32715
2023-08-04 09:52:36 | INFO | train_inner | epoch 028:    819 / 1474 loss=1.965, trans_loss=4.958, nll_loss=2.139, w2v_ctc_loss=0.616, task_loss=1.372, contrastive_loss=0.059, total=4096.2, n_correct=2692.15, ppl=4.41, accuracy=65.723, wps=12081.8, ups=1.47, wpb=8192.4, bsz=307, num_updates=40600, lr=7.01862e-05, gnorm=0.575, clip=0, loss_scale=64, train_wall=67, gb_free=15.7, wall=32783
2023-08-04 09:53:44 | INFO | train_inner | epoch 028:    919 / 1474 loss=1.983, trans_loss=4.972, nll_loss=2.157, w2v_ctc_loss=0.628, task_loss=1.436, contrastive_loss=0.123, total=4120.27, n_correct=2689.28, ppl=4.46, accuracy=65.27, wps=12096.6, ups=1.47, wpb=8240.5, bsz=300.8, num_updates=40700, lr=7.01e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=68, gb_free=17.4, wall=32851
2023-08-04 09:54:52 | INFO | train_inner | epoch 028:   1019 / 1474 loss=1.986, trans_loss=4.971, nll_loss=2.157, w2v_ctc_loss=0.63, task_loss=1.368, contrastive_loss=0.177, total=4177.86, n_correct=2729.36, ppl=4.46, accuracy=65.329, wps=12363.9, ups=1.48, wpb=8355.7, bsz=311.1, num_updates=40800, lr=7.0014e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=67, gb_free=16.4, wall=32919
2023-08-04 09:56:00 | INFO | train_inner | epoch 028:   1119 / 1474 loss=1.969, trans_loss=4.959, nll_loss=2.143, w2v_ctc_loss=0.619, task_loss=1.355, contrastive_loss=0.082, total=4210.86, n_correct=2761.04, ppl=4.42, accuracy=65.57, wps=12327.5, ups=1.46, wpb=8421.7, bsz=318.9, num_updates=40900, lr=6.99284e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=68, gb_free=17.5, wall=32987
2023-08-04 09:57:08 | INFO | train_inner | epoch 028:   1219 / 1474 loss=1.971, trans_loss=4.968, nll_loss=2.154, w2v_ctc_loss=0.617, task_loss=1.379, contrastive_loss=0.068, total=4104.61, n_correct=2686.51, ppl=4.45, accuracy=65.451, wps=12059.6, ups=1.47, wpb=8209.2, bsz=305.6, num_updates=41000, lr=6.9843e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=33055
2023-08-04 09:58:16 | INFO | train_inner | epoch 028:   1319 / 1474 loss=1.985, trans_loss=4.975, nll_loss=2.161, w2v_ctc_loss=0.636, task_loss=1.531, contrastive_loss=0.082, total=4087.78, n_correct=2665.25, ppl=4.47, accuracy=65.2, wps=11987.3, ups=1.47, wpb=8175.6, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=68, gb_free=15, wall=33123
2023-08-04 09:59:24 | INFO | train_inner | epoch 028:   1419 / 1474 loss=1.98, trans_loss=4.973, nll_loss=2.158, w2v_ctc_loss=0.622, task_loss=1.466, contrastive_loss=0.101, total=4145.03, n_correct=2706.02, ppl=4.46, accuracy=65.283, wps=12191.2, ups=1.47, wpb=8290.1, bsz=297.6, num_updates=41200, lr=6.96733e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=68, gb_free=17.6, wall=33191
2023-08-04 10:00:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:3')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:1')
2023-08-04 10:00:27 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.203 | trans_loss 5.573 | nll_loss 2.849 | w2v_ctc_loss 1.343 | task_loss 4.587 | contrastive_loss 0.252 | total 4003.4 | n_correct 2488.3 | ppl 7.2 | accuracy 62.155 | uer 16.771 | wer 18.657 | raw_wer 18.657 | bleu 19.94 | wps 1962.3 | wpb 4003.4 | bsz 141.8 | num_updates 41255 | best_bleu 20.26
2023-08-04 10:00:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41255 updates
2023-08-04 10:00:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt
2023-08-04 10:00:39 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt
2023-08-04 10:00:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt (epoch 28 @ 41255 updates, score 19.94) (writing took 12.504786241799593 seconds)
2023-08-04 10:00:39 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-04 10:00:39 | INFO | train | epoch 028 | loss 1.974 | trans_loss 4.961 | nll_loss 2.143 | w2v_ctc_loss 0.622 | task_loss 1.398 | contrastive_loss 0.113 | total 4138.65 | n_correct 2712.27 | ppl 4.42 | accuracy 65.535 | wps 11267.8 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 41255 | lr 6.96268e-05 | gnorm 0.572 | clip 0 | loss_scale 64 | train_wall 994 | gb_free 16.4 | wall 33266
2023-08-04 10:00:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 10:00:39 | INFO | fairseq.trainer | begin training epoch 29
2023-08-04 10:00:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 10:01:18 | INFO | train_inner | epoch 029:     45 / 1474 loss=1.966, trans_loss=4.948, nll_loss=2.127, w2v_ctc_loss=0.623, task_loss=1.353, contrastive_loss=0.074, total=4163.06, n_correct=2741.8, ppl=4.37, accuracy=65.86, wps=7321.8, ups=0.88, wpb=8326.1, bsz=314, num_updates=41300, lr=6.95889e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=67, gb_free=16.1, wall=33305
2023-08-04 10:02:26 | INFO | train_inner | epoch 029:    145 / 1474 loss=1.966, trans_loss=4.944, nll_loss=2.12, w2v_ctc_loss=0.617, task_loss=1.373, contrastive_loss=0.106, total=4116.29, n_correct=2710.12, ppl=4.35, accuracy=65.839, wps=12141.5, ups=1.47, wpb=8232.6, bsz=308.5, num_updates=41400, lr=6.95048e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=67, gb_free=13.9, wall=33373
2023-08-04 10:03:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 10:03:35 | INFO | train_inner | epoch 029:    246 / 1474 loss=1.952, trans_loss=4.934, nll_loss=2.108, w2v_ctc_loss=0.605, task_loss=1.315, contrastive_loss=0.078, total=4170.42, n_correct=2756.52, ppl=4.31, accuracy=66.097, wps=12090.1, ups=1.45, wpb=8340.8, bsz=321.4, num_updates=41500, lr=6.9421e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=33442
2023-08-04 10:04:43 | INFO | train_inner | epoch 029:    346 / 1474 loss=1.972, trans_loss=4.956, nll_loss=2.136, w2v_ctc_loss=0.626, task_loss=1.5, contrastive_loss=0.062, total=4095.17, n_correct=2688.49, ppl=4.4, accuracy=65.65, wps=11970.8, ups=1.46, wpb=8190.3, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=33510
2023-08-04 10:05:51 | INFO | train_inner | epoch 029:    446 / 1474 loss=1.955, trans_loss=4.934, nll_loss=2.107, w2v_ctc_loss=0.611, task_loss=1.349, contrastive_loss=0.055, total=4157.44, n_correct=2748.16, ppl=4.31, accuracy=66.102, wps=12299.9, ups=1.48, wpb=8314.9, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=67, gb_free=16.5, wall=33578
2023-08-04 10:06:59 | INFO | train_inner | epoch 029:    546 / 1474 loss=1.978, trans_loss=4.957, nll_loss=2.138, w2v_ctc_loss=0.616, task_loss=1.49, contrastive_loss=0.153, total=4150.87, n_correct=2721.02, ppl=4.4, accuracy=65.553, wps=12201.4, ups=1.47, wpb=8301.7, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=33646
2023-08-04 10:08:07 | INFO | train_inner | epoch 029:    646 / 1474 loss=1.967, trans_loss=4.945, nll_loss=2.124, w2v_ctc_loss=0.609, task_loss=1.321, contrastive_loss=0.222, total=4143.02, n_correct=2727.15, ppl=4.36, accuracy=65.825, wps=12225.4, ups=1.48, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=33714
2023-08-04 10:09:15 | INFO | train_inner | epoch 029:    746 / 1474 loss=1.963, trans_loss=4.947, nll_loss=2.126, w2v_ctc_loss=0.607, task_loss=1.291, contrastive_loss=0.143, total=4249.79, n_correct=2797.99, ppl=4.36, accuracy=65.838, wps=12467.7, ups=1.47, wpb=8499.6, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=33782
2023-08-04 10:09:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 10:09:38 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.203 | trans_loss 5.57 | nll_loss 2.843 | w2v_ctc_loss 1.349 | task_loss 4.595 | contrastive_loss 0.254 | total 4003.4 | n_correct 2487.9 | ppl 7.18 | accuracy 62.145 | uer 17.033 | wer 18.903 | raw_wer 18.903 | bleu 20.46 | wps 2244.9 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.46
2023-08-04 10:09:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-04 10:09:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_29_42000.pt
2023-08-04 10:09:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_29_42000.pt
2023-08-04 10:10:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 20.46) (writing took 49.882837280631065 seconds)
2023-08-04 10:11:36 | INFO | train_inner | epoch 029:    846 / 1474 loss=1.974, trans_loss=4.968, nll_loss=2.152, w2v_ctc_loss=0.619, task_loss=1.555, contrastive_loss=0.053, total=4027.19, n_correct=2632.19, ppl=4.44, accuracy=65.36, wps=5698.8, ups=0.71, wpb=8054.4, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.585, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=33923
2023-08-04 10:12:43 | INFO | train_inner | epoch 029:    946 / 1474 loss=1.973, trans_loss=4.967, nll_loss=2.151, w2v_ctc_loss=0.623, task_loss=1.423, contrastive_loss=0.067, total=4082.14, n_correct=2675.68, ppl=4.44, accuracy=65.546, wps=12215, ups=1.5, wpb=8164.3, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.589, clip=0, loss_scale=32, train_wall=66, gb_free=15.3, wall=33990
2023-08-04 10:13:50 | INFO | train_inner | epoch 029:   1046 / 1474 loss=1.967, trans_loss=4.952, nll_loss=2.133, w2v_ctc_loss=0.61, task_loss=1.393, contrastive_loss=0.142, total=4148.18, n_correct=2727.15, ppl=4.39, accuracy=65.743, wps=12273.6, ups=1.48, wpb=8296.4, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=67, gb_free=15.9, wall=34058
2023-08-04 10:14:58 | INFO | train_inner | epoch 029:   1146 / 1474 loss=1.974, trans_loss=4.968, nll_loss=2.153, w2v_ctc_loss=0.623, task_loss=1.532, contrastive_loss=0.049, total=4063.95, n_correct=2661.01, ppl=4.45, accuracy=65.478, wps=11970.8, ups=1.47, wpb=8127.9, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=67, gb_free=13.2, wall=34125
2023-08-04 10:16:07 | INFO | train_inner | epoch 029:   1246 / 1474 loss=1.973, trans_loss=4.968, nll_loss=2.154, w2v_ctc_loss=0.624, task_loss=1.421, contrastive_loss=0.059, total=4158.81, n_correct=2724.14, ppl=4.45, accuracy=65.503, wps=12070.1, ups=1.45, wpb=8317.6, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=34194
2023-08-04 10:17:22 | INFO | train_inner | epoch 029:   1346 / 1474 loss=1.972, trans_loss=4.961, nll_loss=2.145, w2v_ctc_loss=0.613, task_loss=1.374, contrastive_loss=0.125, total=4166.34, n_correct=2733.71, ppl=4.42, accuracy=65.614, wps=11205.9, ups=1.34, wpb=8332.7, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=74, gb_free=17.8, wall=34269
2023-08-04 10:18:34 | INFO | train_inner | epoch 029:   1446 / 1474 loss=1.975, trans_loss=4.962, nll_loss=2.147, w2v_ctc_loss=0.618, task_loss=1.371, contrastive_loss=0.151, total=4162.2, n_correct=2722.33, ppl=4.43, accuracy=65.406, wps=11469.1, ups=1.38, wpb=8324.4, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=72, gb_free=17.3, wall=34341
2023-08-04 10:18:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 10:19:19 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.198 | trans_loss 5.57 | nll_loss 2.845 | w2v_ctc_loss 1.33 | task_loss 4.616 | contrastive_loss 0.252 | total 4003.4 | n_correct 2486.3 | ppl 7.18 | accuracy 62.105 | uer 16.933 | wer 18.933 | raw_wer 18.933 | bleu 20.1 | wps 2083.8 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 20.46
2023-08-04 10:19:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-08-04 10:19:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1004.pt
2023-08-04 10:19:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1004.pt
2023-08-04 10:19:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1004.pt (epoch 29 @ 42728 updates, score 20.1) (writing took 34.401563407853246 seconds)
2023-08-04 10:19:54 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-04 10:19:54 | INFO | train | epoch 029 | loss 1.968 | trans_loss 4.954 | nll_loss 2.134 | w2v_ctc_loss 0.615 | task_loss 1.401 | contrastive_loss 0.104 | total 4136.74 | n_correct 2717.66 | ppl 4.39 | accuracy 65.696 | wps 10552.8 | ups 1.28 | wpb 8273.5 | bsz 305.1 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.575 | clip 0 | loss_scale 32 | train_wall 1007 | gb_free 16 | wall 34421
2023-08-04 10:19:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 10:19:54 | INFO | fairseq.trainer | begin training epoch 30
2023-08-04 10:19:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 10:20:53 | INFO | train_inner | epoch 030:     72 / 1474 loss=1.961, trans_loss=4.939, nll_loss=2.115, w2v_ctc_loss=0.604, task_loss=1.324, contrastive_loss=0.169, total=4182.65, n_correct=2757.48, ppl=4.33, accuracy=65.927, wps=6044.1, ups=0.72, wpb=8365.3, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=71, gb_free=13.4, wall=34480
2023-08-04 10:22:04 | INFO | train_inner | epoch 030:    172 / 1474 loss=1.952, trans_loss=4.92, nll_loss=2.09, w2v_ctc_loss=0.608, task_loss=1.312, contrastive_loss=0.102, total=4203.05, n_correct=2791.77, ppl=4.26, accuracy=66.422, wps=11742.6, ups=1.4, wpb=8406.1, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=71, gb_free=17.4, wall=34551
2023-08-04 10:23:11 | INFO | train_inner | epoch 030:    272 / 1474 loss=1.96, trans_loss=4.938, nll_loss=2.113, w2v_ctc_loss=0.618, task_loss=1.441, contrastive_loss=0.052, total=4116.93, n_correct=2719.35, ppl=4.33, accuracy=66.053, wps=12249.6, ups=1.49, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=34619
2023-08-04 10:24:20 | INFO | train_inner | epoch 030:    372 / 1474 loss=1.951, trans_loss=4.929, nll_loss=2.102, w2v_ctc_loss=0.606, task_loss=1.404, contrastive_loss=0.058, total=4173.13, n_correct=2765.85, ppl=4.29, accuracy=66.278, wps=12187, ups=1.46, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=68, gb_free=11.7, wall=34687
2023-08-04 10:25:28 | INFO | train_inner | epoch 030:    472 / 1474 loss=1.955, trans_loss=4.935, nll_loss=2.11, w2v_ctc_loss=0.601, task_loss=1.334, contrastive_loss=0.123, total=4135.2, n_correct=2736.7, ppl=4.32, accuracy=66.181, wps=12229.8, ups=1.48, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=34755
2023-08-04 10:26:35 | INFO | train_inner | epoch 030:    572 / 1474 loss=1.96, trans_loss=4.945, nll_loss=2.123, w2v_ctc_loss=0.609, task_loss=1.363, contrastive_loss=0.084, total=4168.65, n_correct=2752.64, ppl=4.36, accuracy=66.032, wps=12357.5, ups=1.48, wpb=8337.3, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=67, gb_free=15.8, wall=34822
2023-08-04 10:27:43 | INFO | train_inner | epoch 030:    672 / 1474 loss=1.967, trans_loss=4.946, nll_loss=2.125, w2v_ctc_loss=0.62, task_loss=1.381, contrastive_loss=0.102, total=4183.65, n_correct=2754.71, ppl=4.36, accuracy=65.845, wps=12274.8, ups=1.47, wpb=8367.3, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.577, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=34890
2023-08-04 10:28:51 | INFO | train_inner | epoch 030:    772 / 1474 loss=1.981, trans_loss=4.96, nll_loss=2.143, w2v_ctc_loss=0.627, task_loss=1.432, contrastive_loss=0.179, total=4106.9, n_correct=2692.24, ppl=4.42, accuracy=65.554, wps=12040.9, ups=1.47, wpb=8213.8, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.578, clip=0, loss_scale=32, train_wall=68, gb_free=11.8, wall=34959
2023-08-04 10:30:00 | INFO | train_inner | epoch 030:    872 / 1474 loss=1.964, trans_loss=4.951, nll_loss=2.13, w2v_ctc_loss=0.612, task_loss=1.466, contrastive_loss=0.059, total=4089.18, n_correct=2688.06, ppl=4.38, accuracy=65.736, wps=11984.4, ups=1.47, wpb=8178.4, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=35027
2023-08-04 10:31:08 | INFO | train_inner | epoch 030:    972 / 1474 loss=1.966, trans_loss=4.954, nll_loss=2.135, w2v_ctc_loss=0.615, task_loss=1.413, contrastive_loss=0.08, total=4140.03, n_correct=2721.22, ppl=4.39, accuracy=65.729, wps=12164.2, ups=1.47, wpb=8280.1, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=68, gb_free=13.8, wall=35095
2023-08-04 10:32:16 | INFO | train_inner | epoch 030:   1072 / 1474 loss=1.98, trans_loss=4.965, nll_loss=2.148, w2v_ctc_loss=0.621, task_loss=1.567, contrastive_loss=0.144, total=4101.12, n_correct=2683.86, ppl=4.43, accuracy=65.442, wps=11992.9, ups=1.46, wpb=8202.2, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.579, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=35163
2023-08-04 10:33:24 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.963, trans_loss=4.951, nll_loss=2.132, w2v_ctc_loss=0.602, task_loss=1.342, contrastive_loss=0.131, total=4168.22, n_correct=2742.48, ppl=4.38, accuracy=65.795, wps=12295.2, ups=1.47, wpb=8336.4, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.568, clip=0, loss_scale=64, train_wall=67, gb_free=16.7, wall=35231
2023-08-04 10:34:32 | INFO | train_inner | epoch 030:   1272 / 1474 loss=1.973, trans_loss=4.963, nll_loss=2.146, w2v_ctc_loss=0.621, task_loss=1.564, contrastive_loss=0.062, total=4032.74, n_correct=2641.18, ppl=4.43, accuracy=65.493, wps=11781.7, ups=1.46, wpb=8065.5, bsz=281.8, num_updates=44000, lr=6.742e-05, gnorm=0.588, clip=0, loss_scale=64, train_wall=68, gb_free=16.8, wall=35299
2023-08-04 10:34:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 10:34:56 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.209 | trans_loss 5.57 | nll_loss 2.844 | w2v_ctc_loss 1.364 | task_loss 4.597 | contrastive_loss 0.259 | total 4003.4 | n_correct 2486.6 | ppl 7.18 | accuracy 62.112 | uer 17.015 | wer 18.922 | raw_wer 18.922 | bleu 20.02 | wps 2222.6 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.46
2023-08-04 10:34:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-04 10:34:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_30_44000.pt
2023-08-04 10:34:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_30_44000.pt
2023-08-04 10:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 20.02) (writing took 14.11819569952786 seconds)
2023-08-04 10:36:18 | INFO | train_inner | epoch 030:   1372 / 1474 loss=1.959, trans_loss=4.953, nll_loss=2.136, w2v_ctc_loss=0.609, task_loss=1.316, contrastive_loss=0.077, total=4166.96, n_correct=2743.27, ppl=4.39, accuracy=65.834, wps=7906.4, ups=0.95, wpb=8333.9, bsz=322.3, num_updates=44100, lr=6.73435e-05, gnorm=0.568, clip=0, loss_scale=64, train_wall=67, gb_free=15.2, wall=35405
2023-08-04 10:36:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-04 10:37:26 | INFO | train_inner | epoch 030:   1473 / 1474 loss=1.96, trans_loss=4.956, nll_loss=2.139, w2v_ctc_loss=0.607, task_loss=1.354, contrastive_loss=0.056, total=4120.69, n_correct=2709, ppl=4.4, accuracy=65.741, wps=12124.7, ups=1.47, wpb=8241.4, bsz=305, num_updates=44200, lr=6.72673e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=67, gb_free=16.3, wall=35473
2023-08-04 10:37:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 10:37:49 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.202 | trans_loss 5.57 | nll_loss 2.847 | w2v_ctc_loss 1.344 | task_loss 4.615 | contrastive_loss 0.252 | total 4003.4 | n_correct 2492.4 | ppl 7.19 | accuracy 62.257 | uer 16.98 | wer 18.881 | raw_wer 18.881 | bleu 20.13 | wps 2239 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 20.46
2023-08-04 10:37:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-08-04 10:37:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1306.pt
2023-08-04 10:37:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1306.pt
2023-08-04 10:38:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1306.pt (epoch 30 @ 44201 updates, score 20.13) (writing took 33.71888652071357 seconds)
2023-08-04 10:38:23 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-04 10:38:23 | INFO | train | epoch 030 | loss 1.963 | trans_loss 4.947 | nll_loss 2.125 | w2v_ctc_loss 0.612 | task_loss 1.402 | contrastive_loss 0.1 | total 4137.05 | n_correct 2725.37 | ppl 4.36 | accuracy 65.877 | wps 10986.6 | ups 1.33 | wpb 8274.1 | bsz 305 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.574 | clip 0 | loss_scale 32 | train_wall 999 | gb_free 17.1 | wall 35530
2023-08-04 10:38:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 10:38:23 | INFO | fairseq.trainer | begin training epoch 31
2023-08-04 10:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 10:39:39 | INFO | train_inner | epoch 031:     99 / 1474 loss=1.957, trans_loss=4.928, nll_loss=2.099, w2v_ctc_loss=0.616, task_loss=1.495, contrastive_loss=0.056, total=4054.44, n_correct=2683.59, ppl=4.29, accuracy=66.189, wps=6102.6, ups=0.75, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=35606
2023-08-04 10:40:47 | INFO | train_inner | epoch 031:    199 / 1474 loss=1.957, trans_loss=4.931, nll_loss=2.103, w2v_ctc_loss=0.61, task_loss=1.427, contrastive_loss=0.087, total=4147.4, n_correct=2746.66, ppl=4.3, accuracy=66.226, wps=12213.1, ups=1.47, wpb=8294.8, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=35674
2023-08-04 10:41:55 | INFO | train_inner | epoch 031:    299 / 1474 loss=1.956, trans_loss=4.928, nll_loss=2.1, w2v_ctc_loss=0.605, task_loss=1.429, contrastive_loss=0.123, total=4149.21, n_correct=2746.94, ppl=4.29, accuracy=66.204, wps=12076.7, ups=1.46, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=35742
2023-08-04 10:43:03 | INFO | train_inner | epoch 031:    399 / 1474 loss=1.96, trans_loss=4.94, nll_loss=2.115, w2v_ctc_loss=0.61, task_loss=1.529, contrastive_loss=0.058, total=4092.62, n_correct=2698.89, ppl=4.33, accuracy=65.945, wps=12128.9, ups=1.48, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=67, gb_free=17.2, wall=35810
2023-08-04 10:44:11 | INFO | train_inner | epoch 031:    499 / 1474 loss=1.961, trans_loss=4.936, nll_loss=2.111, w2v_ctc_loss=0.621, task_loss=1.466, contrastive_loss=0.071, total=4111.85, n_correct=2710.51, ppl=4.32, accuracy=65.919, wps=12063.3, ups=1.47, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.582, clip=0, loss_scale=32, train_wall=68, gb_free=10.8, wall=35878
2023-08-04 10:45:19 | INFO | train_inner | epoch 031:    599 / 1474 loss=1.953, trans_loss=4.935, nll_loss=2.109, w2v_ctc_loss=0.602, task_loss=1.461, contrastive_loss=0.059, total=4083.44, n_correct=2701.72, ppl=4.31, accuracy=66.163, wps=11990, ups=1.47, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=35946
2023-08-04 10:46:27 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.948, trans_loss=4.933, nll_loss=2.107, w2v_ctc_loss=0.598, task_loss=1.333, contrastive_loss=0.06, total=4213.98, n_correct=2790.72, ppl=4.31, accuracy=66.225, wps=12430, ups=1.47, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=67, gb_free=16.2, wall=36014
2023-08-04 10:46:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 10:47:35 | INFO | train_inner | epoch 031:    800 / 1474 loss=1.966, trans_loss=4.948, nll_loss=2.127, w2v_ctc_loss=0.607, task_loss=1.458, contrastive_loss=0.133, total=4099.09, n_correct=2701.35, ppl=4.37, accuracy=65.901, wps=11974.7, ups=1.46, wpb=8198.2, bsz=296.5, num_updates=45000, lr=6.66667e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=36082
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:0')
2023-08-04 10:48:44 | INFO | train_inner | epoch 031:    900 / 1474 loss=1.96, trans_loss=4.941, nll_loss=2.118, w2v_ctc_loss=0.611, task_loss=1.476, contrastive_loss=0.076, total=4099.13, n_correct=2699.65, ppl=4.34, accuracy=65.859, wps=12019.7, ups=1.47, wpb=8198.3, bsz=294.3, num_updates=45100, lr=6.65927e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=68, gb_free=15.1, wall=36151
2023-08-04 10:49:51 | INFO | train_inner | epoch 031:   1000 / 1474 loss=1.963, trans_loss=4.949, nll_loss=2.13, w2v_ctc_loss=0.604, task_loss=1.307, contrastive_loss=0.161, total=4186.81, n_correct=2759.01, ppl=4.38, accuracy=65.898, wps=12366, ups=1.48, wpb=8373.6, bsz=320.9, num_updates=45200, lr=6.6519e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=67, gb_free=13.3, wall=36218
2023-08-04 10:50:59 | INFO | train_inner | epoch 031:   1100 / 1474 loss=1.958, trans_loss=4.942, nll_loss=2.12, w2v_ctc_loss=0.604, task_loss=1.365, contrastive_loss=0.111, total=4149.25, n_correct=2737.09, ppl=4.35, accuracy=65.966, wps=12208.3, ups=1.47, wpb=8298.5, bsz=315.2, num_updates=45300, lr=6.64455e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=67, gb_free=15.9, wall=36286
2023-08-04 10:52:06 | INFO | train_inner | epoch 031:   1200 / 1474 loss=1.965, trans_loss=4.947, nll_loss=2.128, w2v_ctc_loss=0.602, task_loss=1.319, contrastive_loss=0.223, total=4187.45, n_correct=2762.18, ppl=4.37, accuracy=65.963, wps=12472.4, ups=1.49, wpb=8374.9, bsz=320.3, num_updates=45400, lr=6.63723e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=67, gb_free=17, wall=36354
2023-08-04 10:53:14 | INFO | train_inner | epoch 031:   1300 / 1474 loss=1.956, trans_loss=4.949, nll_loss=2.13, w2v_ctc_loss=0.606, task_loss=1.253, contrastive_loss=0.067, total=4227.39, n_correct=2789.41, ppl=4.38, accuracy=65.984, wps=12486.9, ups=1.48, wpb=8454.8, bsz=326.7, num_updates=45500, lr=6.62994e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=36421
2023-08-04 10:54:22 | INFO | train_inner | epoch 031:   1400 / 1474 loss=1.973, trans_loss=4.949, nll_loss=2.13, w2v_ctc_loss=0.607, task_loss=1.277, contrastive_loss=0.272, total=4191.1, n_correct=2753.62, ppl=4.38, accuracy=65.702, wps=12305.7, ups=1.47, wpb=8382.2, bsz=327, num_updates=45600, lr=6.62266e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=68, gb_free=16.5, wall=36489
2023-08-04 10:55:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:6')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:4')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:5')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:1')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:7')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:2')
mt_weight tensor(1.)
asr_weight tensor(0.2499, device='cuda:3')
2023-08-04 10:55:35 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.209 | trans_loss 5.564 | nll_loss 2.836 | w2v_ctc_loss 1.38 | task_loss 4.604 | contrastive_loss 0.257 | total 4003.4 | n_correct 2493.2 | ppl 7.14 | accuracy 62.277 | uer 16.853 | wer 18.739 | raw_wer 18.739 | bleu 19.88 | wps 2198.5 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 20.46
2023-08-04 10:55:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-08-04 10:55:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt
2023-08-04 10:55:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt
2023-08-04 10:55:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_last.pt (epoch 31 @ 45674 updates, score 19.88) (writing took 12.459038915112615 seconds)
2023-08-04 10:55:47 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-04 10:55:47 | INFO | train | epoch 031 | loss 1.96 | trans_loss 4.94 | nll_loss 2.117 | w2v_ctc_loss 0.608 | task_loss 1.398 | contrastive_loss 0.11 | total 4138.73 | n_correct 2731.66 | ppl 4.34 | accuracy 66.002 | wps 11677.5 | ups 1.41 | wpb 8277.5 | bsz 305.7 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.576 | clip 0 | loss_scale 16 | train_wall 993 | gb_free 12 | wall 36574
2023-08-04 10:55:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 10:55:48 | INFO | fairseq.trainer | begin training epoch 32
2023-08-04 10:55:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 10:56:12 | INFO | train_inner | epoch 032:     26 / 1474 loss=1.958, trans_loss=4.942, nll_loss=2.119, w2v_ctc_loss=0.61, task_loss=1.474, contrastive_loss=0.055, total=4040.88, n_correct=2668.18, ppl=4.34, accuracy=66.03, wps=7339.9, ups=0.91, wpb=8081.8, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.589, clip=0, loss_scale=16, train_wall=66, gb_free=15.5, wall=36599
2023-08-04 10:57:20 | INFO | train_inner | epoch 032:    126 / 1474 loss=1.932, trans_loss=4.904, nll_loss=2.07, w2v_ctc_loss=0.586, task_loss=1.289, contrastive_loss=0.067, total=4222.14, n_correct=2821.07, ppl=4.2, accuracy=66.816, wps=12498.7, ups=1.48, wpb=8444.3, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.568, clip=0, loss_scale=16, train_wall=67, gb_free=15.4, wall=36667
2023-08-04 10:58:29 | INFO | train_inner | epoch 032:    226 / 1474 loss=1.946, trans_loss=4.923, nll_loss=2.095, w2v_ctc_loss=0.6, task_loss=1.328, contrastive_loss=0.078, total=4159.77, n_correct=2759.97, ppl=4.27, accuracy=66.349, wps=12107.5, ups=1.46, wpb=8319.5, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.571, clip=0, loss_scale=16, train_wall=68, gb_free=16.2, wall=36736
2023-08-04 10:59:36 | INFO | train_inner | epoch 032:    326 / 1474 loss=1.936, trans_loss=4.91, nll_loss=2.078, w2v_ctc_loss=0.588, task_loss=1.323, contrastive_loss=0.07, total=4179.65, n_correct=2790, ppl=4.22, accuracy=66.752, wps=12442.1, ups=1.49, wpb=8359.3, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.57, clip=0, loss_scale=16, train_wall=67, gb_free=16.2, wall=36803
2023-08-04 10:59:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 11:00:00 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.211 | trans_loss 5.577 | nll_loss 2.854 | w2v_ctc_loss 1.358 | task_loss 4.611 | contrastive_loss 0.257 | total 4003.4 | n_correct 2492 | ppl 7.23 | accuracy 62.247 | uer 17.01 | wer 18.944 | raw_wer 18.944 | bleu 19.93 | wps 2124.5 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.46
2023-08-04 11:00:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-04 11:00:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_32_46000.pt
2023-08-04 11:00:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_32_46000.pt
2023-08-04 11:00:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 19.93) (writing took 13.157197698950768 seconds)
2023-08-04 11:01:21 | INFO | train_inner | epoch 032:    426 / 1474 loss=1.944, trans_loss=4.919, nll_loss=2.09, w2v_ctc_loss=0.599, task_loss=1.365, contrastive_loss=0.068, total=4172.34, n_correct=2775.13, ppl=4.26, accuracy=66.513, wps=7908, ups=0.95, wpb=8344.7, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=68, gb_free=17.1, wall=36908
2023-08-04 11:02:30 | INFO | train_inner | epoch 032:    526 / 1474 loss=1.957, trans_loss=4.93, nll_loss=2.104, w2v_ctc_loss=0.604, task_loss=1.365, contrastive_loss=0.151, total=4191.15, n_correct=2779.13, ppl=4.3, accuracy=66.309, wps=12216, ups=1.46, wpb=8382.3, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.575, clip=0, loss_scale=16, train_wall=68, gb_free=14.9, wall=36977
2023-08-04 11:03:39 | INFO | train_inner | epoch 032:    626 / 1474 loss=1.957, trans_loss=4.938, nll_loss=2.114, w2v_ctc_loss=0.607, task_loss=1.464, contrastive_loss=0.075, total=4138.05, n_correct=2732.68, ppl=4.33, accuracy=66.038, wps=12033.7, ups=1.45, wpb=8276.1, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=68, gb_free=13.2, wall=37046
2023-08-04 11:04:47 | INFO | train_inner | epoch 032:    726 / 1474 loss=1.954, trans_loss=4.935, nll_loss=2.11, w2v_ctc_loss=0.609, task_loss=1.418, contrastive_loss=0.057, total=4156.23, n_correct=2749.65, ppl=4.32, accuracy=66.157, wps=12185.6, ups=1.47, wpb=8312.5, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.573, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=37114
2023-08-04 11:05:54 | INFO | train_inner | epoch 032:    826 / 1474 loss=1.951, trans_loss=4.935, nll_loss=2.109, w2v_ctc_loss=0.601, task_loss=1.45, contrastive_loss=0.053, total=4112.3, n_correct=2721.63, ppl=4.31, accuracy=66.183, wps=12243.9, ups=1.49, wpb=8224.6, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=67, gb_free=15.8, wall=37181
2023-08-04 11:07:02 | INFO | train_inner | epoch 032:    926 / 1474 loss=1.95, trans_loss=4.936, nll_loss=2.111, w2v_ctc_loss=0.595, task_loss=1.443, contrastive_loss=0.052, total=4139.37, n_correct=2736.24, ppl=4.32, accuracy=66.103, wps=12188.4, ups=1.47, wpb=8278.7, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=67, gb_free=12.7, wall=37249
2023-08-04 11:08:10 | INFO | train_inner | epoch 032:   1026 / 1474 loss=1.963, trans_loss=4.945, nll_loss=2.123, w2v_ctc_loss=0.607, task_loss=1.374, contrastive_loss=0.148, total=4121.85, n_correct=2713.45, ppl=4.36, accuracy=65.831, wps=12099.8, ups=1.47, wpb=8243.7, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.583, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=37317
2023-08-04 11:09:18 | INFO | train_inner | epoch 032:   1126 / 1474 loss=1.967, trans_loss=4.949, nll_loss=2.127, w2v_ctc_loss=0.609, task_loss=1.656, contrastive_loss=0.091, total=4015.59, n_correct=2637.63, ppl=4.37, accuracy=65.685, wps=11820.9, ups=1.47, wpb=8031.2, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.591, clip=0, loss_scale=16, train_wall=67, gb_free=17.2, wall=37385
2023-08-04 11:10:26 | INFO | train_inner | epoch 032:   1226 / 1474 loss=1.97, trans_loss=4.953, nll_loss=2.135, w2v_ctc_loss=0.606, task_loss=1.379, contrastive_loss=0.2, total=4153.44, n_correct=2731.28, ppl=4.39, accuracy=65.759, wps=12230.9, ups=1.47, wpb=8306.9, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.58, clip=0, loss_scale=16, train_wall=67, gb_free=16.3, wall=37453
2023-08-04 11:11:33 | INFO | train_inner | epoch 032:   1326 / 1474 loss=1.958, trans_loss=4.945, nll_loss=2.123, w2v_ctc_loss=0.607, task_loss=1.444, contrastive_loss=0.053, total=4075.86, n_correct=2688.33, ppl=4.36, accuracy=65.957, wps=12132.8, ups=1.49, wpb=8151.7, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.584, clip=0, loss_scale=32, train_wall=67, gb_free=16.8, wall=37520
2023-08-04 11:12:42 | INFO | train_inner | epoch 032:   1426 / 1474 loss=1.975, trans_loss=4.949, nll_loss=2.129, w2v_ctc_loss=0.611, task_loss=1.394, contrastive_loss=0.288, total=4116.4, n_correct=2709.77, ppl=4.37, accuracy=65.829, wps=12020.2, ups=1.46, wpb=8232.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=37589
2023-08-04 11:13:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 11:13:37 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.571 | nll_loss 2.847 | w2v_ctc_loss 1.371 | task_loss 4.596 | contrastive_loss 0.25 | total 4003.4 | n_correct 2492.7 | ppl 7.2 | accuracy 62.265 | uer 16.877 | wer 18.683 | raw_wer 18.683 | bleu 20.3 | wps 2163.6 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.46
2023-08-04 11:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-08-04 11:13:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.3000.pt
2023-08-04 11:13:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.3000.pt
2023-08-04 11:13:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.3000.pt (epoch 32 @ 47148 updates, score 20.3) (writing took 13.119770050048828 seconds)
2023-08-04 11:13:51 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-04 11:13:51 | INFO | train | epoch 032 | loss 1.954 | trans_loss 4.934 | nll_loss 2.108 | w2v_ctc_loss 0.602 | task_loss 1.397 | contrastive_loss 0.109 | total 4138.65 | n_correct 2738.41 | ppl 4.31 | accuracy 66.167 | wps 11259.5 | ups 1.36 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.577 | clip 0 | loss_scale 32 | train_wall 994 | gb_free 16.4 | wall 37658
2023-08-04 11:13:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 11:13:51 | INFO | fairseq.trainer | begin training epoch 33
2023-08-04 11:13:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 11:14:35 | INFO | train_inner | epoch 033:     52 / 1474 loss=1.954, trans_loss=4.93, nll_loss=2.105, w2v_ctc_loss=0.596, task_loss=1.32, contrastive_loss=0.16, total=4149.21, n_correct=2747.59, ppl=4.3, accuracy=66.22, wps=7330.1, ups=0.88, wpb=8298.4, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=67, gb_free=17, wall=37702
2023-08-04 11:15:43 | INFO | train_inner | epoch 033:    152 / 1474 loss=1.939, trans_loss=4.911, nll_loss=2.077, w2v_ctc_loss=0.586, task_loss=1.504, contrastive_loss=0.043, total=4073.9, n_correct=2713.36, ppl=4.22, accuracy=66.604, wps=12013.1, ups=1.47, wpb=8147.8, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=67, gb_free=15.2, wall=37770
2023-08-04 11:16:51 | INFO | train_inner | epoch 033:    252 / 1474 loss=1.949, trans_loss=4.912, nll_loss=2.083, w2v_ctc_loss=0.591, task_loss=1.195, contrastive_loss=0.228, total=4280.14, n_correct=2849.81, ppl=4.24, accuracy=66.582, wps=12609.2, ups=1.47, wpb=8560.3, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=37838
2023-08-04 11:17:59 | INFO | train_inner | epoch 033:    352 / 1474 loss=1.948, trans_loss=4.923, nll_loss=2.095, w2v_ctc_loss=0.599, task_loss=1.427, contrastive_loss=0.077, total=4120.27, n_correct=2732.91, ppl=4.27, accuracy=66.328, wps=12054.8, ups=1.46, wpb=8240.5, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=37906
2023-08-04 11:19:06 | INFO | train_inner | epoch 033:    452 / 1474 loss=1.935, trans_loss=4.909, nll_loss=2.076, w2v_ctc_loss=0.592, task_loss=1.327, contrastive_loss=0.052, total=4141.22, n_correct=2761.77, ppl=4.22, accuracy=66.69, wps=12384.3, ups=1.5, wpb=8282.4, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=66, gb_free=16.4, wall=37973
2023-08-04 11:20:14 | INFO | train_inner | epoch 033:    552 / 1474 loss=1.955, trans_loss=4.931, nll_loss=2.103, w2v_ctc_loss=0.605, task_loss=1.456, contrastive_loss=0.075, total=4133.59, n_correct=2734.06, ppl=4.3, accuracy=66.143, wps=12169.6, ups=1.47, wpb=8267.2, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=67, gb_free=15.2, wall=38041
2023-08-04 11:21:22 | INFO | train_inner | epoch 033:    652 / 1474 loss=1.956, trans_loss=4.939, nll_loss=2.115, w2v_ctc_loss=0.6, task_loss=1.428, contrastive_loss=0.108, total=4157.63, n_correct=2745.23, ppl=4.33, accuracy=66.029, wps=12236.5, ups=1.47, wpb=8315.3, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.583, clip=0, loss_scale=32, train_wall=67, gb_free=17.7, wall=38109
2023-08-04 11:22:30 | INFO | train_inner | epoch 033:    752 / 1474 loss=1.958, trans_loss=4.935, nll_loss=2.109, w2v_ctc_loss=0.614, task_loss=1.517, contrastive_loss=0.053, total=4070.75, n_correct=2687.87, ppl=4.31, accuracy=66.029, wps=11984.8, ups=1.47, wpb=8141.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.591, clip=0, loss_scale=32, train_wall=67, gb_free=16.4, wall=38177
2023-08-04 11:23:37 | INFO | train_inner | epoch 033:    852 / 1474 loss=1.939, trans_loss=4.921, nll_loss=2.094, w2v_ctc_loss=0.581, task_loss=1.328, contrastive_loss=0.125, total=4130.24, n_correct=2749.17, ppl=4.27, accuracy=66.562, wps=12224.5, ups=1.48, wpb=8260.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=67, gb_free=16.7, wall=38244
2023-08-04 11:23:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 11:24:02 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.209 | trans_loss 5.57 | nll_loss 2.842 | w2v_ctc_loss 1.37 | task_loss 4.609 | contrastive_loss 0.251 | total 4003.4 | n_correct 2497.3 | ppl 7.17 | accuracy 62.379 | uer 16.718 | wer 18.605 | raw_wer 18.605 | bleu 20.29 | wps 2084.8 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.46
2023-08-04 11:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-04 11:24:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_33_48000.pt
2023-08-04 11:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_33_48000.pt
2023-08-04 11:24:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 20.29) (writing took 31.025865769013762 seconds)
2023-08-04 11:25:41 | INFO | train_inner | epoch 033:    952 / 1474 loss=1.953, trans_loss=4.933, nll_loss=2.108, w2v_ctc_loss=0.608, task_loss=1.397, contrastive_loss=0.068, total=4151.18, n_correct=2746.22, ppl=4.31, accuracy=66.155, wps=6708.3, ups=0.81, wpb=8302.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.581, clip=0, loss_scale=32, train_wall=67, gb_free=11.1, wall=38368
2023-08-04 11:25:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-04 11:26:50 | INFO | train_inner | epoch 033:   1053 / 1474 loss=1.948, trans_loss=4.928, nll_loss=2.101, w2v_ctc_loss=0.6, task_loss=1.441, contrastive_loss=0.058, total=4120.84, n_correct=2728.37, ppl=4.29, accuracy=66.209, wps=11934.1, ups=1.45, wpb=8241.7, bsz=300, num_updates=48200, lr=6.44157e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=69, gb_free=15.7, wall=38437
2023-08-04 11:27:59 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.957, trans_loss=4.938, nll_loss=2.115, w2v_ctc_loss=0.596, task_loss=1.399, contrastive_loss=0.158, total=4181.58, n_correct=2761.4, ppl=4.33, accuracy=66.037, wps=12177.9, ups=1.46, wpb=8363.2, bsz=310, num_updates=48300, lr=6.43489e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=68, gb_free=15, wall=38506
2023-08-04 11:29:07 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.954, trans_loss=4.936, nll_loss=2.112, w2v_ctc_loss=0.606, task_loss=1.473, contrastive_loss=0.058, total=4115.76, n_correct=2722.39, ppl=4.32, accuracy=66.145, wps=12121.8, ups=1.47, wpb=8231.5, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=67, gb_free=16.7, wall=38574
2023-08-04 11:30:15 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.948, trans_loss=4.934, nll_loss=2.11, w2v_ctc_loss=0.598, task_loss=1.375, contrastive_loss=0.081, total=4120.69, n_correct=2731.81, ppl=4.32, accuracy=66.295, wps=12030.7, ups=1.46, wpb=8241.4, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.587, clip=0, loss_scale=16, train_wall=68, gb_free=16.8, wall=38642
2023-08-04 11:31:23 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.96, trans_loss=4.936, nll_loss=2.114, w2v_ctc_loss=0.598, task_loss=1.397, contrastive_loss=0.225, total=4125.28, n_correct=2728.08, ppl=4.33, accuracy=66.131, wps=12165.1, ups=1.47, wpb=8250.6, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=38710
2023-08-04 11:31:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 11:32:01 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.214 | trans_loss 5.575 | nll_loss 2.849 | w2v_ctc_loss 1.374 | task_loss 4.614 | contrastive_loss 0.248 | total 4003.4 | n_correct 2486.4 | ppl 7.21 | accuracy 62.107 | uer 16.672 | wer 18.474 | raw_wer 18.474 | bleu 20.19 | wps 2110.4 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 20.46
2023-08-04 11:32:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-08-04 11:32:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1908.pt
2023-08-04 11:32:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1908.pt
2023-08-04 11:32:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint.best_bleu_20.1908.pt (epoch 33 @ 48621 updates, score 20.19) (writing took 13.681596485897899 seconds)
2023-08-04 11:32:15 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-04 11:32:15 | INFO | train | epoch 033 | loss 1.95 | trans_loss 4.927 | nll_loss 2.1 | w2v_ctc_loss 0.598 | task_loss 1.401 | contrastive_loss 0.1 | total 4137.28 | n_correct 2742.5 | ppl 4.29 | accuracy 66.287 | wps 11037.4 | ups 1.33 | wpb 8274.6 | bsz 305.2 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.58 | clip 0 | loss_scale 16 | train_wall 994 | gb_free 17.8 | wall 38762
2023-08-04 11:32:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-04 11:32:16 | INFO | fairseq.trainer | begin training epoch 34
2023-08-04 11:32:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-04 11:33:17 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.94, trans_loss=4.91, nll_loss=2.077, w2v_ctc_loss=0.596, task_loss=1.384, contrastive_loss=0.061, total=4131.47, n_correct=2751.93, ppl=4.22, accuracy=66.609, wps=7240.7, ups=0.88, wpb=8262.9, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.591, clip=0, loss_scale=16, train_wall=67, gb_free=16.6, wall=38824
2023-08-04 11:34:25 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.935, trans_loss=4.902, nll_loss=2.067, w2v_ctc_loss=0.59, task_loss=1.463, contrastive_loss=0.062, total=4065.88, n_correct=2717.39, ppl=4.19, accuracy=66.834, wps=12012.4, ups=1.48, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.585, clip=0, loss_scale=16, train_wall=67, gb_free=16, wall=38892
2023-08-04 11:35:33 | INFO | train_inner | epoch 034:    279 / 1474 loss=1.957, trans_loss=4.922, nll_loss=2.095, w2v_ctc_loss=0.59, task_loss=1.309, contrastive_loss=0.276, total=4246.3, n_correct=2816.57, ppl=4.27, accuracy=66.33, wps=12448.2, ups=1.47, wpb=8492.6, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.576, clip=0, loss_scale=16, train_wall=68, gb_free=17.8, wall=38960
2023-08-04 11:36:41 | INFO | train_inner | epoch 034:    379 / 1474 loss=1.94, trans_loss=4.906, nll_loss=2.073, w2v_ctc_loss=0.586, task_loss=1.329, contrastive_loss=0.163, total=4156.17, n_correct=2774.7, ppl=4.21, accuracy=66.761, wps=12245.4, ups=1.47, wpb=8312.3, bsz=316.7, num_updates=49000, lr=6.38877e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=67, gb_free=17.7, wall=39028
2023-08-04 11:37:49 | INFO | train_inner | epoch 034:    479 / 1474 loss=1.95, trans_loss=4.924, nll_loss=2.094, w2v_ctc_loss=0.605, task_loss=1.538, contrastive_loss=0.054, total=4070.55, n_correct=2701.18, ppl=4.27, accuracy=66.359, wps=12017.3, ups=1.48, wpb=8141.1, bsz=284.6, num_updates=49100, lr=6.38226e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=67, gb_free=17.4, wall=39096
2023-08-04 11:38:56 | INFO | train_inner | epoch 034:    579 / 1474 loss=1.939, trans_loss=4.911, nll_loss=2.079, w2v_ctc_loss=0.592, task_loss=1.42, contrastive_loss=0.057, total=4119.38, n_correct=2747.84, ppl=4.22, accuracy=66.705, wps=12275, ups=1.49, wpb=8238.8, bsz=300.3, num_updates=49200, lr=6.37577e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=67, gb_free=13, wall=39163
2023-08-04 11:40:03 | INFO | train_inner | epoch 034:    679 / 1474 loss=1.938, trans_loss=4.916, nll_loss=2.086, w2v_ctc_loss=0.59, task_loss=1.417, contrastive_loss=0.05, total=4124.83, n_correct=2748.03, ppl=4.24, accuracy=66.622, wps=12267.2, ups=1.49, wpb=8249.7, bsz=300.2, num_updates=49300, lr=6.3693e-05, gnorm=0.578, clip=0, loss_scale=16, train_wall=67, gb_free=14.2, wall=39230
2023-08-04 11:41:11 | INFO | train_inner | epoch 034:    779 / 1474 loss=1.951, trans_loss=4.936, nll_loss=2.111, w2v_ctc_loss=0.587, task_loss=1.471, contrastive_loss=0.122, total=4082.07, n_correct=2703.04, ppl=4.32, accuracy=66.217, wps=12036, ups=1.47, wpb=8164.1, bsz=295, num_updates=49400, lr=6.36285e-05, gnorm=0.586, clip=0, loss_scale=16, train_wall=67, gb_free=15.5, wall=39298
2023-08-04 11:42:19 | INFO | train_inner | epoch 034:    879 / 1474 loss=1.949, trans_loss=4.929, nll_loss=2.102, w2v_ctc_loss=0.597, task_loss=1.478, contrastive_loss=0.082, total=4100.9, n_correct=2718.81, ppl=4.29, accuracy=66.298, wps=12079.5, ups=1.47, wpb=8201.8, bsz=296.6, num_updates=49500, lr=6.35642e-05, gnorm=0.592, clip=0, loss_scale=16, train_wall=67, gb_free=12.1, wall=39366
2023-08-04 11:43:27 | INFO | train_inner | epoch 034:    979 / 1474 loss=1.949, trans_loss=4.927, nll_loss=2.1, w2v_ctc_loss=0.604, task_loss=1.376, contrastive_loss=0.078, total=4168.39, n_correct=2766.05, ppl=4.29, accuracy=66.358, wps=12301.6, ups=1.48, wpb=8336.8, bsz=311.9, num_updates=49600, lr=6.35001e-05, gnorm=0.582, clip=0, loss_scale=16, train_wall=67, gb_free=15.8, wall=39434
2023-08-04 11:44:34 | INFO | train_inner | epoch 034:   1079 / 1474 loss=1.949, trans_loss=4.931, nll_loss=2.106, w2v_ctc_loss=0.604, task_loss=1.359, contrastive_loss=0.058, total=4150.57, n_correct=2751.2, ppl=4.3, accuracy=66.285, wps=12365.6, ups=1.49, wpb=8301.1, bsz=308.5, num_updates=49700, lr=6.34361e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=67, gb_free=16.8, wall=39501
2023-08-04 11:45:41 | INFO | train_inner | epoch 034:   1179 / 1474 loss=1.948, trans_loss=4.93, nll_loss=2.104, w2v_ctc_loss=0.596, task_loss=1.446, contrastive_loss=0.069, total=4098.77, n_correct=2717.31, ppl=4.3, accuracy=66.296, wps=12119.5, ups=1.48, wpb=8197.5, bsz=297.1, num_updates=49800, lr=6.33724e-05, gnorm=0.581, clip=0, loss_scale=16, train_wall=67, gb_free=16.9, wall=39569
2023-08-04 11:46:49 | INFO | train_inner | epoch 034:   1279 / 1474 loss=1.945, trans_loss=4.927, nll_loss=2.1, w2v_ctc_loss=0.595, task_loss=1.409, contrastive_loss=0.054, total=4150.54, n_correct=2753.81, ppl=4.29, accuracy=66.348, wps=12270.8, ups=1.48, wpb=8301.1, bsz=301, num_updates=49900, lr=6.33089e-05, gnorm=0.577, clip=0, loss_scale=16, train_wall=67, gb_free=17.1, wall=39636
2023-08-04 11:47:57 | INFO | train_inner | epoch 034:   1379 / 1474 loss=1.955, trans_loss=4.934, nll_loss=2.11, w2v_ctc_loss=0.605, task_loss=1.341, contrastive_loss=0.121, total=4196.91, n_correct=2775.45, ppl=4.32, accuracy=66.131, wps=12381.5, ups=1.48, wpb=8393.8, bsz=321.4, num_updates=50000, lr=6.32456e-05, gnorm=0.574, clip=0, loss_scale=16, train_wall=67, gb_free=16, wall=39704
2023-08-04 11:47:57 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-04 11:47:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-04 11:48:21 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.2 | trans_loss 5.57 | nll_loss 2.843 | w2v_ctc_loss 1.339 | task_loss 4.624 | contrastive_loss 0.25 | total 4003.4 | n_correct 2493.3 | ppl 7.18 | accuracy 62.28 | uer 16.609 | wer 18.445 | raw_wer 18.445 | bleu 19.98 | wps 2087.1 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.46
2023-08-04 11:48:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-04 11:48:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_34_50000.pt
2023-08-04 11:48:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_34_50000.pt
2023-08-04 11:48:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_0803_at_sentence/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 19.98) (writing took 15.855605602264404 seconds)
2023-08-04 11:48:37 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-04 11:48:37 | INFO | train | epoch 034 | loss 1.946 | trans_loss 4.922 | nll_loss 2.093 | w2v_ctc_loss 0.595 | task_loss 1.409 | contrastive_loss 0.096 | total 4133.04 | n_correct 2746.05 | ppl 4.27 | accuracy 66.441 | wps 11610.4 | ups 1.4 | wpb 8266.1 | bsz 304.2 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.581 | clip 0 | loss_scale 16 | train_wall 927 | gb_free 16 | wall 39744
2023-08-04 11:48:37 | INFO | fairseq_cli.train | done training in 39693.1 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
