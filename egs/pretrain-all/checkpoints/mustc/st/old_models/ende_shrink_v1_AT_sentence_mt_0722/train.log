2023-07-22 13:35:34 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13748
2023-07-22 13:35:34 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:13748
2023-07-22 13:35:34 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13748
2023-07-22 13:35:35 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13748
2023-07-22 13:35:35 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:13748
2023-07-22 13:35:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-22 13:35:35 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:13748
2023-07-22 13:35:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-22 13:35:35 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:13748
2023-07-22 13:35:35 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13748
2023-07-22 13:35:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-22 13:35:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-22 13:35:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-22 13:35:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-22 13:35:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-22 13:35:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-22 13:35:36 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 13:35:36 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-07-22 13:35:36 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 13:35:36 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 13:35:36 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 13:35:36 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-07-22 13:35:36 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-07-22 13:35:36 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-07-22 13:35:36 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 13:35:36 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-07-22 13:35:36 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 13:35:36 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 13:35:36 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 13:35:36 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-07-22 13:35:36 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-07-22 13:35:36 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-07-22 13:35:40 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13748', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-07-22 13:35:40 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-22 13:35:40 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-22 13:35:40 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-22 13:35:40 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-22 13:35:40 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-22 13:35:45 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-07-22 13:35:45 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-22 13:35:45 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-22 13:35:46 | INFO | root | load pretrained hubert
2023-07-22 13:35:50 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-22 13:35:51 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-22 13:35:54 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-22 13:35:54 | INFO | root | share the sematic adapter and textual encoder
2023-07-22 13:35:54 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-22 13:35:54 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-22 13:35:54 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-22 13:35:54 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-22 13:35:54 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-22 13:35:54 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-22 13:35:54 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-22 13:35:54 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 13:35:54 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 13:35:54 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 13:35:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-22 13:35:58 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-22 13:35:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-22 13:35:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-22 13:35:59 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 13:35:59 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 13:35:59 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 13:35:59 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 13:35:59 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 13:35:59 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 13:35:59 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 13:35:59 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 13:35:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-22 13:35:59 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-22 13:35:59 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-22 13:35:59 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-22 13:35:59 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-22 13:35:59 | INFO | fairseq.trainer | loading train data for epoch 1
2023-07-22 13:35:59 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-22 13:35:59 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 13:35:59 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 13:36:00 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 13:36:02 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 13:36:04 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 13:37:16 | INFO | fairseq.optim.adam | using FusedAdam
2023-07-22 13:37:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 13:37:16 | INFO | fairseq.trainer | begin training epoch 1
2023-07-22 13:37:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 13:37:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-22 13:38:49 | INFO | train_inner | epoch 001:    101 / 1474 loss=20.769, trans_loss=5.64, nll_loss=4.216, w2v_ctc_loss=22.495, task_loss=1.755, contrastive_loss=3.31, total=4200.41, n_correct=212.07, ppl=18.58, accuracy=5.049, wps=16237.3, ups=1.29, wpb=12542.9, bsz=467.5, num_updates=100, lr=4.098e-06, gnorm=0.936, clip=0, loss_scale=64, train_wall=85, gb_free=19.1, wall=170
2023-07-22 13:40:06 | INFO | train_inner | epoch 001:    201 / 1474 loss=18.544, trans_loss=5.44, nll_loss=4.026, w2v_ctc_loss=19.352, task_loss=1.728, contrastive_loss=3.286, total=4127.38, n_correct=250.48, ppl=16.29, accuracy=6.069, wps=16024.1, ups=1.3, wpb=12327, bsz=463.1, num_updates=200, lr=8.096e-06, gnorm=3.623, clip=0, loss_scale=64, train_wall=76, gb_free=19.2, wall=247
2023-07-22 13:41:22 | INFO | train_inner | epoch 001:    301 / 1474 loss=11.616, trans_loss=5.404, nll_loss=4.04, w2v_ctc_loss=8.802, task_loss=1.807, contrastive_loss=3.202, total=4079.62, n_correct=250.18, ppl=16.45, accuracy=6.132, wps=15960.3, ups=1.31, wpb=12195.4, bsz=438.2, num_updates=300, lr=1.2094e-05, gnorm=4.659, clip=0, loss_scale=64, train_wall=76, gb_free=19.9, wall=323
2023-07-22 13:42:56 | INFO | train_inner | epoch 001:    401 / 1474 loss=10.383, trans_loss=5.453, nll_loss=4.121, w2v_ctc_loss=6.827, task_loss=1.559, contrastive_loss=3.236, total=4174.14, n_correct=233.11, ppl=17.4, accuracy=5.585, wps=13301.7, ups=1.07, wpb=12461.1, bsz=460.4, num_updates=400, lr=1.6092e-05, gnorm=3.012, clip=0, loss_scale=64, train_wall=93, gb_free=18.9, wall=417
2023-07-22 13:44:14 | INFO | train_inner | epoch 001:    501 / 1474 loss=9.938, trans_loss=5.451, nll_loss=4.126, w2v_ctc_loss=6.165, task_loss=1.417, contrastive_loss=3.23, total=4176.18, n_correct=218.07, ppl=17.47, accuracy=5.222, wps=16123.7, ups=1.29, wpb=12513, bsz=477.4, num_updates=500, lr=2.009e-05, gnorm=1.438, clip=0, loss_scale=64, train_wall=77, gb_free=19.2, wall=495
2023-07-22 13:45:31 | INFO | train_inner | epoch 001:    601 / 1474 loss=9.693, trans_loss=5.477, nll_loss=4.166, w2v_ctc_loss=5.812, task_loss=1.322, contrastive_loss=3.282, total=4147.79, n_correct=216.41, ppl=17.95, accuracy=5.217, wps=16107.7, ups=1.3, wpb=12368.1, bsz=484.2, num_updates=600, lr=2.4088e-05, gnorm=0.738, clip=0, loss_scale=64, train_wall=76, gb_free=19, wall=572
2023-07-22 13:46:47 | INFO | train_inner | epoch 001:    701 / 1474 loss=9.536, trans_loss=5.466, nll_loss=4.159, w2v_ctc_loss=5.702, task_loss=1.337, contrastive_loss=3.031, total=4152.1, n_correct=231.61, ppl=17.86, accuracy=5.578, wps=16251.1, ups=1.31, wpb=12373.8, bsz=456.2, num_updates=700, lr=2.8086e-05, gnorm=0.607, clip=0, loss_scale=64, train_wall=76, gb_free=19.5, wall=648
2023-07-22 13:48:03 | INFO | train_inner | epoch 001:    801 / 1474 loss=9.262, trans_loss=5.422, nll_loss=4.107, w2v_ctc_loss=5.47, task_loss=1.274, contrastive_loss=2.931, total=4123.83, n_correct=255.29, ppl=17.23, accuracy=6.191, wps=16119.3, ups=1.31, wpb=12311.9, bsz=464.1, num_updates=800, lr=3.2084e-05, gnorm=0.848, clip=0, loss_scale=64, train_wall=76, gb_free=19.2, wall=724
2023-07-22 13:49:20 | INFO | train_inner | epoch 001:    901 / 1474 loss=9.014, trans_loss=5.404, nll_loss=4.101, w2v_ctc_loss=5.303, task_loss=1.287, contrastive_loss=2.678, total=4163.61, n_correct=278.03, ppl=17.16, accuracy=6.678, wps=16170.5, ups=1.3, wpb=12409.7, bsz=457.1, num_updates=900, lr=3.6082e-05, gnorm=1.229, clip=0, loss_scale=64, train_wall=76, gb_free=18.9, wall=801
2023-07-22 13:50:37 | INFO | train_inner | epoch 001:   1001 / 1474 loss=8.755, trans_loss=5.389, nll_loss=4.085, w2v_ctc_loss=5.074, task_loss=1.292, contrastive_loss=2.537, total=4135.34, n_correct=297.88, ppl=16.97, accuracy=7.203, wps=16086.2, ups=1.3, wpb=12363.9, bsz=456.8, num_updates=1000, lr=4.008e-05, gnorm=1.486, clip=0, loss_scale=64, train_wall=76, gb_free=19, wall=878
2023-07-22 13:51:53 | INFO | train_inner | epoch 001:   1101 / 1474 loss=8.501, trans_loss=5.381, nll_loss=4.079, w2v_ctc_loss=4.885, task_loss=1.302, contrastive_loss=2.319, total=4147.38, n_correct=314.82, ppl=16.9, accuracy=7.591, wps=16102.2, ups=1.3, wpb=12356.9, bsz=454.9, num_updates=1100, lr=4.4078e-05, gnorm=1.727, clip=0, loss_scale=64, train_wall=76, gb_free=18.9, wall=954
2023-07-22 13:53:10 | INFO | train_inner | epoch 001:   1201 / 1474 loss=8.263, trans_loss=5.361, nll_loss=4.058, w2v_ctc_loss=4.701, task_loss=1.357, contrastive_loss=2.106, total=4139.9, n_correct=326.16, ppl=16.66, accuracy=7.878, wps=16254.1, ups=1.31, wpb=12386.7, bsz=440.1, num_updates=1200, lr=4.8076e-05, gnorm=1.686, clip=0, loss_scale=64, train_wall=76, gb_free=19, wall=1031
2023-07-22 13:54:25 | INFO | train_inner | epoch 001:   1301 / 1474 loss=8.052, trans_loss=5.362, nll_loss=4.063, w2v_ctc_loss=4.511, task_loss=1.308, contrastive_loss=1.927, total=4046.58, n_correct=320.45, ppl=16.71, accuracy=7.919, wps=15976.4, ups=1.32, wpb=12092.5, bsz=439.3, num_updates=1300, lr=5.2074e-05, gnorm=1.734, clip=0, loss_scale=64, train_wall=75, gb_free=19.7, wall=1106
2023-07-22 13:55:42 | INFO | train_inner | epoch 001:   1401 / 1474 loss=7.877, trans_loss=5.359, nll_loss=4.072, w2v_ctc_loss=4.334, task_loss=1.288, contrastive_loss=2.011, total=4133.18, n_correct=329.08, ppl=16.81, accuracy=7.962, wps=16129.9, ups=1.31, wpb=12300.7, bsz=455, num_updates=1400, lr=5.6072e-05, gnorm=1.885, clip=0, loss_scale=64, train_wall=76, gb_free=19.9, wall=1183
2023-07-22 13:56:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 13:57:17 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 9.588 | trans_loss 10.963 | nll_loss 9.955 | w2v_ctc_loss 5.604 | task_loss 7.545 | contrastive_loss 2.336 | total 4003.4 | n_correct 376.5 | ppl 992.88 | accuracy 9.405 | uer 71.489 | wer 69.472 | raw_wer 69.472 | bleu 0.03 | wps 1137.8 | wpb 4003.4 | bsz 141.8 | num_updates 1473
2023-07-22 13:57:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1473 updates
2023-07-22 13:57:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 13:57:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 13:57:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 1 @ 1473 updates, score 0.03) (writing took 5.420503405854106 seconds)
2023-07-22 13:57:23 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-07-22 13:57:23 | INFO | train | epoch 001 | loss 10.591 | trans_loss 5.426 | nll_loss 4.099 | w2v_ctc_loss 7.652 | task_loss 1.422 | contrastive_loss 2.751 | total 4138.32 | n_correct 270.263 | ppl 17.14 | accuracy 6.531 | wps 15280.8 | ups 1.24 | wpb 12354.6 | bsz 458.3 | num_updates 1473 | lr 5.89905e-05 | gnorm 1.815 | clip 0 | loss_scale 64 | train_wall 1146 | gb_free 19.2 | wall 1284
2023-07-22 13:57:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 13:57:23 | INFO | fairseq.trainer | begin training epoch 2
2023-07-22 13:57:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 13:57:53 | INFO | train_inner | epoch 002:     27 / 1474 loss=7.672, trans_loss=5.354, nll_loss=4.055, w2v_ctc_loss=4.127, task_loss=1.228, contrastive_loss=1.843, total=4162.95, n_correct=339.93, ppl=16.62, accuracy=8.166, wps=9454.7, ups=0.76, wpb=12414, bsz=470.8, num_updates=1500, lr=6.007e-05, gnorm=1.59, clip=0, loss_scale=64, train_wall=76, gb_free=19.7, wall=1314
2023-07-22 13:59:10 | INFO | train_inner | epoch 002:    127 / 1474 loss=7.515, trans_loss=5.354, nll_loss=4.055, w2v_ctc_loss=4.008, task_loss=1.313, contrastive_loss=1.642, total=4155.98, n_correct=339.51, ppl=16.62, accuracy=8.169, wps=16190.8, ups=1.31, wpb=12390, bsz=451.6, num_updates=1600, lr=6.4068e-05, gnorm=1.621, clip=0, loss_scale=64, train_wall=76, gb_free=18.9, wall=1391
2023-07-22 14:00:26 | INFO | train_inner | epoch 002:    227 / 1474 loss=7.336, trans_loss=5.326, nll_loss=4.024, w2v_ctc_loss=3.807, task_loss=1.137, contrastive_loss=1.672, total=4179.21, n_correct=350.36, ppl=16.26, accuracy=8.383, wps=16394.1, ups=1.31, wpb=12488.1, bsz=488.9, num_updates=1700, lr=6.8066e-05, gnorm=1.498, clip=0, loss_scale=64, train_wall=76, gb_free=19, wall=1467
2023-07-22 14:01:42 | INFO | train_inner | epoch 002:    327 / 1474 loss=7.181, trans_loss=5.328, nll_loss=4.022, w2v_ctc_loss=3.711, task_loss=1.307, contrastive_loss=1.382, total=4146.1, n_correct=350.88, ppl=16.25, accuracy=8.463, wps=16197.5, ups=1.31, wpb=12381, bsz=447.8, num_updates=1800, lr=7.2064e-05, gnorm=1.41, clip=0, loss_scale=64, train_wall=76, gb_free=18.8, wall=1543
2023-07-22 14:02:58 | INFO | train_inner | epoch 002:    427 / 1474 loss=7.044, trans_loss=5.317, nll_loss=4.013, w2v_ctc_loss=3.616, task_loss=1.435, contrastive_loss=1.204, total=4037.99, n_correct=343.55, ppl=16.14, accuracy=8.508, wps=15907.5, ups=1.32, wpb=12079.4, bsz=415.4, num_updates=1900, lr=7.6062e-05, gnorm=1.429, clip=0, loss_scale=64, train_wall=75, gb_free=19, wall=1619
2023-07-22 14:04:14 | INFO | train_inner | epoch 002:    527 / 1474 loss=6.945, trans_loss=5.313, nll_loss=4.003, w2v_ctc_loss=3.457, task_loss=1.247, contrastive_loss=1.309, total=4176.97, n_correct=362.35, ppl=16.04, accuracy=8.675, wps=16331.2, ups=1.31, wpb=12475.1, bsz=468.6, num_updates=2000, lr=8.006e-05, gnorm=1.381, clip=0, loss_scale=64, train_wall=76, gb_free=19.6, wall=1695
2023-07-22 14:04:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 14:04:55 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.999 | trans_loss 10.818 | nll_loss 9.768 | w2v_ctc_loss 4.521 | task_loss 7.545 | contrastive_loss 1.651 | total 4003.4 | n_correct 398.7 | ppl 871.98 | accuracy 9.959 | uer 61.739 | wer 59.36 | raw_wer 59.36 | bleu 0.04 | wps 1132.8 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0.04
2023-07-22 14:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-07-22 14:04:55 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_2_2000.pt
2023-07-22 14:04:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_2_2000.pt
2023-07-22 14:05:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.04) (writing took 19.290805449709296 seconds)
2023-07-22 14:06:31 | INFO | train_inner | epoch 002:    627 / 1474 loss=6.812, trans_loss=5.306, nll_loss=3.999, w2v_ctc_loss=3.357, task_loss=1.292, contrastive_loss=1.096, total=4126.49, n_correct=361, ppl=15.99, accuracy=8.748, wps=9027.9, ups=0.73, wpb=12299.1, bsz=445.5, num_updates=2100, lr=8.4058e-05, gnorm=1.153, clip=0, loss_scale=128, train_wall=76, gb_free=19.2, wall=1832
2023-07-22 14:07:48 | INFO | train_inner | epoch 002:    727 / 1474 loss=6.736, trans_loss=5.289, nll_loss=3.981, w2v_ctc_loss=3.266, task_loss=1.264, contrastive_loss=1.203, total=4149.06, n_correct=369.98, ppl=15.8, accuracy=8.917, wps=16003.3, ups=1.29, wpb=12372.9, bsz=465.4, num_updates=2200, lr=8.8056e-05, gnorm=1.167, clip=0, loss_scale=128, train_wall=77, gb_free=19.2, wall=1909
2023-07-22 14:09:05 | INFO | train_inner | epoch 002:    827 / 1474 loss=6.65, trans_loss=5.272, nll_loss=3.959, w2v_ctc_loss=3.197, task_loss=1.298, contrastive_loss=1.148, total=4175.4, n_correct=380.42, ppl=15.55, accuracy=9.111, wps=16120.1, ups=1.29, wpb=12477.6, bsz=460.9, num_updates=2300, lr=9.2054e-05, gnorm=1.017, clip=0, loss_scale=128, train_wall=77, gb_free=19.8, wall=1986
2023-07-22 14:10:22 | INFO | train_inner | epoch 002:    927 / 1474 loss=6.551, trans_loss=5.26, nll_loss=3.945, w2v_ctc_loss=3.1, task_loss=1.324, contrastive_loss=1.129, total=4104.2, n_correct=374.69, ppl=15.4, accuracy=9.129, wps=15994.1, ups=1.31, wpb=12243.8, bsz=445.9, num_updates=2400, lr=9.6052e-05, gnorm=1.006, clip=0, loss_scale=128, train_wall=76, gb_free=19, wall=2063
2023-07-22 14:11:38 | INFO | train_inner | epoch 002:   1027 / 1474 loss=6.47, trans_loss=5.257, nll_loss=3.94, w2v_ctc_loss=3.022, task_loss=1.287, contrastive_loss=0.986, total=4102.5, n_correct=377.83, ppl=15.34, accuracy=9.21, wps=16065.2, ups=1.31, wpb=12270.3, bsz=456.3, num_updates=2500, lr=0.00010005, gnorm=0.918, clip=0, loss_scale=128, train_wall=76, gb_free=19.3, wall=2139
2023-07-22 14:12:55 | INFO | train_inner | epoch 002:   1127 / 1474 loss=6.428, trans_loss=5.247, nll_loss=3.927, w2v_ctc_loss=2.942, task_loss=1.169, contrastive_loss=1.198, total=4187.61, n_correct=395.29, ppl=15.22, accuracy=9.44, wps=16228.5, ups=1.3, wpb=12484.3, bsz=487.1, num_updates=2600, lr=0.000104048, gnorm=0.838, clip=0, loss_scale=128, train_wall=76, gb_free=19.5, wall=2216
2023-07-22 14:14:12 | INFO | train_inner | epoch 002:   1227 / 1474 loss=6.374, trans_loss=5.24, nll_loss=3.919, w2v_ctc_loss=2.898, task_loss=1.178, contrastive_loss=1.119, total=4221.06, n_correct=406.24, ppl=15.12, accuracy=9.624, wps=16360.9, ups=1.3, wpb=12590.1, bsz=492.8, num_updates=2700, lr=0.000108046, gnorm=0.825, clip=0, loss_scale=128, train_wall=76, gb_free=19.5, wall=2293
2023-07-22 14:15:29 | INFO | train_inner | epoch 002:   1327 / 1474 loss=6.279, trans_loss=5.226, nll_loss=3.906, w2v_ctc_loss=2.859, task_loss=1.241, contrastive_loss=0.834, total=4157.86, n_correct=405.95, ppl=14.99, accuracy=9.763, wps=16210, ups=1.3, wpb=12422.5, bsz=460.7, num_updates=2800, lr=0.000112044, gnorm=0.788, clip=0, loss_scale=128, train_wall=76, gb_free=19.5, wall=2370
2023-07-22 14:16:46 | INFO | train_inner | epoch 002:   1427 / 1474 loss=6.242, trans_loss=5.223, nll_loss=3.898, w2v_ctc_loss=2.813, task_loss=1.394, contrastive_loss=0.92, total=4054.34, n_correct=395.65, ppl=14.91, accuracy=9.759, wps=15819, ups=1.3, wpb=12128.6, bsz=438.8, num_updates=2900, lr=0.000116042, gnorm=0.745, clip=0, loss_scale=128, train_wall=76, gb_free=19.4, wall=2447
2023-07-22 14:17:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 14:18:01 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 8.199 | trans_loss 10.276 | nll_loss 9.083 | w2v_ctc_loss 3.594 | task_loss 7.545 | contrastive_loss 0.985 | total 4003.4 | n_correct 504.9 | ppl 542.48 | accuracy 12.612 | uer 51.371 | wer 50.434 | raw_wer 50.434 | bleu 0.13 | wps 1144.9 | wpb 4003.4 | bsz 141.8 | num_updates 2947 | best_bleu 0.13
2023-07-22 14:18:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2947 updates
2023-07-22 14:18:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 14:18:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 14:18:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 2 @ 2947 updates, score 0.13) (writing took 20.196663675829768 seconds)
2023-07-22 14:18:22 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-07-22 14:18:22 | INFO | train | epoch 002 | loss 6.753 | trans_loss 5.282 | nll_loss 3.97 | w2v_ctc_loss 3.288 | task_loss 1.274 | contrastive_loss 1.205 | total 4138.65 | n_correct 372.712 | ppl 15.67 | accuracy 9.006 | wps 14467.8 | ups 1.17 | wpb 12355.8 | bsz 458.5 | num_updates 2947 | lr 0.000117921 | gnorm 1.126 | clip 0 | loss_scale 128 | train_wall 1121 | gb_free 19.3 | wall 2543
2023-07-22 14:18:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 14:18:22 | INFO | fairseq.trainer | begin training epoch 3
2023-07-22 14:18:22 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 217 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-22 14:19:25 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11582
2023-07-22 14:19:25 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11582
2023-07-22 14:19:25 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11582
2023-07-22 14:19:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-22 14:19:25 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11582
2023-07-22 14:19:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-22 14:19:25 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11582
2023-07-22 14:19:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-22 14:19:25 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11582
2023-07-22 14:19:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-22 14:19:25 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11582
2023-07-22 14:19:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-22 14:19:25 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11582
2023-07-22 14:19:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-22 14:19:26 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-22 14:19:26 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-22 14:19:26 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:19:26 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:19:26 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:19:26 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-07-22 14:19:26 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-07-22 14:19:26 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-07-22 14:19:26 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:19:26 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-07-22 14:19:26 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:19:26 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-07-22 14:19:26 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:19:26 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:19:26 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:19:26 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-07-22 14:19:26 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-07-22 14:19:26 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-07-22 14:19:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11582', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-07-22 14:19:30 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-22 14:19:30 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-22 14:19:30 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-22 14:19:30 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-22 14:19:30 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-22 14:19:35 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-07-22 14:19:35 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-22 14:19:35 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-22 14:19:37 | INFO | root | load pretrained hubert
2023-07-22 14:19:39 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-22 14:19:40 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-22 14:19:42 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-22 14:19:42 | INFO | root | share the sematic adapter and textual encoder
2023-07-22 14:19:42 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-22 14:19:42 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-22 14:19:42 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-22 14:19:42 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-22 14:19:42 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-22 14:19:42 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-22 14:19:42 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-22 14:19:42 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 14:19:42 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 14:19:42 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 14:19:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-22 14:19:43 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-22 14:19:43 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-22 14:19:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-22 14:19:44 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:19:44 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:19:44 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:19:44 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:19:44 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:19:44 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:19:44 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:19:44 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:19:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-22 14:19:44 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-22 14:19:44 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-22 14:19:44 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-22 14:19:46 | INFO | fairseq.trainer | load the task parameters
asr_weight 1.0
mt_weight 1.0
2023-07-22 14:19:47 | INFO | fairseq.optim.adam | using FusedAdam
2023-07-22 14:19:47 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 3 @ 2947 updates)
2023-07-22 14:19:47 | INFO | fairseq.trainer | loading train data for epoch 3
2023-07-22 14:19:47 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-22 14:19:47 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 14:19:47 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 14:19:52 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 14:19:56 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 14:19:58 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 14:21:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 14:21:10 | INFO | fairseq.trainer | begin training epoch 3
2023-07-22 14:21:10 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
2023-07-22 14:22:09 | INFO | train_inner | epoch 003:     53 / 1474 loss=6.143, trans_loss=5.189, nll_loss=3.854, w2v_ctc_loss=2.729, task_loss=1.282, contrastive_loss=0.907, total=4141.94, n_correct=422.642, ppl=14.46, accuracy=10.204, wps=15980.6, ups=1.29, wpb=12378.2, bsz=461.7, num_updates=3000, lr=0.00012004, gnorm=0.724, clip=0, loss_scale=128, train_wall=50, gb_free=19.1, wall=146
2023-07-22 14:22:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-22 14:22:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-22 14:22:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-22 14:22:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-22 14:22:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-22 14:23:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-07-22 14:24:01 | INFO | train_inner | epoch 003:    159 / 1474 loss=5.385, trans_loss=4.353, nll_loss=2.762, w2v_ctc_loss=2.46, task_loss=0.874, contrastive_loss=0.769, total=4154.84, n_correct=1163.76, ppl=6.78, accuracy=28.01, wps=11172, ups=0.9, wpb=12411.5, bsz=462.6, num_updates=3100, lr=0.000124038, gnorm=2.249, clip=1, loss_scale=2, train_wall=111, gb_free=16.7, wall=257
2023-07-22 14:25:48 | INFO | train_inner | epoch 003:    259 / 1474 loss=4.982, trans_loss=4.134, nll_loss=2.475, w2v_ctc_loss=2.21, task_loss=0.902, contrastive_loss=0.641, total=4155.72, n_correct=1427.38, ppl=5.56, accuracy=34.347, wps=11579.9, ups=0.93, wpb=12432.8, bsz=465.5, num_updates=3200, lr=0.000128036, gnorm=1.481, clip=0, loss_scale=2, train_wall=107, gb_free=17.8, wall=364
2023-07-22 14:27:33 | INFO | train_inner | epoch 003:    359 / 1474 loss=4.871, trans_loss=4.086, nll_loss=2.412, w2v_ctc_loss=2.112, task_loss=0.895, contrastive_loss=0.676, total=4154.07, n_correct=1508.95, ppl=5.32, accuracy=36.325, wps=11752.5, ups=0.95, wpb=12380.5, bsz=464.9, num_updates=3300, lr=0.000132034, gnorm=1.458, clip=0, loss_scale=2, train_wall=105, gb_free=16.5, wall=470
2023-07-22 14:29:19 | INFO | train_inner | epoch 003:    459 / 1474 loss=4.753, trans_loss=4.032, nll_loss=2.343, w2v_ctc_loss=2.043, task_loss=0.877, contrastive_loss=0.527, total=4212.17, n_correct=1610.01, ppl=5.07, accuracy=38.223, wps=11848.2, ups=0.94, wpb=12542, bsz=473.8, num_updates=3400, lr=0.000136032, gnorm=1.374, clip=0, loss_scale=2, train_wall=105, gb_free=16, wall=575
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 131 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-22 14:34:14 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:11851
2023-07-22 14:34:14 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:11851
2023-07-22 14:34:14 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:11851
2023-07-22 14:34:14 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:11851
2023-07-22 14:34:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-22 14:34:14 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:11851
2023-07-22 14:34:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-22 14:34:14 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:11851
2023-07-22 14:34:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-22 14:34:14 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:11851
2023-07-22 14:34:14 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:11851
2023-07-22 14:34:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-22 14:34:14 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-22 14:34:15 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-22 14:34:15 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-22 14:34:15 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-22 14:34:15 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:34:15 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-07-22 14:34:15 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:34:15 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:34:15 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-07-22 14:34:15 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-07-22 14:34:15 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:34:15 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-07-22 14:34:15 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:34:15 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:34:15 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:34:15 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 14:34:15 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-07-22 14:34:15 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-07-22 14:34:15 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-07-22 14:34:15 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-07-22 14:34:19 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11851', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-07-22 14:34:19 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-22 14:34:19 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-22 14:34:19 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-22 14:34:19 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-22 14:34:19 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-22 14:34:24 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-07-22 14:34:24 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-22 14:34:24 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-22 14:34:26 | INFO | root | load pretrained hubert
2023-07-22 14:34:28 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-22 14:34:29 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-22 14:34:31 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-22 14:34:31 | INFO | root | share the sematic adapter and textual encoder
2023-07-22 14:34:31 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-22 14:34:31 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-22 14:34:31 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-22 14:34:31 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-22 14:34:31 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-22 14:34:31 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-22 14:34:31 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-22 14:34:31 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 14:34:31 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 14:34:31 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 14:34:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-22 14:34:37 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-22 14:34:37 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-22 14:34:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-22 14:34:38 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:34:38 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:34:38 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:34:38 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:34:38 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:34:38 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:34:38 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:34:38 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 14:34:38 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-22 14:34:38 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-22 14:34:38 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-22 14:34:38 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-22 14:34:40 | INFO | fairseq.trainer | load the task parameters
asr_weight 1.0
mt_weight 1.0
2023-07-22 14:34:41 | INFO | fairseq.optim.adam | using FusedAdam
2023-07-22 14:34:41 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 3 @ 2947 updates)
2023-07-22 14:34:41 | INFO | fairseq.trainer | loading train data for epoch 3
2023-07-22 14:34:41 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-22 14:34:41 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 14:34:41 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 14:34:46 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 14:34:50 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 14:34:51 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 14:36:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 14:36:03 | INFO | fairseq.trainer | begin training epoch 3
2023-07-22 14:36:03 | INFO | fairseq_cli.train | Start iterating over samples
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
asr_weight 1.0
mt_weight 1.0
2023-07-22 14:37:06 | INFO | train_inner | epoch 003:     53 / 1474 loss=6.143, trans_loss=5.189, nll_loss=3.855, w2v_ctc_loss=2.729, task_loss=1.282, contrastive_loss=0.907, total=4141.94, n_correct=422.981, ppl=14.47, accuracy=10.212, wps=15924.1, ups=1.29, wpb=12378.2, bsz=461.7, num_updates=3000, lr=0.00012004, gnorm=0.724, clip=0, loss_scale=128, train_wall=53, gb_free=19.1, wall=149
2023-07-22 14:37:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-22 14:37:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-22 14:37:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-22 14:37:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-07-22 14:37:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-07-22 14:38:57 | INFO | train_inner | epoch 003:    158 / 1474 loss=5.423, trans_loss=4.467, nll_loss=2.914, w2v_ctc_loss=2.416, task_loss=0.885, contrastive_loss=0.745, total=4144.18, n_correct=1072.4, ppl=7.53, accuracy=25.877, wps=11142.3, ups=0.9, wpb=12381.7, bsz=458.6, num_updates=3100, lr=0.000124038, gnorm=1.752, clip=1, loss_scale=4, train_wall=111, gb_free=16.8, wall=260
2023-07-22 14:40:45 | INFO | train_inner | epoch 003:    258 / 1474 loss=4.971, trans_loss=4.186, nll_loss=2.542, w2v_ctc_loss=2.139, task_loss=0.898, contrastive_loss=0.638, total=4161.13, n_correct=1382.55, ppl=5.82, accuracy=33.225, wps=11519.5, ups=0.93, wpb=12444.3, bsz=467, num_updates=3200, lr=0.000128036, gnorm=1.161, clip=0, loss_scale=4, train_wall=107, gb_free=17.3, wall=368
2023-07-22 14:42:32 | INFO | train_inner | epoch 003:    358 / 1474 loss=4.827, trans_loss=4.1, nll_loss=2.429, w2v_ctc_loss=2.037, task_loss=0.902, contrastive_loss=0.657, total=4150.02, n_correct=1499.97, ppl=5.39, accuracy=36.144, wps=11589.5, ups=0.94, wpb=12369, bsz=461.6, num_updates=3300, lr=0.000132034, gnorm=1.147, clip=0, loss_scale=4, train_wall=106, gb_free=17.3, wall=474
2023-07-22 14:44:19 | INFO | train_inner | epoch 003:    458 / 1474 loss=4.683, trans_loss=4.024, nll_loss=2.331, w2v_ctc_loss=1.95, task_loss=0.873, contrastive_loss=0.514, total=4209.57, n_correct=1633.18, ppl=5.03, accuracy=38.797, wps=11709.9, ups=0.93, wpb=12537.6, bsz=476.8, num_updates=3400, lr=0.000136032, gnorm=1.05, clip=0, loss_scale=4, train_wall=107, gb_free=16.3, wall=581
2023-07-22 14:46:07 | INFO | train_inner | epoch 003:    558 / 1474 loss=4.574, trans_loss=3.983, nll_loss=2.271, w2v_ctc_loss=1.854, task_loss=0.963, contrastive_loss=0.472, total=4088.48, n_correct=1651.8, ppl=4.83, accuracy=40.401, wps=11390.2, ups=0.93, wpb=12237.1, bsz=439.7, num_updates=3500, lr=0.00014003, gnorm=0.997, clip=0, loss_scale=4, train_wall=107, gb_free=17.8, wall=689
2023-07-22 14:47:54 | INFO | train_inner | epoch 003:    658 / 1474 loss=4.523, trans_loss=3.94, nll_loss=2.218, w2v_ctc_loss=1.808, task_loss=0.862, contrastive_loss=0.586, total=4221.58, n_correct=1773.45, ppl=4.65, accuracy=42.009, wps=11656.2, ups=0.93, wpb=12558.6, bsz=481.9, num_updates=3600, lr=0.000144028, gnorm=0.968, clip=0, loss_scale=4, train_wall=107, gb_free=16.6, wall=797
2023-07-22 14:49:41 | INFO | train_inner | epoch 003:    758 / 1474 loss=4.439, trans_loss=3.905, nll_loss=2.172, w2v_ctc_loss=1.769, task_loss=0.86, contrastive_loss=0.353, total=4167.41, n_correct=1806.77, ppl=4.51, accuracy=43.355, wps=11655.7, ups=0.94, wpb=12462.8, bsz=472.6, num_updates=3700, lr=0.000148026, gnorm=0.967, clip=0, loss_scale=4, train_wall=106, gb_free=16.6, wall=904
2023-07-22 14:51:30 | INFO | train_inner | epoch 003:    858 / 1474 loss=4.385, trans_loss=3.889, nll_loss=2.149, w2v_ctc_loss=1.725, task_loss=0.912, contrastive_loss=0.311, total=4165.53, n_correct=1829.97, ppl=4.44, accuracy=43.931, wps=11501.5, ups=0.92, wpb=12445.3, bsz=456.1, num_updates=3800, lr=0.000152024, gnorm=0.927, clip=0, loss_scale=4, train_wall=108, gb_free=17.2, wall=1012
2023-07-22 14:53:16 | INFO | train_inner | epoch 003:    958 / 1474 loss=4.344, trans_loss=3.858, nll_loss=2.109, w2v_ctc_loss=1.695, task_loss=0.876, contrastive_loss=0.338, total=4162.3, n_correct=1880.26, ppl=4.32, accuracy=45.174, wps=11624, ups=0.94, wpb=12408.5, bsz=469.2, num_updates=3900, lr=0.000156022, gnorm=0.924, clip=0, loss_scale=4, train_wall=106, gb_free=17, wall=1119
2023-07-22 14:55:03 | INFO | train_inner | epoch 003:   1058 / 1474 loss=4.314, trans_loss=3.847, nll_loss=2.095, w2v_ctc_loss=1.677, task_loss=0.96, contrastive_loss=0.294, total=4069.95, n_correct=1861.37, ppl=4.27, accuracy=45.734, wps=11428.2, ups=0.94, wpb=12168.2, bsz=443.6, num_updates=4000, lr=0.00016002, gnorm=0.917, clip=0, loss_scale=4, train_wall=106, gb_free=16.5, wall=1225
2023-07-22 14:55:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 14:55:32 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.915 | trans_loss 6.307 | nll_loss 3.813 | w2v_ctc_loss 1.954 | task_loss 4.398 | contrastive_loss 0.421 | total 4003.4 | n_correct 2026.1 | ppl 14.05 | accuracy 50.609 | uer 29.087 | wer 30.066 | raw_wer 30.066 | bleu 12.43 | wps 1622.8 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 12.43
2023-07-22 14:55:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-07-22 14:55:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_3_4000.pt
2023-07-22 14:55:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_3_4000.pt
2023-07-22 14:55:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 12.43) (writing took 20.718663569539785 seconds)
2023-07-22 14:57:38 | INFO | train_inner | epoch 003:   1158 / 1474 loss=4.28, trans_loss=3.837, nll_loss=2.081, w2v_ctc_loss=1.641, task_loss=0.978, contrastive_loss=0.273, total=4038.49, n_correct=1865.37, ppl=4.23, accuracy=46.19, wps=7783.1, ups=0.65, wpb=12064, bsz=432.5, num_updates=4100, lr=0.000164018, gnorm=0.908, clip=0, loss_scale=4, train_wall=105, gb_free=16.6, wall=1380
2023-07-22 14:59:24 | INFO | train_inner | epoch 003:   1258 / 1474 loss=4.246, trans_loss=3.822, nll_loss=2.063, w2v_ctc_loss=1.613, task_loss=0.959, contrastive_loss=0.255, total=4064.31, n_correct=1907.62, ppl=4.18, accuracy=46.936, wps=11456.2, ups=0.94, wpb=12147.9, bsz=433.9, num_updates=4200, lr=0.000168016, gnorm=0.885, clip=0, loss_scale=4, train_wall=105, gb_free=17.5, wall=1486
2023-07-22 15:01:11 | INFO | train_inner | epoch 003:   1358 / 1474 loss=4.224, trans_loss=3.797, nll_loss=2.033, w2v_ctc_loss=1.586, task_loss=0.915, contrastive_loss=0.368, total=4134.58, n_correct=1969.18, ppl=4.09, accuracy=47.627, wps=11525.1, ups=0.93, wpb=12326.9, bsz=460.7, num_updates=4300, lr=0.000172014, gnorm=0.908, clip=0, loss_scale=4, train_wall=106, gb_free=17.9, wall=1593
2023-07-22 15:02:58 | INFO | train_inner | epoch 003:   1458 / 1474 loss=4.202, trans_loss=3.786, nll_loss=2.019, w2v_ctc_loss=1.567, task_loss=0.862, contrastive_loss=0.352, total=4209.94, n_correct=2029.97, ppl=4.05, accuracy=48.219, wps=11687.7, ups=0.93, wpb=12573.7, bsz=477.4, num_updates=4400, lr=0.000176012, gnorm=0.869, clip=0, loss_scale=4, train_wall=107, gb_free=17.2, wall=1701
2023-07-22 15:03:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 15:03:44 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 4.786 | trans_loss 6.195 | nll_loss 3.662 | w2v_ctc_loss 1.791 | task_loss 4.257 | contrastive_loss 0.408 | total 4003.4 | n_correct 2105.8 | ppl 12.66 | accuracy 52.6 | uer 28.216 | wer 28.802 | raw_wer 28.802 | bleu 13.89 | wps 1692 | wpb 4003.4 | bsz 141.8 | num_updates 4416 | best_bleu 13.89
2023-07-22 15:03:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4416 updates
2023-07-22 15:03:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 15:03:54 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 15:04:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 3 @ 4416 updates, score 13.89) (writing took 20.204135168343782 seconds)
2023-07-22 15:04:04 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-07-22 15:04:04 | INFO | train | epoch 003 | loss 4.586 | trans_loss 4.003 | nll_loss 2.301 | w2v_ctc_loss 1.85 | task_loss 0.92 | contrastive_loss 0.456 | total 4140.05 | n_correct 1681.03 | ppl 4.93 | accuracy 40.604 | wps 10942.3 | ups 0.89 | wpb 12360.2 | bsz 459 | num_updates 4416 | lr 0.000176652 | gnorm 1.014 | clip 0.1 | loss_scale 4 | train_wall 1565 | gb_free 16.9 | wall 1766
2023-07-22 15:04:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 15:04:04 | INFO | fairseq.trainer | begin training epoch 4
2023-07-22 15:04:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 15:05:42 | INFO | train_inner | epoch 004:     84 / 1474 loss=4.111, trans_loss=3.757, nll_loss=1.98, w2v_ctc_loss=1.512, task_loss=0.936, contrastive_loss=0.201, total=4099.41, n_correct=2010.26, ppl=3.94, accuracy=49.038, wps=7449, ups=0.61, wpb=12215.8, bsz=439.5, num_updates=4500, lr=0.00018001, gnorm=0.846, clip=0, loss_scale=4, train_wall=105, gb_free=16.6, wall=1865
2023-07-22 15:07:28 | INFO | train_inner | epoch 004:    184 / 1474 loss=4.095, trans_loss=3.741, nll_loss=1.957, w2v_ctc_loss=1.494, task_loss=0.864, contrastive_loss=0.228, total=4175.15, n_correct=2071.46, ppl=3.88, accuracy=49.614, wps=11803.9, ups=0.95, wpb=12466.1, bsz=468.3, num_updates=4600, lr=0.000184008, gnorm=0.851, clip=0, loss_scale=4, train_wall=105, gb_free=16.9, wall=1970
2023-07-22 15:09:15 | INFO | train_inner | epoch 004:    284 / 1474 loss=4.114, trans_loss=3.743, nll_loss=1.962, w2v_ctc_loss=1.493, task_loss=0.907, contrastive_loss=0.354, total=4145.23, n_correct=2059.26, ppl=3.9, accuracy=49.678, wps=11596.7, ups=0.94, wpb=12387.3, bsz=463, num_updates=4700, lr=0.000188006, gnorm=0.847, clip=0, loss_scale=4, train_wall=106, gb_free=16.2, wall=2077
2023-07-22 15:11:02 | INFO | train_inner | epoch 004:    384 / 1474 loss=4.083, trans_loss=3.741, nll_loss=1.957, w2v_ctc_loss=1.483, task_loss=0.943, contrastive_loss=0.199, total=4127.66, n_correct=2054.94, ppl=3.88, accuracy=49.785, wps=11475.1, ups=0.93, wpb=12298.8, bsz=443.5, num_updates=4800, lr=0.000192004, gnorm=0.839, clip=0, loss_scale=4, train_wall=107, gb_free=17.6, wall=2184
2023-07-22 15:12:49 | INFO | train_inner | epoch 004:    484 / 1474 loss=4.099, trans_loss=3.723, nll_loss=1.937, w2v_ctc_loss=1.444, task_loss=0.822, contrastive_loss=0.593, total=4218.78, n_correct=2132.3, ppl=3.83, accuracy=50.543, wps=11761.9, ups=0.94, wpb=12578.2, bsz=497.8, num_updates=4900, lr=0.000196002, gnorm=0.83, clip=0, loss_scale=4, train_wall=106, gb_free=16.7, wall=2291
2023-07-22 15:14:36 | INFO | train_inner | epoch 004:    584 / 1474 loss=4.063, trans_loss=3.717, nll_loss=1.929, w2v_ctc_loss=1.464, task_loss=0.858, contrastive_loss=0.273, total=4217.52, n_correct=2140.87, ppl=3.81, accuracy=50.761, wps=11765, ups=0.93, wpb=12583.6, bsz=485.9, num_updates=5000, lr=0.0002, gnorm=0.831, clip=0, loss_scale=4, train_wall=106, gb_free=16.3, wall=2398
mt_weight tensor(1., device='cuda:0')
asr_weight tensor(0.8203, device='cuda:0')
2023-07-22 15:16:24 | INFO | train_inner | epoch 004:    684 / 1474 loss=4.05, trans_loss=3.72, nll_loss=1.929, w2v_ctc_loss=1.438, task_loss=0.933, contrastive_loss=0.317, total=4176.39, n_correct=2131.07, ppl=3.81, accuracy=51.027, wps=11510.5, ups=0.93, wpb=12440.1, bsz=455.8, num_updates=5100, lr=0.00019803, gnorm=0.707, clip=0, loss_scale=8, train_wall=108, gb_free=17.3, wall=2506
2023-07-22 15:18:10 | INFO | train_inner | epoch 004:    784 / 1474 loss=4.038, trans_loss=3.715, nll_loss=1.923, w2v_ctc_loss=1.445, task_loss=1.005, contrastive_loss=0.192, total=4026.63, n_correct=2060.29, ppl=3.79, accuracy=51.167, wps=11362.5, ups=0.94, wpb=12049.9, bsz=420.6, num_updates=5200, lr=0.000196116, gnorm=0.726, clip=0, loss_scale=8, train_wall=106, gb_free=13.6, wall=2612
2023-07-22 15:19:57 | INFO | train_inner | epoch 004:    884 / 1474 loss=4.044, trans_loss=3.701, nll_loss=1.911, w2v_ctc_loss=1.433, task_loss=0.908, contrastive_loss=0.369, total=4186.04, n_correct=2153.53, ppl=3.76, accuracy=51.446, wps=11723.7, ups=0.94, wpb=12493.4, bsz=466.3, num_updates=5300, lr=0.000194257, gnorm=0.721, clip=0, loss_scale=8, train_wall=106, gb_free=17.8, wall=2719
2023-07-22 15:21:44 | INFO | train_inner | epoch 004:    984 / 1474 loss=4.001, trans_loss=3.692, nll_loss=1.899, w2v_ctc_loss=1.408, task_loss=0.92, contrastive_loss=0.232, total=4125.02, n_correct=2140.29, ppl=3.73, accuracy=51.886, wps=11441.3, ups=0.93, wpb=12319.9, bsz=457.1, num_updates=5400, lr=0.00019245, gnorm=0.709, clip=0, loss_scale=8, train_wall=107, gb_free=13.1, wall=2827
2023-07-22 15:23:31 | INFO | train_inner | epoch 004:   1084 / 1474 loss=4.007, trans_loss=3.702, nll_loss=1.909, w2v_ctc_loss=1.416, task_loss=0.981, contrastive_loss=0.208, total=4075.6, n_correct=2102.45, ppl=3.76, accuracy=51.586, wps=11369.5, ups=0.93, wpb=12166.1, bsz=435.7, num_updates=5500, lr=0.000190693, gnorm=0.7, clip=0, loss_scale=8, train_wall=106, gb_free=16.2, wall=2934
2023-07-22 15:25:17 | INFO | train_inner | epoch 004:   1184 / 1474 loss=4.013, trans_loss=3.693, nll_loss=1.899, w2v_ctc_loss=1.406, task_loss=0.856, contrastive_loss=0.32, total=4161.18, n_correct=2170.3, ppl=3.73, accuracy=52.156, wps=11734.6, ups=0.94, wpb=12451.8, bsz=483.4, num_updates=5600, lr=0.000188982, gnorm=0.7, clip=0, loss_scale=8, train_wall=105, gb_free=17, wall=3040
2023-07-22 15:27:04 | INFO | train_inner | epoch 004:   1284 / 1474 loss=3.989, trans_loss=3.686, nll_loss=1.889, w2v_ctc_loss=1.385, task_loss=0.869, contrastive_loss=0.283, total=4156.53, n_correct=2181.86, ppl=3.7, accuracy=52.492, wps=11681.3, ups=0.94, wpb=12424.6, bsz=472.7, num_updates=5700, lr=0.000187317, gnorm=0.707, clip=0, loss_scale=8, train_wall=106, gb_free=16.2, wall=3146
2023-07-22 15:28:50 | INFO | train_inner | epoch 004:   1384 / 1474 loss=3.968, trans_loss=3.682, nll_loss=1.885, w2v_ctc_loss=1.391, task_loss=0.937, contrastive_loss=0.162, total=4101.23, n_correct=2155.81, ppl=3.69, accuracy=52.565, wps=11593.1, ups=0.95, wpb=12255, bsz=437.6, num_updates=5800, lr=0.000185695, gnorm=0.683, clip=0, loss_scale=8, train_wall=105, gb_free=15.9, wall=3252
2023-07-22 15:30:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1., device='cuda:7')
asr_weight tensor(0.8203, device='cuda:7')
mt_weight tensor(1., device='cuda:4')
asr_weight tensor(0.8203, device='cuda:4')
mt_weight tensor(1., device='cuda:6')
asr_weight tensor(0.8203, device='cuda:6')
mt_weight tensor(1., device='cuda:2')
asr_weight tensor(0.8203, device='cuda:2')
mt_weight tensor(1., device='cuda:5')
asr_weight tensor(0.8203, device='cuda:5')
mt_weight tensor(1., device='cuda:3')
asr_weight tensor(0.8203, device='cuda:3')
mt_weight tensor(1., device='cuda:1')
asr_weight tensor(0.8203, device='cuda:1')
2023-07-22 15:30:49 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.499 | trans_loss 5.912 | nll_loss 3.287 | w2v_ctc_loss 1.524 | task_loss 4.486 | contrastive_loss 0.321 | total 4003.4 | n_correct 2265 | ppl 9.76 | accuracy 56.577 | uer 22.573 | wer 24.142 | raw_wer 24.142 | bleu 16.55 | wps 2008.1 | wpb 4003.4 | bsz 141.8 | num_updates 5890 | best_bleu 16.55
2023-07-22 15:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5890 updates
2023-07-22 15:30:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 15:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 15:31:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 4 @ 5890 updates, score 16.55) (writing took 19.920842392370105 seconds)
2023-07-22 15:31:09 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-07-22 15:31:09 | INFO | train | epoch 004 | loss 4.042 | trans_loss 3.712 | nll_loss 1.922 | w2v_ctc_loss 1.438 | task_loss 0.909 | contrastive_loss 0.28 | total 4138.65 | n_correct 2115.68 | ppl 3.79 | accuracy 51.12 | wps 11206.8 | ups 0.91 | wpb 12355.8 | bsz 458.5 | num_updates 5890 | lr 0.000184271 | gnorm 0.758 | clip 0 | loss_scale 8 | train_wall 1563 | gb_free 15.1 | wall 3391
2023-07-22 15:31:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 15:31:10 | INFO | fairseq.trainer | begin training epoch 5
2023-07-22 15:31:10 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 15:31:28 | INFO | train_inner | epoch 005:     10 / 1474 loss=3.948, trans_loss=3.674, nll_loss=1.874, w2v_ctc_loss=1.362, task_loss=0.946, contrastive_loss=0.182, total=4037.7, n_correct=2137.01, ppl=3.67, accuracy=52.926, wps=7597.6, ups=0.63, wpb=12062.8, bsz=439.3, num_updates=5900, lr=0.000184115, gnorm=0.685, clip=0, loss_scale=8, train_wall=105, gb_free=17, wall=3411
2023-07-22 15:33:14 | INFO | train_inner | epoch 005:    110 / 1474 loss=3.853, trans_loss=3.623, nll_loss=1.808, w2v_ctc_loss=1.282, task_loss=0.823, contrastive_loss=0.191, total=4247.37, n_correct=2312.59, ppl=3.5, accuracy=54.448, wps=11956.5, ups=0.94, wpb=12683.8, bsz=495.1, num_updates=6000, lr=0.000182574, gnorm=0.662, clip=0, loss_scale=8, train_wall=106, gb_free=16.9, wall=3517
2023-07-22 15:33:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 15:33:38 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.493 | trans_loss 5.9 | nll_loss 3.269 | w2v_ctc_loss 1.531 | task_loss 4.505 | contrastive_loss 0.318 | total 4003.4 | n_correct 2278.1 | ppl 9.64 | accuracy 56.904 | uer 22.618 | wer 24.324 | raw_wer 24.324 | bleu 16.56 | wps 2118.3 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.56
2023-07-22 15:33:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-07-22 15:33:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_5_6000.pt
2023-07-22 15:33:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_5_6000.pt
2023-07-22 15:33:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.56) (writing took 20.215894615277648 seconds)
2023-07-22 15:35:45 | INFO | train_inner | epoch 005:    210 / 1474 loss=3.895, trans_loss=3.631, nll_loss=1.817, w2v_ctc_loss=1.297, task_loss=0.843, contrastive_loss=0.409, total=4189.85, n_correct=2271.16, ppl=3.52, accuracy=54.206, wps=8292.1, ups=0.66, wpb=12492.8, bsz=488.2, num_updates=6100, lr=0.000181071, gnorm=0.662, clip=0, loss_scale=8, train_wall=106, gb_free=17.9, wall=3667
2023-07-22 15:37:30 | INFO | train_inner | epoch 005:    310 / 1474 loss=3.888, trans_loss=3.631, nll_loss=1.821, w2v_ctc_loss=1.313, task_loss=0.935, contrastive_loss=0.253, total=4090.1, n_correct=2207.37, ppl=3.53, accuracy=53.969, wps=11620.2, ups=0.95, wpb=12240, bsz=443.9, num_updates=6200, lr=0.000179605, gnorm=0.68, clip=0, loss_scale=8, train_wall=105, gb_free=16.4, wall=3773
2023-07-22 15:39:17 | INFO | train_inner | epoch 005:    410 / 1474 loss=3.874, trans_loss=3.625, nll_loss=1.815, w2v_ctc_loss=1.281, task_loss=0.88, contrastive_loss=0.339, total=4147.17, n_correct=2252.82, ppl=3.52, accuracy=54.322, wps=11562.3, ups=0.93, wpb=12381.8, bsz=472.5, num_updates=6300, lr=0.000178174, gnorm=0.671, clip=0, loss_scale=8, train_wall=107, gb_free=15.1, wall=3880
2023-07-22 15:41:04 | INFO | train_inner | epoch 005:    510 / 1474 loss=3.862, trans_loss=3.636, nll_loss=1.824, w2v_ctc_loss=1.293, task_loss=1.026, contrastive_loss=0.135, total=4026.81, n_correct=2180.09, ppl=3.54, accuracy=54.139, wps=11295.7, ups=0.94, wpb=12047.2, bsz=416.6, num_updates=6400, lr=0.000176777, gnorm=0.663, clip=0, loss_scale=8, train_wall=106, gb_free=17.5, wall=3986
2023-07-22 15:42:51 | INFO | train_inner | epoch 005:    610 / 1474 loss=3.878, trans_loss=3.632, nll_loss=1.82, w2v_ctc_loss=1.288, task_loss=0.935, contrastive_loss=0.31, total=4107.75, n_correct=2226.5, ppl=3.53, accuracy=54.202, wps=11437.2, ups=0.93, wpb=12245.3, bsz=451.2, num_updates=6500, lr=0.000175412, gnorm=0.69, clip=0, loss_scale=8, train_wall=106, gb_free=16.3, wall=4093
2023-07-22 15:44:38 | INFO | train_inner | epoch 005:    710 / 1474 loss=3.868, trans_loss=3.623, nll_loss=1.811, w2v_ctc_loss=1.282, task_loss=0.863, contrastive_loss=0.288, total=4178.85, n_correct=2279.07, ppl=3.51, accuracy=54.538, wps=11675.5, ups=0.94, wpb=12462.3, bsz=480.9, num_updates=6600, lr=0.000174078, gnorm=0.669, clip=0, loss_scale=8, train_wall=106, gb_free=17.8, wall=4200
2023-07-22 15:46:25 | INFO | train_inner | epoch 005:    810 / 1474 loss=3.855, trans_loss=3.628, nll_loss=1.814, w2v_ctc_loss=1.276, task_loss=0.938, contrastive_loss=0.209, total=4127.73, n_correct=2251.29, ppl=3.52, accuracy=54.541, wps=11524.7, ups=0.94, wpb=12320.4, bsz=449.2, num_updates=6700, lr=0.000172774, gnorm=0.661, clip=0, loss_scale=8, train_wall=106, gb_free=15.4, wall=4307
2023-07-22 15:48:12 | INFO | train_inner | epoch 005:    910 / 1474 loss=3.839, trans_loss=3.622, nll_loss=1.808, w2v_ctc_loss=1.264, task_loss=0.944, contrastive_loss=0.172, total=4095.48, n_correct=2244.08, ppl=3.5, accuracy=54.794, wps=11453.4, ups=0.94, wpb=12237.9, bsz=445.3, num_updates=6800, lr=0.000171499, gnorm=0.663, clip=0, loss_scale=8, train_wall=106, gb_free=15.8, wall=4414
2023-07-22 15:49:58 | INFO | train_inner | epoch 005:   1010 / 1474 loss=3.848, trans_loss=3.625, nll_loss=1.813, w2v_ctc_loss=1.265, task_loss=0.898, contrastive_loss=0.249, total=4165.12, n_correct=2281.43, ppl=3.51, accuracy=54.775, wps=11730.3, ups=0.94, wpb=12426.3, bsz=463.5, num_updates=6900, lr=0.000170251, gnorm=0.651, clip=0, loss_scale=8, train_wall=105, gb_free=15.9, wall=4520
2023-07-22 15:51:44 | INFO | train_inner | epoch 005:   1110 / 1474 loss=3.861, trans_loss=3.625, nll_loss=1.811, w2v_ctc_loss=1.272, task_loss=0.902, contrastive_loss=0.255, total=4176.72, n_correct=2297.66, ppl=3.51, accuracy=55.011, wps=11675, ups=0.94, wpb=12467.3, bsz=466.1, num_updates=7000, lr=0.000169031, gnorm=0.657, clip=0, loss_scale=8, train_wall=106, gb_free=16.9, wall=4627
2023-07-22 15:53:32 | INFO | train_inner | epoch 005:   1210 / 1474 loss=3.827, trans_loss=3.624, nll_loss=1.81, w2v_ctc_loss=1.251, task_loss=0.929, contrastive_loss=0.159, total=4164.13, n_correct=2292.4, ppl=3.51, accuracy=55.051, wps=11589.3, ups=0.93, wpb=12416.1, bsz=453.8, num_updates=7100, lr=0.000167836, gnorm=0.65, clip=0, loss_scale=16, train_wall=107, gb_free=17.1, wall=4734
2023-07-22 15:55:18 | INFO | train_inner | epoch 005:   1310 / 1474 loss=3.815, trans_loss=3.619, nll_loss=1.803, w2v_ctc_loss=1.242, task_loss=0.931, contrastive_loss=0.13, total=4134.91, n_correct=2276.57, ppl=3.49, accuracy=55.057, wps=11613.3, ups=0.94, wpb=12356.4, bsz=445.6, num_updates=7200, lr=0.000166667, gnorm=0.655, clip=0, loss_scale=16, train_wall=106, gb_free=16.6, wall=4840
2023-07-22 15:57:04 | INFO | train_inner | epoch 005:   1410 / 1474 loss=3.813, trans_loss=3.61, nll_loss=1.796, w2v_ctc_loss=1.239, task_loss=0.916, contrastive_loss=0.192, total=4134.37, n_correct=2281.25, ppl=3.47, accuracy=55.178, wps=11651.8, ups=0.94, wpb=12339.9, bsz=458.5, num_updates=7300, lr=0.000165521, gnorm=0.647, clip=0, loss_scale=16, train_wall=105, gb_free=17.9, wall=4946
2023-07-22 15:58:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 15:58:35 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.403 | trans_loss 5.825 | nll_loss 3.176 | w2v_ctc_loss 1.396 | task_loss 4.52 | contrastive_loss 0.327 | total 4003.4 | n_correct 2314.5 | ppl 9.04 | accuracy 57.813 | uer 21.28 | wer 22.971 | raw_wer 22.971 | bleu 17.18 | wps 2286 | wpb 4003.4 | bsz 141.8 | num_updates 7364 | best_bleu 17.18
2023-07-22 15:58:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7364 updates
2023-07-22 15:58:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 15:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 15:58:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 5 @ 7364 updates, score 17.18) (writing took 19.169978516176343 seconds)
2023-07-22 15:58:54 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-07-22 15:58:55 | INFO | train | epoch 005 | loss 3.854 | trans_loss 3.625 | nll_loss 1.811 | w2v_ctc_loss 1.274 | task_loss 0.911 | contrastive_loss 0.235 | total 4138.65 | n_correct 2260.26 | ppl 3.51 | accuracy 54.613 | wps 10936.6 | ups 0.89 | wpb 12355.8 | bsz 458.5 | num_updates 7364 | lr 0.0001648 | gnorm 0.664 | clip 0 | loss_scale 16 | train_wall 1562 | gb_free 16.4 | wall 5057
2023-07-22 15:58:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 15:58:55 | INFO | fairseq.trainer | begin training epoch 6
2023-07-22 15:58:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 15:59:43 | INFO | train_inner | epoch 006:     36 / 1474 loss=3.795, trans_loss=3.596, nll_loss=1.774, w2v_ctc_loss=1.226, task_loss=0.937, contrastive_loss=0.188, total=4115.45, n_correct=2293.72, ppl=3.42, accuracy=55.734, wps=7733, ups=0.63, wpb=12279.2, bsz=447.9, num_updates=7400, lr=0.000164399, gnorm=0.661, clip=0, loss_scale=16, train_wall=107, gb_free=16.6, wall=5105
2023-07-22 16:01:29 | INFO | train_inner | epoch 006:    136 / 1474 loss=3.749, trans_loss=3.571, nll_loss=1.743, w2v_ctc_loss=1.179, task_loss=0.911, contrastive_loss=0.232, total=4154.25, n_correct=2337.99, ppl=3.35, accuracy=56.279, wps=11659.3, ups=0.94, wpb=12409.6, bsz=456.1, num_updates=7500, lr=0.000163299, gnorm=0.644, clip=0, loss_scale=16, train_wall=106, gb_free=15.7, wall=5211
2023-07-22 16:03:15 | INFO | train_inner | epoch 006:    236 / 1474 loss=3.767, trans_loss=3.578, nll_loss=1.754, w2v_ctc_loss=1.216, task_loss=0.979, contrastive_loss=0.143, total=4112.66, n_correct=2301.76, ppl=3.37, accuracy=55.968, wps=11651, ups=0.95, wpb=12281.7, bsz=437.3, num_updates=7600, lr=0.000162221, gnorm=0.65, clip=0, loss_scale=16, train_wall=105, gb_free=16.3, wall=5317
2023-07-22 16:05:03 | INFO | train_inner | epoch 006:    336 / 1474 loss=3.768, trans_loss=3.566, nll_loss=1.739, w2v_ctc_loss=1.166, task_loss=0.847, contrastive_loss=0.442, total=4177.51, n_correct=2364.26, ppl=3.34, accuracy=56.595, wps=11529.1, ups=0.93, wpb=12463.7, bsz=491.3, num_updates=7700, lr=0.000161165, gnorm=0.654, clip=0, loss_scale=16, train_wall=108, gb_free=16.3, wall=5425
2023-07-22 16:06:49 | INFO | train_inner | epoch 006:    436 / 1474 loss=3.73, trans_loss=3.57, nll_loss=1.743, w2v_ctc_loss=1.169, task_loss=0.878, contrastive_loss=0.156, total=4154.57, n_correct=2353.26, ppl=3.35, accuracy=56.643, wps=11681.5, ups=0.94, wpb=12407.2, bsz=470.2, num_updates=7800, lr=0.000160128, gnorm=0.644, clip=0, loss_scale=16, train_wall=106, gb_free=16.4, wall=5531
2023-07-22 16:08:35 | INFO | train_inner | epoch 006:    536 / 1474 loss=3.744, trans_loss=3.574, nll_loss=1.749, w2v_ctc_loss=1.191, task_loss=0.918, contrastive_loss=0.143, total=4167.79, n_correct=2357.51, ppl=3.36, accuracy=56.565, wps=11744, ups=0.95, wpb=12419.2, bsz=455.2, num_updates=7900, lr=0.000159111, gnorm=0.641, clip=0, loss_scale=16, train_wall=105, gb_free=16, wall=5637
2023-07-22 16:10:21 | INFO | train_inner | epoch 006:    636 / 1474 loss=3.735, trans_loss=3.574, nll_loss=1.745, w2v_ctc_loss=1.164, task_loss=0.864, contrastive_loss=0.198, total=4146.17, n_correct=2342.05, ppl=3.35, accuracy=56.487, wps=11670.4, ups=0.94, wpb=12395.5, bsz=471.6, num_updates=8000, lr=0.000158114, gnorm=0.64, clip=0, loss_scale=16, train_wall=106, gb_free=16.8, wall=5743
2023-07-22 16:10:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 16:10:45 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.382 | trans_loss 5.798 | nll_loss 3.135 | w2v_ctc_loss 1.41 | task_loss 4.503 | contrastive_loss 0.288 | total 4003.4 | n_correct 2328.9 | ppl 8.79 | accuracy 58.173 | uer 20.659 | wer 22.352 | raw_wer 22.352 | bleu 17.39 | wps 2079.3 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 17.39
2023-07-22 16:10:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-07-22 16:10:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_6_8000.pt
2023-07-22 16:10:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_6_8000.pt
2023-07-22 16:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 17.39) (writing took 30.70377543568611 seconds)
2023-07-22 16:13:03 | INFO | train_inner | epoch 006:    736 / 1474 loss=3.747, trans_loss=3.575, nll_loss=1.751, w2v_ctc_loss=1.189, task_loss=0.931, contrastive_loss=0.153, total=4148.65, n_correct=2345.68, ppl=3.37, accuracy=56.541, wps=7654.6, ups=0.62, wpb=12378.4, bsz=453.7, num_updates=8100, lr=0.000157135, gnorm=0.646, clip=0, loss_scale=16, train_wall=106, gb_free=15.8, wall=5905
2023-07-22 16:14:49 | INFO | train_inner | epoch 006:    836 / 1474 loss=3.744, trans_loss=3.582, nll_loss=1.757, w2v_ctc_loss=1.181, task_loss=0.959, contrastive_loss=0.136, total=4114.34, n_correct=2314.12, ppl=3.38, accuracy=56.245, wps=11542.1, ups=0.94, wpb=12292.5, bsz=441.6, num_updates=8200, lr=0.000156174, gnorm=0.646, clip=0, loss_scale=16, train_wall=106, gb_free=15.3, wall=6011
2023-07-22 16:16:35 | INFO | train_inner | epoch 006:    936 / 1474 loss=3.757, trans_loss=3.579, nll_loss=1.755, w2v_ctc_loss=1.184, task_loss=0.952, contrastive_loss=0.233, total=4081.53, n_correct=2301.56, ppl=3.38, accuracy=56.39, wps=11468.6, ups=0.94, wpb=12166.1, bsz=444.5, num_updates=8300, lr=0.00015523, gnorm=0.651, clip=0, loss_scale=16, train_wall=106, gb_free=17.9, wall=6117
2023-07-22 16:18:22 | INFO | train_inner | epoch 006:   1036 / 1474 loss=3.75, trans_loss=3.573, nll_loss=1.748, w2v_ctc_loss=1.165, task_loss=0.867, contrastive_loss=0.306, total=4165.84, n_correct=2363.55, ppl=3.36, accuracy=56.736, wps=11667.7, ups=0.94, wpb=12437.3, bsz=477.2, num_updates=8400, lr=0.000154303, gnorm=0.648, clip=0, loss_scale=16, train_wall=106, gb_free=17, wall=6224
2023-07-22 16:20:08 | INFO | train_inner | epoch 006:   1136 / 1474 loss=3.739, trans_loss=3.58, nll_loss=1.754, w2v_ctc_loss=1.175, task_loss=1.01, contrastive_loss=0.136, total=4072.29, n_correct=2304.9, ppl=3.37, accuracy=56.6, wps=11450.5, ups=0.94, wpb=12165.1, bsz=428, num_updates=8500, lr=0.000153393, gnorm=0.646, clip=0, loss_scale=16, train_wall=106, gb_free=17.1, wall=6330
2023-07-22 16:21:55 | INFO | train_inner | epoch 006:   1236 / 1474 loss=3.765, trans_loss=3.57, nll_loss=1.745, w2v_ctc_loss=1.159, task_loss=0.886, contrastive_loss=0.452, total=4141.55, n_correct=2353.89, ppl=3.35, accuracy=56.836, wps=11567.1, ups=0.93, wpb=12385.8, bsz=474.8, num_updates=8600, lr=0.000152499, gnorm=0.641, clip=0, loss_scale=16, train_wall=107, gb_free=13.6, wall=6437
2023-07-22 16:23:41 | INFO | train_inner | epoch 006:   1336 / 1474 loss=3.728, trans_loss=3.578, nll_loss=1.75, w2v_ctc_loss=1.16, task_loss=0.909, contrastive_loss=0.123, total=4125.31, n_correct=2347.85, ppl=3.36, accuracy=56.913, wps=11627.3, ups=0.94, wpb=12316, bsz=452.6, num_updates=8700, lr=0.00015162, gnorm=0.635, clip=0, loss_scale=16, train_wall=105, gb_free=17.9, wall=6543
2023-07-22 16:25:28 | INFO | train_inner | epoch 006:   1436 / 1474 loss=3.715, trans_loss=3.565, nll_loss=1.738, w2v_ctc_loss=1.159, task_loss=0.912, contrastive_loss=0.129, total=4196.2, n_correct=2396.82, ppl=3.34, accuracy=57.119, wps=11699.5, ups=0.93, wpb=12515.5, bsz=461.5, num_updates=8800, lr=0.000150756, gnorm=0.625, clip=0, loss_scale=16, train_wall=106, gb_free=11.8, wall=6650
2023-07-22 16:26:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 16:26:32 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.343 | trans_loss 5.768 | nll_loss 3.096 | w2v_ctc_loss 1.351 | task_loss 4.545 | contrastive_loss 0.281 | total 4003.4 | n_correct 2347.6 | ppl 8.55 | accuracy 58.64 | uer 19.775 | wer 21.461 | raw_wer 21.461 | bleu 17.76 | wps 2166.1 | wpb 4003.4 | bsz 141.8 | num_updates 8838 | best_bleu 17.76
2023-07-22 16:26:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8838 updates
2023-07-22 16:26:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 16:26:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 16:26:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 6 @ 8838 updates, score 17.76) (writing took 22.811866061761975 seconds)
2023-07-22 16:26:55 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-07-22 16:26:55 | INFO | train | epoch 006 | loss 3.744 | trans_loss 3.573 | nll_loss 1.747 | w2v_ctc_loss 1.174 | task_loss 0.913 | contrastive_loss 0.212 | total 4138.65 | n_correct 2341.76 | ppl 3.36 | accuracy 56.583 | wps 10837.5 | ups 0.88 | wpb 12355.8 | bsz 458.5 | num_updates 8838 | lr 0.000150431 | gnorm 0.643 | clip 0 | loss_scale 16 | train_wall 1561 | gb_free 15.3 | wall 6737
2023-07-22 16:26:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 16:26:55 | INFO | fairseq.trainer | begin training epoch 7
2023-07-22 16:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 16:28:10 | INFO | train_inner | epoch 007:     62 / 1474 loss=3.675, trans_loss=3.545, nll_loss=1.711, w2v_ctc_loss=1.121, task_loss=0.891, contrastive_loss=0.145, total=4108.19, n_correct=2360.78, ppl=3.27, accuracy=57.465, wps=7558.5, ups=0.62, wpb=12269.7, bsz=461.9, num_updates=8900, lr=0.000149906, gnorm=0.634, clip=0, loss_scale=16, train_wall=106, gb_free=17.3, wall=6813
2023-07-22 16:29:57 | INFO | train_inner | epoch 007:    162 / 1474 loss=3.674, trans_loss=3.539, nll_loss=1.704, w2v_ctc_loss=1.117, task_loss=0.926, contrastive_loss=0.216, total=4106.05, n_correct=2365.2, ppl=3.26, accuracy=57.603, wps=11531.5, ups=0.94, wpb=12254.3, bsz=455.4, num_updates=9000, lr=0.000149071, gnorm=0.639, clip=0, loss_scale=16, train_wall=106, gb_free=16.9, wall=6919
2023-07-22 16:31:43 | INFO | train_inner | epoch 007:    262 / 1474 loss=3.658, trans_loss=3.532, nll_loss=1.693, w2v_ctc_loss=1.115, task_loss=0.923, contrastive_loss=0.124, total=4129.3, n_correct=2391.22, ppl=3.23, accuracy=57.909, wps=11614.8, ups=0.94, wpb=12322.9, bsz=451.8, num_updates=9100, lr=0.00014825, gnorm=0.624, clip=0, loss_scale=16, train_wall=106, gb_free=17.5, wall=7025
2023-07-22 16:33:30 | INFO | train_inner | epoch 007:    362 / 1474 loss=3.693, trans_loss=3.539, nll_loss=1.704, w2v_ctc_loss=1.108, task_loss=0.88, contrastive_loss=0.387, total=4201.67, n_correct=2424.35, ppl=3.26, accuracy=57.7, wps=11723.8, ups=0.94, wpb=12533.1, bsz=479.7, num_updates=9200, lr=0.000147442, gnorm=0.637, clip=0, loss_scale=32, train_wall=106, gb_free=15.6, wall=7132
2023-07-22 16:35:16 | INFO | train_inner | epoch 007:    462 / 1474 loss=3.676, trans_loss=3.536, nll_loss=1.703, w2v_ctc_loss=1.102, task_loss=0.897, contrastive_loss=0.306, total=4155.31, n_correct=2394.4, ppl=3.26, accuracy=57.623, wps=11675.8, ups=0.94, wpb=12394.6, bsz=465.5, num_updates=9300, lr=0.000146647, gnorm=0.64, clip=0, loss_scale=32, train_wall=106, gb_free=16.9, wall=7238
2023-07-22 16:37:03 | INFO | train_inner | epoch 007:    562 / 1474 loss=3.655, trans_loss=3.538, nll_loss=1.703, w2v_ctc_loss=1.106, task_loss=0.896, contrastive_loss=0.133, total=4165.88, n_correct=2411.54, ppl=3.25, accuracy=57.888, wps=11586.6, ups=0.93, wpb=12401.8, bsz=459, num_updates=9400, lr=0.000145865, gnorm=0.63, clip=0, loss_scale=32, train_wall=106, gb_free=17.4, wall=7345
2023-07-22 16:38:49 | INFO | train_inner | epoch 007:    662 / 1474 loss=3.655, trans_loss=3.542, nll_loss=1.704, w2v_ctc_loss=1.098, task_loss=0.916, contrastive_loss=0.12, total=4149.29, n_correct=2405.01, ppl=3.26, accuracy=57.962, wps=11640.6, ups=0.94, wpb=12393.1, bsz=451.6, num_updates=9500, lr=0.000145095, gnorm=0.629, clip=0, loss_scale=32, train_wall=106, gb_free=17.2, wall=7452
2023-07-22 16:40:36 | INFO | train_inner | epoch 007:    762 / 1474 loss=3.661, trans_loss=3.541, nll_loss=1.705, w2v_ctc_loss=1.11, task_loss=0.945, contrastive_loss=0.119, total=4134.54, n_correct=2388.83, ppl=3.26, accuracy=57.777, wps=11530.6, ups=0.93, wpb=12358.8, bsz=449.8, num_updates=9600, lr=0.000144338, gnorm=0.629, clip=0, loss_scale=32, train_wall=107, gb_free=14.1, wall=7559
2023-07-22 16:42:24 | INFO | train_inner | epoch 007:    862 / 1474 loss=3.662, trans_loss=3.541, nll_loss=1.705, w2v_ctc_loss=1.106, task_loss=0.918, contrastive_loss=0.139, total=4151.77, n_correct=2401.38, ppl=3.26, accuracy=57.84, wps=11548.8, ups=0.93, wpb=12405.1, bsz=461.9, num_updates=9700, lr=0.000143592, gnorm=0.637, clip=0, loss_scale=32, train_wall=107, gb_free=15.1, wall=7666
2023-07-22 16:44:11 | INFO | train_inner | epoch 007:    962 / 1474 loss=3.667, trans_loss=3.538, nll_loss=1.703, w2v_ctc_loss=1.094, task_loss=0.876, contrastive_loss=0.233, total=4124.8, n_correct=2396.97, ppl=3.26, accuracy=58.111, wps=11490, ups=0.93, wpb=12316.5, bsz=471.2, num_updates=9800, lr=0.000142857, gnorm=0.637, clip=0, loss_scale=32, train_wall=107, gb_free=16.9, wall=7773
2023-07-22 16:45:57 | INFO | train_inner | epoch 007:   1062 / 1474 loss=3.659, trans_loss=3.545, nll_loss=1.711, w2v_ctc_loss=1.101, task_loss=0.958, contrastive_loss=0.102, total=4113.08, n_correct=2379.65, ppl=3.27, accuracy=57.856, wps=11571.7, ups=0.94, wpb=12291.6, bsz=439.4, num_updates=9900, lr=0.000142134, gnorm=0.628, clip=0, loss_scale=32, train_wall=106, gb_free=15, wall=7880
2023-07-22 16:47:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-22 16:47:46 | INFO | train_inner | epoch 007:   1163 / 1474 loss=3.672, trans_loss=3.534, nll_loss=1.703, w2v_ctc_loss=1.094, task_loss=0.912, contrastive_loss=0.309, total=4112.66, n_correct=2386.95, ppl=3.26, accuracy=58.039, wps=11333.8, ups=0.92, wpb=12274, bsz=460.2, num_updates=10000, lr=0.000141421, gnorm=0.633, clip=0, loss_scale=16, train_wall=108, gb_free=16.3, wall=7988
2023-07-22 16:47:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 16:48:09 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.304 | trans_loss 5.723 | nll_loss 3.04 | w2v_ctc_loss 1.322 | task_loss 4.587 | contrastive_loss 0.28 | total 4003.4 | n_correct 2374.8 | ppl 8.23 | accuracy 59.32 | uer 18.886 | wer 20.682 | raw_wer 20.682 | bleu 18.58 | wps 2190.1 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 18.58
2023-07-22 16:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-07-22 16:48:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_7_10000.pt
2023-07-22 16:48:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_7_10000.pt
2023-07-22 16:48:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 18.58) (writing took 24.20080397091806 seconds)
mt_weight tensor(1., device='cuda:0')
asr_weight tensor(0.5116, device='cuda:0')
2023-07-22 16:50:20 | INFO | train_inner | epoch 007:   1263 / 1474 loss=3.645, trans_loss=3.532, nll_loss=1.697, w2v_ctc_loss=1.09, task_loss=0.927, contrastive_loss=0.129, total=4129.52, n_correct=2402.34, ppl=3.24, accuracy=58.175, wps=7964.3, ups=0.65, wpb=12329.2, bsz=450.2, num_updates=10100, lr=0.00014072, gnorm=0.488, clip=0, loss_scale=16, train_wall=106, gb_free=17.1, wall=8143
2023-07-22 16:52:07 | INFO | train_inner | epoch 007:   1363 / 1474 loss=3.649, trans_loss=3.527, nll_loss=1.691, w2v_ctc_loss=1.094, task_loss=0.858, contrastive_loss=0.167, total=4172.87, n_correct=2439.25, ppl=3.23, accuracy=58.455, wps=11673.7, ups=0.94, wpb=12453.5, bsz=476.2, num_updates=10200, lr=0.000140028, gnorm=0.49, clip=0, loss_scale=16, train_wall=106, gb_free=17.3, wall=8249
2023-07-22 16:53:56 | INFO | train_inner | epoch 007:   1463 / 1474 loss=3.668, trans_loss=3.536, nll_loss=1.703, w2v_ctc_loss=1.093, task_loss=0.985, contrastive_loss=0.23, total=4109.42, n_correct=2392.56, ppl=3.26, accuracy=58.221, wps=11307.2, ups=0.92, wpb=12285.7, bsz=443.8, num_updates=10300, lr=0.000139347, gnorm=0.501, clip=0, loss_scale=16, train_wall=108, gb_free=16.7, wall=8358
2023-07-22 16:54:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1., device='cuda:5')
asr_weight tensor(0.5116, device='cuda:5')
mt_weight tensor(1., device='cuda:6')
asr_weight tensor(0.5116, device='cuda:6')
mt_weight tensor(1., device='cuda:2')
asr_weight tensor(0.5116, device='cuda:2')
mt_weight tensor(1., device='cuda:3')
asr_weight tensor(0.5116, device='cuda:3')
mt_weight tensor(1., device='cuda:7')
asr_weight tensor(0.5116, device='cuda:7')
mt_weight tensor(1., device='cuda:4')
asr_weight tensor(0.5116, device='cuda:4')
mt_weight tensor(1., device='cuda:1')
asr_weight tensor(0.5116, device='cuda:1')
2023-07-22 16:54:30 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.303 | trans_loss 5.719 | nll_loss 3.035 | w2v_ctc_loss 1.328 | task_loss 4.596 | contrastive_loss 0.283 | total 4003.4 | n_correct 2376.3 | ppl 8.19 | accuracy 59.357 | uer 19.335 | wer 21.028 | raw_wer 21.028 | bleu 18.6 | wps 2247.9 | wpb 4003.4 | bsz 141.8 | num_updates 10311 | best_bleu 18.6
2023-07-22 16:54:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10311 updates
2023-07-22 16:54:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 16:54:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 16:54:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 7 @ 10311 updates, score 18.6) (writing took 21.3754365965724 seconds)
2023-07-22 16:54:52 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-07-22 16:54:52 | INFO | train | epoch 007 | loss 3.664 | trans_loss 3.537 | nll_loss 1.702 | w2v_ctc_loss 1.102 | task_loss 0.915 | contrastive_loss 0.192 | total 4137.22 | n_correct 2396.64 | ppl 3.25 | accuracy 57.929 | wps 10847 | ups 0.88 | wpb 12351.6 | bsz 457.8 | num_updates 10311 | lr 0.000139272 | gnorm 0.604 | clip 0 | loss_scale 16 | train_wall 1567 | gb_free 13.5 | wall 8415
2023-07-22 16:54:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 16:54:53 | INFO | fairseq.trainer | begin training epoch 8
2023-07-22 16:54:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 16:56:36 | INFO | train_inner | epoch 008:     89 / 1474 loss=3.603, trans_loss=3.511, nll_loss=1.665, w2v_ctc_loss=1.057, task_loss=0.966, contrastive_loss=0.124, total=4116.25, n_correct=2423.64, ppl=3.17, accuracy=58.88, wps=7632.6, ups=0.62, wpb=12265.9, bsz=443.3, num_updates=10400, lr=0.000138675, gnorm=0.488, clip=0, loss_scale=16, train_wall=106, gb_free=17.2, wall=8519
2023-07-22 16:58:23 | INFO | train_inner | epoch 008:    189 / 1474 loss=3.613, trans_loss=3.515, nll_loss=1.67, w2v_ctc_loss=1.06, task_loss=0.989, contrastive_loss=0.148, total=4037.23, n_correct=2374.17, ppl=3.18, accuracy=58.807, wps=11339.7, ups=0.94, wpb=12033.3, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.497, clip=0, loss_scale=16, train_wall=105, gb_free=13.1, wall=8625
2023-07-22 17:00:09 | INFO | train_inner | epoch 008:    289 / 1474 loss=3.591, trans_loss=3.504, nll_loss=1.657, w2v_ctc_loss=1.044, task_loss=0.859, contrastive_loss=0.146, total=4207.78, n_correct=2486.39, ppl=3.15, accuracy=59.09, wps=11807.8, ups=0.94, wpb=12570.1, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.49, clip=0, loss_scale=16, train_wall=106, gb_free=13.3, wall=8731
2023-07-22 17:01:57 | INFO | train_inner | epoch 008:    389 / 1474 loss=3.617, trans_loss=3.511, nll_loss=1.667, w2v_ctc_loss=1.067, task_loss=0.972, contrastive_loss=0.166, total=4127.24, n_correct=2425.2, ppl=3.17, accuracy=58.761, wps=11398, ups=0.93, wpb=12318.5, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.493, clip=0, loss_scale=16, train_wall=108, gb_free=12.2, wall=8839
2023-07-22 17:03:46 | INFO | train_inner | epoch 008:    489 / 1474 loss=3.64, trans_loss=3.509, nll_loss=1.664, w2v_ctc_loss=1.042, task_loss=0.817, contrastive_loss=0.427, total=4203.76, n_correct=2481.54, ppl=3.17, accuracy=59.031, wps=11593, ups=0.92, wpb=12567.7, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.491, clip=0, loss_scale=16, train_wall=108, gb_free=14.8, wall=8948
2023-07-22 17:05:32 | INFO | train_inner | epoch 008:    589 / 1474 loss=3.609, trans_loss=3.513, nll_loss=1.671, w2v_ctc_loss=1.065, task_loss=0.999, contrastive_loss=0.101, total=4062.5, n_correct=2384.03, ppl=3.18, accuracy=58.684, wps=11384.4, ups=0.94, wpb=12171.9, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.497, clip=0, loss_scale=16, train_wall=106, gb_free=11.7, wall=9055
2023-07-22 17:07:19 | INFO | train_inner | epoch 008:    689 / 1474 loss=3.607, trans_loss=3.508, nll_loss=1.666, w2v_ctc_loss=1.069, task_loss=0.941, contrastive_loss=0.113, total=4142.78, n_correct=2445.25, ppl=3.17, accuracy=59.024, wps=11560, ups=0.94, wpb=12347.9, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.494, clip=0, loss_scale=16, train_wall=106, gb_free=16, wall=9162
2023-07-22 17:09:05 | INFO | train_inner | epoch 008:    789 / 1474 loss=3.612, trans_loss=3.507, nll_loss=1.665, w2v_ctc_loss=1.055, task_loss=0.94, contrastive_loss=0.198, total=4118.9, n_correct=2429.09, ppl=3.17, accuracy=58.974, wps=11615.9, ups=0.94, wpb=12327.8, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.49, clip=0, loss_scale=16, train_wall=105, gb_free=15.4, wall=9268
2023-07-22 17:10:53 | INFO | train_inner | epoch 008:    889 / 1474 loss=3.607, trans_loss=3.508, nll_loss=1.667, w2v_ctc_loss=1.046, task_loss=0.876, contrastive_loss=0.209, total=4169.01, n_correct=2463.49, ppl=3.18, accuracy=59.091, wps=11577.8, ups=0.93, wpb=12455.3, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.492, clip=0, loss_scale=16, train_wall=107, gb_free=16.3, wall=9375
2023-07-22 17:12:40 | INFO | train_inner | epoch 008:    989 / 1474 loss=3.585, trans_loss=3.505, nll_loss=1.662, w2v_ctc_loss=1.045, task_loss=0.876, contrastive_loss=0.108, total=4154.69, n_correct=2456.76, ppl=3.16, accuracy=59.132, wps=11623.8, ups=0.94, wpb=12398.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.492, clip=0, loss_scale=16, train_wall=106, gb_free=17.8, wall=9482
Traceback (most recent call last):
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 564, in <module>
    cli_main()
  File "/mnt/zhangyh/fairseq-AT/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/zhangyh/fairseq-AT/fairseq/distributed/utils.py", line 344, in call_main
    torch.multiprocessing.spawn(
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 240, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 361 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
2023-07-22 20:40:36 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:12971
2023-07-22 20:40:36 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12971
2023-07-22 20:40:36 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12971
2023-07-22 20:40:36 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12971
2023-07-22 20:40:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-07-22 20:40:36 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12971
2023-07-22 20:40:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-07-22 20:40:36 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:12971
2023-07-22 20:40:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-07-22 20:40:36 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:12971
2023-07-22 20:40:36 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:12971
2023-07-22 20:40:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-07-22 20:40:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-07-22 20:40:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-07-22 20:40:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-07-22 20:40:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-07-22 20:40:37 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 20:40:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-07-22 20:40:37 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 20:40:37 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 20:40:37 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 20:40:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-07-22 20:40:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-07-22 20:40:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-07-22 20:40:37 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 20:40:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-07-22 20:40:37 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 20:40:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-07-22 20:40:37 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 20:40:37 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-07-22 20:40:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-07-22 20:40:37 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-07-22 20:40:41 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12971', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr,train_mt', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 60000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.0, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=60000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=False, min_loss_scale=0.0001, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr,train_mt', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-07-22 20:40:41 | INFO | fairseq.tasks.joint_triple_pretraining | dictionary size (dict.wrd.txt): 10,000
2023-07-22 20:40:41 | INFO | fairseq.tasks.joint_triple_pretraining | asr dictionary size (dict.wrd.txt): 10,000
2023-07-22 20:40:41 | INFO | fairseq.tasks.joint_triple_pretraining | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-07-22 20:40:41 | INFO | fairseq.tasks.joint_triple_pretraining | Initial task weight: asr 1.0: mt 1.0
2023-07-22 20:40:41 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-22 20:40:46 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-07-22 20:40:46 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-07-22 20:40:46 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-07-22 20:40:49 | INFO | root | load pretrained hubert
2023-07-22 20:40:49 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_mustc_ende_baseline
2023-07-22 20:40:52 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-22 20:40:55 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/mustc/ende-baseline/last8.ensemble.pt
2023-07-22 20:40:55 | INFO | root | share the sematic adapter and textual encoder
2023-07-22 20:40:55 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=1024, bias=True)
          (fc2): Linear(in_features=1024, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-07-22 20:40:55 | INFO | fairseq_cli.train | task: JointTriplePretrainingTask
2023-07-22 20:40:55 | INFO | fairseq_cli.train | model: S2TJoint
2023-07-22 20:40:55 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointAT
2023-07-22 20:40:55 | INFO | fairseq_cli.train | num. shared model params: 134,449,280 (num. trained: 134,449,280)
2023-07-22 20:40:55 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-07-22 20:40:55 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-22 20:40:55 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 20:40:55 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 20:40:55 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 20:40:58 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-07-22 20:40:58 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-07-22 20:40:58 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-07-22 20:40:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-22 20:40:58 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 20:40:58 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 20:40:58 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 20:40:58 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 20:40:58 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 20:40:58 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 20:40:58 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 20:40:58 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-07-22 20:40:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-07-22 20:40:58 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-07-22 20:40:58 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-07-22 20:40:58 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-22 20:41:01 | INFO | fairseq.trainer | load the task parameters
asr_weight tensor(0.5116)
mt_weight tensor(1.)
2023-07-22 20:41:01 | INFO | fairseq.optim.adam | using FusedAdam
2023-07-22 20:41:02 | INFO | fairseq.trainer | Loaded checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 8 @ 10311 updates)
2023-07-22 20:41:02 | INFO | fairseq.trainer | loading train data for epoch 8
2023-07-22 20:41:02 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-07-22 20:41:02 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 20:41:02 | INFO | fairseq.tasks.joint_triple_pretraining | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-07-22 20:41:06 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_mt", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 20:41:10 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-07-22 20:41:12 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
asr_weight tensor(0.5116)
mt_weight tensor(1.)
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:242: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.asr_weight = torch.tensor(state_dict["asr_weight"]).cuda()
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:247: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mt_weight = torch.tensor(state_dict["mt_weight"]).cuda()
2023-07-22 20:42:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 20:42:21 | INFO | fairseq.trainer | begin training epoch 8
2023-07-22 20:42:21 | INFO | fairseq_cli.train | Start iterating over samples
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:242: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.asr_weight = torch.tensor(state_dict["asr_weight"]).cuda()
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:247: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mt_weight = torch.tensor(state_dict["mt_weight"]).cuda()
asr_weight tensor(0.5116)
mt_weight tensor(1.)
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:242: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.asr_weight = torch.tensor(state_dict["asr_weight"]).cuda()
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:247: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mt_weight = torch.tensor(state_dict["mt_weight"]).cuda()
asr_weight tensor(0.5116)
mt_weight tensor(1.)
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:242: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.asr_weight = torch.tensor(state_dict["asr_weight"]).cuda()
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:247: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mt_weight = torch.tensor(state_dict["mt_weight"]).cuda()
asr_weight tensor(0.5116)
mt_weight tensor(1.)
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:242: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.asr_weight = torch.tensor(state_dict["asr_weight"]).cuda()
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:247: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mt_weight = torch.tensor(state_dict["mt_weight"]).cuda()
asr_weight tensor(0.5116)
mt_weight tensor(1.)
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:242: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.asr_weight = torch.tensor(state_dict["asr_weight"]).cuda()
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:247: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mt_weight = torch.tensor(state_dict["mt_weight"]).cuda()
asr_weight tensor(0.5116)
mt_weight tensor(1.)
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:242: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.asr_weight = torch.tensor(state_dict["asr_weight"]).cuda()
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:247: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mt_weight = torch.tensor(state_dict["mt_weight"]).cuda()
asr_weight tensor(0.5116)
mt_weight tensor(1.)
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:242: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.asr_weight = torch.tensor(state_dict["asr_weight"]).cuda()
/mnt/zhangyh/fairseq-AT/fairseq/tasks/joint_triple_pretraining.py:247: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  self.mt_weight = torch.tensor(state_dict["mt_weight"]).cuda()
2023-07-22 20:44:13 | INFO | train_inner | epoch 008:     89 / 1474 loss=3.594, trans_loss=3.509, nll_loss=1.662, w2v_ctc_loss=1.046, task_loss=0.971, contrastive_loss=0.128, total=4139.6, n_correct=2436.27, ppl=3.16, accuracy=58.853, wps=11665.2, ups=0.94, wpb=12330.9, bsz=445.1, num_updates=10400, lr=0.000138675, gnorm=0.485, clip=0, loss_scale=16, train_wall=103, gb_free=17.1, wall=195
2023-07-22 20:45:59 | INFO | train_inner | epoch 008:    189 / 1474 loss=3.609, trans_loss=3.514, nll_loss=1.67, w2v_ctc_loss=1.056, task_loss=0.991, contrastive_loss=0.146, total=4037.23, n_correct=2373.05, ppl=3.18, accuracy=58.779, wps=11400.3, ups=0.95, wpb=12033.3, bsz=428.6, num_updates=10500, lr=0.000138013, gnorm=0.498, clip=0, loss_scale=16, train_wall=105, gb_free=13.1, wall=300
2023-07-22 20:47:44 | INFO | train_inner | epoch 008:    289 / 1474 loss=3.595, trans_loss=3.505, nll_loss=1.658, w2v_ctc_loss=1.048, task_loss=0.861, contrastive_loss=0.148, total=4207.78, n_correct=2485.87, ppl=3.16, accuracy=59.078, wps=11947.2, ups=0.95, wpb=12570.1, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.488, clip=0, loss_scale=16, train_wall=105, gb_free=13.3, wall=406
2023-07-22 20:49:30 | INFO | train_inner | epoch 008:    389 / 1474 loss=3.616, trans_loss=3.511, nll_loss=1.667, w2v_ctc_loss=1.065, task_loss=0.973, contrastive_loss=0.167, total=4127.24, n_correct=2425.99, ppl=3.17, accuracy=58.78, wps=11613.1, ups=0.94, wpb=12318.5, bsz=441.4, num_updates=10700, lr=0.000136717, gnorm=0.492, clip=0, loss_scale=16, train_wall=106, gb_free=12.1, wall=512
2023-07-22 20:51:17 | INFO | train_inner | epoch 008:    489 / 1474 loss=3.645, trans_loss=3.512, nll_loss=1.669, w2v_ctc_loss=1.051, task_loss=0.82, contrastive_loss=0.431, total=4203.76, n_correct=2473.01, ppl=3.18, accuracy=58.829, wps=11733.6, ups=0.93, wpb=12567.7, bsz=504.5, num_updates=10800, lr=0.000136083, gnorm=0.502, clip=0, loss_scale=16, train_wall=107, gb_free=14.8, wall=619
2023-07-22 20:53:02 | INFO | train_inner | epoch 008:    589 / 1474 loss=3.608, trans_loss=3.513, nll_loss=1.672, w2v_ctc_loss=1.065, task_loss=0.999, contrastive_loss=0.1, total=4062.5, n_correct=2381.69, ppl=3.19, accuracy=58.626, wps=11534.6, ups=0.95, wpb=12171.9, bsz=427.9, num_updates=10900, lr=0.000135457, gnorm=0.496, clip=0, loss_scale=16, train_wall=105, gb_free=11.7, wall=724
2023-07-22 20:54:48 | INFO | train_inner | epoch 008:    689 / 1474 loss=3.606, trans_loss=3.509, nll_loss=1.667, w2v_ctc_loss=1.068, task_loss=0.943, contrastive_loss=0.113, total=4142.78, n_correct=2447.67, ppl=3.18, accuracy=59.083, wps=11702.9, ups=0.95, wpb=12347.9, bsz=448.6, num_updates=11000, lr=0.00013484, gnorm=0.492, clip=0, loss_scale=16, train_wall=105, gb_free=16, wall=830
2023-07-22 20:56:33 | INFO | train_inner | epoch 008:    789 / 1474 loss=3.609, trans_loss=3.507, nll_loss=1.666, w2v_ctc_loss=1.054, task_loss=0.938, contrastive_loss=0.197, total=4118.9, n_correct=2430.2, ppl=3.17, accuracy=59.001, wps=11739, ups=0.95, wpb=12327.8, bsz=447.8, num_updates=11100, lr=0.000134231, gnorm=0.492, clip=0, loss_scale=16, train_wall=104, gb_free=15.4, wall=935
2023-07-22 20:58:19 | INFO | train_inner | epoch 008:    889 / 1474 loss=3.601, trans_loss=3.506, nll_loss=1.664, w2v_ctc_loss=1.039, task_loss=0.877, contrastive_loss=0.207, total=4169.01, n_correct=2465.72, ppl=3.17, accuracy=59.144, wps=11741.6, ups=0.94, wpb=12455.3, bsz=473.7, num_updates=11200, lr=0.000133631, gnorm=0.486, clip=0, loss_scale=16, train_wall=105, gb_free=16.3, wall=1041
2023-07-22 21:00:04 | INFO | train_inner | epoch 008:    989 / 1474 loss=3.58, trans_loss=3.502, nll_loss=1.659, w2v_ctc_loss=1.038, task_loss=0.876, contrastive_loss=0.109, total=4154.69, n_correct=2463.83, ppl=3.16, accuracy=59.302, wps=11845.8, ups=0.96, wpb=12398.4, bsz=464.9, num_updates=11300, lr=0.000133038, gnorm=0.485, clip=0, loss_scale=16, train_wall=104, gb_free=17.8, wall=1146
2023-07-22 21:01:50 | INFO | train_inner | epoch 008:   1089 / 1474 loss=3.619, trans_loss=3.508, nll_loss=1.667, w2v_ctc_loss=1.046, task_loss=0.912, contrastive_loss=0.334, total=4199.1, n_correct=2478.48, ppl=3.18, accuracy=59.024, wps=11800, ups=0.94, wpb=12520.7, bsz=465.3, num_updates=11400, lr=0.000132453, gnorm=0.489, clip=0, loss_scale=16, train_wall=106, gb_free=13, wall=1252
2023-07-22 21:03:36 | INFO | train_inner | epoch 008:   1189 / 1474 loss=3.594, trans_loss=3.507, nll_loss=1.667, w2v_ctc_loss=1.046, task_loss=0.864, contrastive_loss=0.119, total=4177.31, n_correct=2472.37, ppl=3.17, accuracy=59.186, wps=11793, ups=0.95, wpb=12476.4, bsz=472.6, num_updates=11500, lr=0.000131876, gnorm=0.483, clip=0, loss_scale=16, train_wall=105, gb_free=15.1, wall=1358
2023-07-22 21:05:20 | INFO | train_inner | epoch 008:   1289 / 1474 loss=3.603, trans_loss=3.509, nll_loss=1.669, w2v_ctc_loss=1.053, task_loss=0.958, contrastive_loss=0.14, total=4063.85, n_correct=2392.44, ppl=3.18, accuracy=58.871, wps=11669.6, ups=0.96, wpb=12141.2, bsz=438.4, num_updates=11600, lr=0.000131306, gnorm=0.494, clip=0, loss_scale=16, train_wall=104, gb_free=17, wall=1462
2023-07-22 21:07:04 | INFO | train_inner | epoch 008:   1389 / 1474 loss=3.61, trans_loss=3.509, nll_loss=1.67, w2v_ctc_loss=1.051, task_loss=0.905, contrastive_loss=0.193, total=4141.5, n_correct=2447.67, ppl=3.18, accuracy=59.101, wps=11848.6, ups=0.96, wpb=12351.9, bsz=461.5, num_updates=11700, lr=0.000130744, gnorm=0.493, clip=0, loss_scale=16, train_wall=104, gb_free=16.7, wall=1566
2023-07-22 21:08:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 21:08:55 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.278 | trans_loss 5.683 | nll_loss 2.986 | w2v_ctc_loss 1.334 | task_loss 4.609 | contrastive_loss 0.263 | total 4003.4 | n_correct 2403.2 | ppl 7.92 | accuracy 60.029 | uer 18.366 | wer 20.141 | raw_wer 20.141 | bleu 18.61 | wps 2321.8 | wpb 4003.4 | bsz 141.8 | num_updates 11785 | best_bleu 18.61
2023-07-22 21:08:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11785 updates
2023-07-22 21:08:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 21:09:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 21:09:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 8 @ 11785 updates, score 18.61) (writing took 21.675937781110406 seconds)
2023-07-22 21:09:18 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-07-22 21:09:18 | INFO | train | epoch 008 | loss 3.606 | trans_loss 3.509 | nll_loss 1.666 | w2v_ctc_loss 1.051 | task_loss 0.916 | contrastive_loss 0.187 | total 4138.65 | n_correct 2441.65 | ppl 3.17 | accuracy 58.996 | wps 11389.8 | ups 0.92 | wpb 12355.8 | bsz 458.5 | num_updates 11785 | lr 0.000130272 | gnorm 0.491 | clip 0 | loss_scale 16 | train_wall 1556 | gb_free 17.1 | wall 1700
2023-07-22 21:09:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 21:09:18 | INFO | fairseq.trainer | begin training epoch 9
2023-07-22 21:09:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 21:09:43 | INFO | train_inner | epoch 009:     15 / 1474 loss=3.602, trans_loss=3.504, nll_loss=1.662, w2v_ctc_loss=1.028, task_loss=0.882, contrastive_loss=0.316, total=4139.35, n_correct=2459.04, ppl=3.16, accuracy=59.406, wps=7746.4, ups=0.63, wpb=12332.8, bsz=472.9, num_updates=11800, lr=0.000130189, gnorm=0.491, clip=0, loss_scale=16, train_wall=105, gb_free=16.4, wall=1725
2023-07-22 21:11:28 | INFO | train_inner | epoch 009:    115 / 1474 loss=3.537, trans_loss=3.476, nll_loss=1.623, w2v_ctc_loss=0.998, task_loss=0.867, contrastive_loss=0.136, total=4181.9, n_correct=2511.56, ppl=3.08, accuracy=60.058, wps=11941, ups=0.96, wpb=12493.2, bsz=475.9, num_updates=11900, lr=0.000129641, gnorm=0.484, clip=0, loss_scale=16, train_wall=104, gb_free=16.4, wall=1830
2023-07-22 21:13:13 | INFO | train_inner | epoch 009:    215 / 1474 loss=3.542, trans_loss=3.483, nll_loss=1.632, w2v_ctc_loss=1.002, task_loss=0.986, contrastive_loss=0.095, total=4062.07, n_correct=2436, ppl=3.1, accuracy=59.969, wps=11527.8, ups=0.95, wpb=12136.5, bsz=431.6, num_updates=12000, lr=0.000129099, gnorm=0.49, clip=0, loss_scale=16, train_wall=105, gb_free=15.8, wall=1935
2023-07-22 21:13:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 21:13:36 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.268 | trans_loss 5.693 | nll_loss 2.999 | w2v_ctc_loss 1.278 | task_loss 4.582 | contrastive_loss 0.267 | total 4003.4 | n_correct 2392.7 | ppl 8 | accuracy 59.767 | uer 18.337 | wer 20.122 | raw_wer 20.122 | bleu 18.6 | wps 2260.7 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 18.61
2023-07-22 21:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-07-22 21:13:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_9_12000.pt
2023-07-22 21:13:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_9_12000.pt
2023-07-22 21:14:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 18.6) (writing took 25.76761152036488 seconds)
2023-07-22 21:15:50 | INFO | train_inner | epoch 009:    315 / 1474 loss=3.531, trans_loss=3.472, nll_loss=1.62, w2v_ctc_loss=0.988, task_loss=0.855, contrastive_loss=0.143, total=4152.1, n_correct=2503.56, ppl=3.07, accuracy=60.296, wps=7925.8, ups=0.64, wpb=12422.8, bsz=476.6, num_updates=12100, lr=0.000128565, gnorm=0.487, clip=0, loss_scale=16, train_wall=104, gb_free=16.5, wall=2092
2023-07-22 21:17:36 | INFO | train_inner | epoch 009:    415 / 1474 loss=3.541, trans_loss=3.481, nll_loss=1.632, w2v_ctc_loss=1.005, task_loss=0.893, contrastive_loss=0.114, total=4203.78, n_correct=2514.8, ppl=3.1, accuracy=59.822, wps=11830.1, ups=0.94, wpb=12545.5, bsz=469.8, num_updates=12200, lr=0.000128037, gnorm=0.485, clip=0, loss_scale=16, train_wall=106, gb_free=17.3, wall=2198
2023-07-22 21:19:20 | INFO | train_inner | epoch 009:    515 / 1474 loss=3.578, trans_loss=3.49, nll_loss=1.644, w2v_ctc_loss=1.032, task_loss=0.96, contrastive_loss=0.164, total=4112.78, n_correct=2452.68, ppl=3.12, accuracy=59.636, wps=11794.9, ups=0.96, wpb=12260.1, bsz=437.7, num_updates=12300, lr=0.000127515, gnorm=0.492, clip=0, loss_scale=16, train_wall=103, gb_free=16.3, wall=2302
2023-07-22 21:21:05 | INFO | train_inner | epoch 009:    615 / 1474 loss=3.541, trans_loss=3.481, nll_loss=1.634, w2v_ctc_loss=0.998, task_loss=0.933, contrastive_loss=0.124, total=4131.32, n_correct=2472.7, ppl=3.1, accuracy=59.853, wps=11710.7, ups=0.95, wpb=12355.3, bsz=455, num_updates=12400, lr=0.000127, gnorm=0.488, clip=0, loss_scale=32, train_wall=105, gb_free=17.9, wall=2407
2023-07-22 21:22:50 | INFO | train_inner | epoch 009:    715 / 1474 loss=3.572, trans_loss=3.488, nll_loss=1.64, w2v_ctc_loss=1.019, task_loss=0.937, contrastive_loss=0.208, total=4082.11, n_correct=2435.04, ppl=3.12, accuracy=59.652, wps=11622.5, ups=0.95, wpb=12206.9, bsz=449.7, num_updates=12500, lr=0.000126491, gnorm=0.492, clip=0, loss_scale=32, train_wall=104, gb_free=17.1, wall=2512
2023-07-22 21:23:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-07-22 21:24:37 | INFO | train_inner | epoch 009:    816 / 1474 loss=3.57, trans_loss=3.477, nll_loss=1.631, w2v_ctc_loss=1.016, task_loss=0.841, contrastive_loss=0.275, total=4202.99, n_correct=2514.97, ppl=3.1, accuracy=59.838, wps=11773.3, ups=0.94, wpb=12540.2, bsz=492, num_updates=12600, lr=0.000125988, gnorm=0.494, clip=0, loss_scale=16, train_wall=106, gb_free=14.6, wall=2619
2023-07-22 21:26:22 | INFO | train_inner | epoch 009:    916 / 1474 loss=3.574, trans_loss=3.487, nll_loss=1.639, w2v_ctc_loss=1.009, task_loss=0.945, contrastive_loss=0.33, total=4146.05, n_correct=2476.37, ppl=3.12, accuracy=59.728, wps=11705.3, ups=0.95, wpb=12355.9, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.491, clip=0, loss_scale=16, train_wall=105, gb_free=17.9, wall=2724
2023-07-22 21:28:07 | INFO | train_inner | epoch 009:   1016 / 1474 loss=3.566, trans_loss=3.496, nll_loss=1.649, w2v_ctc_loss=1.018, task_loss=1.022, contrastive_loss=0.111, total=4101.48, n_correct=2442.22, ppl=3.14, accuracy=59.545, wps=11711.3, ups=0.96, wpb=12243.2, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.487, clip=0, loss_scale=16, train_wall=104, gb_free=16.1, wall=2829
2023-07-22 21:29:51 | INFO | train_inner | epoch 009:   1116 / 1474 loss=3.549, trans_loss=3.486, nll_loss=1.636, w2v_ctc_loss=1.006, task_loss=0.863, contrastive_loss=0.136, total=4179.09, n_correct=2505.46, ppl=3.11, accuracy=59.952, wps=11926.1, ups=0.96, wpb=12439.9, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.49, clip=0, loss_scale=16, train_wall=104, gb_free=15.5, wall=2933
2023-07-22 21:31:37 | INFO | train_inner | epoch 009:   1216 / 1474 loss=3.568, trans_loss=3.496, nll_loss=1.647, w2v_ctc_loss=1.02, task_loss=0.968, contrastive_loss=0.118, total=4140.66, n_correct=2469.79, ppl=3.13, accuracy=59.647, wps=11714.2, ups=0.94, wpb=12405, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.491, clip=0, loss_scale=16, train_wall=105, gb_free=17.2, wall=3039
2023-07-22 21:33:23 | INFO | train_inner | epoch 009:   1316 / 1474 loss=3.57, trans_loss=3.482, nll_loss=1.633, w2v_ctc_loss=1.001, task_loss=0.831, contrastive_loss=0.308, total=4204.43, n_correct=2528.79, ppl=3.1, accuracy=60.146, wps=11857.2, ups=0.95, wpb=12539.3, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.487, clip=0, loss_scale=16, train_wall=105, gb_free=17.8, wall=3145
2023-07-22 21:35:07 | INFO | train_inner | epoch 009:   1416 / 1474 loss=3.565, trans_loss=3.495, nll_loss=1.648, w2v_ctc_loss=1.02, task_loss=0.992, contrastive_loss=0.094, total=4069.19, n_correct=2430.8, ppl=3.13, accuracy=59.737, wps=11630.4, ups=0.96, wpb=12152.5, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.495, clip=0, loss_scale=16, train_wall=104, gb_free=16.8, wall=3249
2023-07-22 21:36:07 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 21:36:31 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.249 | trans_loss 5.666 | nll_loss 2.971 | w2v_ctc_loss 1.278 | task_loss 4.582 | contrastive_loss 0.26 | total 4003.4 | n_correct 2406 | ppl 7.84 | accuracy 60.099 | uer 17.893 | wer 19.541 | raw_wer 19.541 | bleu 19.01 | wps 2113.6 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 19.01
2023-07-22 21:36:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-07-22 21:36:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 21:36:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 21:36:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 9 @ 13258 updates, score 19.01) (writing took 20.652433719485998 seconds)
2023-07-22 21:36:52 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-07-22 21:36:52 | INFO | train | epoch 009 | loss 3.558 | trans_loss 3.485 | nll_loss 1.636 | w2v_ctc_loss 1.01 | task_loss 0.917 | contrastive_loss 0.174 | total 4137.53 | n_correct 2476.59 | ppl 3.11 | accuracy 59.857 | wps 10999.4 | ups 0.89 | wpb 12352.2 | bsz 457.9 | num_updates 13258 | lr 0.000122822 | gnorm 0.49 | clip 0 | loss_scale 16 | train_wall 1540 | gb_free 12 | wall 3354
2023-07-22 21:36:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 21:36:52 | INFO | fairseq.trainer | begin training epoch 10
2023-07-22 21:36:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 21:37:45 | INFO | train_inner | epoch 010:     42 / 1474 loss=3.546, trans_loss=3.476, nll_loss=1.625, w2v_ctc_loss=0.994, task_loss=0.873, contrastive_loss=0.195, total=4100.8, n_correct=2471.47, ppl=3.08, accuracy=60.268, wps=7766.7, ups=0.63, wpb=12243.3, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.497, clip=0, loss_scale=16, train_wall=103, gb_free=16.4, wall=3407
2023-07-22 21:39:30 | INFO | train_inner | epoch 010:    142 / 1474 loss=3.495, trans_loss=3.459, nll_loss=1.599, w2v_ctc_loss=0.958, task_loss=0.866, contrastive_loss=0.116, total=4247.35, n_correct=2582.11, ppl=3.03, accuracy=60.793, wps=12131.8, ups=0.95, wpb=12717.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.478, clip=0, loss_scale=16, train_wall=104, gb_free=12.1, wall=3512
2023-07-22 21:41:14 | INFO | train_inner | epoch 010:    242 / 1474 loss=3.513, trans_loss=3.453, nll_loss=1.597, w2v_ctc_loss=0.972, task_loss=0.906, contrastive_loss=0.236, total=4122.82, n_correct=2504.37, ppl=3.02, accuracy=60.744, wps=11808.2, ups=0.96, wpb=12279.5, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.485, clip=0, loss_scale=16, train_wall=103, gb_free=16.4, wall=3616
2023-07-22 21:42:58 | INFO | train_inner | epoch 010:    342 / 1474 loss=3.505, trans_loss=3.457, nll_loss=1.603, w2v_ctc_loss=0.968, task_loss=0.928, contrastive_loss=0.148, total=4138.27, n_correct=2512.31, ppl=3.04, accuracy=60.709, wps=11856.1, ups=0.96, wpb=12378.7, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.49, clip=0, loss_scale=16, train_wall=104, gb_free=16.6, wall=3720
2023-07-22 21:44:44 | INFO | train_inner | epoch 010:    442 / 1474 loss=3.515, trans_loss=3.459, nll_loss=1.604, w2v_ctc_loss=0.953, task_loss=0.881, contrastive_loss=0.324, total=4196.37, n_correct=2545.01, ppl=3.04, accuracy=60.648, wps=11829.4, ups=0.94, wpb=12523.5, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.478, clip=0, loss_scale=16, train_wall=105, gb_free=16.6, wall=3826
2023-07-22 21:46:29 | INFO | train_inner | epoch 010:    542 / 1474 loss=3.521, trans_loss=3.471, nll_loss=1.615, w2v_ctc_loss=0.987, task_loss=0.984, contrastive_loss=0.105, total=4102.8, n_correct=2482.23, ppl=3.06, accuracy=60.501, wps=11660.2, ups=0.95, wpb=12224.8, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.49, clip=0, loss_scale=16, train_wall=104, gb_free=17.1, wall=3931
2023-07-22 21:48:14 | INFO | train_inner | epoch 010:    642 / 1474 loss=3.532, trans_loss=3.47, nll_loss=1.617, w2v_ctc_loss=0.981, task_loss=0.87, contrastive_loss=0.221, total=4176.56, n_correct=2526.43, ppl=3.07, accuracy=60.491, wps=11879.4, ups=0.95, wpb=12467.5, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.49, clip=0, loss_scale=16, train_wall=104, gb_free=16.5, wall=4036
2023-07-22 21:49:58 | INFO | train_inner | epoch 010:    742 / 1474 loss=3.521, trans_loss=3.467, nll_loss=1.613, w2v_ctc_loss=0.99, task_loss=0.916, contrastive_loss=0.1, total=4125.87, n_correct=2497.17, ppl=3.06, accuracy=60.525, wps=11860.5, ups=0.96, wpb=12315.5, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.494, clip=0, loss_scale=16, train_wall=103, gb_free=14.7, wall=4140
2023-07-22 21:49:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 21:50:21 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.249 | trans_loss 5.665 | nll_loss 2.964 | w2v_ctc_loss 1.279 | task_loss 4.604 | contrastive_loss 0.272 | total 4003.4 | n_correct 2412.8 | ppl 7.8 | accuracy 60.269 | uer 18.175 | wer 19.664 | raw_wer 19.664 | bleu 18.91 | wps 2231.8 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 19.01
2023-07-22 21:50:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-07-22 21:50:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_10_14000.pt
2023-07-22 21:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_10_14000.pt
2023-07-22 21:50:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 18.91) (writing took 19.29795810393989 seconds)
2023-07-22 21:52:28 | INFO | train_inner | epoch 010:    842 / 1474 loss=3.507, trans_loss=3.466, nll_loss=1.611, w2v_ctc_loss=0.968, task_loss=0.908, contrastive_loss=0.104, total=4128.44, n_correct=2504.77, ppl=3.06, accuracy=60.671, wps=8201.1, ups=0.66, wpb=12345, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.486, clip=0, loss_scale=16, train_wall=104, gb_free=14.9, wall=4290
2023-07-22 21:54:12 | INFO | train_inner | epoch 010:    942 / 1474 loss=3.517, trans_loss=3.465, nll_loss=1.614, w2v_ctc_loss=0.983, task_loss=0.878, contrastive_loss=0.143, total=4160.94, n_correct=2518.78, ppl=3.06, accuracy=60.534, wps=11933.9, ups=0.96, wpb=12380.2, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.489, clip=0, loss_scale=16, train_wall=103, gb_free=15.6, wall=4394
2023-07-22 21:55:56 | INFO | train_inner | epoch 010:   1042 / 1474 loss=3.521, trans_loss=3.47, nll_loss=1.619, w2v_ctc_loss=0.983, task_loss=0.992, contrastive_loss=0.116, total=4067.53, n_correct=2453.05, ppl=3.07, accuracy=60.308, wps=11634.2, ups=0.96, wpb=12142, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.496, clip=0, loss_scale=16, train_wall=104, gb_free=17, wall=4498
2023-07-22 21:57:40 | INFO | train_inner | epoch 010:   1142 / 1474 loss=3.53, trans_loss=3.475, nll_loss=1.624, w2v_ctc_loss=0.993, task_loss=1.019, contrastive_loss=0.098, total=4044.03, n_correct=2433.2, ppl=3.08, accuracy=60.168, wps=11612.9, ups=0.96, wpb=12072.9, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.494, clip=0, loss_scale=16, train_wall=103, gb_free=17.4, wall=4602
2023-07-22 21:59:24 | INFO | train_inner | epoch 010:   1242 / 1474 loss=3.517, trans_loss=3.466, nll_loss=1.617, w2v_ctc_loss=0.985, task_loss=0.937, contrastive_loss=0.094, total=4110.41, n_correct=2486.73, ppl=3.07, accuracy=60.498, wps=11840.4, ups=0.96, wpb=12302.3, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.493, clip=0, loss_scale=16, train_wall=103, gb_free=16.6, wall=4706
2023-07-22 22:01:09 | INFO | train_inner | epoch 010:   1342 / 1474 loss=3.52, trans_loss=3.469, nll_loss=1.618, w2v_ctc_loss=0.987, task_loss=0.935, contrastive_loss=0.106, total=4121.38, n_correct=2491.15, ppl=3.07, accuracy=60.445, wps=11762, ups=0.96, wpb=12315.5, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.492, clip=0, loss_scale=32, train_wall=104, gb_free=14.3, wall=4811
2023-07-22 22:02:54 | INFO | train_inner | epoch 010:   1442 / 1474 loss=3.558, trans_loss=3.475, nll_loss=1.627, w2v_ctc_loss=0.974, task_loss=0.863, contrastive_loss=0.366, total=4192.39, n_correct=2528.39, ppl=3.09, accuracy=60.309, wps=11846.1, ups=0.95, wpb=12477.9, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.501, clip=0, loss_scale=32, train_wall=105, gb_free=17.2, wall=4916
2023-07-22 22:03:27 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 22:03:50 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.252 | trans_loss 5.654 | nll_loss 2.951 | w2v_ctc_loss 1.313 | task_loss 4.621 | contrastive_loss 0.271 | total 4003.4 | n_correct 2423.2 | ppl 7.73 | accuracy 60.529 | uer 17.734 | wer 19.436 | raw_wer 19.436 | bleu 19.18 | wps 2246 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 19.18
2023-07-22 22:03:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-07-22 22:03:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 22:04:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 22:04:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 10 @ 14732 updates, score 19.18) (writing took 20.64280142262578 seconds)
2023-07-22 22:04:12 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-07-22 22:04:12 | INFO | train | epoch 010 | loss 3.52 | trans_loss 3.466 | nll_loss 1.613 | w2v_ctc_loss 0.976 | task_loss 0.916 | contrastive_loss 0.173 | total 4138.65 | n_correct 2505.18 | ppl 3.06 | accuracy 60.531 | wps 11107.6 | ups 0.9 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.49 | clip 0 | loss_scale 32 | train_wall 1533 | gb_free 17.4 | wall 4994
2023-07-22 22:04:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 22:04:12 | INFO | fairseq.trainer | begin training epoch 11
2023-07-22 22:04:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 22:05:32 | INFO | train_inner | epoch 011:     68 / 1474 loss=3.487, trans_loss=3.448, nll_loss=1.59, w2v_ctc_loss=0.95, task_loss=0.849, contrastive_loss=0.18, total=4175.24, n_correct=2554.83, ppl=3.01, accuracy=61.19, wps=7912.2, ups=0.63, wpb=12460.8, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.483, clip=0, loss_scale=32, train_wall=103, gb_free=16.9, wall=5074
2023-07-22 22:07:16 | INFO | train_inner | epoch 011:    168 / 1474 loss=3.474, trans_loss=3.444, nll_loss=1.584, w2v_ctc_loss=0.945, task_loss=0.946, contrastive_loss=0.101, total=4087.78, n_correct=2501.76, ppl=3, accuracy=61.201, wps=11719.9, ups=0.96, wpb=12225.8, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.489, clip=0, loss_scale=32, train_wall=104, gb_free=16.7, wall=5178
2023-07-22 22:09:01 | INFO | train_inner | epoch 011:    268 / 1474 loss=3.468, trans_loss=3.444, nll_loss=1.587, w2v_ctc_loss=0.944, task_loss=0.945, contrastive_loss=0.096, total=4118.77, n_correct=2518.4, ppl=3, accuracy=61.144, wps=11732, ups=0.95, wpb=12285.5, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.487, clip=0, loss_scale=32, train_wall=104, gb_free=12.7, wall=5283
mt_weight tensor(1., device='cuda:0')
asr_weight tensor(0.1533, device='cuda:0')
2023-07-22 22:10:45 | INFO | train_inner | epoch 011:    368 / 1474 loss=3.465, trans_loss=3.445, nll_loss=1.585, w2v_ctc_loss=0.938, task_loss=0.938, contrastive_loss=0.101, total=4097.83, n_correct=2509.37, ppl=3, accuracy=61.237, wps=11728.3, ups=0.96, wpb=12202.1, bsz=444.2, num_updates=15100, lr=0.000115087, gnorm=0.381, clip=0, loss_scale=32, train_wall=103, gb_free=16.4, wall=5387
2023-07-22 22:12:29 | INFO | train_inner | epoch 011:    468 / 1474 loss=3.504, trans_loss=3.456, nll_loss=1.595, w2v_ctc_loss=0.941, task_loss=0.96, contrastive_loss=0.258, total=4110.64, n_correct=2505.56, ppl=3.02, accuracy=60.953, wps=11743.7, ups=0.96, wpb=12265.6, bsz=450.5, num_updates=15200, lr=0.000114708, gnorm=0.383, clip=0, loss_scale=32, train_wall=104, gb_free=16.5, wall=5491
2023-07-22 22:14:14 | INFO | train_inner | epoch 011:    568 / 1474 loss=3.508, trans_loss=3.451, nll_loss=1.595, w2v_ctc_loss=0.953, task_loss=0.979, contrastive_loss=0.257, total=4071.69, n_correct=2487.08, ppl=3.02, accuracy=61.082, wps=11597.5, ups=0.95, wpb=12176.5, bsz=440.6, num_updates=15300, lr=0.000114332, gnorm=0.379, clip=0, loss_scale=32, train_wall=105, gb_free=16.6, wall=5596
2023-07-22 22:15:59 | INFO | train_inner | epoch 011:    668 / 1474 loss=3.512, trans_loss=3.451, nll_loss=1.593, w2v_ctc_loss=0.951, task_loss=0.899, contrastive_loss=0.331, total=4157.2, n_correct=2533.2, ppl=3.02, accuracy=60.935, wps=11813.4, ups=0.95, wpb=12400.2, bsz=464.4, num_updates=15400, lr=0.000113961, gnorm=0.38, clip=0, loss_scale=32, train_wall=104, gb_free=16.9, wall=5701
2023-07-22 22:17:44 | INFO | train_inner | epoch 011:    768 / 1474 loss=3.491, trans_loss=3.454, nll_loss=1.596, w2v_ctc_loss=0.961, task_loss=0.919, contrastive_loss=0.101, total=4174.91, n_correct=2552.08, ppl=3.02, accuracy=61.129, wps=11889.1, ups=0.95, wpb=12472.8, bsz=460.4, num_updates=15500, lr=0.000113592, gnorm=0.379, clip=0, loss_scale=32, train_wall=104, gb_free=17.1, wall=5806
2023-07-22 22:19:29 | INFO | train_inner | epoch 011:    868 / 1474 loss=3.487, trans_loss=3.451, nll_loss=1.596, w2v_ctc_loss=0.962, task_loss=0.96, contrastive_loss=0.085, total=4118.44, n_correct=2507.84, ppl=3.02, accuracy=60.893, wps=11774.4, ups=0.96, wpb=12290.5, bsz=440.6, num_updates=15600, lr=0.000113228, gnorm=0.38, clip=0, loss_scale=32, train_wall=104, gb_free=11.3, wall=5911
2023-07-22 22:21:14 | INFO | train_inner | epoch 011:    968 / 1474 loss=3.489, trans_loss=3.454, nll_loss=1.597, w2v_ctc_loss=0.96, task_loss=0.935, contrastive_loss=0.102, total=4140.92, n_correct=2524.95, ppl=3.03, accuracy=60.976, wps=11757.6, ups=0.95, wpb=12353.7, bsz=452.9, num_updates=15700, lr=0.000112867, gnorm=0.38, clip=0, loss_scale=32, train_wall=105, gb_free=15.8, wall=6016
2023-07-22 22:22:58 | INFO | train_inner | epoch 011:   1068 / 1474 loss=3.494, trans_loss=3.448, nll_loss=1.592, w2v_ctc_loss=0.964, task_loss=0.901, contrastive_loss=0.127, total=4136.99, n_correct=2534.43, ppl=3.01, accuracy=61.263, wps=11875.3, ups=0.96, wpb=12367, bsz=463.2, num_updates=15800, lr=0.000112509, gnorm=0.381, clip=0, loss_scale=32, train_wall=104, gb_free=17.7, wall=6120
2023-07-22 22:24:42 | INFO | train_inner | epoch 011:   1168 / 1474 loss=3.492, trans_loss=3.451, nll_loss=1.598, w2v_ctc_loss=0.966, task_loss=0.908, contrastive_loss=0.11, total=4185.65, n_correct=2554.93, ppl=3.03, accuracy=61.04, wps=11942.9, ups=0.96, wpb=12477.8, bsz=464.7, num_updates=15900, lr=0.000112154, gnorm=0.377, clip=0, loss_scale=32, train_wall=104, gb_free=14.3, wall=6224
2023-07-22 22:26:28 | INFO | train_inner | epoch 011:   1268 / 1474 loss=3.504, trans_loss=3.452, nll_loss=1.595, w2v_ctc_loss=0.958, task_loss=0.881, contrastive_loss=0.198, total=4171.89, n_correct=2550.68, ppl=3.02, accuracy=61.14, wps=11822.5, ups=0.95, wpb=12466.6, bsz=471.1, num_updates=16000, lr=0.000111803, gnorm=0.382, clip=0, loss_scale=32, train_wall=105, gb_free=16.1, wall=6330
2023-07-22 22:26:28 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1., device='cuda:4')
asr_weight tensor(0.1533, device='cuda:4')
mt_weight tensor(1., device='cuda:5')
asr_weight tensor(0.1533, device='cuda:5')
mt_weight tensor(1., device='cuda:7')
asr_weight tensor(0.1533, device='cuda:7')
mt_weight tensor(1., device='cuda:1')
asr_weight tensor(0.1533, device='cuda:1')
mt_weight tensor(1., device='cuda:2')
asr_weight tensor(0.1533, device='cuda:2')
mt_weight tensor(1., device='cuda:3')
asr_weight tensor(0.1533, device='cuda:3')
mt_weight tensor(1., device='cuda:6')
asr_weight tensor(0.1533, device='cuda:6')
2023-07-22 22:26:51 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.265 | trans_loss 5.645 | nll_loss 2.935 | w2v_ctc_loss 1.382 | task_loss 4.652 | contrastive_loss 0.256 | total 4003.4 | n_correct 2427.7 | ppl 7.65 | accuracy 60.641 | uer 17.734 | wer 19.324 | raw_wer 19.324 | bleu 19.18 | wps 2248 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 19.18
2023-07-22 22:26:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-07-22 22:26:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_11_16000.pt
2023-07-22 22:26:55 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_11_16000.pt
2023-07-22 22:27:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 19.18) (writing took 44.45136081054807 seconds)
2023-07-22 22:29:22 | INFO | train_inner | epoch 011:   1368 / 1474 loss=3.522, trans_loss=3.45, nll_loss=1.593, w2v_ctc_loss=0.945, task_loss=0.846, contrastive_loss=0.416, total=4190.34, n_correct=2559.2, ppl=3.02, accuracy=61.074, wps=7198.5, ups=0.58, wpb=12512.8, bsz=491.8, num_updates=16100, lr=0.000111456, gnorm=0.379, clip=0, loss_scale=32, train_wall=105, gb_free=17.1, wall=6504
2023-07-22 22:31:06 | INFO | train_inner | epoch 011:   1468 / 1474 loss=3.49, trans_loss=3.452, nll_loss=1.596, w2v_ctc_loss=0.958, task_loss=0.885, contrastive_loss=0.114, total=4158.39, n_correct=2542, ppl=3.02, accuracy=61.129, wps=11893.9, ups=0.96, wpb=12421.8, bsz=468, num_updates=16200, lr=0.000111111, gnorm=0.381, clip=0, loss_scale=32, train_wall=104, gb_free=17.1, wall=6608
2023-07-22 22:31:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 22:31:35 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.234 | trans_loss 5.634 | nll_loss 2.924 | w2v_ctc_loss 1.304 | task_loss 4.633 | contrastive_loss 0.258 | total 4003.4 | n_correct 2436.2 | ppl 7.59 | accuracy 60.853 | uer 17.607 | wer 19.291 | raw_wer 19.291 | bleu 19.36 | wps 2279.9 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 19.36
2023-07-22 22:31:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-07-22 22:31:35 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 22:31:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 22:31:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 11 @ 16206 updates, score 19.36) (writing took 22.620532544329762 seconds)
2023-07-22 22:31:58 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-07-22 22:31:58 | INFO | train | epoch 011 | loss 3.492 | trans_loss 3.45 | nll_loss 1.592 | w2v_ctc_loss 0.953 | task_loss 0.916 | contrastive_loss 0.169 | total 4138.65 | n_correct 2528.69 | ppl 3.02 | accuracy 61.099 | wps 10930.8 | ups 0.88 | wpb 12355.8 | bsz 458.5 | num_updates 16206 | lr 0.000111091 | gnorm 0.399 | clip 0 | loss_scale 32 | train_wall 1534 | gb_free 17.3 | wall 6660
2023-07-22 22:31:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 22:31:58 | INFO | fairseq.trainer | begin training epoch 12
2023-07-22 22:31:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 22:33:45 | INFO | train_inner | epoch 012:     94 / 1474 loss=3.451, trans_loss=3.421, nll_loss=1.553, w2v_ctc_loss=0.927, task_loss=0.876, contrastive_loss=0.154, total=4146.82, n_correct=2576.65, ppl=2.93, accuracy=62.136, wps=7805.5, ups=0.63, wpb=12379.4, bsz=470.8, num_updates=16300, lr=0.00011077, gnorm=0.375, clip=0, loss_scale=32, train_wall=103, gb_free=15.9, wall=6767
2023-07-22 22:35:29 | INFO | train_inner | epoch 012:    194 / 1474 loss=3.454, trans_loss=3.426, nll_loss=1.562, w2v_ctc_loss=0.938, task_loss=0.945, contrastive_loss=0.089, total=4120.68, n_correct=2544.89, ppl=2.95, accuracy=61.759, wps=11840.7, ups=0.96, wpb=12345.4, bsz=442.1, num_updates=16400, lr=0.000110432, gnorm=0.38, clip=0, loss_scale=32, train_wall=104, gb_free=15.8, wall=6871
2023-07-22 22:37:14 | INFO | train_inner | epoch 012:    294 / 1474 loss=3.449, trans_loss=3.426, nll_loss=1.563, w2v_ctc_loss=0.924, task_loss=0.861, contrastive_loss=0.133, total=4199.46, n_correct=2597.15, ppl=2.95, accuracy=61.845, wps=11970.9, ups=0.95, wpb=12539.6, bsz=480.4, num_updates=16500, lr=0.000110096, gnorm=0.377, clip=0, loss_scale=32, train_wall=104, gb_free=16.8, wall=6976
2023-07-22 22:39:00 | INFO | train_inner | epoch 012:    394 / 1474 loss=3.45, trans_loss=3.429, nll_loss=1.566, w2v_ctc_loss=0.928, task_loss=0.897, contrastive_loss=0.109, total=4151.14, n_correct=2566.66, ppl=2.96, accuracy=61.83, wps=11739.1, ups=0.95, wpb=12410, bsz=461.6, num_updates=16600, lr=0.000109764, gnorm=0.38, clip=0, loss_scale=32, train_wall=105, gb_free=17.3, wall=7081
2023-07-22 22:40:44 | INFO | train_inner | epoch 012:    494 / 1474 loss=3.473, trans_loss=3.442, nll_loss=1.58, w2v_ctc_loss=0.949, task_loss=0.918, contrastive_loss=0.12, total=4110.49, n_correct=2528.14, ppl=2.99, accuracy=61.505, wps=11711.7, ups=0.96, wpb=12226.9, bsz=453.3, num_updates=16700, lr=0.000109435, gnorm=0.383, clip=0, loss_scale=64, train_wall=104, gb_free=14.2, wall=7186
2023-07-22 22:42:30 | INFO | train_inner | epoch 012:    594 / 1474 loss=3.47, trans_loss=3.43, nll_loss=1.569, w2v_ctc_loss=0.936, task_loss=0.877, contrastive_loss=0.204, total=4189.92, n_correct=2587.09, ppl=2.97, accuracy=61.746, wps=11832.9, ups=0.94, wpb=12531.1, bsz=472.7, num_updates=16800, lr=0.000109109, gnorm=0.38, clip=0, loss_scale=64, train_wall=105, gb_free=15.1, wall=7292
2023-07-22 22:44:14 | INFO | train_inner | epoch 012:    694 / 1474 loss=3.47, trans_loss=3.427, nll_loss=1.565, w2v_ctc_loss=0.924, task_loss=0.838, contrastive_loss=0.321, total=4206.3, n_correct=2603.42, ppl=2.96, accuracy=61.893, wps=12045.1, ups=0.96, wpb=12501.9, bsz=488.5, num_updates=16900, lr=0.000108786, gnorm=0.376, clip=0, loss_scale=64, train_wall=103, gb_free=16.5, wall=7396
2023-07-22 22:45:59 | INFO | train_inner | epoch 012:    794 / 1474 loss=3.466, trans_loss=3.434, nll_loss=1.569, w2v_ctc_loss=0.941, task_loss=0.937, contrastive_loss=0.105, total=4085.96, n_correct=2526.35, ppl=2.97, accuracy=61.83, wps=11619.2, ups=0.95, wpb=12212.6, bsz=445.7, num_updates=17000, lr=0.000108465, gnorm=0.382, clip=0, loss_scale=64, train_wall=105, gb_free=16.7, wall=7501
2023-07-22 22:47:44 | INFO | train_inner | epoch 012:    894 / 1474 loss=3.47, trans_loss=3.435, nll_loss=1.575, w2v_ctc_loss=0.938, task_loss=0.936, contrastive_loss=0.173, total=4169.74, n_correct=2569.12, ppl=2.98, accuracy=61.613, wps=11822.4, ups=0.95, wpb=12453, bsz=459.6, num_updates=17100, lr=0.000108148, gnorm=0.38, clip=0, loss_scale=64, train_wall=105, gb_free=16.2, wall=7606
2023-07-22 22:49:28 | INFO | train_inner | epoch 012:    994 / 1474 loss=3.477, trans_loss=3.437, nll_loss=1.576, w2v_ctc_loss=0.944, task_loss=0.933, contrastive_loss=0.186, total=4117.67, n_correct=2538.05, ppl=2.98, accuracy=61.638, wps=11777.5, ups=0.96, wpb=12288, bsz=452.1, num_updates=17200, lr=0.000107833, gnorm=0.383, clip=0, loss_scale=64, train_wall=104, gb_free=17.8, wall=7710
2023-07-22 22:49:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-22 22:51:13 | INFO | train_inner | epoch 012:   1095 / 1474 loss=3.475, trans_loss=3.443, nll_loss=1.581, w2v_ctc_loss=0.954, task_loss=0.998, contrastive_loss=0.079, total=4014.56, n_correct=2470.3, ppl=2.99, accuracy=61.534, wps=11416.8, ups=0.95, wpb=11998.6, bsz=419.2, num_updates=17300, lr=0.000107521, gnorm=0.391, clip=0, loss_scale=32, train_wall=105, gb_free=16.2, wall=7815
2023-07-22 22:52:58 | INFO | train_inner | epoch 012:   1195 / 1474 loss=3.498, trans_loss=3.442, nll_loss=1.585, w2v_ctc_loss=0.963, task_loss=0.891, contrastive_loss=0.205, total=4201.13, n_correct=2575.08, ppl=3, accuracy=61.295, wps=11948.6, ups=0.95, wpb=12545, bsz=478.7, num_updates=17400, lr=0.000107211, gnorm=0.383, clip=0, loss_scale=32, train_wall=105, gb_free=17.4, wall=7920
2023-07-22 22:54:43 | INFO | train_inner | epoch 012:   1295 / 1474 loss=3.476, trans_loss=3.442, nll_loss=1.585, w2v_ctc_loss=0.951, task_loss=1.022, contrastive_loss=0.086, total=4070.27, n_correct=2505.19, ppl=3, accuracy=61.548, wps=11615.9, ups=0.95, wpb=12168, bsz=429.2, num_updates=17500, lr=0.000106904, gnorm=0.383, clip=0, loss_scale=32, train_wall=104, gb_free=16.1, wall=8025
2023-07-22 22:56:28 | INFO | train_inner | epoch 012:   1395 / 1474 loss=3.478, trans_loss=3.438, nll_loss=1.579, w2v_ctc_loss=0.937, task_loss=0.921, contrastive_loss=0.226, total=4139.63, n_correct=2549.27, ppl=2.99, accuracy=61.582, wps=11821.6, ups=0.96, wpb=12331.2, bsz=458.7, num_updates=17600, lr=0.0001066, gnorm=0.382, clip=0, loss_scale=32, train_wall=104, gb_free=17.2, wall=8129
2023-07-22 22:57:50 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 22:58:14 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 4.235 | trans_loss 5.626 | nll_loss 2.913 | w2v_ctc_loss 1.323 | task_loss 4.629 | contrastive_loss 0.263 | total 4003.4 | n_correct 2442.3 | ppl 7.53 | accuracy 61.006 | uer 17.742 | wer 19.343 | raw_wer 19.343 | bleu 19.7 | wps 2083.5 | wpb 4003.4 | bsz 141.8 | num_updates 17679 | best_bleu 19.7
2023-07-22 22:58:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17679 updates
2023-07-22 22:58:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 22:58:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-22 22:58:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 12 @ 17679 updates, score 19.7) (writing took 23.814961787313223 seconds)
2023-07-22 22:58:39 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-07-22 22:58:39 | INFO | train | epoch 012 | loss 3.468 | trans_loss 3.434 | nll_loss 1.572 | w2v_ctc_loss 0.94 | task_loss 0.918 | contrastive_loss 0.155 | total 4136.49 | n_correct 2552.06 | ppl 2.97 | accuracy 61.696 | wps 11364.8 | ups 0.92 | wpb 12350.1 | bsz 457.4 | num_updates 17679 | lr 0.000106362 | gnorm 0.381 | clip 0 | loss_scale 32 | train_wall 1536 | gb_free 13.2 | wall 8261
2023-07-22 22:58:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 22:58:39 | INFO | fairseq.trainer | begin training epoch 13
2023-07-22 22:58:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 22:59:10 | INFO | train_inner | epoch 013:     21 / 1474 loss=3.472, trans_loss=3.435, nll_loss=1.575, w2v_ctc_loss=0.951, task_loss=0.954, contrastive_loss=0.099, total=4096.49, n_correct=2524.94, ppl=2.98, accuracy=61.637, wps=7541.3, ups=0.62, wpb=12243.5, bsz=443.1, num_updates=17700, lr=0.000106299, gnorm=0.387, clip=0, loss_scale=32, train_wall=104, gb_free=14.8, wall=8292
2023-07-22 23:00:54 | INFO | train_inner | epoch 013:    121 / 1474 loss=3.426, trans_loss=3.41, nll_loss=1.541, w2v_ctc_loss=0.912, task_loss=0.917, contrastive_loss=0.114, total=4160.97, n_correct=2590.49, ppl=2.91, accuracy=62.257, wps=11922.4, ups=0.96, wpb=12418.2, bsz=454.3, num_updates=17800, lr=0.000106, gnorm=0.377, clip=0, loss_scale=32, train_wall=104, gb_free=16.5, wall=8396
2023-07-22 23:02:40 | INFO | train_inner | epoch 013:    221 / 1474 loss=3.467, trans_loss=3.415, nll_loss=1.552, w2v_ctc_loss=0.916, task_loss=0.844, contrastive_loss=0.4, total=4212.08, n_correct=2614.22, ppl=2.93, accuracy=62.065, wps=11823.5, ups=0.94, wpb=12529.8, bsz=494.6, num_updates=17900, lr=0.000105703, gnorm=0.378, clip=0, loss_scale=32, train_wall=105, gb_free=14.9, wall=8502
2023-07-22 23:04:24 | INFO | train_inner | epoch 013:    321 / 1474 loss=3.423, trans_loss=3.417, nll_loss=1.549, w2v_ctc_loss=0.907, task_loss=0.953, contrastive_loss=0.094, total=4102.3, n_correct=2560.47, ppl=2.93, accuracy=62.415, wps=11748.5, ups=0.96, wpb=12230, bsz=441.1, num_updates=18000, lr=0.000105409, gnorm=0.384, clip=0, loss_scale=32, train_wall=104, gb_free=17.4, wall=8606
2023-07-22 23:04:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 23:04:49 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.23 | trans_loss 5.628 | nll_loss 2.917 | w2v_ctc_loss 1.303 | task_loss 4.604 | contrastive_loss 0.262 | total 4003.4 | n_correct 2439.3 | ppl 7.55 | accuracy 60.931 | uer 17.551 | wer 19.291 | raw_wer 19.291 | bleu 19.32 | wps 2083.6 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 19.7
2023-07-22 23:04:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-07-22 23:04:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_13_18000.pt
2023-07-22 23:04:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_13_18000.pt
2023-07-22 23:05:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 19.32) (writing took 21.916309090331197 seconds)
2023-07-22 23:06:55 | INFO | train_inner | epoch 013:    421 / 1474 loss=3.442, trans_loss=3.419, nll_loss=1.552, w2v_ctc_loss=0.915, task_loss=0.859, contrastive_loss=0.159, total=4177.29, n_correct=2606.33, ppl=2.93, accuracy=62.393, wps=8243.3, ups=0.66, wpb=12461.8, bsz=477.6, num_updates=18100, lr=0.000105118, gnorm=0.382, clip=0, loss_scale=32, train_wall=104, gb_free=17.6, wall=8757
2023-07-22 23:08:40 | INFO | train_inner | epoch 013:    521 / 1474 loss=3.454, trans_loss=3.422, nll_loss=1.557, w2v_ctc_loss=0.924, task_loss=0.888, contrastive_loss=0.208, total=4201.22, n_correct=2603.65, ppl=2.94, accuracy=61.974, wps=11938.2, ups=0.95, wpb=12536.9, bsz=478.4, num_updates=18200, lr=0.000104828, gnorm=0.38, clip=0, loss_scale=32, train_wall=105, gb_free=13.2, wall=8862
2023-07-22 23:10:25 | INFO | train_inner | epoch 013:    621 / 1474 loss=3.43, trans_loss=3.417, nll_loss=1.551, w2v_ctc_loss=0.915, task_loss=0.889, contrastive_loss=0.091, total=4161.98, n_correct=2594.6, ppl=2.93, accuracy=62.341, wps=11938.9, ups=0.96, wpb=12435.5, bsz=462.4, num_updates=18300, lr=0.000104542, gnorm=0.378, clip=0, loss_scale=32, train_wall=104, gb_free=16, wall=8966
2023-07-22 23:12:09 | INFO | train_inner | epoch 013:    721 / 1474 loss=3.463, trans_loss=3.427, nll_loss=1.563, w2v_ctc_loss=0.956, task_loss=1.017, contrastive_loss=0.089, total=4096.76, n_correct=2529.52, ppl=2.96, accuracy=61.744, wps=11681, ups=0.96, wpb=12226.1, bsz=426.8, num_updates=18400, lr=0.000104257, gnorm=0.388, clip=0, loss_scale=32, train_wall=104, gb_free=16.8, wall=9071
2023-07-22 23:13:55 | INFO | train_inner | epoch 013:    821 / 1474 loss=3.447, trans_loss=3.42, nll_loss=1.555, w2v_ctc_loss=0.923, task_loss=0.925, contrastive_loss=0.152, total=4121.73, n_correct=2555.2, ppl=2.94, accuracy=61.993, wps=11659.3, ups=0.95, wpb=12319.8, bsz=460, num_updates=18500, lr=0.000103975, gnorm=0.385, clip=0, loss_scale=32, train_wall=105, gb_free=15.1, wall=9177
2023-07-22 23:15:39 | INFO | train_inner | epoch 013:    921 / 1474 loss=3.441, trans_loss=3.422, nll_loss=1.558, w2v_ctc_loss=0.923, task_loss=0.936, contrastive_loss=0.102, total=4107.01, n_correct=2553.82, ppl=2.94, accuracy=62.182, wps=11748.8, ups=0.96, wpb=12264.1, bsz=444.7, num_updates=18600, lr=0.000103695, gnorm=0.386, clip=0, loss_scale=32, train_wall=104, gb_free=16.1, wall=9281
2023-07-22 23:17:23 | INFO | train_inner | epoch 013:   1021 / 1474 loss=3.458, trans_loss=3.421, nll_loss=1.56, w2v_ctc_loss=0.935, task_loss=0.966, contrastive_loss=0.17, total=4081.02, n_correct=2522.7, ppl=2.95, accuracy=61.815, wps=11719.2, ups=0.96, wpb=12208.8, bsz=440.1, num_updates=18700, lr=0.000103418, gnorm=0.386, clip=0, loss_scale=32, train_wall=104, gb_free=16.4, wall=9385
2023-07-22 23:19:07 | INFO | train_inner | epoch 013:   1121 / 1474 loss=3.445, trans_loss=3.42, nll_loss=1.554, w2v_ctc_loss=0.92, task_loss=0.904, contrastive_loss=0.145, total=4105.62, n_correct=2556.57, ppl=2.94, accuracy=62.27, wps=11895, ups=0.97, wpb=12265.4, bsz=458.9, num_updates=18800, lr=0.000103142, gnorm=0.382, clip=0, loss_scale=32, train_wall=103, gb_free=16.9, wall=9488
2023-07-22 23:20:51 | INFO | train_inner | epoch 013:   1221 / 1474 loss=3.455, trans_loss=3.431, nll_loss=1.568, w2v_ctc_loss=0.934, task_loss=0.977, contrastive_loss=0.092, total=4110.35, n_correct=2548.46, ppl=2.96, accuracy=62.001, wps=11753.1, ups=0.96, wpb=12287.7, bsz=442.6, num_updates=18900, lr=0.000102869, gnorm=0.389, clip=0, loss_scale=32, train_wall=104, gb_free=15.1, wall=9593
2023-07-22 23:22:35 | INFO | train_inner | epoch 013:   1321 / 1474 loss=3.452, trans_loss=3.42, nll_loss=1.557, w2v_ctc_loss=0.921, task_loss=0.904, contrastive_loss=0.222, total=4112.2, n_correct=2560.91, ppl=2.94, accuracy=62.276, wps=11778, ups=0.96, wpb=12280.4, bsz=462.3, num_updates=19000, lr=0.000102598, gnorm=0.382, clip=0, loss_scale=32, train_wall=104, gb_free=17.7, wall=9697
2023-07-22 23:24:20 | INFO | train_inner | epoch 013:   1421 / 1474 loss=3.461, trans_loss=3.428, nll_loss=1.564, w2v_ctc_loss=0.915, task_loss=0.901, contrastive_loss=0.236, total=4180.88, n_correct=2598.2, ppl=2.96, accuracy=62.145, wps=11971.8, ups=0.96, wpb=12470.5, bsz=468.3, num_updates=19100, lr=0.000102329, gnorm=0.379, clip=0, loss_scale=32, train_wall=104, gb_free=15.5, wall=9801
2023-07-22 23:25:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 23:25:39 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 4.233 | trans_loss 5.621 | nll_loss 2.906 | w2v_ctc_loss 1.333 | task_loss 4.621 | contrastive_loss 0.254 | total 4003.4 | n_correct 2445.4 | ppl 7.49 | accuracy 61.083 | uer 17.479 | wer 19.112 | raw_wer 19.112 | bleu 19.42 | wps 2050.3 | wpb 4003.4 | bsz 141.8 | num_updates 19153 | best_bleu 19.7
2023-07-22 23:25:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19153 updates
2023-07-22 23:25:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.4200.pt
2023-07-22 23:25:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.4200.pt
2023-07-22 23:25:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.4200.pt (epoch 13 @ 19153 updates, score 19.42) (writing took 11.491198856383562 seconds)
2023-07-22 23:25:51 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-07-22 23:25:51 | INFO | train | epoch 013 | loss 3.447 | trans_loss 3.42 | nll_loss 1.555 | w2v_ctc_loss 0.923 | task_loss 0.916 | contrastive_loss 0.163 | total 4138.65 | n_correct 2572.07 | ppl 2.94 | accuracy 62.147 | wps 11157.2 | ups 0.9 | wpb 12355.8 | bsz 458.5 | num_updates 19153 | lr 0.000102187 | gnorm 0.382 | clip 0 | loss_scale 32 | train_wall 1532 | gb_free 17.8 | wall 9893
2023-07-22 23:25:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 23:25:51 | INFO | fairseq.trainer | begin training epoch 14
2023-07-22 23:25:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 23:26:49 | INFO | train_inner | epoch 014:     47 / 1474 loss=3.404, trans_loss=3.398, nll_loss=1.528, w2v_ctc_loss=0.897, task_loss=0.836, contrastive_loss=0.109, total=4176.2, n_correct=2628.81, ppl=2.88, accuracy=62.947, wps=8335.7, ups=0.67, wpb=12486.4, bsz=483.4, num_updates=19200, lr=0.000102062, gnorm=0.377, clip=0, loss_scale=32, train_wall=103, gb_free=11.2, wall=9951
2023-07-22 23:28:32 | INFO | train_inner | epoch 014:    147 / 1474 loss=3.401, trans_loss=3.399, nll_loss=1.525, w2v_ctc_loss=0.896, task_loss=0.926, contrastive_loss=0.085, total=4080.86, n_correct=2566.22, ppl=2.88, accuracy=62.884, wps=11840.4, ups=0.97, wpb=12203.2, bsz=449.3, num_updates=19300, lr=0.000101797, gnorm=0.38, clip=0, loss_scale=64, train_wall=103, gb_free=17.1, wall=10054
2023-07-22 23:30:16 | INFO | train_inner | epoch 014:    247 / 1474 loss=3.43, trans_loss=3.408, nll_loss=1.538, w2v_ctc_loss=0.901, task_loss=0.965, contrastive_loss=0.217, total=4106.97, n_correct=2572.99, ppl=2.9, accuracy=62.649, wps=11781.8, ups=0.96, wpb=12224.4, bsz=440, num_updates=19400, lr=0.000101535, gnorm=0.381, clip=0, loss_scale=64, train_wall=103, gb_free=12.7, wall=10158
2023-07-22 23:32:00 | INFO | train_inner | epoch 014:    347 / 1474 loss=3.396, trans_loss=3.389, nll_loss=1.522, w2v_ctc_loss=0.894, task_loss=0.84, contrastive_loss=0.134, total=4179.8, n_correct=2629.93, ppl=2.87, accuracy=62.92, wps=11995.6, ups=0.96, wpb=12454.9, bsz=483.8, num_updates=19500, lr=0.000101274, gnorm=0.378, clip=0, loss_scale=64, train_wall=103, gb_free=17.4, wall=10262
2023-07-22 23:33:44 | INFO | train_inner | epoch 014:    447 / 1474 loss=3.407, trans_loss=3.406, nll_loss=1.537, w2v_ctc_loss=0.897, task_loss=0.943, contrastive_loss=0.081, total=4120.38, n_correct=2577.89, ppl=2.9, accuracy=62.564, wps=11787.1, ups=0.96, wpb=12283.1, bsz=444.5, num_updates=19600, lr=0.000101015, gnorm=0.38, clip=0, loss_scale=64, train_wall=104, gb_free=17.3, wall=10366
2023-07-22 23:35:29 | INFO | train_inner | epoch 014:    547 / 1474 loss=3.441, trans_loss=3.413, nll_loss=1.545, w2v_ctc_loss=0.922, task_loss=0.968, contrastive_loss=0.126, total=4089.86, n_correct=2549.26, ppl=2.92, accuracy=62.331, wps=11717.4, ups=0.96, wpb=12262.9, bsz=443.3, num_updates=19700, lr=0.000100759, gnorm=0.388, clip=0, loss_scale=64, train_wall=104, gb_free=12.4, wall=10471
2023-07-22 23:37:13 | INFO | train_inner | epoch 014:    647 / 1474 loss=3.435, trans_loss=3.412, nll_loss=1.545, w2v_ctc_loss=0.908, task_loss=0.916, contrastive_loss=0.185, total=4158.94, n_correct=2598.25, ppl=2.92, accuracy=62.474, wps=11909.4, ups=0.96, wpb=12415.4, bsz=460, num_updates=19800, lr=0.000100504, gnorm=0.386, clip=0, loss_scale=64, train_wall=104, gb_free=16.4, wall=10575
2023-07-22 23:38:57 | INFO | train_inner | epoch 014:    747 / 1474 loss=3.413, trans_loss=3.406, nll_loss=1.538, w2v_ctc_loss=0.904, task_loss=0.89, contrastive_loss=0.096, total=4150.03, n_correct=2603.97, ppl=2.9, accuracy=62.746, wps=11931, ups=0.96, wpb=12407.3, bsz=465.5, num_updates=19900, lr=0.000100251, gnorm=0.381, clip=0, loss_scale=64, train_wall=103, gb_free=15.8, wall=10679
2023-07-22 23:40:41 | INFO | train_inner | epoch 014:    847 / 1474 loss=3.431, trans_loss=3.401, nll_loss=1.534, w2v_ctc_loss=0.903, task_loss=0.875, contrastive_loss=0.241, total=4162.8, n_correct=2607.25, ppl=2.9, accuracy=62.632, wps=11930.8, ups=0.96, wpb=12422.9, bsz=475.8, num_updates=20000, lr=0.0001, gnorm=0.384, clip=0, loss_scale=64, train_wall=104, gb_free=17.2, wall=10783
2023-07-22 23:40:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-22 23:41:06 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.227 | trans_loss 5.614 | nll_loss 2.897 | w2v_ctc_loss 1.325 | task_loss 4.626 | contrastive_loss 0.263 | total 4003.4 | n_correct 2448.5 | ppl 7.45 | accuracy 61.161 | uer 17.227 | wer 18.851 | raw_wer 18.851 | bleu 19.23 | wps 2081.1 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 19.7
2023-07-22 23:41:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-07-22 23:41:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_14_20000.pt
2023-07-22 23:41:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_14_20000.pt
2023-07-22 23:41:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 19.23) (writing took 15.70414263010025 seconds)
mt_weight tensor(1., device='cuda:0')
asr_weight tensor(0.0009, device='cuda:0')
2023-07-22 23:42:43 | INFO | train_inner | epoch 014:    947 / 1474 loss=4.329, trans_loss=5.067, nll_loss=2.297, w2v_ctc_loss=0.687, task_loss=1.384, contrastive_loss=0.074, total=4159.46, n_correct=2592.4, ppl=4.91, accuracy=62.325, wps=6855.3, ups=0.82, wpb=8378.4, bsz=309.1, num_updates=20100, lr=9.97509e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=81, gb_free=15.6, wall=10905
2023-07-22 23:44:06 | INFO | train_inner | epoch 014:   1047 / 1474 loss=4.345, trans_loss=5.096, nll_loss=2.311, w2v_ctc_loss=0.67, task_loss=1.369, contrastive_loss=0.139, total=4155.93, n_correct=2593.86, ppl=4.96, accuracy=62.413, wps=10131.2, ups=1.22, wpb=8310, bsz=305.9, num_updates=20200, lr=9.95037e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=82, gb_free=16.7, wall=10987
2023-07-22 23:45:28 | INFO | train_inner | epoch 014:   1147 / 1474 loss=4.352, trans_loss=5.095, nll_loss=2.31, w2v_ctc_loss=0.683, task_loss=1.285, contrastive_loss=0.365, total=4228.09, n_correct=2630.08, ppl=4.96, accuracy=62.205, wps=10285.4, ups=1.22, wpb=8439, bsz=326.3, num_updates=20300, lr=9.92583e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=82, gb_free=17.7, wall=11069
2023-07-22 23:46:48 | INFO | train_inner | epoch 014:   1247 / 1474 loss=4.367, trans_loss=5.108, nll_loss=2.323, w2v_ctc_loss=0.695, task_loss=1.599, contrastive_loss=0.055, total=4027.71, n_correct=2504.82, ppl=5.01, accuracy=62.19, wps=10072.7, ups=1.25, wpb=8067.4, bsz=273.6, num_updates=20400, lr=9.90148e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=80, gb_free=17, wall=11150
2023-07-22 23:48:09 | INFO | train_inner | epoch 014:   1347 / 1474 loss=4.335, trans_loss=5.093, nll_loss=2.308, w2v_ctc_loss=0.67, task_loss=1.318, contrastive_loss=0.072, total=4198.71, n_correct=2624.7, ppl=4.95, accuracy=62.512, wps=10330.3, ups=1.23, wpb=8395.6, bsz=315.4, num_updates=20500, lr=9.8773e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=81, gb_free=16.9, wall=11231
2023-07-22 23:49:30 | INFO | train_inner | epoch 014:   1447 / 1474 loss=4.352, trans_loss=5.103, nll_loss=2.32, w2v_ctc_loss=0.681, task_loss=1.354, contrastive_loss=0.115, total=4140.5, n_correct=2580.47, ppl=4.99, accuracy=62.323, wps=10221.1, ups=1.23, wpb=8288.3, bsz=307.1, num_updates=20600, lr=9.85329e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=81, gb_free=17.7, wall=11312
2023-07-22 23:49:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1., device='cuda:4')
asr_weight tensor(0.0009, device='cuda:4')
mt_weight tensor(1., device='cuda:7')
asr_weight tensor(0.0009, device='cuda:7')
mt_weight tensor(1., device='cuda:5')
asr_weight tensor(0.0009, device='cuda:5')
mt_weight tensor(1., device='cuda:1')
asr_weight tensor(0.0009, device='cuda:1')
mt_weight tensor(1., device='cuda:6')
asr_weight tensor(0.0009, device='cuda:6')
mt_weight tensor(1., device='cuda:2')
asr_weight tensor(0.0009, device='cuda:2')
mt_weight tensor(1., device='cuda:3')
asr_weight tensor(0.0009, device='cuda:3')
2023-07-22 23:50:14 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 4.233 | trans_loss 5.613 | nll_loss 2.896 | w2v_ctc_loss 1.348 | task_loss 4.618 | contrastive_loss 0.261 | total 4003.4 | n_correct 2449.6 | ppl 7.45 | accuracy 61.188 | uer 17.453 | wer 19.198 | raw_wer 19.198 | bleu 19.35 | wps 2297.3 | wpb 4003.4 | bsz 141.8 | num_updates 20627 | best_bleu 19.7
2023-07-22 23:50:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20627 updates
2023-07-22 23:50:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.3500.pt
2023-07-22 23:50:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.3500.pt
2023-07-22 23:50:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.3500.pt (epoch 14 @ 20627 updates, score 19.35) (writing took 11.56500775553286 seconds)
2023-07-22 23:50:26 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-07-22 23:50:26 | INFO | train | epoch 014 | loss 3.728 | trans_loss 3.965 | nll_loss 1.793 | w2v_ctc_loss 0.828 | task_loss 1.066 | contrastive_loss 0.141 | total 4138.65 | n_correct 2587.69 | ppl 3.46 | accuracy 62.525 | wps 10616.4 | ups 1 | wpb 10623.1 | bsz 393.9 | num_updates 20627 | lr 9.84684e-05 | gnorm 0.449 | clip 0 | loss_scale 64 | train_wall 1383 | gb_free 16.6 | wall 11368
2023-07-22 23:50:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-22 23:50:26 | INFO | fairseq.trainer | begin training epoch 15
2023-07-22 23:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-22 23:51:33 | INFO | train_inner | epoch 015:     73 / 1474 loss=4.323, trans_loss=5.072, nll_loss=2.28, w2v_ctc_loss=0.664, task_loss=1.375, contrastive_loss=0.16, total=4083.93, n_correct=2559.7, ppl=4.86, accuracy=62.677, wps=6632, ups=0.81, wpb=8166.9, bsz=300.1, num_updates=20700, lr=9.82946e-05, gnorm=0.538, clip=0, loss_scale=64, train_wall=80, gb_free=15.8, wall=11435
2023-07-22 23:52:54 | INFO | train_inner | epoch 015:    173 / 1474 loss=4.321, trans_loss=5.069, nll_loss=2.274, w2v_ctc_loss=0.678, task_loss=1.418, contrastive_loss=0.07, total=4122.67, n_correct=2590.3, ppl=4.84, accuracy=62.831, wps=10171, ups=1.23, wpb=8245.4, bsz=299.1, num_updates=20800, lr=9.80581e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=81, gb_free=17.3, wall=11516
2023-07-22 23:54:15 | INFO | train_inner | epoch 015:    273 / 1474 loss=4.314, trans_loss=5.068, nll_loss=2.274, w2v_ctc_loss=0.666, task_loss=1.321, contrastive_loss=0.061, total=4190.11, n_correct=2643.21, ppl=4.84, accuracy=63.082, wps=10327.5, ups=1.23, wpb=8378.8, bsz=312.6, num_updates=20900, lr=9.78232e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=81, gb_free=17.3, wall=11597
2023-07-22 23:55:36 | INFO | train_inner | epoch 015:    373 / 1474 loss=4.317, trans_loss=5.068, nll_loss=2.273, w2v_ctc_loss=0.666, task_loss=1.412, contrastive_loss=0.083, total=4150.33, n_correct=2610.37, ppl=4.83, accuracy=62.895, wps=10246.1, ups=1.24, wpb=8275.8, bsz=301, num_updates=21000, lr=9.759e-05, gnorm=0.539, clip=0, loss_scale=64, train_wall=80, gb_free=15.7, wall=11678
2023-07-22 23:56:57 | INFO | train_inner | epoch 015:    473 / 1474 loss=4.33, trans_loss=5.074, nll_loss=2.282, w2v_ctc_loss=0.668, task_loss=1.407, contrastive_loss=0.178, total=4082.7, n_correct=2559.11, ppl=4.86, accuracy=62.682, wps=10102.7, ups=1.24, wpb=8165.9, bsz=298.5, num_updates=21100, lr=9.73585e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=80, gb_free=17.2, wall=11759
2023-07-22 23:58:18 | INFO | train_inner | epoch 015:    573 / 1474 loss=4.33, trans_loss=5.074, nll_loss=2.281, w2v_ctc_loss=0.676, task_loss=1.451, contrastive_loss=0.066, total=4130.96, n_correct=2597.32, ppl=4.86, accuracy=62.874, wps=10174.1, ups=1.23, wpb=8272.7, bsz=293.4, num_updates=21200, lr=9.71286e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=81, gb_free=17.4, wall=11840
2023-07-22 23:59:40 | INFO | train_inner | epoch 015:    673 / 1474 loss=4.322, trans_loss=5.068, nll_loss=2.275, w2v_ctc_loss=0.669, task_loss=1.365, contrastive_loss=0.139, total=4138.41, n_correct=2608.02, ppl=4.84, accuracy=63.02, wps=10194.2, ups=1.23, wpb=8291.4, bsz=309.4, num_updates=21300, lr=9.69003e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=81, gb_free=17.1, wall=11922
2023-07-23 00:01:01 | INFO | train_inner | epoch 015:    773 / 1474 loss=4.332, trans_loss=5.084, nll_loss=2.295, w2v_ctc_loss=0.678, task_loss=1.379, contrastive_loss=0.087, total=4186.48, n_correct=2624.04, ppl=4.91, accuracy=62.679, wps=10273.6, ups=1.23, wpb=8351.6, bsz=307.9, num_updates=21400, lr=9.66736e-05, gnorm=0.54, clip=0, loss_scale=128, train_wall=81, gb_free=16.9, wall=12003
2023-07-23 00:02:22 | INFO | train_inner | epoch 015:    873 / 1474 loss=4.343, trans_loss=5.086, nll_loss=2.298, w2v_ctc_loss=0.68, task_loss=1.499, contrastive_loss=0.067, total=4054.09, n_correct=2537.19, ppl=4.92, accuracy=62.583, wps=10089.1, ups=1.24, wpb=8135.5, bsz=286.2, num_updates=21500, lr=9.64486e-05, gnorm=0.547, clip=0, loss_scale=128, train_wall=80, gb_free=16, wall=12083
2023-07-23 00:03:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-23 00:03:43 | INFO | train_inner | epoch 015:    974 / 1474 loss=4.319, trans_loss=5.069, nll_loss=2.276, w2v_ctc_loss=0.666, task_loss=1.392, contrastive_loss=0.126, total=4112.28, n_correct=2586.69, ppl=4.84, accuracy=62.902, wps=10036.2, ups=1.22, wpb=8198, bsz=299.3, num_updates=21600, lr=9.6225e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=81, gb_free=17.7, wall=12165
2023-07-23 00:05:05 | INFO | train_inner | epoch 015:   1074 / 1474 loss=4.336, trans_loss=5.083, nll_loss=2.296, w2v_ctc_loss=0.667, task_loss=1.28, contrastive_loss=0.309, total=4192.24, n_correct=2628.71, ppl=4.91, accuracy=62.704, wps=10256.8, ups=1.22, wpb=8373.3, bsz=325.2, num_updates=21700, lr=9.60031e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=81, gb_free=17.3, wall=12247
2023-07-23 00:06:26 | INFO | train_inner | epoch 015:   1174 / 1474 loss=4.308, trans_loss=5.065, nll_loss=2.273, w2v_ctc_loss=0.661, task_loss=1.234, contrastive_loss=0.116, total=4185, n_correct=2642.36, ppl=4.83, accuracy=63.139, wps=10340.6, ups=1.24, wpb=8369.7, bsz=329.3, num_updates=21800, lr=9.57826e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=80, gb_free=16.4, wall=12328
2023-07-23 00:07:47 | INFO | train_inner | epoch 015:   1274 / 1474 loss=4.331, trans_loss=5.077, nll_loss=2.287, w2v_ctc_loss=0.678, task_loss=1.399, contrastive_loss=0.07, total=4152.04, n_correct=2613.04, ppl=4.88, accuracy=62.934, wps=10238.7, ups=1.23, wpb=8309.2, bsz=303.7, num_updates=21900, lr=9.55637e-05, gnorm=0.538, clip=0, loss_scale=64, train_wall=81, gb_free=16.7, wall=12409
2023-07-23 00:09:08 | INFO | train_inner | epoch 015:   1374 / 1474 loss=4.335, trans_loss=5.082, nll_loss=2.292, w2v_ctc_loss=0.676, task_loss=1.42, contrastive_loss=0.058, total=4100.21, n_correct=2578.72, ppl=4.9, accuracy=62.892, wps=10179.6, ups=1.24, wpb=8205.1, bsz=293.6, num_updates=22000, lr=9.53463e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=80, gb_free=17.6, wall=12489
2023-07-23 00:09:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 00:09:32 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.212 | trans_loss 5.608 | nll_loss 2.888 | w2v_ctc_loss 1.292 | task_loss 4.612 | contrastive_loss 0.256 | total 4003.4 | n_correct 2458.2 | ppl 7.4 | accuracy 61.403 | uer 17.039 | wer 18.802 | raw_wer 18.802 | bleu 19.57 | wps 2044.6 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 19.7
2023-07-23 00:09:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-07-23 00:09:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_15_22000.pt
2023-07-23 00:09:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_15_22000.pt
2023-07-23 00:09:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 19.57) (writing took 13.707275012508035 seconds)
2023-07-23 00:11:11 | INFO | train_inner | epoch 015:   1474 / 1474 loss=4.332, trans_loss=5.08, nll_loss=2.292, w2v_ctc_loss=0.672, task_loss=1.332, contrastive_loss=0.149, total=4141.17, n_correct=2597.95, ppl=4.9, accuracy=62.735, wps=6749.5, ups=0.81, wpb=8307.8, bsz=314.3, num_updates=22100, lr=9.51303e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=82, gb_free=17.2, wall=12613
2023-07-23 00:11:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 00:11:34 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 4.225 | trans_loss 5.608 | nll_loss 2.884 | w2v_ctc_loss 1.333 | task_loss 4.645 | contrastive_loss 0.258 | total 4003.4 | n_correct 2456.6 | ppl 7.38 | accuracy 61.363 | uer 17.251 | wer 19.112 | raw_wer 19.112 | bleu 19.63 | wps 2110.8 | wpb 4003.4 | bsz 141.8 | num_updates 22100 | best_bleu 19.7
2023-07-23 00:11:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22100 updates
2023-07-23 00:11:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6309.pt
2023-07-23 00:11:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6309.pt
2023-07-23 00:11:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6309.pt (epoch 15 @ 22100 updates, score 19.63) (writing took 13.550964877009392 seconds)
2023-07-23 00:11:49 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-07-23 00:11:49 | INFO | train | epoch 015 | loss 4.326 | trans_loss 5.074 | nll_loss 2.282 | w2v_ctc_loss 0.671 | task_loss 1.374 | contrastive_loss 0.118 | total 4137.64 | n_correct 2601 | ppl 4.86 | accuracy 62.862 | wps 9504.3 | ups 1.15 | wpb 8275.3 | bsz 305.4 | num_updates 22100 | lr 9.51303e-05 | gnorm 0.54 | clip 0 | loss_scale 64 | train_wall 1187 | gb_free 17.2 | wall 12650
2023-07-23 00:11:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 00:11:49 | INFO | fairseq.trainer | begin training epoch 16
2023-07-23 00:11:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 00:13:18 | INFO | train_inner | epoch 016:    100 / 1474 loss=4.288, trans_loss=5.04, nll_loss=2.238, w2v_ctc_loss=0.654, task_loss=1.309, contrastive_loss=0.088, total=4126.22, n_correct=2622.33, ppl=4.72, accuracy=63.553, wps=6479.9, ups=0.78, wpb=8260.9, bsz=315.6, num_updates=22200, lr=9.49158e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=80, gb_free=16.3, wall=12740
2023-07-23 00:14:39 | INFO | train_inner | epoch 016:    200 / 1474 loss=4.297, trans_loss=5.043, nll_loss=2.241, w2v_ctc_loss=0.651, task_loss=1.415, contrastive_loss=0.063, total=4100.6, n_correct=2601.57, ppl=4.73, accuracy=63.444, wps=10191.8, ups=1.24, wpb=8229.9, bsz=296.8, num_updates=22300, lr=9.47027e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=80, gb_free=13, wall=12821
2023-07-23 00:16:00 | INFO | train_inner | epoch 016:    300 / 1474 loss=4.311, trans_loss=5.059, nll_loss=2.264, w2v_ctc_loss=0.672, task_loss=1.363, contrastive_loss=0.137, total=4166.94, n_correct=2634.47, ppl=4.8, accuracy=63.223, wps=10207, ups=1.23, wpb=8292.7, bsz=308.9, num_updates=22400, lr=9.44911e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=81, gb_free=17.3, wall=12902
2023-07-23 00:17:21 | INFO | train_inner | epoch 016:    400 / 1474 loss=4.322, trans_loss=5.06, nll_loss=2.263, w2v_ctc_loss=0.666, task_loss=1.465, contrastive_loss=0.149, total=4073.3, n_correct=2570.95, ppl=4.8, accuracy=63.117, wps=10075.1, ups=1.23, wpb=8159.8, bsz=288.1, num_updates=22500, lr=9.42809e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=80, gb_free=17.2, wall=12983
2023-07-23 00:18:42 | INFO | train_inner | epoch 016:    500 / 1474 loss=4.298, trans_loss=5.05, nll_loss=2.253, w2v_ctc_loss=0.665, task_loss=1.321, contrastive_loss=0.098, total=4174.67, n_correct=2646.79, ppl=4.77, accuracy=63.401, wps=10277.1, ups=1.23, wpb=8336.5, bsz=319.1, num_updates=22600, lr=9.40721e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=81, gb_free=16.1, wall=13064
2023-07-23 00:20:03 | INFO | train_inner | epoch 016:    600 / 1474 loss=4.311, trans_loss=5.059, nll_loss=2.263, w2v_ctc_loss=0.664, task_loss=1.383, contrastive_loss=0.058, total=4124.65, n_correct=2607.17, ppl=4.8, accuracy=63.209, wps=10232.5, ups=1.24, wpb=8247.4, bsz=297.6, num_updates=22700, lr=9.38647e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=80, gb_free=16.4, wall=13145
2023-07-23 00:21:24 | INFO | train_inner | epoch 016:    700 / 1474 loss=4.312, trans_loss=5.058, nll_loss=2.262, w2v_ctc_loss=0.669, task_loss=1.41, contrastive_loss=0.061, total=4095.49, n_correct=2589.6, ppl=4.8, accuracy=63.231, wps=10158.6, ups=1.24, wpb=8188.3, bsz=296.3, num_updates=22800, lr=9.36586e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=80, gb_free=16.4, wall=13225
2023-07-23 00:22:44 | INFO | train_inner | epoch 016:    800 / 1474 loss=4.307, trans_loss=5.055, nll_loss=2.259, w2v_ctc_loss=0.654, task_loss=1.321, contrastive_loss=0.122, total=4174.94, n_correct=2644.84, ppl=4.79, accuracy=63.35, wps=10348.6, ups=1.24, wpb=8359, bsz=310.9, num_updates=22900, lr=9.34539e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=80, gb_free=16.6, wall=13306
2023-07-23 00:24:05 | INFO | train_inner | epoch 016:    900 / 1474 loss=4.31, trans_loss=5.059, nll_loss=2.264, w2v_ctc_loss=0.661, task_loss=1.329, contrastive_loss=0.113, total=4163.19, n_correct=2633.95, ppl=4.8, accuracy=63.268, wps=10345.6, ups=1.24, wpb=8323.1, bsz=310.6, num_updates=23000, lr=9.32505e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=80, gb_free=17, wall=13387
2023-07-23 00:25:26 | INFO | train_inner | epoch 016:   1000 / 1474 loss=4.323, trans_loss=5.064, nll_loss=2.269, w2v_ctc_loss=0.676, task_loss=1.433, contrastive_loss=0.112, total=4103.45, n_correct=2584.92, ppl=4.82, accuracy=62.994, wps=10065.4, ups=1.22, wpb=8222.1, bsz=298.1, num_updates=23100, lr=9.30484e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=81, gb_free=15.1, wall=13468
2023-07-23 00:26:48 | INFO | train_inner | epoch 016:   1100 / 1474 loss=4.329, trans_loss=5.071, nll_loss=2.28, w2v_ctc_loss=0.674, task_loss=1.464, contrastive_loss=0.089, total=4119.27, n_correct=2599.02, ppl=4.86, accuracy=63.094, wps=10111.3, ups=1.22, wpb=8256.4, bsz=295.3, num_updates=23200, lr=9.28477e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=81, gb_free=17.9, wall=13550
2023-07-23 00:28:10 | INFO | train_inner | epoch 016:   1200 / 1474 loss=4.32, trans_loss=5.065, nll_loss=2.272, w2v_ctc_loss=0.659, task_loss=1.389, contrastive_loss=0.183, total=4165.11, n_correct=2625.49, ppl=4.83, accuracy=63.035, wps=10210.9, ups=1.23, wpb=8328.2, bsz=308.7, num_updates=23300, lr=9.26482e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=81, gb_free=16.9, wall=13632
2023-07-23 00:29:31 | INFO | train_inner | epoch 016:   1300 / 1474 loss=4.321, trans_loss=5.066, nll_loss=2.274, w2v_ctc_loss=0.672, task_loss=1.353, contrastive_loss=0.164, total=4134.61, n_correct=2610.58, ppl=4.84, accuracy=63.14, wps=10172, ups=1.23, wpb=8274.4, bsz=310.8, num_updates=23400, lr=9.245e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=81, gb_free=16.9, wall=13713
2023-07-23 00:30:53 | INFO | train_inner | epoch 016:   1400 / 1474 loss=4.31, trans_loss=5.063, nll_loss=2.271, w2v_ctc_loss=0.669, task_loss=1.304, contrastive_loss=0.095, total=4206.33, n_correct=2655.62, ppl=4.83, accuracy=63.134, wps=10222.4, ups=1.22, wpb=8396.9, bsz=322.2, num_updates=23500, lr=9.22531e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=82, gb_free=15.7, wall=13795
2023-07-23 00:31:53 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 00:32:17 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.602 | nll_loss 2.884 | w2v_ctc_loss 1.317 | task_loss 4.608 | contrastive_loss 0.256 | total 4003.4 | n_correct 2465.7 | ppl 7.38 | accuracy 61.59 | uer 17.081 | wer 18.817 | raw_wer 18.817 | bleu 20.09 | wps 2074.2 | wpb 4003.4 | bsz 141.8 | num_updates 23574 | best_bleu 20.09
2023-07-23 00:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23574 updates
2023-07-23 00:32:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-23 00:32:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt
2023-07-23 00:32:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_best.pt (epoch 16 @ 23574 updates, score 20.09) (writing took 19.49459635093808 seconds)
2023-07-23 00:32:37 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-07-23 00:32:37 | INFO | train | epoch 016 | loss 4.312 | trans_loss 5.058 | nll_loss 2.263 | w2v_ctc_loss 0.665 | task_loss 1.374 | contrastive_loss 0.119 | total 4138.65 | n_correct 2616.74 | ppl 4.8 | accuracy 63.227 | wps 9771.3 | ups 1.18 | wpb 8277.3 | bsz 305.7 | num_updates 23574 | lr 9.21082e-05 | gnorm 0.541 | clip 0 | loss_scale 64 | train_wall 1188 | gb_free 15.6 | wall 13899
2023-07-23 00:32:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 00:32:37 | INFO | fairseq.trainer | begin training epoch 17
2023-07-23 00:32:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 00:33:07 | INFO | train_inner | epoch 017:     26 / 1474 loss=4.307, trans_loss=5.05, nll_loss=2.253, w2v_ctc_loss=0.654, task_loss=1.383, contrastive_loss=0.227, total=4152.31, n_correct=2634.42, ppl=4.77, accuracy=63.445, wps=6191.8, ups=0.75, wpb=8283.1, bsz=304.6, num_updates=23600, lr=9.20575e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=81, gb_free=14.1, wall=13929
2023-07-23 00:34:28 | INFO | train_inner | epoch 017:    126 / 1474 loss=4.294, trans_loss=5.036, nll_loss=2.233, w2v_ctc_loss=0.667, task_loss=1.418, contrastive_loss=0.064, total=4118.91, n_correct=2619.87, ppl=4.7, accuracy=63.606, wps=10143.6, ups=1.23, wpb=8228.1, bsz=295.8, num_updates=23700, lr=9.1863e-05, gnorm=0.543, clip=0, loss_scale=128, train_wall=81, gb_free=16.6, wall=14010
2023-07-23 00:34:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-23 00:35:50 | INFO | train_inner | epoch 017:    227 / 1474 loss=4.29, trans_loss=5.034, nll_loss=2.231, w2v_ctc_loss=0.646, task_loss=1.302, contrastive_loss=0.23, total=4156.38, n_correct=2650.66, ppl=4.7, accuracy=63.773, wps=10104.8, ups=1.22, wpb=8305, bsz=317.2, num_updates=23800, lr=9.16698e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=82, gb_free=17.1, wall=14092
2023-07-23 00:37:11 | INFO | train_inner | epoch 017:    327 / 1474 loss=4.296, trans_loss=5.037, nll_loss=2.235, w2v_ctc_loss=0.66, task_loss=1.365, contrastive_loss=0.233, total=4156.91, n_correct=2641.88, ppl=4.71, accuracy=63.554, wps=10276, ups=1.24, wpb=8291.6, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=80, gb_free=17.6, wall=14173
2023-07-23 00:38:32 | INFO | train_inner | epoch 017:    427 / 1474 loss=4.295, trans_loss=5.042, nll_loss=2.24, w2v_ctc_loss=0.656, task_loss=1.359, contrastive_loss=0.065, total=4146.43, n_correct=2642.28, ppl=4.72, accuracy=63.724, wps=10245, ups=1.23, wpb=8320.5, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=81, gb_free=16.7, wall=14254
2023-07-23 00:38:32 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 00:38:58 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.238 | trans_loss 5.614 | nll_loss 2.889 | w2v_ctc_loss 1.365 | task_loss 4.633 | contrastive_loss 0.257 | total 4003.4 | n_correct 2455.2 | ppl 7.41 | accuracy 61.328 | uer 17.315 | wer 19.093 | raw_wer 19.093 | bleu 19.63 | wps 1887.4 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 20.09
2023-07-23 00:38:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-07-23 00:38:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_17_24000.pt
2023-07-23 00:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_17_24000.pt
2023-07-23 00:39:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 19.63) (writing took 15.820229226723313 seconds)
2023-07-23 00:40:36 | INFO | train_inner | epoch 017:    527 / 1474 loss=4.299, trans_loss=5.044, nll_loss=2.244, w2v_ctc_loss=0.666, task_loss=1.428, contrastive_loss=0.112, total=4182.1, n_correct=2652.47, ppl=4.74, accuracy=63.424, wps=6722.1, ups=0.81, wpb=8346.4, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=82, gb_free=17, wall=14378
2023-07-23 00:41:58 | INFO | train_inner | epoch 017:    627 / 1474 loss=4.293, trans_loss=5.042, nll_loss=2.242, w2v_ctc_loss=0.653, task_loss=1.387, contrastive_loss=0.059, total=4167.27, n_correct=2654.5, ppl=4.73, accuracy=63.699, wps=10246.1, ups=1.23, wpb=8316.3, bsz=302.2, num_updates=24200, lr=9.09091e-05, gnorm=0.538, clip=0, loss_scale=64, train_wall=81, gb_free=11.3, wall=14459
2023-07-23 00:43:19 | INFO | train_inner | epoch 017:    727 / 1474 loss=4.307, trans_loss=5.051, nll_loss=2.254, w2v_ctc_loss=0.669, task_loss=1.36, contrastive_loss=0.107, total=4166.12, n_correct=2639.87, ppl=4.77, accuracy=63.365, wps=10286.1, ups=1.23, wpb=8334.7, bsz=308.1, num_updates=24300, lr=9.07218e-05, gnorm=0.539, clip=0, loss_scale=64, train_wall=80, gb_free=16.5, wall=14540
2023-07-23 00:44:39 | INFO | train_inner | epoch 017:    827 / 1474 loss=4.307, trans_loss=5.049, nll_loss=2.25, w2v_ctc_loss=0.667, task_loss=1.389, contrastive_loss=0.072, total=4091.64, n_correct=2594.39, ppl=4.76, accuracy=63.407, wps=10205.9, ups=1.25, wpb=8190.8, bsz=295.3, num_updates=24400, lr=9.05357e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=80, gb_free=17.4, wall=14621
2023-07-23 00:45:58 | INFO | train_inner | epoch 017:    927 / 1474 loss=4.301, trans_loss=5.051, nll_loss=2.254, w2v_ctc_loss=0.659, task_loss=1.351, contrastive_loss=0.071, total=4106.83, n_correct=2607.64, ppl=4.77, accuracy=63.495, wps=10298.7, ups=1.25, wpb=8208.4, bsz=304.6, num_updates=24500, lr=9.03508e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=79, gb_free=16, wall=14700
2023-07-23 00:47:19 | INFO | train_inner | epoch 017:   1027 / 1474 loss=4.295, trans_loss=5.043, nll_loss=2.243, w2v_ctc_loss=0.661, task_loss=1.352, contrastive_loss=0.074, total=4115.49, n_correct=2614.74, ppl=4.73, accuracy=63.534, wps=10226.7, ups=1.24, wpb=8229.1, bsz=305.8, num_updates=24600, lr=9.0167e-05, gnorm=0.542, clip=0, loss_scale=64, train_wall=80, gb_free=16.8, wall=14781
2023-07-23 00:48:39 | INFO | train_inner | epoch 017:   1127 / 1474 loss=4.297, trans_loss=5.044, nll_loss=2.244, w2v_ctc_loss=0.649, task_loss=1.429, contrastive_loss=0.059, total=4078.39, n_correct=2596.79, ppl=4.74, accuracy=63.672, wps=10195, ups=1.25, wpb=8165.8, bsz=293.7, num_updates=24700, lr=8.99843e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=80, gb_free=15.8, wall=14861
2023-07-23 00:50:01 | INFO | train_inner | epoch 017:   1227 / 1474 loss=4.305, trans_loss=5.049, nll_loss=2.252, w2v_ctc_loss=0.651, task_loss=1.329, contrastive_loss=0.305, total=4173.49, n_correct=2639.41, ppl=4.76, accuracy=63.242, wps=10201.9, ups=1.22, wpb=8354.6, bsz=323.7, num_updates=24800, lr=8.98027e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=81, gb_free=16.3, wall=14943
2023-07-23 00:51:22 | INFO | train_inner | epoch 017:   1327 / 1474 loss=4.299, trans_loss=5.048, nll_loss=2.25, w2v_ctc_loss=0.649, task_loss=1.358, contrastive_loss=0.142, total=4156.28, n_correct=2639.42, ppl=4.76, accuracy=63.504, wps=10285.4, ups=1.24, wpb=8295.1, bsz=308, num_updates=24900, lr=8.96221e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=80, gb_free=17.9, wall=15024
2023-07-23 00:52:43 | INFO | train_inner | epoch 017:   1427 / 1474 loss=4.305, trans_loss=5.051, nll_loss=2.254, w2v_ctc_loss=0.655, task_loss=1.389, contrastive_loss=0.064, total=4112.95, n_correct=2613.59, ppl=4.77, accuracy=63.545, wps=10217.7, ups=1.24, wpb=8265.7, bsz=303.2, num_updates=25000, lr=8.94427e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=80, gb_free=17, wall=15104
mt_weight tensor(1., device='cuda:0')
asr_weight tensor(0.0009, device='cuda:0')
2023-07-23 00:53:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1., device='cuda:7')
asr_weight tensor(0.0009, device='cuda:7')
mt_weight tensor(1., device='cuda:6')
asr_weight tensor(0.0009, device='cuda:6')
mt_weight tensor(1., device='cuda:4')
asr_weight tensor(0.0009, device='cuda:4')
mt_weight tensor(1., device='cuda:5')
asr_weight tensor(0.0009, device='cuda:5')
mt_weight tensor(1., device='cuda:3')
asr_weight tensor(0.0009, device='cuda:3')
mt_weight tensor(1., device='cuda:1')
asr_weight tensor(0.0009, device='cuda:1')
mt_weight tensor(1., device='cuda:2')
asr_weight tensor(0.0009, device='cuda:2')
2023-07-23 00:53:44 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 4.239 | trans_loss 5.603 | nll_loss 2.881 | w2v_ctc_loss 1.392 | task_loss 4.657 | contrastive_loss 0.258 | total 4003.4 | n_correct 2462.9 | ppl 7.36 | accuracy 61.52 | uer 17.378 | wer 19.019 | raw_wer 19.019 | bleu 19.85 | wps 2163 | wpb 4003.4 | bsz 141.8 | num_updates 25047 | best_bleu 20.09
2023-07-23 00:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25047 updates
2023-07-23 00:53:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8508.pt
2023-07-23 00:53:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8508.pt
2023-07-23 00:53:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8508.pt (epoch 17 @ 25047 updates, score 19.85) (writing took 13.979488426819444 seconds)
2023-07-23 00:53:59 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-07-23 00:53:59 | INFO | train | epoch 017 | loss 4.299 | trans_loss 5.044 | nll_loss 2.244 | w2v_ctc_loss 0.658 | task_loss 1.373 | contrastive_loss 0.117 | total 4138.83 | n_correct 2630.06 | ppl 4.74 | accuracy 63.546 | wps 9513.3 | ups 1.15 | wpb 8277.7 | bsz 305.7 | num_updates 25047 | lr 8.93588e-05 | gnorm 0.543 | clip 0 | loss_scale 64 | train_wall 1186 | gb_free 16.6 | wall 15181
2023-07-23 00:53:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 00:53:59 | INFO | fairseq.trainer | begin training epoch 18
2023-07-23 00:53:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 00:54:51 | INFO | train_inner | epoch 018:     53 / 1474 loss=4.292, trans_loss=5.036, nll_loss=2.233, w2v_ctc_loss=0.667, task_loss=1.4, contrastive_loss=0.074, total=4139.04, n_correct=2630.85, ppl=4.7, accuracy=63.562, wps=6422.6, ups=0.78, wpb=8279.9, bsz=303.3, num_updates=25100, lr=8.92644e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=81, gb_free=17.3, wall=15233
2023-07-23 00:56:12 | INFO | train_inner | epoch 018:    153 / 1474 loss=4.273, trans_loss=5.017, nll_loss=2.209, w2v_ctc_loss=0.636, task_loss=1.309, contrastive_loss=0.198, total=4154.85, n_correct=2663.29, ppl=4.62, accuracy=64.101, wps=10309.4, ups=1.24, wpb=8300.4, bsz=312.7, num_updates=25200, lr=8.90871e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=80, gb_free=16.9, wall=15314
2023-07-23 00:57:33 | INFO | train_inner | epoch 018:    253 / 1474 loss=4.268, trans_loss=5.017, nll_loss=2.209, w2v_ctc_loss=0.649, task_loss=1.333, contrastive_loss=0.065, total=4162.72, n_correct=2677.67, ppl=4.62, accuracy=64.325, wps=10236.1, ups=1.23, wpb=8309.6, bsz=312.9, num_updates=25300, lr=8.89108e-05, gnorm=0.538, clip=0, loss_scale=64, train_wall=81, gb_free=16.4, wall=15395
2023-07-23 00:58:54 | INFO | train_inner | epoch 018:    353 / 1474 loss=4.284, trans_loss=5.028, nll_loss=2.223, w2v_ctc_loss=0.65, task_loss=1.393, contrastive_loss=0.079, total=4161.22, n_correct=2661.37, ppl=4.67, accuracy=63.956, wps=10230.2, ups=1.23, wpb=8319, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=81, gb_free=14.6, wall=15476
2023-07-23 01:00:16 | INFO | train_inner | epoch 018:    453 / 1474 loss=4.292, trans_loss=5.029, nll_loss=2.224, w2v_ctc_loss=0.65, task_loss=1.468, contrastive_loss=0.171, total=4092.36, n_correct=2606.98, ppl=4.67, accuracy=63.704, wps=10061.6, ups=1.23, wpb=8202.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=81, gb_free=16.9, wall=15558
2023-07-23 01:01:37 | INFO | train_inner | epoch 018:    553 / 1474 loss=4.267, trans_loss=5.02, nll_loss=2.214, w2v_ctc_loss=0.644, task_loss=1.234, contrastive_loss=0.081, total=4206.45, n_correct=2696.98, ppl=4.64, accuracy=64.115, wps=10446.5, ups=1.24, wpb=8423.5, bsz=328.9, num_updates=25600, lr=8.83883e-05, gnorm=0.539, clip=0, loss_scale=64, train_wall=80, gb_free=17.9, wall=15639
2023-07-23 01:02:58 | INFO | train_inner | epoch 018:    653 / 1474 loss=4.3, trans_loss=5.043, nll_loss=2.244, w2v_ctc_loss=0.655, task_loss=1.417, contrastive_loss=0.146, total=4097.96, n_correct=2610.99, ppl=4.74, accuracy=63.714, wps=10100.1, ups=1.23, wpb=8190.5, bsz=298.6, num_updates=25700, lr=8.82162e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=81, gb_free=12.6, wall=15720
2023-07-23 01:04:19 | INFO | train_inner | epoch 018:    753 / 1474 loss=4.295, trans_loss=5.037, nll_loss=2.237, w2v_ctc_loss=0.658, task_loss=1.311, contrastive_loss=0.238, total=4208.5, n_correct=2679.37, ppl=4.71, accuracy=63.666, wps=10324.9, ups=1.23, wpb=8414.3, bsz=322.6, num_updates=25800, lr=8.80451e-05, gnorm=0.542, clip=0, loss_scale=128, train_wall=81, gb_free=16.4, wall=15801
2023-07-23 01:05:40 | INFO | train_inner | epoch 018:    853 / 1474 loss=4.285, trans_loss=5.031, nll_loss=2.227, w2v_ctc_loss=0.646, task_loss=1.389, contrastive_loss=0.056, total=4166.07, n_correct=2659.09, ppl=4.68, accuracy=63.827, wps=10310.7, ups=1.24, wpb=8342.5, bsz=302.4, num_updates=25900, lr=8.7875e-05, gnorm=0.541, clip=0, loss_scale=128, train_wall=80, gb_free=16.5, wall=15882
2023-07-23 01:07:01 | INFO | train_inner | epoch 018:    953 / 1474 loss=4.271, trans_loss=5.025, nll_loss=2.221, w2v_ctc_loss=0.645, task_loss=1.276, contrastive_loss=0.079, total=4141.27, n_correct=2650.37, ppl=4.66, accuracy=63.999, wps=10278.4, ups=1.24, wpb=8264.3, bsz=316, num_updates=26000, lr=8.77058e-05, gnorm=0.546, clip=0, loss_scale=128, train_wall=80, gb_free=16.2, wall=15962
2023-07-23 01:07:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 01:07:25 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.194 | trans_loss 5.59 | nll_loss 2.863 | w2v_ctc_loss 1.276 | task_loss 4.616 | contrastive_loss 0.248 | total 4003.4 | n_correct 2467.1 | ppl 7.28 | accuracy 61.625 | uer 17.142 | wer 19.108 | raw_wer 19.108 | bleu 19.89 | wps 2029.4 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 20.09
2023-07-23 01:07:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-07-23 01:07:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_18_26000.pt
2023-07-23 01:07:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_18_26000.pt
2023-07-23 01:07:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 19.89) (writing took 15.183554271236062 seconds)
2023-07-23 01:09:03 | INFO | train_inner | epoch 018:   1053 / 1474 loss=4.285, trans_loss=5.032, nll_loss=2.229, w2v_ctc_loss=0.646, task_loss=1.43, contrastive_loss=0.067, total=4134.55, n_correct=2639.43, ppl=4.69, accuracy=63.838, wps=6775.9, ups=0.82, wpb=8269.2, bsz=300.8, num_updates=26100, lr=8.75376e-05, gnorm=0.543, clip=0, loss_scale=128, train_wall=81, gb_free=16.6, wall=16084
2023-07-23 01:09:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-23 01:10:24 | INFO | train_inner | epoch 018:   1154 / 1474 loss=4.286, trans_loss=5.03, nll_loss=2.227, w2v_ctc_loss=0.658, task_loss=1.345, contrastive_loss=0.061, total=4136.34, n_correct=2644.58, ppl=4.68, accuracy=63.935, wps=10140.9, ups=1.22, wpb=8286.8, bsz=306.2, num_updates=26200, lr=8.73704e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=81, gb_free=15.4, wall=16166
2023-07-23 01:11:45 | INFO | train_inner | epoch 018:   1254 / 1474 loss=4.301, trans_loss=5.043, nll_loss=2.243, w2v_ctc_loss=0.657, task_loss=1.477, contrastive_loss=0.061, total=4087.62, n_correct=2602.02, ppl=4.73, accuracy=63.656, wps=10124.7, ups=1.24, wpb=8175.1, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=80, gb_free=16.8, wall=16247
2023-07-23 01:13:06 | INFO | train_inner | epoch 018:   1354 / 1474 loss=4.31, trans_loss=5.049, nll_loss=2.252, w2v_ctc_loss=0.67, task_loss=1.461, contrastive_loss=0.088, total=4070.69, n_correct=2587.01, ppl=4.76, accuracy=63.552, wps=10058, ups=1.23, wpb=8146.9, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=80, gb_free=17.5, wall=16328
2023-07-23 01:14:27 | INFO | train_inner | epoch 018:   1454 / 1474 loss=4.304, trans_loss=5.044, nll_loss=2.245, w2v_ctc_loss=0.663, task_loss=1.449, contrastive_loss=0.073, total=4113.2, n_correct=2616.76, ppl=4.74, accuracy=63.619, wps=10245.2, ups=1.24, wpb=8252.5, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=80, gb_free=16.6, wall=16409
2023-07-23 01:14:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-23 01:14:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 01:15:06 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.596 | nll_loss 2.873 | w2v_ctc_loss 1.332 | task_loss 4.63 | contrastive_loss 0.25 | total 4003.4 | n_correct 2460.2 | ppl 7.32 | accuracy 61.453 | uer 16.848 | wer 18.638 | raw_wer 18.638 | bleu 19.61 | wps 2134.5 | wpb 4003.4 | bsz 141.8 | num_updates 26519 | best_bleu 20.09
2023-07-23 01:15:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26519 updates
2023-07-23 01:15:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6101.pt
2023-07-23 01:15:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6101.pt
2023-07-23 01:15:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6101.pt (epoch 18 @ 26519 updates, score 19.61) (writing took 15.662976516410708 seconds)
2023-07-23 01:15:22 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-07-23 01:15:22 | INFO | train | epoch 018 | loss 4.287 | trans_loss 5.031 | nll_loss 2.228 | w2v_ctc_loss 0.652 | task_loss 1.378 | contrastive_loss 0.103 | total 4136.37 | n_correct 2641.11 | ppl 4.69 | accuracy 63.851 | wps 9490.6 | ups 1.15 | wpb 8273.7 | bsz 304.8 | num_updates 26519 | lr 8.68433e-05 | gnorm 0.545 | clip 0 | loss_scale 32 | train_wall 1187 | gb_free 16.1 | wall 16464
2023-07-23 01:15:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 01:15:22 | INFO | fairseq.trainer | begin training epoch 19
2023-07-23 01:15:22 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 01:16:37 | INFO | train_inner | epoch 019:     81 / 1474 loss=4.277, trans_loss=5.019, nll_loss=2.211, w2v_ctc_loss=0.657, task_loss=1.407, contrastive_loss=0.05, total=4090.17, n_correct=2621.59, ppl=4.63, accuracy=64.095, wps=6263.9, ups=0.77, wpb=8154, bsz=291, num_updates=26600, lr=8.6711e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=81, gb_free=13.1, wall=16539
2023-07-23 01:17:59 | INFO | train_inner | epoch 019:    181 / 1474 loss=4.264, trans_loss=5.006, nll_loss=2.196, w2v_ctc_loss=0.651, task_loss=1.282, contrastive_loss=0.114, total=4222.18, n_correct=2715.68, ppl=4.58, accuracy=64.319, wps=10313.5, ups=1.22, wpb=8462.7, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=81, gb_free=12.1, wall=16621
2023-07-23 01:19:20 | INFO | train_inner | epoch 019:    281 / 1474 loss=4.263, trans_loss=5.008, nll_loss=2.196, w2v_ctc_loss=0.643, task_loss=1.347, contrastive_loss=0.056, total=4187.37, n_correct=2696.05, ppl=4.58, accuracy=64.385, wps=10354.9, ups=1.24, wpb=8374.8, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=80, gb_free=17.6, wall=16702
2023-07-23 01:20:40 | INFO | train_inner | epoch 019:    381 / 1474 loss=4.27, trans_loss=5.013, nll_loss=2.205, w2v_ctc_loss=0.638, task_loss=1.356, contrastive_loss=0.163, total=4170.67, n_correct=2680.72, ppl=4.61, accuracy=64.276, wps=10326.5, ups=1.24, wpb=8331.8, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=80, gb_free=17.3, wall=16782
2023-07-23 01:22:01 | INFO | train_inner | epoch 019:    481 / 1474 loss=4.269, trans_loss=5.012, nll_loss=2.203, w2v_ctc_loss=0.644, task_loss=1.405, contrastive_loss=0.072, total=4115.22, n_correct=2640.58, ppl=4.61, accuracy=64.166, wps=10197.7, ups=1.24, wpb=8243.3, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=80, gb_free=15.3, wall=16863
2023-07-23 01:23:22 | INFO | train_inner | epoch 019:    581 / 1474 loss=4.269, trans_loss=5.015, nll_loss=2.207, w2v_ctc_loss=0.637, task_loss=1.346, contrastive_loss=0.136, total=4129.22, n_correct=2655.78, ppl=4.62, accuracy=64.317, wps=10223.7, ups=1.24, wpb=8249.7, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=80, gb_free=16.1, wall=16944
2023-07-23 01:24:43 | INFO | train_inner | epoch 019:    681 / 1474 loss=4.261, trans_loss=5.016, nll_loss=2.209, w2v_ctc_loss=0.632, task_loss=1.257, contrastive_loss=0.065, total=4197.2, n_correct=2701.59, ppl=4.62, accuracy=64.366, wps=10377.4, ups=1.24, wpb=8385.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=80, gb_free=14.9, wall=17025
2023-07-23 01:26:04 | INFO | train_inner | epoch 019:    781 / 1474 loss=4.277, trans_loss=5.018, nll_loss=2.211, w2v_ctc_loss=0.651, task_loss=1.385, contrastive_loss=0.076, total=4142.6, n_correct=2657.43, ppl=4.63, accuracy=64.149, wps=10202, ups=1.23, wpb=8311, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.542, clip=0, loss_scale=32, train_wall=81, gb_free=16.6, wall=17106
2023-07-23 01:27:26 | INFO | train_inner | epoch 019:    881 / 1474 loss=4.278, trans_loss=5.024, nll_loss=2.218, w2v_ctc_loss=0.649, task_loss=1.404, contrastive_loss=0.061, total=4153.47, n_correct=2659.05, ppl=4.65, accuracy=64.02, wps=10207.1, ups=1.23, wpb=8303.4, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=81, gb_free=16.4, wall=17188
2023-07-23 01:28:47 | INFO | train_inner | epoch 019:    981 / 1474 loss=4.295, trans_loss=5.033, nll_loss=2.232, w2v_ctc_loss=0.651, task_loss=1.371, contrastive_loss=0.295, total=4101.29, n_correct=2614.76, ppl=4.7, accuracy=63.755, wps=10042.7, ups=1.23, wpb=8197.4, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=81, gb_free=16.8, wall=17269
2023-07-23 01:30:08 | INFO | train_inner | epoch 019:   1081 / 1474 loss=4.288, trans_loss=5.028, nll_loss=2.224, w2v_ctc_loss=0.644, task_loss=1.468, contrastive_loss=0.105, total=4036.97, n_correct=2576.68, ppl=4.67, accuracy=63.827, wps=10059.5, ups=1.24, wpb=8106.5, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=80, gb_free=14.9, wall=17350
2023-07-23 01:31:30 | INFO | train_inner | epoch 019:   1181 / 1474 loss=4.29, trans_loss=5.032, nll_loss=2.23, w2v_ctc_loss=0.652, task_loss=1.39, contrastive_loss=0.188, total=4137.49, n_correct=2641.03, ppl=4.69, accuracy=63.832, wps=10076.7, ups=1.22, wpb=8258.3, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=81, gb_free=15.1, wall=17432
2023-07-23 01:32:50 | INFO | train_inner | epoch 019:   1281 / 1474 loss=4.284, trans_loss=5.03, nll_loss=2.228, w2v_ctc_loss=0.646, task_loss=1.39, contrastive_loss=0.086, total=4141.89, n_correct=2644.05, ppl=4.68, accuracy=63.837, wps=10285, ups=1.24, wpb=8266.6, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=80, gb_free=15.8, wall=17512
2023-07-23 01:34:11 | INFO | train_inner | epoch 019:   1381 / 1474 loss=4.279, trans_loss=5.022, nll_loss=2.217, w2v_ctc_loss=0.649, task_loss=1.403, contrastive_loss=0.071, total=4133.26, n_correct=2646.88, ppl=4.65, accuracy=64.039, wps=10239.1, ups=1.24, wpb=8264.4, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=80, gb_free=16.4, wall=17593
2023-07-23 01:35:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 01:35:51 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 4.227 | trans_loss 5.598 | nll_loss 2.876 | w2v_ctc_loss 1.363 | task_loss 4.621 | contrastive_loss 0.26 | total 4003.4 | n_correct 2465 | ppl 7.34 | accuracy 61.573 | uer 16.975 | wer 18.758 | raw_wer 18.758 | bleu 19.7 | wps 2036.5 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 20.09
2023-07-23 01:35:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-07-23 01:35:51 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7000.pt
2023-07-23 01:36:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7000.pt
2023-07-23 01:36:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7000.pt (epoch 19 @ 27993 updates, score 19.7) (writing took 19.800898348912597 seconds)
2023-07-23 01:36:11 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-07-23 01:36:11 | INFO | train | epoch 019 | loss 4.276 | trans_loss 5.02 | nll_loss 2.214 | w2v_ctc_loss 0.646 | task_loss 1.373 | contrastive_loss 0.114 | total 4138.65 | n_correct 2653.15 | ppl 4.64 | accuracy 64.107 | wps 9770.1 | ups 1.18 | wpb 8277.3 | bsz 305.7 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.546 | clip 0 | loss_scale 32 | train_wall 1185 | gb_free 17.5 | wall 17713
2023-07-23 01:36:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 01:36:11 | INFO | fairseq.trainer | begin training epoch 20
2023-07-23 01:36:11 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 01:36:26 | INFO | train_inner | epoch 020:      7 / 1474 loss=4.28, trans_loss=5.022, nll_loss=2.218, w2v_ctc_loss=0.64, task_loss=1.39, contrastive_loss=0.153, total=4119.08, n_correct=2643.36, ppl=4.65, accuracy=64.174, wps=6084.3, ups=0.74, wpb=8243.7, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=81, gb_free=16.5, wall=17728
2023-07-23 01:36:26 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 01:36:50 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.234 | trans_loss 5.601 | nll_loss 2.879 | w2v_ctc_loss 1.382 | task_loss 4.645 | contrastive_loss 0.259 | total 4003.4 | n_correct 2468.2 | ppl 7.36 | accuracy 61.653 | uer 17.049 | wer 18.843 | raw_wer 18.843 | bleu 19.61 | wps 2139.1 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 20.09
2023-07-23 01:36:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-07-23 01:36:50 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_20_28000.pt
2023-07-23 01:36:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_20_28000.pt
2023-07-23 01:37:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 19.61) (writing took 15.454469984397292 seconds)
2023-07-23 01:38:28 | INFO | train_inner | epoch 020:    107 / 1474 loss=4.245, trans_loss=4.991, nll_loss=2.177, w2v_ctc_loss=0.632, task_loss=1.322, contrastive_loss=0.078, total=4195.03, n_correct=2713.2, ppl=4.52, accuracy=64.677, wps=6902.9, ups=0.82, wpb=8385.8, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=81, gb_free=15.3, wall=17850
2023-07-23 01:39:49 | INFO | train_inner | epoch 020:    207 / 1474 loss=4.258, trans_loss=4.997, nll_loss=2.183, w2v_ctc_loss=0.639, task_loss=1.423, contrastive_loss=0.127, total=4154.14, n_correct=2681.07, ppl=4.54, accuracy=64.54, wps=10181.5, ups=1.23, wpb=8305.4, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=81, gb_free=17.3, wall=17931
2023-07-23 01:41:10 | INFO | train_inner | epoch 020:    307 / 1474 loss=4.242, trans_loss=4.994, nll_loss=2.18, w2v_ctc_loss=0.636, task_loss=1.241, contrastive_loss=0.068, total=4188.05, n_correct=2711.23, ppl=4.53, accuracy=64.737, wps=10335.3, ups=1.24, wpb=8358.5, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=80, gb_free=15.7, wall=18012
2023-07-23 01:42:31 | INFO | train_inner | epoch 020:    407 / 1474 loss=4.259, trans_loss=4.999, nll_loss=2.186, w2v_ctc_loss=0.636, task_loss=1.393, contrastive_loss=0.065, total=4115.16, n_correct=2655.64, ppl=4.55, accuracy=64.533, wps=10225.1, ups=1.24, wpb=8252.1, bsz=297, num_updates=28400, lr=8.39181e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=80, gb_free=15.7, wall=18093
2023-07-23 01:43:52 | INFO | train_inner | epoch 020:    507 / 1474 loss=4.267, trans_loss=5.011, nll_loss=2.202, w2v_ctc_loss=0.636, task_loss=1.405, contrastive_loss=0.153, total=4108.46, n_correct=2640.73, ppl=4.6, accuracy=64.275, wps=10114, ups=1.23, wpb=8204.4, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=80, gb_free=16.6, wall=18174
2023-07-23 01:45:13 | INFO | train_inner | epoch 020:    607 / 1474 loss=4.28, trans_loss=5.015, nll_loss=2.207, w2v_ctc_loss=0.649, task_loss=1.445, contrastive_loss=0.157, total=4094.9, n_correct=2625.15, ppl=4.62, accuracy=64.108, wps=10159.6, ups=1.24, wpb=8198.1, bsz=296.1, num_updates=28600, lr=8.36242e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=80, gb_free=12.4, wall=18255
2023-07-23 01:46:34 | INFO | train_inner | epoch 020:    707 / 1474 loss=4.267, trans_loss=5.012, nll_loss=2.204, w2v_ctc_loss=0.646, task_loss=1.37, contrastive_loss=0.059, total=4140.23, n_correct=2665.08, ppl=4.61, accuracy=64.37, wps=10201.1, ups=1.24, wpb=8253.6, bsz=300.6, num_updates=28700, lr=8.34784e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=80, gb_free=16.4, wall=18336
2023-07-23 01:47:54 | INFO | train_inner | epoch 020:    807 / 1474 loss=4.265, trans_loss=5.008, nll_loss=2.199, w2v_ctc_loss=0.643, task_loss=1.364, contrastive_loss=0.061, total=4140.66, n_correct=2667.95, ppl=4.59, accuracy=64.433, wps=10307.7, ups=1.24, wpb=8299.7, bsz=305.6, num_updates=28800, lr=8.33333e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=80, gb_free=17.6, wall=18416
2023-07-23 01:49:17 | INFO | train_inner | epoch 020:    907 / 1474 loss=4.281, trans_loss=5.02, nll_loss=2.217, w2v_ctc_loss=0.647, task_loss=1.311, contrastive_loss=0.354, total=4157.15, n_correct=2663.83, ppl=4.65, accuracy=64.078, wps=10060.9, ups=1.22, wpb=8275, bsz=322.6, num_updates=28900, lr=8.3189e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=82, gb_free=17.8, wall=18498
2023-07-23 01:50:38 | INFO | train_inner | epoch 020:   1007 / 1474 loss=4.259, trans_loss=5.006, nll_loss=2.197, w2v_ctc_loss=0.632, task_loss=1.355, contrastive_loss=0.069, total=4171.86, n_correct=2690.23, ppl=4.59, accuracy=64.485, wps=10252.8, ups=1.23, wpb=8333.6, bsz=308.6, num_updates=29000, lr=8.30455e-05, gnorm=0.544, clip=0, loss_scale=64, train_wall=81, gb_free=16.2, wall=18580
2023-07-23 01:51:59 | INFO | train_inner | epoch 020:   1107 / 1474 loss=4.275, trans_loss=5.018, nll_loss=2.212, w2v_ctc_loss=0.642, task_loss=1.324, contrastive_loss=0.206, total=4162.96, n_correct=2670.56, ppl=4.63, accuracy=64.151, wps=10233.7, ups=1.23, wpb=8311.5, bsz=314.9, num_updates=29100, lr=8.29027e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=81, gb_free=17.2, wall=18661
2023-07-23 01:53:19 | INFO | train_inner | epoch 020:   1207 / 1474 loss=4.278, trans_loss=5.013, nll_loss=2.205, w2v_ctc_loss=0.648, task_loss=1.499, contrastive_loss=0.056, total=4033.74, n_correct=2594.99, ppl=4.61, accuracy=64.332, wps=10074.1, ups=1.24, wpb=8092.9, bsz=285.2, num_updates=29200, lr=8.27606e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=80, gb_free=17.4, wall=18741
2023-07-23 01:54:41 | INFO | train_inner | epoch 020:   1307 / 1474 loss=4.279, trans_loss=5.019, nll_loss=2.213, w2v_ctc_loss=0.643, task_loss=1.45, contrastive_loss=0.059, total=4124.42, n_correct=2644.32, ppl=4.64, accuracy=64.114, wps=10201.9, ups=1.23, wpb=8283.7, bsz=297, num_updates=29300, lr=8.26192e-05, gnorm=0.548, clip=0, loss_scale=64, train_wall=81, gb_free=16.2, wall=18822
2023-07-23 01:56:02 | INFO | train_inner | epoch 020:   1407 / 1474 loss=4.283, trans_loss=5.023, nll_loss=2.218, w2v_ctc_loss=0.645, task_loss=1.454, contrastive_loss=0.06, total=4114.1, n_correct=2637.8, ppl=4.65, accuracy=64.116, wps=10140, ups=1.23, wpb=8240.1, bsz=293.7, num_updates=29400, lr=8.24786e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=81, gb_free=14.7, wall=18904
2023-07-23 01:56:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 01:57:19 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 4.197 | trans_loss 5.599 | nll_loss 2.876 | w2v_ctc_loss 1.261 | task_loss 4.612 | contrastive_loss 0.257 | total 4003.4 | n_correct 2465.7 | ppl 7.34 | accuracy 61.59 | uer 16.898 | wer 18.754 | raw_wer 18.754 | bleu 19.6 | wps 2141.2 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 20.09
2023-07-23 01:57:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-07-23 01:57:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6007.pt
2023-07-23 01:57:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6007.pt
2023-07-23 01:57:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6007.pt (epoch 20 @ 29467 updates, score 19.6) (writing took 14.854817990213633 seconds)
2023-07-23 01:57:34 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-07-23 01:57:34 | INFO | train | epoch 020 | loss 4.266 | trans_loss 5.009 | nll_loss 2.2 | w2v_ctc_loss 0.641 | task_loss 1.372 | contrastive_loss 0.113 | total 4138.65 | n_correct 2663.28 | ppl 4.6 | accuracy 64.351 | wps 9506.4 | ups 1.15 | wpb 8277.3 | bsz 305.7 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.548 | clip 0 | loss_scale 64 | train_wall 1186 | gb_free 16.7 | wall 18996
2023-07-23 01:57:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 01:57:35 | INFO | fairseq.trainer | begin training epoch 21
2023-07-23 01:57:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 01:58:10 | INFO | train_inner | epoch 021:     33 / 1474 loss=4.261, trans_loss=5.006, nll_loss=2.197, w2v_ctc_loss=0.632, task_loss=1.298, contrastive_loss=0.183, total=4155.01, n_correct=2671.95, ppl=4.58, accuracy=64.307, wps=6487.1, ups=0.78, wpb=8315.3, bsz=317.6, num_updates=29500, lr=8.23387e-05, gnorm=0.543, clip=0, loss_scale=64, train_wall=80, gb_free=16.5, wall=19032
2023-07-23 01:58:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-23 01:59:32 | INFO | train_inner | epoch 021:    134 / 1474 loss=4.24, trans_loss=4.982, nll_loss=2.164, w2v_ctc_loss=0.635, task_loss=1.33, contrastive_loss=0.062, total=4168.09, n_correct=2704.7, ppl=4.48, accuracy=64.891, wps=10197.1, ups=1.22, wpb=8341.6, bsz=310.2, num_updates=29600, lr=8.21995e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=81, gb_free=17.2, wall=19114
2023-07-23 02:00:53 | INFO | train_inner | epoch 021:    234 / 1474 loss=4.236, trans_loss=4.983, nll_loss=2.166, w2v_ctc_loss=0.617, task_loss=1.308, contrastive_loss=0.125, total=4155.31, n_correct=2693.3, ppl=4.49, accuracy=64.816, wps=10264.1, ups=1.24, wpb=8305.4, bsz=312.6, num_updates=29700, lr=8.2061e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=80, gb_free=16.9, wall=19195
2023-07-23 02:02:14 | INFO | train_inner | epoch 021:    334 / 1474 loss=4.251, trans_loss=4.991, nll_loss=2.177, w2v_ctc_loss=0.634, task_loss=1.362, contrastive_loss=0.13, total=4151.51, n_correct=2683.72, ppl=4.52, accuracy=64.644, wps=10189.1, ups=1.23, wpb=8316, bsz=310.8, num_updates=29800, lr=8.19232e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=81, gb_free=15.8, wall=19276
2023-07-23 02:03:35 | INFO | train_inner | epoch 021:    434 / 1474 loss=4.24, trans_loss=4.985, nll_loss=2.169, w2v_ctc_loss=0.623, task_loss=1.33, contrastive_loss=0.053, total=4180.85, n_correct=2717.41, ppl=4.5, accuracy=64.997, wps=10376, ups=1.24, wpb=8359.9, bsz=306.8, num_updates=29900, lr=8.17861e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=80, gb_free=16, wall=19357
2023-07-23 02:04:56 | INFO | train_inner | epoch 021:    534 / 1474 loss=4.253, trans_loss=4.992, nll_loss=2.177, w2v_ctc_loss=0.635, task_loss=1.429, contrastive_loss=0.055, total=4083.98, n_correct=2644.18, ppl=4.52, accuracy=64.745, wps=10139.8, ups=1.24, wpb=8190.4, bsz=295.1, num_updates=30000, lr=8.16497e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=80, gb_free=13.4, wall=19438
2023-07-23 02:04:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 02:05:22 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.598 | nll_loss 2.875 | w2v_ctc_loss 1.291 | task_loss 4.633 | contrastive_loss 0.257 | total 4003.4 | n_correct 2468.4 | ppl 7.34 | accuracy 61.658 | uer 17.055 | wer 18.881 | raw_wer 18.881 | bleu 19.72 | wps 1882.8 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 20.09
2023-07-23 02:05:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-07-23 02:05:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_21_30000.pt
2023-07-23 02:05:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_21_30000.pt
2023-07-23 02:05:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 19.72) (writing took 16.600710712373257 seconds)
mt_weight tensor(1., device='cuda:0')
asr_weight tensor(0.0009, device='cuda:0')
2023-07-23 02:07:01 | INFO | train_inner | epoch 021:    634 / 1474 loss=4.256, trans_loss=4.998, nll_loss=2.186, w2v_ctc_loss=0.63, task_loss=1.357, contrastive_loss=0.226, total=4215.41, n_correct=2724.5, ppl=4.55, accuracy=64.632, wps=6728.1, ups=0.8, wpb=8403.4, bsz=315.4, num_updates=30100, lr=8.15139e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=81, gb_free=11.8, wall=19563
2023-07-23 02:08:22 | INFO | train_inner | epoch 021:    734 / 1474 loss=4.257, trans_loss=5.001, nll_loss=2.191, w2v_ctc_loss=0.633, task_loss=1.367, contrastive_loss=0.088, total=4152.97, n_correct=2678.86, ppl=4.57, accuracy=64.505, wps=10278.5, ups=1.24, wpb=8318.4, bsz=309.3, num_updates=30200, lr=8.13788e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=80, gb_free=16.5, wall=19643
2023-07-23 02:09:43 | INFO | train_inner | epoch 021:    834 / 1474 loss=4.267, trans_loss=5.006, nll_loss=2.196, w2v_ctc_loss=0.637, task_loss=1.454, contrastive_loss=0.1, total=4066.93, n_correct=2616.07, ppl=4.58, accuracy=64.325, wps=10043.5, ups=1.23, wpb=8158.7, bsz=294.4, num_updates=30300, lr=8.12444e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=81, gb_free=17.1, wall=19725
2023-07-23 02:11:03 | INFO | train_inner | epoch 021:    934 / 1474 loss=4.253, trans_loss=4.998, nll_loss=2.187, w2v_ctc_loss=0.634, task_loss=1.37, contrastive_loss=0.072, total=4103.34, n_correct=2653.13, ppl=4.55, accuracy=64.658, wps=10189.8, ups=1.24, wpb=8188.2, bsz=301, num_updates=30400, lr=8.11107e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=80, gb_free=14.3, wall=19805
2023-07-23 02:12:24 | INFO | train_inner | epoch 021:   1034 / 1474 loss=4.262, trans_loss=5.008, nll_loss=2.199, w2v_ctc_loss=0.637, task_loss=1.397, contrastive_loss=0.07, total=4099.86, n_correct=2642.53, ppl=4.59, accuracy=64.454, wps=10168.9, ups=1.24, wpb=8182.9, bsz=298.8, num_updates=30500, lr=8.09776e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=80, gb_free=11.8, wall=19886
2023-07-23 02:13:45 | INFO | train_inner | epoch 021:   1134 / 1474 loss=4.265, trans_loss=5.004, nll_loss=2.193, w2v_ctc_loss=0.64, task_loss=1.476, contrastive_loss=0.073, total=4120.75, n_correct=2653.91, ppl=4.57, accuracy=64.404, wps=10175.7, ups=1.23, wpb=8241.3, bsz=293.5, num_updates=30600, lr=8.08452e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=80, gb_free=16, wall=19967
2023-07-23 02:15:05 | INFO | train_inner | epoch 021:   1234 / 1474 loss=4.254, trans_loss=4.999, nll_loss=2.188, w2v_ctc_loss=0.634, task_loss=1.309, contrastive_loss=0.126, total=4154.73, n_correct=2683.02, ppl=4.56, accuracy=64.577, wps=10327.7, ups=1.25, wpb=8292.3, bsz=311.6, num_updates=30700, lr=8.07134e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=80, gb_free=13, wall=20047
2023-07-23 02:16:26 | INFO | train_inner | epoch 021:   1334 / 1474 loss=4.257, trans_loss=5.001, nll_loss=2.191, w2v_ctc_loss=0.63, task_loss=1.332, contrastive_loss=0.087, total=4147.17, n_correct=2683.6, ppl=4.57, accuracy=64.709, wps=10212.8, ups=1.23, wpb=8315.3, bsz=311.9, num_updates=30800, lr=8.05823e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=81, gb_free=16.4, wall=20128
2023-07-23 02:17:48 | INFO | train_inner | epoch 021:   1434 / 1474 loss=4.28, trans_loss=5.017, nll_loss=2.211, w2v_ctc_loss=0.658, task_loss=1.438, contrastive_loss=0.136, total=4133.93, n_correct=2654.83, ppl=4.63, accuracy=64.22, wps=10165.8, ups=1.23, wpb=8265.5, bsz=304.5, num_updates=30900, lr=8.04518e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=81, gb_free=15.7, wall=20210
2023-07-23 02:18:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1., device='cuda:5')
asr_weight tensor(0.0009, device='cuda:5')
mt_weight tensor(1., device='cuda:7')
asr_weight tensor(0.0009, device='cuda:7')
mt_weight tensor(1., device='cuda:4')
asr_weight tensor(0.0009, device='cuda:4')
mt_weight tensor(1., device='cuda:6')
asr_weight tensor(0.0009, device='cuda:6')
mt_weight tensor(1., device='cuda:2')
asr_weight tensor(0.0009, device='cuda:2')
mt_weight tensor(1., device='cuda:1')
asr_weight tensor(0.0009, device='cuda:1')
mt_weight tensor(1., device='cuda:3')
asr_weight tensor(0.0009, device='cuda:3')
2023-07-23 02:18:43 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.6 | nll_loss 2.875 | w2v_ctc_loss 1.331 | task_loss 4.615 | contrastive_loss 0.26 | total 4003.4 | n_correct 2461.8 | ppl 7.33 | accuracy 61.493 | uer 16.97 | wer 18.866 | raw_wer 18.866 | bleu 19.62 | wps 2271.5 | wpb 4003.4 | bsz 141.8 | num_updates 30940 | best_bleu 20.09
2023-07-23 02:18:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30940 updates
2023-07-23 02:18:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6201.pt
2023-07-23 02:18:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6201.pt
2023-07-23 02:18:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.6201.pt (epoch 21 @ 30940 updates, score 19.62) (writing took 12.461306657642126 seconds)
2023-07-23 02:18:56 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-07-23 02:18:56 | INFO | train | epoch 021 | loss 4.255 | trans_loss 4.998 | nll_loss 2.186 | w2v_ctc_loss 0.634 | task_loss 1.376 | contrastive_loss 0.105 | total 4137.02 | n_correct 2672.74 | ppl 4.55 | accuracy 64.605 | wps 9513 | ups 1.15 | wpb 8274.5 | bsz 305.1 | num_updates 30940 | lr 8.03998e-05 | gnorm 0.55 | clip 0 | loss_scale 32 | train_wall 1186 | gb_free 15.6 | wall 20278
2023-07-23 02:18:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 02:18:56 | INFO | fairseq.trainer | begin training epoch 22
2023-07-23 02:18:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 02:19:53 | INFO | train_inner | epoch 022:     60 / 1474 loss=4.249, trans_loss=4.989, nll_loss=2.174, w2v_ctc_loss=0.634, task_loss=1.394, contrastive_loss=0.053, total=4128.84, n_correct=2677.19, ppl=4.51, accuracy=64.841, wps=6579.7, ups=0.8, wpb=8260.4, bsz=297.7, num_updates=31000, lr=8.03219e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=80, gb_free=14.4, wall=20335
2023-07-23 02:21:14 | INFO | train_inner | epoch 022:    160 / 1474 loss=4.244, trans_loss=4.984, nll_loss=2.168, w2v_ctc_loss=0.635, task_loss=1.383, contrastive_loss=0.138, total=4123.35, n_correct=2674.29, ppl=4.49, accuracy=64.857, wps=10168, ups=1.23, wpb=8244.6, bsz=310.3, num_updates=31100, lr=8.01927e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=81, gb_free=14.9, wall=20416
2023-07-23 02:22:36 | INFO | train_inner | epoch 022:    260 / 1474 loss=4.218, trans_loss=4.969, nll_loss=2.149, w2v_ctc_loss=0.612, task_loss=1.212, contrastive_loss=0.079, total=4267.16, n_correct=2781.7, ppl=4.44, accuracy=65.189, wps=10489, ups=1.23, wpb=8531.7, bsz=329.9, num_updates=31200, lr=8.00641e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=81, gb_free=17, wall=20498
2023-07-23 02:23:58 | INFO | train_inner | epoch 022:    360 / 1474 loss=4.255, trans_loss=4.988, nll_loss=2.173, w2v_ctc_loss=0.632, task_loss=1.393, contrastive_loss=0.237, total=4180.09, n_correct=2707.3, ppl=4.51, accuracy=64.767, wps=10131.1, ups=1.21, wpb=8362.3, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=82, gb_free=17.7, wall=20580
2023-07-23 02:25:20 | INFO | train_inner | epoch 022:    460 / 1474 loss=4.253, trans_loss=4.993, nll_loss=2.178, w2v_ctc_loss=0.634, task_loss=1.448, contrastive_loss=0.119, total=4132.62, n_correct=2671.35, ppl=4.53, accuracy=64.641, wps=10120.9, ups=1.23, wpb=8240.5, bsz=297.2, num_updates=31400, lr=7.98087e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=81, gb_free=16.7, wall=20662
2023-07-23 02:26:41 | INFO | train_inner | epoch 022:    560 / 1474 loss=4.245, trans_loss=4.987, nll_loss=2.171, w2v_ctc_loss=0.634, task_loss=1.383, contrastive_loss=0.066, total=4155.5, n_correct=2692.09, ppl=4.5, accuracy=64.784, wps=10167.1, ups=1.22, wpb=8319.6, bsz=307.3, num_updates=31500, lr=7.96819e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=81, gb_free=16.6, wall=20743
2023-07-23 02:28:02 | INFO | train_inner | epoch 022:    660 / 1474 loss=4.232, trans_loss=4.976, nll_loss=2.158, w2v_ctc_loss=0.616, task_loss=1.3, contrastive_loss=0.147, total=4147.84, n_correct=2700.14, ppl=4.46, accuracy=65.097, wps=10303.7, ups=1.24, wpb=8290, bsz=313.1, num_updates=31600, lr=7.95557e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=80, gb_free=13.4, wall=20824
2023-07-23 02:29:24 | INFO | train_inner | epoch 022:    760 / 1474 loss=4.249, trans_loss=4.991, nll_loss=2.177, w2v_ctc_loss=0.63, task_loss=1.407, contrastive_loss=0.068, total=4166.89, n_correct=2701.05, ppl=4.52, accuracy=64.822, wps=10200.6, ups=1.22, wpb=8332.9, bsz=304.3, num_updates=31700, lr=7.94301e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=81, gb_free=16.1, wall=20906
2023-07-23 02:30:45 | INFO | train_inner | epoch 022:    860 / 1474 loss=4.262, trans_loss=4.997, nll_loss=2.185, w2v_ctc_loss=0.63, task_loss=1.498, contrastive_loss=0.054, total=4074.75, n_correct=2633.37, ppl=4.55, accuracy=64.627, wps=10024.4, ups=1.22, wpb=8197.1, bsz=288.4, num_updates=31800, lr=7.93052e-05, gnorm=0.551, clip=0, loss_scale=64, train_wall=81, gb_free=17.6, wall=20987
2023-07-23 02:32:07 | INFO | train_inner | epoch 022:    960 / 1474 loss=4.243, trans_loss=4.988, nll_loss=2.173, w2v_ctc_loss=0.627, task_loss=1.38, contrastive_loss=0.055, total=4136.34, n_correct=2687.89, ppl=4.51, accuracy=64.982, wps=10155.6, ups=1.23, wpb=8268.5, bsz=303.7, num_updates=31900, lr=7.91808e-05, gnorm=0.549, clip=0, loss_scale=64, train_wall=81, gb_free=16.8, wall=21069
2023-07-23 02:33:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-23 02:33:29 | INFO | train_inner | epoch 022:   1061 / 1474 loss=4.244, trans_loss=4.989, nll_loss=2.176, w2v_ctc_loss=0.624, task_loss=1.371, contrastive_loss=0.063, total=4125.15, n_correct=2678.4, ppl=4.52, accuracy=64.929, wps=10080, ups=1.22, wpb=8246.6, bsz=303, num_updates=32000, lr=7.90569e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=81, gb_free=17.4, wall=21151
2023-07-23 02:33:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 02:33:53 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.215 | trans_loss 5.596 | nll_loss 2.873 | w2v_ctc_loss 1.332 | task_loss 4.629 | contrastive_loss 0.255 | total 4003.4 | n_correct 2466.1 | ppl 7.33 | accuracy 61.6 | uer 16.906 | wer 18.866 | raw_wer 18.866 | bleu 19.87 | wps 2075.5 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 20.09
2023-07-23 02:33:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-07-23 02:33:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_22_32000.pt
2023-07-23 02:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_22_32000.pt
2023-07-23 02:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 19.87) (writing took 12.844015015289187 seconds)
2023-07-23 02:35:30 | INFO | train_inner | epoch 022:   1161 / 1474 loss=4.254, trans_loss=4.995, nll_loss=2.183, w2v_ctc_loss=0.637, task_loss=1.418, contrastive_loss=0.105, total=4099.59, n_correct=2648.08, ppl=4.54, accuracy=64.594, wps=6763.2, ups=0.83, wpb=8180.2, bsz=296.2, num_updates=32100, lr=7.89337e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=80, gb_free=15.2, wall=21271
2023-07-23 02:36:51 | INFO | train_inner | epoch 022:   1261 / 1474 loss=4.241, trans_loss=4.99, nll_loss=2.178, w2v_ctc_loss=0.627, task_loss=1.271, contrastive_loss=0.103, total=4182.05, n_correct=2706.87, ppl=4.52, accuracy=64.726, wps=10318.1, ups=1.23, wpb=8365.4, bsz=323, num_updates=32200, lr=7.8811e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=81, gb_free=15.8, wall=21353
2023-07-23 02:38:11 | INFO | train_inner | epoch 022:   1361 / 1474 loss=4.248, trans_loss=4.991, nll_loss=2.177, w2v_ctc_loss=0.623, task_loss=1.377, contrastive_loss=0.121, total=4062.31, n_correct=2632.92, ppl=4.52, accuracy=64.813, wps=10164.4, ups=1.25, wpb=8134.9, bsz=299, num_updates=32300, lr=7.86889e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=80, gb_free=15.3, wall=21433
2023-07-23 02:39:32 | INFO | train_inner | epoch 022:   1461 / 1474 loss=4.271, trans_loss=5.008, nll_loss=2.2, w2v_ctc_loss=0.643, task_loss=1.469, contrastive_loss=0.071, total=4081.88, n_correct=2632.88, ppl=4.59, accuracy=64.502, wps=10074.7, ups=1.23, wpb=8161.1, bsz=288.9, num_updates=32400, lr=7.85674e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=80, gb_free=17.3, wall=21514
2023-07-23 02:39:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 02:40:05 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 4.201 | trans_loss 5.589 | nll_loss 2.863 | w2v_ctc_loss 1.301 | task_loss 4.599 | contrastive_loss 0.249 | total 4003.4 | n_correct 2466.7 | ppl 7.27 | accuracy 61.615 | uer 16.8 | wer 18.705 | raw_wer 18.705 | bleu 19.58 | wps 2257.5 | wpb 4003.4 | bsz 141.8 | num_updates 32413 | best_bleu 20.09
2023-07-23 02:40:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32413 updates
2023-07-23 02:40:05 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 02:40:16 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 02:40:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 22 @ 32413 updates, score 19.58) (writing took 11.047629203647375 seconds)
2023-07-23 02:40:16 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-07-23 02:40:16 | INFO | train | epoch 022 | loss 4.247 | trans_loss 4.989 | nll_loss 2.174 | w2v_ctc_loss 0.629 | task_loss 1.378 | contrastive_loss 0.1 | total 4136.53 | n_correct 2681.37 | ppl 4.51 | accuracy 64.822 | wps 9517.8 | ups 1.15 | wpb 8273.7 | bsz 304.9 | num_updates 32413 | lr 7.85517e-05 | gnorm 0.551 | clip 0 | loss_scale 32 | train_wall 1189 | gb_free 12.2 | wall 21558
2023-07-23 02:40:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 02:40:16 | INFO | fairseq.trainer | begin training epoch 23
2023-07-23 02:40:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 02:41:36 | INFO | train_inner | epoch 023:     87 / 1474 loss=4.23, trans_loss=4.97, nll_loss=2.149, w2v_ctc_loss=0.625, task_loss=1.406, contrastive_loss=0.062, total=4096.09, n_correct=2670.97, ppl=4.44, accuracy=65.208, wps=6588.6, ups=0.8, wpb=8207.5, bsz=301.2, num_updates=32500, lr=7.84465e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=81, gb_free=16.6, wall=21638
2023-07-23 02:42:58 | INFO | train_inner | epoch 023:    187 / 1474 loss=4.231, trans_loss=4.971, nll_loss=2.15, w2v_ctc_loss=0.621, task_loss=1.46, contrastive_loss=0.06, total=4107.77, n_correct=2678.49, ppl=4.44, accuracy=65.205, wps=10049.8, ups=1.22, wpb=8214.3, bsz=293.4, num_updates=32600, lr=7.8326e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=81, gb_free=16.6, wall=21720
2023-07-23 02:44:20 | INFO | train_inner | epoch 023:    287 / 1474 loss=4.232, trans_loss=4.973, nll_loss=2.153, w2v_ctc_loss=0.619, task_loss=1.378, contrastive_loss=0.137, total=4153.12, n_correct=2697.87, ppl=4.45, accuracy=64.96, wps=10135.5, ups=1.22, wpb=8296.2, bsz=306.4, num_updates=32700, lr=7.82062e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=81, gb_free=17.2, wall=21802
2023-07-23 02:45:41 | INFO | train_inner | epoch 023:    387 / 1474 loss=4.229, trans_loss=4.968, nll_loss=2.146, w2v_ctc_loss=0.615, task_loss=1.425, contrastive_loss=0.05, total=4116.7, n_correct=2688.79, ppl=4.43, accuracy=65.314, wps=10143.7, ups=1.23, wpb=8242.9, bsz=294, num_updates=32800, lr=7.80869e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=81, gb_free=15.5, wall=21883
2023-07-23 02:47:02 | INFO | train_inner | epoch 023:    487 / 1474 loss=4.232, trans_loss=4.977, nll_loss=2.16, w2v_ctc_loss=0.62, task_loss=1.334, contrastive_loss=0.109, total=4157.6, n_correct=2706.42, ppl=4.47, accuracy=65.096, wps=10274, ups=1.24, wpb=8310.1, bsz=313.5, num_updates=32900, lr=7.79681e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=80, gb_free=17.4, wall=21964
2023-07-23 02:48:23 | INFO | train_inner | epoch 023:    587 / 1474 loss=4.217, trans_loss=4.962, nll_loss=2.14, w2v_ctc_loss=0.61, task_loss=1.296, contrastive_loss=0.056, total=4173.42, n_correct=2735.78, ppl=4.41, accuracy=65.552, wps=10361, ups=1.24, wpb=8359.3, bsz=316, num_updates=33000, lr=7.78499e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=80, gb_free=13.1, wall=22045
2023-07-23 02:49:43 | INFO | train_inner | epoch 023:    687 / 1474 loss=4.235, trans_loss=4.974, nll_loss=2.154, w2v_ctc_loss=0.62, task_loss=1.372, contrastive_loss=0.095, total=4137.82, n_correct=2699.17, ppl=4.45, accuracy=65.232, wps=10264.4, ups=1.24, wpb=8286.5, bsz=302.5, num_updates=33100, lr=7.77322e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=80, gb_free=17.3, wall=22125
2023-07-23 02:51:05 | INFO | train_inner | epoch 023:    787 / 1474 loss=4.241, trans_loss=4.984, nll_loss=2.168, w2v_ctc_loss=0.631, task_loss=1.383, contrastive_loss=0.077, total=4150.99, n_correct=2696.3, ppl=4.49, accuracy=64.956, wps=10228.3, ups=1.23, wpb=8289.2, bsz=305.4, num_updates=33200, lr=7.76151e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=81, gb_free=16.6, wall=22206
2023-07-23 02:52:25 | INFO | train_inner | epoch 023:    887 / 1474 loss=4.228, trans_loss=4.974, nll_loss=2.156, w2v_ctc_loss=0.623, task_loss=1.252, contrastive_loss=0.156, total=4181.99, n_correct=2721.55, ppl=4.46, accuracy=65.078, wps=10364.2, ups=1.24, wpb=8354.2, bsz=324.7, num_updates=33300, lr=7.74984e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=80, gb_free=16.6, wall=22287
2023-07-23 02:53:47 | INFO | train_inner | epoch 023:    987 / 1474 loss=4.248, trans_loss=4.983, nll_loss=2.167, w2v_ctc_loss=0.62, task_loss=1.367, contrastive_loss=0.314, total=4168.73, n_correct=2710.4, ppl=4.49, accuracy=65.017, wps=10205.5, ups=1.23, wpb=8308.5, bsz=310.5, num_updates=33400, lr=7.73823e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=81, gb_free=11.5, wall=22368
2023-07-23 02:55:08 | INFO | train_inner | epoch 023:   1087 / 1474 loss=4.245, trans_loss=4.982, nll_loss=2.165, w2v_ctc_loss=0.625, task_loss=1.465, contrastive_loss=0.062, total=4088.49, n_correct=2656.77, ppl=4.48, accuracy=64.982, wps=10059.7, ups=1.23, wpb=8188.1, bsz=290, num_updates=33500, lr=7.72667e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=81, gb_free=16.1, wall=22450
2023-07-23 02:56:30 | INFO | train_inner | epoch 023:   1187 / 1474 loss=4.24, trans_loss=4.983, nll_loss=2.167, w2v_ctc_loss=0.628, task_loss=1.366, contrastive_loss=0.056, total=4162.7, n_correct=2703.91, ppl=4.49, accuracy=64.956, wps=10163.1, ups=1.22, wpb=8342.1, bsz=309.3, num_updates=33600, lr=7.71517e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=82, gb_free=16.4, wall=22532
2023-07-23 02:57:51 | INFO | train_inner | epoch 023:   1287 / 1474 loss=4.231, trans_loss=4.978, nll_loss=2.161, w2v_ctc_loss=0.619, task_loss=1.336, contrastive_loss=0.068, total=4135.53, n_correct=2692.07, ppl=4.47, accuracy=65.096, wps=10213.7, ups=1.24, wpb=8260.6, bsz=308.9, num_updates=33700, lr=7.70371e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=80, gb_free=16.9, wall=22613
2023-07-23 02:59:12 | INFO | train_inner | epoch 023:   1387 / 1474 loss=4.257, trans_loss=4.998, nll_loss=2.187, w2v_ctc_loss=0.631, task_loss=1.385, contrastive_loss=0.126, total=4143.98, n_correct=2678.09, ppl=4.55, accuracy=64.626, wps=10183.2, ups=1.23, wpb=8288.2, bsz=305.2, num_updates=33800, lr=7.69231e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=81, gb_free=16.2, wall=22694
2023-07-23 03:00:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 03:00:46 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.594 | nll_loss 2.868 | w2v_ctc_loss 1.346 | task_loss 4.633 | contrastive_loss 0.252 | total 4003.4 | n_correct 2470.8 | ppl 7.3 | accuracy 61.718 | uer 16.914 | wer 18.743 | raw_wer 18.743 | bleu 19.59 | wps 2199.1 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 20.09
2023-07-23 03:00:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-07-23 03:00:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 03:00:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 03:00:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 23 @ 33887 updates, score 19.59) (writing took 11.022282931953669 seconds)
2023-07-23 03:00:57 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-07-23 03:00:57 | INFO | train | epoch 023 | loss 4.237 | trans_loss 4.978 | nll_loss 2.16 | w2v_ctc_loss 0.622 | task_loss 1.372 | contrastive_loss 0.11 | total 4138.65 | n_correct 2693 | ppl 4.47 | accuracy 65.07 | wps 9829.6 | ups 1.19 | wpb 8277.3 | bsz 305.7 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.551 | clip 0 | loss_scale 32 | train_wall 1190 | gb_free 14.1 | wall 22799
2023-07-23 03:00:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 03:00:58 | INFO | fairseq.trainer | begin training epoch 24
2023-07-23 03:00:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 03:01:17 | INFO | train_inner | epoch 024:     13 / 1474 loss=4.253, trans_loss=4.99, nll_loss=2.177, w2v_ctc_loss=0.623, task_loss=1.381, contrastive_loss=0.206, total=4085.11, n_correct=2644.64, ppl=4.52, accuracy=64.739, wps=6557.5, ups=0.8, wpb=8178.5, bsz=304.2, num_updates=33900, lr=7.68095e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=81, gb_free=13, wall=22819
2023-07-23 03:02:38 | INFO | train_inner | epoch 024:    113 / 1474 loss=4.213, trans_loss=4.954, nll_loss=2.13, w2v_ctc_loss=0.611, task_loss=1.268, contrastive_loss=0.225, total=4171.44, n_correct=2729.6, ppl=4.38, accuracy=65.435, wps=10276.2, ups=1.23, wpb=8323.3, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.546, clip=0, loss_scale=32, train_wall=80, gb_free=16.5, wall=22900
2023-07-23 03:02:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 03:03:02 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.212 | trans_loss 5.594 | nll_loss 2.868 | w2v_ctc_loss 1.325 | task_loss 4.638 | contrastive_loss 0.251 | total 4003.4 | n_correct 2473.5 | ppl 7.3 | accuracy 61.785 | uer 16.948 | wer 18.642 | raw_wer 18.642 | bleu 19.72 | wps 2057.2 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 20.09
2023-07-23 03:03:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-07-23 03:03:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_24_34000.pt
2023-07-23 03:03:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_24_34000.pt
2023-07-23 03:03:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 19.72) (writing took 15.422232612967491 seconds)
2023-07-23 03:04:40 | INFO | train_inner | epoch 024:    213 / 1474 loss=4.207, trans_loss=4.953, nll_loss=2.129, w2v_ctc_loss=0.596, task_loss=1.2, contrastive_loss=0.276, total=4251.29, n_correct=2784.48, ppl=4.38, accuracy=65.497, wps=6978.1, ups=0.82, wpb=8487.3, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=81, gb_free=16.9, wall=23022
2023-07-23 03:06:01 | INFO | train_inner | epoch 024:    313 / 1474 loss=4.211, trans_loss=4.955, nll_loss=2.131, w2v_ctc_loss=0.604, task_loss=1.346, contrastive_loss=0.053, total=4128.18, n_correct=2706.13, ppl=4.38, accuracy=65.553, wps=10178.6, ups=1.23, wpb=8264, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=81, gb_free=16.3, wall=23103
2023-07-23 03:06:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-23 03:07:24 | INFO | train_inner | epoch 024:    414 / 1474 loss=4.242, trans_loss=4.976, nll_loss=2.157, w2v_ctc_loss=0.626, task_loss=1.484, contrastive_loss=0.081, total=4138.36, n_correct=2697.37, ppl=4.46, accuracy=65.18, wps=10017.2, ups=1.21, wpb=8281.8, bsz=291.7, num_updates=34300, lr=7.63604e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=82, gb_free=16.3, wall=23185
2023-07-23 03:08:45 | INFO | train_inner | epoch 024:    514 / 1474 loss=4.226, trans_loss=4.965, nll_loss=2.144, w2v_ctc_loss=0.62, task_loss=1.399, contrastive_loss=0.121, total=4141.88, n_correct=2704.03, ppl=4.42, accuracy=65.285, wps=10180.4, ups=1.23, wpb=8275.6, bsz=302.6, num_updates=34400, lr=7.62493e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=81, gb_free=15.4, wall=23267
2023-07-23 03:10:06 | INFO | train_inner | epoch 024:    614 / 1474 loss=4.225, trans_loss=4.969, nll_loss=2.148, w2v_ctc_loss=0.611, task_loss=1.379, contrastive_loss=0.086, total=4162.06, n_correct=2716.41, ppl=4.43, accuracy=65.266, wps=10254.5, ups=1.23, wpb=8317.8, bsz=308.1, num_updates=34500, lr=7.61387e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=81, gb_free=16.9, wall=23348
2023-07-23 03:11:27 | INFO | train_inner | epoch 024:    714 / 1474 loss=4.237, trans_loss=4.974, nll_loss=2.154, w2v_ctc_loss=0.622, task_loss=1.423, contrastive_loss=0.096, total=4097.35, n_correct=2669.92, ppl=4.45, accuracy=65.162, wps=10121.7, ups=1.23, wpb=8199.5, bsz=293.8, num_updates=34600, lr=7.60286e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=80, gb_free=17.4, wall=23429
2023-07-23 03:12:48 | INFO | train_inner | epoch 024:    814 / 1474 loss=4.221, trans_loss=4.969, nll_loss=2.149, w2v_ctc_loss=0.61, task_loss=1.373, contrastive_loss=0.076, total=4124.25, n_correct=2690.74, ppl=4.44, accuracy=65.242, wps=10136.7, ups=1.23, wpb=8242.9, bsz=308.2, num_updates=34700, lr=7.5919e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=81, gb_free=16.6, wall=23510
2023-07-23 03:14:08 | INFO | train_inner | epoch 024:    914 / 1474 loss=4.246, trans_loss=4.98, nll_loss=2.162, w2v_ctc_loss=0.629, task_loss=1.526, contrastive_loss=0.048, total=4041.44, n_correct=2626.84, ppl=4.48, accuracy=64.998, wps=10130.2, ups=1.25, wpb=8096.6, bsz=280.5, num_updates=34800, lr=7.58098e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=79, gb_free=16.4, wall=23590
2023-07-23 03:15:30 | INFO | train_inner | epoch 024:   1014 / 1474 loss=4.234, trans_loss=4.975, nll_loss=2.156, w2v_ctc_loss=0.608, task_loss=1.432, contrastive_loss=0.051, total=4128.8, n_correct=2692.9, ppl=4.46, accuracy=65.222, wps=10165.1, ups=1.23, wpb=8282.7, bsz=296.5, num_updates=34900, lr=7.57011e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=81, gb_free=15.3, wall=23672
2023-07-23 03:16:51 | INFO | train_inner | epoch 024:   1114 / 1474 loss=4.223, trans_loss=4.961, nll_loss=2.14, w2v_ctc_loss=0.617, task_loss=1.332, contrastive_loss=0.096, total=4130.49, n_correct=2700.87, ppl=4.41, accuracy=65.389, wps=10241.5, ups=1.24, wpb=8282.3, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=80, gb_free=16.3, wall=23752
mt_weight tensor(1., device='cuda:0')
asr_weight tensor(0.0009, device='cuda:0')
2023-07-23 03:18:12 | INFO | train_inner | epoch 024:   1214 / 1474 loss=4.229, trans_loss=4.974, nll_loss=2.156, w2v_ctc_loss=0.615, task_loss=1.361, contrastive_loss=0.086, total=4157.47, n_correct=2709.38, ppl=4.46, accuracy=65.169, wps=10252.3, ups=1.23, wpb=8318.1, bsz=311.2, num_updates=35100, lr=7.54851e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=81, gb_free=13.1, wall=23834
2023-07-23 03:19:33 | INFO | train_inner | epoch 024:   1314 / 1474 loss=4.237, trans_loss=4.977, nll_loss=2.159, w2v_ctc_loss=0.632, task_loss=1.458, contrastive_loss=0.059, total=4107.23, n_correct=2673.05, ppl=4.47, accuracy=65.082, wps=10073.2, ups=1.23, wpb=8189.4, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=81, gb_free=17.7, wall=23915
2023-07-23 03:20:53 | INFO | train_inner | epoch 024:   1414 / 1474 loss=4.245, trans_loss=4.985, nll_loss=2.17, w2v_ctc_loss=0.627, task_loss=1.434, contrastive_loss=0.056, total=4094.39, n_correct=2666.42, ppl=4.5, accuracy=65.124, wps=10185.9, ups=1.24, wpb=8186.3, bsz=292.9, num_updates=35300, lr=7.5271e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=80, gb_free=16.5, wall=23995
2023-07-23 03:21:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1., device='cuda:5')
asr_weight tensor(0.0009, device='cuda:5')
mt_weight tensor(1., device='cuda:2')
asr_weight tensor(0.0009, device='cuda:2')
mt_weight tensor(1., device='cuda:7')
asr_weight tensor(0.0009, device='cuda:7')
mt_weight tensor(1., device='cuda:4')
asr_weight tensor(0.0009, device='cuda:4')
mt_weight tensor(1., device='cuda:6')
asr_weight tensor(0.0009, device='cuda:6')
mt_weight tensor(1., device='cuda:1')
asr_weight tensor(0.0009, device='cuda:1')
mt_weight tensor(1., device='cuda:3')
asr_weight tensor(0.0009, device='cuda:3')
2023-07-23 03:22:07 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 4.213 | trans_loss 5.591 | nll_loss 2.864 | w2v_ctc_loss 1.336 | task_loss 4.636 | contrastive_loss 0.249 | total 4003.4 | n_correct 2472.8 | ppl 7.28 | accuracy 61.767 | uer 16.946 | wer 18.75 | raw_wer 18.75 | bleu 19.61 | wps 2120.3 | wpb 4003.4 | bsz 141.8 | num_updates 35360 | best_bleu 20.09
2023-07-23 03:22:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35360 updates
2023-07-23 03:22:07 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 03:22:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 03:22:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 24 @ 35360 updates, score 19.61) (writing took 10.786001110449433 seconds)
2023-07-23 03:22:17 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-07-23 03:22:17 | INFO | train | epoch 024 | loss 4.228 | trans_loss 4.969 | nll_loss 2.149 | w2v_ctc_loss 0.616 | task_loss 1.377 | contrastive_loss 0.101 | total 4137.03 | n_correct 2700.06 | ppl 4.43 | accuracy 65.266 | wps 9522.6 | ups 1.15 | wpb 8274.6 | bsz 305.1 | num_updates 35360 | lr 7.52071e-05 | gnorm 0.553 | clip 0 | loss_scale 32 | train_wall 1189 | gb_free 16.3 | wall 24079
2023-07-23 03:22:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 03:22:18 | INFO | fairseq.trainer | begin training epoch 25
2023-07-23 03:22:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 03:22:58 | INFO | train_inner | epoch 025:     40 / 1474 loss=4.216, trans_loss=4.959, nll_loss=2.137, w2v_ctc_loss=0.608, task_loss=1.322, contrastive_loss=0.062, total=4165.57, n_correct=2732.41, ppl=4.4, accuracy=65.595, wps=6665.7, ups=0.8, wpb=8340.3, bsz=311.2, num_updates=35400, lr=7.51646e-05, gnorm=0.544, clip=0, loss_scale=32, train_wall=81, gb_free=13.5, wall=24120
2023-07-23 03:24:19 | INFO | train_inner | epoch 025:    140 / 1474 loss=4.198, trans_loss=4.942, nll_loss=2.114, w2v_ctc_loss=0.6, task_loss=1.338, contrastive_loss=0.062, total=4135.43, n_correct=2724.54, ppl=4.33, accuracy=65.883, wps=10245, ups=1.24, wpb=8268.2, bsz=308.9, num_updates=35500, lr=7.50587e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=80, gb_free=17.8, wall=24201
2023-07-23 03:25:42 | INFO | train_inner | epoch 025:    240 / 1474 loss=4.209, trans_loss=4.949, nll_loss=2.122, w2v_ctc_loss=0.603, task_loss=1.408, contrastive_loss=0.066, total=4116.13, n_correct=2703.21, ppl=4.35, accuracy=65.674, wps=10013.4, ups=1.21, wpb=8260.2, bsz=303, num_updates=35600, lr=7.49532e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=82, gb_free=17.4, wall=24284
2023-07-23 03:27:04 | INFO | train_inner | epoch 025:    340 / 1474 loss=4.225, trans_loss=4.961, nll_loss=2.138, w2v_ctc_loss=0.615, task_loss=1.464, contrastive_loss=0.094, total=4141.49, n_correct=2708.81, ppl=4.4, accuracy=65.407, wps=10089.6, ups=1.22, wpb=8276.8, bsz=294.2, num_updates=35700, lr=7.48481e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=81, gb_free=15.4, wall=24366
2023-07-23 03:28:25 | INFO | train_inner | epoch 025:    440 / 1474 loss=4.233, trans_loss=4.965, nll_loss=2.142, w2v_ctc_loss=0.63, task_loss=1.433, contrastive_loss=0.173, total=4167.4, n_correct=2721.11, ppl=4.41, accuracy=65.295, wps=10183.7, ups=1.23, wpb=8297.2, bsz=297.7, num_updates=35800, lr=7.47435e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=81, gb_free=16, wall=24447
2023-07-23 03:29:47 | INFO | train_inner | epoch 025:    540 / 1474 loss=4.213, trans_loss=4.957, nll_loss=2.134, w2v_ctc_loss=0.61, task_loss=1.339, contrastive_loss=0.066, total=4160.61, n_correct=2727.73, ppl=4.39, accuracy=65.561, wps=10207.9, ups=1.22, wpb=8337.8, bsz=313.9, num_updates=35900, lr=7.46393e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=81, gb_free=17.7, wall=24529
2023-07-23 03:31:08 | INFO | train_inner | epoch 025:    640 / 1474 loss=4.218, trans_loss=4.959, nll_loss=2.135, w2v_ctc_loss=0.608, task_loss=1.364, contrastive_loss=0.132, total=4153.68, n_correct=2722.44, ppl=4.39, accuracy=65.543, wps=10256.5, ups=1.23, wpb=8311.3, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.552, clip=0, loss_scale=32, train_wall=80, gb_free=16.5, wall=24610
2023-07-23 03:31:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 03:31:30 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.223 | trans_loss 5.593 | nll_loss 2.865 | w2v_ctc_loss 1.366 | task_loss 4.639 | contrastive_loss 0.252 | total 4003.4 | n_correct 2475 | ppl 7.29 | accuracy 61.822 | uer 16.877 | wer 18.743 | raw_wer 18.743 | bleu 19.44 | wps 2323.7 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 20.09
2023-07-23 03:31:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-07-23 03:31:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_25_36000.pt
2023-07-23 03:31:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_25_36000.pt
2023-07-23 03:31:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 19.44) (writing took 10.674391901120543 seconds)
2023-07-23 03:33:02 | INFO | train_inner | epoch 025:    740 / 1474 loss=4.221, trans_loss=4.956, nll_loss=2.132, w2v_ctc_loss=0.614, task_loss=1.393, contrastive_loss=0.126, total=4128.34, n_correct=2702.17, ppl=4.38, accuracy=65.454, wps=7219.7, ups=0.87, wpb=8267.2, bsz=301.3, num_updates=36100, lr=7.44323e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=81, gb_free=17.2, wall=24724
2023-07-23 03:34:24 | INFO | train_inner | epoch 025:    840 / 1474 loss=4.209, trans_loss=4.961, nll_loss=2.14, w2v_ctc_loss=0.61, task_loss=1.266, contrastive_loss=0.076, total=4182.4, n_correct=2739.61, ppl=4.41, accuracy=65.503, wps=10256, ups=1.23, wpb=8352, bsz=326, num_updates=36200, lr=7.43294e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=81, gb_free=17.8, wall=24806
2023-07-23 03:35:45 | INFO | train_inner | epoch 025:    940 / 1474 loss=4.213, trans_loss=4.956, nll_loss=2.134, w2v_ctc_loss=0.611, task_loss=1.3, contrastive_loss=0.132, total=4155.21, n_correct=2719.4, ppl=4.39, accuracy=65.446, wps=10240.1, ups=1.23, wpb=8305.8, bsz=317, num_updates=36300, lr=7.4227e-05, gnorm=0.547, clip=0, loss_scale=64, train_wall=81, gb_free=14.4, wall=24887
2023-07-23 03:36:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-23 03:37:08 | INFO | train_inner | epoch 025:   1041 / 1474 loss=4.227, trans_loss=4.965, nll_loss=2.143, w2v_ctc_loss=0.606, task_loss=1.38, contrastive_loss=0.222, total=4159.83, n_correct=2717.88, ppl=4.42, accuracy=65.336, wps=10056.3, ups=1.21, wpb=8315.4, bsz=305.5, num_updates=36400, lr=7.41249e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=82, gb_free=17, wall=24970
2023-07-23 03:38:29 | INFO | train_inner | epoch 025:   1141 / 1474 loss=4.228, trans_loss=4.967, nll_loss=2.146, w2v_ctc_loss=0.609, task_loss=1.474, contrastive_loss=0.047, total=4042.33, n_correct=2643.91, ppl=4.43, accuracy=65.406, wps=10010.6, ups=1.24, wpb=8092.7, bsz=286.5, num_updates=36500, lr=7.40233e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=80, gb_free=17.9, wall=25050
2023-07-23 03:39:49 | INFO | train_inner | epoch 025:   1241 / 1474 loss=4.223, trans_loss=4.965, nll_loss=2.144, w2v_ctc_loss=0.611, task_loss=1.4, contrastive_loss=0.056, total=4087.78, n_correct=2673.98, ppl=4.42, accuracy=65.414, wps=10133.2, ups=1.24, wpb=8175.5, bsz=295.1, num_updates=36600, lr=7.39221e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=80, gb_free=17.8, wall=25131
2023-07-23 03:41:10 | INFO | train_inner | epoch 025:   1341 / 1474 loss=4.221, trans_loss=4.963, nll_loss=2.142, w2v_ctc_loss=0.61, task_loss=1.345, contrastive_loss=0.15, total=4166.64, n_correct=2731.05, ppl=4.41, accuracy=65.546, wps=10216.6, ups=1.23, wpb=8299.4, bsz=309.3, num_updates=36700, lr=7.38213e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=81, gb_free=16.7, wall=25212
2023-07-23 03:42:33 | INFO | train_inner | epoch 025:   1441 / 1474 loss=4.239, trans_loss=4.977, nll_loss=2.159, w2v_ctc_loss=0.622, task_loss=1.401, contrastive_loss=0.119, total=4114.64, n_correct=2677.68, ppl=4.47, accuracy=65.077, wps=10036.8, ups=1.22, wpb=8254.8, bsz=304.3, num_updates=36800, lr=7.3721e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=82, gb_free=16.8, wall=25295
2023-07-23 03:42:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 03:43:22 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 4.204 | trans_loss 5.585 | nll_loss 2.859 | w2v_ctc_loss 1.318 | task_loss 4.643 | contrastive_loss 0.252 | total 4003.4 | n_correct 2475.3 | ppl 7.26 | accuracy 61.83 | uer 16.704 | wer 18.78 | raw_wer 18.78 | bleu 19.78 | wps 2252.4 | wpb 4003.4 | bsz 141.8 | num_updates 36833 | best_bleu 20.09
2023-07-23 03:43:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36833 updates
2023-07-23 03:43:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7800.pt
2023-07-23 03:43:26 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7800.pt
2023-07-23 03:43:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7800.pt (epoch 25 @ 36833 updates, score 19.78) (writing took 11.8864203710109 seconds)
2023-07-23 03:43:35 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-07-23 03:43:35 | INFO | train | epoch 025 | loss 4.219 | trans_loss 4.96 | nll_loss 2.137 | w2v_ctc_loss 0.611 | task_loss 1.374 | contrastive_loss 0.106 | total 4137.68 | n_correct 2709.14 | ppl 4.4 | accuracy 65.475 | wps 9544.3 | ups 1.15 | wpb 8275.5 | bsz 305.4 | num_updates 36833 | lr 7.36879e-05 | gnorm 0.554 | clip 0 | loss_scale 32 | train_wall 1192 | gb_free 14.6 | wall 25356
2023-07-23 03:43:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 03:43:35 | INFO | fairseq.trainer | begin training epoch 26
2023-07-23 03:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 03:44:37 | INFO | train_inner | epoch 026:     67 / 1474 loss=4.2, trans_loss=4.943, nll_loss=2.116, w2v_ctc_loss=0.597, task_loss=1.299, contrastive_loss=0.084, total=4172.16, n_correct=2747.17, ppl=4.34, accuracy=65.845, wps=6719.5, ups=0.8, wpb=8372, bsz=316.9, num_updates=36900, lr=7.3621e-05, gnorm=0.549, clip=0, loss_scale=32, train_wall=80, gb_free=17.2, wall=25419
2023-07-23 03:45:59 | INFO | train_inner | epoch 026:    167 / 1474 loss=4.19, trans_loss=4.936, nll_loss=2.107, w2v_ctc_loss=0.589, task_loss=1.21, contrastive_loss=0.259, total=4265.22, n_correct=2815.54, ppl=4.31, accuracy=66.012, wps=10472.6, ups=1.23, wpb=8504.4, bsz=338.7, num_updates=37000, lr=7.35215e-05, gnorm=0.545, clip=0, loss_scale=32, train_wall=81, gb_free=15.6, wall=25500
2023-07-23 03:47:20 | INFO | train_inner | epoch 026:    267 / 1474 loss=4.209, trans_loss=4.948, nll_loss=2.122, w2v_ctc_loss=0.608, task_loss=1.364, contrastive_loss=0.146, total=4123.94, n_correct=2710.36, ppl=4.35, accuracy=65.723, wps=10163.1, ups=1.23, wpb=8237.8, bsz=306.6, num_updates=37100, lr=7.34223e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=81, gb_free=17.2, wall=25581
2023-07-23 03:48:41 | INFO | train_inner | epoch 026:    367 / 1474 loss=4.208, trans_loss=4.95, nll_loss=2.125, w2v_ctc_loss=0.609, task_loss=1.31, contrastive_loss=0.106, total=4168.11, n_correct=2741.64, ppl=4.36, accuracy=65.777, wps=10238, ups=1.23, wpb=8332.5, bsz=315.2, num_updates=37200, lr=7.33236e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=81, gb_free=17.3, wall=25663
2023-07-23 03:50:02 | INFO | train_inner | epoch 026:    467 / 1474 loss=4.2, trans_loss=4.941, nll_loss=2.113, w2v_ctc_loss=0.606, task_loss=1.316, contrastive_loss=0.15, total=4167.53, n_correct=2749.98, ppl=4.33, accuracy=65.986, wps=10298.6, ups=1.24, wpb=8305.7, bsz=314.6, num_updates=37300, lr=7.32252e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=80, gb_free=14.3, wall=25744
2023-07-23 03:51:23 | INFO | train_inner | epoch 026:    567 / 1474 loss=4.211, trans_loss=4.946, nll_loss=2.119, w2v_ctc_loss=0.61, task_loss=1.378, contrastive_loss=0.069, total=4158.48, n_correct=2735.93, ppl=4.34, accuracy=65.792, wps=10281.9, ups=1.23, wpb=8346.4, bsz=304.4, num_updates=37400, lr=7.31272e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=81, gb_free=13.2, wall=25825
2023-07-23 03:52:45 | INFO | train_inner | epoch 026:    667 / 1474 loss=4.205, trans_loss=4.946, nll_loss=2.119, w2v_ctc_loss=0.598, task_loss=1.41, contrastive_loss=0.054, total=4129.11, n_correct=2714.86, ppl=4.34, accuracy=65.749, wps=10099.6, ups=1.22, wpb=8256.6, bsz=297.7, num_updates=37500, lr=7.30297e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=81, gb_free=14.2, wall=25906
2023-07-23 03:54:05 | INFO | train_inner | epoch 026:    767 / 1474 loss=4.215, trans_loss=4.952, nll_loss=2.127, w2v_ctc_loss=0.606, task_loss=1.386, contrastive_loss=0.167, total=4096.84, n_correct=2684.97, ppl=4.37, accuracy=65.538, wps=10179.2, ups=1.24, wpb=8188.1, bsz=300.5, num_updates=37600, lr=7.29325e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=80, gb_free=16.9, wall=25987
2023-07-23 03:55:26 | INFO | train_inner | epoch 026:    867 / 1474 loss=4.215, trans_loss=4.958, nll_loss=2.135, w2v_ctc_loss=0.616, task_loss=1.37, contrastive_loss=0.07, total=4176.27, n_correct=2741.4, ppl=4.39, accuracy=65.642, wps=10325.5, ups=1.24, wpb=8320.1, bsz=306.4, num_updates=37700, lr=7.28357e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=80, gb_free=16.4, wall=26067
2023-07-23 03:56:47 | INFO | train_inner | epoch 026:    967 / 1474 loss=4.224, trans_loss=4.964, nll_loss=2.142, w2v_ctc_loss=0.602, task_loss=1.414, contrastive_loss=0.122, total=4141.01, n_correct=2712.07, ppl=4.41, accuracy=65.493, wps=10180.8, ups=1.23, wpb=8280.8, bsz=299.7, num_updates=37800, lr=7.27393e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=81, gb_free=15.7, wall=26149
2023-07-23 03:58:08 | INFO | train_inner | epoch 026:   1067 / 1474 loss=4.219, trans_loss=4.956, nll_loss=2.131, w2v_ctc_loss=0.608, task_loss=1.452, contrastive_loss=0.054, total=4113.69, n_correct=2702, ppl=4.38, accuracy=65.683, wps=10170.3, ups=1.23, wpb=8246.1, bsz=293, num_updates=37900, lr=7.26433e-05, gnorm=0.556, clip=0, loss_scale=32, train_wall=81, gb_free=15.8, wall=26230
2023-07-23 03:59:30 | INFO | train_inner | epoch 026:   1167 / 1474 loss=4.219, trans_loss=4.959, nll_loss=2.136, w2v_ctc_loss=0.61, task_loss=1.434, contrastive_loss=0.092, total=4116.78, n_correct=2697.33, ppl=4.4, accuracy=65.52, wps=10029.6, ups=1.22, wpb=8229.6, bsz=299, num_updates=38000, lr=7.25476e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=82, gb_free=16.7, wall=26312
2023-07-23 03:59:30 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 03:59:53 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.227 | trans_loss 5.592 | nll_loss 2.864 | w2v_ctc_loss 1.378 | task_loss 4.645 | contrastive_loss 0.256 | total 4003.4 | n_correct 2475.6 | ppl 7.28 | accuracy 61.837 | uer 17.025 | wer 18.799 | raw_wer 18.799 | bleu 19.7 | wps 2242.4 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 20.09
2023-07-23 03:59:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-07-23 03:59:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_26_38000.pt
2023-07-23 03:59:56 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_26_38000.pt
2023-07-23 04:00:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 19.7) (writing took 14.380823630839586 seconds)
2023-07-23 04:01:32 | INFO | train_inner | epoch 026:   1267 / 1474 loss=4.236, trans_loss=4.969, nll_loss=2.149, w2v_ctc_loss=0.622, task_loss=1.522, contrastive_loss=0.056, total=4001.06, n_correct=2608.42, ppl=4.44, accuracy=65.193, wps=6602, ups=0.82, wpb=8027.4, bsz=280.6, num_updates=38100, lr=7.24524e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=81, gb_free=15.9, wall=26434
2023-07-23 04:02:54 | INFO | train_inner | epoch 026:   1367 / 1474 loss=4.216, trans_loss=4.961, nll_loss=2.139, w2v_ctc_loss=0.607, task_loss=1.373, contrastive_loss=0.072, total=4157.69, n_correct=2724.36, ppl=4.4, accuracy=65.526, wps=10054.1, ups=1.21, wpb=8322.1, bsz=310.5, num_updates=38200, lr=7.23575e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=82, gb_free=16.5, wall=26516
2023-07-23 04:04:16 | INFO | train_inner | epoch 026:   1467 / 1474 loss=4.204, trans_loss=4.952, nll_loss=2.128, w2v_ctc_loss=0.597, task_loss=1.304, contrastive_loss=0.064, total=4158.47, n_correct=2731.85, ppl=4.37, accuracy=65.694, wps=10263, ups=1.23, wpb=8326.1, bsz=316.5, num_updates=38300, lr=7.22629e-05, gnorm=0.547, clip=0, loss_scale=32, train_wall=81, gb_free=17.5, wall=26597
2023-07-23 04:04:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 04:04:44 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 4.194 | trans_loss 5.592 | nll_loss 2.868 | w2v_ctc_loss 1.271 | task_loss 4.616 | contrastive_loss 0.252 | total 4003.4 | n_correct 2478.4 | ppl 7.3 | accuracy 61.907 | uer 16.603 | wer 18.489 | raw_wer 18.489 | bleu 19.7 | wps 2140.9 | wpb 4003.4 | bsz 141.8 | num_updates 38307 | best_bleu 20.09
2023-07-23 04:04:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38307 updates
2023-07-23 04:04:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7008.pt
2023-07-23 04:04:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7008.pt
2023-07-23 04:04:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7008.pt (epoch 26 @ 38307 updates, score 19.7) (writing took 13.123986903578043 seconds)
2023-07-23 04:04:59 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-07-23 04:04:59 | INFO | train | epoch 026 | loss 4.211 | trans_loss 4.952 | nll_loss 2.127 | w2v_ctc_loss 0.606 | task_loss 1.373 | contrastive_loss 0.107 | total 4138.65 | n_correct 2718.53 | ppl 4.37 | accuracy 65.686 | wps 9500.9 | ups 1.15 | wpb 8277.3 | bsz 305.7 | num_updates 38307 | lr 7.22563e-05 | gnorm 0.554 | clip 0 | loss_scale 32 | train_wall 1190 | gb_free 16.2 | wall 26641
2023-07-23 04:04:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 04:04:59 | INFO | fairseq.trainer | begin training epoch 27
2023-07-23 04:04:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 04:06:23 | INFO | train_inner | epoch 027:     93 / 1474 loss=4.193, trans_loss=4.93, nll_loss=2.096, w2v_ctc_loss=0.595, task_loss=1.465, contrastive_loss=0.043, total=4067.62, n_correct=2695.15, ppl=4.28, accuracy=66.259, wps=6394, ups=0.79, wpb=8117.2, bsz=284.4, num_updates=38400, lr=7.21688e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=80, gb_free=15.1, wall=26724
2023-07-23 04:07:44 | INFO | train_inner | epoch 027:    193 / 1474 loss=4.19, trans_loss=4.935, nll_loss=2.105, w2v_ctc_loss=0.602, task_loss=1.311, contrastive_loss=0.075, total=4185.52, n_correct=2763.96, ppl=4.3, accuracy=66.036, wps=10254.9, ups=1.22, wpb=8373.6, bsz=321.7, num_updates=38500, lr=7.2075e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=81, gb_free=17.7, wall=26806
2023-07-23 04:09:06 | INFO | train_inner | epoch 027:    293 / 1474 loss=4.198, trans_loss=4.94, nll_loss=2.11, w2v_ctc_loss=0.602, task_loss=1.369, contrastive_loss=0.056, total=4167.92, n_correct=2748.53, ppl=4.32, accuracy=65.945, wps=10226.6, ups=1.23, wpb=8347.1, bsz=306.8, num_updates=38600, lr=7.19816e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=81, gb_free=17, wall=26888
2023-07-23 04:10:27 | INFO | train_inner | epoch 027:    393 / 1474 loss=4.218, trans_loss=4.948, nll_loss=2.122, w2v_ctc_loss=0.602, task_loss=1.441, contrastive_loss=0.239, total=4075.21, n_correct=2681.85, ppl=4.35, accuracy=65.809, wps=10059.2, ups=1.23, wpb=8152.7, bsz=296, num_updates=38700, lr=7.18885e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=81, gb_free=17.8, wall=26969
2023-07-23 04:11:49 | INFO | train_inner | epoch 027:    493 / 1474 loss=4.201, trans_loss=4.945, nll_loss=2.12, w2v_ctc_loss=0.6, task_loss=1.256, contrastive_loss=0.177, total=4249.35, n_correct=2795.77, ppl=4.35, accuracy=65.793, wps=10339.5, ups=1.22, wpb=8491.6, bsz=331.9, num_updates=38800, lr=7.17958e-05, gnorm=0.55, clip=0, loss_scale=64, train_wall=82, gb_free=12.4, wall=27051
2023-07-23 04:13:10 | INFO | train_inner | epoch 027:    593 / 1474 loss=4.199, trans_loss=4.94, nll_loss=2.111, w2v_ctc_loss=0.602, task_loss=1.348, contrastive_loss=0.114, total=4133.39, n_correct=2724.08, ppl=4.32, accuracy=65.904, wps=10252.4, ups=1.24, wpb=8274.2, bsz=312, num_updates=38900, lr=7.17035e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=80, gb_free=12.5, wall=27132
2023-07-23 04:14:31 | INFO | train_inner | epoch 027:    693 / 1474 loss=4.207, trans_loss=4.946, nll_loss=2.119, w2v_ctc_loss=0.604, task_loss=1.368, contrastive_loss=0.095, total=4162.71, n_correct=2741.41, ppl=4.34, accuracy=65.856, wps=10259.3, ups=1.23, wpb=8324.9, bsz=305.4, num_updates=39000, lr=7.16115e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=81, gb_free=16.4, wall=27213
2023-07-23 04:15:51 | INFO | train_inner | epoch 027:    793 / 1474 loss=4.204, trans_loss=4.942, nll_loss=2.114, w2v_ctc_loss=0.606, task_loss=1.446, contrastive_loss=0.057, total=4103.81, n_correct=2703.32, ppl=4.33, accuracy=65.873, wps=10191.4, ups=1.24, wpb=8202.8, bsz=294.2, num_updates=39100, lr=7.15199e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=80, gb_free=16.7, wall=27293
2023-07-23 04:17:13 | INFO | train_inner | epoch 027:    893 / 1474 loss=4.203, trans_loss=4.946, nll_loss=2.119, w2v_ctc_loss=0.595, task_loss=1.428, contrastive_loss=0.047, total=4101.56, n_correct=2700.24, ppl=4.34, accuracy=65.834, wps=10042.4, ups=1.23, wpb=8183.5, bsz=292.1, num_updates=39200, lr=7.14286e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=81, gb_free=17.8, wall=27375
2023-07-23 04:18:34 | INFO | train_inner | epoch 027:    993 / 1474 loss=4.209, trans_loss=4.943, nll_loss=2.117, w2v_ctc_loss=0.598, task_loss=1.329, contrastive_loss=0.235, total=4199.56, n_correct=2764.47, ppl=4.34, accuracy=65.828, wps=10364.4, ups=1.23, wpb=8418.5, bsz=316.8, num_updates=39300, lr=7.13376e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=81, gb_free=12.1, wall=27456
2023-07-23 04:19:55 | INFO | train_inner | epoch 027:   1093 / 1474 loss=4.204, trans_loss=4.944, nll_loss=2.118, w2v_ctc_loss=0.601, task_loss=1.381, contrastive_loss=0.068, total=4150.97, n_correct=2732.77, ppl=4.34, accuracy=65.834, wps=10222.3, ups=1.23, wpb=8314.2, bsz=305, num_updates=39400, lr=7.1247e-05, gnorm=0.554, clip=0, loss_scale=64, train_wall=81, gb_free=12.4, wall=27537
2023-07-23 04:21:17 | INFO | train_inner | epoch 027:   1193 / 1474 loss=4.211, trans_loss=4.949, nll_loss=2.123, w2v_ctc_loss=0.607, task_loss=1.438, contrastive_loss=0.071, total=4103.06, n_correct=2698.35, ppl=4.35, accuracy=65.764, wps=10082.5, ups=1.23, wpb=8216.4, bsz=297.7, num_updates=39500, lr=7.11568e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=81, gb_free=16.8, wall=27619
2023-07-23 04:22:38 | INFO | train_inner | epoch 027:   1293 / 1474 loss=4.22, trans_loss=4.955, nll_loss=2.132, w2v_ctc_loss=0.604, task_loss=1.473, contrastive_loss=0.123, total=4062.52, n_correct=2663.16, ppl=4.38, accuracy=65.554, wps=10014.5, ups=1.23, wpb=8139.8, bsz=292.2, num_updates=39600, lr=7.10669e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=81, gb_free=16.7, wall=27700
2023-07-23 04:23:58 | INFO | train_inner | epoch 027:   1393 / 1474 loss=4.205, trans_loss=4.948, nll_loss=2.123, w2v_ctc_loss=0.604, task_loss=1.294, contrastive_loss=0.105, total=4152, n_correct=2733.48, ppl=4.36, accuracy=65.835, wps=10350.6, ups=1.25, wpb=8291.5, bsz=312.5, num_updates=39700, lr=7.09773e-05, gnorm=0.552, clip=0, loss_scale=64, train_wall=80, gb_free=16.7, wall=27780
2023-07-23 04:25:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 04:25:27 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 4.214 | trans_loss 5.596 | nll_loss 2.869 | w2v_ctc_loss 1.323 | task_loss 4.624 | contrastive_loss 0.264 | total 4003.4 | n_correct 2472.7 | ppl 7.31 | accuracy 61.765 | uer 17.02 | wer 18.896 | raw_wer 18.896 | bleu 19.76 | wps 2242.8 | wpb 4003.4 | bsz 141.8 | num_updates 39781 | best_bleu 20.09
2023-07-23 04:25:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39781 updates
2023-07-23 04:25:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7607.pt
2023-07-23 04:25:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7607.pt
2023-07-23 04:25:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.7607.pt (epoch 27 @ 39781 updates, score 19.76) (writing took 14.046628508716822 seconds)
2023-07-23 04:25:41 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-07-23 04:25:41 | INFO | train | epoch 027 | loss 4.204 | trans_loss 4.944 | nll_loss 2.116 | w2v_ctc_loss 0.601 | task_loss 1.373 | contrastive_loss 0.106 | total 4138.65 | n_correct 2726.13 | ppl 4.34 | accuracy 65.87 | wps 9818.1 | ups 1.19 | wpb 8277.3 | bsz 305.7 | num_updates 39781 | lr 7.0905e-05 | gnorm 0.556 | clip 0 | loss_scale 64 | train_wall 1189 | gb_free 17.9 | wall 27883
2023-07-23 04:25:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 04:25:42 | INFO | fairseq.trainer | begin training epoch 28
2023-07-23 04:25:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 04:26:06 | INFO | train_inner | epoch 028:     19 / 1474 loss=4.193, trans_loss=4.939, nll_loss=2.112, w2v_ctc_loss=0.595, task_loss=1.325, contrastive_loss=0.056, total=4108.43, n_correct=2710.92, ppl=4.32, accuracy=65.984, wps=6409.7, ups=0.78, wpb=8198, bsz=305.1, num_updates=39800, lr=7.08881e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=81, gb_free=16.5, wall=27908
2023-07-23 04:27:27 | INFO | train_inner | epoch 028:    119 / 1474 loss=4.186, trans_loss=4.925, nll_loss=2.091, w2v_ctc_loss=0.597, task_loss=1.433, contrastive_loss=0.054, total=4113.41, n_correct=2722.09, ppl=4.26, accuracy=66.176, wps=10185.5, ups=1.24, wpb=8209.1, bsz=293.9, num_updates=39900, lr=7.07992e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=80, gb_free=17.2, wall=27989
2023-07-23 04:28:48 | INFO | train_inner | epoch 028:    219 / 1474 loss=4.175, trans_loss=4.921, nll_loss=2.087, w2v_ctc_loss=0.584, task_loss=1.299, contrastive_loss=0.06, total=4191.56, n_correct=2782.59, ppl=4.25, accuracy=66.386, wps=10367.1, ups=1.24, wpb=8380.1, bsz=315.2, num_updates=40000, lr=7.07107e-05, gnorm=0.546, clip=0, loss_scale=64, train_wall=80, gb_free=15.3, wall=28070
2023-07-23 04:28:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 04:29:12 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.22 | trans_loss 5.594 | nll_loss 2.868 | w2v_ctc_loss 1.352 | task_loss 4.629 | contrastive_loss 0.249 | total 4003.4 | n_correct 2473.6 | ppl 7.3 | accuracy 61.787 | uer 16.808 | wer 18.687 | raw_wer 18.687 | bleu 19.43 | wps 2071.2 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 20.09
2023-07-23 04:29:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-07-23 04:29:12 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_28_40000.pt
2023-07-23 04:29:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_28_40000.pt
2023-07-23 04:29:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 19.43) (writing took 10.966812646016479 seconds)
mt_weight tensor(1., device='cuda:0')
asr_weight tensor(0.0009, device='cuda:0')
2023-07-23 04:29:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-23 04:30:46 | INFO | train_inner | epoch 028:    320 / 1474 loss=4.19, trans_loss=4.927, nll_loss=2.094, w2v_ctc_loss=0.586, task_loss=1.395, contrastive_loss=0.283, total=4127.08, n_correct=2727.8, ppl=4.27, accuracy=66.095, wps=6950.6, ups=0.84, wpb=8227.4, bsz=308.8, num_updates=40100, lr=7.06225e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=82, gb_free=13.6, wall=28188
2023-07-23 04:32:07 | INFO | train_inner | epoch 028:    420 / 1474 loss=4.2, trans_loss=4.938, nll_loss=2.108, w2v_ctc_loss=0.603, task_loss=1.422, contrastive_loss=0.047, total=4089.84, n_correct=2698.01, ppl=4.31, accuracy=65.969, wps=10115.1, ups=1.24, wpb=8189.7, bsz=295.7, num_updates=40200, lr=7.05346e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=81, gb_free=16.9, wall=28269
2023-07-23 04:33:28 | INFO | train_inner | epoch 028:    520 / 1474 loss=4.19, trans_loss=4.93, nll_loss=2.098, w2v_ctc_loss=0.589, task_loss=1.428, contrastive_loss=0.059, total=4098.92, n_correct=2715.93, ppl=4.28, accuracy=66.26, wps=10169.1, ups=1.24, wpb=8199.3, bsz=295.7, num_updates=40300, lr=7.0447e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=80, gb_free=17.1, wall=28350
2023-07-23 04:34:49 | INFO | train_inner | epoch 028:    620 / 1474 loss=4.197, trans_loss=4.938, nll_loss=2.109, w2v_ctc_loss=0.598, task_loss=1.383, contrastive_loss=0.061, total=4180.1, n_correct=2755.31, ppl=4.31, accuracy=65.915, wps=10242.5, ups=1.23, wpb=8360.1, bsz=305.3, num_updates=40400, lr=7.03598e-05, gnorm=0.553, clip=0, loss_scale=32, train_wall=81, gb_free=16.7, wall=28431
2023-07-23 04:36:10 | INFO | train_inner | epoch 028:    720 / 1474 loss=4.192, trans_loss=4.937, nll_loss=2.11, w2v_ctc_loss=0.596, task_loss=1.24, contrastive_loss=0.174, total=4191.62, n_correct=2766.41, ppl=4.32, accuracy=65.999, wps=10312, ups=1.23, wpb=8372, bsz=329.2, num_updates=40500, lr=7.02728e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=81, gb_free=17.2, wall=28512
2023-07-23 04:37:31 | INFO | train_inner | epoch 028:    820 / 1474 loss=4.191, trans_loss=4.936, nll_loss=2.107, w2v_ctc_loss=0.594, task_loss=1.355, contrastive_loss=0.051, total=4088.91, n_correct=2704.42, ppl=4.31, accuracy=66.14, wps=10116.4, ups=1.24, wpb=8171, bsz=304.3, num_updates=40600, lr=7.01862e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=80, gb_free=17.2, wall=28593
2023-07-23 04:38:53 | INFO | train_inner | epoch 028:    920 / 1474 loss=4.207, trans_loss=4.943, nll_loss=2.115, w2v_ctc_loss=0.597, task_loss=1.428, contrastive_loss=0.117, total=4117.01, n_correct=2708.44, ppl=4.33, accuracy=65.787, wps=10136.6, ups=1.23, wpb=8260.3, bsz=299.7, num_updates=40700, lr=7.01e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=81, gb_free=15.5, wall=28675
2023-07-23 04:40:14 | INFO | train_inner | epoch 028:   1020 / 1474 loss=4.204, trans_loss=4.94, nll_loss=2.112, w2v_ctc_loss=0.6, task_loss=1.337, contrastive_loss=0.167, total=4182.85, n_correct=2758.77, ppl=4.32, accuracy=65.954, wps=10324.3, ups=1.23, wpb=8373.6, bsz=312, num_updates=40800, lr=7.0014e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=81, gb_free=16.7, wall=28756
2023-07-23 04:41:35 | INFO | train_inner | epoch 028:   1120 / 1474 loss=4.193, trans_loss=4.938, nll_loss=2.11, w2v_ctc_loss=0.597, task_loss=1.32, contrastive_loss=0.074, total=4220.16, n_correct=2787.46, ppl=4.32, accuracy=66.051, wps=10369.7, ups=1.23, wpb=8439.4, bsz=321, num_updates=40900, lr=6.99284e-05, gnorm=0.554, clip=0, loss_scale=32, train_wall=81, gb_free=16.4, wall=28837
2023-07-23 04:42:56 | INFO | train_inner | epoch 028:   1220 / 1474 loss=4.196, trans_loss=4.939, nll_loss=2.111, w2v_ctc_loss=0.591, task_loss=1.369, contrastive_loss=0.058, total=4092.46, n_correct=2699.62, ppl=4.32, accuracy=65.966, wps=10154, ups=1.24, wpb=8198.5, bsz=303.1, num_updates=41000, lr=6.9843e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=80, gb_free=17.8, wall=28918
2023-07-23 04:44:18 | INFO | train_inner | epoch 028:   1320 / 1474 loss=4.219, trans_loss=4.951, nll_loss=2.125, w2v_ctc_loss=0.607, task_loss=1.505, contrastive_loss=0.074, total=4084.55, n_correct=2685.99, ppl=4.36, accuracy=65.76, wps=10022.3, ups=1.22, wpb=8182.2, bsz=285.1, num_updates=41100, lr=6.9758e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=81, gb_free=15.9, wall=28999
2023-07-23 04:45:39 | INFO | train_inner | epoch 028:   1420 / 1474 loss=4.216, trans_loss=4.952, nll_loss=2.127, w2v_ctc_loss=0.605, task_loss=1.434, contrastive_loss=0.097, total=4154.09, n_correct=2732.25, ppl=4.37, accuracy=65.773, wps=10230.2, ups=1.23, wpb=8315.9, bsz=299.3, num_updates=41200, lr=6.96733e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=81, gb_free=16.2, wall=29081
2023-07-23 04:46:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1., device='cuda:4')
asr_weight tensor(0.0009, device='cuda:4')
mt_weight tensor(1., device='cuda:3')
asr_weight tensor(0.0009, device='cuda:3')
mt_weight tensor(1., device='cuda:7')
asr_weight tensor(0.0009, device='cuda:7')
mt_weight tensor(1., device='cuda:5')
asr_weight tensor(0.0009, device='cuda:5')
mt_weight tensor(1., device='cuda:6')
asr_weight tensor(0.0009, device='cuda:6')
mt_weight tensor(1., device='cuda:2')
asr_weight tensor(0.0009, device='cuda:2')
mt_weight tensor(1., device='cuda:1')
asr_weight tensor(0.0009, device='cuda:1')
2023-07-23 04:46:47 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 4.221 | trans_loss 5.598 | nll_loss 2.872 | w2v_ctc_loss 1.345 | task_loss 4.609 | contrastive_loss 0.253 | total 4003.4 | n_correct 2473.8 | ppl 7.32 | accuracy 61.792 | uer 16.903 | wer 18.72 | raw_wer 18.72 | bleu 19.69 | wps 2063.1 | wpb 4003.4 | bsz 141.8 | num_updates 41254 | best_bleu 20.09
2023-07-23 04:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41254 updates
2023-07-23 04:46:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 04:46:58 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 04:46:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 28 @ 41254 updates, score 19.69) (writing took 11.420791951939464 seconds)
2023-07-23 04:46:58 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-07-23 04:46:58 | INFO | train | epoch 028 | loss 4.196 | trans_loss 4.936 | nll_loss 2.107 | w2v_ctc_loss 0.596 | task_loss 1.376 | contrastive_loss 0.097 | total 4137.55 | n_correct 2731.94 | ppl 4.31 | accuracy 66.028 | wps 9549.2 | ups 1.15 | wpb 8275.7 | bsz 305.2 | num_updates 41254 | lr 6.96277e-05 | gnorm 0.558 | clip 0 | loss_scale 32 | train_wall 1188 | gb_free 16.7 | wall 29160
2023-07-23 04:46:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 04:46:58 | INFO | fairseq.trainer | begin training epoch 29
2023-07-23 04:46:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 04:47:45 | INFO | train_inner | epoch 029:     46 / 1474 loss=4.179, trans_loss=4.921, nll_loss=2.087, w2v_ctc_loss=0.599, task_loss=1.319, contrastive_loss=0.073, total=4169.12, n_correct=2766.44, ppl=4.25, accuracy=66.355, wps=6618.7, ups=0.79, wpb=8337, bsz=316.4, num_updates=41300, lr=6.95889e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=80, gb_free=16.5, wall=29207
2023-07-23 04:49:06 | INFO | train_inner | epoch 029:    146 / 1474 loss=4.183, trans_loss=4.923, nll_loss=2.089, w2v_ctc_loss=0.593, task_loss=1.366, contrastive_loss=0.09, total=4105.72, n_correct=2719.49, ppl=4.25, accuracy=66.237, wps=10097.5, ups=1.23, wpb=8206.9, bsz=304.1, num_updates=41400, lr=6.95048e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=81, gb_free=16.2, wall=29288
2023-07-23 04:50:28 | INFO | train_inner | epoch 029:    246 / 1474 loss=4.172, trans_loss=4.916, nll_loss=2.082, w2v_ctc_loss=0.579, task_loss=1.255, contrastive_loss=0.177, total=4199.67, n_correct=2789.48, ppl=4.23, accuracy=66.421, wps=10251.7, ups=1.22, wpb=8398.8, bsz=330.5, num_updates=41500, lr=6.9421e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=81, gb_free=15.8, wall=29370
2023-07-23 04:51:49 | INFO | train_inner | epoch 029:    346 / 1474 loss=4.198, trans_loss=4.931, nll_loss=2.1, w2v_ctc_loss=0.607, task_loss=1.471, contrastive_loss=0.053, total=4095.17, n_correct=2703.17, ppl=4.29, accuracy=66.009, wps=10143.1, ups=1.24, wpb=8201.6, bsz=291.2, num_updates=41600, lr=6.93375e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=80, gb_free=16.8, wall=29451
2023-07-23 04:53:10 | INFO | train_inner | epoch 029:    446 / 1474 loss=4.171, trans_loss=4.913, nll_loss=2.076, w2v_ctc_loss=0.585, task_loss=1.322, contrastive_loss=0.048, total=4157.44, n_correct=2769.75, ppl=4.22, accuracy=66.622, wps=10209.9, ups=1.23, wpb=8310.1, bsz=307.7, num_updates=41700, lr=6.92543e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=81, gb_free=16.7, wall=29532
2023-07-23 04:54:32 | INFO | train_inner | epoch 029:    546 / 1474 loss=4.204, trans_loss=4.938, nll_loss=2.109, w2v_ctc_loss=0.595, task_loss=1.46, contrastive_loss=0.147, total=4150.87, n_correct=2738.55, ppl=4.31, accuracy=65.975, wps=10150.9, ups=1.23, wpb=8280.5, bsz=294.9, num_updates=41800, lr=6.91714e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=81, gb_free=15.9, wall=29614
2023-07-23 04:55:53 | INFO | train_inner | epoch 029:    646 / 1474 loss=4.185, trans_loss=4.924, nll_loss=2.092, w2v_ctc_loss=0.587, task_loss=1.296, contrastive_loss=0.213, total=4143.02, n_correct=2744.69, ppl=4.26, accuracy=66.249, wps=10277, ups=1.24, wpb=8290.3, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=80, gb_free=17.2, wall=29694
2023-07-23 04:57:15 | INFO | train_inner | epoch 029:    746 / 1474 loss=4.181, trans_loss=4.925, nll_loss=2.094, w2v_ctc_loss=0.587, task_loss=1.266, contrastive_loss=0.132, total=4249.79, n_correct=2816.17, ppl=4.27, accuracy=66.266, wps=10316.7, ups=1.21, wpb=8508.7, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.55, clip=0, loss_scale=32, train_wall=82, gb_free=16.8, wall=29777
2023-07-23 04:57:15 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 04:57:39 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.225 | trans_loss 5.591 | nll_loss 2.864 | w2v_ctc_loss 1.375 | task_loss 4.635 | contrastive_loss 0.255 | total 4003.4 | n_correct 2481.7 | ppl 7.28 | accuracy 61.99 | uer 17.079 | wer 18.855 | raw_wer 18.855 | bleu 19.59 | wps 2091.2 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 20.09
2023-07-23 04:57:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-07-23 04:57:39 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_29_42000.pt
2023-07-23 04:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_29_42000.pt
2023-07-23 04:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 19.59) (writing took 11.097133297473192 seconds)
2023-07-23 04:59:12 | INFO | train_inner | epoch 029:    846 / 1474 loss=4.202, trans_loss=4.94, nll_loss=2.111, w2v_ctc_loss=0.59, task_loss=1.523, contrastive_loss=0.047, total=4027.19, n_correct=2652.9, ppl=4.32, accuracy=65.875, wps=6911.1, ups=0.86, wpb=8060.5, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=80, gb_free=17.4, wall=29894
2023-07-23 05:00:32 | INFO | train_inner | epoch 029:    946 / 1474 loss=4.201, trans_loss=4.938, nll_loss=2.109, w2v_ctc_loss=0.601, task_loss=1.4, contrastive_loss=0.059, total=4082.14, n_correct=2696.32, ppl=4.31, accuracy=66.052, wps=10161.5, ups=1.24, wpb=8177.2, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=80, gb_free=15.6, wall=29974
2023-07-23 05:01:54 | INFO | train_inner | epoch 029:   1046 / 1474 loss=4.188, trans_loss=4.928, nll_loss=2.096, w2v_ctc_loss=0.583, task_loss=1.365, contrastive_loss=0.133, total=4148.18, n_correct=2750.59, ppl=4.27, accuracy=66.308, wps=10168.5, ups=1.22, wpb=8303.3, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=81, gb_free=16.1, wall=30056
2023-07-23 05:03:14 | INFO | train_inner | epoch 029:   1146 / 1474 loss=4.209, trans_loss=4.942, nll_loss=2.114, w2v_ctc_loss=0.605, task_loss=1.506, contrastive_loss=0.044, total=4063.95, n_correct=2676.76, ppl=4.33, accuracy=65.866, wps=10102, ups=1.24, wpb=8138.5, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=80, gb_free=13.6, wall=30136
2023-07-23 05:04:36 | INFO | train_inner | epoch 029:   1246 / 1474 loss=4.202, trans_loss=4.942, nll_loss=2.114, w2v_ctc_loss=0.601, task_loss=1.397, contrastive_loss=0.052, total=4158.81, n_correct=2744.63, ppl=4.33, accuracy=65.996, wps=10221.8, ups=1.23, wpb=8313.9, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=81, gb_free=15.9, wall=30218
2023-07-23 05:05:57 | INFO | train_inner | epoch 029:   1346 / 1474 loss=4.191, trans_loss=4.933, nll_loss=2.103, w2v_ctc_loss=0.591, task_loss=1.351, contrastive_loss=0.117, total=4166.34, n_correct=2757.76, ppl=4.3, accuracy=66.191, wps=10236.3, ups=1.23, wpb=8312.8, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=81, gb_free=17.9, wall=30299
2023-07-23 05:07:18 | INFO | train_inner | epoch 029:   1446 / 1474 loss=4.194, trans_loss=4.934, nll_loss=2.106, w2v_ctc_loss=0.591, task_loss=1.348, contrastive_loss=0.147, total=4162.2, n_correct=2755.26, ppl=4.3, accuracy=66.197, wps=10231.4, ups=1.23, wpb=8310.9, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=81, gb_free=17.5, wall=30380
2023-07-23 05:07:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 05:08:04 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 4.223 | trans_loss 5.587 | nll_loss 2.86 | w2v_ctc_loss 1.378 | task_loss 4.655 | contrastive_loss 0.255 | total 4003.4 | n_correct 2482.2 | ppl 7.26 | accuracy 62.002 | uer 16.877 | wer 18.664 | raw_wer 18.664 | bleu 19.85 | wps 2156.1 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 20.09
2023-07-23 05:08:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-07-23 05:08:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8509.pt
2023-07-23 05:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8509.pt
2023-07-23 05:08:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8509.pt (epoch 29 @ 42728 updates, score 19.85) (writing took 11.905576149001718 seconds)
2023-07-23 05:08:17 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-07-23 05:08:17 | INFO | train | epoch 029 | loss 4.19 | trans_loss 4.93 | nll_loss 2.099 | w2v_ctc_loss 0.592 | task_loss 1.373 | contrastive_loss 0.104 | total 4138.65 | n_correct 2738.99 | ppl 4.28 | accuracy 66.181 | wps 9540.5 | ups 1.15 | wpb 8277.3 | bsz 305.7 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.56 | clip 0 | loss_scale 64 | train_wall 1190 | gb_free 16.4 | wall 30439
2023-07-23 05:08:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 05:08:17 | INFO | fairseq.trainer | begin training epoch 30
2023-07-23 05:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 05:09:24 | INFO | train_inner | epoch 030:     72 / 1474 loss=4.173, trans_loss=4.916, nll_loss=2.081, w2v_ctc_loss=0.578, task_loss=1.298, contrastive_loss=0.161, total=4182.65, n_correct=2783.81, ppl=4.23, accuracy=66.556, wps=6658.4, ups=0.8, wpb=8352.5, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=81, gb_free=13.8, wall=30506
2023-07-23 05:10:44 | INFO | train_inner | epoch 030:    172 / 1474 loss=4.166, trans_loss=4.905, nll_loss=2.066, w2v_ctc_loss=0.588, task_loss=1.289, contrastive_loss=0.095, total=4203.05, n_correct=2805.56, ppl=4.19, accuracy=66.751, wps=10404.8, ups=1.24, wpb=8404.3, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=80, gb_free=17.5, wall=30586
2023-07-23 05:12:06 | INFO | train_inner | epoch 030:    272 / 1474 loss=4.175, trans_loss=4.912, nll_loss=2.074, w2v_ctc_loss=0.589, task_loss=1.416, contrastive_loss=0.046, total=4116.93, n_correct=2739.2, ppl=4.21, accuracy=66.535, wps=10147.8, ups=1.23, wpb=8232.2, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=81, gb_free=17.1, wall=30667
2023-07-23 05:13:27 | INFO | train_inner | epoch 030:    372 / 1474 loss=4.175, trans_loss=4.916, nll_loss=2.079, w2v_ctc_loss=0.587, task_loss=1.379, contrastive_loss=0.05, total=4173.13, n_correct=2779.27, ppl=4.23, accuracy=66.599, wps=10229.6, ups=1.23, wpb=8337.6, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=81, gb_free=12.2, wall=30749
2023-07-23 05:14:47 | INFO | train_inner | epoch 030:    472 / 1474 loss=4.174, trans_loss=4.916, nll_loss=2.081, w2v_ctc_loss=0.581, task_loss=1.309, contrastive_loss=0.115, total=4135.2, n_correct=2748.28, ppl=4.23, accuracy=66.461, wps=10310.5, ups=1.25, wpb=8277.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=80, gb_free=17, wall=30829
2023-07-23 05:16:09 | INFO | train_inner | epoch 030:    572 / 1474 loss=4.177, trans_loss=4.919, nll_loss=2.085, w2v_ctc_loss=0.583, task_loss=1.338, contrastive_loss=0.079, total=4168.65, n_correct=2774.28, ppl=4.24, accuracy=66.551, wps=10268.6, ups=1.23, wpb=8348.4, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=81, gb_free=16.1, wall=30911
2023-07-23 05:17:30 | INFO | train_inner | epoch 030:    672 / 1474 loss=4.179, trans_loss=4.919, nll_loss=2.085, w2v_ctc_loss=0.59, task_loss=1.357, contrastive_loss=0.092, total=4183.65, n_correct=2777.37, ppl=4.24, accuracy=66.386, wps=10289.5, ups=1.23, wpb=8370.4, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=81, gb_free=17, wall=30992
2023-07-23 05:18:51 | INFO | train_inner | epoch 030:    772 / 1474 loss=4.197, trans_loss=4.932, nll_loss=2.101, w2v_ctc_loss=0.599, task_loss=1.403, contrastive_loss=0.171, total=4106.9, n_correct=2718.1, ppl=4.29, accuracy=66.184, wps=10090.1, ups=1.23, wpb=8199.4, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=81, gb_free=12.3, wall=31073
2023-07-23 05:20:12 | INFO | train_inner | epoch 030:    872 / 1474 loss=4.188, trans_loss=4.927, nll_loss=2.095, w2v_ctc_loss=0.589, task_loss=1.438, contrastive_loss=0.053, total=4089.18, n_correct=2707.6, ppl=4.27, accuracy=66.214, wps=10125.8, ups=1.24, wpb=8182.6, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=80, gb_free=16.9, wall=31154
2023-07-23 05:21:33 | INFO | train_inner | epoch 030:    972 / 1474 loss=4.19, trans_loss=4.93, nll_loss=2.099, w2v_ctc_loss=0.596, task_loss=1.387, contrastive_loss=0.073, total=4140.03, n_correct=2738.73, ppl=4.28, accuracy=66.152, wps=10191.4, ups=1.23, wpb=8275.9, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.56, clip=0, loss_scale=64, train_wall=81, gb_free=14.1, wall=31235
2023-07-23 05:22:55 | INFO | train_inner | epoch 030:   1072 / 1474 loss=4.2, trans_loss=4.933, nll_loss=2.102, w2v_ctc_loss=0.586, task_loss=1.537, contrastive_loss=0.14, total=4101.12, n_correct=2710.81, ppl=4.29, accuracy=66.099, wps=9989.9, ups=1.22, wpb=8187.1, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.558, clip=0, loss_scale=64, train_wall=81, gb_free=17, wall=31317
2023-07-23 05:24:17 | INFO | train_inner | epoch 030:   1172 / 1474 loss=4.187, trans_loss=4.929, nll_loss=2.098, w2v_ctc_loss=0.58, task_loss=1.318, contrastive_loss=0.122, total=4168.22, n_correct=2765.8, ppl=4.28, accuracy=66.354, wps=10264.3, ups=1.23, wpb=8349.6, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=81, gb_free=16.9, wall=31398
2023-07-23 05:25:38 | INFO | train_inner | epoch 030:   1272 / 1474 loss=4.202, trans_loss=4.935, nll_loss=2.104, w2v_ctc_loss=0.593, task_loss=1.538, contrastive_loss=0.055, total=4032.74, n_correct=2669.02, ppl=4.3, accuracy=66.184, wps=9901.9, ups=1.22, wpb=8092.2, bsz=281.8, num_updates=44000, lr=6.742e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=81, gb_free=17, wall=31480
2023-07-23 05:25:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 05:26:01 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.232 | trans_loss 5.593 | nll_loss 2.863 | w2v_ctc_loss 1.391 | task_loss 4.62 | contrastive_loss 0.259 | total 4003.4 | n_correct 2475.2 | ppl 7.28 | accuracy 61.827 | uer 16.898 | wer 18.642 | raw_wer 18.642 | bleu 19.78 | wps 2233.5 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 20.09
2023-07-23 05:26:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-07-23 05:26:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_30_44000.pt
2023-07-23 05:26:04 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_30_44000.pt
2023-07-23 05:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 19.78) (writing took 13.262237124145031 seconds)
2023-07-23 05:27:37 | INFO | train_inner | epoch 030:   1372 / 1474 loss=4.175, trans_loss=4.921, nll_loss=2.089, w2v_ctc_loss=0.586, task_loss=1.293, contrastive_loss=0.068, total=4166.96, n_correct=2765.56, ppl=4.25, accuracy=66.369, wps=7055.6, ups=0.84, wpb=8350.6, bsz=322.3, num_updates=44100, lr=6.73435e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=80, gb_free=16.4, wall=31599
2023-07-23 05:28:57 | INFO | train_inner | epoch 030:   1472 / 1474 loss=4.187, trans_loss=4.926, nll_loss=2.095, w2v_ctc_loss=0.589, task_loss=1.311, contrastive_loss=0.211, total=4125.17, n_correct=2731.47, ppl=4.27, accuracy=66.215, wps=10239.4, ups=1.24, wpb=8232.7, bsz=310, num_updates=44200, lr=6.72673e-05, gnorm=0.563, clip=0, loss_scale=128, train_wall=80, gb_free=17.1, wall=31679
2023-07-23 05:28:59 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 05:29:22 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 4.21 | trans_loss 5.586 | nll_loss 2.86 | w2v_ctc_loss 1.336 | task_loss 4.625 | contrastive_loss 0.25 | total 4003.4 | n_correct 2480.6 | ppl 7.26 | accuracy 61.962 | uer 16.84 | wer 18.612 | raw_wer 18.612 | bleu 19.35 | wps 2200 | wpb 4003.4 | bsz 141.8 | num_updates 44202 | best_bleu 20.09
2023-07-23 05:29:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44202 updates
2023-07-23 05:29:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 05:29:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 05:29:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 30 @ 44202 updates, score 19.35) (writing took 11.184084990993142 seconds)
2023-07-23 05:29:33 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-07-23 05:29:33 | INFO | train | epoch 030 | loss 4.183 | trans_loss 4.922 | nll_loss 2.088 | w2v_ctc_loss 0.587 | task_loss 1.373 | contrastive_loss 0.103 | total 4138.65 | n_correct 2747.02 | ppl 4.25 | accuracy 66.375 | wps 9559 | ups 1.15 | wpb 8277.3 | bsz 305.7 | num_updates 44202 | lr 6.72658e-05 | gnorm 0.56 | clip 0 | loss_scale 128 | train_wall 1189 | gb_free 17.2 | wall 31715
2023-07-23 05:29:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 05:29:33 | INFO | fairseq.trainer | begin training epoch 31
2023-07-23 05:29:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 05:31:01 | INFO | train_inner | epoch 031:     98 / 1474 loss=4.169, trans_loss=4.905, nll_loss=2.065, w2v_ctc_loss=0.586, task_loss=1.428, contrastive_loss=0.052, total=4081.34, n_correct=2717.49, ppl=4.18, accuracy=66.583, wps=6609.8, ups=0.81, wpb=8177.1, bsz=294.7, num_updates=44300, lr=6.71913e-05, gnorm=0.559, clip=0, loss_scale=128, train_wall=80, gb_free=16.6, wall=31803
2023-07-23 05:32:22 | INFO | train_inner | epoch 031:    198 / 1474 loss=4.172, trans_loss=4.91, nll_loss=2.072, w2v_ctc_loss=0.581, task_loss=1.401, contrastive_loss=0.079, total=4146.03, n_correct=2763, ppl=4.2, accuracy=66.642, wps=10177.3, ups=1.23, wpb=8295.2, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.555, clip=0, loss_scale=128, train_wall=81, gb_free=13.7, wall=31884
2023-07-23 05:33:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-23 05:33:45 | INFO | train_inner | epoch 031:    299 / 1474 loss=4.175, trans_loss=4.91, nll_loss=2.072, w2v_ctc_loss=0.589, task_loss=1.432, contrastive_loss=0.048, total=4124.61, n_correct=2748, ppl=4.2, accuracy=66.624, wps=10031.3, ups=1.22, wpb=8249.1, bsz=295.1, num_updates=44500, lr=6.70402e-05, gnorm=0.556, clip=0, loss_scale=64, train_wall=82, gb_free=16.3, wall=31966
2023-07-23 05:35:06 | INFO | train_inner | epoch 031:    399 / 1474 loss=4.182, trans_loss=4.918, nll_loss=2.082, w2v_ctc_loss=0.588, task_loss=1.501, contrastive_loss=0.054, total=4092.62, n_correct=2714.49, ppl=4.23, accuracy=66.326, wps=10005.5, ups=1.22, wpb=8170.5, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=81, gb_free=17.3, wall=32048
2023-07-23 05:36:27 | INFO | train_inner | epoch 031:    499 / 1474 loss=4.177, trans_loss=4.913, nll_loss=2.077, w2v_ctc_loss=0.593, task_loss=1.434, contrastive_loss=0.062, total=4111.85, n_correct=2731.8, ppl=4.22, accuracy=66.437, wps=10121.4, ups=1.23, wpb=8227.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=81, gb_free=11.5, wall=32129
2023-07-23 05:37:49 | INFO | train_inner | epoch 031:    599 / 1474 loss=4.176, trans_loss=4.915, nll_loss=2.079, w2v_ctc_loss=0.584, task_loss=1.436, contrastive_loss=0.053, total=4083.44, n_correct=2717.4, ppl=4.23, accuracy=66.547, wps=10072.7, ups=1.23, wpb=8161.2, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.566, clip=0, loss_scale=64, train_wall=81, gb_free=16.9, wall=32210
2023-07-23 05:39:10 | INFO | train_inner | epoch 031:    699 / 1474 loss=4.161, trans_loss=4.904, nll_loss=2.065, w2v_ctc_loss=0.572, task_loss=1.31, contrastive_loss=0.054, total=4213.98, n_correct=2814.89, ppl=4.19, accuracy=66.799, wps=10377.3, ups=1.23, wpb=8435.3, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.555, clip=0, loss_scale=64, train_wall=81, gb_free=16.6, wall=32292
2023-07-23 05:40:31 | INFO | train_inner | epoch 031:    799 / 1474 loss=4.187, trans_loss=4.919, nll_loss=2.085, w2v_ctc_loss=0.581, task_loss=1.436, contrastive_loss=0.123, total=4097.37, n_correct=2718.1, ppl=4.24, accuracy=66.338, wps=10136.4, ups=1.23, wpb=8230.1, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.557, clip=0, loss_scale=64, train_wall=81, gb_free=13.3, wall=32373
mt_weight tensor(1., device='cuda:0')
asr_weight tensor(0.0009, device='cuda:0')
2023-07-23 05:41:52 | INFO | train_inner | epoch 031:    899 / 1474 loss=4.178, trans_loss=4.916, nll_loss=2.081, w2v_ctc_loss=0.582, task_loss=1.432, contrastive_loss=0.069, total=4096.72, n_correct=2725.09, ppl=4.23, accuracy=66.519, wps=10130.8, ups=1.24, wpb=8194, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=80, gb_free=17.4, wall=32454
2023-07-23 05:43:13 | INFO | train_inner | epoch 031:    999 / 1474 loss=4.175, trans_loss=4.92, nll_loss=2.087, w2v_ctc_loss=0.581, task_loss=1.297, contrastive_loss=0.152, total=4187.84, n_correct=2789.54, ppl=4.25, accuracy=66.61, wps=10288.9, ups=1.23, wpb=8346.1, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=81, gb_free=17.4, wall=32535
2023-07-23 05:44:35 | INFO | train_inner | epoch 031:   1099 / 1474 loss=4.175, trans_loss=4.918, nll_loss=2.084, w2v_ctc_loss=0.58, task_loss=1.345, contrastive_loss=0.102, total=4149.44, n_correct=2758.17, ppl=4.24, accuracy=66.471, wps=10192.8, ups=1.23, wpb=8309.1, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=81, gb_free=17.7, wall=32616
2023-07-23 05:45:55 | INFO | train_inner | epoch 031:   1199 / 1474 loss=4.178, trans_loss=4.918, nll_loss=2.085, w2v_ctc_loss=0.584, task_loss=1.284, contrastive_loss=0.215, total=4189.76, n_correct=2784.12, ppl=4.24, accuracy=66.451, wps=10360, ups=1.24, wpb=8360.8, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=80, gb_free=13.5, wall=32697
2023-07-23 05:47:16 | INFO | train_inner | epoch 031:   1299 / 1474 loss=4.169, trans_loss=4.917, nll_loss=2.083, w2v_ctc_loss=0.584, task_loss=1.236, contrastive_loss=0.06, total=4227.44, n_correct=2817.43, ppl=4.24, accuracy=66.646, wps=10457.2, ups=1.24, wpb=8445.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.553, clip=0, loss_scale=64, train_wall=80, gb_free=16.7, wall=32778
2023-07-23 05:48:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-23 05:48:38 | INFO | train_inner | epoch 031:   1400 / 1474 loss=4.175, trans_loss=4.915, nll_loss=2.081, w2v_ctc_loss=0.58, task_loss=1.281, contrastive_loss=0.156, total=4162.83, n_correct=2773.43, ppl=4.23, accuracy=66.624, wps=10134.2, ups=1.22, wpb=8335.9, bsz=319.1, num_updates=45600, lr=6.62266e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=82, gb_free=16.7, wall=32860
2023-07-23 05:49:38 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1., device='cuda:4')
asr_weight tensor(0.0009, device='cuda:4')
mt_weight tensor(1., device='cuda:6')
asr_weight tensor(0.0009, device='cuda:6')
mt_weight tensor(1., device='cuda:3')
asr_weight tensor(0.0009, device='cuda:3')
mt_weight tensor(1., device='cuda:5')
asr_weight tensor(0.0009, device='cuda:5')
mt_weight tensor(1., device='cuda:7')
asr_weight tensor(0.0009, device='cuda:7')
mt_weight tensor(1., device='cuda:2')
asr_weight tensor(0.0009, device='cuda:2')
mt_weight tensor(1., device='cuda:1')
asr_weight tensor(0.0009, device='cuda:1')
2023-07-23 05:50:01 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 4.206 | trans_loss 5.585 | nll_loss 2.857 | w2v_ctc_loss 1.331 | task_loss 4.623 | contrastive_loss 0.245 | total 4003.4 | n_correct 2478.8 | ppl 7.24 | accuracy 61.917 | uer 16.548 | wer 18.445 | raw_wer 18.445 | bleu 19.81 | wps 2217.4 | wpb 4003.4 | bsz 141.8 | num_updates 45674 | best_bleu 20.09
2023-07-23 05:50:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45674 updates
2023-07-23 05:50:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8109.pt
2023-07-23 05:50:05 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8109.pt
2023-07-23 05:50:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8109.pt (epoch 31 @ 45674 updates, score 19.81) (writing took 13.17859541065991 seconds)
2023-07-23 05:50:15 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-07-23 05:50:15 | INFO | train | epoch 031 | loss 4.176 | trans_loss 4.915 | nll_loss 2.079 | w2v_ctc_loss 0.583 | task_loss 1.377 | contrastive_loss 0.09 | total 4135.53 | n_correct 2751.72 | ppl 4.23 | accuracy 66.538 | wps 9808.5 | ups 1.19 | wpb 8272 | bsz 304.8 | num_updates 45674 | lr 6.61729e-05 | gnorm 0.561 | clip 0 | loss_scale 32 | train_wall 1189 | gb_free 12.5 | wall 32956
2023-07-23 05:50:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 05:50:15 | INFO | fairseq.trainer | begin training epoch 32
2023-07-23 05:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 05:50:44 | INFO | train_inner | epoch 032:     26 / 1474 loss=4.179, trans_loss=4.916, nll_loss=2.081, w2v_ctc_loss=0.585, task_loss=1.448, contrastive_loss=0.049, total=4040.88, n_correct=2688.35, ppl=4.23, accuracy=66.529, wps=6426.2, ups=0.79, wpb=8089.7, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=80, gb_free=15.7, wall=32986
2023-07-23 05:52:05 | INFO | train_inner | epoch 032:    126 / 1474 loss=4.141, trans_loss=4.886, nll_loss=2.042, w2v_ctc_loss=0.565, task_loss=1.275, contrastive_loss=0.059, total=4222.14, n_correct=2834.93, ppl=4.12, accuracy=67.144, wps=10448.5, ups=1.24, wpb=8447.4, bsz=322.6, num_updates=45800, lr=6.60819e-05, gnorm=0.548, clip=0, loss_scale=32, train_wall=80, gb_free=15.7, wall=33067
2023-07-23 05:53:27 | INFO | train_inner | epoch 032:    226 / 1474 loss=4.162, trans_loss=4.904, nll_loss=2.065, w2v_ctc_loss=0.573, task_loss=1.309, contrastive_loss=0.07, total=4159.77, n_correct=2777.16, ppl=4.19, accuracy=66.762, wps=10152.4, ups=1.21, wpb=8360.9, bsz=320.8, num_updates=45900, lr=6.60098e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=82, gb_free=16.4, wall=33149
2023-07-23 05:54:48 | INFO | train_inner | epoch 032:    326 / 1474 loss=4.144, trans_loss=4.89, nll_loss=2.047, w2v_ctc_loss=0.562, task_loss=1.301, contrastive_loss=0.062, total=4179.65, n_correct=2809.29, ppl=4.13, accuracy=67.214, wps=10318.1, ups=1.24, wpb=8343.5, bsz=313.8, num_updates=46000, lr=6.5938e-05, gnorm=0.557, clip=0, loss_scale=32, train_wall=80, gb_free=16.5, wall=33230
2023-07-23 05:54:48 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 05:55:11 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.217 | trans_loss 5.59 | nll_loss 2.862 | w2v_ctc_loss 1.352 | task_loss 4.627 | contrastive_loss 0.245 | total 4003.4 | n_correct 2475.2 | ppl 7.27 | accuracy 61.827 | uer 16.503 | wer 18.321 | raw_wer 18.321 | bleu 20.03 | wps 2202.8 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 20.09
2023-07-23 05:55:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-07-23 05:55:11 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_32_46000.pt
2023-07-23 05:55:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_32_46000.pt
2023-07-23 05:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 20.03) (writing took 16.723623683676124 seconds)
2023-07-23 05:56:50 | INFO | train_inner | epoch 032:    426 / 1474 loss=4.158, trans_loss=4.899, nll_loss=2.059, w2v_ctc_loss=0.574, task_loss=1.339, contrastive_loss=0.06, total=4172.34, n_correct=2793.99, ppl=4.17, accuracy=66.965, wps=6837.5, ups=0.82, wpb=8347.9, bsz=309.9, num_updates=46100, lr=6.58665e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=81, gb_free=17.2, wall=33352
2023-07-23 05:58:12 | INFO | train_inner | epoch 032:    526 / 1474 loss=4.174, trans_loss=4.91, nll_loss=2.074, w2v_ctc_loss=0.591, task_loss=1.341, contrastive_loss=0.144, total=4191.15, n_correct=2789.83, ppl=4.21, accuracy=66.565, wps=10207.8, ups=1.22, wpb=8378.5, bsz=315.1, num_updates=46200, lr=6.57952e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=81, gb_free=15.3, wall=33434
2023-07-23 05:59:34 | INFO | train_inner | epoch 032:    626 / 1474 loss=4.178, trans_loss=4.914, nll_loss=2.078, w2v_ctc_loss=0.583, task_loss=1.432, contrastive_loss=0.068, total=4138.05, n_correct=2754.13, ppl=4.22, accuracy=66.556, wps=10172.4, ups=1.23, wpb=8284.7, bsz=299.5, num_updates=46300, lr=6.57241e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=81, gb_free=13.7, wall=33516
2023-07-23 06:00:55 | INFO | train_inner | epoch 032:    726 / 1474 loss=4.168, trans_loss=4.908, nll_loss=2.07, w2v_ctc_loss=0.587, task_loss=1.388, contrastive_loss=0.051, total=4156.23, n_correct=2770.14, ppl=4.2, accuracy=66.65, wps=10163.2, ups=1.23, wpb=8292.8, bsz=303, num_updates=46400, lr=6.56532e-05, gnorm=0.555, clip=0, loss_scale=32, train_wall=81, gb_free=16.8, wall=33597
2023-07-23 06:02:16 | INFO | train_inner | epoch 032:    826 / 1474 loss=4.173, trans_loss=4.91, nll_loss=2.072, w2v_ctc_loss=0.575, task_loss=1.426, contrastive_loss=0.048, total=4112.3, n_correct=2744.28, ppl=4.2, accuracy=66.733, wps=10175.4, ups=1.24, wpb=8239.2, bsz=293.9, num_updates=46500, lr=6.55826e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=80, gb_free=16.1, wall=33678
2023-07-23 06:03:38 | INFO | train_inner | epoch 032:    926 / 1474 loss=4.166, trans_loss=4.908, nll_loss=2.07, w2v_ctc_loss=0.576, task_loss=1.42, contrastive_loss=0.047, total=4139.37, n_correct=2760.27, ppl=4.2, accuracy=66.683, wps=10148, ups=1.23, wpb=8269.1, bsz=298.6, num_updates=46600, lr=6.55122e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=81, gb_free=13.2, wall=33760
2023-07-23 06:04:59 | INFO | train_inner | epoch 032:   1026 / 1474 loss=4.176, trans_loss=4.913, nll_loss=2.077, w2v_ctc_loss=0.578, task_loss=1.355, contrastive_loss=0.141, total=4121.85, n_correct=2746.3, ppl=4.22, accuracy=66.628, wps=10217.4, ups=1.24, wpb=8262, bsz=306.1, num_updates=46700, lr=6.5442e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=80, gb_free=17.1, wall=33841
2023-07-23 06:06:20 | INFO | train_inner | epoch 032:   1126 / 1474 loss=4.195, trans_loss=4.922, nll_loss=2.087, w2v_ctc_loss=0.592, task_loss=1.633, contrastive_loss=0.084, total=4015.59, n_correct=2661.52, ppl=4.25, accuracy=66.28, wps=9871.5, ups=1.23, wpb=8031.7, bsz=270.1, num_updates=46800, lr=6.5372e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=81, gb_free=17.4, wall=33922
2023-07-23 06:07:42 | INFO | train_inner | epoch 032:   1226 / 1474 loss=4.187, trans_loss=4.924, nll_loss=2.093, w2v_ctc_loss=0.585, task_loss=1.352, contrastive_loss=0.192, total=4153.44, n_correct=2756.69, ppl=4.27, accuracy=66.371, wps=10148.8, ups=1.22, wpb=8288.1, bsz=310.8, num_updates=46900, lr=6.53023e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=81, gb_free=16.5, wall=34004
2023-07-23 06:09:02 | INFO | train_inner | epoch 032:   1326 / 1474 loss=4.179, trans_loss=4.918, nll_loss=2.084, w2v_ctc_loss=0.589, task_loss=1.415, contrastive_loss=0.047, total=4075.86, n_correct=2710.08, ppl=4.24, accuracy=66.491, wps=10156.4, ups=1.25, wpb=8148.8, bsz=295.4, num_updates=47000, lr=6.52328e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=80, gb_free=17, wall=34084
2023-07-23 06:10:23 | INFO | train_inner | epoch 032:   1426 / 1474 loss=4.186, trans_loss=4.919, nll_loss=2.086, w2v_ctc_loss=0.584, task_loss=1.366, contrastive_loss=0.279, total=4116.4, n_correct=2736.58, ppl=4.25, accuracy=66.48, wps=10165.7, ups=1.24, wpb=8215.8, bsz=307.6, num_updates=47100, lr=6.51635e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=80, gb_free=16.9, wall=34165
2023-07-23 06:11:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 06:11:27 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 4.22 | trans_loss 5.59 | nll_loss 2.865 | w2v_ctc_loss 1.36 | task_loss 4.626 | contrastive_loss 0.256 | total 4003.4 | n_correct 2478.3 | ppl 7.28 | accuracy 61.905 | uer 16.699 | wer 18.62 | raw_wer 18.62 | bleu 19.97 | wps 1966 | wpb 4003.4 | bsz 141.8 | num_updates 47148 | best_bleu 20.09
2023-07-23 06:11:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47148 updates
2023-07-23 06:11:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.9707.pt
2023-07-23 06:11:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.9707.pt
2023-07-23 06:11:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.9707.pt (epoch 32 @ 47148 updates, score 19.97) (writing took 12.686835607513785 seconds)
2023-07-23 06:11:40 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-07-23 06:11:40 | INFO | train | epoch 032 | loss 4.17 | trans_loss 4.909 | nll_loss 2.071 | w2v_ctc_loss 0.579 | task_loss 1.373 | contrastive_loss 0.102 | total 4138.65 | n_correct 2759.82 | ppl 4.2 | accuracy 66.684 | wps 9493.3 | ups 1.15 | wpb 8277.3 | bsz 305.7 | num_updates 47148 | lr 6.51303e-05 | gnorm 0.562 | clip 0 | loss_scale 32 | train_wall 1190 | gb_free 16.8 | wall 34242
2023-07-23 06:11:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 06:11:40 | INFO | fairseq.trainer | begin training epoch 33
2023-07-23 06:11:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 06:12:31 | INFO | train_inner | epoch 033:     52 / 1474 loss=4.162, trans_loss=4.905, nll_loss=2.067, w2v_ctc_loss=0.573, task_loss=1.295, contrastive_loss=0.152, total=4149.21, n_correct=2772.12, ppl=4.19, accuracy=66.811, wps=6457.1, ups=0.78, wpb=8287.9, bsz=320.5, num_updates=47200, lr=6.50945e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=81, gb_free=17.2, wall=34293
2023-07-23 06:13:52 | INFO | train_inner | epoch 033:    152 / 1474 loss=4.155, trans_loss=4.891, nll_loss=2.046, w2v_ctc_loss=0.559, task_loss=1.481, contrastive_loss=0.038, total=4073.9, n_correct=2733.3, ppl=4.13, accuracy=67.093, wps=10116.1, ups=1.24, wpb=8168.9, bsz=284.8, num_updates=47300, lr=6.50256e-05, gnorm=0.559, clip=0, loss_scale=32, train_wall=80, gb_free=15.5, wall=34374
2023-07-23 06:15:14 | INFO | train_inner | epoch 033:    252 / 1474 loss=4.148, trans_loss=4.888, nll_loss=2.046, w2v_ctc_loss=0.567, task_loss=1.172, contrastive_loss=0.219, total=4280.14, n_correct=2874.68, ppl=4.13, accuracy=67.163, wps=10510, ups=1.23, wpb=8576, bsz=346.5, num_updates=47400, lr=6.4957e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=81, gb_free=16.6, wall=34456
2023-07-23 06:16:35 | INFO | train_inner | epoch 033:    352 / 1474 loss=4.159, trans_loss=4.9, nll_loss=2.06, w2v_ctc_loss=0.577, task_loss=1.401, contrastive_loss=0.069, total=4120.27, n_correct=2755.61, ppl=4.17, accuracy=66.879, wps=10090, ups=1.23, wpb=8214.2, bsz=300.7, num_updates=47500, lr=6.48886e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=81, gb_free=17.4, wall=34537
2023-07-23 06:17:56 | INFO | train_inner | epoch 033:    452 / 1474 loss=4.14, trans_loss=4.884, nll_loss=2.039, w2v_ctc_loss=0.563, task_loss=1.302, contrastive_loss=0.046, total=4141.22, n_correct=2781.29, ppl=4.11, accuracy=67.161, wps=10258.5, ups=1.24, wpb=8279.3, bsz=310.8, num_updates=47600, lr=6.48204e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=80, gb_free=16.6, wall=34618
2023-07-23 06:19:17 | INFO | train_inner | epoch 033:    552 / 1474 loss=4.172, trans_loss=4.91, nll_loss=2.071, w2v_ctc_loss=0.585, task_loss=1.428, contrastive_loss=0.068, total=4133.59, n_correct=2754.27, ppl=4.2, accuracy=66.631, wps=10154.5, ups=1.23, wpb=8237.5, bsz=294, num_updates=47700, lr=6.47524e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=81, gb_free=15.5, wall=34699
2023-07-23 06:20:38 | INFO | train_inner | epoch 033:    652 / 1474 loss=4.174, trans_loss=4.912, nll_loss=2.075, w2v_ctc_loss=0.581, task_loss=1.401, contrastive_loss=0.103, total=4157.63, n_correct=2766.3, ppl=4.21, accuracy=66.536, wps=10189.4, ups=1.23, wpb=8308.5, bsz=301.6, num_updates=47800, lr=6.46846e-05, gnorm=0.568, clip=0, loss_scale=64, train_wall=81, gb_free=17.8, wall=34780
2023-07-23 06:21:59 | INFO | train_inner | epoch 033:    752 / 1474 loss=4.174, trans_loss=4.909, nll_loss=2.071, w2v_ctc_loss=0.59, task_loss=1.49, contrastive_loss=0.047, total=4070.75, n_correct=2713.76, ppl=4.2, accuracy=66.665, wps=10063.3, ups=1.24, wpb=8130.5, bsz=287.2, num_updates=47900, lr=6.46171e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=80, gb_free=16.6, wall=34861
2023-07-23 06:23:20 | INFO | train_inner | epoch 033:    852 / 1474 loss=4.155, trans_loss=4.898, nll_loss=2.058, w2v_ctc_loss=0.559, task_loss=1.307, contrastive_loss=0.117, total=4130.24, n_correct=2769.79, ppl=4.16, accuracy=67.061, wps=10246.1, ups=1.24, wpb=8285.5, bsz=316.3, num_updates=48000, lr=6.45497e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=80, gb_free=16.9, wall=34942
2023-07-23 06:23:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 06:23:45 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.221 | trans_loss 5.592 | nll_loss 2.867 | w2v_ctc_loss 1.359 | task_loss 4.633 | contrastive_loss 0.251 | total 4003.4 | n_correct 2472 | ppl 7.29 | accuracy 61.748 | uer 16.938 | wer 18.612 | raw_wer 18.612 | bleu 19.62 | wps 2018.7 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 20.09
2023-07-23 06:23:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-07-23 06:23:45 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_33_48000.pt
2023-07-23 06:23:48 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_33_48000.pt
2023-07-23 06:23:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 19.62) (writing took 11.728043287992477 seconds)
2023-07-23 06:25:18 | INFO | train_inner | epoch 033:    952 / 1474 loss=4.17, trans_loss=4.907, nll_loss=2.07, w2v_ctc_loss=0.587, task_loss=1.366, contrastive_loss=0.061, total=4151.18, n_correct=2768.98, ppl=4.2, accuracy=66.703, wps=7035.9, ups=0.85, wpb=8320.4, bsz=308.3, num_updates=48100, lr=6.44826e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=81, gb_free=11.6, wall=35060
2023-07-23 06:26:40 | INFO | train_inner | epoch 033:   1052 / 1474 loss=4.176, trans_loss=4.91, nll_loss=2.074, w2v_ctc_loss=0.582, task_loss=1.375, contrastive_loss=0.165, total=4140.1, n_correct=2762.98, ppl=4.21, accuracy=66.737, wps=10105.1, ups=1.22, wpb=8275.4, bsz=307.6, num_updates=48200, lr=6.44157e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=81, gb_free=12.1, wall=35142
2023-07-23 06:28:02 | INFO | train_inner | epoch 033:   1152 / 1474 loss=4.168, trans_loss=4.909, nll_loss=2.072, w2v_ctc_loss=0.571, task_loss=1.371, contrastive_loss=0.151, total=4182.67, n_correct=2787.83, ppl=4.21, accuracy=66.652, wps=10236.1, ups=1.23, wpb=8344.7, bsz=309.5, num_updates=48300, lr=6.43489e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=81, gb_free=17.7, wall=35224
2023-07-23 06:29:23 | INFO | train_inner | epoch 033:   1252 / 1474 loss=4.178, trans_loss=4.913, nll_loss=2.076, w2v_ctc_loss=0.587, task_loss=1.445, contrastive_loss=0.053, total=4110.02, n_correct=2738.91, ppl=4.22, accuracy=66.64, wps=10082.2, ups=1.22, wpb=8235.5, bsz=294.4, num_updates=48400, lr=6.42824e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=81, gb_free=17.1, wall=35305
2023-07-23 06:30:45 | INFO | train_inner | epoch 033:   1352 / 1474 loss=4.167, trans_loss=4.906, nll_loss=2.069, w2v_ctc_loss=0.579, task_loss=1.346, contrastive_loss=0.073, total=4128.82, n_correct=2757.34, ppl=4.2, accuracy=66.783, wps=10150.5, ups=1.22, wpb=8295.1, bsz=312.4, num_updates=48500, lr=6.42161e-05, gnorm=0.561, clip=0, loss_scale=64, train_wall=81, gb_free=16.3, wall=35387
2023-07-23 06:32:07 | INFO | train_inner | epoch 033:   1452 / 1474 loss=4.171, trans_loss=4.907, nll_loss=2.071, w2v_ctc_loss=0.576, task_loss=1.368, contrastive_loss=0.217, total=4123.47, n_correct=2755.33, ppl=4.2, accuracy=66.821, wps=10119.6, ups=1.23, wpb=8236.1, bsz=308.9, num_updates=48600, lr=6.415e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=81, gb_free=16.7, wall=35468
2023-07-23 06:32:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 06:32:49 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 4.216 | trans_loss 5.586 | nll_loss 2.854 | w2v_ctc_loss 1.361 | task_loss 4.624 | contrastive_loss 0.245 | total 4003.4 | n_correct 2476 | ppl 7.23 | accuracy 61.847 | uer 16.739 | wer 18.609 | raw_wer 18.609 | bleu 19.96 | wps 1975.3 | wpb 4003.4 | bsz 141.8 | num_updates 48622 | best_bleu 20.09
2023-07-23 06:32:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48622 updates
2023-07-23 06:32:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.9607.pt
2023-07-23 06:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.9607.pt
2023-07-23 06:33:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.9607.pt (epoch 33 @ 48622 updates, score 19.96) (writing took 14.660865241661668 seconds)
2023-07-23 06:33:04 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-07-23 06:33:04 | INFO | train | epoch 033 | loss 4.164 | trans_loss 4.903 | nll_loss 2.064 | w2v_ctc_loss 0.576 | task_loss 1.372 | contrastive_loss 0.101 | total 4138.65 | n_correct 2765.66 | ppl 4.18 | accuracy 66.825 | wps 9500.4 | ups 1.15 | wpb 8277.3 | bsz 305.7 | num_updates 48622 | lr 6.41355e-05 | gnorm 0.564 | clip 0 | loss_scale 64 | train_wall 1191 | gb_free 17.9 | wall 35526
2023-07-23 06:33:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 06:33:04 | INFO | fairseq.trainer | begin training epoch 34
2023-07-23 06:33:04 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 06:34:17 | INFO | train_inner | epoch 034:     78 / 1474 loss=4.152, trans_loss=4.891, nll_loss=2.048, w2v_ctc_loss=0.57, task_loss=1.355, contrastive_loss=0.054, total=4128.94, n_correct=2772.62, ppl=4.14, accuracy=67.151, wps=6348, ups=0.77, wpb=8260.8, bsz=302.1, num_updates=48700, lr=6.40841e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=81, gb_free=15.4, wall=35599
2023-07-23 06:35:38 | INFO | train_inner | epoch 034:    178 / 1474 loss=4.152, trans_loss=4.886, nll_loss=2.042, w2v_ctc_loss=0.576, task_loss=1.432, contrastive_loss=0.056, total=4071.22, n_correct=2735.6, ppl=4.12, accuracy=67.194, wps=10005.7, ups=1.23, wpb=8155.2, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=81, gb_free=15.8, wall=35680
2023-07-23 06:37:00 | INFO | train_inner | epoch 034:    278 / 1474 loss=4.162, trans_loss=4.9, nll_loss=2.06, w2v_ctc_loss=0.571, task_loss=1.293, contrastive_loss=0.263, total=4237.89, n_correct=2830.42, ppl=4.17, accuracy=66.788, wps=10348.3, ups=1.22, wpb=8449, bsz=326.9, num_updates=48900, lr=6.39529e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=81, gb_free=10.9, wall=35762
2023-07-23 06:38:21 | INFO | train_inner | epoch 034:    378 / 1474 loss=4.147, trans_loss=4.887, nll_loss=2.043, w2v_ctc_loss=0.564, task_loss=1.296, contrastive_loss=0.153, total=4167, n_correct=2801.61, ppl=4.12, accuracy=67.233, wps=10214.2, ups=1.23, wpb=8332.3, bsz=319, num_updates=49000, lr=6.38877e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=81, gb_free=17.5, wall=35843
2023-07-23 06:39:42 | INFO | train_inner | epoch 034:    478 / 1474 loss=4.162, trans_loss=4.894, nll_loss=2.051, w2v_ctc_loss=0.581, task_loss=1.501, contrastive_loss=0.048, total=4071.65, n_correct=2721.35, ppl=4.14, accuracy=66.837, wps=10092.6, ups=1.24, wpb=8150, bsz=284.8, num_updates=49100, lr=6.38226e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=80, gb_free=12, wall=35924
2023-07-23 06:41:03 | INFO | train_inner | epoch 034:    578 / 1474 loss=4.152, trans_loss=4.89, nll_loss=2.047, w2v_ctc_loss=0.574, task_loss=1.395, contrastive_loss=0.051, total=4110.13, n_correct=2763.22, ppl=4.13, accuracy=67.23, wps=10204.1, ups=1.24, wpb=8212.9, bsz=299, num_updates=49200, lr=6.37577e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=80, gb_free=16.9, wall=36005
2023-07-23 06:42:24 | INFO | train_inner | epoch 034:    678 / 1474 loss=4.151, trans_loss=4.891, nll_loss=2.048, w2v_ctc_loss=0.566, task_loss=1.391, contrastive_loss=0.045, total=4128.65, n_correct=2770.89, ppl=4.14, accuracy=67.114, wps=10185.9, ups=1.23, wpb=8256.3, bsz=300.7, num_updates=49300, lr=6.3693e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=81, gb_free=17.9, wall=36086
2023-07-23 06:43:45 | INFO | train_inner | epoch 034:    778 / 1474 loss=4.167, trans_loss=4.904, nll_loss=2.066, w2v_ctc_loss=0.569, task_loss=1.437, contrastive_loss=0.116, total=4075.69, n_correct=2726.42, ppl=4.19, accuracy=66.895, wps=10071.5, ups=1.24, wpb=8148.6, bsz=294.5, num_updates=49400, lr=6.36285e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=80, gb_free=17.4, wall=36167
2023-07-23 06:45:06 | INFO | train_inner | epoch 034:    878 / 1474 loss=4.16, trans_loss=4.898, nll_loss=2.057, w2v_ctc_loss=0.571, task_loss=1.446, contrastive_loss=0.073, total=4104.97, n_correct=2749.98, ppl=4.16, accuracy=66.991, wps=10052.7, ups=1.22, wpb=8211.2, bsz=296.3, num_updates=49500, lr=6.35642e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=81, gb_free=17.9, wall=36248
2023-07-23 06:46:27 | INFO | train_inner | epoch 034:    978 / 1474 loss=4.163, trans_loss=4.903, nll_loss=2.065, w2v_ctc_loss=0.581, task_loss=1.338, contrastive_loss=0.07, total=4168.94, n_correct=2785.25, ppl=4.18, accuracy=66.81, wps=10346.3, ups=1.24, wpb=8348.8, bsz=312.8, num_updates=49600, lr=6.35001e-05, gnorm=0.565, clip=0, loss_scale=64, train_wall=80, gb_free=15.2, wall=36329
2023-07-23 06:47:48 | INFO | train_inner | epoch 034:   1078 / 1474 loss=4.159, trans_loss=4.902, nll_loss=2.062, w2v_ctc_loss=0.579, task_loss=1.325, contrastive_loss=0.052, total=4155.12, n_correct=2780.29, ppl=4.18, accuracy=66.912, wps=10276.1, ups=1.24, wpb=8293.2, bsz=309.1, num_updates=49700, lr=6.34361e-05, gnorm=0.564, clip=0, loss_scale=128, train_wall=80, gb_free=17, wall=36410
2023-07-23 06:49:09 | INFO | train_inner | epoch 034:   1178 / 1474 loss=4.162, trans_loss=4.902, nll_loss=2.062, w2v_ctc_loss=0.571, task_loss=1.418, contrastive_loss=0.063, total=4096.48, n_correct=2738.47, ppl=4.18, accuracy=66.849, wps=10099.6, ups=1.23, wpb=8190.3, bsz=297.2, num_updates=49800, lr=6.33724e-05, gnorm=0.571, clip=0, loss_scale=128, train_wall=81, gb_free=16.9, wall=36491
2023-07-23 06:50:30 | INFO | train_inner | epoch 034:   1278 / 1474 loss=4.162, trans_loss=4.899, nll_loss=2.058, w2v_ctc_loss=0.572, task_loss=1.39, contrastive_loss=0.047, total=4149.03, n_correct=2778.9, ppl=4.16, accuracy=66.977, wps=10282.4, ups=1.24, wpb=8316, bsz=299.7, num_updates=49900, lr=6.33089e-05, gnorm=0.56, clip=0, loss_scale=128, train_wall=80, gb_free=16.6, wall=36572
2023-07-23 06:51:51 | INFO | train_inner | epoch 034:   1378 / 1474 loss=4.163, trans_loss=4.903, nll_loss=2.066, w2v_ctc_loss=0.575, task_loss=1.312, contrastive_loss=0.113, total=4200.34, n_correct=2809.22, ppl=4.19, accuracy=66.881, wps=10343, ups=1.23, wpb=8417.9, bsz=321.9, num_updates=50000, lr=6.32456e-05, gnorm=0.564, clip=0, loss_scale=128, train_wall=81, gb_free=15.3, wall=36653
2023-07-23 06:51:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 06:52:15 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.59 | nll_loss 2.861 | w2v_ctc_loss 1.315 | task_loss 4.626 | contrastive_loss 0.241 | total 4003.4 | n_correct 2471.9 | ppl 7.27 | accuracy 61.745 | uer 16.455 | wer 18.321 | raw_wer 18.321 | bleu 19.47 | wps 2102.1 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 20.09
2023-07-23 06:52:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-07-23 06:52:15 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_34_50000.pt
2023-07-23 06:52:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_34_50000.pt
2023-07-23 06:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 19.47) (writing took 11.842354483902454 seconds)
mt_weight tensor(1., device='cuda:0')
asr_weight tensor(0.0009, device='cuda:0')
2023-07-23 06:52:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-07-23 06:53:46 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1., device='cuda:4')
asr_weight tensor(0.0009, device='cuda:4')
mt_weight tensor(1., device='cuda:7')
asr_weight tensor(0.0009, device='cuda:7')
mt_weight tensor(1., device='cuda:3')
asr_weight tensor(0.0009, device='cuda:3')
mt_weight tensor(1., device='cuda:6')
asr_weight tensor(0.0009, device='cuda:6')
mt_weight tensor(1., device='cuda:1')
asr_weight tensor(0.0009, device='cuda:1')
mt_weight tensor(1., device='cuda:5')
asr_weight tensor(0.0009, device='cuda:5')
mt_weight tensor(1., device='cuda:2')
asr_weight tensor(0.0009, device='cuda:2')
2023-07-23 06:54:09 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 4.214 | trans_loss 5.587 | nll_loss 2.858 | w2v_ctc_loss 1.352 | task_loss 4.621 | contrastive_loss 0.243 | total 4003.4 | n_correct 2476.8 | ppl 7.25 | accuracy 61.867 | uer 16.646 | wer 18.418 | raw_wer 18.418 | bleu 19.56 | wps 2265.8 | wpb 4003.4 | bsz 141.8 | num_updates 50095 | best_bleu 20.09
2023-07-23 06:54:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50095 updates
2023-07-23 06:54:09 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 06:54:20 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 06:54:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 34 @ 50095 updates, score 19.56) (writing took 11.115981429815292 seconds)
2023-07-23 06:54:20 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-07-23 06:54:20 | INFO | train | epoch 034 | loss 4.158 | trans_loss 4.896 | nll_loss 2.056 | w2v_ctc_loss 0.572 | task_loss 1.374 | contrastive_loss 0.089 | total 4136.68 | n_correct 2771.09 | ppl 4.16 | accuracy 66.988 | wps 9551.7 | ups 1.15 | wpb 8274 | bsz 305 | num_updates 50095 | lr 6.31856e-05 | gnorm 0.567 | clip 0 | loss_scale 64 | train_wall 1189 | gb_free 17.5 | wall 36802
2023-07-23 06:54:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 06:54:20 | INFO | fairseq.trainer | begin training epoch 35
2023-07-23 06:54:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 06:54:33 | INFO | train_inner | epoch 035:      5 / 1474 loss=4.154, trans_loss=4.898, nll_loss=2.059, w2v_ctc_loss=0.57, task_loss=1.297, contrastive_loss=0.097, total=4180.05, n_correct=2798.66, ppl=4.17, accuracy=66.953, wps=5152, ups=0.62, wpb=8343.3, bsz=315.9, num_updates=50100, lr=6.31824e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=82, gb_free=17.5, wall=36815
2023-07-23 06:55:54 | INFO | train_inner | epoch 035:    105 / 1474 loss=4.146, trans_loss=4.882, nll_loss=2.037, w2v_ctc_loss=0.553, task_loss=1.324, contrastive_loss=0.191, total=4166.04, n_correct=2803.99, ppl=4.1, accuracy=67.306, wps=10289, ups=1.23, wpb=8340.2, bsz=313.1, num_updates=50200, lr=6.31194e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=81, gb_free=16.8, wall=36896
2023-07-23 06:57:15 | INFO | train_inner | epoch 035:    205 / 1474 loss=4.13, trans_loss=4.875, nll_loss=2.028, w2v_ctc_loss=0.557, task_loss=1.293, contrastive_loss=0.048, total=4171.82, n_correct=2815, ppl=4.08, accuracy=67.477, wps=10286.3, ups=1.23, wpb=8346.8, bsz=316.5, num_updates=50300, lr=6.30567e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=81, gb_free=17.2, wall=36977
2023-07-23 06:58:37 | INFO | train_inner | epoch 035:    305 / 1474 loss=4.15, trans_loss=4.88, nll_loss=2.033, w2v_ctc_loss=0.561, task_loss=1.435, contrastive_loss=0.213, total=4111.19, n_correct=2761.98, ppl=4.09, accuracy=67.182, wps=10082.2, ups=1.22, wpb=8238.2, bsz=299.9, num_updates=50400, lr=6.29941e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=81, gb_free=16.2, wall=37059
2023-07-23 06:59:58 | INFO | train_inner | epoch 035:    405 / 1474 loss=4.163, trans_loss=4.894, nll_loss=2.051, w2v_ctc_loss=0.588, task_loss=1.527, contrastive_loss=0.051, total=4070.26, n_correct=2726.39, ppl=4.14, accuracy=66.983, wps=10006.8, ups=1.23, wpb=8116.8, bsz=282.7, num_updates=50500, lr=6.29317e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=81, gb_free=17, wall=37140
2023-07-23 07:00:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-23 07:01:20 | INFO | train_inner | epoch 035:    506 / 1474 loss=4.148, trans_loss=4.888, nll_loss=2.043, w2v_ctc_loss=0.569, task_loss=1.425, contrastive_loss=0.057, total=4143.09, n_correct=2783.82, ppl=4.12, accuracy=67.192, wps=10075.7, ups=1.22, wpb=8263.8, bsz=299.5, num_updates=50600, lr=6.28695e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=82, gb_free=16.5, wall=37222
2023-07-23 07:02:41 | INFO | train_inner | epoch 035:    606 / 1474 loss=4.144, trans_loss=4.881, nll_loss=2.036, w2v_ctc_loss=0.561, task_loss=1.356, contrastive_loss=0.131, total=4167.77, n_correct=2803.3, ppl=4.1, accuracy=67.261, wps=10348.6, ups=1.24, wpb=8341, bsz=309.7, num_updates=50700, lr=6.28074e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=80, gb_free=16.3, wall=37303
2023-07-23 07:04:02 | INFO | train_inner | epoch 035:    706 / 1474 loss=4.157, trans_loss=4.893, nll_loss=2.051, w2v_ctc_loss=0.577, task_loss=1.442, contrastive_loss=0.06, total=4084.16, n_correct=2738.77, ppl=4.14, accuracy=67.058, wps=10076.6, ups=1.23, wpb=8165, bsz=294.8, num_updates=50800, lr=6.27456e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=81, gb_free=17.2, wall=37384
2023-07-23 07:05:23 | INFO | train_inner | epoch 035:    806 / 1474 loss=4.154, trans_loss=4.892, nll_loss=2.05, w2v_ctc_loss=0.575, task_loss=1.346, contrastive_loss=0.068, total=4151.07, n_correct=2781.08, ppl=4.14, accuracy=66.997, wps=10236.5, ups=1.23, wpb=8321.9, bsz=311.5, num_updates=50900, lr=6.26839e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=81, gb_free=17.1, wall=37465
2023-07-23 07:06:45 | INFO | train_inner | epoch 035:    906 / 1474 loss=4.16, trans_loss=4.895, nll_loss=2.054, w2v_ctc_loss=0.58, task_loss=1.448, contrastive_loss=0.047, total=4097.72, n_correct=2747.64, ppl=4.15, accuracy=67.053, wps=10035.2, ups=1.23, wpb=8185.4, bsz=292.9, num_updates=51000, lr=6.26224e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=81, gb_free=16.2, wall=37547
2023-07-23 07:08:06 | INFO | train_inner | epoch 035:   1006 / 1474 loss=4.159, trans_loss=4.894, nll_loss=2.053, w2v_ctc_loss=0.568, task_loss=1.391, contrastive_loss=0.175, total=4141.74, n_correct=2774.36, ppl=4.15, accuracy=66.985, wps=10166.4, ups=1.23, wpb=8275.4, bsz=306.2, num_updates=51100, lr=6.25611e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=81, gb_free=17.7, wall=37628
2023-07-23 07:09:27 | INFO | train_inner | epoch 035:   1106 / 1474 loss=4.153, trans_loss=4.893, nll_loss=2.051, w2v_ctc_loss=0.577, task_loss=1.314, contrastive_loss=0.056, total=4182.91, n_correct=2804.12, ppl=4.15, accuracy=67.038, wps=10326.6, ups=1.24, wpb=8361.6, bsz=311.4, num_updates=51200, lr=6.25e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=80, gb_free=10.7, wall=37709
2023-07-23 07:10:48 | INFO | train_inner | epoch 035:   1206 / 1474 loss=4.151, trans_loss=4.895, nll_loss=2.056, w2v_ctc_loss=0.567, task_loss=1.269, contrastive_loss=0.109, total=4207.87, n_correct=2824.57, ppl=4.16, accuracy=67.126, wps=10420.6, ups=1.24, wpb=8393, bsz=320.3, num_updates=51300, lr=6.24391e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=80, gb_free=15.1, wall=37789
2023-07-23 07:12:08 | INFO | train_inner | epoch 035:   1306 / 1474 loss=4.15, trans_loss=4.892, nll_loss=2.051, w2v_ctc_loss=0.564, task_loss=1.309, contrastive_loss=0.059, total=4141.67, n_correct=2780.03, ppl=4.14, accuracy=67.123, wps=10304.6, ups=1.24, wpb=8313.8, bsz=313.9, num_updates=51400, lr=6.23783e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=80, gb_free=16.5, wall=37870
2023-07-23 07:13:29 | INFO | train_inner | epoch 035:   1406 / 1474 loss=4.167, trans_loss=4.903, nll_loss=2.063, w2v_ctc_loss=0.572, task_loss=1.5, contrastive_loss=0.047, total=4057.93, n_correct=2709.36, ppl=4.18, accuracy=66.767, wps=10063.5, ups=1.24, wpb=8126.1, bsz=285.6, num_updates=51500, lr=6.23177e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=80, gb_free=15.6, wall=37951
2023-07-23 07:14:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 07:14:48 | INFO | dev_st | epoch 035 | valid on 'dev_st' subset | loss 4.214 | trans_loss 5.585 | nll_loss 2.853 | w2v_ctc_loss 1.358 | task_loss 4.643 | contrastive_loss 0.245 | total 4003.4 | n_correct 2484.1 | ppl 7.23 | accuracy 62.05 | uer 16.42 | wer 18.131 | raw_wer 18.131 | bleu 19.86 | wps 2100.6 | wpb 4003.4 | bsz 141.8 | num_updates 51568 | best_bleu 20.09
2023-07-23 07:14:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 51568 updates
2023-07-23 07:14:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8601.pt
2023-07-23 07:14:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8601.pt
2023-07-23 07:15:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.8601.pt (epoch 35 @ 51568 updates, score 19.86) (writing took 15.750475509092212 seconds)
2023-07-23 07:15:04 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-07-23 07:15:04 | INFO | train | epoch 035 | loss 4.152 | trans_loss 4.89 | nll_loss 2.047 | w2v_ctc_loss 0.569 | task_loss 1.374 | contrastive_loss 0.095 | total 4137.86 | n_correct 2777.43 | ppl 4.13 | accuracy 67.122 | wps 9796.3 | ups 1.18 | wpb 8276.1 | bsz 305.3 | num_updates 51568 | lr 6.22766e-05 | gnorm 0.566 | clip 0 | loss_scale 32 | train_wall 1188 | gb_free 17.4 | wall 38046
2023-07-23 07:15:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 07:15:05 | INFO | fairseq.trainer | begin training epoch 36
2023-07-23 07:15:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 07:15:39 | INFO | train_inner | epoch 036:     32 / 1474 loss=4.15, trans_loss=4.889, nll_loss=2.046, w2v_ctc_loss=0.568, task_loss=1.33, contrastive_loss=0.091, total=4128.66, n_correct=2780.57, ppl=4.13, accuracy=67.348, wps=6346.3, ups=0.77, wpb=8256, bsz=309, num_updates=51600, lr=6.22573e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=80, gb_free=16.5, wall=38081
2023-07-23 07:17:01 | INFO | train_inner | epoch 036:    132 / 1474 loss=4.139, trans_loss=4.876, nll_loss=2.028, w2v_ctc_loss=0.563, task_loss=1.429, contrastive_loss=0.057, total=4101.15, n_correct=2763.43, ppl=4.08, accuracy=67.382, wps=10050.7, ups=1.23, wpb=8202.2, bsz=298.9, num_updates=51700, lr=6.2197e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=81, gb_free=16.7, wall=38163
2023-07-23 07:18:23 | INFO | train_inner | epoch 036:    232 / 1474 loss=4.141, trans_loss=4.879, nll_loss=2.032, w2v_ctc_loss=0.564, task_loss=1.395, contrastive_loss=0.07, total=4153.27, n_correct=2803.37, ppl=4.09, accuracy=67.498, wps=10142.3, ups=1.22, wpb=8295.6, bsz=303.6, num_updates=51800, lr=6.2137e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=81, gb_free=17, wall=38244
2023-07-23 07:19:43 | INFO | train_inner | epoch 036:    332 / 1474 loss=4.13, trans_loss=4.875, nll_loss=2.027, w2v_ctc_loss=0.551, task_loss=1.302, contrastive_loss=0.045, total=4162.11, n_correct=2807.98, ppl=4.08, accuracy=67.465, wps=10395.2, ups=1.25, wpb=8320.7, bsz=310.2, num_updates=51900, lr=6.20771e-05, gnorm=0.56, clip=0, loss_scale=32, train_wall=79, gb_free=16.8, wall=38324
2023-07-23 07:21:04 | INFO | train_inner | epoch 036:    432 / 1474 loss=4.131, trans_loss=4.875, nll_loss=2.03, w2v_ctc_loss=0.558, task_loss=1.205, contrastive_loss=0.165, total=4234.05, n_correct=2853.27, ppl=4.08, accuracy=67.389, wps=10353.2, ups=1.23, wpb=8442.3, bsz=333.1, num_updates=52000, lr=6.20174e-05, gnorm=0.562, clip=0, loss_scale=32, train_wall=81, gb_free=16.3, wall=38406
2023-07-23 07:21:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 07:21:28 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 4.23 | trans_loss 5.593 | nll_loss 2.865 | w2v_ctc_loss 1.39 | task_loss 4.605 | contrastive_loss 0.246 | total 4003.4 | n_correct 2475.4 | ppl 7.29 | accuracy 61.832 | uer 16.675 | wer 18.456 | raw_wer 18.456 | bleu 19.84 | wps 2149.1 | wpb 4003.4 | bsz 141.8 | num_updates 52000 | best_bleu 20.09
2023-07-23 07:21:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 52000 updates
2023-07-23 07:21:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_36_52000.pt
2023-07-23 07:21:31 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_36_52000.pt
2023-07-23 07:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_36_52000.pt (epoch 36 @ 52000 updates, score 19.84) (writing took 16.019048046320677 seconds)
2023-07-23 07:23:07 | INFO | train_inner | epoch 036:    532 / 1474 loss=4.155, trans_loss=4.886, nll_loss=2.042, w2v_ctc_loss=0.559, task_loss=1.367, contrastive_loss=0.306, total=4149.22, n_correct=2785.91, ppl=4.12, accuracy=67.143, wps=6783.7, ups=0.82, wpb=8304, bsz=312.3, num_updates=52100, lr=6.19578e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=81, gb_free=17.9, wall=38528
2023-07-23 07:24:28 | INFO | train_inner | epoch 036:    632 / 1474 loss=4.138, trans_loss=4.878, nll_loss=2.032, w2v_ctc_loss=0.559, task_loss=1.322, contrastive_loss=0.123, total=4179.05, n_correct=2820.69, ppl=4.09, accuracy=67.496, wps=10296.8, ups=1.23, wpb=8359, bsz=316.9, num_updates=52200, lr=6.18984e-05, gnorm=0.551, clip=0, loss_scale=32, train_wall=81, gb_free=17.2, wall=38610
2023-07-23 07:25:49 | INFO | train_inner | epoch 036:    732 / 1474 loss=4.142, trans_loss=4.884, nll_loss=2.04, w2v_ctc_loss=0.569, task_loss=1.329, contrastive_loss=0.059, total=4180.07, n_correct=2807.55, ppl=4.11, accuracy=67.165, wps=10226.2, ups=1.22, wpb=8361.4, bsz=315.5, num_updates=52300, lr=6.18392e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=81, gb_free=14, wall=38691
2023-07-23 07:27:11 | INFO | train_inner | epoch 036:    832 / 1474 loss=4.157, trans_loss=4.895, nll_loss=2.055, w2v_ctc_loss=0.572, task_loss=1.286, contrastive_loss=0.231, total=4178.14, n_correct=2794.88, ppl=4.16, accuracy=66.893, wps=10163.2, ups=1.22, wpb=8326.4, bsz=321.7, num_updates=52400, lr=6.17802e-05, gnorm=0.575, clip=0, loss_scale=32, train_wall=81, gb_free=16.5, wall=38773
2023-07-23 07:28:33 | INFO | train_inner | epoch 036:    932 / 1474 loss=4.141, trans_loss=4.879, nll_loss=2.033, w2v_ctc_loss=0.563, task_loss=1.385, contrastive_loss=0.047, total=4175.34, n_correct=2812.05, ppl=4.09, accuracy=67.349, wps=10290, ups=1.23, wpb=8368.2, bsz=305.3, num_updates=52500, lr=6.17213e-05, gnorm=0.558, clip=0, loss_scale=32, train_wall=81, gb_free=17.7, wall=38855
2023-07-23 07:29:54 | INFO | train_inner | epoch 036:   1032 / 1474 loss=4.152, trans_loss=4.889, nll_loss=2.045, w2v_ctc_loss=0.569, task_loss=1.413, contrastive_loss=0.044, total=4176.5, n_correct=2805.76, ppl=4.13, accuracy=67.18, wps=10286.9, ups=1.23, wpb=8358.2, bsz=301.7, num_updates=52600, lr=6.16626e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=81, gb_free=16.5, wall=38936
2023-07-23 07:31:15 | INFO | train_inner | epoch 036:   1132 / 1474 loss=4.148, trans_loss=4.885, nll_loss=2.041, w2v_ctc_loss=0.568, task_loss=1.365, contrastive_loss=0.06, total=4130.46, n_correct=2778.87, ppl=4.12, accuracy=67.277, wps=10210.1, ups=1.23, wpb=8285.1, bsz=306.7, num_updates=52700, lr=6.16041e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=81, gb_free=17.9, wall=39017
2023-07-23 07:32:36 | INFO | train_inner | epoch 036:   1232 / 1474 loss=4.165, trans_loss=4.895, nll_loss=2.053, w2v_ctc_loss=0.571, task_loss=1.532, contrastive_loss=0.038, total=4051.75, n_correct=2720.02, ppl=4.15, accuracy=67.132, wps=10045, ups=1.24, wpb=8125.4, bsz=280, num_updates=52800, lr=6.15457e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=80, gb_free=17.2, wall=39098
2023-07-23 07:33:57 | INFO | train_inner | epoch 036:   1332 / 1474 loss=4.148, trans_loss=4.889, nll_loss=2.048, w2v_ctc_loss=0.569, task_loss=1.374, contrastive_loss=0.051, total=4108.74, n_correct=2759.18, ppl=4.13, accuracy=67.154, wps=10134.7, ups=1.23, wpb=8214.5, bsz=305.1, num_updates=52900, lr=6.14875e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=81, gb_free=16.1, wall=39179
2023-07-23 07:35:19 | INFO | train_inner | epoch 036:   1432 / 1474 loss=4.168, trans_loss=4.896, nll_loss=2.055, w2v_ctc_loss=0.576, task_loss=1.548, contrastive_loss=0.101, total=4048.28, n_correct=2709.94, ppl=4.16, accuracy=66.941, wps=9916.2, ups=1.22, wpb=8099.7, bsz=278.8, num_updates=53000, lr=6.14295e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=81, gb_free=11.3, wall=39261
2023-07-23 07:35:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 07:36:16 | INFO | dev_st | epoch 036 | valid on 'dev_st' subset | loss 4.224 | trans_loss 5.592 | nll_loss 2.862 | w2v_ctc_loss 1.375 | task_loss 4.639 | contrastive_loss 0.247 | total 4003.4 | n_correct 2480.4 | ppl 7.27 | accuracy 61.957 | uer 16.598 | wer 18.277 | raw_wer 18.277 | bleu 19.57 | wps 2016.8 | wpb 4003.4 | bsz 141.8 | num_updates 53042 | best_bleu 20.09
2023-07-23 07:36:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 53042 updates
2023-07-23 07:36:16 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 07:36:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 07:36:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 36 @ 53042 updates, score 19.57) (writing took 10.63446761853993 seconds)
2023-07-23 07:36:27 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-07-23 07:36:27 | INFO | train | epoch 036 | loss 4.147 | trans_loss 4.884 | nll_loss 2.04 | w2v_ctc_loss 0.565 | task_loss 1.372 | contrastive_loss 0.099 | total 4138.65 | n_correct 2783.62 | ppl 4.11 | accuracy 67.259 | wps 9512.5 | ups 1.15 | wpb 8277.3 | bsz 305.7 | num_updates 53042 | lr 6.14052e-05 | gnorm 0.568 | clip 0 | loss_scale 64 | train_wall 1190 | gb_free 17 | wall 39329
2023-07-23 07:36:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 07:36:27 | INFO | fairseq.trainer | begin training epoch 37
2023-07-23 07:36:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 07:37:22 | INFO | train_inner | epoch 037:     58 / 1474 loss=4.137, trans_loss=4.875, nll_loss=2.028, w2v_ctc_loss=0.562, task_loss=1.374, contrastive_loss=0.055, total=4092.98, n_correct=2765.71, ppl=4.08, accuracy=67.572, wps=6631.4, ups=0.81, wpb=8186.1, bsz=299.9, num_updates=53100, lr=6.13716e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=80, gb_free=15.5, wall=39384
2023-07-23 07:38:44 | INFO | train_inner | epoch 037:    158 / 1474 loss=4.14, trans_loss=4.877, nll_loss=2.03, w2v_ctc_loss=0.565, task_loss=1.396, contrastive_loss=0.11, total=4124.56, n_correct=2781.9, ppl=4.08, accuracy=67.447, wps=10096.3, ups=1.22, wpb=8243, bsz=306.8, num_updates=53200, lr=6.13139e-05, gnorm=0.572, clip=0, loss_scale=64, train_wall=81, gb_free=16.5, wall=39466
2023-07-23 07:40:05 | INFO | train_inner | epoch 037:    258 / 1474 loss=4.117, trans_loss=4.863, nll_loss=2.013, w2v_ctc_loss=0.546, task_loss=1.28, contrastive_loss=0.05, total=4188.93, n_correct=2840.79, ppl=4.04, accuracy=67.817, wps=10321.3, ups=1.23, wpb=8375.7, bsz=319.3, num_updates=53300, lr=6.12564e-05, gnorm=0.559, clip=0, loss_scale=64, train_wall=81, gb_free=15.1, wall=39547
2023-07-23 07:41:27 | INFO | train_inner | epoch 037:    358 / 1474 loss=4.132, trans_loss=4.871, nll_loss=2.022, w2v_ctc_loss=0.564, task_loss=1.381, contrastive_loss=0.06, total=4171.05, n_correct=2817.12, ppl=4.06, accuracy=67.54, wps=10192.1, ups=1.23, wpb=8313.7, bsz=305.8, num_updates=53400, lr=6.1199e-05, gnorm=0.562, clip=0, loss_scale=64, train_wall=81, gb_free=16.1, wall=39628
2023-07-23 07:42:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-23 07:42:49 | INFO | train_inner | epoch 037:    459 / 1474 loss=4.15, trans_loss=4.885, nll_loss=2.041, w2v_ctc_loss=0.56, task_loss=1.358, contrastive_loss=0.208, total=4154.31, n_correct=2789.15, ppl=4.11, accuracy=67.139, wps=10050.6, ups=1.21, wpb=8285.7, bsz=309.5, num_updates=53500, lr=6.11418e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=82, gb_free=14.1, wall=39711
2023-07-23 07:44:11 | INFO | train_inner | epoch 037:    559 / 1474 loss=4.14, trans_loss=4.876, nll_loss=2.028, w2v_ctc_loss=0.565, task_loss=1.427, contrastive_loss=0.047, total=4092.13, n_correct=2761.84, ppl=4.08, accuracy=67.492, wps=10056.5, ups=1.23, wpb=8203.7, bsz=299.7, num_updates=53600, lr=6.10847e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=81, gb_free=16.9, wall=39793
2023-07-23 07:45:32 | INFO | train_inner | epoch 037:    659 / 1474 loss=4.148, trans_loss=4.88, nll_loss=2.034, w2v_ctc_loss=0.572, task_loss=1.446, contrastive_loss=0.057, total=4102.49, n_correct=2754.41, ppl=4.1, accuracy=67.14, wps=10086.7, ups=1.23, wpb=8223.1, bsz=292, num_updates=53700, lr=6.10278e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=81, gb_free=17.2, wall=39874
2023-07-23 07:46:53 | INFO | train_inner | epoch 037:    759 / 1474 loss=4.142, trans_loss=4.879, nll_loss=2.033, w2v_ctc_loss=0.558, task_loss=1.362, contrastive_loss=0.114, total=4123.95, n_correct=2775.65, ppl=4.09, accuracy=67.306, wps=10250.6, ups=1.24, wpb=8269.9, bsz=304.9, num_updates=53800, lr=6.09711e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=80, gb_free=16.9, wall=39955
2023-07-23 07:48:14 | INFO | train_inner | epoch 037:    859 / 1474 loss=4.127, trans_loss=4.875, nll_loss=2.028, w2v_ctc_loss=0.554, task_loss=1.292, contrastive_loss=0.049, total=4159.03, n_correct=2808.44, ppl=4.08, accuracy=67.526, wps=10284.6, ups=1.24, wpb=8296.8, bsz=315.7, num_updates=53900, lr=6.09145e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=80, gb_free=15.9, wall=40035
2023-07-23 07:49:35 | INFO | train_inner | epoch 037:    959 / 1474 loss=4.151, trans_loss=4.886, nll_loss=2.041, w2v_ctc_loss=0.565, task_loss=1.461, contrastive_loss=0.055, total=4097.89, n_correct=2757, ppl=4.11, accuracy=67.279, wps=10126.8, ups=1.23, wpb=8209.9, bsz=292.3, num_updates=54000, lr=6.08581e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=81, gb_free=16, wall=40116
2023-07-23 07:49:35 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 07:49:58 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.218 | trans_loss 5.587 | nll_loss 2.857 | w2v_ctc_loss 1.363 | task_loss 4.634 | contrastive_loss 0.247 | total 4003.4 | n_correct 2478.1 | ppl 7.24 | accuracy 61.9 | uer 16.508 | wer 18.269 | raw_wer 18.269 | bleu 20.02 | wps 2161.4 | wpb 4003.4 | bsz 141.8 | num_updates 54000 | best_bleu 20.09
2023-07-23 07:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54000 updates
2023-07-23 07:49:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_37_54000.pt
2023-07-23 07:50:01 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_37_54000.pt
2023-07-23 07:50:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_37_54000.pt (epoch 37 @ 54000 updates, score 20.02) (writing took 16.247561566531658 seconds)
2023-07-23 07:51:36 | INFO | train_inner | epoch 037:   1059 / 1474 loss=4.144, trans_loss=4.881, nll_loss=2.037, w2v_ctc_loss=0.557, task_loss=1.284, contrastive_loss=0.182, total=4162.64, n_correct=2807.11, ppl=4.1, accuracy=67.436, wps=6857.2, ups=0.82, wpb=8346.4, bsz=319.8, num_updates=54100, lr=6.08018e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=81, gb_free=16.7, wall=40238
2023-07-23 07:52:58 | INFO | train_inner | epoch 037:   1159 / 1474 loss=4.151, trans_loss=4.886, nll_loss=2.044, w2v_ctc_loss=0.56, task_loss=1.333, contrastive_loss=0.212, total=4176.35, n_correct=2803.49, ppl=4.12, accuracy=67.128, wps=10230.4, ups=1.22, wpb=8352.9, bsz=312.1, num_updates=54200, lr=6.07457e-05, gnorm=0.565, clip=0, loss_scale=32, train_wall=81, gb_free=16.2, wall=40320
2023-07-23 07:54:19 | INFO | train_inner | epoch 037:   1259 / 1474 loss=4.138, trans_loss=4.882, nll_loss=2.038, w2v_ctc_loss=0.555, task_loss=1.326, contrastive_loss=0.057, total=4167.2, n_correct=2806.34, ppl=4.11, accuracy=67.344, wps=10280.6, ups=1.23, wpb=8336.4, bsz=311.9, num_updates=54300, lr=6.06897e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=81, gb_free=16.2, wall=40401
2023-07-23 07:55:40 | INFO | train_inner | epoch 037:   1359 / 1474 loss=4.159, trans_loss=4.891, nll_loss=2.048, w2v_ctc_loss=0.58, task_loss=1.504, contrastive_loss=0.046, total=4072.63, n_correct=2732.69, ppl=4.14, accuracy=67.099, wps=9993.5, ups=1.23, wpb=8132.6, bsz=286, num_updates=54400, lr=6.06339e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=81, gb_free=16.1, wall=40482
2023-07-23 07:57:01 | INFO | train_inner | epoch 037:   1459 / 1474 loss=4.145, trans_loss=4.882, nll_loss=2.037, w2v_ctc_loss=0.563, task_loss=1.364, contrastive_loss=0.082, total=4155.97, n_correct=2796.64, ppl=4.1, accuracy=67.292, wps=10268.4, ups=1.23, wpb=8318.1, bsz=305.1, num_updates=54500, lr=6.05783e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=81, gb_free=16.2, wall=40563
2023-07-23 07:57:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 07:57:38 | INFO | dev_st | epoch 037 | valid on 'dev_st' subset | loss 4.224 | trans_loss 5.591 | nll_loss 2.863 | w2v_ctc_loss 1.375 | task_loss 4.618 | contrastive_loss 0.251 | total 4003.4 | n_correct 2485.2 | ppl 7.27 | accuracy 62.077 | uer 16.659 | wer 18.534 | raw_wer 18.534 | bleu 19.96 | wps 2011 | wpb 4003.4 | bsz 141.8 | num_updates 54515 | best_bleu 20.09
2023-07-23 07:57:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 54515 updates
2023-07-23 07:57:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.9605.pt
2023-07-23 07:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.9605.pt
2023-07-23 07:57:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_19.9605.pt (epoch 37 @ 54515 updates, score 19.96) (writing took 14.205468462780118 seconds)
2023-07-23 07:57:53 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-07-23 07:57:53 | INFO | train | epoch 037 | loss 4.142 | trans_loss 4.879 | nll_loss 2.033 | w2v_ctc_loss 0.562 | task_loss 1.374 | contrastive_loss 0.094 | total 4136.85 | n_correct 2786.7 | ppl 4.09 | accuracy 67.363 | wps 9478 | ups 1.15 | wpb 8274.1 | bsz 305.1 | num_updates 54515 | lr 6.05699e-05 | gnorm 0.568 | clip 0 | loss_scale 32 | train_wall 1190 | gb_free 13.2 | wall 40615
2023-07-23 07:57:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 07:57:53 | INFO | fairseq.trainer | begin training epoch 38
2023-07-23 07:57:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 07:59:10 | INFO | train_inner | epoch 038:     85 / 1474 loss=4.126, trans_loss=4.863, nll_loss=2.012, w2v_ctc_loss=0.551, task_loss=1.431, contrastive_loss=0.042, total=4085.19, n_correct=2768.68, ppl=4.03, accuracy=67.774, wps=6350.5, ups=0.78, wpb=8165.3, bsz=293.6, num_updates=54600, lr=6.05228e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=80, gb_free=17.1, wall=40692
2023-07-23 08:00:31 | INFO | train_inner | epoch 038:    185 / 1474 loss=4.13, trans_loss=4.865, nll_loss=2.014, w2v_ctc_loss=0.557, task_loss=1.44, contrastive_loss=0.047, total=4081.12, n_correct=2760.47, ppl=4.04, accuracy=67.64, wps=10123.3, ups=1.24, wpb=8171.7, bsz=292.5, num_updates=54700, lr=6.04674e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=80, gb_free=17, wall=40773
2023-07-23 08:01:52 | INFO | train_inner | epoch 038:    285 / 1474 loss=4.133, trans_loss=4.87, nll_loss=2.02, w2v_ctc_loss=0.555, task_loss=1.433, contrastive_loss=0.066, total=4073.75, n_correct=2753.48, ppl=4.06, accuracy=67.591, wps=10098.8, ups=1.24, wpb=8155.6, bsz=295.7, num_updates=54800, lr=6.04122e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=80, gb_free=17, wall=40853
2023-07-23 08:03:12 | INFO | train_inner | epoch 038:    385 / 1474 loss=4.132, trans_loss=4.87, nll_loss=2.021, w2v_ctc_loss=0.561, task_loss=1.358, contrastive_loss=0.066, total=4173.43, n_correct=2818.9, ppl=4.06, accuracy=67.544, wps=10348.6, ups=1.24, wpb=8349.9, bsz=308.2, num_updates=54900, lr=6.03572e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=80, gb_free=14.1, wall=40934
2023-07-23 08:04:34 | INFO | train_inner | epoch 038:    485 / 1474 loss=4.123, trans_loss=4.865, nll_loss=2.015, w2v_ctc_loss=0.547, task_loss=1.324, contrastive_loss=0.064, total=4192.03, n_correct=2839.89, ppl=4.04, accuracy=67.745, wps=10291.9, ups=1.23, wpb=8374.4, bsz=312, num_updates=55000, lr=6.03023e-05, gnorm=0.563, clip=0, loss_scale=32, train_wall=81, gb_free=16.3, wall=41015
mt_weight tensor(1., device='cuda:0')
asr_weight tensor(0.0009, device='cuda:0')
2023-07-23 08:05:56 | INFO | train_inner | epoch 038:    585 / 1474 loss=4.149, trans_loss=4.881, nll_loss=2.035, w2v_ctc_loss=0.56, task_loss=1.376, contrastive_loss=0.233, total=4172.44, n_correct=2802.91, ppl=4.1, accuracy=67.177, wps=10101.9, ups=1.21, wpb=8332.4, bsz=308.8, num_updates=55100, lr=6.02475e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=82, gb_free=16.3, wall=41098
2023-07-23 08:07:17 | INFO | train_inner | epoch 038:    685 / 1474 loss=4.125, trans_loss=4.863, nll_loss=2.013, w2v_ctc_loss=0.545, task_loss=1.303, contrastive_loss=0.217, total=4179.22, n_correct=2827.22, ppl=4.04, accuracy=67.649, wps=10296.6, ups=1.23, wpb=8367.5, bsz=322.5, num_updates=55200, lr=6.01929e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=81, gb_free=13.4, wall=41179
2023-07-23 08:08:39 | INFO | train_inner | epoch 038:    785 / 1474 loss=4.126, trans_loss=4.869, nll_loss=2.021, w2v_ctc_loss=0.549, task_loss=1.261, contrastive_loss=0.141, total=4180.46, n_correct=2831.09, ppl=4.06, accuracy=67.722, wps=10282.9, ups=1.23, wpb=8358.2, bsz=325.7, num_updates=55300, lr=6.01385e-05, gnorm=0.564, clip=0, loss_scale=32, train_wall=81, gb_free=16, wall=41261
2023-07-23 08:09:59 | INFO | train_inner | epoch 038:    885 / 1474 loss=4.129, trans_loss=4.869, nll_loss=2.021, w2v_ctc_loss=0.557, task_loss=1.306, contrastive_loss=0.048, total=4122.77, n_correct=2790.57, ppl=4.06, accuracy=67.687, wps=10308.2, ups=1.25, wpb=8263.8, bsz=311.9, num_updates=55400, lr=6.00842e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=80, gb_free=15.7, wall=41341
2023-07-23 08:11:20 | INFO | train_inner | epoch 038:    985 / 1474 loss=4.148, trans_loss=4.882, nll_loss=2.036, w2v_ctc_loss=0.559, task_loss=1.377, contrastive_loss=0.084, total=4116.2, n_correct=2770.04, ppl=4.1, accuracy=67.296, wps=10227.8, ups=1.24, wpb=8278.8, bsz=301.5, num_updates=55500, lr=6.003e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=80, gb_free=16.4, wall=41422
2023-07-23 08:12:41 | INFO | train_inner | epoch 038:   1085 / 1474 loss=4.127, trans_loss=4.872, nll_loss=2.025, w2v_ctc_loss=0.556, task_loss=1.247, contrastive_loss=0.116, total=4248.59, n_correct=2869.81, ppl=4.07, accuracy=67.547, wps=10457.3, ups=1.23, wpb=8469.8, bsz=328.8, num_updates=55600, lr=5.9976e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=81, gb_free=16.7, wall=41503
2023-07-23 08:14:03 | INFO | train_inner | epoch 038:   1185 / 1474 loss=4.16, trans_loss=4.89, nll_loss=2.047, w2v_ctc_loss=0.575, task_loss=1.508, contrastive_loss=0.053, total=4077.59, n_correct=2735.7, ppl=4.13, accuracy=67.091, wps=9973.9, ups=1.22, wpb=8172.2, bsz=287.4, num_updates=55700, lr=5.99222e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=81, gb_free=14.3, wall=41585
2023-07-23 08:15:25 | INFO | train_inner | epoch 038:   1285 / 1474 loss=4.149, trans_loss=4.888, nll_loss=2.044, w2v_ctc_loss=0.565, task_loss=1.456, contrastive_loss=0.051, total=4146.3, n_correct=2785.09, ppl=4.12, accuracy=67.17, wps=10059.1, ups=1.22, wpb=8267.4, bsz=295.6, num_updates=55800, lr=5.98684e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=82, gb_free=17.7, wall=41667
2023-07-23 08:15:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-07-23 08:16:47 | INFO | train_inner | epoch 038:   1386 / 1474 loss=4.141, trans_loss=4.882, nll_loss=2.038, w2v_ctc_loss=0.571, task_loss=1.38, contrastive_loss=0.063, total=4137.08, n_correct=2781.91, ppl=4.11, accuracy=67.243, wps=10090.6, ups=1.22, wpb=8248.7, bsz=305.7, num_updates=55900, lr=5.98149e-05, gnorm=0.58, clip=0, loss_scale=32, train_wall=81, gb_free=15.9, wall=41749
2023-07-23 08:17:58 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(1., device='cuda:6')
asr_weight tensor(0.0009, device='cuda:6')
mt_weight tensor(1., device='cuda:7')
asr_weight tensor(0.0009, device='cuda:7')
mt_weight tensor(1., device='cuda:3')
asr_weight tensor(0.0009, device='cuda:3')
mt_weight tensor(1., device='cuda:4')
asr_weight tensor(0.0009, device='cuda:4')
mt_weight tensor(1., device='cuda:5')
asr_weight tensor(0.0009, device='cuda:5')
mt_weight tensor(1., device='cuda:2')
asr_weight tensor(0.0009, device='cuda:2')
mt_weight tensor(1., device='cuda:1')
asr_weight tensor(0.0009, device='cuda:1')
2023-07-23 08:18:23 | INFO | dev_st | epoch 038 | valid on 'dev_st' subset | loss 4.231 | trans_loss 5.59 | nll_loss 2.863 | w2v_ctc_loss 1.399 | task_loss 4.63 | contrastive_loss 0.253 | total 4003.4 | n_correct 2480.8 | ppl 7.28 | accuracy 61.967 | uer 16.834 | wer 18.579 | raw_wer 18.579 | bleu 19.76 | wps 1944.5 | wpb 4003.4 | bsz 141.8 | num_updates 55988 | best_bleu 20.09
2023-07-23 08:18:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 55988 updates
2023-07-23 08:18:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 08:18:34 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 08:18:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 38 @ 55988 updates, score 19.76) (writing took 10.591342622414231 seconds)
2023-07-23 08:18:34 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-07-23 08:18:34 | INFO | train | epoch 038 | loss 4.136 | trans_loss 4.874 | nll_loss 2.026 | w2v_ctc_loss 0.558 | task_loss 1.374 | contrastive_loss 0.095 | total 4137.7 | n_correct 2792.36 | ppl 4.07 | accuracy 67.486 | wps 9823 | ups 1.19 | wpb 8275.8 | bsz 305.4 | num_updates 55988 | lr 5.97678e-05 | gnorm 0.572 | clip 0 | loss_scale 32 | train_wall 1189 | gb_free 16.8 | wall 41856
2023-07-23 08:18:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 08:18:34 | INFO | fairseq.trainer | begin training epoch 39
2023-07-23 08:18:34 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 08:18:52 | INFO | train_inner | epoch 039:     12 / 1474 loss=4.15, trans_loss=4.884, nll_loss=2.039, w2v_ctc_loss=0.564, task_loss=1.466, contrastive_loss=0.109, total=4040.68, n_correct=2721.33, ppl=4.11, accuracy=67.348, wps=6423.3, ups=0.8, wpb=8077.6, bsz=287.2, num_updates=56000, lr=5.97614e-05, gnorm=0.579, clip=0, loss_scale=32, train_wall=80, gb_free=16.2, wall=41874
2023-07-23 08:18:52 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 08:19:18 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.232 | trans_loss 5.589 | nll_loss 2.858 | w2v_ctc_loss 1.404 | task_loss 4.642 | contrastive_loss 0.252 | total 4003.4 | n_correct 2483.9 | ppl 7.25 | accuracy 62.045 | uer 16.656 | wer 18.411 | raw_wer 18.411 | bleu 20.01 | wps 1844 | wpb 4003.4 | bsz 141.8 | num_updates 56000 | best_bleu 20.09
2023-07-23 08:19:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 56000 updates
2023-07-23 08:19:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_39_56000.pt
2023-07-23 08:19:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_39_56000.pt
2023-07-23 08:19:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_39_56000.pt (epoch 39 @ 56000 updates, score 20.01) (writing took 15.084801837801933 seconds)
2023-07-23 08:20:55 | INFO | train_inner | epoch 039:    112 / 1474 loss=4.125, trans_loss=4.858, nll_loss=2.004, w2v_ctc_loss=0.552, task_loss=1.468, contrastive_loss=0.044, total=4056.32, n_correct=2757.07, ppl=4.01, accuracy=67.97, wps=6613.9, ups=0.82, wpb=8111.2, bsz=285.9, num_updates=56100, lr=5.97081e-05, gnorm=0.572, clip=0, loss_scale=32, train_wall=80, gb_free=15.9, wall=41997
2023-07-23 08:22:16 | INFO | train_inner | epoch 039:    212 / 1474 loss=4.12, trans_loss=4.858, nll_loss=2.005, w2v_ctc_loss=0.551, task_loss=1.401, contrastive_loss=0.044, total=4133.67, n_correct=2807.39, ppl=4.01, accuracy=67.915, wps=10214.3, ups=1.24, wpb=8254.8, bsz=300.7, num_updates=56200, lr=5.9655e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=80, gb_free=16.6, wall=42078
2023-07-23 08:23:37 | INFO | train_inner | epoch 039:    312 / 1474 loss=4.126, trans_loss=4.86, nll_loss=2.008, w2v_ctc_loss=0.554, task_loss=1.41, contrastive_loss=0.048, total=4134.37, n_correct=2807.97, ppl=4.02, accuracy=67.918, wps=10229, ups=1.23, wpb=8284.2, bsz=298.8, num_updates=56300, lr=5.9602e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=81, gb_free=16.5, wall=42159
2023-07-23 08:24:58 | INFO | train_inner | epoch 039:    412 / 1474 loss=4.138, trans_loss=4.872, nll_loss=2.024, w2v_ctc_loss=0.555, task_loss=1.343, contrastive_loss=0.199, total=4130.57, n_correct=2791.6, ppl=4.07, accuracy=67.584, wps=10152, ups=1.23, wpb=8275.9, bsz=313.7, num_updates=56400, lr=5.95491e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=81, gb_free=16.6, wall=42240
2023-07-23 08:26:20 | INFO | train_inner | epoch 039:    512 / 1474 loss=4.132, trans_loss=4.864, nll_loss=2.014, w2v_ctc_loss=0.552, task_loss=1.359, contrastive_loss=0.205, total=4144.84, n_correct=2799.73, ppl=4.04, accuracy=67.547, wps=10173.2, ups=1.22, wpb=8314.2, bsz=310.8, num_updates=56500, lr=5.94964e-05, gnorm=0.569, clip=0, loss_scale=32, train_wall=81, gb_free=16.7, wall=42322
2023-07-23 08:27:42 | INFO | train_inner | epoch 039:    612 / 1474 loss=4.131, trans_loss=4.869, nll_loss=2.021, w2v_ctc_loss=0.552, task_loss=1.388, contrastive_loss=0.102, total=4133.85, n_correct=2791.65, ppl=4.06, accuracy=67.531, wps=10143.3, ups=1.23, wpb=8264.4, bsz=303.9, num_updates=56600, lr=5.94438e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=81, gb_free=17, wall=42403
2023-07-23 08:29:02 | INFO | train_inner | epoch 039:    712 / 1474 loss=4.121, trans_loss=4.863, nll_loss=2.012, w2v_ctc_loss=0.547, task_loss=1.335, contrastive_loss=0.095, total=4137.3, n_correct=2798.44, ppl=4.03, accuracy=67.639, wps=10295.4, ups=1.25, wpb=8252, bsz=305.8, num_updates=56700, lr=5.93914e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=80, gb_free=16.2, wall=42484
2023-07-23 08:30:23 | INFO | train_inner | epoch 039:    812 / 1474 loss=4.131, trans_loss=4.869, nll_loss=2.02, w2v_ctc_loss=0.56, task_loss=1.39, contrastive_loss=0.057, total=4165.72, n_correct=2816.97, ppl=4.06, accuracy=67.623, wps=10201.9, ups=1.22, wpb=8328.4, bsz=307.4, num_updates=56800, lr=5.93391e-05, gnorm=0.571, clip=0, loss_scale=32, train_wall=81, gb_free=15.4, wall=42565
2023-07-23 08:31:44 | INFO | train_inner | epoch 039:    912 / 1474 loss=4.137, trans_loss=4.873, nll_loss=2.025, w2v_ctc_loss=0.56, task_loss=1.41, contrastive_loss=0.06, total=4131.2, n_correct=2787.62, ppl=4.07, accuracy=67.477, wps=10249.7, ups=1.24, wpb=8269.9, bsz=300.7, num_updates=56900, lr=5.92869e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=80, gb_free=12.6, wall=42646
2023-07-23 08:33:06 | INFO | train_inner | epoch 039:   1012 / 1474 loss=4.135, trans_loss=4.874, nll_loss=2.028, w2v_ctc_loss=0.553, task_loss=1.341, contrastive_loss=0.172, total=4199.31, n_correct=2833.89, ppl=4.08, accuracy=67.485, wps=10243.1, ups=1.22, wpb=8383.9, bsz=319.2, num_updates=57000, lr=5.92349e-05, gnorm=0.57, clip=0, loss_scale=32, train_wall=81, gb_free=16.8, wall=42728
2023-07-23 08:34:27 | INFO | train_inner | epoch 039:   1112 / 1474 loss=4.126, trans_loss=4.866, nll_loss=2.018, w2v_ctc_loss=0.556, task_loss=1.288, contrastive_loss=0.146, total=4192.7, n_correct=2831.68, ppl=4.05, accuracy=67.538, wps=10302.2, ups=1.23, wpb=8370.1, bsz=321.8, num_updates=57100, lr=5.9183e-05, gnorm=0.567, clip=0, loss_scale=32, train_wall=81, gb_free=12.4, wall=42809
2023-07-23 08:35:48 | INFO | train_inner | epoch 039:   1212 / 1474 loss=4.134, trans_loss=4.874, nll_loss=2.027, w2v_ctc_loss=0.556, task_loss=1.365, contrastive_loss=0.089, total=4126.68, n_correct=2783.03, ppl=4.07, accuracy=67.44, wps=10193, ups=1.23, wpb=8264.1, bsz=309.2, num_updates=57200, lr=5.91312e-05, gnorm=0.574, clip=0, loss_scale=32, train_wall=81, gb_free=16.8, wall=42890
2023-07-23 08:37:09 | INFO | train_inner | epoch 039:   1312 / 1474 loss=4.13, trans_loss=4.871, nll_loss=2.024, w2v_ctc_loss=0.561, task_loss=1.314, contrastive_loss=0.071, total=4176.04, n_correct=2823.44, ppl=4.07, accuracy=67.61, wps=10289.8, ups=1.23, wpb=8351.4, bsz=315.4, num_updates=57300, lr=5.90796e-05, gnorm=0.568, clip=0, loss_scale=32, train_wall=81, gb_free=17.4, wall=42971
2023-07-23 08:38:30 | INFO | train_inner | epoch 039:   1412 / 1474 loss=4.149, trans_loss=4.881, nll_loss=2.034, w2v_ctc_loss=0.561, task_loss=1.51, contrastive_loss=0.036, total=4055.22, n_correct=2735.36, ppl=4.1, accuracy=67.453, wps=10093.1, ups=1.24, wpb=8107, bsz=278.4, num_updates=57400, lr=5.90281e-05, gnorm=0.576, clip=0, loss_scale=32, train_wall=80, gb_free=15.1, wall=43052
2023-07-23 08:39:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 08:39:43 | INFO | dev_st | epoch 039 | valid on 'dev_st' subset | loss 4.217 | trans_loss 5.591 | nll_loss 2.859 | w2v_ctc_loss 1.349 | task_loss 4.64 | contrastive_loss 0.253 | total 4003.4 | n_correct 2484.7 | ppl 7.25 | accuracy 62.065 | uer 16.617 | wer 18.422 | raw_wer 18.422 | bleu 20 | wps 2214.1 | wpb 4003.4 | bsz 141.8 | num_updates 57462 | best_bleu 20.09
2023-07-23 08:39:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 57462 updates
2023-07-23 08:39:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_20.0001.pt
2023-07-23 08:39:47 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_20.0001.pt
2023-07-23 08:39:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint.best_bleu_20.0001.pt (epoch 39 @ 57462 updates, score 20.0) (writing took 11.636398877948523 seconds)
2023-07-23 08:39:56 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-07-23 08:39:56 | INFO | train | epoch 039 | loss 4.131 | trans_loss 4.868 | nll_loss 2.019 | w2v_ctc_loss 0.555 | task_loss 1.373 | contrastive_loss 0.097 | total 4138.65 | n_correct 2798.56 | ppl 4.05 | accuracy 67.62 | wps 9519.5 | ups 1.15 | wpb 8277.3 | bsz 305.7 | num_updates 57462 | lr 5.89963e-05 | gnorm 0.571 | clip 0 | loss_scale 32 | train_wall 1188 | gb_free 15.7 | wall 43137
2023-07-23 08:39:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 08:39:56 | INFO | fairseq.trainer | begin training epoch 40
2023-07-23 08:39:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 08:40:36 | INFO | train_inner | epoch 040:     38 / 1474 loss=4.128, trans_loss=4.871, nll_loss=2.024, w2v_ctc_loss=0.546, task_loss=1.324, contrastive_loss=0.061, total=4169.65, n_correct=2817.58, ppl=4.07, accuracy=67.574, wps=6631.8, ups=0.79, wpb=8345.7, bsz=312, num_updates=57500, lr=5.89768e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=80, gb_free=16.1, wall=43177
2023-07-23 08:41:57 | INFO | train_inner | epoch 040:    138 / 1474 loss=4.107, trans_loss=4.845, nll_loss=1.988, w2v_ctc_loss=0.546, task_loss=1.366, contrastive_loss=0.052, total=4150.02, n_correct=2829.95, ppl=3.97, accuracy=68.191, wps=10202.5, ups=1.23, wpb=8287.2, bsz=305.2, num_updates=57600, lr=5.89256e-05, gnorm=0.566, clip=0, loss_scale=32, train_wall=81, gb_free=17.9, wall=43259
2023-07-23 08:43:18 | INFO | train_inner | epoch 040:    238 / 1474 loss=4.119, trans_loss=4.853, nll_loss=1.999, w2v_ctc_loss=0.558, task_loss=1.405, contrastive_loss=0.052, total=4101.15, n_correct=2783.61, ppl=4, accuracy=67.874, wps=10178, ups=1.24, wpb=8217.1, bsz=299.8, num_updates=57700, lr=5.88745e-05, gnorm=0.573, clip=0, loss_scale=32, train_wall=80, gb_free=10.8, wall=43339
2023-07-23 08:44:38 | INFO | train_inner | epoch 040:    338 / 1474 loss=4.102, trans_loss=4.848, nll_loss=1.994, w2v_ctc_loss=0.537, task_loss=1.269, contrastive_loss=0.062, total=4161.74, n_correct=2838.2, ppl=3.98, accuracy=68.197, wps=10274.7, ups=1.24, wpb=8315.5, bsz=321.1, num_updates=57800, lr=5.88235e-05, gnorm=0.561, clip=0, loss_scale=32, train_wall=80, gb_free=17.2, wall=43420
2023-07-23 08:46:00 | INFO | train_inner | epoch 040:    438 / 1474 loss=4.122, trans_loss=4.859, nll_loss=2.007, w2v_ctc_loss=0.55, task_loss=1.369, contrastive_loss=0.139, total=4141.51, n_correct=2806.78, ppl=4.02, accuracy=67.772, wps=10183.3, ups=1.23, wpb=8285.4, bsz=310.5, num_updates=57900, lr=5.87727e-05, gnorm=0.573, clip=0, loss_scale=64, train_wall=81, gb_free=16.7, wall=43502
2023-07-23 08:47:22 | INFO | train_inner | epoch 040:    538 / 1474 loss=4.118, trans_loss=4.855, nll_loss=2.003, w2v_ctc_loss=0.538, task_loss=1.332, contrastive_loss=0.161, total=4167.53, n_correct=2830.16, ppl=4.01, accuracy=67.91, wps=10201.4, ups=1.22, wpb=8339.8, bsz=315.5, num_updates=58000, lr=5.8722e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=81, gb_free=16.3, wall=43583
2023-07-23 08:47:22 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 08:47:46 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 4.233 | trans_loss 5.596 | nll_loss 2.866 | w2v_ctc_loss 1.39 | task_loss 4.632 | contrastive_loss 0.253 | total 4003.4 | n_correct 2479.7 | ppl 7.29 | accuracy 61.94 | uer 16.678 | wer 18.459 | raw_wer 18.459 | bleu 19.67 | wps 2095 | wpb 4003.4 | bsz 141.8 | num_updates 58000 | best_bleu 20.09
2023-07-23 08:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58000 updates
2023-07-23 08:47:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_40_58000.pt
2023-07-23 08:47:49 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_40_58000.pt
2023-07-23 08:47:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_40_58000.pt (epoch 40 @ 58000 updates, score 19.67) (writing took 10.986150411888957 seconds)
2023-07-23 08:49:18 | INFO | train_inner | epoch 040:    638 / 1474 loss=4.132, trans_loss=4.866, nll_loss=2.015, w2v_ctc_loss=0.554, task_loss=1.421, contrastive_loss=0.065, total=4118.6, n_correct=2785.93, ppl=4.04, accuracy=67.643, wps=7092, ups=0.86, wpb=8261.6, bsz=298.4, num_updates=58100, lr=5.86715e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=81, gb_free=12.7, wall=43700
2023-07-23 08:50:39 | INFO | train_inner | epoch 040:    738 / 1474 loss=4.117, trans_loss=4.859, nll_loss=2.008, w2v_ctc_loss=0.545, task_loss=1.327, contrastive_loss=0.043, total=4137.91, n_correct=2812.71, ppl=4.02, accuracy=67.974, wps=10248.4, ups=1.24, wpb=8275.7, bsz=308.3, num_updates=58200, lr=5.8621e-05, gnorm=0.564, clip=0, loss_scale=64, train_wall=80, gb_free=16.4, wall=43781
2023-07-23 08:52:01 | INFO | train_inner | epoch 040:    838 / 1474 loss=4.126, trans_loss=4.864, nll_loss=2.016, w2v_ctc_loss=0.545, task_loss=1.243, contrastive_loss=0.256, total=4214.92, n_correct=2850.03, ppl=4.04, accuracy=67.618, wps=10251.7, ups=1.22, wpb=8418.8, bsz=329.3, num_updates=58300, lr=5.85707e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=82, gb_free=16.8, wall=43863
2023-07-23 08:53:21 | INFO | train_inner | epoch 040:    938 / 1474 loss=4.14, trans_loss=4.873, nll_loss=2.025, w2v_ctc_loss=0.556, task_loss=1.443, contrastive_loss=0.071, total=4092.24, n_correct=2761.03, ppl=4.07, accuracy=67.47, wps=10192, ups=1.24, wpb=8205.7, bsz=293.6, num_updates=58400, lr=5.85206e-05, gnorm=0.582, clip=0, loss_scale=64, train_wall=80, gb_free=15.2, wall=43943
2023-07-23 08:54:43 | INFO | train_inner | epoch 040:   1038 / 1474 loss=4.148, trans_loss=4.879, nll_loss=2.032, w2v_ctc_loss=0.564, task_loss=1.487, contrastive_loss=0.092, total=4119.93, n_correct=2770.36, ppl=4.09, accuracy=67.243, wps=10141, ups=1.23, wpb=8234.6, bsz=287.5, num_updates=58500, lr=5.84705e-05, gnorm=0.576, clip=0, loss_scale=64, train_wall=81, gb_free=16, wall=44025
2023-07-23 08:56:04 | INFO | train_inner | epoch 040:   1138 / 1474 loss=4.135, trans_loss=4.871, nll_loss=2.022, w2v_ctc_loss=0.553, task_loss=1.428, contrastive_loss=0.055, total=4124.74, n_correct=2788.41, ppl=4.06, accuracy=67.602, wps=10109.3, ups=1.22, wpb=8268.2, bsz=298.3, num_updates=58600, lr=5.84206e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=81, gb_free=16.9, wall=44106
2023-07-23 08:57:26 | INFO | train_inner | epoch 040:   1238 / 1474 loss=4.131, trans_loss=4.869, nll_loss=2.02, w2v_ctc_loss=0.552, task_loss=1.349, contrastive_loss=0.117, total=4198.52, n_correct=2845.95, ppl=4.06, accuracy=67.785, wps=10294.8, ups=1.23, wpb=8382, bsz=310.8, num_updates=58700, lr=5.83708e-05, gnorm=0.567, clip=0, loss_scale=64, train_wall=81, gb_free=17.2, wall=44188
2023-07-23 08:58:47 | INFO | train_inner | epoch 040:   1338 / 1474 loss=4.129, trans_loss=4.868, nll_loss=2.02, w2v_ctc_loss=0.547, task_loss=1.379, contrastive_loss=0.121, total=4124.38, n_correct=2791.54, ppl=4.05, accuracy=67.684, wps=10183.4, ups=1.23, wpb=8247.5, bsz=306, num_updates=58800, lr=5.83212e-05, gnorm=0.587, clip=0, loss_scale=64, train_wall=81, gb_free=16.4, wall=44269
2023-07-23 09:00:08 | INFO | train_inner | epoch 040:   1438 / 1474 loss=4.134, trans_loss=4.872, nll_loss=2.025, w2v_ctc_loss=0.557, task_loss=1.377, contrastive_loss=0.086, total=4121.8, n_correct=2789.08, ppl=4.07, accuracy=67.667, wps=10163.2, ups=1.23, wpb=8233.2, bsz=304.3, num_updates=58900, lr=5.82717e-05, gnorm=0.574, clip=0, loss_scale=64, train_wall=81, gb_free=15.8, wall=44350
2023-07-23 09:00:37 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 09:01:02 | INFO | dev_st | epoch 040 | valid on 'dev_st' subset | loss 4.227 | trans_loss 5.595 | nll_loss 2.868 | w2v_ctc_loss 1.379 | task_loss 4.63 | contrastive_loss 0.24 | total 4003.4 | n_correct 2476.4 | ppl 7.3 | accuracy 61.857 | uer 16.63 | wer 18.303 | raw_wer 18.303 | bleu 19.73 | wps 1900.5 | wpb 4003.4 | bsz 141.8 | num_updates 58936 | best_bleu 20.09
2023-07-23 09:01:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 58936 updates
2023-07-23 09:01:02 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 09:01:13 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt
2023-07-23 09:01:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_last.pt (epoch 40 @ 58936 updates, score 19.73) (writing took 10.594364335760474 seconds)
2023-07-23 09:01:13 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-07-23 09:01:13 | INFO | train | epoch 040 | loss 4.125 | trans_loss 4.863 | nll_loss 2.012 | w2v_ctc_loss 0.55 | task_loss 1.371 | contrastive_loss 0.097 | total 4138.65 | n_correct 2804.21 | ppl 4.03 | accuracy 67.757 | wps 9551.3 | ups 1.15 | wpb 8277.3 | bsz 305.7 | num_updates 58936 | lr 5.82539e-05 | gnorm 0.572 | clip 0 | loss_scale 64 | train_wall 1189 | gb_free 15.9 | wall 44415
2023-07-23 09:01:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-07-23 09:01:13 | INFO | fairseq.trainer | begin training epoch 41
2023-07-23 09:01:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-07-23 09:02:12 | INFO | train_inner | epoch 041:     64 / 1474 loss=4.116, trans_loss=4.856, nll_loss=2.003, w2v_ctc_loss=0.545, task_loss=1.428, contrastive_loss=0.057, total=4088.95, n_correct=2772.95, ppl=4.01, accuracy=67.816, wps=6546.8, ups=0.8, wpb=8146.4, bsz=295.6, num_updates=59000, lr=5.82223e-05, gnorm=0.577, clip=0, loss_scale=64, train_wall=80, gb_free=17.1, wall=44474
2023-07-23 09:03:33 | INFO | train_inner | epoch 041:    164 / 1474 loss=4.099, trans_loss=4.836, nll_loss=1.978, w2v_ctc_loss=0.538, task_loss=1.328, contrastive_loss=0.11, total=4141.51, n_correct=2826.12, ppl=3.94, accuracy=68.239, wps=10227.8, ups=1.23, wpb=8285.8, bsz=311.5, num_updates=59100, lr=5.8173e-05, gnorm=0.563, clip=0, loss_scale=64, train_wall=81, gb_free=16, wall=44555
2023-07-23 09:04:53 | INFO | train_inner | epoch 041:    264 / 1474 loss=4.107, trans_loss=4.849, nll_loss=1.994, w2v_ctc_loss=0.544, task_loss=1.277, contrastive_loss=0.106, total=4181.72, n_correct=2844.13, ppl=3.98, accuracy=68.013, wps=10425.8, ups=1.25, wpb=8352, bsz=319.1, num_updates=59200, lr=5.81238e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=80, gb_free=16.5, wall=44635
2023-07-23 09:06:15 | INFO | train_inner | epoch 041:    364 / 1474 loss=4.12, trans_loss=4.854, nll_loss=2.001, w2v_ctc_loss=0.555, task_loss=1.368, contrastive_loss=0.063, total=4147.02, n_correct=2820.22, ppl=4, accuracy=68.006, wps=10219.7, ups=1.23, wpb=8301.6, bsz=304.9, num_updates=59300, lr=5.80748e-05, gnorm=0.58, clip=0, loss_scale=64, train_wall=81, gb_free=16.6, wall=44717
2023-07-23 09:07:35 | INFO | train_inner | epoch 041:    464 / 1474 loss=4.112, trans_loss=4.85, nll_loss=1.995, w2v_ctc_loss=0.544, task_loss=1.378, contrastive_loss=0.045, total=4144.36, n_correct=2822.6, ppl=3.99, accuracy=68.107, wps=10274.9, ups=1.24, wpb=8295.2, bsz=302.8, num_updates=59400, lr=5.80259e-05, gnorm=0.571, clip=0, loss_scale=64, train_wall=80, gb_free=16, wall=44797
2023-07-23 09:08:56 | INFO | train_inner | epoch 041:    564 / 1474 loss=4.115, trans_loss=4.851, nll_loss=1.996, w2v_ctc_loss=0.549, task_loss=1.374, contrastive_loss=0.063, total=4145.19, n_correct=2820.82, ppl=3.99, accuracy=68.05, wps=10307.3, ups=1.24, wpb=8303.7, bsz=307.1, num_updates=59500, lr=5.79771e-05, gnorm=0.568, clip=0, loss_scale=64, train_wall=80, gb_free=17.1, wall=44878
2023-07-23 09:10:17 | INFO | train_inner | epoch 041:    664 / 1474 loss=4.105, trans_loss=4.849, nll_loss=1.994, w2v_ctc_loss=0.544, task_loss=1.291, contrastive_loss=0.048, total=4189.74, n_correct=2854.62, ppl=3.98, accuracy=68.134, wps=10377.2, ups=1.24, wpb=8368.1, bsz=318.1, num_updates=59600, lr=5.79284e-05, gnorm=0.569, clip=0, loss_scale=64, train_wall=80, gb_free=16.6, wall=44959
2023-07-23 09:11:37 | INFO | train_inner | epoch 041:    764 / 1474 loss=4.117, trans_loss=4.856, nll_loss=2.003, w2v_ctc_loss=0.543, task_loss=1.388, contrastive_loss=0.044, total=4150.75, n_correct=2818.95, ppl=4.01, accuracy=67.914, wps=10304.7, ups=1.24, wpb=8290.3, bsz=300.9, num_updates=59700, lr=5.78799e-05, gnorm=0.57, clip=0, loss_scale=64, train_wall=80, gb_free=16.3, wall=45039
2023-07-23 09:12:58 | INFO | train_inner | epoch 041:    864 / 1474 loss=4.121, trans_loss=4.858, nll_loss=2.005, w2v_ctc_loss=0.555, task_loss=1.423, contrastive_loss=0.047, total=4108.1, n_correct=2784.35, ppl=4.02, accuracy=67.777, wps=10179.5, ups=1.24, wpb=8197.9, bsz=295.8, num_updates=59800, lr=5.78315e-05, gnorm=0.578, clip=0, loss_scale=64, train_wall=80, gb_free=16.9, wall=45120
2023-07-23 09:14:20 | INFO | train_inner | epoch 041:    964 / 1474 loss=4.134, trans_loss=4.867, nll_loss=2.018, w2v_ctc_loss=0.555, task_loss=1.428, contrastive_loss=0.137, total=4122.2, n_correct=2789.08, ppl=4.05, accuracy=67.66, wps=10026.4, ups=1.22, wpb=8236, bsz=299.1, num_updates=59900, lr=5.77832e-05, gnorm=0.578, clip=0, loss_scale=64, train_wall=82, gb_free=15.2, wall=45202
2023-07-23 09:15:40 | INFO | train_inner | epoch 041:   1064 / 1474 loss=4.124, trans_loss=4.863, nll_loss=2.013, w2v_ctc_loss=0.549, task_loss=1.365, contrastive_loss=0.05, total=4133.83, n_correct=2803.39, ppl=4.04, accuracy=67.816, wps=10270.5, ups=1.24, wpb=8276.8, bsz=303.9, num_updates=60000, lr=5.7735e-05, gnorm=0.575, clip=0, loss_scale=128, train_wall=80, gb_free=12.8, wall=45282
2023-07-23 09:15:40 | INFO | fairseq_cli.train | Stopping training due to num_updates: 60000 >= max_update: 60000
2023-07-23 09:15:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-07-23 09:16:04 | INFO | dev_st | epoch 041 | valid on 'dev_st' subset | loss 4.229 | trans_loss 5.597 | nll_loss 2.869 | w2v_ctc_loss 1.374 | task_loss 4.635 | contrastive_loss 0.26 | total 4003.4 | n_correct 2476.3 | ppl 7.31 | accuracy 61.855 | uer 16.68 | wer 18.523 | raw_wer 18.523 | bleu 19.96 | wps 2177.5 | wpb 4003.4 | bsz 141.8 | num_updates 60000 | best_bleu 20.09
2023-07-23 09:16:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 60000 updates
2023-07-23 09:16:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_41_60000.pt
2023-07-23 09:16:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_41_60000.pt
2023-07-23 09:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_AT_sentence_mt_0722/checkpoint_41_60000.pt (epoch 41 @ 60000 updates, score 19.96) (writing took 19.33481133542955 seconds)
2023-07-23 09:16:24 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-07-23 09:16:24 | INFO | train | epoch 041 | loss 4.115 | trans_loss 4.853 | nll_loss 2 | w2v_ctc_loss 0.548 | task_loss 1.364 | contrastive_loss 0.071 | total 4144.26 | n_correct 2816.75 | ppl 4 | accuracy 67.967 | wps 9680.1 | ups 1.17 | wpb 8285 | bsz 306 | num_updates 60000 | lr 5.7735e-05 | gnorm 0.573 | clip 0 | loss_scale 128 | train_wall 854 | gb_free 12.8 | wall 45326
2023-07-23 09:16:24 | INFO | fairseq_cli.train | done training in 45242.5 seconds
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
    raise EOFError
EOFError
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
