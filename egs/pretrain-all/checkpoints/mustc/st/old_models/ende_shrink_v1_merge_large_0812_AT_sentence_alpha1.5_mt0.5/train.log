2023-08-12 22:58:52 | INFO | fairseq.distributed.utils | distributed init (rank 4): tcp://localhost:19918
2023-08-12 22:58:52 | INFO | fairseq.distributed.utils | distributed init (rank 7): tcp://localhost:19918
2023-08-12 22:58:53 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19918
2023-08-12 22:58:53 | INFO | fairseq.distributed.utils | distributed init (rank 6): tcp://localhost:19918
2023-08-12 22:58:53 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19918
2023-08-12 22:58:53 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19918
2023-08-12 22:58:53 | INFO | fairseq.distributed.utils | distributed init (rank 5): tcp://localhost:19918
2023-08-12 22:58:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 5
2023-08-12 22:58:53 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19918
2023-08-12 22:58:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-08-12 22:58:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 4
2023-08-12 22:58:53 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 7
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 6
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-12 22:58:54 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 0
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-12 22:58:54 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 6
2023-08-12 22:58:54 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 3
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-12 22:58:54 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 4
2023-08-12 22:58:54 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 5
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-12 22:58:54 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-08-12 22:58:54 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 7
2023-08-12 22:58:54 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 1
2023-08-12 22:58:54 | INFO | fairseq.distributed.utils | initialized host cpc1-finc11-0-0-cust154.4-2.cable.virginm.net as rank 2
2023-08-12 22:58:58 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19918', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_st,train_asr', 'valid_subset': 'dev_st', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': './checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': 10, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_joint', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'task': Namespace(_name='joint_triple_pretraining_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'criterion': Namespace(_name='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9,0.98)', adam_eps=1e-08, adapter_dim=4096, adapter_dropout=0.0, adapter_layers=0, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_position_embed=True, add_position_embed_after_ctc=True, add_proj_norm=False, adversarial_training=True, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, apply_mask=True, arch='s2t_joint', at_adapte_win=False, at_level='sentence', at_nomute=False, at_nopad=False, at_scale=1.0, attention_dropout=0.1, avg_shrink=False, azureml_logging=False, ban_cl_step=-1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, cluster_embed_path='', cnn_module_kernel=31, combine_valid_subsets=None, config_yaml='config_st.yaml', continue_once=None, contrastive_alpha=1.5, contrastive_beta=1.0, contrastive_temperature=0.1, conv_channels=512, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy_with_w2v_ctc_shrink_joint_AT_merge', ctc_weight=0.3, curriculum=0, data='data_all_ende_lcrm', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline', decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, decrease_step=0, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, dropout=0.1, dropout_input=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, embed_path='', embedding_l2norm=False, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_normalize_before=True, eos=2, eval_bleu=True, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, feature_grad_mult=0.0, final_dropout=0.1, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, freeze_finetune_updates=3000, gen_subset='test', get_similarity=False, gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, is_shrink='uniq', keep_best_checkpoints=10, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=2, keep_mt_task=True, label_smoothing=0.2, latent_temp=(1, 0.1, 0.999995), layerdrop=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lookback=False, lr=[0.0002], lr_scheduler='inverse_sqrt', macaron_style=False, mask_channel_length=6, mask_channel_other=0, mask_channel_prob=0.25, mask_channel_selection='static', mask_length=10, mask_other=0, mask_prob=0.5, mask_selection='static', max_epoch=100, max_position_ctc=0, max_source_positions=6000, max_target_positions=1024, max_tokens=15000, max_tokens_valid=15000, max_update=50000, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_mt_st=True, min_loss_scale=0.0001, mixup_for_whole_model=False, mixup_rate=0.0, model_parallel_size=1, mt_model_args=None, mt_model_filter_size=0, mt_model_path='/mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt', no_epoch_checkpoints=True, no_last_checkpoints=False, no_mask_channel_overlap=False, no_mask_overlap=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, normalize=False, not_fsdp_flatten_parameters=False, nprocs_per_node=8, num_shards=1, num_workers=2, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', position_unit_size=0, post_process='sentencepiece', profile=False, quant_noise_pq=0, quantization_config_path=None, rel_pos_type='legacy', relative_attn=False, report_accuracy=True, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5', save_interval=1, save_interval_updates=2000, scoring='bleu', sead_layers=6, seed=1, sentence_avg=False, shard_id=0, share_ctc_embed=True, share_decoder_input_output_embed=True, share_two_encoders=True, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='joint_triple_pretraining_merge', tensorboard_logdir='./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5', text_conv_kernel=0, threshold_loss_scale=None, tokenizer=None, tpu=False, train_config='/mnt/zhangyh/fairseq-AT/egs/pretrain-all/conf/train_shrink_AT_zyh.yaml', train_st_without_ctc=False, train_subset='train_st,train_asr', transfer_proj=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_cnn_module=True, use_ctc_cluster=False, use_ctc_loss=True, use_ctc_shrink=True, use_double_ctc=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, use_token_contrastive=False, use_two_contrastive=False, use_w2v_ctc=True, user_dir=None, valid_subset='dev_st', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, w2v_args=None, w2v_path='/mnt/zhangyh/pretrain/hubert_base_ls960.pt', wandb_project=None, warmup_init_lr=1e-07, warmup_updates=5000, weight_decay=0.0, weight_steps=5000, word_align=False, write_checkpoints_asynchronously=False, zero_infinity=True, zero_sharding='none', zero_triu=False), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 5000, 'warmup_init_lr': 1e-07, 'lr': [0.0002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-08-12 22:58:58 | INFO | fairseq.tasks.joint_triple_pretraining_merge | dictionary size (dict.wrd.txt): 10,000
2023-08-12 22:58:58 | INFO | fairseq.tasks.joint_triple_pretraining_merge | asr dictionary size (dict.wrd.txt): 10,000
2023-08-12 22:58:58 | INFO | fairseq.tasks.joint_triple_pretraining_merge | cluster dictionary size (kmeans100.convert.txt): 5,224
2023-08-12 22:58:58 | INFO | fairseq.tasks.joint_triple_pretraining_merge | Initial task weight: asr 1.0: mt 0.5
2023-08-12 22:58:58 | INFO | root | load pretrained embeddings: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-12 22:59:02 | INFO | fairseq.tasks.hubert_pretraining | current directory is /mnt/zhangyh/fairseq-AT/egs/pretrain-all
2023-08-12 22:59:02 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'data_all_ende_lcrm', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}
2023-08-12 22:59:02 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 6, 'mask_channel_prob': 0.25, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}
2023-08-12 22:59:04 | INFO | root | load pretrained hubert
2023-08-12 22:59:07 | INFO | root | load pretrained embedding as ctc proj: /mnt/zhangyh/fairseq-AT/egs/machine_translation/pretrain_embeddings_wmt_ende_baseline
2023-08-12 22:59:08 | INFO | root | load pretrained encoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-12 22:59:09 | INFO | root | load pretrained decoder: /mnt/zhangyh/fairseq-AT/egs/machine_translation/checkpoints/wmt-en2de/ende-baseline/last8.ensemble.pt
2023-08-12 22:59:09 | INFO | root | share the sematic adapter and textual encoder
2023-08-12 22:59:09 | INFO | fairseq_cli.train | S2TJoint(
  (acoustic_encoder): AcousticEncoder(
    (compress_ffn): Linear(in_features=768, out_features=512, bias=True)
    (proj): Linear(in_features=512, out_features=10000, bias=False)
    (w2v_model): HubertModel(
      (feature_extractor): ConvFeatureExtractionModel(
        (conv_layers): ModuleList(
          (0): Sequential(
            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
            (3): GELU(approximate='none')
          )
          (1): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (2): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (3): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (4): Sequential(
            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (5): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
          (6): Sequential(
            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
            (1): Dropout(p=0.0, inplace=False)
            (2): GELU(approximate='none')
          )
        )
      )
      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
      (dropout_input): Dropout(p=0.0, inplace=False)
      (dropout_features): Dropout(p=0.1, inplace=False)
      (encoder): TransformerEncoder(
        (pos_conv): Sequential(
          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
          (1): SamePad()
          (2): GELU(approximate='none')
        )
        (layers): ModuleList(
          (0): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (1): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (2): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (3): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (4): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (5): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (6): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (7): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (8): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (9): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (10): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
          (11): TransformerSentenceEncoderLayer(
            (self_attn): MultiheadAttention(
              (dropout_module): FairseqDropout()
              (k_proj): Linear(in_features=768, out_features=768, bias=True)
              (v_proj): Linear(in_features=768, out_features=768, bias=True)
              (q_proj): Linear(in_features=768, out_features=768, bias=True)
              (out_proj): Linear(in_features=768, out_features=768, bias=True)
            )
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
            (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
          )
        )
        (layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      (final_proj): None
    )
    (noad): NormalAdapter(
      (subsample): Conv1dSubsampler(
        (conv_layers): ModuleList(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
          (1): Conv1d(256, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        )
      )
      (layers): ModuleList()
    )
    (sead): SemanticAdapter(
      (embed_positions): SinusoidalPositionalEmbedding()
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=512, out_features=512, bias=True)
            (v_proj): Linear(in_features=512, out_features=512, bias=True)
            (q_proj): Linear(in_features=512, out_features=512, bias=True)
            (out_proj): Linear(in_features=512, out_features=512, bias=True)
          )
          (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        )
      )
      (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    )
    (final_dropout): Dropout(p=0.1, inplace=False)
    (shrink_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (textual_encoder): MTModelEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=10000, bias=False)
  )
  (task_net): TaskNetwork(
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (down_proj): Linear(in_features=512, out_features=256, bias=True)
    (up_proj): Linear(in_features=256, out_features=512, bias=True)
    (dropout_module): FairseqDropout()
    (task_proj): Linear(in_features=512, out_features=1, bias=False)
  )
)
2023-08-12 22:59:09 | INFO | fairseq_cli.train | task: JointTriplePretrainingMergeTask
2023-08-12 22:59:09 | INFO | fairseq_cli.train | model: S2TJoint
2023-08-12 22:59:09 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropywithW2vCtcShrinkJointATMerge
2023-08-12 22:59:09 | INFO | fairseq_cli.train | num. shared model params: 147,044,480 (num. trained: 147,044,480)
2023-08-12 22:59:09 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-08-12 22:59:09 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-12 22:59:09 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-12 22:59:09 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-12 22:59:09 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="dev_st", n_samples=1418, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-12 22:59:15 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-08-12 22:59:15 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- textual_encoder.embed_tokens.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.embed_tokens.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.weight <- decoder.output_projection.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- acoustic_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- decoder.output_projection.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.proj.bias <- task_net.task_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.weight <- textual_encoder.layers.0.self_attn.k_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.k_proj.bias <- textual_encoder.layers.0.self_attn.k_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.weight <- textual_encoder.layers.0.self_attn.v_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.v_proj.bias <- textual_encoder.layers.0.self_attn.v_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.weight <- textual_encoder.layers.0.self_attn.q_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.q_proj.bias <- textual_encoder.layers.0.self_attn.q_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.weight <- textual_encoder.layers.0.self_attn.out_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn.out_proj.bias <- textual_encoder.layers.0.self_attn.out_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.weight <- textual_encoder.layers.0.self_attn_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.self_attn_layer_norm.bias <- textual_encoder.layers.0.self_attn_layer_norm.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.weight <- textual_encoder.layers.0.fc1.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc1.bias <- textual_encoder.layers.0.fc1.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.weight <- textual_encoder.layers.0.fc2.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.fc2.bias <- textual_encoder.layers.0.fc2.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.weight <- textual_encoder.layers.0.final_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.0.final_layer_norm.bias <- textual_encoder.layers.0.final_layer_norm.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.weight <- textual_encoder.layers.1.self_attn.k_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.k_proj.bias <- textual_encoder.layers.1.self_attn.k_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.weight <- textual_encoder.layers.1.self_attn.v_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.v_proj.bias <- textual_encoder.layers.1.self_attn.v_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.weight <- textual_encoder.layers.1.self_attn.q_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.q_proj.bias <- textual_encoder.layers.1.self_attn.q_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.weight <- textual_encoder.layers.1.self_attn.out_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn.out_proj.bias <- textual_encoder.layers.1.self_attn.out_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.weight <- textual_encoder.layers.1.self_attn_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.self_attn_layer_norm.bias <- textual_encoder.layers.1.self_attn_layer_norm.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.weight <- textual_encoder.layers.1.fc1.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc1.bias <- textual_encoder.layers.1.fc1.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.weight <- textual_encoder.layers.1.fc2.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.fc2.bias <- textual_encoder.layers.1.fc2.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.weight <- textual_encoder.layers.1.final_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.1.final_layer_norm.bias <- textual_encoder.layers.1.final_layer_norm.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.weight <- textual_encoder.layers.2.self_attn.k_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.k_proj.bias <- textual_encoder.layers.2.self_attn.k_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.weight <- textual_encoder.layers.2.self_attn.v_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.v_proj.bias <- textual_encoder.layers.2.self_attn.v_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.weight <- textual_encoder.layers.2.self_attn.q_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.q_proj.bias <- textual_encoder.layers.2.self_attn.q_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.weight <- textual_encoder.layers.2.self_attn.out_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn.out_proj.bias <- textual_encoder.layers.2.self_attn.out_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.weight <- textual_encoder.layers.2.self_attn_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.self_attn_layer_norm.bias <- textual_encoder.layers.2.self_attn_layer_norm.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.weight <- textual_encoder.layers.2.fc1.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc1.bias <- textual_encoder.layers.2.fc1.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.weight <- textual_encoder.layers.2.fc2.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.fc2.bias <- textual_encoder.layers.2.fc2.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.weight <- textual_encoder.layers.2.final_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.2.final_layer_norm.bias <- textual_encoder.layers.2.final_layer_norm.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.weight <- textual_encoder.layers.3.self_attn.k_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.k_proj.bias <- textual_encoder.layers.3.self_attn.k_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.weight <- textual_encoder.layers.3.self_attn.v_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.v_proj.bias <- textual_encoder.layers.3.self_attn.v_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.weight <- textual_encoder.layers.3.self_attn.q_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.q_proj.bias <- textual_encoder.layers.3.self_attn.q_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.weight <- textual_encoder.layers.3.self_attn.out_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn.out_proj.bias <- textual_encoder.layers.3.self_attn.out_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.weight <- textual_encoder.layers.3.self_attn_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.self_attn_layer_norm.bias <- textual_encoder.layers.3.self_attn_layer_norm.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.weight <- textual_encoder.layers.3.fc1.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc1.bias <- textual_encoder.layers.3.fc1.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.weight <- textual_encoder.layers.3.fc2.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.fc2.bias <- textual_encoder.layers.3.fc2.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.weight <- textual_encoder.layers.3.final_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.3.final_layer_norm.bias <- textual_encoder.layers.3.final_layer_norm.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.weight <- textual_encoder.layers.4.self_attn.k_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.k_proj.bias <- textual_encoder.layers.4.self_attn.k_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.weight <- textual_encoder.layers.4.self_attn.v_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.v_proj.bias <- textual_encoder.layers.4.self_attn.v_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.weight <- textual_encoder.layers.4.self_attn.q_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.q_proj.bias <- textual_encoder.layers.4.self_attn.q_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.weight <- textual_encoder.layers.4.self_attn.out_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn.out_proj.bias <- textual_encoder.layers.4.self_attn.out_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.weight <- textual_encoder.layers.4.self_attn_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.self_attn_layer_norm.bias <- textual_encoder.layers.4.self_attn_layer_norm.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.weight <- textual_encoder.layers.4.fc1.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc1.bias <- textual_encoder.layers.4.fc1.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.weight <- textual_encoder.layers.4.fc2.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.fc2.bias <- textual_encoder.layers.4.fc2.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.weight <- textual_encoder.layers.4.final_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.4.final_layer_norm.bias <- textual_encoder.layers.4.final_layer_norm.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.weight <- textual_encoder.layers.5.self_attn.k_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.k_proj.bias <- textual_encoder.layers.5.self_attn.k_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.weight <- textual_encoder.layers.5.self_attn.v_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.v_proj.bias <- textual_encoder.layers.5.self_attn.v_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.weight <- textual_encoder.layers.5.self_attn.q_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.q_proj.bias <- textual_encoder.layers.5.self_attn.q_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.weight <- textual_encoder.layers.5.self_attn.out_proj.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn.out_proj.bias <- textual_encoder.layers.5.self_attn.out_proj.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.weight <- textual_encoder.layers.5.self_attn_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.self_attn_layer_norm.bias <- textual_encoder.layers.5.self_attn_layer_norm.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.weight <- textual_encoder.layers.5.fc1.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc1.bias <- textual_encoder.layers.5.fc1.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.weight <- textual_encoder.layers.5.fc2.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.fc2.bias <- textual_encoder.layers.5.fc2.bias
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.weight <- textual_encoder.layers.5.final_layer_norm.weight
2023-08-12 22:59:15 | INFO | fairseq.trainer | detected shared parameter: acoustic_encoder.sead.layers.5.final_layer_norm.bias <- textual_encoder.layers.5.final_layer_norm.bias
2023-08-12 22:59:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-12 22:59:16 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-12 22:59:16 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-12 22:59:16 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-12 22:59:16 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-12 22:59:16 | INFO | fairseq.utils | rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-12 22:59:16 | INFO | fairseq.utils | rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-12 22:59:16 | INFO | fairseq.utils | rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-12 22:59:16 | INFO | fairseq.utils | rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-08-12 22:59:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 8 workers***********************
2023-08-12 22:59:16 | INFO | fairseq_cli.train | training on 8 devices (GPUs/TPUs)
2023-08-12 22:59:16 | INFO | fairseq_cli.train | max tokens per device = 15000 and max sentences per device = None
2023-08-12 22:59:16 | INFO | fairseq.trainer | Preparing to load checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-12 22:59:16 | INFO | fairseq.trainer | No existing checkpoint found ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-12 22:59:16 | INFO | fairseq.trainer | loading train data for epoch 1
2023-08-12 22:59:16 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2023-08-12 22:59:16 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-12 22:59:16 | INFO | fairseq.tasks.joint_triple_pretraining_merge | src tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/mnt/zhangyh/fairseq-AT/egs/pretrain-all/data_all_ende_lcrm/sentencepiece.bpe.model'}
2023-08-12 22:59:18 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_asr", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-12 22:59:19 | INFO | fairseq.data.audio.triple_dataset | TripleDataset(split="train_st", n_samples=225277, prepend_tgt_lang_tag=False, shuffle=False, transforms=None)
2023-08-12 23:00:07 | INFO | fairseq.optim.adam | using FusedAdam
2023-08-12 23:00:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-12 23:00:07 | INFO | fairseq.trainer | begin training epoch 1
2023-08-12 23:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-12 23:00:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-12 23:00:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-12 23:00:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-12 23:00:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-08-12 23:00:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-08-12 23:01:32 | INFO | train_inner | epoch 001:    105 / 1474 loss=20.049, trans_loss=5.877, nll_loss=4.687, w2v_ctc_loss=22.327, task_loss=1.764, contrastive_loss=3.266, total=4220.17, n_correct=125.12, ppl=25.75, accuracy=2.965, wps=18229.8, ups=1.45, wpb=12590.6, bsz=475, num_updates=100, lr=4.098e-06, gnorm=2.827, clip=0, loss_scale=4, train_wall=76, gb_free=19.4, wall=136
2023-08-12 23:02:37 | INFO | train_inner | epoch 001:    205 / 1474 loss=16.562, trans_loss=5.853, nll_loss=4.682, w2v_ctc_loss=17.042, task_loss=1.712, contrastive_loss=3.237, total=4114.86, n_correct=115.74, ppl=25.67, accuracy=2.813, wps=18905.8, ups=1.54, wpb=12286.8, bsz=458.8, num_updates=200, lr=8.096e-06, gnorm=7.297, clip=19, loss_scale=4, train_wall=65, gb_free=19.4, wall=201
2023-08-12 23:03:41 | INFO | train_inner | epoch 001:    305 / 1474 loss=9.919, trans_loss=5.834, nll_loss=4.697, w2v_ctc_loss=6.898, task_loss=1.668, contrastive_loss=3.175, total=4080.91, n_correct=112.08, ppl=25.94, accuracy=2.746, wps=18814.8, ups=1.54, wpb=12190.4, bsz=439.4, num_updates=300, lr=1.2094e-05, gnorm=2.171, clip=0, loss_scale=4, train_wall=64, gb_free=18.6, wall=265
2023-08-12 23:04:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-12 23:04:47 | INFO | train_inner | epoch 001:    406 / 1474 loss=9.389, trans_loss=5.775, nll_loss=4.656, w2v_ctc_loss=6.108, task_loss=1.437, contrastive_loss=3.201, total=4175.04, n_correct=104.68, ppl=25.21, accuracy=2.507, wps=18963.6, ups=1.52, wpb=12465.9, bsz=459.4, num_updates=400, lr=1.6092e-05, gnorm=1.276, clip=0, loss_scale=2, train_wall=65, gb_free=18.6, wall=331
2023-08-12 23:05:53 | INFO | train_inner | epoch 001:    506 / 1474 loss=9.232, trans_loss=5.776, nll_loss=4.679, w2v_ctc_loss=5.809, task_loss=1.27, contrastive_loss=3.301, total=4181.66, n_correct=96.96, ppl=25.61, accuracy=2.319, wps=19109.1, ups=1.53, wpb=12495.1, bsz=487, num_updates=500, lr=2.009e-05, gnorm=1.302, clip=0, loss_scale=2, train_wall=65, gb_free=19.2, wall=397
2023-08-12 23:06:58 | INFO | train_inner | epoch 001:    606 / 1474 loss=9.176, trans_loss=5.897, nll_loss=4.839, w2v_ctc_loss=5.649, task_loss=1.24, contrastive_loss=3.253, total=4137.35, n_correct=92.34, ppl=28.62, accuracy=2.232, wps=18812, ups=1.52, wpb=12337.2, bsz=474.5, num_updates=600, lr=2.4088e-05, gnorm=0.876, clip=0, loss_scale=2, train_wall=65, gb_free=18.7, wall=462
2023-08-12 23:08:03 | INFO | train_inner | epoch 001:    706 / 1474 loss=9.129, trans_loss=6, nll_loss=4.974, w2v_ctc_loss=5.554, task_loss=1.311, contrastive_loss=3.122, total=4145.85, n_correct=68.65, ppl=31.42, accuracy=1.656, wps=19223.6, ups=1.55, wpb=12381.9, bsz=454.4, num_updates=700, lr=2.8086e-05, gnorm=0.83, clip=0, loss_scale=2, train_wall=64, gb_free=19.5, wall=527
2023-08-12 23:09:07 | INFO | train_inner | epoch 001:    806 / 1474 loss=8.937, trans_loss=6.05, nll_loss=5.023, w2v_ctc_loss=5.284, task_loss=1.271, contrastive_loss=3.125, total=4129.2, n_correct=61.51, ppl=32.51, accuracy=1.49, wps=19043.2, ups=1.55, wpb=12318.4, bsz=463.3, num_updates=800, lr=3.2084e-05, gnorm=1.217, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=591
2023-08-12 23:10:12 | INFO | train_inner | epoch 001:    906 / 1474 loss=8.751, trans_loss=6.089, nll_loss=5.066, w2v_ctc_loss=5.032, task_loss=1.291, contrastive_loss=3.025, total=4167.97, n_correct=48.48, ppl=33.5, accuracy=1.163, wps=19305.3, ups=1.55, wpb=12446.3, bsz=458.8, num_updates=900, lr=3.6082e-05, gnorm=1.532, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=656
2023-08-12 23:11:18 | INFO | train_inner | epoch 001:   1006 / 1474 loss=8.561, trans_loss=6.099, nll_loss=5.075, w2v_ctc_loss=4.777, task_loss=1.292, contrastive_loss=3.011, total=4137.5, n_correct=50.15, ppl=33.71, accuracy=1.212, wps=18762.8, ups=1.52, wpb=12361.1, bsz=459.1, num_updates=1000, lr=4.008e-05, gnorm=1.858, clip=0, loss_scale=2, train_wall=65, gb_free=19.3, wall=722
2023-08-12 23:12:22 | INFO | train_inner | epoch 001:   1106 / 1474 loss=8.377, trans_loss=6.137, nll_loss=5.116, w2v_ctc_loss=4.568, task_loss=1.327, contrastive_loss=2.921, total=4151.84, n_correct=55.49, ppl=34.68, accuracy=1.337, wps=19208.8, ups=1.55, wpb=12382.4, bsz=452.7, num_updates=1100, lr=4.4078e-05, gnorm=2.188, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=786
2023-08-12 23:13:26 | INFO | train_inner | epoch 001:   1206 / 1474 loss=8.208, trans_loss=6.133, nll_loss=5.113, w2v_ctc_loss=4.416, task_loss=1.383, contrastive_loss=2.817, total=4123.25, n_correct=53.81, ppl=34.61, accuracy=1.305, wps=19125, ups=1.55, wpb=12316.7, bsz=437.7, num_updates=1200, lr=4.8076e-05, gnorm=2.245, clip=0, loss_scale=2, train_wall=64, gb_free=19.6, wall=850
2023-08-12 23:14:30 | INFO | train_inner | epoch 001:   1306 / 1474 loss=8.107, trans_loss=6.158, nll_loss=5.142, w2v_ctc_loss=4.258, task_loss=1.302, contrastive_loss=2.785, total=4066.16, n_correct=52.22, ppl=35.32, accuracy=1.284, wps=19018, ups=1.57, wpb=12138.7, bsz=445.8, num_updates=1300, lr=5.2074e-05, gnorm=2.705, clip=0, loss_scale=2, train_wall=63, gb_free=18.8, wall=914
2023-08-12 23:15:36 | INFO | train_inner | epoch 001:   1406 / 1474 loss=7.941, trans_loss=6.122, nll_loss=5.101, w2v_ctc_loss=4.117, task_loss=1.324, contrastive_loss=2.846, total=4119.98, n_correct=58.15, ppl=34.32, accuracy=1.411, wps=18742.5, ups=1.52, wpb=12311.1, bsz=449.5, num_updates=1400, lr=5.6072e-05, gnorm=2.362, clip=0, loss_scale=2, train_wall=65, gb_free=18.6, wall=980
2023-08-12 23:16:20 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 23:17:00 | INFO | dev_st | epoch 001 | valid on 'dev_st' subset | loss 12.453 | trans_loss 13.913 | nll_loss 13.763 | w2v_ctc_loss 5.315 | task_loss 7.545 | contrastive_loss 4.067 | total 4003.4 | n_correct 33.8 | ppl 13900.5 | accuracy 0.844 | uer 67.99 | wer 66.578 | raw_wer 66.578 | bleu 0 | wps 1150.4 | wpb 4003.4 | bsz 141.8 | num_updates 1468
2023-08-12 23:17:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1468 updates
2023-08-12 23:17:00 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-12 23:17:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-12 23:17:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 1 @ 1468 updates, score 0.0) (writing took 6.764944702386856 seconds)
2023-08-12 23:17:06 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-08-12 23:17:06 | INFO | train | epoch 001 | loss 10.072 | trans_loss 5.992 | nll_loss 4.926 | w2v_ctc_loss 7.142 | task_loss 1.392 | contrastive_loss 3.068 | total 4139.17 | n_correct 77.1546 | ppl 30.4 | accuracy 1.864 | wps 18071.2 | ups 1.46 | wpb 12357.4 | bsz 458.6 | num_updates 1468 | lr 5.87906e-05 | gnorm 2.204 | clip 1.3 | loss_scale 2 | train_wall 958 | gb_free 18.9 | wall 1070
2023-08-12 23:17:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-12 23:17:07 | INFO | fairseq.trainer | begin training epoch 2
2023-08-12 23:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-12 23:17:37 | INFO | train_inner | epoch 002:     32 / 1474 loss=7.838, trans_loss=6.137, nll_loss=5.116, w2v_ctc_loss=3.977, task_loss=1.253, contrastive_loss=2.811, total=4165.61, n_correct=54.07, ppl=34.67, accuracy=1.298, wps=10303.5, ups=0.83, wpb=12422.6, bsz=470.4, num_updates=1500, lr=6.007e-05, gnorm=2.619, clip=0, loss_scale=2, train_wall=64, gb_free=18.7, wall=1101
2023-08-12 23:18:41 | INFO | train_inner | epoch 002:    132 / 1474 loss=7.701, trans_loss=6.123, nll_loss=5.099, w2v_ctc_loss=3.896, task_loss=1.31, contrastive_loss=2.66, total=4153.7, n_correct=55.89, ppl=34.28, accuracy=1.346, wps=19221.5, ups=1.55, wpb=12391.2, bsz=453.7, num_updates=1600, lr=6.4068e-05, gnorm=2.488, clip=0, loss_scale=2, train_wall=64, gb_free=19.2, wall=1165
2023-08-12 23:19:45 | INFO | train_inner | epoch 002:    232 / 1474 loss=7.634, trans_loss=6.134, nll_loss=5.117, w2v_ctc_loss=3.752, task_loss=1.144, contrastive_loss=2.731, total=4201.44, n_correct=54.35, ppl=34.71, accuracy=1.294, wps=19479.4, ups=1.55, wpb=12547.2, bsz=493.6, num_updates=1700, lr=6.8066e-05, gnorm=2.523, clip=0, loss_scale=2, train_wall=64, gb_free=18.9, wall=1229
2023-08-12 23:20:51 | INFO | train_inner | epoch 002:    332 / 1474 loss=7.437, trans_loss=6.098, nll_loss=5.072, w2v_ctc_loss=3.705, task_loss=1.337, contrastive_loss=2.497, total=4130.13, n_correct=61.01, ppl=33.64, accuracy=1.477, wps=18767.1, ups=1.52, wpb=12330.1, bsz=445.5, num_updates=1800, lr=7.2064e-05, gnorm=2.638, clip=0, loss_scale=2, train_wall=65, gb_free=18.7, wall=1295
2023-08-12 23:21:55 | INFO | train_inner | epoch 002:    432 / 1474 loss=7.307, trans_loss=6.1, nll_loss=5.078, w2v_ctc_loss=3.649, task_loss=1.468, contrastive_loss=2.316, total=4035.12, n_correct=57.32, ppl=33.78, accuracy=1.421, wps=18794.2, ups=1.56, wpb=12062.7, bsz=413.5, num_updates=1900, lr=7.6062e-05, gnorm=2.508, clip=0, loss_scale=2, train_wall=64, gb_free=19, wall=1359
2023-08-12 23:23:00 | INFO | train_inner | epoch 002:    532 / 1474 loss=7.244, trans_loss=6.077, nll_loss=5.043, w2v_ctc_loss=3.517, task_loss=1.268, contrastive_loss=2.468, total=4183.09, n_correct=65.42, ppl=32.97, accuracy=1.564, wps=19331.2, ups=1.55, wpb=12479, bsz=468.4, num_updates=2000, lr=8.006e-05, gnorm=2.599, clip=0, loss_scale=2, train_wall=64, gb_free=18.5, wall=1424
2023-08-12 23:23:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 23:23:40 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 11.647 | trans_loss 13.369 | nll_loss 13.059 | w2v_ctc_loss 4.566 | task_loss 7.545 | contrastive_loss 3.525 | total 4003.4 | n_correct 64.2 | ppl 8533.34 | accuracy 1.604 | uer 61.819 | wer 59.987 | raw_wer 59.987 | bleu 0 | wps 1138.3 | wpb 4003.4 | bsz 141.8 | num_updates 2000 | best_bleu 0
2023-08-12 23:23:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2000 updates
2023-08-12 23:23:40 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-12 23:23:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_2_2000.pt
2023-08-12 23:24:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_2_2000.pt (epoch 2 @ 2000 updates, score 0.0) (writing took 29.414591386914253 seconds)
2023-08-12 23:25:14 | INFO | train_inner | epoch 002:    632 / 1474 loss=7.089, trans_loss=6.052, nll_loss=5.012, w2v_ctc_loss=3.429, task_loss=1.301, contrastive_loss=2.282, total=4123.85, n_correct=65.04, ppl=32.26, accuracy=1.577, wps=9148.2, ups=0.74, wpb=12306.4, bsz=448.7, num_updates=2100, lr=8.4058e-05, gnorm=2.414, clip=0, loss_scale=2, train_wall=64, gb_free=18.6, wall=1558
2023-08-12 23:26:20 | INFO | train_inner | epoch 002:    732 / 1474 loss=7.029, trans_loss=6.044, nll_loss=5.002, w2v_ctc_loss=3.373, task_loss=1.288, contrastive_loss=2.36, total=4148.13, n_correct=70.26, ppl=32.05, accuracy=1.694, wps=18972.9, ups=1.53, wpb=12381, bsz=462.1, num_updates=2200, lr=8.8056e-05, gnorm=2.516, clip=0, loss_scale=2, train_wall=65, gb_free=18.6, wall=1624
2023-08-12 23:27:24 | INFO | train_inner | epoch 002:    832 / 1474 loss=6.936, trans_loss=6.028, nll_loss=4.984, w2v_ctc_loss=3.324, task_loss=1.301, contrastive_loss=2.31, total=4172.27, n_correct=74.66, ppl=31.65, accuracy=1.789, wps=19425.9, ups=1.56, wpb=12465.7, bsz=464.5, num_updates=2300, lr=9.2054e-05, gnorm=2.385, clip=0, loss_scale=2, train_wall=64, gb_free=18.8, wall=1688
2023-08-12 23:28:28 | INFO | train_inner | epoch 002:    932 / 1474 loss=6.813, trans_loss=6.033, nll_loss=4.987, w2v_ctc_loss=3.242, task_loss=1.362, contrastive_loss=2.234, total=4101.67, n_correct=66.33, ppl=31.72, accuracy=1.617, wps=19032.4, ups=1.55, wpb=12242.5, bsz=441.6, num_updates=2400, lr=9.6052e-05, gnorm=2.359, clip=0, loss_scale=4, train_wall=64, gb_free=18.9, wall=1752
2023-08-12 23:29:33 | INFO | train_inner | epoch 002:   1032 / 1474 loss=6.734, trans_loss=6.035, nll_loss=4.99, w2v_ctc_loss=3.184, task_loss=1.324, contrastive_loss=2.127, total=4091.09, n_correct=69.35, ppl=31.78, accuracy=1.695, wps=18931.9, ups=1.55, wpb=12214.8, bsz=451.5, num_updates=2500, lr=0.00010005, gnorm=2.136, clip=0, loss_scale=4, train_wall=64, gb_free=19.2, wall=1817
2023-08-12 23:30:39 | INFO | train_inner | epoch 002:   1132 / 1474 loss=6.707, trans_loss=6.023, nll_loss=4.975, w2v_ctc_loss=3.09, task_loss=1.149, contrastive_loss=2.352, total=4219.19, n_correct=76.3, ppl=31.45, accuracy=1.808, wps=19117, ups=1.52, wpb=12595.1, bsz=500.6, num_updates=2600, lr=0.000104048, gnorm=2.22, clip=1, loss_scale=4, train_wall=65, gb_free=19, wall=1883
2023-08-12 23:31:43 | INFO | train_inner | epoch 002:   1232 / 1474 loss=6.603, trans_loss=6.009, nll_loss=4.957, w2v_ctc_loss=3.062, task_loss=1.21, contrastive_loss=2.161, total=4212.91, n_correct=76.81, ppl=31.06, accuracy=1.823, wps=19450.8, ups=1.55, wpb=12571.7, bsz=486.8, num_updates=2700, lr=0.000108046, gnorm=2.038, clip=0, loss_scale=4, train_wall=64, gb_free=19.1, wall=1947
2023-08-12 23:32:47 | INFO | train_inner | epoch 002:   1332 / 1474 loss=6.499, trans_loss=6, nll_loss=4.949, w2v_ctc_loss=3.026, task_loss=1.271, contrastive_loss=1.947, total=4142.48, n_correct=77.26, ppl=30.88, accuracy=1.865, wps=19430.2, ups=1.57, wpb=12381.2, bsz=456.3, num_updates=2800, lr=0.000112044, gnorm=2.099, clip=0, loss_scale=4, train_wall=63, gb_free=18.9, wall=2011
2023-08-12 23:33:52 | INFO | train_inner | epoch 002:   1432 / 1474 loss=6.413, trans_loss=5.998, nll_loss=4.944, w2v_ctc_loss=2.983, task_loss=1.386, contrastive_loss=2.007, total=4063.28, n_correct=72.26, ppl=30.78, accuracy=1.778, wps=18745.2, ups=1.55, wpb=12131.5, bsz=444.3, num_updates=2900, lr=0.000116042, gnorm=1.963, clip=0, loss_scale=4, train_wall=64, gb_free=19.6, wall=2076
2023-08-12 23:34:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 23:34:59 | INFO | dev_st | epoch 002 | valid on 'dev_st' subset | loss 10.924 | trans_loss 13.104 | nll_loss 12.709 | w2v_ctc_loss 3.796 | task_loss 7.545 | contrastive_loss 2.728 | total 4003.4 | n_correct 81 | ppl 6695.76 | accuracy 2.023 | uer 52.956 | wer 52.377 | raw_wer 52.377 | bleu 0 | wps 1148.9 | wpb 4003.4 | bsz 141.8 | num_updates 2942 | best_bleu 0
2023-08-12 23:34:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2942 updates
2023-08-12 23:34:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-12 23:35:15 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-12 23:35:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 2 @ 2942 updates, score 0.0) (writing took 28.27140049636364 seconds)
2023-08-12 23:35:27 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-08-12 23:35:27 | INFO | train | epoch 002 | loss 7.01 | trans_loss 6.054 | nll_loss 5.015 | w2v_ctc_loss 3.375 | task_loss 1.292 | contrastive_loss 2.318 | total 4138.65 | n_correct 67.2571 | ppl 32.34 | accuracy 1.625 | wps 16543.4 | ups 1.34 | wpb 12355.8 | bsz 458.5 | num_updates 2942 | lr 0.000117721 | gnorm 2.348 | clip 0.1 | loss_scale 4 | train_wall 946 | gb_free 19 | wall 2171
2023-08-12 23:35:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-12 23:35:28 | INFO | fairseq.trainer | begin training epoch 3
2023-08-12 23:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-12 23:36:14 | INFO | train_inner | epoch 003:     58 / 1474 loss=6.316, trans_loss=5.984, nll_loss=4.927, w2v_ctc_loss=2.932, task_loss=1.362, contrastive_loss=1.86, total=4048.67, n_correct=76.24, ppl=30.41, accuracy=1.883, wps=8509.9, ups=0.7, wpb=12085.6, bsz=433.9, num_updates=3000, lr=0.00012004, gnorm=1.837, clip=0, loss_scale=4, train_wall=65, gb_free=18.8, wall=2218
2023-08-12 23:36:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-12 23:37:46 | INFO | train_inner | epoch 003:    159 / 1474 loss=5.636, trans_loss=5.306, nll_loss=4.069, w2v_ctc_loss=2.672, task_loss=0.904, contrastive_loss=1.8, total=4157.96, n_correct=278.94, ppl=16.79, accuracy=6.709, wps=13422.1, ups=1.08, wpb=12415.3, bsz=461.9, num_updates=3100, lr=0.000124038, gnorm=3.646, clip=2, loss_scale=2, train_wall=92, gb_free=16.2, wall=2310
2023-08-12 23:39:19 | INFO | train_inner | epoch 003:    259 / 1474 loss=4.719, trans_loss=4.529, nll_loss=3.038, w2v_ctc_loss=2.382, task_loss=0.928, contrastive_loss=1.617, total=4155.72, n_correct=876.7, ppl=8.21, accuracy=21.096, wps=13322.1, ups=1.07, wpb=12415.9, bsz=465.5, num_updates=3200, lr=0.000128036, gnorm=2.335, clip=0, loss_scale=2, train_wall=93, gb_free=17.4, wall=2403
2023-08-12 23:40:52 | INFO | train_inner | epoch 003:    359 / 1474 loss=4.336, trans_loss=4.26, nll_loss=2.684, w2v_ctc_loss=2.256, task_loss=0.917, contrastive_loss=1.529, total=4154.07, n_correct=1198.22, ppl=6.43, accuracy=28.844, wps=13356.7, ups=1.08, wpb=12396.6, bsz=464.9, num_updates=3300, lr=0.000132034, gnorm=2.111, clip=0, loss_scale=2, train_wall=92, gb_free=15.5, wall=2496
2023-08-12 23:42:26 | INFO | train_inner | epoch 003:    459 / 1474 loss=4.098, trans_loss=4.191, nll_loss=2.598, w2v_ctc_loss=2.141, task_loss=0.901, contrastive_loss=1.322, total=4212.17, n_correct=1315.85, ppl=6.05, accuracy=31.239, wps=13443.1, ups=1.07, wpb=12572.6, bsz=473.8, num_updates=3400, lr=0.000136032, gnorm=1.823, clip=0, loss_scale=2, train_wall=93, gb_free=15.5, wall=2590
2023-08-12 23:43:58 | INFO | train_inner | epoch 003:    559 / 1474 loss=3.91, trans_loss=4.158, nll_loss=2.559, w2v_ctc_loss=2.05, task_loss=0.984, contrastive_loss=1.192, total=4081.04, n_correct=1322.42, ppl=5.89, accuracy=32.404, wps=13187, ups=1.08, wpb=12190.8, bsz=440.1, num_updates=3500, lr=0.00014003, gnorm=1.784, clip=0, loss_scale=2, train_wall=92, gb_free=16.2, wall=2682
2023-08-12 23:45:31 | INFO | train_inner | epoch 003:    659 / 1474 loss=3.81, trans_loss=4.136, nll_loss=2.526, w2v_ctc_loss=1.962, task_loss=0.875, contrastive_loss=1.235, total=4231.09, n_correct=1420.22, ppl=5.76, accuracy=33.566, wps=13524.5, ups=1.07, wpb=12615.6, bsz=484.4, num_updates=3600, lr=0.000144028, gnorm=1.641, clip=0, loss_scale=2, train_wall=93, gb_free=15.7, wall=2775
2023-08-12 23:47:04 | INFO | train_inner | epoch 003:    759 / 1474 loss=3.651, trans_loss=4.096, nll_loss=2.479, w2v_ctc_loss=1.926, task_loss=0.884, contrastive_loss=0.941, total=4160.74, n_correct=1447.31, ppl=5.57, accuracy=34.785, wps=13478.3, ups=1.08, wpb=12428.5, bsz=469.2, num_updates=3700, lr=0.000148026, gnorm=1.545, clip=0, loss_scale=2, train_wall=92, gb_free=16.5, wall=2868
2023-08-12 23:48:37 | INFO | train_inner | epoch 003:    859 / 1474 loss=3.533, trans_loss=4.071, nll_loss=2.445, w2v_ctc_loss=1.88, task_loss=0.935, contrastive_loss=0.851, total=4160.47, n_correct=1494.93, ppl=5.45, accuracy=35.932, wps=13251, ups=1.07, wpb=12423.6, bsz=455.4, num_updates=3800, lr=0.000152024, gnorm=1.5, clip=0, loss_scale=2, train_wall=93, gb_free=16.1, wall=2961
2023-08-12 23:50:10 | INFO | train_inner | epoch 003:    959 / 1474 loss=3.443, trans_loss=4.035, nll_loss=2.396, w2v_ctc_loss=1.846, task_loss=0.898, contrastive_loss=0.825, total=4162.26, n_correct=1567.37, ppl=5.26, accuracy=37.657, wps=13392.4, ups=1.08, wpb=12416.1, bsz=467.9, num_updates=3900, lr=0.000156022, gnorm=1.465, clip=0, loss_scale=2, train_wall=92, gb_free=17.6, wall=3054
2023-08-12 23:51:42 | INFO | train_inner | epoch 003:   1059 / 1474 loss=3.339, trans_loss=3.999, nll_loss=2.351, w2v_ctc_loss=1.827, task_loss=0.979, contrastive_loss=0.721, total=4062.67, n_correct=1578.9, ppl=5.1, accuracy=38.864, wps=13272.5, ups=1.09, wpb=12131.7, bsz=443.2, num_updates=4000, lr=0.00016002, gnorm=1.365, clip=0, loss_scale=2, train_wall=91, gb_free=15.4, wall=3146
2023-08-12 23:51:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 23:52:13 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.481 | trans_loss 6.723 | nll_loss 4.418 | w2v_ctc_loss 2.141 | task_loss 4.322 | contrastive_loss 0.935 | total 4003.4 | n_correct 1745.3 | ppl 21.37 | accuracy 43.595 | uer 31.014 | wer 31.748 | raw_wer 31.748 | bleu 5.1 | wps 1536.5 | wpb 4003.4 | bsz 141.8 | num_updates 4000 | best_bleu 5.1
2023-08-12 23:52:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4000 updates
2023-08-12 23:52:13 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-12 23:52:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_3_4000.pt
2023-08-12 23:52:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_3_4000.pt (epoch 3 @ 4000 updates, score 5.1) (writing took 40.386196333914995 seconds)
2023-08-12 23:54:25 | INFO | train_inner | epoch 003:   1159 / 1474 loss=3.248, trans_loss=3.973, nll_loss=2.316, w2v_ctc_loss=1.789, task_loss=0.994, contrastive_loss=0.655, total=4046.76, n_correct=1626.13, ppl=4.98, accuracy=40.184, wps=7381.7, ups=0.61, wpb=12078.6, bsz=433.9, num_updates=4100, lr=0.000164018, gnorm=1.398, clip=0, loss_scale=2, train_wall=91, gb_free=15.9, wall=3309
2023-08-12 23:55:57 | INFO | train_inner | epoch 003:   1259 / 1474 loss=3.157, trans_loss=3.931, nll_loss=2.264, w2v_ctc_loss=1.752, task_loss=0.981, contrastive_loss=0.595, total=4064.26, n_correct=1695.37, ppl=4.8, accuracy=41.714, wps=13229.5, ups=1.09, wpb=12137.6, bsz=434, num_updates=4200, lr=0.000168016, gnorm=1.28, clip=0, loss_scale=2, train_wall=91, gb_free=16.4, wall=3401
2023-08-12 23:57:30 | INFO | train_inner | epoch 003:   1359 / 1474 loss=3.12, trans_loss=3.899, nll_loss=2.22, w2v_ctc_loss=1.713, task_loss=0.929, contrastive_loss=0.683, total=4137.36, n_correct=1782.74, ppl=4.66, accuracy=43.089, wps=13312, ups=1.08, wpb=12352.2, bsz=461.5, num_updates=4300, lr=0.000172014, gnorm=1.301, clip=0, loss_scale=2, train_wall=92, gb_free=15.9, wall=3494
2023-08-12 23:59:03 | INFO | train_inner | epoch 003:   1459 / 1474 loss=3.061, trans_loss=3.873, nll_loss=2.189, w2v_ctc_loss=1.69, task_loss=0.883, contrastive_loss=0.641, total=4207.75, n_correct=1859.72, ppl=4.56, accuracy=44.197, wps=13456.2, ups=1.07, wpb=12567.9, bsz=476.7, num_updates=4400, lr=0.000176012, gnorm=1.238, clip=0, loss_scale=2, train_wall=93, gb_free=17.1, wall=3587
2023-08-12 23:59:17 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-12 23:59:44 | INFO | dev_st | epoch 003 | valid on 'dev_st' subset | loss 5.066 | trans_loss 6.278 | nll_loss 3.837 | w2v_ctc_loss 1.991 | task_loss 4.202 | contrastive_loss 0.748 | total 4003.4 | n_correct 2003.9 | ppl 14.29 | accuracy 50.055 | uer 30.045 | wer 30.379 | raw_wer 30.379 | bleu 9.54 | wps 1706.1 | wpb 4003.4 | bsz 141.8 | num_updates 4415 | best_bleu 9.54
2023-08-12 23:59:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 4415 updates
2023-08-12 23:59:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-12 23:59:59 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 00:00:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 3 @ 4415 updates, score 9.54) (writing took 28.252112990245223 seconds)
2023-08-13 00:00:13 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-08-13 00:00:13 | INFO | train | epoch 003 | loss 3.883 | trans_loss 4.244 | nll_loss 2.67 | w2v_ctc_loss 2.026 | task_loss 0.944 | contrastive_loss 1.077 | total 4138.83 | n_correct 1342.36 | ppl 6.36 | accuracy 32.433 | wps 12254.7 | ups 0.99 | wpb 12356.3 | bsz 458.5 | num_updates 4415 | lr 0.000176612 | gnorm 1.743 | clip 0.1 | loss_scale 2 | train_wall 1342 | gb_free 16.2 | wall 3657
2023-08-13 00:00:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 00:00:13 | INFO | fairseq.trainer | begin training epoch 4
2023-08-13 00:00:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 00:01:38 | INFO | train_inner | epoch 004:     85 / 1474 loss=2.937, trans_loss=3.841, nll_loss=2.144, w2v_ctc_loss=1.644, task_loss=0.966, contrastive_loss=0.462, total=4095.18, n_correct=1862.54, ppl=4.42, accuracy=45.481, wps=7870.9, ups=0.64, wpb=12222.9, bsz=437.8, num_updates=4500, lr=0.00018001, gnorm=1.17, clip=0, loss_scale=2, train_wall=91, gb_free=12.2, wall=3742
2023-08-13 00:03:10 | INFO | train_inner | epoch 004:    185 / 1474 loss=2.906, trans_loss=3.812, nll_loss=2.108, w2v_ctc_loss=1.625, task_loss=0.88, contrastive_loss=0.479, total=4178.83, n_correct=1945.25, ppl=4.31, accuracy=46.55, wps=13656.5, ups=1.09, wpb=12476.1, bsz=469.5, num_updates=4600, lr=0.000184008, gnorm=1.167, clip=0, loss_scale=2, train_wall=91, gb_free=14.4, wall=3834
2023-08-13 00:04:42 | INFO | train_inner | epoch 004:    285 / 1474 loss=2.899, trans_loss=3.8, nll_loss=2.095, w2v_ctc_loss=1.617, task_loss=0.937, contrastive_loss=0.585, total=4142.3, n_correct=1948.98, ppl=4.27, accuracy=47.051, wps=13398.7, ups=1.08, wpb=12373.8, bsz=460.7, num_updates=4700, lr=0.000188006, gnorm=1.143, clip=0, loss_scale=2, train_wall=92, gb_free=12.9, wall=3926
2023-08-13 00:06:14 | INFO | train_inner | epoch 004:    385 / 1474 loss=2.831, trans_loss=3.789, nll_loss=2.076, w2v_ctc_loss=1.595, task_loss=0.963, contrastive_loss=0.416, total=4124.92, n_correct=1966.06, ppl=4.22, accuracy=47.663, wps=13454.2, ups=1.09, wpb=12307.7, bsz=444.2, num_updates=4800, lr=0.000192004, gnorm=1.089, clip=0, loss_scale=2, train_wall=91, gb_free=12, wall=4018
2023-08-13 00:07:47 | INFO | train_inner | epoch 004:    485 / 1474 loss=2.869, trans_loss=3.761, nll_loss=2.043, w2v_ctc_loss=1.558, task_loss=0.844, contrastive_loss=0.798, total=4216.09, n_correct=2053.77, ppl=4.12, accuracy=48.713, wps=13447.2, ups=1.07, wpb=12585.8, bsz=497.6, num_updates=4900, lr=0.000196002, gnorm=1.1, clip=0, loss_scale=2, train_wall=93, gb_free=16.6, wall=4111
2023-08-13 00:09:20 | INFO | train_inner | epoch 004:    585 / 1474 loss=2.795, trans_loss=3.748, nll_loss=2.026, w2v_ctc_loss=1.572, task_loss=0.864, contrastive_loss=0.479, total=4231.12, n_correct=2087.19, ppl=4.07, accuracy=49.329, wps=13614.8, ups=1.08, wpb=12629.4, bsz=490.1, num_updates=5000, lr=0.0002, gnorm=1.085, clip=0, loss_scale=2, train_wall=92, gb_free=15.8, wall=4204
mt_weight tensor(0.5000)
asr_weight tensor(0.4717, device='cuda:0')
2023-08-13 00:10:54 | INFO | train_inner | epoch 004:    685 / 1474 loss=2.751, trans_loss=3.742, nll_loss=2.014, w2v_ctc_loss=1.54, task_loss=0.961, contrastive_loss=0.502, total=4176.95, n_correct=2081.49, ppl=4.04, accuracy=49.833, wps=13257.9, ups=1.06, wpb=12451, bsz=455.2, num_updates=5100, lr=0.00019803, gnorm=0.704, clip=0, loss_scale=4, train_wall=93, gb_free=14.7, wall=4298
2023-08-13 00:12:26 | INFO | train_inner | epoch 004:    785 / 1474 loss=2.715, trans_loss=3.723, nll_loss=1.995, w2v_ctc_loss=1.553, task_loss=1.028, contrastive_loss=0.367, total=4016.91, n_correct=2020.64, ppl=3.99, accuracy=50.303, wps=13052, ups=1.09, wpb=11995.1, bsz=418.7, num_updates=5200, lr=0.000196116, gnorm=0.702, clip=0, loss_scale=4, train_wall=91, gb_free=15.8, wall=4390
2023-08-13 00:13:59 | INFO | train_inner | epoch 004:    885 / 1474 loss=2.742, trans_loss=3.706, nll_loss=1.974, w2v_ctc_loss=1.54, task_loss=0.932, contrastive_loss=0.542, total=4183.4, n_correct=2126.6, ppl=3.93, accuracy=50.834, wps=13351.9, ups=1.07, wpb=12493.2, bsz=465.4, num_updates=5300, lr=0.000194257, gnorm=0.692, clip=0, loss_scale=4, train_wall=93, gb_free=15.2, wall=4483
2023-08-13 00:15:33 | INFO | train_inner | epoch 004:    985 / 1474 loss=2.703, trans_loss=3.696, nll_loss=1.961, w2v_ctc_loss=1.536, task_loss=0.947, contrastive_loss=0.418, total=4128.78, n_correct=2122.91, ppl=3.89, accuracy=51.417, wps=13159.8, ups=1.07, wpb=12332, bsz=456.8, num_updates=5400, lr=0.00019245, gnorm=0.796, clip=0, loss_scale=4, train_wall=93, gb_free=15.6, wall=4577
2023-08-13 00:16:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-08-13 00:17:07 | INFO | train_inner | epoch 004:   1086 / 1474 loss=2.722, trans_loss=3.705, nll_loss=1.971, w2v_ctc_loss=1.564, task_loss=0.988, contrastive_loss=0.4, total=4086.67, n_correct=2089.69, ppl=3.92, accuracy=51.134, wps=13062.2, ups=1.07, wpb=12198.4, bsz=441.5, num_updates=5500, lr=0.000190693, gnorm=1.079, clip=1, loss_scale=2, train_wall=93, gb_free=16.4, wall=4670
2023-08-13 00:18:39 | INFO | train_inner | epoch 004:   1186 / 1474 loss=2.705, trans_loss=3.687, nll_loss=1.951, w2v_ctc_loss=1.537, task_loss=0.875, contrastive_loss=0.489, total=4162.44, n_correct=2159.24, ppl=3.87, accuracy=51.874, wps=13489.7, ups=1.08, wpb=12433, bsz=482.7, num_updates=5600, lr=0.000188982, gnorm=0.674, clip=0, loss_scale=2, train_wall=92, gb_free=16.7, wall=4763
2023-08-13 00:20:12 | INFO | train_inner | epoch 004:   1286 / 1474 loss=2.646, trans_loss=3.664, nll_loss=1.921, w2v_ctc_loss=1.497, task_loss=0.893, contrastive_loss=0.443, total=4144.75, n_correct=2182.47, ppl=3.79, accuracy=52.656, wps=13239.1, ups=1.07, wpb=12378.7, bsz=470, num_updates=5700, lr=0.000187317, gnorm=0.661, clip=0, loss_scale=2, train_wall=93, gb_free=16.3, wall=4856
2023-08-13 00:21:44 | INFO | train_inner | epoch 004:   1386 / 1474 loss=2.601, trans_loss=3.655, nll_loss=1.909, w2v_ctc_loss=1.495, task_loss=0.955, contrastive_loss=0.316, total=4107.86, n_correct=2180.27, ppl=3.75, accuracy=53.076, wps=13419.6, ups=1.09, wpb=12268.5, bsz=439.2, num_updates=5800, lr=0.000185695, gnorm=0.627, clip=0, loss_scale=2, train_wall=91, gb_free=16.9, wall=4948
2023-08-13 00:23:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.4717, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.4717, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.4717, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.4717, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.4717, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.4717, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.4717, device='cuda:7')
2023-08-13 00:23:29 | INFO | dev_st | epoch 004 | valid on 'dev_st' subset | loss 4.463 | trans_loss 5.659 | nll_loss 3.046 | w2v_ctc_loss 1.664 | task_loss 4.448 | contrastive_loss 0.488 | total 4003.4 | n_correct 2352.6 | ppl 8.26 | accuracy 58.765 | uer 24.737 | wer 26.233 | raw_wer 26.233 | bleu 16.03 | wps 2006.9 | wpb 4003.4 | bsz 141.8 | num_updates 5888 | best_bleu 16.03
2023-08-13 00:23:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 5888 updates
2023-08-13 00:23:29 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 00:23:44 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 00:23:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 4 @ 5888 updates, score 16.03) (writing took 29.07888289168477 seconds)
2023-08-13 00:23:58 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-08-13 00:23:58 | INFO | train | epoch 004 | loss 2.76 | trans_loss 3.732 | nll_loss 2.005 | w2v_ctc_loss 1.556 | task_loss 0.931 | contrastive_loss 0.474 | total 4138.97 | n_correct 2067.84 | ppl 4.02 | accuracy 49.96 | wps 12772.5 | ups 1.03 | wpb 12356.8 | bsz 458.6 | num_updates 5888 | lr 0.000184302 | gnorm 0.887 | clip 0.1 | loss_scale 2 | train_wall 1357 | gb_free 14.5 | wall 5082
2023-08-13 00:23:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 00:23:59 | INFO | fairseq.trainer | begin training epoch 5
2023-08-13 00:23:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 00:24:17 | INFO | train_inner | epoch 005:     12 / 1474 loss=2.577, trans_loss=3.648, nll_loss=1.898, w2v_ctc_loss=1.465, task_loss=0.974, contrastive_loss=0.328, total=4036.09, n_correct=2154.26, ppl=3.73, accuracy=53.375, wps=7855.3, ups=0.65, wpb=12049.9, bsz=436.9, num_updates=5900, lr=0.000184115, gnorm=0.633, clip=0, loss_scale=2, train_wall=91, gb_free=11.3, wall=5101
2023-08-13 00:25:49 | INFO | train_inner | epoch 005:    112 / 1474 loss=2.509, trans_loss=3.607, nll_loss=1.846, w2v_ctc_loss=1.389, task_loss=0.833, contrastive_loss=0.348, total=4256.69, n_correct=2334.66, ppl=3.6, accuracy=54.847, wps=13779.3, ups=1.08, wpb=12710.6, bsz=500.9, num_updates=6000, lr=0.000182574, gnorm=0.598, clip=0, loss_scale=2, train_wall=92, gb_free=17.1, wall=5193
2023-08-13 00:25:49 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 00:26:14 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.439 | trans_loss 5.639 | nll_loss 3.02 | w2v_ctc_loss 1.638 | task_loss 4.48 | contrastive_loss 0.482 | total 4003.4 | n_correct 2365.8 | ppl 8.11 | accuracy 59.095 | uer 24.644 | wer 26.08 | raw_wer 26.08 | bleu 16.34 | wps 2038.3 | wpb 4003.4 | bsz 141.8 | num_updates 6000 | best_bleu 16.34
2023-08-13 00:26:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 6000 updates
2023-08-13 00:26:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-13 00:26:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_5_6000.pt
2023-08-13 00:27:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_5_6000.pt (epoch 5 @ 6000 updates, score 16.34) (writing took 50.36201134137809 seconds)
2023-08-13 00:28:36 | INFO | train_inner | epoch 005:    212 / 1474 loss=2.553, trans_loss=3.614, nll_loss=1.854, w2v_ctc_loss=1.41, task_loss=0.868, contrastive_loss=0.539, total=4186.1, n_correct=2289.4, ppl=3.61, accuracy=54.691, wps=7498.1, ups=0.6, wpb=12490.5, bsz=484.8, num_updates=6100, lr=0.000181071, gnorm=0.629, clip=0, loss_scale=2, train_wall=91, gb_free=14.4, wall=5360
2023-08-13 00:30:07 | INFO | train_inner | epoch 005:    312 / 1474 loss=2.521, trans_loss=3.599, nll_loss=1.84, w2v_ctc_loss=1.418, task_loss=0.95, contrastive_loss=0.394, total=4098.24, n_correct=2243.28, ppl=3.58, accuracy=54.738, wps=13413.4, ups=1.09, wpb=12253.4, bsz=447.9, num_updates=6200, lr=0.000179605, gnorm=0.606, clip=0, loss_scale=2, train_wall=91, gb_free=16, wall=5451
2023-08-13 00:31:40 | INFO | train_inner | epoch 005:    412 / 1474 loss=2.513, trans_loss=3.589, nll_loss=1.826, w2v_ctc_loss=1.386, task_loss=0.92, contrastive_loss=0.468, total=4138.6, n_correct=2289.76, ppl=3.55, accuracy=55.327, wps=13322.6, ups=1.08, wpb=12367.6, bsz=466.6, num_updates=6300, lr=0.000178174, gnorm=0.607, clip=0, loss_scale=2, train_wall=92, gb_free=12.6, wall=5544
2023-08-13 00:33:12 | INFO | train_inner | epoch 005:    512 / 1474 loss=2.459, trans_loss=3.592, nll_loss=1.829, w2v_ctc_loss=1.391, task_loss=1.043, contrastive_loss=0.262, total=4018.65, n_correct=2221.04, ppl=3.55, accuracy=55.268, wps=13051.5, ups=1.09, wpb=12005.2, bsz=417.4, num_updates=6400, lr=0.000176777, gnorm=0.596, clip=0, loss_scale=2, train_wall=91, gb_free=16.4, wall=5636
2023-08-13 00:34:45 | INFO | train_inner | epoch 005:    612 / 1474 loss=2.486, trans_loss=3.595, nll_loss=1.829, w2v_ctc_loss=1.377, task_loss=0.961, contrastive_loss=0.432, total=4121.58, n_correct=2283.95, ppl=3.55, accuracy=55.414, wps=13241.3, ups=1.08, wpb=12295, bsz=451, num_updates=6500, lr=0.000175412, gnorm=0.601, clip=0, loss_scale=2, train_wall=92, gb_free=16.3, wall=5729
2023-08-13 00:36:17 | INFO | train_inner | epoch 005:    712 / 1474 loss=2.481, trans_loss=3.588, nll_loss=1.823, w2v_ctc_loss=1.373, task_loss=0.879, contrastive_loss=0.41, total=4169.57, n_correct=2324.43, ppl=3.54, accuracy=55.747, wps=13476.8, ups=1.08, wpb=12447.3, bsz=482.2, num_updates=6600, lr=0.000174078, gnorm=0.593, clip=0, loss_scale=2, train_wall=92, gb_free=16.8, wall=5821
2023-08-13 00:37:50 | INFO | train_inner | epoch 005:    812 / 1474 loss=2.451, trans_loss=3.577, nll_loss=1.808, w2v_ctc_loss=1.37, task_loss=0.961, contrastive_loss=0.334, total=4123.32, n_correct=2308.22, ppl=3.5, accuracy=55.98, wps=13246.8, ups=1.08, wpb=12307, bsz=448.5, num_updates=6700, lr=0.000172774, gnorm=0.584, clip=0, loss_scale=2, train_wall=92, gb_free=17.4, wall=5914
2023-08-13 00:39:23 | INFO | train_inner | epoch 005:    912 / 1474 loss=2.417, trans_loss=3.568, nll_loss=1.797, w2v_ctc_loss=1.353, task_loss=0.955, contrastive_loss=0.29, total=4109.54, n_correct=2317.48, ppl=3.47, accuracy=56.393, wps=13268.4, ups=1.08, wpb=12270.4, bsz=449.3, num_updates=6800, lr=0.000171499, gnorm=0.58, clip=0, loss_scale=2, train_wall=92, gb_free=16.1, wall=6007
2023-08-13 00:40:55 | INFO | train_inner | epoch 005:   1012 / 1474 loss=2.427, trans_loss=3.572, nll_loss=1.802, w2v_ctc_loss=1.355, task_loss=0.936, contrastive_loss=0.36, total=4157.73, n_correct=2343.7, ppl=3.49, accuracy=56.37, wps=13432.5, ups=1.08, wpb=12411.9, bsz=458.8, num_updates=6900, lr=0.000170251, gnorm=0.574, clip=0, loss_scale=2, train_wall=92, gb_free=17.1, wall=6099
2023-08-13 00:42:28 | INFO | train_inner | epoch 005:   1112 / 1474 loss=2.443, trans_loss=3.566, nll_loss=1.793, w2v_ctc_loss=1.362, task_loss=0.924, contrastive_loss=0.37, total=4172.61, n_correct=2361.13, ppl=3.46, accuracy=56.586, wps=13376.9, ups=1.07, wpb=12446.4, bsz=466.7, num_updates=7000, lr=0.000169031, gnorm=0.573, clip=0, loss_scale=2, train_wall=92, gb_free=13.3, wall=6192
2023-08-13 00:44:01 | INFO | train_inner | epoch 005:   1212 / 1474 loss=2.392, trans_loss=3.561, nll_loss=1.786, w2v_ctc_loss=1.335, task_loss=0.949, contrastive_loss=0.268, total=4166.97, n_correct=2367.6, ppl=3.45, accuracy=56.818, wps=13420.5, ups=1.08, wpb=12430.2, bsz=454.5, num_updates=7100, lr=0.000167836, gnorm=0.574, clip=0, loss_scale=2, train_wall=92, gb_free=16.7, wall=6285
2023-08-13 00:45:33 | INFO | train_inner | epoch 005:   1312 / 1474 loss=2.37, trans_loss=3.556, nll_loss=1.78, w2v_ctc_loss=1.325, task_loss=0.949, contrastive_loss=0.234, total=4132.22, n_correct=2353.82, ppl=3.44, accuracy=56.963, wps=13302.3, ups=1.08, wpb=12332.7, bsz=445.1, num_updates=7200, lr=0.000166667, gnorm=0.562, clip=0, loss_scale=2, train_wall=92, gb_free=16.3, wall=6377
2023-08-13 00:47:06 | INFO | train_inner | epoch 005:   1412 / 1474 loss=2.38, trans_loss=3.554, nll_loss=1.781, w2v_ctc_loss=1.32, task_loss=0.946, contrastive_loss=0.297, total=4135.72, n_correct=2360.16, ppl=3.44, accuracy=57.068, wps=13297.5, ups=1.08, wpb=12352.5, bsz=457.5, num_updates=7300, lr=0.000165521, gnorm=0.556, clip=0, loss_scale=2, train_wall=92, gb_free=16, wall=6470
2023-08-13 00:48:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 00:48:26 | INFO | dev_st | epoch 005 | valid on 'dev_st' subset | loss 4.278 | trans_loss 5.492 | nll_loss 2.844 | w2v_ctc_loss 1.485 | task_loss 4.489 | contrastive_loss 0.436 | total 4003.4 | n_correct 2456.1 | ppl 7.18 | accuracy 61.35 | uer 23.431 | wer 24.943 | raw_wer 24.943 | bleu 18.25 | wps 2229 | wpb 4003.4 | bsz 141.8 | num_updates 7362 | best_bleu 18.25
2023-08-13 00:48:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 7362 updates
2023-08-13 00:48:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 00:48:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 00:48:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 5 @ 7362 updates, score 18.25) (writing took 31.048818834125996 seconds)
2023-08-13 00:48:57 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-08-13 00:48:58 | INFO | train | epoch 005 | loss 2.455 | trans_loss 3.58 | nll_loss 1.812 | w2v_ctc_loss 1.368 | task_loss 0.933 | contrastive_loss 0.357 | total 4138.65 | n_correct 2314.08 | ppl 3.51 | accuracy 55.914 | wps 12147.3 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 7362 | lr 0.000164823 | gnorm 0.587 | clip 0 | loss_scale 2 | train_wall 1355 | gb_free 15.9 | wall 6581
2023-08-13 00:48:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 00:48:58 | INFO | fairseq.trainer | begin training epoch 6
2023-08-13 00:48:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 00:49:41 | INFO | train_inner | epoch 006:     38 / 1474 loss=2.365, trans_loss=3.537, nll_loss=1.757, w2v_ctc_loss=1.315, task_loss=0.963, contrastive_loss=0.289, total=4115.39, n_correct=2368.37, ppl=3.38, accuracy=57.549, wps=7939.4, ups=0.65, wpb=12279.5, bsz=446.7, num_updates=7400, lr=0.000164399, gnorm=0.562, clip=0, loss_scale=2, train_wall=92, gb_free=16.6, wall=6625
2023-08-13 00:51:13 | INFO | train_inner | epoch 006:    138 / 1474 loss=2.317, trans_loss=3.509, nll_loss=1.722, w2v_ctc_loss=1.259, task_loss=0.926, contrastive_loss=0.329, total=4157.06, n_correct=2420.77, ppl=3.3, accuracy=58.233, wps=13567.3, ups=1.09, wpb=12417.1, bsz=457.8, num_updates=7500, lr=0.000163299, gnorm=0.548, clip=0, loss_scale=4, train_wall=91, gb_free=17.5, wall=6717
2023-08-13 00:52:45 | INFO | train_inner | epoch 006:    238 / 1474 loss=2.322, trans_loss=3.52, nll_loss=1.738, w2v_ctc_loss=1.294, task_loss=0.992, contrastive_loss=0.238, total=4115.6, n_correct=2384.44, ppl=3.34, accuracy=57.937, wps=13293.4, ups=1.08, wpb=12295.8, bsz=440.7, num_updates=7600, lr=0.000162221, gnorm=0.547, clip=0, loss_scale=4, train_wall=92, gb_free=16.6, wall=6809
2023-08-13 00:54:20 | INFO | train_inner | epoch 006:    338 / 1474 loss=2.35, trans_loss=3.508, nll_loss=1.721, w2v_ctc_loss=1.239, task_loss=0.885, contrastive_loss=0.537, total=4163.86, n_correct=2432.84, ppl=3.3, accuracy=58.428, wps=13107.6, ups=1.05, wpb=12432.8, bsz=484.8, num_updates=7700, lr=0.000161165, gnorm=0.559, clip=0, loss_scale=4, train_wall=94, gb_free=15.8, wall=6904
2023-08-13 00:55:52 | INFO | train_inner | epoch 006:    438 / 1474 loss=2.286, trans_loss=3.504, nll_loss=1.716, w2v_ctc_loss=1.251, task_loss=0.893, contrastive_loss=0.247, total=4156.74, n_correct=2443.59, ppl=3.29, accuracy=58.786, wps=13500.8, ups=1.09, wpb=12410.9, bsz=471.8, num_updates=7800, lr=0.000160128, gnorm=0.544, clip=0, loss_scale=4, train_wall=91, gb_free=15.2, wall=6996
2023-08-13 00:57:24 | INFO | train_inner | epoch 006:    538 / 1474 loss=2.289, trans_loss=3.508, nll_loss=1.72, w2v_ctc_loss=1.263, task_loss=0.939, contrastive_loss=0.236, total=4173.1, n_correct=2449.39, ppl=3.3, accuracy=58.695, wps=13521.4, ups=1.09, wpb=12456.1, bsz=456.3, num_updates=7900, lr=0.000159111, gnorm=0.537, clip=0, loss_scale=4, train_wall=92, gb_free=15.6, wall=7088
2023-08-13 00:58:56 | INFO | train_inner | epoch 006:    638 / 1474 loss=2.287, trans_loss=3.506, nll_loss=1.718, w2v_ctc_loss=1.244, task_loss=0.886, contrastive_loss=0.285, total=4147.23, n_correct=2433.23, ppl=3.29, accuracy=58.671, wps=13417.7, ups=1.08, wpb=12379.1, bsz=471.9, num_updates=8000, lr=0.000158114, gnorm=0.547, clip=0, loss_scale=4, train_wall=92, gb_free=12.2, wall=7180
2023-08-13 00:58:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 00:59:19 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.205 | trans_loss 5.418 | nll_loss 2.75 | w2v_ctc_loss 1.46 | task_loss 4.561 | contrastive_loss 0.391 | total 4003.4 | n_correct 2493.8 | ppl 6.73 | accuracy 62.292 | uer 21.896 | wer 23.59 | raw_wer 23.59 | bleu 18.42 | wps 2343 | wpb 4003.4 | bsz 141.8 | num_updates 8000 | best_bleu 18.42
2023-08-13 00:59:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8000 updates
2023-08-13 00:59:19 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-13 00:59:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_6_8000.pt
2023-08-13 01:00:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_6_8000.pt (epoch 6 @ 8000 updates, score 18.42) (writing took 50.554253701120615 seconds)
2023-08-13 01:01:43 | INFO | train_inner | epoch 006:    738 / 1474 loss=2.286, trans_loss=3.507, nll_loss=1.72, w2v_ctc_loss=1.262, task_loss=0.956, contrastive_loss=0.24, total=4147.61, n_correct=2437.15, ppl=3.29, accuracy=58.76, wps=7434, ups=0.6, wpb=12383.5, bsz=453.2, num_updates=8100, lr=0.000157135, gnorm=0.54, clip=0, loss_scale=4, train_wall=93, gb_free=16, wall=7347
2023-08-13 01:03:15 | INFO | train_inner | epoch 006:    838 / 1474 loss=2.273, trans_loss=3.508, nll_loss=1.721, w2v_ctc_loss=1.253, task_loss=0.978, contrastive_loss=0.219, total=4114.7, n_correct=2414.75, ppl=3.3, accuracy=58.686, wps=13304.9, ups=1.08, wpb=12284.9, bsz=442.6, num_updates=8200, lr=0.000156174, gnorm=0.54, clip=0, loss_scale=4, train_wall=92, gb_free=17.6, wall=7439
2023-08-13 01:04:47 | INFO | train_inner | epoch 006:    938 / 1474 loss=2.301, trans_loss=3.512, nll_loss=1.726, w2v_ctc_loss=1.259, task_loss=0.989, contrastive_loss=0.316, total=4082.44, n_correct=2390.61, ppl=3.31, accuracy=58.558, wps=13262.9, ups=1.09, wpb=12184.1, bsz=442.4, num_updates=8300, lr=0.00015523, gnorm=0.545, clip=0, loss_scale=4, train_wall=91, gb_free=15.9, wall=7531
2023-08-13 01:06:19 | INFO | train_inner | epoch 006:   1038 / 1474 loss=2.292, trans_loss=3.496, nll_loss=1.705, w2v_ctc_loss=1.234, task_loss=0.88, contrastive_loss=0.386, total=4168.55, n_correct=2466.1, ppl=3.26, accuracy=59.16, wps=13490.9, ups=1.08, wpb=12442.3, bsz=478.7, num_updates=8400, lr=0.000154303, gnorm=0.554, clip=0, loss_scale=4, train_wall=92, gb_free=15.4, wall=7623
2023-08-13 01:07:51 | INFO | train_inner | epoch 006:   1138 / 1474 loss=2.261, trans_loss=3.496, nll_loss=1.706, w2v_ctc_loss=1.245, task_loss=1.028, contrastive_loss=0.221, total=4075.88, n_correct=2403.39, ppl=3.26, accuracy=58.966, wps=13248.8, ups=1.09, wpb=12168.6, bsz=430.6, num_updates=8500, lr=0.000153393, gnorm=0.542, clip=0, loss_scale=4, train_wall=91, gb_free=13.8, wall=7715
2023-08-13 01:09:24 | INFO | train_inner | epoch 006:   1238 / 1474 loss=2.313, trans_loss=3.487, nll_loss=1.696, w2v_ctc_loss=1.228, task_loss=0.917, contrastive_loss=0.534, total=4136.41, n_correct=2452.18, ppl=3.24, accuracy=59.283, wps=13237.7, ups=1.07, wpb=12356.2, bsz=470.5, num_updates=8600, lr=0.000152499, gnorm=0.535, clip=0, loss_scale=4, train_wall=93, gb_free=15, wall=7808
2023-08-13 01:10:56 | INFO | train_inner | epoch 006:   1338 / 1474 loss=2.236, trans_loss=3.492, nll_loss=1.699, w2v_ctc_loss=1.227, task_loss=0.929, contrastive_loss=0.201, total=4123.87, n_correct=2453.96, ppl=3.25, accuracy=59.506, wps=13494, ups=1.1, wpb=12299.9, bsz=453.6, num_updates=8700, lr=0.00015162, gnorm=0.529, clip=0, loss_scale=4, train_wall=91, gb_free=16, wall=7900
2023-08-13 01:12:29 | INFO | train_inner | epoch 006:   1438 / 1474 loss=2.236, trans_loss=3.486, nll_loss=1.694, w2v_ctc_loss=1.225, task_loss=0.932, contrastive_loss=0.208, total=4197.44, n_correct=2497.99, ppl=3.23, accuracy=59.512, wps=13419.8, ups=1.07, wpb=12530.9, bsz=462.9, num_updates=8800, lr=0.000150756, gnorm=0.527, clip=0, loss_scale=4, train_wall=93, gb_free=16.1, wall=7993
2023-08-13 01:13:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 01:13:26 | INFO | dev_st | epoch 006 | valid on 'dev_st' subset | loss 4.15 | trans_loss 5.362 | nll_loss 2.681 | w2v_ctc_loss 1.419 | task_loss 4.592 | contrastive_loss 0.382 | total 4003.4 | n_correct 2520.7 | ppl 6.41 | accuracy 62.964 | uer 21.023 | wer 22.851 | raw_wer 22.851 | bleu 19.39 | wps 2122.8 | wpb 4003.4 | bsz 141.8 | num_updates 8836 | best_bleu 19.39
2023-08-13 01:13:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 8836 updates
2023-08-13 01:13:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 01:13:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 01:13:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 6 @ 8836 updates, score 19.39) (writing took 28.650203993543983 seconds)
2023-08-13 01:13:54 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-08-13 01:13:54 | INFO | train | epoch 006 | loss 2.288 | trans_loss 3.503 | nll_loss 1.714 | w2v_ctc_loss 1.249 | task_loss 0.936 | contrastive_loss 0.298 | total 4138.65 | n_correct 2433.83 | ppl 3.28 | accuracy 58.807 | wps 12170.3 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 8836 | lr 0.000150448 | gnorm 0.542 | clip 0 | loss_scale 4 | train_wall 1355 | gb_free 14.8 | wall 8078
2023-08-13 01:13:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 01:13:55 | INFO | fairseq.trainer | begin training epoch 7
2023-08-13 01:13:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 01:15:01 | INFO | train_inner | epoch 007:     64 / 1474 loss=2.205, trans_loss=3.472, nll_loss=1.676, w2v_ctc_loss=1.195, task_loss=0.92, contrastive_loss=0.22, total=4105.94, n_correct=2462.58, ppl=3.19, accuracy=59.976, wps=8056.9, ups=0.66, wpb=12258, bsz=460.8, num_updates=8900, lr=0.000149906, gnorm=0.527, clip=0, loss_scale=4, train_wall=92, gb_free=14.7, wall=8145
2023-08-13 01:16:33 | INFO | train_inner | epoch 007:    164 / 1474 loss=2.207, trans_loss=3.464, nll_loss=1.665, w2v_ctc_loss=1.182, task_loss=0.954, contrastive_loss=0.293, total=4101.13, n_correct=2465.51, ppl=3.17, accuracy=60.118, wps=13315.6, ups=1.09, wpb=12245.3, bsz=452.9, num_updates=9000, lr=0.000149071, gnorm=0.528, clip=0, loss_scale=4, train_wall=91, gb_free=16.6, wall=8237
2023-08-13 01:18:05 | INFO | train_inner | epoch 007:    264 / 1474 loss=2.184, trans_loss=3.458, nll_loss=1.656, w2v_ctc_loss=1.182, task_loss=0.93, contrastive_loss=0.2, total=4143.65, n_correct=2503.74, ppl=3.15, accuracy=60.424, wps=13468.4, ups=1.09, wpb=12365.3, bsz=458, num_updates=9100, lr=0.00014825, gnorm=0.523, clip=0, loss_scale=4, train_wall=91, gb_free=15.9, wall=8329
2023-08-13 01:19:38 | INFO | train_inner | epoch 007:    364 / 1474 loss=2.234, trans_loss=3.463, nll_loss=1.662, w2v_ctc_loss=1.175, task_loss=0.907, contrastive_loss=0.458, total=4190.59, n_correct=2523.35, ppl=3.17, accuracy=60.215, wps=13454.8, ups=1.08, wpb=12506.9, bsz=477.2, num_updates=9200, lr=0.000147442, gnorm=0.543, clip=0, loss_scale=4, train_wall=92, gb_free=16.4, wall=8422
2023-08-13 01:21:10 | INFO | train_inner | epoch 007:    464 / 1474 loss=2.215, trans_loss=3.462, nll_loss=1.663, w2v_ctc_loss=1.172, task_loss=0.929, contrastive_loss=0.378, total=4154.13, n_correct=2501.84, ppl=3.17, accuracy=60.225, wps=13435.3, ups=1.08, wpb=12405.4, bsz=461.6, num_updates=9300, lr=0.000146647, gnorm=0.53, clip=0, loss_scale=4, train_wall=92, gb_free=16.1, wall=8514
2023-08-13 01:22:42 | INFO | train_inner | epoch 007:    564 / 1474 loss=2.177, trans_loss=3.458, nll_loss=1.656, w2v_ctc_loss=1.174, task_loss=0.912, contrastive_loss=0.202, total=4171.52, n_correct=2525.5, ppl=3.15, accuracy=60.541, wps=13581.1, ups=1.09, wpb=12446, bsz=461, num_updates=9400, lr=0.000145865, gnorm=0.517, clip=0, loss_scale=4, train_wall=91, gb_free=16.7, wall=8606
2023-08-13 01:24:14 | INFO | train_inner | epoch 007:    664 / 1474 loss=2.166, trans_loss=3.455, nll_loss=1.652, w2v_ctc_loss=1.167, task_loss=0.933, contrastive_loss=0.189, total=4151.13, n_correct=2521.42, ppl=3.14, accuracy=60.741, wps=13408.7, ups=1.08, wpb=12385.9, bsz=454, num_updates=9500, lr=0.000145095, gnorm=0.527, clip=0, loss_scale=4, train_wall=92, gb_free=12.3, wall=8698
2023-08-13 01:25:47 | INFO | train_inner | epoch 007:    764 / 1474 loss=2.162, trans_loss=3.448, nll_loss=1.644, w2v_ctc_loss=1.168, task_loss=0.977, contrastive_loss=0.183, total=4124.23, n_correct=2503.61, ppl=3.13, accuracy=60.705, wps=13226.5, ups=1.07, wpb=12314.5, bsz=446.8, num_updates=9600, lr=0.000144338, gnorm=0.519, clip=0, loss_scale=8, train_wall=93, gb_free=13.8, wall=8791
2023-08-13 01:27:20 | INFO | train_inner | epoch 007:    864 / 1474 loss=2.169, trans_loss=3.457, nll_loss=1.656, w2v_ctc_loss=1.168, task_loss=0.938, contrastive_loss=0.204, total=4148.43, n_correct=2513.4, ppl=3.15, accuracy=60.587, wps=13322.7, ups=1.08, wpb=12380.2, bsz=461.8, num_updates=9700, lr=0.000143592, gnorm=0.525, clip=0, loss_scale=8, train_wall=92, gb_free=16.1, wall=8884
2023-08-13 01:28:53 | INFO | train_inner | epoch 007:    964 / 1474 loss=2.178, trans_loss=3.448, nll_loss=1.646, w2v_ctc_loss=1.155, task_loss=0.898, contrastive_loss=0.296, total=4141.1, n_correct=2516.57, ppl=3.13, accuracy=60.771, wps=13399.7, ups=1.08, wpb=12362.4, bsz=473.7, num_updates=9800, lr=0.000142857, gnorm=0.519, clip=0, loss_scale=8, train_wall=92, gb_free=13.4, wall=8977
2023-08-13 01:30:25 | INFO | train_inner | epoch 007:   1064 / 1474 loss=2.16, trans_loss=3.458, nll_loss=1.658, w2v_ctc_loss=1.171, task_loss=0.977, contrastive_loss=0.169, total=4100.93, n_correct=2482.54, ppl=3.16, accuracy=60.536, wps=13288.7, ups=1.09, wpb=12243.4, bsz=437.6, num_updates=9900, lr=0.000142134, gnorm=0.515, clip=0, loss_scale=8, train_wall=92, gb_free=14.5, wall=9069
2023-08-13 01:31:57 | INFO | train_inner | epoch 007:   1164 / 1474 loss=2.211, trans_loss=3.444, nll_loss=1.642, w2v_ctc_loss=1.157, task_loss=0.909, contrastive_loss=0.429, total=4139.88, n_correct=2517.48, ppl=3.12, accuracy=60.81, wps=13372.6, ups=1.08, wpb=12369.6, bsz=471.4, num_updates=10000, lr=0.000141421, gnorm=0.525, clip=0, loss_scale=8, train_wall=92, gb_free=16.3, wall=9161
2023-08-13 01:31:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 01:32:20 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.083 | trans_loss 5.31 | nll_loss 2.616 | w2v_ctc_loss 1.339 | task_loss 4.618 | contrastive_loss 0.357 | total 4003.4 | n_correct 2560.7 | ppl 6.13 | accuracy 63.963 | uer 19.669 | wer 21.465 | raw_wer 21.465 | bleu 20.02 | wps 2212.7 | wpb 4003.4 | bsz 141.8 | num_updates 10000 | best_bleu 20.02
2023-08-13 01:32:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10000 updates
2023-08-13 01:32:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-13 01:32:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_7_10000.pt
2023-08-13 01:33:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_7_10000.pt (epoch 7 @ 10000 updates, score 20.02) (writing took 48.133526131510735 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:0')
2023-08-13 01:34:40 | INFO | train_inner | epoch 007:   1264 / 1474 loss=2.15, trans_loss=3.447, nll_loss=1.644, w2v_ctc_loss=1.155, task_loss=0.953, contrastive_loss=0.197, total=4129.16, n_correct=2509.87, ppl=3.13, accuracy=60.784, wps=7572.1, ups=0.61, wpb=12331, bsz=448.9, num_updates=10100, lr=0.00014072, gnorm=0.418, clip=0, loss_scale=8, train_wall=91, gb_free=16.5, wall=9324
2023-08-13 01:36:12 | INFO | train_inner | epoch 007:   1364 / 1474 loss=2.167, trans_loss=3.44, nll_loss=1.636, w2v_ctc_loss=1.163, task_loss=0.874, contrastive_loss=0.232, total=4177.71, n_correct=2551.91, ppl=3.11, accuracy=61.084, wps=13599.8, ups=1.09, wpb=12473.7, bsz=478.6, num_updates=10200, lr=0.000140028, gnorm=0.419, clip=0, loss_scale=8, train_wall=91, gb_free=16.5, wall=9416
2023-08-13 01:37:46 | INFO | train_inner | epoch 007:   1464 / 1474 loss=2.175, trans_loss=3.445, nll_loss=1.644, w2v_ctc_loss=1.161, task_loss=1.008, contrastive_loss=0.295, total=4107.01, n_correct=2498.05, ppl=3.12, accuracy=60.824, wps=12998.4, ups=1.06, wpb=12270.2, bsz=442.8, num_updates=10300, lr=0.000139347, gnorm=0.422, clip=0, loss_scale=8, train_wall=94, gb_free=12.9, wall=9510
2023-08-13 01:37:55 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:1')
2023-08-13 01:38:20 | INFO | dev_st | epoch 007 | valid on 'dev_st' subset | loss 4.081 | trans_loss 5.299 | nll_loss 2.602 | w2v_ctc_loss 1.359 | task_loss 4.596 | contrastive_loss 0.354 | total 4003.4 | n_correct 2568.5 | ppl 6.07 | accuracy 64.158 | uer 20.346 | wer 22.255 | raw_wer 22.255 | bleu 19.9 | wps 2064.4 | wpb 4003.4 | bsz 141.8 | num_updates 10310 | best_bleu 20.02
2023-08-13 01:38:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 10310 updates
2023-08-13 01:38:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_19.9005.pt
2023-08-13 01:38:24 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_19.9005.pt
2023-08-13 01:38:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_19.9005.pt (epoch 7 @ 10310 updates, score 19.9) (writing took 18.75494719669223 seconds)
2023-08-13 01:38:38 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-08-13 01:38:38 | INFO | train | epoch 007 | loss 2.183 | trans_loss 3.454 | nll_loss 1.652 | w2v_ctc_loss 1.169 | task_loss 0.936 | contrastive_loss 0.265 | total 4138.65 | n_correct 2507.25 | ppl 3.14 | accuracy 60.581 | wps 12273 | ups 0.99 | wpb 12355.8 | bsz 458.5 | num_updates 10310 | lr 0.000139279 | gnorm 0.503 | clip 0 | loss_scale 8 | train_wall 1355 | gb_free 12.8 | wall 9562
2023-08-13 01:38:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 01:38:39 | INFO | fairseq.trainer | begin training epoch 8
2023-08-13 01:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 01:40:10 | INFO | train_inner | epoch 008:     90 / 1474 loss=2.122, trans_loss=3.434, nll_loss=1.623, w2v_ctc_loss=1.13, task_loss=0.995, contrastive_loss=0.189, total=4106.01, n_correct=2522.55, ppl=3.08, accuracy=61.436, wps=8489.6, ups=0.69, wpb=12242.2, bsz=440.9, num_updates=10400, lr=0.000138675, gnorm=0.422, clip=0, loss_scale=8, train_wall=92, gb_free=16.8, wall=9654
2023-08-13 01:41:43 | INFO | train_inner | epoch 008:    190 / 1474 loss=2.116, trans_loss=3.422, nll_loss=1.608, w2v_ctc_loss=1.12, task_loss=1.012, contrastive_loss=0.209, total=4043.12, n_correct=2497.46, ppl=3.05, accuracy=61.771, wps=13087.8, ups=1.09, wpb=12058.4, bsz=430, num_updates=10500, lr=0.000138013, gnorm=0.426, clip=0, loss_scale=8, train_wall=92, gb_free=12.8, wall=9746
2023-08-13 01:43:14 | INFO | train_inner | epoch 008:    290 / 1474 loss=2.115, trans_loss=3.419, nll_loss=1.606, w2v_ctc_loss=1.121, task_loss=0.877, contrastive_loss=0.203, total=4207.9, n_correct=2601.15, ppl=3.05, accuracy=61.816, wps=13688.1, ups=1.09, wpb=12558.3, bsz=488.1, num_updates=10600, lr=0.000137361, gnorm=0.419, clip=0, loss_scale=8, train_wall=91, gb_free=13.7, wall=9838
2023-08-13 01:44:48 | INFO | train_inner | epoch 008:    390 / 1474 loss=2.131, trans_loss=3.423, nll_loss=1.611, w2v_ctc_loss=1.135, task_loss=0.985, contrastive_loss=0.229, total=4134.6, n_correct=2546.09, ppl=3.06, accuracy=61.58, wps=13214.8, ups=1.07, wpb=12337.2, bsz=444.7, num_updates=10700, lr=0.000136717, gnorm=0.423, clip=0, loss_scale=8, train_wall=93, gb_free=17.1, wall=9932
2023-08-13 01:46:21 | INFO | train_inner | epoch 008:    490 / 1474 loss=2.185, trans_loss=3.421, nll_loss=1.611, w2v_ctc_loss=1.116, task_loss=0.846, contrastive_loss=0.493, total=4196.6, n_correct=2588.08, ppl=3.05, accuracy=61.671, wps=13442.6, ups=1.07, wpb=12528.1, bsz=501.4, num_updates=10800, lr=0.000136083, gnorm=0.435, clip=0, loss_scale=8, train_wall=93, gb_free=12.5, wall=10025
2023-08-13 01:47:53 | INFO | train_inner | epoch 008:    590 / 1474 loss=2.116, trans_loss=3.419, nll_loss=1.611, w2v_ctc_loss=1.136, task_loss=1.019, contrastive_loss=0.162, total=4065.55, n_correct=2501.2, ppl=3.05, accuracy=61.522, wps=13144.1, ups=1.08, wpb=12153.4, bsz=428.3, num_updates=10900, lr=0.000135457, gnorm=0.422, clip=0, loss_scale=8, train_wall=92, gb_free=15.8, wall=10117
2023-08-13 01:49:26 | INFO | train_inner | epoch 008:    690 / 1474 loss=2.106, trans_loss=3.414, nll_loss=1.601, w2v_ctc_loss=1.127, task_loss=0.97, contrastive_loss=0.173, total=4135.41, n_correct=2560.56, ppl=3.03, accuracy=61.918, wps=13351.5, ups=1.08, wpb=12343.8, bsz=447.2, num_updates=11000, lr=0.00013484, gnorm=0.413, clip=0, loss_scale=8, train_wall=92, gb_free=15.7, wall=10210
2023-08-13 01:50:58 | INFO | train_inner | epoch 008:    790 / 1474 loss=2.117, trans_loss=3.409, nll_loss=1.599, w2v_ctc_loss=1.119, task_loss=0.948, contrastive_loss=0.257, total=4128.86, n_correct=2557.84, ppl=3.03, accuracy=61.95, wps=13409.2, ups=1.09, wpb=12339, bsz=452.1, num_updates=11100, lr=0.000134231, gnorm=0.416, clip=0, loss_scale=8, train_wall=92, gb_free=16, wall=10302
2023-08-13 01:52:30 | INFO | train_inner | epoch 008:    890 / 1474 loss=2.116, trans_loss=3.414, nll_loss=1.603, w2v_ctc_loss=1.109, task_loss=0.902, contrastive_loss=0.263, total=4166.92, n_correct=2581.85, ppl=3.04, accuracy=61.961, wps=13488.1, ups=1.08, wpb=12446.8, bsz=471.5, num_updates=11200, lr=0.000133631, gnorm=0.418, clip=0, loss_scale=8, train_wall=92, gb_free=14.2, wall=10394
2023-08-13 01:54:02 | INFO | train_inner | epoch 008:    990 / 1474 loss=2.09, trans_loss=3.413, nll_loss=1.601, w2v_ctc_loss=1.109, task_loss=0.901, contrastive_loss=0.166, total=4150.39, n_correct=2581.2, ppl=3.03, accuracy=62.192, wps=13542, ups=1.09, wpb=12390.2, bsz=462.8, num_updates=11300, lr=0.000133038, gnorm=0.413, clip=0, loss_scale=8, train_wall=91, gb_free=17, wall=10486
2023-08-13 01:55:34 | INFO | train_inner | epoch 008:   1090 / 1474 loss=2.137, trans_loss=3.415, nll_loss=1.603, w2v_ctc_loss=1.108, task_loss=0.928, contrastive_loss=0.394, total=4197.39, n_correct=2597.15, ppl=3.04, accuracy=61.875, wps=13497.9, ups=1.08, wpb=12529.5, bsz=466.4, num_updates=11400, lr=0.000132453, gnorm=0.416, clip=0, loss_scale=8, train_wall=92, gb_free=16.5, wall=10578
2023-08-13 01:57:07 | INFO | train_inner | epoch 008:   1190 / 1474 loss=2.096, trans_loss=3.409, nll_loss=1.597, w2v_ctc_loss=1.113, task_loss=0.886, contrastive_loss=0.176, total=4180.55, n_correct=2594.98, ppl=3.02, accuracy=62.073, wps=13456.8, ups=1.08, wpb=12487.2, bsz=472.7, num_updates=11500, lr=0.000131876, gnorm=0.411, clip=0, loss_scale=8, train_wall=92, gb_free=17, wall=10671
2023-08-13 01:58:40 | INFO | train_inner | epoch 008:   1290 / 1474 loss=2.106, trans_loss=3.413, nll_loss=1.602, w2v_ctc_loss=1.122, task_loss=0.979, contrastive_loss=0.199, total=4062.6, n_correct=2513.58, ppl=3.04, accuracy=61.871, wps=13078.4, ups=1.08, wpb=12135.3, bsz=437.8, num_updates=11600, lr=0.000131306, gnorm=0.415, clip=0, loss_scale=16, train_wall=92, gb_free=12.7, wall=10764
2023-08-13 02:00:13 | INFO | train_inner | epoch 008:   1390 / 1474 loss=2.115, trans_loss=3.414, nll_loss=1.603, w2v_ctc_loss=1.11, task_loss=0.909, contrastive_loss=0.262, total=4159.11, n_correct=2584.36, ppl=3.04, accuracy=62.137, wps=13348.3, ups=1.07, wpb=12419, bsz=468.7, num_updates=11700, lr=0.000130744, gnorm=0.41, clip=0, loss_scale=16, train_wall=93, gb_free=13, wall=10857
2023-08-13 02:01:31 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 02:01:56 | INFO | dev_st | epoch 008 | valid on 'dev_st' subset | loss 4.056 | trans_loss 5.255 | nll_loss 2.545 | w2v_ctc_loss 1.389 | task_loss 4.642 | contrastive_loss 0.339 | total 4003.4 | n_correct 2593.7 | ppl 5.84 | accuracy 64.787 | uer 19.598 | wer 21.524 | raw_wer 21.524 | bleu 20.62 | wps 2007.4 | wpb 4003.4 | bsz 141.8 | num_updates 11784 | best_bleu 20.62
2023-08-13 02:01:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 11784 updates
2023-08-13 02:01:56 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 02:02:11 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 02:02:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 8 @ 11784 updates, score 20.62) (writing took 29.453620115295053 seconds)
2023-08-13 02:02:26 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-08-13 02:02:26 | INFO | train | epoch 008 | loss 2.118 | trans_loss 3.417 | nll_loss 1.605 | w2v_ctc_loss 1.118 | task_loss 0.936 | contrastive_loss 0.247 | total 4138.65 | n_correct 2560.16 | ppl 3.04 | accuracy 61.86 | wps 12753.4 | ups 1.03 | wpb 12355.8 | bsz 458.5 | num_updates 11784 | lr 0.000130277 | gnorm 0.418 | clip 0 | loss_scale 16 | train_wall 1357 | gb_free 16.6 | wall 10990
2023-08-13 02:02:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 02:02:27 | INFO | fairseq.trainer | begin training epoch 9
2023-08-13 02:02:27 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 02:02:50 | INFO | train_inner | epoch 009:     16 / 1474 loss=2.114, trans_loss=3.409, nll_loss=1.594, w2v_ctc_loss=1.094, task_loss=0.916, contrastive_loss=0.363, total=4121.25, n_correct=2564.94, ppl=3.02, accuracy=62.237, wps=7858, ups=0.64, wpb=12298.5, bsz=466, num_updates=11800, lr=0.000130189, gnorm=0.416, clip=0, loss_scale=16, train_wall=93, gb_free=17.5, wall=11014
2023-08-13 02:04:23 | INFO | train_inner | epoch 009:    116 / 1474 loss=2.055, trans_loss=3.383, nll_loss=1.562, w2v_ctc_loss=1.07, task_loss=0.883, contrastive_loss=0.193, total=4191.82, n_correct=2642.33, ppl=2.95, accuracy=63.035, wps=13348.4, ups=1.07, wpb=12518.2, bsz=479.9, num_updates=11900, lr=0.000129641, gnorm=0.411, clip=0, loss_scale=16, train_wall=93, gb_free=15.6, wall=11107
2023-08-13 02:05:57 | INFO | train_inner | epoch 009:    216 / 1474 loss=2.045, trans_loss=3.387, nll_loss=1.567, w2v_ctc_loss=1.072, task_loss=1.009, contrastive_loss=0.15, total=4061.27, n_correct=2552.32, ppl=2.96, accuracy=62.845, wps=12915.4, ups=1.07, wpb=12126.5, bsz=431.4, num_updates=12000, lr=0.000129099, gnorm=0.407, clip=0, loss_scale=16, train_wall=93, gb_free=17.4, wall=11201
2023-08-13 02:05:57 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 02:06:22 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.041 | trans_loss 5.265 | nll_loss 2.554 | w2v_ctc_loss 1.316 | task_loss 4.618 | contrastive_loss 0.348 | total 4003.4 | n_correct 2583.1 | ppl 5.87 | accuracy 64.523 | uer 19.629 | wer 21.532 | raw_wer 21.532 | bleu 20.65 | wps 2073.5 | wpb 4003.4 | bsz 141.8 | num_updates 12000 | best_bleu 20.65
2023-08-13 02:06:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 12000 updates
2023-08-13 02:06:22 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-13 02:06:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_9_12000.pt
2023-08-13 02:06:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_9_12000.pt (epoch 9 @ 12000 updates, score 20.65) (writing took 29.66578613780439 seconds)
2023-08-13 02:08:25 | INFO | train_inner | epoch 009:    316 / 1474 loss=2.046, trans_loss=3.376, nll_loss=1.556, w2v_ctc_loss=1.058, task_loss=0.886, contrastive_loss=0.2, total=4146.43, n_correct=2617.62, ppl=2.94, accuracy=63.129, wps=8371.2, ups=0.68, wpb=12389.9, bsz=474.6, num_updates=12100, lr=0.000128565, gnorm=0.414, clip=0, loss_scale=16, train_wall=92, gb_free=16, wall=11349
2023-08-13 02:10:00 | INFO | train_inner | epoch 009:    416 / 1474 loss=2.049, trans_loss=3.392, nll_loss=1.573, w2v_ctc_loss=1.068, task_loss=0.92, contrastive_loss=0.167, total=4194.84, n_correct=2629.84, ppl=2.98, accuracy=62.692, wps=13252.8, ups=1.06, wpb=12524.6, bsz=466.7, num_updates=12200, lr=0.000128037, gnorm=0.405, clip=0, loss_scale=16, train_wall=94, gb_free=15.8, wall=11444
2023-08-13 02:11:33 | INFO | train_inner | epoch 009:    516 / 1474 loss=2.079, trans_loss=3.392, nll_loss=1.572, w2v_ctc_loss=1.092, task_loss=0.983, contrastive_loss=0.218, total=4124.3, n_correct=2584.19, ppl=2.97, accuracy=62.658, wps=13241.2, ups=1.08, wpb=12310.3, bsz=439.5, num_updates=12300, lr=0.000127515, gnorm=0.436, clip=0, loss_scale=16, train_wall=92, gb_free=11.2, wall=11537
2023-08-13 02:13:06 | INFO | train_inner | epoch 009:    616 / 1474 loss=2.043, trans_loss=3.383, nll_loss=1.566, w2v_ctc_loss=1.064, task_loss=0.959, contrastive_loss=0.176, total=4120.96, n_correct=2591.59, ppl=2.96, accuracy=62.888, wps=13183, ups=1.07, wpb=12316.4, bsz=453.4, num_updates=12400, lr=0.000127, gnorm=0.408, clip=0, loss_scale=16, train_wall=93, gb_free=15.9, wall=11630
2023-08-13 02:14:39 | INFO | train_inner | epoch 009:    716 / 1474 loss=2.08, trans_loss=3.391, nll_loss=1.575, w2v_ctc_loss=1.088, task_loss=0.951, contrastive_loss=0.259, total=4088.53, n_correct=2562.34, ppl=2.98, accuracy=62.671, wps=13171, ups=1.08, wpb=12213.7, bsz=451.4, num_updates=12500, lr=0.000126491, gnorm=0.415, clip=0, loss_scale=16, train_wall=92, gb_free=16.7, wall=11723
2023-08-13 02:16:13 | INFO | train_inner | epoch 009:    816 / 1474 loss=2.113, trans_loss=3.384, nll_loss=1.567, w2v_ctc_loss=1.076, task_loss=0.846, contrastive_loss=0.4, total=4220.43, n_correct=2652.73, ppl=2.96, accuracy=62.854, wps=13352.9, ups=1.06, wpb=12611.1, bsz=501.1, num_updates=12600, lr=0.000125988, gnorm=0.417, clip=0, loss_scale=16, train_wall=94, gb_free=14, wall=11817
2023-08-13 02:17:48 | INFO | train_inner | epoch 009:    916 / 1474 loss=2.091, trans_loss=3.39, nll_loss=1.569, w2v_ctc_loss=1.076, task_loss=0.965, contrastive_loss=0.385, total=4146.05, n_correct=2604.56, ppl=2.97, accuracy=62.82, wps=13003.2, ups=1.05, wpb=12371.5, bsz=450.3, num_updates=12700, lr=0.000125491, gnorm=0.412, clip=0, loss_scale=16, train_wall=95, gb_free=17.5, wall=11912
2023-08-13 02:19:22 | INFO | train_inner | epoch 009:   1016 / 1474 loss=2.056, trans_loss=3.394, nll_loss=1.576, w2v_ctc_loss=1.081, task_loss=1.045, contrastive_loss=0.165, total=4101.48, n_correct=2572.83, ppl=2.98, accuracy=62.729, wps=13076.7, ups=1.07, wpb=12241.7, bsz=424.4, num_updates=12800, lr=0.000125, gnorm=0.408, clip=0, loss_scale=16, train_wall=93, gb_free=15.6, wall=12006
2023-08-13 02:20:54 | INFO | train_inner | epoch 009:   1116 / 1474 loss=2.054, trans_loss=3.393, nll_loss=1.571, w2v_ctc_loss=1.072, task_loss=0.882, contrastive_loss=0.186, total=4179.09, n_correct=2628.77, ppl=2.97, accuracy=62.903, wps=13537.1, ups=1.09, wpb=12457.7, bsz=474.7, num_updates=12900, lr=0.000124515, gnorm=0.408, clip=0, loss_scale=16, train_wall=92, gb_free=15, wall=12098
2023-08-13 02:22:27 | INFO | train_inner | epoch 009:   1216 / 1474 loss=2.06, trans_loss=3.39, nll_loss=1.572, w2v_ctc_loss=1.086, task_loss=0.991, contrastive_loss=0.171, total=4140.66, n_correct=2599.49, ppl=2.97, accuracy=62.78, wps=13288.1, ups=1.07, wpb=12363.4, bsz=448.1, num_updates=13000, lr=0.000124035, gnorm=0.409, clip=0, loss_scale=16, train_wall=93, gb_free=16.8, wall=12191
2023-08-13 02:24:00 | INFO | train_inner | epoch 009:   1316 / 1474 loss=2.085, trans_loss=3.384, nll_loss=1.562, w2v_ctc_loss=1.064, task_loss=0.852, contrastive_loss=0.358, total=4204.43, n_correct=2650.49, ppl=2.95, accuracy=63.04, wps=13582.9, ups=1.08, wpb=12544.9, bsz=492.5, num_updates=13100, lr=0.00012356, gnorm=0.406, clip=0, loss_scale=16, train_wall=92, gb_free=17.5, wall=12284
2023-08-13 02:25:31 | INFO | train_inner | epoch 009:   1416 / 1474 loss=2.052, trans_loss=3.396, nll_loss=1.579, w2v_ctc_loss=1.083, task_loss=1.014, contrastive_loss=0.148, total=4069.19, n_correct=2549.12, ppl=2.99, accuracy=62.644, wps=13263.9, ups=1.09, wpb=12143.2, bsz=427.7, num_updates=13200, lr=0.000123091, gnorm=0.415, clip=0, loss_scale=16, train_wall=91, gb_free=16.3, wall=12375
2023-08-13 02:26:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 02:26:48 | INFO | dev_st | epoch 009 | valid on 'dev_st' subset | loss 4.011 | trans_loss 5.235 | nll_loss 2.523 | w2v_ctc_loss 1.294 | task_loss 4.647 | contrastive_loss 0.333 | total 4003.4 | n_correct 2603.6 | ppl 5.75 | accuracy 65.035 | uer 18.807 | wer 20.726 | raw_wer 20.726 | bleu 20.76 | wps 1979.5 | wpb 4003.4 | bsz 141.8 | num_updates 13258 | best_bleu 20.76
2023-08-13 02:26:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 13258 updates
2023-08-13 02:26:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 02:27:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 02:27:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 9 @ 13258 updates, score 20.76) (writing took 28.468942906707525 seconds)
2023-08-13 02:27:17 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-08-13 02:27:17 | INFO | train | epoch 009 | loss 2.065 | trans_loss 3.388 | nll_loss 1.569 | w2v_ctc_loss 1.075 | task_loss 0.937 | contrastive_loss 0.233 | total 4138.65 | n_correct 2600.86 | ppl 2.97 | accuracy 62.843 | wps 12217.2 | ups 0.99 | wpb 12355.8 | bsz 458.5 | num_updates 13258 | lr 0.000122822 | gnorm 0.412 | clip 0 | loss_scale 16 | train_wall 1367 | gb_free 11.2 | wall 12481
2023-08-13 02:27:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 02:27:17 | INFO | fairseq.trainer | begin training epoch 10
2023-08-13 02:27:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 02:28:04 | INFO | train_inner | epoch 010:     42 / 1474 loss=2.048, trans_loss=3.379, nll_loss=1.557, w2v_ctc_loss=1.054, task_loss=0.893, contrastive_loss=0.241, total=4100.8, n_correct=2595.65, ppl=2.94, accuracy=63.296, wps=8026.9, ups=0.66, wpb=12238.2, bsz=469.4, num_updates=13300, lr=0.000122628, gnorm=0.409, clip=0, loss_scale=16, train_wall=90, gb_free=16, wall=12528
2023-08-13 02:29:36 | INFO | train_inner | epoch 010:    142 / 1474 loss=2.003, trans_loss=3.36, nll_loss=1.534, w2v_ctc_loss=1.026, task_loss=0.884, contrastive_loss=0.165, total=4247.35, n_correct=2709, ppl=2.9, accuracy=63.781, wps=13783.5, ups=1.09, wpb=12684.5, bsz=479.6, num_updates=13400, lr=0.000122169, gnorm=0.399, clip=0, loss_scale=16, train_wall=92, gb_free=11.2, wall=12620
2023-08-13 02:31:08 | INFO | train_inner | epoch 010:    242 / 1474 loss=2.032, trans_loss=3.359, nll_loss=1.53, w2v_ctc_loss=1.035, task_loss=0.927, contrastive_loss=0.286, total=4122.82, n_correct=2628.43, ppl=2.89, accuracy=63.753, wps=13287.7, ups=1.08, wpb=12303.3, bsz=461.4, num_updates=13500, lr=0.000121716, gnorm=0.404, clip=0, loss_scale=16, train_wall=92, gb_free=16, wall=12712
2023-08-13 02:32:40 | INFO | train_inner | epoch 010:    342 / 1474 loss=2.011, trans_loss=3.359, nll_loss=1.534, w2v_ctc_loss=1.031, task_loss=0.948, contrastive_loss=0.2, total=4138.27, n_correct=2635.62, ppl=2.9, accuracy=63.689, wps=13424.5, ups=1.09, wpb=12371, bsz=453.8, num_updates=13600, lr=0.000121268, gnorm=0.406, clip=0, loss_scale=16, train_wall=92, gb_free=16.1, wall=12804
2023-08-13 02:34:14 | INFO | train_inner | epoch 010:    442 / 1474 loss=2.036, trans_loss=3.363, nll_loss=1.536, w2v_ctc_loss=1.017, task_loss=0.903, contrastive_loss=0.372, total=4196.37, n_correct=2671.33, ppl=2.9, accuracy=63.658, wps=13422.1, ups=1.07, wpb=12528, bsz=481.1, num_updates=13700, lr=0.000120824, gnorm=0.404, clip=0, loss_scale=32, train_wall=93, gb_free=15.8, wall=12898
2023-08-13 02:35:46 | INFO | train_inner | epoch 010:    542 / 1474 loss=2.023, trans_loss=3.375, nll_loss=1.548, w2v_ctc_loss=1.056, task_loss=1.006, contrastive_loss=0.154, total=4102.8, n_correct=2604.3, ppl=2.92, accuracy=63.476, wps=13220.6, ups=1.08, wpb=12234.1, bsz=437.8, num_updates=13800, lr=0.000120386, gnorm=0.409, clip=0, loss_scale=32, train_wall=92, gb_free=16.7, wall=12990
2023-08-13 02:37:20 | INFO | train_inner | epoch 010:    642 / 1474 loss=2.04, trans_loss=3.37, nll_loss=1.545, w2v_ctc_loss=1.041, task_loss=0.891, contrastive_loss=0.269, total=4176.56, n_correct=2655.21, ppl=2.92, accuracy=63.574, wps=13353.8, ups=1.07, wpb=12464, bsz=477.2, num_updates=13900, lr=0.000119952, gnorm=0.405, clip=0, loss_scale=32, train_wall=93, gb_free=15.9, wall=13084
2023-08-13 02:38:51 | INFO | train_inner | epoch 010:    742 / 1474 loss=2.026, trans_loss=3.368, nll_loss=1.542, w2v_ctc_loss=1.062, task_loss=0.938, contrastive_loss=0.153, total=4125.87, n_correct=2622, ppl=2.91, accuracy=63.55, wps=13494, ups=1.1, wpb=12315.3, bsz=454.4, num_updates=14000, lr=0.000119523, gnorm=0.413, clip=0, loss_scale=32, train_wall=91, gb_free=14.1, wall=13175
2023-08-13 02:38:51 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 02:39:14 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.019 | trans_loss 5.226 | nll_loss 2.508 | w2v_ctc_loss 1.343 | task_loss 4.616 | contrastive_loss 0.335 | total 4003.4 | n_correct 2615.6 | ppl 5.69 | accuracy 65.334 | uer 19.364 | wer 21.45 | raw_wer 21.45 | bleu 21 | wps 2237.2 | wpb 4003.4 | bsz 141.8 | num_updates 14000 | best_bleu 21
2023-08-13 02:39:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14000 updates
2023-08-13 02:39:14 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-13 02:39:18 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_10_14000.pt
2023-08-13 02:40:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_10_14000.pt (epoch 10 @ 14000 updates, score 21.0) (writing took 52.59662443958223 seconds)
2023-08-13 02:41:39 | INFO | train_inner | epoch 010:    842 / 1474 loss=2.001, trans_loss=3.365, nll_loss=1.54, w2v_ctc_loss=1.031, task_loss=0.927, contrastive_loss=0.154, total=4128.44, n_correct=2628.27, ppl=2.91, accuracy=63.663, wps=7317.2, ups=0.59, wpb=12327.8, bsz=456.3, num_updates=14100, lr=0.000119098, gnorm=0.402, clip=0, loss_scale=32, train_wall=91, gb_free=14.4, wall=13343
2023-08-13 02:43:11 | INFO | train_inner | epoch 010:    942 / 1474 loss=2.019, trans_loss=3.364, nll_loss=1.536, w2v_ctc_loss=1.041, task_loss=0.9, contrastive_loss=0.19, total=4160.94, n_correct=2651.41, ppl=2.9, accuracy=63.721, wps=13553.9, ups=1.09, wpb=12411.1, bsz=468.1, num_updates=14200, lr=0.000118678, gnorm=0.407, clip=0, loss_scale=32, train_wall=91, gb_free=15.1, wall=13435
2023-08-13 02:44:44 | INFO | train_inner | epoch 010:   1042 / 1474 loss=2.016, trans_loss=3.365, nll_loss=1.539, w2v_ctc_loss=1.045, task_loss=1.012, contrastive_loss=0.166, total=4067.53, n_correct=2584.96, ppl=2.91, accuracy=63.551, wps=13085.3, ups=1.08, wpb=12145, bsz=434.3, num_updates=14300, lr=0.000118262, gnorm=0.409, clip=0, loss_scale=32, train_wall=92, gb_free=16.6, wall=13528
2023-08-13 02:46:15 | INFO | train_inner | epoch 010:   1142 / 1474 loss=2.022, trans_loss=3.373, nll_loss=1.549, w2v_ctc_loss=1.058, task_loss=1.042, contrastive_loss=0.148, total=4044.03, n_correct=2558.84, ppl=2.93, accuracy=63.275, wps=13245.5, ups=1.1, wpb=12074.4, bsz=422.3, num_updates=14400, lr=0.000117851, gnorm=0.412, clip=0, loss_scale=32, train_wall=91, gb_free=17, wall=13619
2023-08-13 02:47:47 | INFO | train_inner | epoch 010:   1242 / 1474 loss=2.011, trans_loss=3.358, nll_loss=1.535, w2v_ctc_loss=1.05, task_loss=0.96, contrastive_loss=0.145, total=4110.41, n_correct=2614.53, ppl=2.9, accuracy=63.608, wps=13379.3, ups=1.09, wpb=12291.6, bsz=445.2, num_updates=14500, lr=0.000117444, gnorm=0.407, clip=0, loss_scale=32, train_wall=91, gb_free=16.2, wall=13711
2023-08-13 02:49:19 | INFO | train_inner | epoch 010:   1342 / 1474 loss=2.01, trans_loss=3.365, nll_loss=1.541, w2v_ctc_loss=1.044, task_loss=0.957, contrastive_loss=0.155, total=4121.38, n_correct=2624.12, ppl=2.91, accuracy=63.671, wps=13348.3, ups=1.08, wpb=12308.4, bsz=451, num_updates=14600, lr=0.000117041, gnorm=0.404, clip=0, loss_scale=32, train_wall=92, gb_free=13.7, wall=13803
2023-08-13 02:50:52 | INFO | train_inner | epoch 010:   1442 / 1474 loss=2.068, trans_loss=3.375, nll_loss=1.55, w2v_ctc_loss=1.028, task_loss=0.883, contrastive_loss=0.405, total=4192.39, n_correct=2658.69, ppl=2.93, accuracy=63.417, wps=13487.2, ups=1.08, wpb=12506.1, bsz=482, num_updates=14700, lr=0.000116642, gnorm=0.407, clip=0, loss_scale=32, train_wall=92, gb_free=16.8, wall=13896
2023-08-13 02:51:21 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 02:51:44 | INFO | dev_st | epoch 010 | valid on 'dev_st' subset | loss 4.006 | trans_loss 5.214 | nll_loss 2.493 | w2v_ctc_loss 1.329 | task_loss 4.645 | contrastive_loss 0.332 | total 4003.4 | n_correct 2620.1 | ppl 5.63 | accuracy 65.447 | uer 18.403 | wer 20.249 | raw_wer 20.249 | bleu 21.22 | wps 2176.6 | wpb 4003.4 | bsz 141.8 | num_updates 14732 | best_bleu 21.22
2023-08-13 02:51:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 14732 updates
2023-08-13 02:51:44 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 02:52:00 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 02:52:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 10 @ 14732 updates, score 21.22) (writing took 32.56779687665403 seconds)
2023-08-13 02:52:17 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-08-13 02:52:18 | INFO | train | epoch 010 | loss 2.023 | trans_loss 3.365 | nll_loss 1.54 | w2v_ctc_loss 1.039 | task_loss 0.937 | contrastive_loss 0.222 | total 4138.65 | n_correct 2632.63 | ppl 2.91 | accuracy 63.611 | wps 12139.1 | ups 0.98 | wpb 12355.8 | bsz 458.5 | num_updates 14732 | lr 0.000116516 | gnorm 0.406 | clip 0 | loss_scale 32 | train_wall 1352 | gb_free 17 | wall 13982
2023-08-13 02:52:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 02:52:18 | INFO | fairseq.trainer | begin training epoch 11
2023-08-13 02:52:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 02:53:27 | INFO | train_inner | epoch 011:     68 / 1474 loss=1.992, trans_loss=3.345, nll_loss=1.513, w2v_ctc_loss=1.008, task_loss=0.867, contrastive_loss=0.232, total=4175.24, n_correct=2686.32, ppl=2.85, accuracy=64.339, wps=8050.8, ups=0.65, wpb=12463.5, bsz=478.8, num_updates=14800, lr=0.000116248, gnorm=0.399, clip=0, loss_scale=32, train_wall=91, gb_free=16.4, wall=14050
2023-08-13 02:54:59 | INFO | train_inner | epoch 011:    168 / 1474 loss=1.976, trans_loss=3.345, nll_loss=1.516, w2v_ctc_loss=1.012, task_loss=0.967, contrastive_loss=0.148, total=4087.78, n_correct=2624.48, ppl=2.86, accuracy=64.203, wps=13246.5, ups=1.08, wpb=12214.2, bsz=445.9, num_updates=14900, lr=0.000115857, gnorm=0.405, clip=0, loss_scale=32, train_wall=92, gb_free=16.2, wall=14143
2023-08-13 02:56:31 | INFO | train_inner | epoch 011:    268 / 1474 loss=1.966, trans_loss=3.343, nll_loss=1.511, w2v_ctc_loss=1.004, task_loss=0.967, contrastive_loss=0.143, total=4118.77, n_correct=2649.32, ppl=2.85, accuracy=64.323, wps=13342.4, ups=1.08, wpb=12299.1, bsz=446.5, num_updates=15000, lr=0.00011547, gnorm=0.399, clip=0, loss_scale=32, train_wall=92, gb_free=12, wall=14235
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:0')
2023-08-13 02:57:40 | INFO | train_inner | epoch 011:    368 / 1474 loss=2.05, trans_loss=4.967, nll_loss=2.247, w2v_ctc_loss=0.756, task_loss=1.436, contrastive_loss=0.113, total=4097.83, n_correct=2631.49, ppl=4.75, accuracy=64.217, wps=11936.3, ups=1.45, wpb=8240.8, bsz=298, num_updates=15100, lr=0.000115087, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=14304
2023-08-13 02:58:50 | INFO | train_inner | epoch 011:    468 / 1474 loss=2.067, trans_loss=5.003, nll_loss=2.271, w2v_ctc_loss=0.748, task_loss=1.469, contrastive_loss=0.229, total=4110.64, n_correct=2632.61, ppl=4.83, accuracy=64.044, wps=11781.1, ups=1.43, wpb=8221.3, bsz=300.4, num_updates=15200, lr=0.000114708, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=14374
2023-08-13 02:59:59 | INFO | train_inner | epoch 011:    568 / 1474 loss=2.07, trans_loss=5.001, nll_loss=2.27, w2v_ctc_loss=0.76, task_loss=1.506, contrastive_loss=0.228, total=4071.69, n_correct=2605.15, ppl=4.82, accuracy=63.982, wps=11728, ups=1.44, wpb=8143.4, bsz=293.7, num_updates=15300, lr=0.000114332, gnorm=0.547, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=14443
2023-08-13 03:01:09 | INFO | train_inner | epoch 011:    668 / 1474 loss=2.07, trans_loss=4.993, nll_loss=2.26, w2v_ctc_loss=0.756, task_loss=1.377, contrastive_loss=0.286, total=4157.2, n_correct=2666.99, ppl=4.79, accuracy=64.154, wps=11967.2, ups=1.44, wpb=8314.4, bsz=309.6, num_updates=15400, lr=0.000113961, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=14513
2023-08-13 03:02:19 | INFO | train_inner | epoch 011:    768 / 1474 loss=2.064, trans_loss=5.007, nll_loss=2.278, w2v_ctc_loss=0.77, task_loss=1.409, contrastive_loss=0.111, total=4174.91, n_correct=2674.88, ppl=4.85, accuracy=64.07, wps=11900.9, ups=1.43, wpb=8349.8, bsz=306.9, num_updates=15500, lr=0.000113592, gnorm=0.534, clip=0, loss_scale=32, train_wall=70, gb_free=16.7, wall=14583
2023-08-13 03:03:28 | INFO | train_inner | epoch 011:    868 / 1474 loss=2.059, trans_loss=5.005, nll_loss=2.274, w2v_ctc_loss=0.762, task_loss=1.469, contrastive_loss=0.1, total=4118.44, n_correct=2635.01, ppl=4.84, accuracy=63.981, wps=11971.3, ups=1.45, wpb=8236.9, bsz=293.7, num_updates=15600, lr=0.000113228, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=10.4, wall=14652
2023-08-13 03:04:37 | INFO | train_inner | epoch 011:    968 / 1474 loss=2.058, trans_loss=5.003, nll_loss=2.272, w2v_ctc_loss=0.765, task_loss=1.437, contrastive_loss=0.112, total=4140.92, n_correct=2652.26, ppl=4.83, accuracy=64.05, wps=11896.1, ups=1.44, wpb=8281.8, bsz=301.9, num_updates=15700, lr=0.000112867, gnorm=0.534, clip=0, loss_scale=64, train_wall=69, gb_free=15.4, wall=14721
2023-08-13 03:05:47 | INFO | train_inner | epoch 011:   1068 / 1474 loss=2.057, trans_loss=4.998, nll_loss=2.267, w2v_ctc_loss=0.761, task_loss=1.379, contrastive_loss=0.131, total=4136.99, n_correct=2654.1, ppl=4.81, accuracy=64.155, wps=11843.1, ups=1.43, wpb=8274, bsz=308.8, num_updates=15800, lr=0.000112509, gnorm=0.534, clip=0, loss_scale=64, train_wall=69, gb_free=17.3, wall=14791
2023-08-13 03:06:57 | INFO | train_inner | epoch 011:   1168 / 1474 loss=2.059, trans_loss=5.004, nll_loss=2.274, w2v_ctc_loss=0.765, task_loss=1.396, contrastive_loss=0.118, total=4185.65, n_correct=2680.46, ppl=4.84, accuracy=64.039, wps=12038.3, ups=1.44, wpb=8371.3, bsz=309.8, num_updates=15900, lr=0.000112154, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=13.6, wall=14861
2023-08-13 03:08:06 | INFO | train_inner | epoch 011:   1268 / 1474 loss=2.067, trans_loss=5, nll_loss=2.269, w2v_ctc_loss=0.766, task_loss=1.349, contrastive_loss=0.186, total=4171.89, n_correct=2672.99, ppl=4.82, accuracy=64.071, wps=12056, ups=1.44, wpb=8343.8, bsz=314.1, num_updates=16000, lr=0.000111803, gnorm=0.533, clip=0, loss_scale=64, train_wall=69, gb_free=15.6, wall=14930
2023-08-13 03:08:06 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:3')
2023-08-13 03:08:30 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 4.022 | trans_loss 5.205 | nll_loss 2.484 | w2v_ctc_loss 1.405 | task_loss 4.669 | contrastive_loss 0.328 | total 4003.4 | n_correct 2629.9 | ppl 5.59 | accuracy 65.692 | uer 18.751 | wer 20.655 | raw_wer 20.655 | bleu 21.3 | wps 2069.3 | wpb 4003.4 | bsz 141.8 | num_updates 16000 | best_bleu 21.3
2023-08-13 03:08:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16000 updates
2023-08-13 03:08:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-13 03:08:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_11_16000.pt
2023-08-13 03:09:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_11_16000.pt (epoch 11 @ 16000 updates, score 21.3) (writing took 43.54221928678453 seconds)
2023-08-13 03:10:25 | INFO | train_inner | epoch 011:   1368 / 1474 loss=2.073, trans_loss=4.996, nll_loss=2.265, w2v_ctc_loss=0.751, task_loss=1.299, contrastive_loss=0.347, total=4190.34, n_correct=2684.03, ppl=4.81, accuracy=64.053, wps=6037.4, ups=0.72, wpb=8380.7, bsz=327.9, num_updates=16100, lr=0.000111456, gnorm=0.537, clip=0, loss_scale=64, train_wall=69, gb_free=16.7, wall=15069
2023-08-13 03:11:35 | INFO | train_inner | epoch 011:   1468 / 1474 loss=2.055, trans_loss=5.001, nll_loss=2.271, w2v_ctc_loss=0.757, task_loss=1.36, contrastive_loss=0.122, total=4158.39, n_correct=2662.57, ppl=4.83, accuracy=64.029, wps=11895.5, ups=1.43, wpb=8316.8, bsz=312, num_updates=16200, lr=0.000111111, gnorm=0.531, clip=0, loss_scale=64, train_wall=69, gb_free=16.6, wall=15139
2023-08-13 03:11:39 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 03:12:01 | INFO | dev_st | epoch 011 | valid on 'dev_st' subset | loss 3.997 | trans_loss 5.205 | nll_loss 2.481 | w2v_ctc_loss 1.321 | task_loss 4.649 | contrastive_loss 0.329 | total 4003.4 | n_correct 2631.1 | ppl 5.58 | accuracy 65.722 | uer 18.921 | wer 20.924 | raw_wer 20.924 | bleu 21.3 | wps 2022.4 | wpb 4003.4 | bsz 141.8 | num_updates 16206 | best_bleu 21.3
2023-08-13 03:12:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 16206 updates
2023-08-13 03:12:01 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 03:12:17 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 03:12:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 11 @ 16206 updates, score 21.3) (writing took 30.6097700484097 seconds)
2023-08-13 03:12:33 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-08-13 03:12:33 | INFO | train | epoch 011 | loss 2.04 | trans_loss 4.587 | nll_loss 2.08 | w2v_ctc_loss 0.821 | task_loss 1.288 | contrastive_loss 0.167 | total 4138.65 | n_correct 2653.5 | ppl 4.23 | accuracy 64.115 | wps 10942.9 | ups 1.21 | wpb 9021 | bsz 333.4 | num_updates 16206 | lr 0.000111091 | gnorm 0.51 | clip 0 | loss_scale 64 | train_wall 1078 | gb_free 16.9 | wall 15197
2023-08-13 03:12:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 03:12:33 | INFO | fairseq.trainer | begin training epoch 12
2023-08-13 03:12:33 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 03:13:45 | INFO | train_inner | epoch 012:     94 / 1474 loss=2.036, trans_loss=4.961, nll_loss=2.218, w2v_ctc_loss=0.741, task_loss=1.345, contrastive_loss=0.152, total=4146.82, n_correct=2693.01, ppl=4.65, accuracy=64.942, wps=6349.9, ups=0.77, wpb=8293.6, bsz=313.9, num_updates=16300, lr=0.00011077, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=15.4, wall=15269
2023-08-13 03:14:54 | INFO | train_inner | epoch 012:    194 / 1474 loss=2.04, trans_loss=4.967, nll_loss=2.225, w2v_ctc_loss=0.75, task_loss=1.452, contrastive_loss=0.106, total=4120.68, n_correct=2662.22, ppl=4.68, accuracy=64.606, wps=11943.2, ups=1.45, wpb=8241.4, bsz=294.7, num_updates=16400, lr=0.000110432, gnorm=0.535, clip=0, loss_scale=64, train_wall=69, gb_free=15.3, wall=15338
2023-08-13 03:16:03 | INFO | train_inner | epoch 012:    294 / 1474 loss=2.037, trans_loss=4.969, nll_loss=2.229, w2v_ctc_loss=0.738, task_loss=1.325, contrastive_loss=0.134, total=4199.46, n_correct=2718.24, ppl=4.69, accuracy=64.728, wps=12156.1, ups=1.45, wpb=8398.9, bsz=320.3, num_updates=16500, lr=0.000110096, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=16.3, wall=15407
2023-08-13 03:17:13 | INFO | train_inner | epoch 012:    394 / 1474 loss=2.038, trans_loss=4.97, nll_loss=2.228, w2v_ctc_loss=0.747, task_loss=1.377, contrastive_loss=0.118, total=4151.14, n_correct=2685.5, ppl=4.69, accuracy=64.693, wps=11928.8, ups=1.44, wpb=8302.3, bsz=307.8, num_updates=16600, lr=0.000109764, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=16.9, wall=15477
2023-08-13 03:18:22 | INFO | train_inner | epoch 012:    494 / 1474 loss=2.048, trans_loss=4.983, nll_loss=2.247, w2v_ctc_loss=0.756, task_loss=1.409, contrastive_loss=0.125, total=4110.49, n_correct=2655.45, ppl=4.75, accuracy=64.602, wps=11855.4, ups=1.44, wpb=8221, bsz=302.2, num_updates=16700, lr=0.000109435, gnorm=0.531, clip=0, loss_scale=64, train_wall=69, gb_free=13.5, wall=15546
2023-08-13 03:19:32 | INFO | train_inner | epoch 012:    594 / 1474 loss=2.047, trans_loss=4.971, nll_loss=2.232, w2v_ctc_loss=0.747, task_loss=1.346, contrastive_loss=0.19, total=4189.92, n_correct=2710.4, ppl=4.7, accuracy=64.689, wps=12038.2, ups=1.44, wpb=8379.8, bsz=315.1, num_updates=16800, lr=0.000109109, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=14.6, wall=15616
2023-08-13 03:19:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 03:20:42 | INFO | train_inner | epoch 012:    695 / 1474 loss=2.033, trans_loss=4.97, nll_loss=2.23, w2v_ctc_loss=0.738, task_loss=1.344, contrastive_loss=0.119, total=4176.04, n_correct=2708.97, ppl=4.69, accuracy=64.869, wps=11959.9, ups=1.43, wpb=8352.1, bsz=313.5, num_updates=16900, lr=0.000108786, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=15686
2023-08-13 03:21:51 | INFO | train_inner | epoch 012:    795 / 1474 loss=2.038, trans_loss=4.967, nll_loss=2.226, w2v_ctc_loss=0.749, task_loss=1.421, contrastive_loss=0.113, total=4095.72, n_correct=2652.35, ppl=4.68, accuracy=64.759, wps=11780.7, ups=1.44, wpb=8191.4, bsz=298.9, num_updates=17000, lr=0.000108465, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=15755
2023-08-13 03:23:01 | INFO | train_inner | epoch 012:    895 / 1474 loss=2.046, trans_loss=4.972, nll_loss=2.232, w2v_ctc_loss=0.747, task_loss=1.443, contrastive_loss=0.165, total=4162.82, n_correct=2690.71, ppl=4.7, accuracy=64.637, wps=11980.7, ups=1.44, wpb=8325.6, bsz=305.4, num_updates=17100, lr=0.000108148, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=15825
2023-08-13 03:24:10 | INFO | train_inner | epoch 012:    995 / 1474 loss=2.048, trans_loss=4.975, nll_loss=2.237, w2v_ctc_loss=0.754, task_loss=1.43, contrastive_loss=0.176, total=4117.63, n_correct=2658.21, ppl=4.71, accuracy=64.557, wps=11924.9, ups=1.45, wpb=8235.3, bsz=301.6, num_updates=17200, lr=0.000107833, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=15894
2023-08-13 03:24:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-13 03:25:19 | INFO | train_inner | epoch 012:   1096 / 1474 loss=2.059, trans_loss=4.98, nll_loss=2.243, w2v_ctc_loss=0.757, task_loss=1.485, contrastive_loss=0.22, total=4045.11, n_correct=2611.07, ppl=4.74, accuracy=64.549, wps=11648.5, ups=1.44, wpb=8090.2, bsz=288.7, num_updates=17300, lr=0.000107521, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=15963
2023-08-13 03:26:30 | INFO | train_inner | epoch 012:   1196 / 1474 loss=2.063, trans_loss=4.997, nll_loss=2.266, w2v_ctc_loss=0.765, task_loss=1.366, contrastive_loss=0.189, total=4196.85, n_correct=2693.52, ppl=4.81, accuracy=64.18, wps=11942.7, ups=1.42, wpb=8393.7, bsz=319, num_updates=17400, lr=0.000107211, gnorm=0.53, clip=0, loss_scale=16, train_wall=70, gb_free=16.2, wall=16034
2023-08-13 03:27:39 | INFO | train_inner | epoch 012:   1296 / 1474 loss=2.051, trans_loss=4.98, nll_loss=2.243, w2v_ctc_loss=0.77, task_loss=1.572, contrastive_loss=0.101, total=4067.78, n_correct=2618.41, ppl=4.73, accuracy=64.37, wps=11711, ups=1.44, wpb=8135.6, bsz=285.5, num_updates=17500, lr=0.000106904, gnorm=0.533, clip=0, loss_scale=16, train_wall=69, gb_free=14.8, wall=16103
2023-08-13 03:28:48 | INFO | train_inner | epoch 012:   1396 / 1474 loss=2.048, trans_loss=4.983, nll_loss=2.247, w2v_ctc_loss=0.74, task_loss=1.418, contrastive_loss=0.205, total=4142.88, n_correct=2676.63, ppl=4.75, accuracy=64.608, wps=11995.7, ups=1.45, wpb=8285.8, bsz=306.2, num_updates=17600, lr=0.0001066, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=16172
2023-08-13 03:29:42 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 03:30:06 | INFO | dev_st | epoch 012 | valid on 'dev_st' subset | loss 3.987 | trans_loss 5.196 | nll_loss 2.471 | w2v_ctc_loss 1.313 | task_loss 4.636 | contrastive_loss 0.325 | total 4003.4 | n_correct 2634 | ppl 5.54 | accuracy 65.794 | uer 18.554 | wer 20.409 | raw_wer 20.409 | bleu 21.45 | wps 2163.4 | wpb 4003.4 | bsz 141.8 | num_updates 17678 | best_bleu 21.45
2023-08-13 03:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 17678 updates
2023-08-13 03:30:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 03:30:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 03:30:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 12 @ 17678 updates, score 21.45) (writing took 30.76048882678151 seconds)
2023-08-13 03:30:37 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-08-13 03:30:37 | INFO | train | epoch 012 | loss 2.045 | trans_loss 4.975 | nll_loss 2.236 | w2v_ctc_loss 0.75 | task_loss 1.41 | contrastive_loss 0.149 | total 4136.55 | n_correct 2673.24 | ppl 4.71 | accuracy 64.625 | wps 11230.4 | ups 1.36 | wpb 8273.1 | bsz 304.8 | num_updates 17678 | lr 0.000106365 | gnorm 0.531 | clip 0 | loss_scale 16 | train_wall 1015 | gb_free 12.5 | wall 16281
2023-08-13 03:30:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 03:30:37 | INFO | fairseq.trainer | begin training epoch 13
2023-08-13 03:30:37 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 03:31:00 | INFO | train_inner | epoch 013:     22 / 1474 loss=2.043, trans_loss=4.98, nll_loss=2.242, w2v_ctc_loss=0.755, task_loss=1.45, contrastive_loss=0.109, total=4097.08, n_correct=2645.17, ppl=4.73, accuracy=64.562, wps=6199.5, ups=0.76, wpb=8194.2, bsz=296.6, num_updates=17700, lr=0.000106299, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=16304
2023-08-13 03:32:10 | INFO | train_inner | epoch 013:    122 / 1474 loss=2.027, trans_loss=4.95, nll_loss=2.204, w2v_ctc_loss=0.735, task_loss=1.413, contrastive_loss=0.122, total=4164.24, n_correct=2710.08, ppl=4.61, accuracy=65.08, wps=11938.6, ups=1.43, wpb=8328.5, bsz=301.9, num_updates=17800, lr=0.000106, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=16374
2023-08-13 03:33:20 | INFO | train_inner | epoch 013:    222 / 1474 loss=2.045, trans_loss=4.957, nll_loss=2.214, w2v_ctc_loss=0.731, task_loss=1.302, contrastive_loss=0.338, total=4201.52, n_correct=2731.01, ppl=4.64, accuracy=65.001, wps=12059.5, ups=1.44, wpb=8403, bsz=328.5, num_updates=17900, lr=0.000105703, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=12.7, wall=16444
2023-08-13 03:34:29 | INFO | train_inner | epoch 013:    322 / 1474 loss=2.018, trans_loss=4.941, nll_loss=2.192, w2v_ctc_loss=0.728, task_loss=1.461, contrastive_loss=0.105, total=4102.53, n_correct=2681.6, ppl=4.57, accuracy=65.365, wps=11931.4, ups=1.45, wpb=8205.1, bsz=293.9, num_updates=18000, lr=0.000105409, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=15.7, wall=16513
2023-08-13 03:34:29 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 03:34:53 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.988 | trans_loss 5.203 | nll_loss 2.48 | w2v_ctc_loss 1.295 | task_loss 4.635 | contrastive_loss 0.334 | total 4003.4 | n_correct 2627 | ppl 5.58 | accuracy 65.619 | uer 18.515 | wer 20.435 | raw_wer 20.435 | bleu 21.61 | wps 2033.2 | wpb 4003.4 | bsz 141.8 | num_updates 18000 | best_bleu 21.61
2023-08-13 03:34:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 18000 updates
2023-08-13 03:34:53 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-13 03:34:57 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_13_18000.pt
2023-08-13 03:35:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_13_18000.pt (epoch 13 @ 18000 updates, score 21.61) (writing took 51.34474027529359 seconds)
2023-08-13 03:36:54 | INFO | train_inner | epoch 013:    422 / 1474 loss=2.027, trans_loss=4.948, nll_loss=2.202, w2v_ctc_loss=0.738, task_loss=1.308, contrastive_loss=0.152, total=4190.45, n_correct=2733.84, ppl=4.6, accuracy=65.24, wps=5749.4, ups=0.69, wpb=8380.9, bsz=320.3, num_updates=18100, lr=0.000105118, gnorm=0.523, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=16658
2023-08-13 03:38:04 | INFO | train_inner | epoch 013:    522 / 1474 loss=2.035, trans_loss=4.957, nll_loss=2.213, w2v_ctc_loss=0.739, task_loss=1.361, contrastive_loss=0.189, total=4194.45, n_correct=2723.98, ppl=4.64, accuracy=64.942, wps=12024.7, ups=1.43, wpb=8388.9, bsz=319, num_updates=18200, lr=0.000104828, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=16728
2023-08-13 03:39:13 | INFO | train_inner | epoch 013:    622 / 1474 loss=2.021, trans_loss=4.951, nll_loss=2.206, w2v_ctc_loss=0.733, task_loss=1.376, contrastive_loss=0.102, total=4158.04, n_correct=2711.93, ppl=4.61, accuracy=65.221, wps=12094.7, ups=1.45, wpb=8316.1, bsz=306.7, num_updates=18300, lr=0.000104542, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=13.1, wall=16797
2023-08-13 03:40:22 | INFO | train_inner | epoch 013:    722 / 1474 loss=2.038, trans_loss=4.959, nll_loss=2.215, w2v_ctc_loss=0.758, task_loss=1.558, contrastive_loss=0.102, total=4099.91, n_correct=2661.12, ppl=4.64, accuracy=64.907, wps=11824.3, ups=1.44, wpb=8199.8, bsz=285.5, num_updates=18400, lr=0.000104257, gnorm=0.542, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=16866
2023-08-13 03:41:32 | INFO | train_inner | epoch 013:    822 / 1474 loss=2.033, trans_loss=4.958, nll_loss=2.215, w2v_ctc_loss=0.738, task_loss=1.428, contrastive_loss=0.147, total=4122.78, n_correct=2673.72, ppl=4.64, accuracy=64.852, wps=11822.2, ups=1.43, wpb=8245.6, bsz=306, num_updates=18500, lr=0.000103975, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=14.6, wall=16936
2023-08-13 03:42:41 | INFO | train_inner | epoch 013:    922 / 1474 loss=2.031, trans_loss=4.957, nll_loss=2.213, w2v_ctc_loss=0.743, task_loss=1.437, contrastive_loss=0.112, total=4102.59, n_correct=2669.65, ppl=4.64, accuracy=65.072, wps=11866.1, ups=1.45, wpb=8205.2, bsz=296.6, num_updates=18600, lr=0.000103695, gnorm=0.543, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=17005
2023-08-13 03:43:50 | INFO | train_inner | epoch 013:   1022 / 1474 loss=2.038, trans_loss=4.958, nll_loss=2.215, w2v_ctc_loss=0.744, task_loss=1.49, contrastive_loss=0.162, total=4087.8, n_correct=2652.47, ppl=4.64, accuracy=64.887, wps=11946, ups=1.46, wpb=8175.6, bsz=293.7, num_updates=18700, lr=0.000103418, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=17074
2023-08-13 03:44:58 | INFO | train_inner | epoch 013:   1122 / 1474 loss=2.026, trans_loss=4.949, nll_loss=2.203, w2v_ctc_loss=0.735, task_loss=1.394, contrastive_loss=0.143, total=4098.77, n_correct=2671.1, ppl=4.6, accuracy=65.168, wps=11950, ups=1.46, wpb=8197.5, bsz=304.8, num_updates=18800, lr=0.000103142, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=13.3, wall=17142
2023-08-13 03:46:08 | INFO | train_inner | epoch 013:   1222 / 1474 loss=2.033, trans_loss=4.96, nll_loss=2.218, w2v_ctc_loss=0.747, task_loss=1.491, contrastive_loss=0.103, total=4115.57, n_correct=2671.33, ppl=4.65, accuracy=64.908, wps=11843.3, ups=1.44, wpb=8231.1, bsz=295.9, num_updates=18900, lr=0.000102869, gnorm=0.541, clip=0, loss_scale=16, train_wall=69, gb_free=14.8, wall=17212
2023-08-13 03:47:17 | INFO | train_inner | epoch 013:   1322 / 1474 loss=2.031, trans_loss=4.948, nll_loss=2.202, w2v_ctc_loss=0.736, task_loss=1.395, contrastive_loss=0.2, total=4111.02, n_correct=2686.53, ppl=4.6, accuracy=65.349, wps=11854.9, ups=1.44, wpb=8222, bsz=307.8, num_updates=19000, lr=0.000102598, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=17.6, wall=17281
2023-08-13 03:48:26 | INFO | train_inner | epoch 013:   1422 / 1474 loss=2.038, trans_loss=4.957, nll_loss=2.214, w2v_ctc_loss=0.735, task_loss=1.381, contrastive_loss=0.213, total=4179.06, n_correct=2718.16, ppl=4.64, accuracy=65.042, wps=12092.6, ups=1.45, wpb=8358.1, bsz=311.9, num_updates=19100, lr=0.000102329, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=17350
2023-08-13 03:49:02 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 03:49:25 | INFO | dev_st | epoch 013 | valid on 'dev_st' subset | loss 3.979 | trans_loss 5.192 | nll_loss 2.462 | w2v_ctc_loss 1.303 | task_loss 4.645 | contrastive_loss 0.317 | total 4003.4 | n_correct 2638.6 | ppl 5.51 | accuracy 65.909 | uer 18.448 | wer 20.409 | raw_wer 20.409 | bleu 21.45 | wps 2150.8 | wpb 4003.4 | bsz 141.8 | num_updates 19152 | best_bleu 21.61
2023-08-13 03:49:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 19152 updates
2023-08-13 03:49:25 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.4505.pt
2023-08-13 03:49:29 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.4505.pt
2023-08-13 03:49:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.4505.pt (epoch 13 @ 19152 updates, score 21.45) (writing took 20.852344861254096 seconds)
2023-08-13 03:49:46 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-08-13 03:49:47 | INFO | train | epoch 013 | loss 2.031 | trans_loss 4.953 | nll_loss 2.208 | w2v_ctc_loss 0.739 | task_loss 1.407 | contrastive_loss 0.157 | total 4138.65 | n_correct 2693.67 | ppl 4.62 | accuracy 65.086 | wps 10614.7 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 19152 | lr 0.00010219 | gnorm 0.531 | clip 0 | loss_scale 16 | train_wall 1013 | gb_free 17.4 | wall 17430
2023-08-13 03:49:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 03:49:47 | INFO | fairseq.trainer | begin training epoch 14
2023-08-13 03:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 03:50:28 | INFO | train_inner | epoch 014:     48 / 1474 loss=2.009, trans_loss=4.926, nll_loss=2.175, w2v_ctc_loss=0.725, task_loss=1.294, contrastive_loss=0.116, total=4179.66, n_correct=2745.69, ppl=4.52, accuracy=65.692, wps=6874, ups=0.82, wpb=8359.3, bsz=322, num_updates=19200, lr=0.000102062, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=10.1, wall=17472
2023-08-13 03:51:36 | INFO | train_inner | epoch 014:    148 / 1474 loss=2.006, trans_loss=4.919, nll_loss=2.163, w2v_ctc_loss=0.726, task_loss=1.408, contrastive_loss=0.098, total=4081.01, n_correct=2687.33, ppl=4.48, accuracy=65.85, wps=11904.3, ups=1.46, wpb=8162, bsz=300.6, num_updates=19300, lr=0.000101797, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=15.7, wall=17540
2023-08-13 03:52:45 | INFO | train_inner | epoch 014:    248 / 1474 loss=2.022, trans_loss=4.932, nll_loss=2.181, w2v_ctc_loss=0.728, task_loss=1.466, contrastive_loss=0.2, total=4109.83, n_correct=2695.27, ppl=4.54, accuracy=65.581, wps=11968.2, ups=1.46, wpb=8219.7, bsz=295.2, num_updates=19400, lr=0.000101535, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=17609
2023-08-13 03:53:54 | INFO | train_inner | epoch 014:    348 / 1474 loss=2.011, trans_loss=4.932, nll_loss=2.181, w2v_ctc_loss=0.723, task_loss=1.311, contrastive_loss=0.132, total=4171.83, n_correct=2741.22, ppl=4.54, accuracy=65.708, wps=12083, ups=1.45, wpb=8343.7, bsz=319.7, num_updates=19500, lr=0.000101274, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=17678
2023-08-13 03:55:03 | INFO | train_inner | epoch 014:    448 / 1474 loss=2.012, trans_loss=4.936, nll_loss=2.187, w2v_ctc_loss=0.723, task_loss=1.413, contrastive_loss=0.108, total=4142.75, n_correct=2713.7, ppl=4.55, accuracy=65.505, wps=11974.7, ups=1.45, wpb=8285.5, bsz=302.2, num_updates=19600, lr=0.000101015, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=17747
2023-08-13 03:56:14 | INFO | train_inner | epoch 014:    548 / 1474 loss=2.024, trans_loss=4.935, nll_loss=2.185, w2v_ctc_loss=0.745, task_loss=1.514, contrastive_loss=0.117, total=4073.76, n_correct=2661.64, ppl=4.55, accuracy=65.336, wps=11594.6, ups=1.42, wpb=8147.5, bsz=290.9, num_updates=19700, lr=0.000100759, gnorm=0.534, clip=0, loss_scale=32, train_wall=70, gb_free=15.2, wall=17817
2023-08-13 03:57:23 | INFO | train_inner | epoch 014:    648 / 1474 loss=2.02, trans_loss=4.935, nll_loss=2.184, w2v_ctc_loss=0.727, task_loss=1.405, contrastive_loss=0.173, total=4158.79, n_correct=2722.74, ppl=4.55, accuracy=65.47, wps=12000.5, ups=1.44, wpb=8317.6, bsz=306.8, num_updates=19800, lr=0.000100504, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=17887
2023-08-13 03:58:32 | INFO | train_inner | epoch 014:    748 / 1474 loss=2.006, trans_loss=4.924, nll_loss=2.171, w2v_ctc_loss=0.72, task_loss=1.373, contrastive_loss=0.105, total=4145.47, n_correct=2725.79, ppl=4.5, accuracy=65.753, wps=12051, ups=1.45, wpb=8290.9, bsz=309.6, num_updates=19900, lr=0.000100251, gnorm=0.521, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=17956
2023-08-13 03:59:41 | INFO | train_inner | epoch 014:    848 / 1474 loss=2.021, trans_loss=4.927, nll_loss=2.176, w2v_ctc_loss=0.725, task_loss=1.336, contrastive_loss=0.214, total=4171.1, n_correct=2736.49, ppl=4.52, accuracy=65.606, wps=12035.8, ups=1.44, wpb=8342.2, bsz=319.7, num_updates=20000, lr=0.0001, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=18025
2023-08-13 03:59:41 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 04:00:04 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.983 | trans_loss 5.188 | nll_loss 2.455 | w2v_ctc_loss 1.326 | task_loss 4.625 | contrastive_loss 0.316 | total 4003.4 | n_correct 2637.3 | ppl 5.48 | accuracy 65.877 | uer 18.39 | wer 20.335 | raw_wer 20.335 | bleu 21.8 | wps 1982 | wpb 4003.4 | bsz 141.8 | num_updates 20000 | best_bleu 21.8
2023-08-13 04:00:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20000 updates
2023-08-13 04:00:04 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-13 04:00:09 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_14_20000.pt
2023-08-13 04:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_14_20000.pt (epoch 14 @ 20000 updates, score 21.8) (writing took 51.5786818806082 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:0')
2023-08-13 04:02:07 | INFO | train_inner | epoch 014:    948 / 1474 loss=2.017, trans_loss=4.934, nll_loss=2.183, w2v_ctc_loss=0.726, task_loss=1.412, contrastive_loss=0.154, total=4167.75, n_correct=2724.86, ppl=4.54, accuracy=65.38, wps=5703.9, ups=0.68, wpb=8335.5, bsz=310.1, num_updates=20100, lr=9.97509e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=18171
2023-08-13 04:03:17 | INFO | train_inner | epoch 014:   1048 / 1474 loss=2.016, trans_loss=4.936, nll_loss=2.187, w2v_ctc_loss=0.725, task_loss=1.432, contrastive_loss=0.127, total=4143.92, n_correct=2714.37, ppl=4.55, accuracy=65.502, wps=11856.4, ups=1.43, wpb=8287.8, bsz=300.7, num_updates=20200, lr=9.95037e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=18241
2023-08-13 04:03:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-13 04:04:27 | INFO | train_inner | epoch 014:   1149 / 1474 loss=2.043, trans_loss=4.935, nll_loss=2.187, w2v_ctc_loss=0.732, task_loss=1.34, contrastive_loss=0.396, total=4212.14, n_correct=2752.43, ppl=4.55, accuracy=65.345, wps=11982.4, ups=1.42, wpb=8424.3, bsz=322.3, num_updates=20300, lr=9.92583e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=70, gb_free=16.1, wall=18311
2023-08-13 04:05:36 | INFO | train_inner | epoch 014:   1249 / 1474 loss=2.023, trans_loss=4.943, nll_loss=2.195, w2v_ctc_loss=0.744, task_loss=1.633, contrastive_loss=0.088, total=4032.06, n_correct=2633.53, ppl=4.58, accuracy=65.315, wps=11715.5, ups=1.45, wpb=8064.1, bsz=274.4, num_updates=20400, lr=9.90148e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=17.4, wall=18380
2023-08-13 04:06:45 | INFO | train_inner | epoch 014:   1349 / 1474 loss=2.009, trans_loss=4.936, nll_loss=2.187, w2v_ctc_loss=0.721, task_loss=1.334, contrastive_loss=0.104, total=4205.07, n_correct=2754.72, ppl=4.55, accuracy=65.509, wps=12136.1, ups=1.44, wpb=8410.1, bsz=317.3, num_updates=20500, lr=9.8773e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=18449
2023-08-13 04:07:54 | INFO | train_inner | epoch 014:   1449 / 1474 loss=2.02, trans_loss=4.941, nll_loss=2.193, w2v_ctc_loss=0.728, task_loss=1.407, contrastive_loss=0.144, total=4126.44, n_correct=2698.64, ppl=4.57, accuracy=65.399, wps=12019.5, ups=1.46, wpb=8252.9, bsz=303.9, num_updates=20600, lr=9.85329e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=18518
2023-08-13 04:08:11 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:2')
2023-08-13 04:08:34 | INFO | dev_st | epoch 014 | valid on 'dev_st' subset | loss 3.97 | trans_loss 5.183 | nll_loss 2.453 | w2v_ctc_loss 1.294 | task_loss 4.63 | contrastive_loss 0.319 | total 4003.4 | n_correct 2645.3 | ppl 5.48 | accuracy 66.076 | uer 18.374 | wer 20.23 | raw_wer 20.23 | bleu 21.59 | wps 2228 | wpb 4003.4 | bsz 141.8 | num_updates 20625 | best_bleu 21.8
2023-08-13 04:08:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 20625 updates
2023-08-13 04:08:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.5907.pt
2023-08-13 04:08:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.5907.pt
2023-08-13 04:08:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.5907.pt (epoch 14 @ 20625 updates, score 21.59) (writing took 22.64870852045715 seconds)
2023-08-13 04:08:57 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-08-13 04:08:57 | INFO | train | epoch 014 | loss 2.018 | trans_loss 4.933 | nll_loss 2.183 | w2v_ctc_loss 0.728 | task_loss 1.408 | contrastive_loss 0.154 | total 4137.77 | n_correct 2711 | ppl 4.54 | accuracy 65.518 | wps 10592.2 | ups 1.28 | wpb 8275.5 | bsz 305.4 | num_updates 20625 | lr 9.84732e-05 | gnorm 0.526 | clip 0 | loss_scale 16 | train_wall 1014 | gb_free 16.1 | wall 18581
2023-08-13 04:08:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 04:08:58 | INFO | fairseq.trainer | begin training epoch 15
2023-08-13 04:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 04:09:56 | INFO | train_inner | epoch 015:     75 / 1474 loss=2.014, trans_loss=4.924, nll_loss=2.171, w2v_ctc_loss=0.72, task_loss=1.41, contrastive_loss=0.192, total=4090.99, n_correct=2691.68, ppl=4.5, accuracy=65.795, wps=6709.1, ups=0.82, wpb=8182, bsz=300.8, num_updates=20700, lr=9.82946e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=68, gb_free=16.6, wall=18640
2023-08-13 04:11:05 | INFO | train_inner | epoch 015:    175 / 1474 loss=2.006, trans_loss=4.916, nll_loss=2.16, w2v_ctc_loss=0.73, task_loss=1.458, contrastive_loss=0.102, total=4115.56, n_correct=2712.52, ppl=4.47, accuracy=65.909, wps=11924, ups=1.45, wpb=8231.1, bsz=298.5, num_updates=20800, lr=9.80581e-05, gnorm=0.588, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=18709
2023-08-13 04:12:14 | INFO | train_inner | epoch 015:    275 / 1474 loss=1.994, trans_loss=4.913, nll_loss=2.157, w2v_ctc_loss=0.709, task_loss=1.37, contrastive_loss=0.093, total=4182.19, n_correct=2763.67, ppl=4.46, accuracy=66.082, wps=12080.9, ups=1.44, wpb=8364.4, bsz=310.5, num_updates=20900, lr=9.78232e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.2, wall=18778
2023-08-13 04:13:23 | INFO | train_inner | epoch 015:    375 / 1474 loss=2, trans_loss=4.908, nll_loss=2.15, w2v_ctc_loss=0.714, task_loss=1.404, contrastive_loss=0.118, total=4172.52, n_correct=2751.58, ppl=4.44, accuracy=65.945, wps=12085.5, ups=1.45, wpb=8345, bsz=307.7, num_updates=21000, lr=9.759e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=69, gb_free=16.4, wall=18847
2023-08-13 04:14:32 | INFO | train_inner | epoch 015:    475 / 1474 loss=2.01, trans_loss=4.914, nll_loss=2.158, w2v_ctc_loss=0.707, task_loss=1.476, contrastive_loss=0.208, total=4076.84, n_correct=2683.65, ppl=4.46, accuracy=65.827, wps=11855.6, ups=1.45, wpb=8153.7, bsz=293.4, num_updates=21100, lr=9.73585e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=18916
2023-08-13 04:15:41 | INFO | train_inner | epoch 015:    575 / 1474 loss=2.002, trans_loss=4.912, nll_loss=2.156, w2v_ctc_loss=0.719, task_loss=1.438, contrastive_loss=0.12, total=4156.05, n_correct=2737.28, ppl=4.46, accuracy=65.863, wps=12031, ups=1.45, wpb=8312.1, bsz=302.8, num_updates=21200, lr=9.71286e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=11.4, wall=18985
2023-08-13 04:16:51 | INFO | train_inner | epoch 015:    675 / 1474 loss=2.011, trans_loss=4.912, nll_loss=2.155, w2v_ctc_loss=0.724, task_loss=1.439, contrastive_loss=0.163, total=4118.87, n_correct=2714.45, ppl=4.45, accuracy=65.903, wps=11847.1, ups=1.44, wpb=8237.7, bsz=303, num_updates=21300, lr=9.69003e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=16.7, wall=19055
2023-08-13 04:18:00 | INFO | train_inner | epoch 015:    775 / 1474 loss=2.003, trans_loss=4.918, nll_loss=2.162, w2v_ctc_loss=0.721, task_loss=1.418, contrastive_loss=0.104, total=4176.64, n_correct=2748.25, ppl=4.48, accuracy=65.8, wps=12026.3, ups=1.44, wpb=8353.3, bsz=305.3, num_updates=21400, lr=9.66736e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=13.7, wall=19124
2023-08-13 04:19:09 | INFO | train_inner | epoch 015:    875 / 1474 loss=2.009, trans_loss=4.924, nll_loss=2.171, w2v_ctc_loss=0.729, task_loss=1.523, contrastive_loss=0.098, total=4056.99, n_correct=2665.03, ppl=4.5, accuracy=65.69, wps=11849, ups=1.46, wpb=8114, bsz=288, num_updates=21500, lr=9.64486e-05, gnorm=0.543, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=19193
2023-08-13 04:20:17 | INFO | train_inner | epoch 015:    975 / 1474 loss=2.007, trans_loss=4.916, nll_loss=2.161, w2v_ctc_loss=0.715, task_loss=1.401, contrastive_loss=0.182, total=4134.44, n_correct=2727.24, ppl=4.47, accuracy=65.964, wps=12087.4, ups=1.46, wpb=8268.9, bsz=304.8, num_updates=21600, lr=9.6225e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=68, gb_free=15.8, wall=19261
2023-08-13 04:21:27 | INFO | train_inner | epoch 015:   1075 / 1474 loss=2.026, trans_loss=4.925, nll_loss=2.173, w2v_ctc_loss=0.719, task_loss=1.326, contrastive_loss=0.341, total=4185.02, n_correct=2749.88, ppl=4.51, accuracy=65.708, wps=11924.3, ups=1.42, wpb=8370, bsz=324.2, num_updates=21700, lr=9.60031e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=70, gb_free=16.4, wall=19331
2023-08-13 04:22:36 | INFO | train_inner | epoch 015:   1175 / 1474 loss=1.992, trans_loss=4.912, nll_loss=2.157, w2v_ctc_loss=0.697, task_loss=1.258, contrastive_loss=0.144, total=4187.68, n_correct=2769.91, ppl=4.46, accuracy=66.144, wps=12230.6, ups=1.46, wpb=8375.4, bsz=329.7, num_updates=21800, lr=9.57826e-05, gnorm=0.513, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=19400
2023-08-13 04:23:45 | INFO | train_inner | epoch 015:   1275 / 1474 loss=2.007, trans_loss=4.915, nll_loss=2.159, w2v_ctc_loss=0.73, task_loss=1.452, contrastive_loss=0.103, total=4141.6, n_correct=2724.72, ppl=4.47, accuracy=65.789, wps=11968.3, ups=1.44, wpb=8283.2, bsz=301.1, num_updates=21900, lr=9.55637e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=13.1, wall=19469
2023-08-13 04:24:54 | INFO | train_inner | epoch 015:   1375 / 1474 loss=1.999, trans_loss=4.914, nll_loss=2.158, w2v_ctc_loss=0.717, task_loss=1.456, contrastive_loss=0.089, total=4099.6, n_correct=2701.01, ppl=4.46, accuracy=65.885, wps=11919, ups=1.45, wpb=8199.2, bsz=293.2, num_updates=22000, lr=9.53463e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=68, gb_free=14, wall=19538
2023-08-13 04:24:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 04:25:18 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.958 | trans_loss 5.179 | nll_loss 2.446 | w2v_ctc_loss 1.267 | task_loss 4.622 | contrastive_loss 0.316 | total 4003.4 | n_correct 2643.1 | ppl 5.45 | accuracy 66.021 | uer 17.933 | wer 19.735 | raw_wer 19.735 | bleu 22.3 | wps 2009.4 | wpb 4003.4 | bsz 141.8 | num_updates 22000 | best_bleu 22.3
2023-08-13 04:25:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22000 updates
2023-08-13 04:25:18 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-13 04:25:22 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_15_22000.pt
2023-08-13 04:26:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_15_22000.pt (epoch 15 @ 22000 updates, score 22.3) (writing took 54.10793102905154 seconds)
2023-08-13 04:27:23 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 04:27:46 | INFO | dev_st | epoch 015 | valid on 'dev_st' subset | loss 3.964 | trans_loss 5.176 | nll_loss 2.446 | w2v_ctc_loss 1.286 | task_loss 4.641 | contrastive_loss 0.322 | total 4003.4 | n_correct 2648.2 | ppl 5.45 | accuracy 66.149 | uer 18.029 | wer 19.895 | raw_wer 19.895 | bleu 21.92 | wps 2197.2 | wpb 4003.4 | bsz 141.8 | num_updates 22099 | best_bleu 22.3
2023-08-13 04:27:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 22099 updates
2023-08-13 04:27:46 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.9202.pt
2023-08-13 04:27:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.9202.pt
2023-08-13 04:28:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.9202.pt (epoch 15 @ 22099 updates, score 21.92) (writing took 20.91215106472373 seconds)
2023-08-13 04:28:07 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-08-13 04:28:07 | INFO | train | epoch 015 | loss 2.006 | trans_loss 4.916 | nll_loss 2.16 | w2v_ctc_loss 0.717 | task_loss 1.408 | contrastive_loss 0.151 | total 4138.65 | n_correct 2726.91 | ppl 4.47 | accuracy 65.889 | wps 10610.2 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 22099 | lr 9.51325e-05 | gnorm 0.53 | clip 0 | loss_scale 16 | train_wall 1012 | gb_free 16.7 | wall 19731
2023-08-13 04:28:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 04:28:08 | INFO | fairseq.trainer | begin training epoch 16
2023-08-13 04:28:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 04:28:15 | INFO | train_inner | epoch 016:      1 / 1474 loss=2.012, trans_loss=4.924, nll_loss=2.172, w2v_ctc_loss=0.72, task_loss=1.344, contrastive_loss=0.177, total=4149.9, n_correct=2729.05, ppl=4.51, accuracy=65.762, wps=4126.7, ups=0.5, wpb=8299.8, bsz=316.3, num_updates=22100, lr=9.51303e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=70, gb_free=17.2, wall=19739
2023-08-13 04:29:23 | INFO | train_inner | epoch 016:    101 / 1474 loss=1.989, trans_loss=4.897, nll_loss=2.137, w2v_ctc_loss=0.705, task_loss=1.349, contrastive_loss=0.118, total=4118.73, n_correct=2731.84, ppl=4.4, accuracy=66.327, wps=12045.5, ups=1.46, wpb=8237.5, bsz=314, num_updates=22200, lr=9.49158e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=19807
2023-08-13 04:30:33 | INFO | train_inner | epoch 016:    201 / 1474 loss=1.981, trans_loss=4.887, nll_loss=2.123, w2v_ctc_loss=0.697, task_loss=1.443, contrastive_loss=0.093, total=4106.45, n_correct=2732.98, ppl=4.36, accuracy=66.553, wps=11826.3, ups=1.44, wpb=8212.9, bsz=297.4, num_updates=22300, lr=9.47027e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=19877
2023-08-13 04:31:42 | INFO | train_inner | epoch 016:    301 / 1474 loss=1.999, trans_loss=4.899, nll_loss=2.139, w2v_ctc_loss=0.713, task_loss=1.388, contrastive_loss=0.167, total=4169.65, n_correct=2759.35, ppl=4.4, accuracy=66.177, wps=12039.1, ups=1.44, wpb=8339.3, bsz=309.9, num_updates=22400, lr=9.44911e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=10.3, wall=19946
2023-08-13 04:32:51 | INFO | train_inner | epoch 016:    401 / 1474 loss=2.003, trans_loss=4.897, nll_loss=2.135, w2v_ctc_loss=0.716, task_loss=1.509, contrastive_loss=0.186, total=4063.79, n_correct=2691.69, ppl=4.39, accuracy=66.236, wps=11730.1, ups=1.44, wpb=8127.6, bsz=286.5, num_updates=22500, lr=9.42809e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=12.3, wall=20015
2023-08-13 04:34:01 | INFO | train_inner | epoch 016:    501 / 1474 loss=1.991, trans_loss=4.901, nll_loss=2.142, w2v_ctc_loss=0.704, task_loss=1.351, contrastive_loss=0.124, total=4179.53, n_correct=2774.36, ppl=4.41, accuracy=66.38, wps=12026.8, ups=1.44, wpb=8359.1, bsz=319.5, num_updates=22600, lr=9.40721e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=20085
2023-08-13 04:35:09 | INFO | train_inner | epoch 016:    601 / 1474 loss=1.987, trans_loss=4.897, nll_loss=2.136, w2v_ctc_loss=0.704, task_loss=1.417, contrastive_loss=0.088, total=4121.37, n_correct=2733.48, ppl=4.4, accuracy=66.325, wps=12030.5, ups=1.46, wpb=8242.7, bsz=297.5, num_updates=22700, lr=9.38647e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=20153
2023-08-13 04:36:18 | INFO | train_inner | epoch 016:    701 / 1474 loss=1.99, trans_loss=4.9, nll_loss=2.14, w2v_ctc_loss=0.712, task_loss=1.439, contrastive_loss=0.091, total=4099.17, n_correct=2715.89, ppl=4.41, accuracy=66.255, wps=11957.7, ups=1.46, wpb=8198.3, bsz=297.5, num_updates=22800, lr=9.36586e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=20222
2023-08-13 04:37:27 | INFO | train_inner | epoch 016:    801 / 1474 loss=1.99, trans_loss=4.896, nll_loss=2.135, w2v_ctc_loss=0.699, task_loss=1.344, contrastive_loss=0.153, total=4184.53, n_correct=2775.73, ppl=4.39, accuracy=66.333, wps=12069.4, ups=1.44, wpb=8369.1, bsz=313, num_updates=22900, lr=9.34539e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=13, wall=20291
2023-08-13 04:38:36 | INFO | train_inner | epoch 016:    901 / 1474 loss=1.993, trans_loss=4.897, nll_loss=2.137, w2v_ctc_loss=0.705, task_loss=1.378, contrastive_loss=0.145, total=4151.84, n_correct=2754.69, ppl=4.4, accuracy=66.349, wps=12034.7, ups=1.45, wpb=8303.7, bsz=307, num_updates=23000, lr=9.32505e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=20360
2023-08-13 04:39:46 | INFO | train_inner | epoch 016:   1001 / 1474 loss=2.003, trans_loss=4.905, nll_loss=2.147, w2v_ctc_loss=0.721, task_loss=1.458, contrastive_loss=0.143, total=4112.79, n_correct=2714.67, ppl=4.43, accuracy=66.006, wps=11857.6, ups=1.44, wpb=8225.6, bsz=299.5, num_updates=23100, lr=9.30484e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=14.6, wall=20430
2023-08-13 04:40:55 | INFO | train_inner | epoch 016:   1101 / 1474 loss=2.004, trans_loss=4.912, nll_loss=2.156, w2v_ctc_loss=0.723, task_loss=1.497, contrastive_loss=0.119, total=4111.6, n_correct=2713.88, ppl=4.46, accuracy=66.005, wps=11789.8, ups=1.43, wpb=8223.2, bsz=295.6, num_updates=23200, lr=9.28477e-05, gnorm=0.537, clip=0, loss_scale=32, train_wall=69, gb_free=14.4, wall=20499
2023-08-13 04:42:05 | INFO | train_inner | epoch 016:   1201 / 1474 loss=2.003, trans_loss=4.907, nll_loss=2.15, w2v_ctc_loss=0.7, task_loss=1.431, contrastive_loss=0.211, total=4157.51, n_correct=2746.79, ppl=4.44, accuracy=66.068, wps=11883.9, ups=1.43, wpb=8315, bsz=306.6, num_updates=23300, lr=9.26482e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=70, gb_free=14.6, wall=20569
2023-08-13 04:43:15 | INFO | train_inner | epoch 016:   1301 / 1474 loss=2.002, trans_loss=4.902, nll_loss=2.143, w2v_ctc_loss=0.715, task_loss=1.365, contrastive_loss=0.192, total=4151.03, n_correct=2749.1, ppl=4.42, accuracy=66.227, wps=11978.5, ups=1.44, wpb=8302.1, bsz=314.5, num_updates=23400, lr=9.245e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=20639
2023-08-13 04:44:24 | INFO | train_inner | epoch 016:   1401 / 1474 loss=1.994, trans_loss=4.903, nll_loss=2.144, w2v_ctc_loss=0.714, task_loss=1.341, contrastive_loss=0.12, total=4201.47, n_correct=2780.79, ppl=4.42, accuracy=66.186, wps=12152.7, ups=1.45, wpb=8402.9, bsz=320.7, num_updates=23500, lr=9.22531e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=20708
2023-08-13 04:45:14 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 04:45:38 | INFO | dev_st | epoch 016 | valid on 'dev_st' subset | loss 3.955 | trans_loss 5.172 | nll_loss 2.438 | w2v_ctc_loss 1.276 | task_loss 4.654 | contrastive_loss 0.31 | total 4003.4 | n_correct 2660 | ppl 5.42 | accuracy 66.444 | uer 17.896 | wer 19.735 | raw_wer 19.735 | bleu 22.22 | wps 2197 | wpb 4003.4 | bsz 141.8 | num_updates 23573 | best_bleu 22.3
2023-08-13 04:45:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 23573 updates
2023-08-13 04:45:38 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.2203.pt
2023-08-13 04:45:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.2203.pt
2023-08-13 04:45:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.2203.pt (epoch 16 @ 23573 updates, score 22.22) (writing took 20.346234649419785 seconds)
2023-08-13 04:45:59 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-08-13 04:45:59 | INFO | train | epoch 016 | loss 1.995 | trans_loss 4.9 | nll_loss 2.14 | w2v_ctc_loss 0.709 | task_loss 1.406 | contrastive_loss 0.148 | total 4138.65 | n_correct 2741.48 | ppl 4.41 | accuracy 66.241 | wps 11389 | ups 1.38 | wpb 8277.3 | bsz 305.7 | num_updates 23573 | lr 9.21102e-05 | gnorm 0.529 | clip 0 | loss_scale 32 | train_wall 1013 | gb_free 15.1 | wall 20803
2023-08-13 04:45:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 04:45:59 | INFO | fairseq.trainer | begin training epoch 17
2023-08-13 04:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 04:46:25 | INFO | train_inner | epoch 017:     27 / 1474 loss=1.999, trans_loss=4.891, nll_loss=2.129, w2v_ctc_loss=0.701, task_loss=1.434, contrastive_loss=0.259, total=4145.04, n_correct=2750.53, ppl=4.37, accuracy=66.357, wps=6870.6, ups=0.83, wpb=8290.1, bsz=302.4, num_updates=23600, lr=9.20575e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=20829
2023-08-13 04:47:34 | INFO | train_inner | epoch 017:    127 / 1474 loss=1.981, trans_loss=4.878, nll_loss=2.111, w2v_ctc_loss=0.705, task_loss=1.443, contrastive_loss=0.094, total=4117.27, n_correct=2744.76, ppl=4.32, accuracy=66.665, wps=11917.8, ups=1.45, wpb=8234.5, bsz=296.2, num_updates=23700, lr=9.1863e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=20898
2023-08-13 04:48:42 | INFO | train_inner | epoch 017:    227 / 1474 loss=1.99, trans_loss=4.876, nll_loss=2.109, w2v_ctc_loss=0.689, task_loss=1.333, contrastive_loss=0.258, total=4159.6, n_correct=2774.19, ppl=4.31, accuracy=66.694, wps=12084.8, ups=1.45, wpb=8319.2, bsz=317.6, num_updates=23800, lr=9.16698e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=20966
2023-08-13 04:49:51 | INFO | train_inner | epoch 017:    327 / 1474 loss=1.993, trans_loss=4.884, nll_loss=2.119, w2v_ctc_loss=0.694, task_loss=1.401, contrastive_loss=0.263, total=4156.91, n_correct=2767.77, ppl=4.34, accuracy=66.582, wps=12071.3, ups=1.45, wpb=8313.8, bsz=305.7, num_updates=23900, lr=9.14779e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=17.2, wall=21035
2023-08-13 04:51:01 | INFO | train_inner | epoch 017:    427 / 1474 loss=1.976, trans_loss=4.881, nll_loss=2.116, w2v_ctc_loss=0.695, task_loss=1.394, contrastive_loss=0.093, total=4146.43, n_correct=2768.99, ppl=4.34, accuracy=66.78, wps=11907.9, ups=1.44, wpb=8292.9, bsz=308, num_updates=24000, lr=9.12871e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=21105
2023-08-13 04:51:01 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 04:51:24 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.958 | trans_loss 5.169 | nll_loss 2.433 | w2v_ctc_loss 1.298 | task_loss 4.667 | contrastive_loss 0.303 | total 4003.4 | n_correct 2656.6 | ppl 5.4 | accuracy 66.359 | uer 17.896 | wer 19.742 | raw_wer 19.742 | bleu 21.98 | wps 2239.7 | wpb 4003.4 | bsz 141.8 | num_updates 24000 | best_bleu 22.3
2023-08-13 04:51:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 24000 updates
2023-08-13 04:51:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-13 04:51:28 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_17_24000.pt
2023-08-13 04:52:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_17_24000.pt (epoch 17 @ 24000 updates, score 21.98) (writing took 38.85660979896784 seconds)
2023-08-13 04:53:14 | INFO | train_inner | epoch 017:    527 / 1474 loss=1.987, trans_loss=4.887, nll_loss=2.123, w2v_ctc_loss=0.704, task_loss=1.459, contrastive_loss=0.136, total=4182.1, n_correct=2778.78, ppl=4.36, accuracy=66.445, wps=6278.4, ups=0.75, wpb=8364.2, bsz=307.9, num_updates=24100, lr=9.10975e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=70, gb_free=16.5, wall=21238
2023-08-13 04:54:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-13 04:54:24 | INFO | train_inner | epoch 017:    628 / 1474 loss=1.979, trans_loss=4.887, nll_loss=2.124, w2v_ctc_loss=0.697, task_loss=1.417, contrastive_loss=0.088, total=4164.56, n_correct=2774.47, ppl=4.36, accuracy=66.621, wps=11997.5, ups=1.44, wpb=8329.1, bsz=302.1, num_updates=24200, lr=9.09091e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=21308
2023-08-13 04:55:33 | INFO | train_inner | epoch 017:    728 / 1474 loss=1.991, trans_loss=4.888, nll_loss=2.124, w2v_ctc_loss=0.712, task_loss=1.391, contrastive_loss=0.136, total=4168.97, n_correct=2769.95, ppl=4.36, accuracy=66.442, wps=12100.9, ups=1.45, wpb=8337.9, bsz=308.4, num_updates=24300, lr=9.07218e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=68, gb_free=16.7, wall=21377
2023-08-13 04:56:42 | INFO | train_inner | epoch 017:    828 / 1474 loss=1.982, trans_loss=4.886, nll_loss=2.122, w2v_ctc_loss=0.701, task_loss=1.415, contrastive_loss=0.101, total=4097.38, n_correct=2727.05, ppl=4.35, accuracy=66.556, wps=11790.6, ups=1.44, wpb=8194.8, bsz=297.3, num_updates=24400, lr=9.05357e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=10.1, wall=21446
2023-08-13 04:57:51 | INFO | train_inner | epoch 017:    928 / 1474 loss=1.978, trans_loss=4.886, nll_loss=2.122, w2v_ctc_loss=0.696, task_loss=1.389, contrastive_loss=0.096, total=4105.01, n_correct=2731.64, ppl=4.35, accuracy=66.544, wps=11986.1, ups=1.46, wpb=8210, bsz=304.1, num_updates=24500, lr=9.03508e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=21515
2023-08-13 04:58:59 | INFO | train_inner | epoch 017:   1028 / 1474 loss=1.981, trans_loss=4.885, nll_loss=2.121, w2v_ctc_loss=0.703, task_loss=1.404, contrastive_loss=0.102, total=4105.88, n_correct=2730.07, ppl=4.35, accuracy=66.492, wps=11959.8, ups=1.46, wpb=8211.8, bsz=303.4, num_updates=24600, lr=9.0167e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=21583
2023-08-13 05:00:07 | INFO | train_inner | epoch 017:   1128 / 1474 loss=1.979, trans_loss=4.884, nll_loss=2.12, w2v_ctc_loss=0.697, task_loss=1.44, contrastive_loss=0.093, total=4095.58, n_correct=2725.53, ppl=4.35, accuracy=66.548, wps=12026, ups=1.47, wpb=8191.2, bsz=298.5, num_updates=24700, lr=8.99843e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=68, gb_free=15.4, wall=21651
2023-08-13 05:01:18 | INFO | train_inner | epoch 017:   1228 / 1474 loss=2.005, trans_loss=4.893, nll_loss=2.132, w2v_ctc_loss=0.694, task_loss=1.377, contrastive_loss=0.332, total=4162.14, n_correct=2757.25, ppl=4.38, accuracy=66.246, wps=11859.1, ups=1.42, wpb=8324.3, bsz=320.2, num_updates=24800, lr=8.98027e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=70, gb_free=15.9, wall=21722
2023-08-13 05:02:27 | INFO | train_inner | epoch 017:   1328 / 1474 loss=1.985, trans_loss=4.887, nll_loss=2.124, w2v_ctc_loss=0.689, task_loss=1.398, contrastive_loss=0.173, total=4149.03, n_correct=2762.38, ppl=4.36, accuracy=66.579, wps=11940.9, ups=1.44, wpb=8298.1, bsz=306.7, num_updates=24900, lr=8.96221e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=16.6, wall=21791
2023-08-13 05:03:36 | INFO | train_inner | epoch 017:   1428 / 1474 loss=1.978, trans_loss=4.888, nll_loss=2.125, w2v_ctc_loss=0.694, task_loss=1.412, contrastive_loss=0.093, total=4117.13, n_correct=2741.07, ppl=4.36, accuracy=66.577, wps=11899.5, ups=1.45, wpb=8234.3, bsz=303.7, num_updates=25000, lr=8.94427e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=21860
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:0')
2023-08-13 05:04:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:7')
2023-08-13 05:04:31 | INFO | dev_st | epoch 017 | valid on 'dev_st' subset | loss 3.966 | trans_loss 5.171 | nll_loss 2.437 | w2v_ctc_loss 1.31 | task_loss 4.652 | contrastive_loss 0.318 | total 4003.4 | n_correct 2655.8 | ppl 5.42 | accuracy 66.339 | uer 17.928 | wer 19.895 | raw_wer 19.895 | bleu 21.89 | wps 2186.1 | wpb 4003.4 | bsz 141.8 | num_updates 25046 | best_bleu 22.3
2023-08-13 05:04:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 25046 updates
2023-08-13 05:04:31 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.8906.pt
2023-08-13 05:04:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.8906.pt
2023-08-13 05:04:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_21.8906.pt (epoch 17 @ 25046 updates, score 21.89) (writing took 23.182971570640802 seconds)
2023-08-13 05:04:55 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-08-13 05:04:55 | INFO | train | epoch 017 | loss 1.984 | trans_loss 4.885 | nll_loss 2.12 | w2v_ctc_loss 0.698 | task_loss 1.406 | contrastive_loss 0.146 | total 4138.66 | n_correct 2754.79 | ppl 4.35 | accuracy 66.562 | wps 10729.7 | ups 1.3 | wpb 8277.3 | bsz 305.7 | num_updates 25046 | lr 8.93605e-05 | gnorm 0.525 | clip 0 | loss_scale 16 | train_wall 1013 | gb_free 16.1 | wall 21939
2023-08-13 05:04:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 05:04:55 | INFO | fairseq.trainer | begin training epoch 18
2023-08-13 05:04:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 05:05:40 | INFO | train_inner | epoch 018:     54 / 1474 loss=1.979, trans_loss=4.879, nll_loss=2.113, w2v_ctc_loss=0.702, task_loss=1.431, contrastive_loss=0.103, total=4138.21, n_correct=2759.86, ppl=4.33, accuracy=66.692, wps=6684.1, ups=0.81, wpb=8276.4, bsz=303.2, num_updates=25100, lr=8.92644e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=21984
2023-08-13 05:06:50 | INFO | train_inner | epoch 018:    154 / 1474 loss=1.975, trans_loss=4.86, nll_loss=2.089, w2v_ctc_loss=0.674, task_loss=1.342, contrastive_loss=0.223, total=4158.88, n_correct=2787.96, ppl=4.25, accuracy=67.036, wps=11895.3, ups=1.43, wpb=8317.8, bsz=314, num_updates=25200, lr=8.90871e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=16.5, wall=22054
2023-08-13 05:07:59 | INFO | train_inner | epoch 018:    254 / 1474 loss=1.962, trans_loss=4.859, nll_loss=2.087, w2v_ctc_loss=0.683, task_loss=1.364, contrastive_loss=0.094, total=4164.11, n_correct=2796.21, ppl=4.25, accuracy=67.15, wps=12034.9, ups=1.45, wpb=8328.2, bsz=312.5, num_updates=25300, lr=8.89108e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=22123
2023-08-13 05:09:09 | INFO | train_inner | epoch 018:    354 / 1474 loss=1.971, trans_loss=4.869, nll_loss=2.099, w2v_ctc_loss=0.69, task_loss=1.428, contrastive_loss=0.108, total=4163.13, n_correct=2785.03, ppl=4.28, accuracy=66.898, wps=11985.5, ups=1.44, wpb=8326.3, bsz=301.5, num_updates=25400, lr=8.87357e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=22193
2023-08-13 05:10:18 | INFO | train_inner | epoch 018:    454 / 1474 loss=1.983, trans_loss=4.874, nll_loss=2.106, w2v_ctc_loss=0.69, task_loss=1.503, contrastive_loss=0.197, total=4087.83, n_correct=2728.25, ppl=4.3, accuracy=66.741, wps=11733.3, ups=1.44, wpb=8175.7, bsz=295.3, num_updates=25500, lr=8.85615e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=22262
2023-08-13 05:11:28 | INFO | train_inner | epoch 018:    554 / 1474 loss=1.961, trans_loss=4.859, nll_loss=2.088, w2v_ctc_loss=0.682, task_loss=1.265, contrastive_loss=0.106, total=4204.41, n_correct=2822.88, ppl=4.25, accuracy=67.141, wps=12100.5, ups=1.44, wpb=8408.8, bsz=328, num_updates=25600, lr=8.83883e-05, gnorm=0.521, clip=0, loss_scale=16, train_wall=69, gb_free=17.2, wall=22332
2023-08-13 05:12:37 | INFO | train_inner | epoch 018:    654 / 1474 loss=1.982, trans_loss=4.876, nll_loss=2.109, w2v_ctc_loss=0.695, task_loss=1.452, contrastive_loss=0.178, total=4096.81, n_correct=2735.44, ppl=4.31, accuracy=66.77, wps=11916.3, ups=1.45, wpb=8193.6, bsz=298.9, num_updates=25700, lr=8.82162e-05, gnorm=0.524, clip=0, loss_scale=16, train_wall=68, gb_free=16.4, wall=22401
2023-08-13 05:13:46 | INFO | train_inner | epoch 018:    754 / 1474 loss=1.991, trans_loss=4.879, nll_loss=2.113, w2v_ctc_loss=0.697, task_loss=1.343, contrastive_loss=0.268, total=4208.29, n_correct=2808.01, ppl=4.33, accuracy=66.726, wps=12145.9, ups=1.44, wpb=8416.6, bsz=322.8, num_updates=25800, lr=8.80451e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=17.5, wall=22470
2023-08-13 05:14:55 | INFO | train_inner | epoch 018:    854 / 1474 loss=1.97, trans_loss=4.872, nll_loss=2.104, w2v_ctc_loss=0.689, task_loss=1.431, contrastive_loss=0.085, total=4166.81, n_correct=2785.27, ppl=4.3, accuracy=66.844, wps=12072.6, ups=1.45, wpb=8333.6, bsz=301.9, num_updates=25900, lr=8.7875e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=12.3, wall=22539
2023-08-13 05:16:04 | INFO | train_inner | epoch 018:    954 / 1474 loss=1.965, trans_loss=4.866, nll_loss=2.097, w2v_ctc_loss=0.68, task_loss=1.311, contrastive_loss=0.107, total=4142.65, n_correct=2776.24, ppl=4.28, accuracy=67.016, wps=12055.5, ups=1.46, wpb=8285.3, bsz=316.1, num_updates=26000, lr=8.77058e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=68, gb_free=14.5, wall=22608
2023-08-13 05:16:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 05:16:27 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.979 | trans_loss 5.175 | nll_loss 2.437 | w2v_ctc_loss 1.354 | task_loss 4.672 | contrastive_loss 0.306 | total 4003.4 | n_correct 2657.2 | ppl 5.42 | accuracy 66.374 | uer 18.337 | wer 20.167 | raw_wer 20.167 | bleu 22.05 | wps 2200.8 | wpb 4003.4 | bsz 141.8 | num_updates 26000 | best_bleu 22.3
2023-08-13 05:16:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26000 updates
2023-08-13 05:16:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-13 05:16:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_18_26000.pt
2023-08-13 05:17:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_18_26000.pt (epoch 18 @ 26000 updates, score 22.05) (writing took 41.87134310789406 seconds)
2023-08-13 05:18:20 | INFO | train_inner | epoch 018:   1054 / 1474 loss=1.966, trans_loss=4.869, nll_loss=2.1, w2v_ctc_loss=0.68, task_loss=1.464, contrastive_loss=0.093, total=4137.77, n_correct=2771.28, ppl=4.29, accuracy=66.975, wps=6090.8, ups=0.74, wpb=8275.5, bsz=300.5, num_updates=26100, lr=8.75376e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=69, gb_free=17.1, wall=22744
2023-08-13 05:19:28 | INFO | train_inner | epoch 018:   1154 / 1474 loss=1.976, trans_loss=4.86, nll_loss=2.09, w2v_ctc_loss=0.685, task_loss=1.33, contrastive_loss=0.202, total=4153.69, n_correct=2786.31, ppl=4.26, accuracy=67.08, wps=12056.1, ups=1.45, wpb=8307.4, bsz=314.9, num_updates=26200, lr=8.73704e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=22812
2023-08-13 05:20:37 | INFO | train_inner | epoch 018:   1254 / 1474 loss=1.974, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.691, task_loss=1.508, contrastive_loss=0.088, total=4087.62, n_correct=2727.42, ppl=4.33, accuracy=66.724, wps=11859.2, ups=1.45, wpb=8175.2, bsz=287.1, num_updates=26300, lr=8.72041e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=22881
2023-08-13 05:21:46 | INFO | train_inner | epoch 018:   1354 / 1474 loss=1.984, trans_loss=4.88, nll_loss=2.114, w2v_ctc_loss=0.707, task_loss=1.498, contrastive_loss=0.114, total=4070.69, n_correct=2712.23, ppl=4.33, accuracy=66.628, wps=11813.5, ups=1.45, wpb=8141.4, bsz=291.7, num_updates=26400, lr=8.70388e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=17.1, wall=22950
2023-08-13 05:22:55 | INFO | train_inner | epoch 018:   1454 / 1474 loss=1.976, trans_loss=4.876, nll_loss=2.109, w2v_ctc_loss=0.697, task_loss=1.48, contrastive_loss=0.099, total=4113.2, n_correct=2746.44, ppl=4.31, accuracy=66.771, wps=11934.8, ups=1.45, wpb=8226.4, bsz=297.5, num_updates=26500, lr=8.68744e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=16.2, wall=23019
2023-08-13 05:23:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 05:23:34 | INFO | dev_st | epoch 018 | valid on 'dev_st' subset | loss 3.963 | trans_loss 5.167 | nll_loss 2.431 | w2v_ctc_loss 1.319 | task_loss 4.657 | contrastive_loss 0.305 | total 4003.4 | n_correct 2663.9 | ppl 5.39 | accuracy 66.541 | uer 17.437 | wer 19.261 | raw_wer 19.261 | bleu 22.05 | wps 1932.9 | wpb 4003.4 | bsz 141.8 | num_updates 26520 | best_bleu 22.3
2023-08-13 05:23:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 26520 updates
2023-08-13 05:23:34 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.0509.pt
2023-08-13 05:23:38 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.0509.pt
2023-08-13 05:23:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.0509.pt (epoch 18 @ 26520 updates, score 22.05) (writing took 21.5887741278857 seconds)
2023-08-13 05:23:56 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-08-13 05:23:56 | INFO | train | epoch 018 | loss 1.974 | trans_loss 4.87 | nll_loss 2.102 | w2v_ctc_loss 0.689 | task_loss 1.407 | contrastive_loss 0.143 | total 4138.65 | n_correct 2768.09 | ppl 4.29 | accuracy 66.884 | wps 10689 | ups 1.29 | wpb 8277.3 | bsz 305.7 | num_updates 26520 | lr 8.68417e-05 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 1014 | gb_free 15.7 | wall 23080
2023-08-13 05:23:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 05:23:57 | INFO | fairseq.trainer | begin training epoch 19
2023-08-13 05:23:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 05:24:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-13 05:25:00 | INFO | train_inner | epoch 019:     81 / 1474 loss=1.966, trans_loss=4.853, nll_loss=2.08, w2v_ctc_loss=0.682, task_loss=1.417, contrastive_loss=0.149, total=4104.12, n_correct=2752.94, ppl=4.23, accuracy=67.077, wps=6585.8, ups=0.8, wpb=8208.2, bsz=296, num_updates=26600, lr=8.6711e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=69, gb_free=12.4, wall=23144
2023-08-13 05:26:10 | INFO | train_inner | epoch 019:    181 / 1474 loss=1.966, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.689, task_loss=1.315, contrastive_loss=0.141, total=4222.18, n_correct=2839.56, ppl=4.22, accuracy=67.253, wps=12099.8, ups=1.43, wpb=8444.4, bsz=324.4, num_updates=26700, lr=8.65485e-05, gnorm=0.534, clip=0, loss_scale=16, train_wall=69, gb_free=11.3, wall=23214
2023-08-13 05:27:19 | INFO | train_inner | epoch 019:    281 / 1474 loss=1.955, trans_loss=4.848, nll_loss=2.073, w2v_ctc_loss=0.678, task_loss=1.382, contrastive_loss=0.085, total=4187.37, n_correct=2819.86, ppl=4.21, accuracy=67.342, wps=12117.3, ups=1.45, wpb=8374.7, bsz=307, num_updates=26800, lr=8.63868e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=17.3, wall=23283
2023-08-13 05:28:28 | INFO | train_inner | epoch 019:    381 / 1474 loss=1.965, trans_loss=4.848, nll_loss=2.073, w2v_ctc_loss=0.67, task_loss=1.39, contrastive_loss=0.192, total=4170.67, n_correct=2806.61, ppl=4.21, accuracy=67.294, wps=12053.6, ups=1.45, wpb=8341.3, bsz=310.5, num_updates=26900, lr=8.62261e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=23352
2023-08-13 05:29:37 | INFO | train_inner | epoch 019:    481 / 1474 loss=1.964, trans_loss=4.857, nll_loss=2.085, w2v_ctc_loss=0.687, task_loss=1.447, contrastive_loss=0.1, total=4115.22, n_correct=2763.47, ppl=4.24, accuracy=67.152, wps=12011.3, ups=1.46, wpb=8230.4, bsz=301.9, num_updates=27000, lr=8.60663e-05, gnorm=0.529, clip=0, loss_scale=16, train_wall=68, gb_free=14.8, wall=23421
2023-08-13 05:30:45 | INFO | train_inner | epoch 019:    581 / 1474 loss=1.963, trans_loss=4.852, nll_loss=2.078, w2v_ctc_loss=0.678, task_loss=1.379, contrastive_loss=0.165, total=4129.22, n_correct=2778.61, ppl=4.22, accuracy=67.291, wps=12008.2, ups=1.45, wpb=8258.4, bsz=306, num_updates=27100, lr=8.59074e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=68, gb_free=15.6, wall=23489
2023-08-13 05:31:55 | INFO | train_inner | epoch 019:    681 / 1474 loss=1.95, trans_loss=4.855, nll_loss=2.083, w2v_ctc_loss=0.664, task_loss=1.282, contrastive_loss=0.09, total=4197.2, n_correct=2827.04, ppl=4.24, accuracy=67.355, wps=12127.3, ups=1.44, wpb=8394.4, bsz=320.8, num_updates=27200, lr=8.57493e-05, gnorm=0.522, clip=0, loss_scale=16, train_wall=69, gb_free=14.3, wall=23559
2023-08-13 05:33:04 | INFO | train_inner | epoch 019:    781 / 1474 loss=1.964, trans_loss=4.856, nll_loss=2.084, w2v_ctc_loss=0.688, task_loss=1.415, contrastive_loss=0.104, total=4142.6, n_correct=2781.91, ppl=4.24, accuracy=67.154, wps=11972.7, ups=1.45, wpb=8285.2, bsz=305.1, num_updates=27300, lr=8.55921e-05, gnorm=0.518, clip=0, loss_scale=16, train_wall=69, gb_free=16, wall=23628
2023-08-13 05:34:13 | INFO | train_inner | epoch 019:    881 / 1474 loss=1.964, trans_loss=4.861, nll_loss=2.09, w2v_ctc_loss=0.685, task_loss=1.437, contrastive_loss=0.088, total=4153.47, n_correct=2786.72, ppl=4.26, accuracy=67.094, wps=12006.1, ups=1.45, wpb=8306.9, bsz=303.1, num_updates=27400, lr=8.54358e-05, gnorm=0.519, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=23697
2023-08-13 05:35:23 | INFO | train_inner | epoch 019:    981 / 1474 loss=1.986, trans_loss=4.869, nll_loss=2.1, w2v_ctc_loss=0.68, task_loss=1.405, contrastive_loss=0.322, total=4101.29, n_correct=2743.18, ppl=4.29, accuracy=66.886, wps=11695.1, ups=1.43, wpb=8202.6, bsz=309.9, num_updates=27500, lr=8.52803e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=70, gb_free=16.4, wall=23767
2023-08-13 05:36:32 | INFO | train_inner | epoch 019:   1081 / 1474 loss=1.968, trans_loss=4.866, nll_loss=2.096, w2v_ctc_loss=0.681, task_loss=1.507, contrastive_loss=0.128, total=4036.97, n_correct=2704.11, ppl=4.27, accuracy=66.984, wps=11653.9, ups=1.44, wpb=8073.9, bsz=291, num_updates=27600, lr=8.51257e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=14.3, wall=23836
2023-08-13 05:37:42 | INFO | train_inner | epoch 019:   1181 / 1474 loss=1.981, trans_loss=4.866, nll_loss=2.097, w2v_ctc_loss=0.688, task_loss=1.43, contrastive_loss=0.213, total=4137.49, n_correct=2767.67, ppl=4.28, accuracy=66.892, wps=11854.6, ups=1.43, wpb=8275, bsz=307.7, num_updates=27700, lr=8.49719e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=69, gb_free=14.5, wall=23906
2023-08-13 05:38:51 | INFO | train_inner | epoch 019:   1281 / 1474 loss=1.964, trans_loss=4.862, nll_loss=2.092, w2v_ctc_loss=0.677, task_loss=1.423, contrastive_loss=0.11, total=4141.89, n_correct=2777.68, ppl=4.26, accuracy=67.063, wps=12058.7, ups=1.46, wpb=8283.8, bsz=300.1, num_updates=27800, lr=8.48189e-05, gnorm=0.52, clip=0, loss_scale=16, train_wall=68, gb_free=15.3, wall=23975
2023-08-13 05:40:00 | INFO | train_inner | epoch 019:   1381 / 1474 loss=1.964, trans_loss=4.861, nll_loss=2.09, w2v_ctc_loss=0.682, task_loss=1.439, contrastive_loss=0.097, total=4133.26, n_correct=2770.42, ppl=4.26, accuracy=67.027, wps=11989, ups=1.45, wpb=8266.5, bsz=301, num_updates=27900, lr=8.46668e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=15.9, wall=24044
2023-08-13 05:41:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 05:41:30 | INFO | dev_st | epoch 019 | valid on 'dev_st' subset | loss 3.963 | trans_loss 5.163 | nll_loss 2.425 | w2v_ctc_loss 1.331 | task_loss 4.661 | contrastive_loss 0.302 | total 4003.4 | n_correct 2663 | ppl 5.37 | accuracy 66.518 | uer 17.891 | wer 20.104 | raw_wer 20.104 | bleu 22.07 | wps 1986.7 | wpb 4003.4 | bsz 141.8 | num_updates 27993 | best_bleu 22.3
2023-08-13 05:41:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 27993 updates
2023-08-13 05:41:30 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.0706.pt
2023-08-13 05:41:33 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.0706.pt
2023-08-13 05:41:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.0706.pt (epoch 19 @ 27993 updates, score 22.07) (writing took 21.960061069577932 seconds)
2023-08-13 05:41:52 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-08-13 05:41:52 | INFO | train | epoch 019 | loss 1.965 | trans_loss 4.857 | nll_loss 2.085 | w2v_ctc_loss 0.68 | task_loss 1.407 | contrastive_loss 0.141 | total 4138.56 | n_correct 2778.88 | ppl 4.24 | accuracy 67.146 | wps 11335.8 | ups 1.37 | wpb 8277.1 | bsz 305.6 | num_updates 27993 | lr 8.4526e-05 | gnorm 0.526 | clip 0 | loss_scale 16 | train_wall 1014 | gb_free 17.1 | wall 24156
2023-08-13 05:41:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 05:41:52 | INFO | fairseq.trainer | begin training epoch 20
2023-08-13 05:41:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 05:42:05 | INFO | train_inner | epoch 020:      7 / 1474 loss=1.965, trans_loss=4.853, nll_loss=2.08, w2v_ctc_loss=0.674, task_loss=1.418, contrastive_loss=0.179, total=4119.08, n_correct=2769.24, ppl=4.23, accuracy=67.23, wps=6603.9, ups=0.8, wpb=8238.2, bsz=304.1, num_updates=28000, lr=8.45154e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=24169
2023-08-13 05:42:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 05:42:28 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.965 | trans_loss 5.163 | nll_loss 2.425 | w2v_ctc_loss 1.34 | task_loss 4.671 | contrastive_loss 0.297 | total 4003.4 | n_correct 2665.4 | ppl 5.37 | accuracy 66.578 | uer 17.832 | wer 20.051 | raw_wer 20.051 | bleu 22.22 | wps 2163.5 | wpb 4003.4 | bsz 141.8 | num_updates 28000 | best_bleu 22.3
2023-08-13 05:42:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 28000 updates
2023-08-13 05:42:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-13 05:42:32 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_20_28000.pt
2023-08-13 05:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_20_28000.pt (epoch 20 @ 28000 updates, score 22.22) (writing took 39.88900672644377 seconds)
2023-08-13 05:44:18 | INFO | train_inner | epoch 020:    107 / 1474 loss=1.947, trans_loss=4.835, nll_loss=2.056, w2v_ctc_loss=0.665, task_loss=1.359, contrastive_loss=0.103, total=4195.03, n_correct=2835, ppl=4.16, accuracy=67.58, wps=6272.6, ups=0.75, wpb=8390.1, bsz=313.7, num_updates=28100, lr=8.43649e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=14.7, wall=24302
2023-08-13 05:45:28 | INFO | train_inner | epoch 020:    207 / 1474 loss=1.956, trans_loss=4.84, nll_loss=2.062, w2v_ctc_loss=0.671, task_loss=1.458, contrastive_loss=0.158, total=4154.14, n_correct=2803, ppl=4.18, accuracy=67.475, wps=11922.9, ups=1.44, wpb=8308.3, bsz=301, num_updates=28200, lr=8.42152e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=16.9, wall=24372
2023-08-13 05:46:38 | INFO | train_inner | epoch 020:    307 / 1474 loss=1.945, trans_loss=4.836, nll_loss=2.058, w2v_ctc_loss=0.671, task_loss=1.272, contrastive_loss=0.093, total=4188.05, n_correct=2831.04, ppl=4.16, accuracy=67.598, wps=12012.9, ups=1.43, wpb=8376.1, bsz=326.2, num_updates=28300, lr=8.40663e-05, gnorm=0.525, clip=0, loss_scale=16, train_wall=69, gb_free=15.3, wall=24442
2023-08-13 05:47:47 | INFO | train_inner | epoch 020:    407 / 1474 loss=1.947, trans_loss=4.834, nll_loss=2.054, w2v_ctc_loss=0.666, task_loss=1.427, contrastive_loss=0.092, total=4115.16, n_correct=2782.58, ppl=4.15, accuracy=67.618, wps=11903.3, ups=1.45, wpb=8230.3, bsz=297, num_updates=28400, lr=8.39181e-05, gnorm=0.523, clip=0, loss_scale=16, train_wall=69, gb_free=15.2, wall=24511
2023-08-13 05:48:56 | INFO | train_inner | epoch 020:    507 / 1474 loss=1.963, trans_loss=4.85, nll_loss=2.076, w2v_ctc_loss=0.67, task_loss=1.442, contrastive_loss=0.178, total=4108.46, n_correct=2763.84, ppl=4.22, accuracy=67.272, wps=11881.9, ups=1.45, wpb=8216.9, bsz=300.4, num_updates=28500, lr=8.37708e-05, gnorm=0.526, clip=0, loss_scale=16, train_wall=69, gb_free=16.1, wall=24580
2023-08-13 05:50:05 | INFO | train_inner | epoch 020:    607 / 1474 loss=1.965, trans_loss=4.847, nll_loss=2.071, w2v_ctc_loss=0.674, task_loss=1.481, contrastive_loss=0.18, total=4094.9, n_correct=2755.62, ppl=4.2, accuracy=67.294, wps=11888.7, ups=1.45, wpb=8189.8, bsz=296.1, num_updates=28600, lr=8.36242e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=11.5, wall=24649
2023-08-13 05:51:14 | INFO | train_inner | epoch 020:    707 / 1474 loss=1.955, trans_loss=4.848, nll_loss=2.072, w2v_ctc_loss=0.678, task_loss=1.412, contrastive_loss=0.086, total=4140.23, n_correct=2788.62, ppl=4.21, accuracy=67.354, wps=12036, ups=1.45, wpb=8280.5, bsz=300.6, num_updates=28700, lr=8.34784e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=24718
2023-08-13 05:52:23 | INFO | train_inner | epoch 020:    807 / 1474 loss=1.955, trans_loss=4.848, nll_loss=2.074, w2v_ctc_loss=0.681, task_loss=1.398, contrastive_loss=0.089, total=4140.66, n_correct=2790.72, ppl=4.21, accuracy=67.398, wps=12021.8, ups=1.45, wpb=8281.3, bsz=305.6, num_updates=28800, lr=8.33333e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=17.3, wall=24787
2023-08-13 05:53:33 | INFO | train_inner | epoch 020:    907 / 1474 loss=1.988, trans_loss=4.857, nll_loss=2.086, w2v_ctc_loss=0.677, task_loss=1.345, contrastive_loss=0.379, total=4157.15, n_correct=2789.36, ppl=4.24, accuracy=67.098, wps=11887.9, ups=1.43, wpb=8314.3, bsz=322.6, num_updates=28900, lr=8.3189e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=24857
2023-08-13 05:54:42 | INFO | train_inner | epoch 020:   1007 / 1474 loss=1.95, trans_loss=4.846, nll_loss=2.071, w2v_ctc_loss=0.665, task_loss=1.387, contrastive_loss=0.093, total=4171.86, n_correct=2813.49, ppl=4.2, accuracy=67.44, wps=12076, ups=1.45, wpb=8343.7, bsz=308.6, num_updates=29000, lr=8.30455e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=24926
2023-08-13 05:55:51 | INFO | train_inner | epoch 020:   1107 / 1474 loss=1.968, trans_loss=4.848, nll_loss=2.073, w2v_ctc_loss=0.672, task_loss=1.359, contrastive_loss=0.231, total=4162.96, n_correct=2803.98, ppl=4.21, accuracy=67.355, wps=11934.7, ups=1.43, wpb=8325.9, bsz=314.9, num_updates=29100, lr=8.29027e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=24995
2023-08-13 05:57:00 | INFO | train_inner | epoch 020:   1207 / 1474 loss=1.955, trans_loss=4.837, nll_loss=2.059, w2v_ctc_loss=0.685, task_loss=1.541, contrastive_loss=0.082, total=4033.74, n_correct=2721.05, ppl=4.17, accuracy=67.457, wps=11731.5, ups=1.45, wpb=8067.5, bsz=285.2, num_updates=29200, lr=8.27606e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=25064
2023-08-13 05:58:09 | INFO | train_inner | epoch 020:   1307 / 1474 loss=1.954, trans_loss=4.849, nll_loss=2.074, w2v_ctc_loss=0.673, task_loss=1.49, contrastive_loss=0.089, total=4124.42, n_correct=2778.24, ppl=4.21, accuracy=67.361, wps=11921.2, ups=1.45, wpb=8248.8, bsz=297, num_updates=29300, lr=8.26192e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=25133
2023-08-13 05:59:19 | INFO | train_inner | epoch 020:   1407 / 1474 loss=1.955, trans_loss=4.848, nll_loss=2.073, w2v_ctc_loss=0.674, task_loss=1.492, contrastive_loss=0.087, total=4114.1, n_correct=2768.43, ppl=4.21, accuracy=67.291, wps=11902, ups=1.45, wpb=8228.2, bsz=293.7, num_updates=29400, lr=8.24786e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=14.1, wall=25203
2023-08-13 06:00:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 06:00:28 | INFO | dev_st | epoch 020 | valid on 'dev_st' subset | loss 3.949 | trans_loss 5.166 | nll_loss 2.425 | w2v_ctc_loss 1.273 | task_loss 4.635 | contrastive_loss 0.311 | total 4003.4 | n_correct 2662.7 | ppl 5.37 | accuracy 66.511 | uer 17.986 | wer 20.16 | raw_wer 20.16 | bleu 22.34 | wps 2181.4 | wpb 4003.4 | bsz 141.8 | num_updates 29467 | best_bleu 22.34
2023-08-13 06:00:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 29467 updates
2023-08-13 06:00:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 06:00:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 06:01:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 20 @ 29467 updates, score 22.34) (writing took 31.6883101798594 seconds)
2023-08-13 06:01:00 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-08-13 06:01:00 | INFO | train | epoch 020 | loss 1.957 | trans_loss 4.845 | nll_loss 2.069 | w2v_ctc_loss 0.673 | task_loss 1.408 | contrastive_loss 0.139 | total 4138.65 | n_correct 2789.53 | ppl 4.19 | accuracy 67.402 | wps 10624 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 29467 | lr 8.23848e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 1014 | gb_free 15.9 | wall 25304
2023-08-13 06:01:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 06:01:01 | INFO | fairseq.trainer | begin training epoch 21
2023-08-13 06:01:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 06:01:31 | INFO | train_inner | epoch 021:     33 / 1474 loss=1.963, trans_loss=4.845, nll_loss=2.07, w2v_ctc_loss=0.672, task_loss=1.327, contrastive_loss=0.205, total=4155.01, n_correct=2802.13, ppl=4.2, accuracy=67.44, wps=6254.9, ups=0.75, wpb=8310, bsz=317.6, num_updates=29500, lr=8.23387e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=25335
2023-08-13 06:02:41 | INFO | train_inner | epoch 021:    133 / 1474 loss=1.95, trans_loss=4.824, nll_loss=2.042, w2v_ctc_loss=0.66, task_loss=1.329, contrastive_loss=0.197, total=4186.67, n_correct=2838.03, ppl=4.12, accuracy=67.787, wps=12062.5, ups=1.44, wpb=8373.3, bsz=317.4, num_updates=29600, lr=8.21995e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=12.7, wall=25405
2023-08-13 06:03:49 | INFO | train_inner | epoch 021:    233 / 1474 loss=1.938, trans_loss=4.825, nll_loss=2.043, w2v_ctc_loss=0.648, task_loss=1.323, contrastive_loss=0.154, total=4166.37, n_correct=2829.5, ppl=4.12, accuracy=67.913, wps=12168.3, ups=1.46, wpb=8332.7, bsz=315.2, num_updates=29700, lr=8.2061e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=68, gb_free=13.7, wall=25473
2023-08-13 06:04:59 | INFO | train_inner | epoch 021:    333 / 1474 loss=1.95, trans_loss=4.83, nll_loss=2.05, w2v_ctc_loss=0.667, task_loss=1.423, contrastive_loss=0.151, total=4132.25, n_correct=2795.73, ppl=4.14, accuracy=67.656, wps=11832.4, ups=1.43, wpb=8264.5, bsz=305, num_updates=29800, lr=8.19232e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=25543
2023-08-13 06:06:09 | INFO | train_inner | epoch 021:    433 / 1474 loss=1.936, trans_loss=4.826, nll_loss=2.044, w2v_ctc_loss=0.654, task_loss=1.335, contrastive_loss=0.086, total=4195.53, n_correct=2844.03, ppl=4.12, accuracy=67.787, wps=12077.8, ups=1.44, wpb=8391.1, bsz=311.6, num_updates=29900, lr=8.17861e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=25613
2023-08-13 06:07:18 | INFO | train_inner | epoch 021:    533 / 1474 loss=1.938, trans_loss=4.82, nll_loss=2.036, w2v_ctc_loss=0.666, task_loss=1.449, contrastive_loss=0.08, total=4085.05, n_correct=2777.62, ppl=4.1, accuracy=67.995, wps=11857.5, ups=1.45, wpb=8170.1, bsz=296.1, num_updates=30000, lr=8.16497e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=25682
2023-08-13 06:07:18 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 06:07:41 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.952 | trans_loss 5.167 | nll_loss 2.427 | w2v_ctc_loss 1.29 | task_loss 4.643 | contrastive_loss 0.297 | total 4003.4 | n_correct 2668.2 | ppl 5.38 | accuracy 66.648 | uer 17.546 | wer 19.462 | raw_wer 19.462 | bleu 22.42 | wps 2143.3 | wpb 4003.4 | bsz 141.8 | num_updates 30000 | best_bleu 22.42
2023-08-13 06:07:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30000 updates
2023-08-13 06:07:41 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-13 06:07:45 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_21_30000.pt
2023-08-13 06:08:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_21_30000.pt (epoch 21 @ 30000 updates, score 22.42) (writing took 52.514616560190916 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:0')
2023-08-13 06:09:44 | INFO | train_inner | epoch 021:    633 / 1474 loss=1.953, trans_loss=4.826, nll_loss=2.045, w2v_ctc_loss=0.656, task_loss=1.387, contrastive_loss=0.251, total=4220.3, n_correct=2862.83, ppl=4.13, accuracy=67.835, wps=5774.5, ups=0.68, wpb=8440.6, bsz=315.8, num_updates=30100, lr=8.15139e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=25828
2023-08-13 06:10:53 | INFO | train_inner | epoch 021:    733 / 1474 loss=1.949, trans_loss=4.838, nll_loss=2.06, w2v_ctc_loss=0.666, task_loss=1.407, contrastive_loss=0.112, total=4148.18, n_correct=2805.96, ppl=4.17, accuracy=67.643, wps=11957.2, ups=1.44, wpb=8296.4, bsz=308.3, num_updates=30200, lr=8.13788e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=11.5, wall=25897
2023-08-13 06:12:03 | INFO | train_inner | epoch 021:    833 / 1474 loss=1.952, trans_loss=4.841, nll_loss=2.063, w2v_ctc_loss=0.666, task_loss=1.495, contrastive_loss=0.125, total=4062.56, n_correct=2744.93, ppl=4.18, accuracy=67.567, wps=11713, ups=1.44, wpb=8125.1, bsz=293, num_updates=30300, lr=8.12444e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=25966
2023-08-13 06:13:11 | INFO | train_inner | epoch 021:    933 / 1474 loss=1.943, trans_loss=4.831, nll_loss=2.051, w2v_ctc_loss=0.664, task_loss=1.404, contrastive_loss=0.097, total=4103.66, n_correct=2778.74, ppl=4.14, accuracy=67.714, wps=11972.8, ups=1.46, wpb=8207.3, bsz=301.5, num_updates=30400, lr=8.11107e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=16.9, wall=26035
2023-08-13 06:14:20 | INFO | train_inner | epoch 021:   1033 / 1474 loss=1.949, trans_loss=4.841, nll_loss=2.064, w2v_ctc_loss=0.668, task_loss=1.439, contrastive_loss=0.094, total=4100.54, n_correct=2770.9, ppl=4.18, accuracy=67.574, wps=11982.1, ups=1.46, wpb=8201.1, bsz=298.2, num_updates=30500, lr=8.09776e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=17.6, wall=26103
2023-08-13 06:15:29 | INFO | train_inner | epoch 021:   1133 / 1474 loss=1.947, trans_loss=4.831, nll_loss=2.05, w2v_ctc_loss=0.667, task_loss=1.511, contrastive_loss=0.097, total=4119.98, n_correct=2787.75, ppl=4.14, accuracy=67.664, wps=11875.1, ups=1.44, wpb=8240, bsz=294, num_updates=30600, lr=8.08452e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=17.6, wall=26173
2023-08-13 06:16:38 | INFO | train_inner | epoch 021:   1233 / 1474 loss=1.95, trans_loss=4.834, nll_loss=2.055, w2v_ctc_loss=0.664, task_loss=1.327, contrastive_loss=0.151, total=4161.49, n_correct=2812.78, ppl=4.16, accuracy=67.591, wps=12090.1, ups=1.45, wpb=8323, bsz=313, num_updates=30700, lr=8.07134e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=68, gb_free=16.5, wall=26242
2023-08-13 06:17:46 | INFO | train_inner | epoch 021:   1333 / 1474 loss=1.948, trans_loss=4.835, nll_loss=2.057, w2v_ctc_loss=0.667, task_loss=1.363, contrastive_loss=0.111, total=4141.76, n_correct=2801.48, ppl=4.16, accuracy=67.64, wps=12052.5, ups=1.45, wpb=8283.5, bsz=311.7, num_updates=30800, lr=8.05823e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=68, gb_free=17.1, wall=26310
2023-08-13 06:18:56 | INFO | train_inner | epoch 021:   1433 / 1474 loss=1.965, trans_loss=4.843, nll_loss=2.067, w2v_ctc_loss=0.683, task_loss=1.487, contrastive_loss=0.16, total=4127.02, n_correct=2776.78, ppl=4.19, accuracy=67.283, wps=11872.5, ups=1.44, wpb=8254, bsz=302.1, num_updates=30900, lr=8.04518e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=69, gb_free=16.2, wall=26380
2023-08-13 06:19:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:1')
2023-08-13 06:19:48 | INFO | dev_st | epoch 021 | valid on 'dev_st' subset | loss 3.958 | trans_loss 5.165 | nll_loss 2.427 | w2v_ctc_loss 1.313 | task_loss 4.652 | contrastive_loss 0.303 | total 4003.4 | n_correct 2667.7 | ppl 5.38 | accuracy 66.636 | uer 17.641 | wer 19.552 | raw_wer 19.552 | bleu 22.52 | wps 2175.2 | wpb 4003.4 | bsz 141.8 | num_updates 30941 | best_bleu 22.52
2023-08-13 06:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 30941 updates
2023-08-13 06:19:48 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 06:20:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 06:20:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 21 @ 30941 updates, score 22.52) (writing took 27.418336130678654 seconds)
2023-08-13 06:20:16 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-08-13 06:20:16 | INFO | train | epoch 021 | loss 1.948 | trans_loss 4.832 | nll_loss 2.052 | w2v_ctc_loss 0.664 | task_loss 1.406 | contrastive_loss 0.138 | total 4138.65 | n_correct 2801.27 | ppl 4.15 | accuracy 67.686 | wps 10559 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 30941 | lr 8.03985e-05 | gnorm 0.526 | clip 0 | loss_scale 64 | train_wall 1013 | gb_free 15.1 | wall 26460
2023-08-13 06:20:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 06:20:16 | INFO | fairseq.trainer | begin training epoch 22
2023-08-13 06:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 06:21:04 | INFO | train_inner | epoch 022:     59 / 1474 loss=1.938, trans_loss=4.821, nll_loss=2.038, w2v_ctc_loss=0.663, task_loss=1.42, contrastive_loss=0.08, total=4140.16, n_correct=2816.34, ppl=4.11, accuracy=68.025, wps=6479.8, ups=0.78, wpb=8280.3, bsz=300.1, num_updates=31000, lr=8.03219e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=68, gb_free=17.5, wall=26508
2023-08-13 06:22:14 | INFO | train_inner | epoch 022:    159 / 1474 loss=1.94, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.657, task_loss=1.415, contrastive_loss=0.159, total=4115.86, n_correct=2800.39, ppl=4.08, accuracy=68.039, wps=11802, ups=1.43, wpb=8231.7, bsz=309.4, num_updates=31100, lr=8.01927e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=26578
2023-08-13 06:23:23 | INFO | train_inner | epoch 022:    259 / 1474 loss=1.926, trans_loss=4.811, nll_loss=2.025, w2v_ctc_loss=0.644, task_loss=1.277, contrastive_loss=0.092, total=4247.73, n_correct=2896.02, ppl=4.07, accuracy=68.178, wps=12234.4, ups=1.44, wpb=8495.5, bsz=323.2, num_updates=31200, lr=8.00641e-05, gnorm=0.515, clip=0, loss_scale=64, train_wall=69, gb_free=13.5, wall=26647
2023-08-13 06:24:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 06:24:34 | INFO | train_inner | epoch 022:    360 / 1474 loss=1.95, trans_loss=4.82, nll_loss=2.037, w2v_ctc_loss=0.659, task_loss=1.421, contrastive_loss=0.205, total=4186, n_correct=2843.48, ppl=4.1, accuracy=67.928, wps=11827.9, ups=1.41, wpb=8372, bsz=310, num_updates=31300, lr=7.99361e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=70, gb_free=17.3, wall=26718
2023-08-13 06:25:43 | INFO | train_inner | epoch 022:    460 / 1474 loss=1.947, trans_loss=4.823, nll_loss=2.04, w2v_ctc_loss=0.662, task_loss=1.481, contrastive_loss=0.143, total=4132.62, n_correct=2802.82, ppl=4.11, accuracy=67.822, wps=11870.7, ups=1.44, wpb=8265.2, bsz=297.2, num_updates=31400, lr=7.98087e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=26787
2023-08-13 06:26:53 | INFO | train_inner | epoch 022:    560 / 1474 loss=1.936, trans_loss=4.817, nll_loss=2.033, w2v_ctc_loss=0.66, task_loss=1.414, contrastive_loss=0.091, total=4155.5, n_correct=2827.16, ppl=4.09, accuracy=68.034, wps=11882.5, ups=1.43, wpb=8311, bsz=307.3, num_updates=31500, lr=7.96819e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=70, gb_free=16.1, wall=26857
2023-08-13 06:28:02 | INFO | train_inner | epoch 022:    660 / 1474 loss=1.934, trans_loss=4.811, nll_loss=2.026, w2v_ctc_loss=0.645, task_loss=1.331, contrastive_loss=0.172, total=4147.84, n_correct=2827.91, ppl=4.07, accuracy=68.178, wps=12068.8, ups=1.45, wpb=8295.7, bsz=313.1, num_updates=31600, lr=7.95557e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=12.7, wall=26926
2023-08-13 06:29:11 | INFO | train_inner | epoch 022:    760 / 1474 loss=1.934, trans_loss=4.813, nll_loss=2.027, w2v_ctc_loss=0.657, task_loss=1.439, contrastive_loss=0.091, total=4166.89, n_correct=2835.17, ppl=4.08, accuracy=68.04, wps=12045.8, ups=1.45, wpb=8333.8, bsz=304.3, num_updates=31700, lr=7.94301e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=26995
2023-08-13 06:30:22 | INFO | train_inner | epoch 022:    860 / 1474 loss=1.944, trans_loss=4.829, nll_loss=2.049, w2v_ctc_loss=0.666, task_loss=1.53, contrastive_loss=0.08, total=4074.75, n_correct=2754.72, ppl=4.14, accuracy=67.605, wps=11560.8, ups=1.42, wpb=8149.5, bsz=288.4, num_updates=31800, lr=7.93052e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=70, gb_free=17.3, wall=27066
2023-08-13 06:31:31 | INFO | train_inner | epoch 022:    960 / 1474 loss=1.929, trans_loss=4.815, nll_loss=2.03, w2v_ctc_loss=0.649, task_loss=1.412, contrastive_loss=0.078, total=4136.34, n_correct=2815.7, ppl=4.08, accuracy=68.072, wps=11948.6, ups=1.44, wpb=8272.7, bsz=303.7, num_updates=31900, lr=7.91808e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=27135
2023-08-13 06:32:40 | INFO | train_inner | epoch 022:   1060 / 1474 loss=1.946, trans_loss=4.817, nll_loss=2.034, w2v_ctc_loss=0.65, task_loss=1.34, contrastive_loss=0.25, total=4157.21, n_correct=2824.93, ppl=4.09, accuracy=67.953, wps=12064.8, ups=1.45, wpb=8314.4, bsz=315.4, num_updates=32000, lr=7.90569e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=11.7, wall=27204
2023-08-13 06:32:40 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 06:33:03 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.947 | trans_loss 5.159 | nll_loss 2.42 | w2v_ctc_loss 1.29 | task_loss 4.671 | contrastive_loss 0.297 | total 4003.4 | n_correct 2671.8 | ppl 5.35 | accuracy 66.738 | uer 17.564 | wer 19.548 | raw_wer 19.548 | bleu 21.96 | wps 2212.7 | wpb 4003.4 | bsz 141.8 | num_updates 32000 | best_bleu 22.52
2023-08-13 06:33:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32000 updates
2023-08-13 06:33:03 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-13 06:33:07 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_22_32000.pt
2023-08-13 06:33:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_22_32000.pt (epoch 22 @ 32000 updates, score 21.96) (writing took 19.168241495266557 seconds)
2023-08-13 06:34:32 | INFO | train_inner | epoch 022:   1160 / 1474 loss=1.955, trans_loss=4.839, nll_loss=2.061, w2v_ctc_loss=0.671, task_loss=1.465, contrastive_loss=0.132, total=4092.91, n_correct=2762.97, ppl=4.17, accuracy=67.506, wps=7301.8, ups=0.89, wpb=8185.8, bsz=294.3, num_updates=32100, lr=7.89337e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=27316
2023-08-13 06:35:41 | INFO | train_inner | epoch 022:   1260 / 1474 loss=1.944, trans_loss=4.835, nll_loss=2.057, w2v_ctc_loss=0.661, task_loss=1.303, contrastive_loss=0.125, total=4182.65, n_correct=2830.45, ppl=4.16, accuracy=67.671, wps=12080.5, ups=1.44, wpb=8365.3, bsz=323.6, num_updates=32200, lr=7.8811e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=27385
2023-08-13 06:36:50 | INFO | train_inner | epoch 022:   1360 / 1474 loss=1.937, trans_loss=4.818, nll_loss=2.035, w2v_ctc_loss=0.65, task_loss=1.399, contrastive_loss=0.15, total=4071.58, n_correct=2768.45, ppl=4.1, accuracy=67.994, wps=11833, ups=1.45, wpb=8143.2, bsz=300.6, num_updates=32300, lr=7.86889e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=27454
2023-08-13 06:37:59 | INFO | train_inner | epoch 022:   1460 / 1474 loss=1.948, trans_loss=4.834, nll_loss=2.054, w2v_ctc_loss=0.67, task_loss=1.503, contrastive_loss=0.096, total=4077.83, n_correct=2757.11, ppl=4.15, accuracy=67.612, wps=11780.7, ups=1.44, wpb=8155.7, bsz=288, num_updates=32400, lr=7.85674e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=27523
2023-08-13 06:38:09 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 06:38:32 | INFO | dev_st | epoch 022 | valid on 'dev_st' subset | loss 3.942 | trans_loss 5.158 | nll_loss 2.416 | w2v_ctc_loss 1.276 | task_loss 4.657 | contrastive_loss 0.305 | total 4003.4 | n_correct 2674.5 | ppl 5.34 | accuracy 66.806 | uer 17.689 | wer 19.727 | raw_wer 19.727 | bleu 22.32 | wps 2210.7 | wpb 4003.4 | bsz 141.8 | num_updates 32414 | best_bleu 22.52
2023-08-13 06:38:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 32414 updates
2023-08-13 06:38:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.3204.pt
2023-08-13 06:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.3204.pt
2023-08-13 06:38:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.3204.pt (epoch 22 @ 32414 updates, score 22.32) (writing took 18.396154703572392 seconds)
2023-08-13 06:38:51 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-08-13 06:38:51 | INFO | train | epoch 022 | loss 1.94 | trans_loss 4.821 | nll_loss 2.038 | w2v_ctc_loss 0.658 | task_loss 1.409 | contrastive_loss 0.131 | total 4137.49 | n_correct 2810.08 | ppl 4.11 | accuracy 67.918 | wps 10928.6 | ups 1.32 | wpb 8275 | bsz 305.2 | num_updates 32414 | lr 7.85505e-05 | gnorm 0.525 | clip 0 | loss_scale 32 | train_wall 1016 | gb_free 11.3 | wall 27575
2023-08-13 06:38:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 06:38:52 | INFO | fairseq.trainer | begin training epoch 23
2023-08-13 06:38:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 06:39:58 | INFO | train_inner | epoch 023:     86 / 1474 loss=1.931, trans_loss=4.805, nll_loss=2.017, w2v_ctc_loss=0.66, task_loss=1.455, contrastive_loss=0.085, total=4089.8, n_correct=2790.21, ppl=4.05, accuracy=68.224, wps=6877.4, ups=0.84, wpb=8179.6, bsz=299.5, num_updates=32500, lr=7.84465e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=27642
2023-08-13 06:41:08 | INFO | train_inner | epoch 023:    186 / 1474 loss=1.923, trans_loss=4.797, nll_loss=2.006, w2v_ctc_loss=0.644, task_loss=1.479, contrastive_loss=0.083, total=4117.76, n_correct=2817.86, ppl=4.02, accuracy=68.432, wps=11837, ups=1.44, wpb=8235.5, bsz=296, num_updates=32600, lr=7.8326e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=15.2, wall=27712
2023-08-13 06:42:18 | INFO | train_inner | epoch 023:    286 / 1474 loss=1.932, trans_loss=4.811, nll_loss=2.024, w2v_ctc_loss=0.639, task_loss=1.433, contrastive_loss=0.16, total=4144.73, n_correct=2826.45, ppl=4.07, accuracy=68.194, wps=11891.2, ups=1.43, wpb=8289.5, bsz=304, num_updates=32700, lr=7.82062e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=27782
2023-08-13 06:43:26 | INFO | train_inner | epoch 023:    386 / 1474 loss=1.923, trans_loss=4.8, nll_loss=2.01, w2v_ctc_loss=0.646, task_loss=1.448, contrastive_loss=0.075, total=4126.79, n_correct=2819.71, ppl=4.03, accuracy=68.327, wps=11982.1, ups=1.45, wpb=8253.6, bsz=296.4, num_updates=32800, lr=7.80869e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=68, gb_free=16.8, wall=27850
2023-08-13 06:44:36 | INFO | train_inner | epoch 023:    486 / 1474 loss=1.936, trans_loss=4.814, nll_loss=2.028, w2v_ctc_loss=0.654, task_loss=1.377, contrastive_loss=0.133, total=4150.15, n_correct=2824.73, ppl=4.08, accuracy=68.063, wps=12016.8, ups=1.45, wpb=8300.3, bsz=312.1, num_updates=32900, lr=7.79681e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=27920
2023-08-13 06:45:45 | INFO | train_inner | epoch 023:    586 / 1474 loss=1.918, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.64, task_loss=1.325, contrastive_loss=0.081, total=4174.6, n_correct=2857.01, ppl=4.02, accuracy=68.438, wps=11968.9, ups=1.43, wpb=8349.2, bsz=316.3, num_updates=33000, lr=7.78499e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=27989
2023-08-13 06:46:54 | INFO | train_inner | epoch 023:    686 / 1474 loss=1.931, trans_loss=4.809, nll_loss=2.022, w2v_ctc_loss=0.647, task_loss=1.417, contrastive_loss=0.121, total=4136.6, n_correct=2821.86, ppl=4.06, accuracy=68.217, wps=11989.9, ups=1.45, wpb=8273.2, bsz=301.2, num_updates=33100, lr=7.77322e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=17.4, wall=28058
2023-08-13 06:48:03 | INFO | train_inner | epoch 023:    786 / 1474 loss=1.932, trans_loss=4.812, nll_loss=2.026, w2v_ctc_loss=0.653, task_loss=1.422, contrastive_loss=0.1, total=4147.22, n_correct=2823.95, ppl=4.07, accuracy=68.093, wps=12047.7, ups=1.45, wpb=8294.4, bsz=305.1, num_updates=33200, lr=7.76151e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=68, gb_free=17, wall=28127
2023-08-13 06:49:12 | INFO | train_inner | epoch 023:    886 / 1474 loss=1.933, trans_loss=4.807, nll_loss=2.021, w2v_ctc_loss=0.646, task_loss=1.274, contrastive_loss=0.181, total=4193.16, n_correct=2863.07, ppl=4.06, accuracy=68.28, wps=12154, ups=1.45, wpb=8386.3, bsz=327.3, num_updates=33300, lr=7.74984e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=28196
2023-08-13 06:50:22 | INFO | train_inner | epoch 023:    986 / 1474 loss=1.947, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.641, task_loss=1.401, contrastive_loss=0.335, total=4164.33, n_correct=2837.61, ppl=4.06, accuracy=68.141, wps=11958.7, ups=1.44, wpb=8328.7, bsz=310.1, num_updates=33400, lr=7.73823e-05, gnorm=0.519, clip=0, loss_scale=64, train_wall=69, gb_free=17.4, wall=28266
2023-08-13 06:51:32 | INFO | train_inner | epoch 023:   1086 / 1474 loss=1.937, trans_loss=4.815, nll_loss=2.029, w2v_ctc_loss=0.662, task_loss=1.507, contrastive_loss=0.088, total=4088.37, n_correct=2782.05, ppl=4.08, accuracy=68.048, wps=11710.1, ups=1.43, wpb=8176.7, bsz=289.6, num_updates=33500, lr=7.72667e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=69, gb_free=15.3, wall=28336
2023-08-13 06:52:41 | INFO | train_inner | epoch 023:   1186 / 1474 loss=1.931, trans_loss=4.817, nll_loss=2.033, w2v_ctc_loss=0.655, task_loss=1.398, contrastive_loss=0.081, total=4162.3, n_correct=2828.95, ppl=4.09, accuracy=67.966, wps=12015.9, ups=1.44, wpb=8324.6, bsz=309, num_updates=33600, lr=7.71517e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=15.3, wall=28405
2023-08-13 06:53:50 | INFO | train_inner | epoch 023:   1286 / 1474 loss=1.924, trans_loss=4.81, nll_loss=2.024, w2v_ctc_loss=0.643, task_loss=1.371, contrastive_loss=0.09, total=4131.74, n_correct=2818.49, ppl=4.07, accuracy=68.216, wps=11989, ups=1.45, wpb=8263.5, bsz=308.7, num_updates=33700, lr=7.70371e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=68, gb_free=16.8, wall=28474
2023-08-13 06:55:00 | INFO | train_inner | epoch 023:   1386 / 1474 loss=1.943, trans_loss=4.824, nll_loss=2.042, w2v_ctc_loss=0.655, task_loss=1.421, contrastive_loss=0.149, total=4141.25, n_correct=2810.22, ppl=4.12, accuracy=67.859, wps=11894.9, ups=1.44, wpb=8282.5, bsz=304.7, num_updates=33800, lr=7.69231e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=69, gb_free=16.5, wall=28543
2023-08-13 06:55:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 06:56:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 06:56:24 | INFO | dev_st | epoch 023 | valid on 'dev_st' subset | loss 3.963 | trans_loss 5.156 | nll_loss 2.415 | w2v_ctc_loss 1.35 | task_loss 4.655 | contrastive_loss 0.301 | total 4003.4 | n_correct 2676.6 | ppl 5.33 | accuracy 66.858 | uer 17.907 | wer 19.899 | raw_wer 19.899 | bleu 22.35 | wps 2166.3 | wpb 4003.4 | bsz 141.8 | num_updates 33887 | best_bleu 22.52
2023-08-13 06:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 33887 updates
2023-08-13 06:56:24 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.3507.pt
2023-08-13 06:56:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.3507.pt
2023-08-13 06:56:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.3507.pt (epoch 23 @ 33887 updates, score 22.35) (writing took 21.558350950479507 seconds)
2023-08-13 06:56:46 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-08-13 06:56:46 | INFO | train | epoch 023 | loss 1.932 | trans_loss 4.81 | nll_loss 2.023 | w2v_ctc_loss 0.649 | task_loss 1.411 | contrastive_loss 0.126 | total 4136.71 | n_correct 2819.98 | ppl 4.06 | accuracy 68.17 | wps 11343.6 | ups 1.37 | wpb 8273.4 | bsz 305 | num_updates 33887 | lr 7.68243e-05 | gnorm 0.527 | clip 0 | loss_scale 32 | train_wall 1015 | gb_free 13.3 | wall 28650
2023-08-13 06:56:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 06:56:46 | INFO | fairseq.trainer | begin training epoch 24
2023-08-13 06:56:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 06:57:03 | INFO | train_inner | epoch 024:     13 / 1474 loss=1.936, trans_loss=4.818, nll_loss=2.035, w2v_ctc_loss=0.652, task_loss=1.463, contrastive_loss=0.11, total=4062.78, n_correct=2763.45, ppl=4.1, accuracy=68.019, wps=6596, ups=0.81, wpb=8125.6, bsz=295.2, num_updates=33900, lr=7.68095e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=70, gb_free=12.2, wall=28667
2023-08-13 06:58:12 | INFO | train_inner | epoch 024:    113 / 1474 loss=1.93, trans_loss=4.792, nll_loss=2, w2v_ctc_loss=0.633, task_loss=1.298, contrastive_loss=0.242, total=4171.44, n_correct=2856.87, ppl=4, accuracy=68.486, wps=12015.5, ups=1.44, wpb=8342.9, bsz=324.6, num_updates=34000, lr=7.66965e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=28736
2023-08-13 06:58:12 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 06:58:36 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.946 | trans_loss 5.163 | nll_loss 2.418 | w2v_ctc_loss 1.283 | task_loss 4.665 | contrastive_loss 0.299 | total 4003.4 | n_correct 2670.7 | ppl 5.34 | accuracy 66.711 | uer 17.445 | wer 19.433 | raw_wer 19.433 | bleu 22.29 | wps 2161.4 | wpb 4003.4 | bsz 141.8 | num_updates 34000 | best_bleu 22.52
2023-08-13 06:58:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 34000 updates
2023-08-13 06:58:36 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-13 06:58:40 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_24_34000.pt
2023-08-13 06:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_24_34000.pt (epoch 24 @ 34000 updates, score 22.29) (writing took 42.412146516144276 seconds)
2023-08-13 07:00:28 | INFO | train_inner | epoch 024:    213 / 1474 loss=1.933, trans_loss=4.797, nll_loss=2.007, w2v_ctc_loss=0.627, task_loss=1.233, contrastive_loss=0.297, total=4251.29, n_correct=2912.31, ppl=4.02, accuracy=68.504, wps=6237.8, ups=0.73, wpb=8502.6, bsz=340.8, num_updates=34100, lr=7.6584e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=28872
2023-08-13 07:01:37 | INFO | train_inner | epoch 024:    313 / 1474 loss=1.917, trans_loss=4.794, nll_loss=2.002, w2v_ctc_loss=0.641, task_loss=1.378, contrastive_loss=0.077, total=4128.18, n_correct=2828.31, ppl=4.01, accuracy=68.512, wps=11993.2, ups=1.45, wpb=8256.4, bsz=305.5, num_updates=34200, lr=7.64719e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=68, gb_free=15.9, wall=28941
2023-08-13 07:02:47 | INFO | train_inner | epoch 024:    413 / 1474 loss=1.944, trans_loss=4.801, nll_loss=2.011, w2v_ctc_loss=0.652, task_loss=1.472, contrastive_loss=0.222, total=4158.92, n_correct=2837.89, ppl=4.03, accuracy=68.236, wps=11967.9, ups=1.44, wpb=8317.8, bsz=299.7, num_updates=34300, lr=7.63604e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=29011
2023-08-13 07:03:57 | INFO | train_inner | epoch 024:    513 / 1474 loss=1.928, trans_loss=4.796, nll_loss=2.005, w2v_ctc_loss=0.645, task_loss=1.43, contrastive_loss=0.149, total=4144.91, n_correct=2835.85, ppl=4.01, accuracy=68.418, wps=11843.1, ups=1.43, wpb=8289.8, bsz=303.3, num_updates=34400, lr=7.62493e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=70, gb_free=16.7, wall=29081
2023-08-13 07:05:06 | INFO | train_inner | epoch 024:    613 / 1474 loss=1.921, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.636, task_loss=1.414, contrastive_loss=0.109, total=4165.3, n_correct=2851.99, ppl=4.02, accuracy=68.47, wps=12052.7, ups=1.45, wpb=8330.6, bsz=307.7, num_updates=34500, lr=7.61387e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.3, wall=29150
2023-08-13 07:06:15 | INFO | train_inner | epoch 024:    713 / 1474 loss=1.929, trans_loss=4.805, nll_loss=2.017, w2v_ctc_loss=0.644, task_loss=1.45, contrastive_loss=0.122, total=4102.21, n_correct=2799.72, ppl=4.05, accuracy=68.249, wps=11804.5, ups=1.44, wpb=8204.4, bsz=295.1, num_updates=34600, lr=7.60286e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=29219
2023-08-13 07:07:25 | INFO | train_inner | epoch 024:    813 / 1474 loss=1.924, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.641, task_loss=1.418, contrastive_loss=0.096, total=4110.6, n_correct=2805.77, ppl=4.06, accuracy=68.257, wps=11813.2, ups=1.44, wpb=8221.2, bsz=305.3, num_updates=34700, lr=7.5919e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=29289
2023-08-13 07:08:34 | INFO | train_inner | epoch 024:    913 / 1474 loss=1.93, trans_loss=4.805, nll_loss=2.016, w2v_ctc_loss=0.654, task_loss=1.561, contrastive_loss=0.074, total=4043.03, n_correct=2754.11, ppl=4.05, accuracy=68.12, wps=11759.1, ups=1.45, wpb=8086.1, bsz=281, num_updates=34800, lr=7.58098e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=68, gb_free=10.8, wall=29358
2023-08-13 07:09:43 | INFO | train_inner | epoch 024:   1013 / 1474 loss=1.922, trans_loss=4.805, nll_loss=2.016, w2v_ctc_loss=0.641, task_loss=1.454, contrastive_loss=0.077, total=4136.81, n_correct=2829.65, ppl=4.05, accuracy=68.402, wps=11896.3, ups=1.44, wpb=8273.6, bsz=298.4, num_updates=34900, lr=7.57011e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=29427
2023-08-13 07:10:53 | INFO | train_inner | epoch 024:   1113 / 1474 loss=1.923, trans_loss=4.792, nll_loss=2.001, w2v_ctc_loss=0.647, task_loss=1.355, contrastive_loss=0.119, total=4135.73, n_correct=2833, ppl=4, accuracy=68.501, wps=11817.9, ups=1.43, wpb=8271.5, bsz=308.9, num_updates=35000, lr=7.55929e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=70, gb_free=16.8, wall=29497
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:0')
2023-08-13 07:12:02 | INFO | train_inner | epoch 024:   1213 / 1474 loss=1.925, trans_loss=4.803, nll_loss=2.015, w2v_ctc_loss=0.642, task_loss=1.392, contrastive_loss=0.11, total=4148.3, n_correct=2836.87, ppl=4.04, accuracy=68.386, wps=12002.9, ups=1.45, wpb=8296.6, bsz=310.8, num_updates=35100, lr=7.54851e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=29566
2023-08-13 07:13:12 | INFO | train_inner | epoch 024:   1313 / 1474 loss=1.931, trans_loss=4.808, nll_loss=2.021, w2v_ctc_loss=0.658, task_loss=1.494, contrastive_loss=0.082, total=4110.05, n_correct=2803.4, ppl=4.06, accuracy=68.208, wps=11803.4, ups=1.44, wpb=8220.1, bsz=294.3, num_updates=35200, lr=7.53778e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=29636
2023-08-13 07:14:21 | INFO | train_inner | epoch 024:   1413 / 1474 loss=1.929, trans_loss=4.807, nll_loss=2.021, w2v_ctc_loss=0.656, task_loss=1.473, contrastive_loss=0.081, total=4090.91, n_correct=2790.18, ppl=4.06, accuracy=68.204, wps=11855.5, ups=1.45, wpb=8181.8, bsz=292.7, num_updates=35300, lr=7.5271e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=29705
2023-08-13 07:15:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:7')
2023-08-13 07:15:26 | INFO | dev_st | epoch 024 | valid on 'dev_st' subset | loss 3.937 | trans_loss 5.159 | nll_loss 2.418 | w2v_ctc_loss 1.259 | task_loss 4.649 | contrastive_loss 0.302 | total 4003.4 | n_correct 2681.4 | ppl 5.34 | accuracy 66.978 | uer 17.331 | wer 19.421 | raw_wer 19.421 | bleu 22.29 | wps 2214.8 | wpb 4003.4 | bsz 141.8 | num_updates 35361 | best_bleu 22.52
2023-08-13 07:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 35361 updates
2023-08-13 07:15:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.2905.pt
2023-08-13 07:15:41 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.2905.pt
2023-08-13 07:15:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.2905.pt (epoch 24 @ 35361 updates, score 22.29) (writing took 27.594521578401327 seconds)
2023-08-13 07:15:54 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-08-13 07:15:54 | INFO | train | epoch 024 | loss 1.927 | trans_loss 4.801 | nll_loss 2.012 | w2v_ctc_loss 0.643 | task_loss 1.406 | contrastive_loss 0.133 | total 4138.65 | n_correct 2829.17 | ppl 4.03 | accuracy 68.36 | wps 10624.9 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 35361 | lr 7.5206e-05 | gnorm 0.526 | clip 0 | loss_scale 32 | train_wall 1016 | gb_free 15.9 | wall 29798
2023-08-13 07:15:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 07:15:55 | INFO | fairseq.trainer | begin training epoch 25
2023-08-13 07:15:55 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 07:16:29 | INFO | train_inner | epoch 025:     39 / 1474 loss=1.914, trans_loss=4.793, nll_loss=2.002, w2v_ctc_loss=0.636, task_loss=1.346, contrastive_loss=0.087, total=4166.95, n_correct=2859.54, ppl=4.01, accuracy=68.624, wps=6540.3, ups=0.78, wpb=8333.9, bsz=312, num_updates=35400, lr=7.51646e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=29833
2023-08-13 07:17:38 | INFO | train_inner | epoch 025:    139 / 1474 loss=1.907, trans_loss=4.779, nll_loss=1.983, w2v_ctc_loss=0.629, task_loss=1.376, contrastive_loss=0.084, total=4133.64, n_correct=2846.78, ppl=3.95, accuracy=68.869, wps=11956.2, ups=1.45, wpb=8267.3, bsz=307.7, num_updates=35500, lr=7.50587e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=29902
2023-08-13 07:18:47 | INFO | train_inner | epoch 025:    239 / 1474 loss=1.912, trans_loss=4.784, nll_loss=1.989, w2v_ctc_loss=0.634, task_loss=1.443, contrastive_loss=0.089, total=4114.53, n_correct=2825.12, ppl=3.97, accuracy=68.662, wps=11848.6, ups=1.44, wpb=8229.1, bsz=302.7, num_updates=35600, lr=7.49532e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=29971
2023-08-13 07:19:57 | INFO | train_inner | epoch 025:    339 / 1474 loss=1.919, trans_loss=4.786, nll_loss=1.991, w2v_ctc_loss=0.636, task_loss=1.497, contrastive_loss=0.118, total=4148.7, n_correct=2846.86, ppl=3.98, accuracy=68.621, wps=11864.2, ups=1.43, wpb=8297.4, bsz=295.1, num_updates=35700, lr=7.48481e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=30041
2023-08-13 07:21:07 | INFO | train_inner | epoch 025:    439 / 1474 loss=1.935, trans_loss=4.788, nll_loss=1.995, w2v_ctc_loss=0.651, task_loss=1.462, contrastive_loss=0.196, total=4167.03, n_correct=2857.68, ppl=3.99, accuracy=68.578, wps=11943.9, ups=1.43, wpb=8334.1, bsz=298.3, num_updates=35800, lr=7.47435e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=11.9, wall=30111
2023-08-13 07:22:16 | INFO | train_inner | epoch 025:    539 / 1474 loss=1.919, trans_loss=4.799, nll_loss=2.008, w2v_ctc_loss=0.64, task_loss=1.379, contrastive_loss=0.088, total=4156.93, n_correct=2845.6, ppl=4.02, accuracy=68.454, wps=11964.1, ups=1.44, wpb=8313.9, bsz=312.8, num_updates=35900, lr=7.46393e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=69, gb_free=16.7, wall=30180
2023-08-13 07:23:25 | INFO | train_inner | epoch 025:    639 / 1474 loss=1.922, trans_loss=4.783, nll_loss=1.989, w2v_ctc_loss=0.644, task_loss=1.396, contrastive_loss=0.158, total=4153.23, n_correct=2851.07, ppl=3.97, accuracy=68.647, wps=12033.5, ups=1.45, wpb=8306.5, bsz=309.6, num_updates=36000, lr=7.45356e-05, gnorm=0.537, clip=0, loss_scale=64, train_wall=69, gb_free=14.5, wall=30249
2023-08-13 07:23:25 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 07:23:49 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.945 | trans_loss 5.164 | nll_loss 2.421 | w2v_ctc_loss 1.274 | task_loss 4.647 | contrastive_loss 0.302 | total 4003.4 | n_correct 2675.3 | ppl 5.36 | accuracy 66.826 | uer 17.336 | wer 19.261 | raw_wer 19.261 | bleu 22.42 | wps 2222.9 | wpb 4003.4 | bsz 141.8 | num_updates 36000 | best_bleu 22.52
2023-08-13 07:23:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36000 updates
2023-08-13 07:23:49 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-13 07:23:53 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_25_36000.pt
2023-08-13 07:24:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_25_36000.pt (epoch 25 @ 36000 updates, score 22.42) (writing took 42.94810410775244 seconds)
2023-08-13 07:25:45 | INFO | train_inner | epoch 025:    739 / 1474 loss=1.924, trans_loss=4.787, nll_loss=1.994, w2v_ctc_loss=0.639, task_loss=1.423, contrastive_loss=0.149, total=4123.21, n_correct=2828.57, ppl=3.98, accuracy=68.601, wps=5903.9, ups=0.72, wpb=8246.4, bsz=300.7, num_updates=36100, lr=7.44323e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=69, gb_free=14.4, wall=30389
2023-08-13 07:26:54 | INFO | train_inner | epoch 025:    839 / 1474 loss=1.912, trans_loss=4.791, nll_loss=1.999, w2v_ctc_loss=0.634, task_loss=1.29, contrastive_loss=0.096, total=4197.27, n_correct=2880.69, ppl=4, accuracy=68.632, wps=12195.6, ups=1.45, wpb=8394.5, bsz=328.2, num_updates=36200, lr=7.43294e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=68, gb_free=15.9, wall=30458
2023-08-13 07:28:03 | INFO | train_inner | epoch 025:    939 / 1474 loss=1.923, trans_loss=4.792, nll_loss=2.002, w2v_ctc_loss=0.64, task_loss=1.355, contrastive_loss=0.154, total=4137.23, n_correct=2834.34, ppl=4, accuracy=68.508, wps=11920.4, ups=1.44, wpb=8274.5, bsz=313.3, num_updates=36300, lr=7.4227e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=69, gb_free=16.3, wall=30527
2023-08-13 07:29:13 | INFO | train_inner | epoch 025:   1039 / 1474 loss=1.931, trans_loss=4.798, nll_loss=2.008, w2v_ctc_loss=0.629, task_loss=1.39, contrastive_loss=0.265, total=4183.45, n_correct=2864.19, ppl=4.02, accuracy=68.465, wps=12079, ups=1.44, wpb=8366.9, bsz=311, num_updates=36400, lr=7.41249e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=30597
2023-08-13 07:30:22 | INFO | train_inner | epoch 025:   1139 / 1474 loss=1.912, trans_loss=4.788, nll_loss=1.995, w2v_ctc_loss=0.63, task_loss=1.512, contrastive_loss=0.072, total=4045.24, n_correct=2776.44, ppl=3.99, accuracy=68.635, wps=11637.5, ups=1.44, wpb=8090.5, bsz=287, num_updates=36500, lr=7.40233e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=16.1, wall=30666
2023-08-13 07:31:30 | INFO | train_inner | epoch 025:   1239 / 1474 loss=1.917, trans_loss=4.797, nll_loss=2.006, w2v_ctc_loss=0.637, task_loss=1.442, contrastive_loss=0.076, total=4079.17, n_correct=2795.24, ppl=4.02, accuracy=68.525, wps=11999.1, ups=1.47, wpb=8158.3, bsz=292.3, num_updates=36600, lr=7.39221e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=68, gb_free=16.7, wall=30734
2023-08-13 07:32:40 | INFO | train_inner | epoch 025:   1339 / 1474 loss=1.926, trans_loss=4.793, nll_loss=2.002, w2v_ctc_loss=0.64, task_loss=1.358, contrastive_loss=0.178, total=4173.55, n_correct=2859.88, ppl=4.01, accuracy=68.524, wps=12017, ups=1.44, wpb=8347.1, bsz=312.7, num_updates=36700, lr=7.38213e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=69, gb_free=16.5, wall=30804
2023-08-13 07:33:49 | INFO | train_inner | epoch 025:   1439 / 1474 loss=1.928, trans_loss=4.804, nll_loss=2.015, w2v_ctc_loss=0.643, task_loss=1.461, contrastive_loss=0.124, total=4102.27, n_correct=2799.37, ppl=4.04, accuracy=68.24, wps=11847.2, ups=1.44, wpb=8204.5, bsz=299.9, num_updates=36800, lr=7.3721e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=69, gb_free=15.6, wall=30873
2023-08-13 07:34:13 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 07:34:37 | INFO | dev_st | epoch 025 | valid on 'dev_st' subset | loss 3.935 | trans_loss 5.157 | nll_loss 2.414 | w2v_ctc_loss 1.26 | task_loss 4.623 | contrastive_loss 0.297 | total 4003.4 | n_correct 2678.7 | ppl 5.33 | accuracy 66.911 | uer 17.113 | wer 19.227 | raw_wer 19.227 | bleu 22.69 | wps 2213.9 | wpb 4003.4 | bsz 141.8 | num_updates 36835 | best_bleu 22.69
2023-08-13 07:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 36835 updates
2023-08-13 07:34:37 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 07:34:52 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt
2023-08-13 07:35:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_best.pt (epoch 25 @ 36835 updates, score 22.69) (writing took 28.916100587695837 seconds)
2023-08-13 07:35:06 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-08-13 07:35:06 | INFO | train | epoch 025 | loss 1.92 | trans_loss 4.791 | nll_loss 1.999 | w2v_ctc_loss 0.638 | task_loss 1.406 | contrastive_loss 0.131 | total 4138.65 | n_correct 2837.74 | ppl 4 | accuracy 68.567 | wps 10591.3 | ups 1.28 | wpb 8277.3 | bsz 305.7 | num_updates 36835 | lr 7.36859e-05 | gnorm 0.527 | clip 0 | loss_scale 64 | train_wall 1015 | gb_free 14 | wall 30950
2023-08-13 07:35:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 07:35:06 | INFO | fairseq.trainer | begin training epoch 26
2023-08-13 07:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 07:35:59 | INFO | train_inner | epoch 026:     65 / 1474 loss=1.907, trans_loss=4.776, nll_loss=1.98, w2v_ctc_loss=0.627, task_loss=1.331, contrastive_loss=0.109, total=4178.19, n_correct=2878.78, ppl=3.94, accuracy=68.9, wps=6440.5, ups=0.77, wpb=8356.4, bsz=317.5, num_updates=36900, lr=7.3621e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=13.9, wall=31003
2023-08-13 07:37:08 | INFO | train_inner | epoch 026:    165 / 1474 loss=1.922, trans_loss=4.779, nll_loss=1.984, w2v_ctc_loss=0.618, task_loss=1.234, contrastive_loss=0.292, total=4269.55, n_correct=2941.87, ppl=3.96, accuracy=68.904, wps=12247.6, ups=1.43, wpb=8539.1, bsz=341.4, num_updates=37000, lr=7.35215e-05, gnorm=0.518, clip=0, loss_scale=64, train_wall=69, gb_free=15, wall=31072
2023-08-13 07:38:17 | INFO | train_inner | epoch 026:    265 / 1474 loss=1.918, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.637, task_loss=1.393, contrastive_loss=0.172, total=4128.39, n_correct=2841.62, ppl=3.94, accuracy=68.831, wps=11946.6, ups=1.45, wpb=8256.8, bsz=306.8, num_updates=37100, lr=7.34223e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=9.6, wall=31141
2023-08-13 07:39:27 | INFO | train_inner | epoch 026:    365 / 1474 loss=1.912, trans_loss=4.777, nll_loss=1.981, w2v_ctc_loss=0.631, task_loss=1.349, contrastive_loss=0.124, total=4166.22, n_correct=2871.22, ppl=3.95, accuracy=68.917, wps=12063.4, ups=1.45, wpb=8332.4, bsz=315, num_updates=37200, lr=7.33236e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=31211
2023-08-13 07:40:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 07:40:37 | INFO | train_inner | epoch 026:    466 / 1474 loss=1.912, trans_loss=4.769, nll_loss=1.971, w2v_ctc_loss=0.628, task_loss=1.35, contrastive_loss=0.171, total=4164.93, n_correct=2874.21, ppl=3.92, accuracy=69.01, wps=11865.3, ups=1.42, wpb=8329.9, bsz=313.7, num_updates=37300, lr=7.32252e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=70, gb_free=17.5, wall=31281
2023-08-13 07:41:47 | INFO | train_inner | epoch 026:    566 / 1474 loss=1.917, trans_loss=4.783, nll_loss=1.988, w2v_ctc_loss=0.645, task_loss=1.421, contrastive_loss=0.094, total=4155.02, n_correct=2855.01, ppl=3.97, accuracy=68.712, wps=11912.7, ups=1.43, wpb=8310, bsz=303.9, num_updates=37400, lr=7.31272e-05, gnorm=0.528, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=31350
2023-08-13 07:42:56 | INFO | train_inner | epoch 026:    666 / 1474 loss=1.908, trans_loss=4.78, nll_loss=1.985, w2v_ctc_loss=0.627, task_loss=1.434, contrastive_loss=0.078, total=4136.96, n_correct=2841.71, ppl=3.96, accuracy=68.691, wps=11882.1, ups=1.44, wpb=8273.9, bsz=299.2, num_updates=37500, lr=7.30297e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=15.1, wall=31420
2023-08-13 07:44:05 | INFO | train_inner | epoch 026:    766 / 1474 loss=1.923, trans_loss=4.784, nll_loss=1.989, w2v_ctc_loss=0.632, task_loss=1.429, contrastive_loss=0.192, total=4086.28, n_correct=2806.1, ppl=3.97, accuracy=68.671, wps=11886.3, ups=1.45, wpb=8172.6, bsz=298.5, num_updates=37600, lr=7.29325e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=68, gb_free=14.8, wall=31489
2023-08-13 07:45:14 | INFO | train_inner | epoch 026:    866 / 1474 loss=1.913, trans_loss=4.779, nll_loss=1.983, w2v_ctc_loss=0.638, task_loss=1.393, contrastive_loss=0.091, total=4183.26, n_correct=2875.65, ppl=3.95, accuracy=68.742, wps=12104, ups=1.45, wpb=8366.5, bsz=308.1, num_updates=37700, lr=7.28357e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=31558
2023-08-13 07:46:24 | INFO | train_inner | epoch 026:    966 / 1474 loss=1.917, trans_loss=4.788, nll_loss=1.995, w2v_ctc_loss=0.624, task_loss=1.456, contrastive_loss=0.146, total=4137.96, n_correct=2839.99, ppl=3.99, accuracy=68.633, wps=11834.3, ups=1.43, wpb=8275.9, bsz=299, num_updates=37800, lr=7.27393e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=31628
2023-08-13 07:47:33 | INFO | train_inner | epoch 026:   1066 / 1474 loss=1.909, trans_loss=4.78, nll_loss=1.985, w2v_ctc_loss=0.631, task_loss=1.476, contrastive_loss=0.077, total=4120.53, n_correct=2837.67, ppl=3.96, accuracy=68.867, wps=11888.2, ups=1.44, wpb=8241.1, bsz=294.3, num_updates=37900, lr=7.26433e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=31697
2023-08-13 07:48:43 | INFO | train_inner | epoch 026:   1166 / 1474 loss=1.918, trans_loss=4.789, nll_loss=1.996, w2v_ctc_loss=0.635, task_loss=1.473, contrastive_loss=0.119, total=4113.86, n_correct=2822.18, ppl=3.99, accuracy=68.602, wps=11831.5, ups=1.44, wpb=8227.7, bsz=298.5, num_updates=38000, lr=7.25476e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=16.3, wall=31767
2023-08-13 07:48:43 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 07:49:06 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.948 | trans_loss 5.16 | nll_loss 2.418 | w2v_ctc_loss 1.299 | task_loss 4.677 | contrastive_loss 0.293 | total 4003.4 | n_correct 2673.7 | ppl 5.35 | accuracy 66.786 | uer 17.378 | wer 19.276 | raw_wer 19.276 | bleu 22.41 | wps 2209.3 | wpb 4003.4 | bsz 141.8 | num_updates 38000 | best_bleu 22.69
2023-08-13 07:49:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38000 updates
2023-08-13 07:49:06 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-13 07:49:10 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_26_38000.pt
2023-08-13 07:49:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_26_38000.pt (epoch 26 @ 38000 updates, score 22.41) (writing took 21.983971064910293 seconds)
2023-08-13 07:50:39 | INFO | train_inner | epoch 026:   1266 / 1474 loss=1.925, trans_loss=4.798, nll_loss=2.007, w2v_ctc_loss=0.652, task_loss=1.572, contrastive_loss=0.08, total=3996.19, n_correct=2734.7, ppl=4.02, accuracy=68.433, wps=6894.9, ups=0.86, wpb=7992.4, bsz=279.3, num_updates=38100, lr=7.24524e-05, gnorm=0.536, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=31883
2023-08-13 07:51:49 | INFO | train_inner | epoch 026:   1366 / 1474 loss=1.91, trans_loss=4.789, nll_loss=1.997, w2v_ctc_loss=0.626, task_loss=1.402, contrastive_loss=0.092, total=4159.74, n_correct=2861.48, ppl=3.99, accuracy=68.79, wps=11807.2, ups=1.42, wpb=8319.5, bsz=311.4, num_updates=38200, lr=7.23575e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=70, gb_free=17, wall=31953
2023-08-13 07:52:58 | INFO | train_inner | epoch 026:   1466 / 1474 loss=1.904, trans_loss=4.783, nll_loss=1.989, w2v_ctc_loss=0.623, task_loss=1.333, contrastive_loss=0.086, total=4165.66, n_correct=2870.08, ppl=3.97, accuracy=68.899, wps=12069.3, ups=1.45, wpb=8331.3, bsz=317.5, num_updates=38300, lr=7.22629e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=16, wall=32022
2023-08-13 07:53:04 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 07:53:27 | INFO | dev_st | epoch 026 | valid on 'dev_st' subset | loss 3.947 | trans_loss 5.161 | nll_loss 2.42 | w2v_ctc_loss 1.288 | task_loss 4.656 | contrastive_loss 0.299 | total 4003.4 | n_correct 2671.8 | ppl 5.35 | accuracy 66.738 | uer 17.214 | wer 19.145 | raw_wer 19.145 | bleu 22.62 | wps 2177.8 | wpb 4003.4 | bsz 141.8 | num_updates 38308 | best_bleu 22.69
2023-08-13 07:53:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 38308 updates
2023-08-13 07:53:27 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6205.pt
2023-08-13 07:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6205.pt
2023-08-13 07:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6205.pt (epoch 26 @ 38308 updates, score 22.62) (writing took 20.788315081968904 seconds)
2023-08-13 07:53:48 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-08-13 07:53:48 | INFO | train | epoch 026 | loss 1.914 | trans_loss 4.781 | nll_loss 1.987 | w2v_ctc_loss 0.631 | task_loss 1.408 | contrastive_loss 0.129 | total 4138.63 | n_correct 2846.83 | ppl 3.96 | accuracy 68.787 | wps 10867.9 | ups 1.31 | wpb 8277.3 | bsz 305.6 | num_updates 38308 | lr 7.22554e-05 | gnorm 0.528 | clip 0 | loss_scale 32 | train_wall 1017 | gb_free 15.7 | wall 32072
2023-08-13 07:53:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 07:53:48 | INFO | fairseq.trainer | begin training epoch 27
2023-08-13 07:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 07:54:59 | INFO | train_inner | epoch 027:     92 / 1474 loss=1.894, trans_loss=4.753, nll_loss=1.948, w2v_ctc_loss=0.616, task_loss=1.514, contrastive_loss=0.068, total=4054.57, n_correct=2811.32, ppl=3.86, accuracy=69.337, wps=6708.9, ups=0.83, wpb=8109.1, bsz=282.4, num_updates=38400, lr=7.21688e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=32143
2023-08-13 07:56:09 | INFO | train_inner | epoch 027:    192 / 1474 loss=1.899, trans_loss=4.763, nll_loss=1.963, w2v_ctc_loss=0.624, task_loss=1.337, contrastive_loss=0.093, total=4195.2, n_correct=2900.29, ppl=3.9, accuracy=69.134, wps=12075.7, ups=1.44, wpb=8390.4, bsz=323.2, num_updates=38500, lr=7.2075e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=32213
2023-08-13 07:57:19 | INFO | train_inner | epoch 027:    292 / 1474 loss=1.899, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.622, task_loss=1.408, contrastive_loss=0.079, total=4162.23, n_correct=2879.86, ppl=3.91, accuracy=69.19, wps=11902.3, ups=1.43, wpb=8324.5, bsz=305.5, num_updates=38600, lr=7.19816e-05, gnorm=0.521, clip=0, loss_scale=32, train_wall=70, gb_free=16.9, wall=32283
2023-08-13 07:58:28 | INFO | train_inner | epoch 027:    392 / 1474 loss=1.92, trans_loss=4.772, nll_loss=1.974, w2v_ctc_loss=0.621, task_loss=1.474, contrastive_loss=0.262, total=4079.05, n_correct=2811.51, ppl=3.93, accuracy=68.926, wps=11705.2, ups=1.43, wpb=8158.1, bsz=297.1, num_updates=38700, lr=7.18885e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=32352
2023-08-13 07:59:38 | INFO | train_inner | epoch 027:    492 / 1474 loss=1.917, trans_loss=4.781, nll_loss=1.987, w2v_ctc_loss=0.627, task_loss=1.294, contrastive_loss=0.197, total=4243.25, n_correct=2919.4, ppl=3.96, accuracy=68.801, wps=12141.7, ups=1.43, wpb=8486.5, bsz=331, num_updates=38800, lr=7.17958e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=32422
2023-08-13 08:00:47 | INFO | train_inner | epoch 027:    592 / 1474 loss=1.908, trans_loss=4.767, nll_loss=1.969, w2v_ctc_loss=0.628, task_loss=1.365, contrastive_loss=0.135, total=4137.92, n_correct=2856.2, ppl=3.91, accuracy=69.025, wps=12020.7, ups=1.45, wpb=8275.8, bsz=313.5, num_updates=38900, lr=7.17035e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=68, gb_free=15.6, wall=32491
2023-08-13 08:01:57 | INFO | train_inner | epoch 027:    692 / 1474 loss=1.911, trans_loss=4.776, nll_loss=1.979, w2v_ctc_loss=0.631, task_loss=1.412, contrastive_loss=0.115, total=4158.48, n_correct=2865.9, ppl=3.94, accuracy=68.917, wps=11959.3, ups=1.44, wpb=8317, bsz=304.1, num_updates=39000, lr=7.16115e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=32561
2023-08-13 08:03:05 | INFO | train_inner | epoch 027:    792 / 1474 loss=1.908, trans_loss=4.775, nll_loss=1.978, w2v_ctc_loss=0.632, task_loss=1.495, contrastive_loss=0.078, total=4100.88, n_correct=2822.17, ppl=3.94, accuracy=68.819, wps=11978.6, ups=1.46, wpb=8201.8, bsz=292.2, num_updates=39100, lr=7.15199e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=15.4, wall=32629
2023-08-13 08:04:14 | INFO | train_inner | epoch 027:    892 / 1474 loss=1.901, trans_loss=4.777, nll_loss=1.98, w2v_ctc_loss=0.618, task_loss=1.453, contrastive_loss=0.072, total=4111.94, n_correct=2838.96, ppl=3.94, accuracy=69.042, wps=11861.2, ups=1.44, wpb=8223.9, bsz=294.9, num_updates=39200, lr=7.14286e-05, gnorm=0.529, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=32698
2023-08-13 08:05:24 | INFO | train_inner | epoch 027:    992 / 1474 loss=1.918, trans_loss=4.774, nll_loss=1.978, w2v_ctc_loss=0.623, task_loss=1.368, contrastive_loss=0.257, total=4189.27, n_correct=2889.04, ppl=3.94, accuracy=68.963, wps=11985.8, ups=1.43, wpb=8378.5, bsz=314.9, num_updates=39300, lr=7.13376e-05, gnorm=0.516, clip=0, loss_scale=32, train_wall=69, gb_free=14, wall=32768
2023-08-13 08:06:34 | INFO | train_inner | epoch 027:   1092 / 1474 loss=1.898, trans_loss=4.77, nll_loss=1.971, w2v_ctc_loss=0.617, task_loss=1.399, contrastive_loss=0.089, total=4160.42, n_correct=2872.59, ppl=3.92, accuracy=69.046, wps=11913.3, ups=1.43, wpb=8320.8, bsz=307.3, num_updates=39400, lr=7.1247e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=16.7, wall=32838
2023-08-13 08:07:43 | INFO | train_inner | epoch 027:   1192 / 1474 loss=1.912, trans_loss=4.777, nll_loss=1.98, w2v_ctc_loss=0.639, task_loss=1.475, contrastive_loss=0.093, total=4103.72, n_correct=2825.3, ppl=3.95, accuracy=68.847, wps=11886.5, ups=1.45, wpb=8207.4, bsz=297.1, num_updates=39500, lr=7.11568e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=69, gb_free=17.4, wall=32907
2023-08-13 08:08:52 | INFO | train_inner | epoch 027:   1292 / 1474 loss=1.918, trans_loss=4.782, nll_loss=1.987, w2v_ctc_loss=0.632, task_loss=1.503, contrastive_loss=0.144, total=4065.94, n_correct=2793.74, ppl=3.97, accuracy=68.711, wps=11829.2, ups=1.45, wpb=8131.9, bsz=292.4, num_updates=39600, lr=7.10669e-05, gnorm=0.538, clip=0, loss_scale=64, train_wall=68, gb_free=15.8, wall=32976
2023-08-13 08:10:00 | INFO | train_inner | epoch 027:   1392 / 1474 loss=1.903, trans_loss=4.775, nll_loss=1.978, w2v_ctc_loss=0.617, task_loss=1.328, contrastive_loss=0.125, total=4149.21, n_correct=2862.18, ppl=3.94, accuracy=68.981, wps=12213, ups=1.47, wpb=8298.4, bsz=312.6, num_updates=39700, lr=7.09773e-05, gnorm=0.515, clip=0, loss_scale=64, train_wall=68, gb_free=16.6, wall=33044
2023-08-13 08:10:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 08:11:21 | INFO | dev_st | epoch 027 | valid on 'dev_st' subset | loss 3.946 | trans_loss 5.159 | nll_loss 2.417 | w2v_ctc_loss 1.294 | task_loss 4.65 | contrastive_loss 0.294 | total 4003.4 | n_correct 2679.3 | ppl 5.34 | accuracy 66.926 | uer 17.286 | wer 19.47 | raw_wer 19.47 | bleu 22.46 | wps 2025 | wpb 4003.4 | bsz 141.8 | num_updates 39782 | best_bleu 22.69
2023-08-13 08:11:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 39782 updates
2023-08-13 08:11:21 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.4608.pt
2023-08-13 08:11:25 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.4608.pt
2023-08-13 08:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.4608.pt (epoch 27 @ 39782 updates, score 22.46) (writing took 20.717465583235025 seconds)
2023-08-13 08:11:42 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-08-13 08:11:42 | INFO | train | epoch 027 | loss 1.907 | trans_loss 4.772 | nll_loss 1.974 | w2v_ctc_loss 0.624 | task_loss 1.407 | contrastive_loss 0.128 | total 4138.65 | n_correct 2855.17 | ppl 3.93 | accuracy 68.988 | wps 11360 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 39782 | lr 7.09042e-05 | gnorm 0.528 | clip 0 | loss_scale 64 | train_wall 1014 | gb_free 17.5 | wall 33146
2023-08-13 08:11:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 08:11:42 | INFO | fairseq.trainer | begin training epoch 28
2023-08-13 08:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 08:12:01 | INFO | train_inner | epoch 028:     18 / 1474 loss=1.896, trans_loss=4.767, nll_loss=1.969, w2v_ctc_loss=0.618, task_loss=1.362, contrastive_loss=0.079, total=4106.72, n_correct=2838.94, ppl=3.91, accuracy=69.129, wps=6759.3, ups=0.82, wpb=8213.4, bsz=305, num_updates=39800, lr=7.08881e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=68, gb_free=15.8, wall=33165
2023-08-13 08:13:10 | INFO | train_inner | epoch 028:    118 / 1474 loss=1.89, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.616, task_loss=1.477, contrastive_loss=0.075, total=4103.42, n_correct=2853.82, ppl=3.84, accuracy=69.547, wps=11975.8, ups=1.46, wpb=8206.8, bsz=292, num_updates=39900, lr=7.07992e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=68, gb_free=15.8, wall=33234
2023-08-13 08:14:19 | INFO | train_inner | epoch 028:    218 / 1474 loss=1.89, trans_loss=4.756, nll_loss=1.954, w2v_ctc_loss=0.613, task_loss=1.315, contrastive_loss=0.082, total=4200.12, n_correct=2914.06, ppl=3.87, accuracy=69.38, wps=12150.1, ups=1.45, wpb=8400.2, bsz=317.8, num_updates=40000, lr=7.07107e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=10.6, wall=33303
2023-08-13 08:14:19 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 08:14:43 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.949 | trans_loss 5.163 | nll_loss 2.422 | w2v_ctc_loss 1.291 | task_loss 4.618 | contrastive_loss 0.301 | total 4003.4 | n_correct 2672.9 | ppl 5.36 | accuracy 66.766 | uer 17.854 | wer 20.063 | raw_wer 20.063 | bleu 22.46 | wps 2197.7 | wpb 4003.4 | bsz 141.8 | num_updates 40000 | best_bleu 22.69
2023-08-13 08:14:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 40000 updates
2023-08-13 08:14:43 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-13 08:14:46 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_28_40000.pt
2023-08-13 08:15:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_28_40000.pt (epoch 28 @ 40000 updates, score 22.46) (writing took 41.48923405446112 seconds)
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:0')
2023-08-13 08:16:35 | INFO | train_inner | epoch 028:    318 / 1474 loss=1.929, trans_loss=4.768, nll_loss=1.968, w2v_ctc_loss=0.611, task_loss=1.398, contrastive_loss=0.415, total=4147.36, n_correct=2860.47, ppl=3.91, accuracy=68.971, wps=6121, ups=0.74, wpb=8294.7, bsz=315.4, num_updates=40100, lr=7.06225e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=33439
2023-08-13 08:17:44 | INFO | train_inner | epoch 028:    418 / 1474 loss=1.897, trans_loss=4.757, nll_loss=1.955, w2v_ctc_loss=0.625, task_loss=1.454, contrastive_loss=0.07, total=4087.34, n_correct=2832.53, ppl=3.88, accuracy=69.3, wps=11855.6, ups=1.45, wpb=8174.7, bsz=295.1, num_updates=40200, lr=7.05346e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=16.5, wall=33508
2023-08-13 08:18:52 | INFO | train_inner | epoch 028:    518 / 1474 loss=1.897, trans_loss=4.762, nll_loss=1.96, w2v_ctc_loss=0.617, task_loss=1.46, contrastive_loss=0.082, total=4099.71, n_correct=2838.3, ppl=3.89, accuracy=69.232, wps=11916.1, ups=1.45, wpb=8199.4, bsz=296.2, num_updates=40300, lr=7.0447e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=68, gb_free=14.9, wall=33576
2023-08-13 08:20:02 | INFO | train_inner | epoch 028:    618 / 1474 loss=1.901, trans_loss=4.77, nll_loss=1.972, w2v_ctc_loss=0.623, task_loss=1.426, contrastive_loss=0.082, total=4177.06, n_correct=2883.62, ppl=3.92, accuracy=69.035, wps=11987.4, ups=1.43, wpb=8354.1, bsz=304.1, num_updates=40400, lr=7.03598e-05, gnorm=0.523, clip=0, loss_scale=64, train_wall=69, gb_free=17, wall=33646
2023-08-13 08:21:11 | INFO | train_inner | epoch 028:    718 / 1474 loss=1.907, trans_loss=4.771, nll_loss=1.973, w2v_ctc_loss=0.616, task_loss=1.264, contrastive_loss=0.19, total=4190.74, n_correct=2894.65, ppl=3.93, accuracy=69.073, wps=12214, ups=1.46, wpb=8381.5, bsz=328.5, num_updates=40500, lr=7.02728e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=68, gb_free=15.2, wall=33715
2023-08-13 08:22:19 | INFO | train_inner | epoch 028:    818 / 1474 loss=1.892, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.615, task_loss=1.388, contrastive_loss=0.074, total=4091.75, n_correct=2836.71, ppl=3.9, accuracy=69.328, wps=11894.4, ups=1.45, wpb=8183.5, bsz=306, num_updates=40600, lr=7.01862e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=68, gb_free=16.2, wall=33783
2023-08-13 08:23:29 | INFO | train_inner | epoch 028:    918 / 1474 loss=1.909, trans_loss=4.769, nll_loss=1.97, w2v_ctc_loss=0.625, task_loss=1.445, contrastive_loss=0.136, total=4123.89, n_correct=2844.86, ppl=3.92, accuracy=68.985, wps=11833.7, ups=1.43, wpb=8247.8, bsz=301, num_updates=40700, lr=7.01e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=69, gb_free=16.9, wall=33853
2023-08-13 08:24:38 | INFO | train_inner | epoch 028:   1018 / 1474 loss=1.916, trans_loss=4.77, nll_loss=1.972, w2v_ctc_loss=0.63, task_loss=1.368, contrastive_loss=0.189, total=4176.06, n_correct=2879.19, ppl=3.92, accuracy=68.945, wps=12054.7, ups=1.44, wpb=8352.1, bsz=311.4, num_updates=40800, lr=7.0014e-05, gnorm=0.545, clip=0, loss_scale=64, train_wall=69, gb_free=16.6, wall=33922
2023-08-13 08:25:48 | INFO | train_inner | epoch 028:   1118 / 1474 loss=1.895, trans_loss=4.761, nll_loss=1.961, w2v_ctc_loss=0.616, task_loss=1.371, contrastive_loss=0.093, total=4206.08, n_correct=2910.9, ppl=3.89, accuracy=69.207, wps=12180.8, ups=1.45, wpb=8412.2, bsz=317.3, num_updates=40900, lr=6.99284e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=17, wall=33992
2023-08-13 08:26:57 | INFO | train_inner | epoch 028:   1218 / 1474 loss=1.895, trans_loss=4.767, nll_loss=1.968, w2v_ctc_loss=0.615, task_loss=1.382, contrastive_loss=0.082, total=4109.72, n_correct=2842.19, ppl=3.91, accuracy=69.158, wps=11830.6, ups=1.44, wpb=8219.4, bsz=306.9, num_updates=41000, lr=6.9843e-05, gnorm=0.54, clip=0, loss_scale=64, train_wall=69, gb_free=15.8, wall=34061
2023-08-13 08:28:06 | INFO | train_inner | epoch 028:   1318 / 1474 loss=1.91, trans_loss=4.771, nll_loss=1.972, w2v_ctc_loss=0.633, task_loss=1.535, contrastive_loss=0.096, total=4085.44, n_correct=2816.54, ppl=3.92, accuracy=68.941, wps=11779.6, ups=1.44, wpb=8170.9, bsz=285.6, num_updates=41100, lr=6.9758e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=69, gb_free=16, wall=34130
2023-08-13 08:29:16 | INFO | train_inner | epoch 028:   1418 / 1474 loss=1.905, trans_loss=4.767, nll_loss=1.967, w2v_ctc_loss=0.622, task_loss=1.492, contrastive_loss=0.118, total=4137.47, n_correct=2857.54, ppl=3.91, accuracy=69.065, wps=11931.9, ups=1.44, wpb=8274.9, bsz=294.8, num_updates=41200, lr=6.96733e-05, gnorm=0.52, clip=0, loss_scale=64, train_wall=69, gb_free=16.6, wall=34200
2023-08-13 08:29:54 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:2')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:5')
2023-08-13 08:30:17 | INFO | dev_st | epoch 028 | valid on 'dev_st' subset | loss 3.952 | trans_loss 5.165 | nll_loss 2.423 | w2v_ctc_loss 1.296 | task_loss 4.635 | contrastive_loss 0.303 | total 4003.4 | n_correct 2677.7 | ppl 5.36 | accuracy 66.886 | uer 17.498 | wer 19.522 | raw_wer 19.522 | bleu 22.6 | wps 2206.2 | wpb 4003.4 | bsz 141.8 | num_updates 41256 | best_bleu 22.69
2023-08-13 08:30:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 41256 updates
2023-08-13 08:30:17 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6009.pt
2023-08-13 08:30:21 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6009.pt
2023-08-13 08:30:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6009.pt (epoch 28 @ 41256 updates, score 22.6) (writing took 21.869092848151922 seconds)
2023-08-13 08:30:40 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-08-13 08:30:40 | INFO | train | epoch 028 | loss 1.902 | trans_loss 4.764 | nll_loss 1.964 | w2v_ctc_loss 0.62 | task_loss 1.405 | contrastive_loss 0.127 | total 4138.65 | n_correct 2862.52 | ppl 3.9 | accuracy 69.166 | wps 10726.1 | ups 1.3 | wpb 8277.3 | bsz 305.7 | num_updates 41256 | lr 6.9626e-05 | gnorm 0.528 | clip 0 | loss_scale 64 | train_wall 1012 | gb_free 16.2 | wall 34284
2023-08-13 08:30:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 08:30:40 | INFO | fairseq.trainer | begin training epoch 29
2023-08-13 08:30:40 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 08:31:18 | INFO | train_inner | epoch 029:     44 / 1474 loss=1.895, trans_loss=4.757, nll_loss=1.955, w2v_ctc_loss=0.622, task_loss=1.35, contrastive_loss=0.087, total=4168.25, n_correct=2892.21, ppl=3.88, accuracy=69.387, wps=6842.2, ups=0.82, wpb=8336.5, bsz=315.7, num_updates=41300, lr=6.95889e-05, gnorm=0.525, clip=0, loss_scale=64, train_wall=69, gb_free=17.4, wall=34322
2023-08-13 08:32:27 | INFO | train_inner | epoch 029:    144 / 1474 loss=1.896, trans_loss=4.755, nll_loss=1.951, w2v_ctc_loss=0.615, task_loss=1.38, contrastive_loss=0.116, total=4117.66, n_correct=2859.29, ppl=3.87, accuracy=69.44, wps=11903.9, ups=1.45, wpb=8235.3, bsz=308.4, num_updates=41400, lr=6.95048e-05, gnorm=0.533, clip=0, loss_scale=128, train_wall=69, gb_free=16.9, wall=34391
2023-08-13 08:32:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-13 08:33:37 | INFO | train_inner | epoch 029:    245 / 1474 loss=1.893, trans_loss=4.746, nll_loss=1.941, w2v_ctc_loss=0.6, task_loss=1.296, contrastive_loss=0.187, total=4183.42, n_correct=2910.12, ppl=3.84, accuracy=69.563, wps=11933.8, ups=1.43, wpb=8366.8, bsz=326.1, num_updates=41500, lr=6.9421e-05, gnorm=0.522, clip=0, loss_scale=64, train_wall=70, gb_free=16.8, wall=34461
2023-08-13 08:34:46 | INFO | train_inner | epoch 029:    345 / 1474 loss=1.9, trans_loss=4.764, nll_loss=1.962, w2v_ctc_loss=0.625, task_loss=1.512, contrastive_loss=0.077, total=4092.21, n_correct=2833.66, ppl=3.9, accuracy=69.245, wps=11865.3, ups=1.45, wpb=8184.4, bsz=290.6, num_updates=41600, lr=6.93375e-05, gnorm=0.531, clip=0, loss_scale=64, train_wall=69, gb_free=15.3, wall=34530
2023-08-13 08:35:55 | INFO | train_inner | epoch 029:    445 / 1474 loss=1.881, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.609, task_loss=1.358, contrastive_loss=0.071, total=4161.27, n_correct=2901.19, ppl=3.8, accuracy=69.719, wps=12056, ups=1.45, wpb=8322.5, bsz=307.8, num_updates=41700, lr=6.92543e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=69, gb_free=15.7, wall=34599
2023-08-13 08:36:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 08:37:05 | INFO | train_inner | epoch 029:    546 / 1474 loss=1.901, trans_loss=4.759, nll_loss=1.957, w2v_ctc_loss=0.617, task_loss=1.521, contrastive_loss=0.108, total=4137.09, n_correct=2861.33, ppl=3.88, accuracy=69.163, wps=11809.9, ups=1.43, wpb=8274.2, bsz=290.3, num_updates=41800, lr=6.91714e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=70, gb_free=15.4, wall=34669
2023-08-13 08:38:14 | INFO | train_inner | epoch 029:    646 / 1474 loss=1.899, trans_loss=4.75, nll_loss=1.946, w2v_ctc_loss=0.607, task_loss=1.331, contrastive_loss=0.236, total=4143.02, n_correct=2877.44, ppl=3.85, accuracy=69.453, wps=12003.6, ups=1.45, wpb=8286, bsz=318.6, num_updates=41900, lr=6.90889e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=16.8, wall=34738
2023-08-13 08:39:24 | INFO | train_inner | epoch 029:    746 / 1474 loss=1.893, trans_loss=4.751, nll_loss=1.947, w2v_ctc_loss=0.606, task_loss=1.295, contrastive_loss=0.153, total=4249.79, n_correct=2952.09, ppl=3.85, accuracy=69.464, wps=12170.7, ups=1.43, wpb=8499.6, bsz=330, num_updates=42000, lr=6.90066e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=34808
2023-08-13 08:39:24 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 08:39:47 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.975 | trans_loss 5.163 | nll_loss 2.418 | w2v_ctc_loss 1.381 | task_loss 4.64 | contrastive_loss 0.296 | total 4003.4 | n_correct 2683.8 | ppl 5.35 | accuracy 67.038 | uer 17.888 | wer 19.902 | raw_wer 19.902 | bleu 22.82 | wps 2193.6 | wpb 4003.4 | bsz 141.8 | num_updates 42000 | best_bleu 22.82
2023-08-13 08:39:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42000 updates
2023-08-13 08:39:47 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-13 08:39:50 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_29_42000.pt
2023-08-13 08:40:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_29_42000.pt (epoch 29 @ 42000 updates, score 22.82) (writing took 52.43738898821175 seconds)
2023-08-13 08:41:49 | INFO | train_inner | epoch 029:    846 / 1474 loss=1.899, trans_loss=4.766, nll_loss=1.966, w2v_ctc_loss=0.619, task_loss=1.56, contrastive_loss=0.071, total=4027.19, n_correct=2785.09, ppl=3.91, accuracy=69.157, wps=5531.2, ups=0.69, wpb=8054.4, bsz=280.6, num_updates=42100, lr=6.89246e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=34953
2023-08-13 08:42:58 | INFO | train_inner | epoch 029:    946 / 1474 loss=1.897, trans_loss=4.76, nll_loss=1.959, w2v_ctc_loss=0.622, task_loss=1.432, contrastive_loss=0.082, total=4082.14, n_correct=2828.26, ppl=3.89, accuracy=69.284, wps=11944.4, ups=1.46, wpb=8164.3, bsz=296.3, num_updates=42200, lr=6.88428e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=68, gb_free=15, wall=35022
2023-08-13 08:44:07 | INFO | train_inner | epoch 029:   1046 / 1474 loss=1.894, trans_loss=4.752, nll_loss=1.948, w2v_ctc_loss=0.608, task_loss=1.402, contrastive_loss=0.155, total=4148.18, n_correct=2880.31, ppl=3.86, accuracy=69.436, wps=12011.7, ups=1.45, wpb=8296.4, bsz=308.2, num_updates=42300, lr=6.87614e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=35091
2023-08-13 08:45:16 | INFO | train_inner | epoch 029:   1146 / 1474 loss=1.899, trans_loss=4.765, nll_loss=1.964, w2v_ctc_loss=0.622, task_loss=1.541, contrastive_loss=0.068, total=4063.95, n_correct=2809.77, ppl=3.9, accuracy=69.139, wps=11811.3, ups=1.45, wpb=8127.9, bsz=283, num_updates=42400, lr=6.86803e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=13, wall=35160
2023-08-13 08:46:25 | INFO | train_inner | epoch 029:   1246 / 1474 loss=1.896, trans_loss=4.763, nll_loss=1.962, w2v_ctc_loss=0.62, task_loss=1.428, contrastive_loss=0.075, total=4158.81, n_correct=2876.68, ppl=3.9, accuracy=69.171, wps=12032.4, ups=1.45, wpb=8317.6, bsz=301.2, num_updates=42500, lr=6.85994e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=15.4, wall=35229
2023-08-13 08:47:34 | INFO | train_inner | epoch 029:   1346 / 1474 loss=1.897, trans_loss=4.753, nll_loss=1.95, w2v_ctc_loss=0.611, task_loss=1.382, contrastive_loss=0.137, total=4166.34, n_correct=2888.16, ppl=3.86, accuracy=69.321, wps=11978.3, ups=1.44, wpb=8332.7, bsz=310.7, num_updates=42600, lr=6.85189e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=17.6, wall=35298
2023-08-13 08:48:43 | INFO | train_inner | epoch 029:   1446 / 1474 loss=1.9, trans_loss=4.755, nll_loss=1.953, w2v_ctc_loss=0.616, task_loss=1.379, contrastive_loss=0.166, total=4162.2, n_correct=2885.13, ppl=3.87, accuracy=69.317, wps=12076, ups=1.45, wpb=8324.4, bsz=311.5, num_updates=42700, lr=6.84386e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=17.1, wall=35367
2023-08-13 08:49:03 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 08:49:26 | INFO | dev_st | epoch 029 | valid on 'dev_st' subset | loss 3.953 | trans_loss 5.161 | nll_loss 2.417 | w2v_ctc_loss 1.315 | task_loss 4.681 | contrastive_loss 0.297 | total 4003.4 | n_correct 2678.6 | ppl 5.34 | accuracy 66.908 | uer 17.02 | wer 18.993 | raw_wer 18.993 | bleu 22.61 | wps 2178.5 | wpb 4003.4 | bsz 141.8 | num_updates 42728 | best_bleu 22.82
2023-08-13 08:49:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 42728 updates
2023-08-13 08:49:26 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6101.pt
2023-08-13 08:49:30 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6101.pt
2023-08-13 08:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6101.pt (epoch 29 @ 42728 updates, score 22.61) (writing took 21.935052927583456 seconds)
2023-08-13 08:49:48 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-08-13 08:49:48 | INFO | train | epoch 029 | loss 1.895 | trans_loss 4.755 | nll_loss 1.952 | w2v_ctc_loss 0.614 | task_loss 1.408 | contrastive_loss 0.121 | total 4136.69 | n_correct 2868.89 | ppl 3.87 | accuracy 69.352 | wps 10600.7 | ups 1.28 | wpb 8273.4 | bsz 305.1 | num_updates 42728 | lr 6.84162e-05 | gnorm 0.529 | clip 0 | loss_scale 32 | train_wall 1013 | gb_free 15.8 | wall 35432
2023-08-13 08:49:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 08:49:49 | INFO | fairseq.trainer | begin training epoch 30
2023-08-13 08:49:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 08:50:46 | INFO | train_inner | epoch 030:     72 / 1474 loss=1.892, trans_loss=4.745, nll_loss=1.94, w2v_ctc_loss=0.6, task_loss=1.331, contrastive_loss=0.185, total=4182.65, n_correct=2909.04, ppl=3.84, accuracy=69.55, wps=6819.9, ups=0.82, wpb=8365.3, bsz=320.5, num_updates=42800, lr=6.83586e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=69, gb_free=13.1, wall=35490
2023-08-13 08:51:55 | INFO | train_inner | epoch 030:    172 / 1474 loss=1.884, trans_loss=4.731, nll_loss=1.921, w2v_ctc_loss=0.608, task_loss=1.318, contrastive_loss=0.115, total=4203.05, n_correct=2934.74, ppl=3.79, accuracy=69.824, wps=12149.9, ups=1.45, wpb=8406.1, bsz=318.3, num_updates=42900, lr=6.82789e-05, gnorm=0.522, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=35559
2023-08-13 08:53:03 | INFO | train_inner | epoch 030:    272 / 1474 loss=1.89, trans_loss=4.748, nll_loss=1.942, w2v_ctc_loss=0.618, task_loss=1.45, contrastive_loss=0.071, total=4116.93, n_correct=2865.07, ppl=3.84, accuracy=69.592, wps=12084.4, ups=1.47, wpb=8233.9, bsz=295.1, num_updates=43000, lr=6.81994e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=68, gb_free=16.7, wall=35627
2023-08-13 08:54:13 | INFO | train_inner | epoch 030:    372 / 1474 loss=1.879, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.603, task_loss=1.413, contrastive_loss=0.073, total=4173.13, n_correct=2912.48, ppl=3.8, accuracy=69.791, wps=11971.1, ups=1.43, wpb=8346.3, bsz=305.6, num_updates=43100, lr=6.81203e-05, gnorm=0.519, clip=0, loss_scale=32, train_wall=69, gb_free=11.4, wall=35697
2023-08-13 08:55:21 | INFO | train_inner | epoch 030:    472 / 1474 loss=1.886, trans_loss=4.743, nll_loss=1.937, w2v_ctc_loss=0.6, task_loss=1.34, contrastive_loss=0.135, total=4135.2, n_correct=2876.93, ppl=3.83, accuracy=69.572, wps=12094.5, ups=1.46, wpb=8270.4, bsz=314.8, num_updates=43200, lr=6.80414e-05, gnorm=0.52, clip=0, loss_scale=32, train_wall=68, gb_free=16.6, wall=35765
2023-08-13 08:56:31 | INFO | train_inner | epoch 030:    572 / 1474 loss=1.888, trans_loss=4.746, nll_loss=1.941, w2v_ctc_loss=0.61, task_loss=1.369, contrastive_loss=0.098, total=4168.65, n_correct=2898.27, ppl=3.84, accuracy=69.525, wps=12062.3, ups=1.45, wpb=8337.3, bsz=312.1, num_updates=43300, lr=6.79628e-05, gnorm=0.527, clip=0, loss_scale=32, train_wall=69, gb_free=15.6, wall=35835
2023-08-13 08:57:40 | INFO | train_inner | epoch 030:    672 / 1474 loss=1.891, trans_loss=4.746, nll_loss=1.941, w2v_ctc_loss=0.614, task_loss=1.387, contrastive_loss=0.11, total=4183.65, n_correct=2904.95, ppl=3.84, accuracy=69.436, wps=12122.5, ups=1.45, wpb=8367.3, bsz=314.5, num_updates=43400, lr=6.78844e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=35904
2023-08-13 08:58:49 | INFO | train_inner | epoch 030:    772 / 1474 loss=1.908, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.624, task_loss=1.441, contrastive_loss=0.191, total=4106.9, n_correct=2844.79, ppl=3.86, accuracy=69.269, wps=11773.9, ups=1.43, wpb=8213.8, bsz=302.9, num_updates=43500, lr=6.78064e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=11.5, wall=35973
2023-08-13 08:59:58 | INFO | train_inner | epoch 030:    872 / 1474 loss=1.889, trans_loss=4.749, nll_loss=1.944, w2v_ctc_loss=0.61, task_loss=1.474, contrastive_loss=0.076, total=4089.18, n_correct=2838.98, ppl=3.85, accuracy=69.427, wps=11878, ups=1.45, wpb=8178.4, bsz=291.4, num_updates=43600, lr=6.77285e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=68, gb_free=16.3, wall=36042
2023-08-13 09:01:08 | INFO | train_inner | epoch 030:    972 / 1474 loss=1.892, trans_loss=4.753, nll_loss=1.949, w2v_ctc_loss=0.614, task_loss=1.418, contrastive_loss=0.093, total=4140.03, n_correct=2872.63, ppl=3.86, accuracy=69.387, wps=11919.6, ups=1.44, wpb=8280.1, bsz=303.9, num_updates=43700, lr=6.7651e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=13.5, wall=36112
2023-08-13 09:02:17 | INFO | train_inner | epoch 030:   1072 / 1474 loss=1.906, trans_loss=4.759, nll_loss=1.956, w2v_ctc_loss=0.619, task_loss=1.576, contrastive_loss=0.164, total=4101.12, n_correct=2839.44, ppl=3.88, accuracy=69.236, wps=11795.4, ups=1.44, wpb=8202.2, bsz=282.8, num_updates=43800, lr=6.75737e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=36181
2023-08-13 09:03:27 | INFO | train_inner | epoch 030:   1172 / 1474 loss=1.888, trans_loss=4.746, nll_loss=1.942, w2v_ctc_loss=0.599, task_loss=1.348, contrastive_loss=0.142, total=4168.22, n_correct=2900.85, ppl=3.84, accuracy=69.594, wps=11999.5, ups=1.44, wpb=8336.4, bsz=314.5, num_updates=43900, lr=6.74967e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=69, gb_free=16.5, wall=36251
2023-08-13 09:03:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 09:04:36 | INFO | train_inner | epoch 030:   1273 / 1474 loss=1.895, trans_loss=4.754, nll_loss=1.95, w2v_ctc_loss=0.62, task_loss=1.559, contrastive_loss=0.077, total=4041.34, n_correct=2799.65, ppl=3.86, accuracy=69.275, wps=11602.6, ups=1.44, wpb=8082.7, bsz=283.7, num_updates=44000, lr=6.742e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=69, gb_free=15.5, wall=36320
2023-08-13 09:04:36 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 09:04:59 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.958 | trans_loss 5.159 | nll_loss 2.416 | w2v_ctc_loss 1.336 | task_loss 4.65 | contrastive_loss 0.294 | total 4003.4 | n_correct 2676.2 | ppl 5.34 | accuracy 66.848 | uer 17.588 | wer 19.712 | raw_wer 19.712 | bleu 22.53 | wps 2164.7 | wpb 4003.4 | bsz 141.8 | num_updates 44000 | best_bleu 22.82
2023-08-13 09:04:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44000 updates
2023-08-13 09:04:59 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-13 09:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_30_44000.pt
2023-08-13 09:05:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_30_44000.pt (epoch 30 @ 44000 updates, score 22.53) (writing took 41.01639890484512 seconds)
2023-08-13 09:06:50 | INFO | train_inner | epoch 030:   1373 / 1474 loss=1.885, trans_loss=4.751, nll_loss=1.947, w2v_ctc_loss=0.607, task_loss=1.326, contrastive_loss=0.086, total=4165.07, n_correct=2895.51, ppl=3.86, accuracy=69.519, wps=6217.6, ups=0.75, wpb=8330.1, bsz=321.6, num_updates=44100, lr=6.73435e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=16.4, wall=36454
2023-08-13 09:07:59 | INFO | train_inner | epoch 030:   1473 / 1474 loss=1.898, trans_loss=4.753, nll_loss=1.95, w2v_ctc_loss=0.601, task_loss=1.321, contrastive_loss=0.233, total=4141.76, n_correct=2873.29, ppl=3.87, accuracy=69.374, wps=12028.3, ups=1.45, wpb=8283.5, bsz=314.3, num_updates=44200, lr=6.72673e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=16.1, wall=36523
2023-08-13 09:08:00 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 09:08:23 | INFO | dev_st | epoch 030 | valid on 'dev_st' subset | loss 3.961 | trans_loss 5.16 | nll_loss 2.415 | w2v_ctc_loss 1.342 | task_loss 4.651 | contrastive_loss 0.296 | total 4003.4 | n_correct 2681.7 | ppl 5.33 | accuracy 66.986 | uer 17.44 | wer 19.522 | raw_wer 19.522 | bleu 22.75 | wps 2185.7 | wpb 4003.4 | bsz 141.8 | num_updates 44201 | best_bleu 22.82
2023-08-13 09:08:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 44201 updates
2023-08-13 09:08:23 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.7506.pt
2023-08-13 09:08:27 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.7506.pt
2023-08-13 09:08:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.7506.pt (epoch 30 @ 44201 updates, score 22.75) (writing took 24.16008524224162 seconds)
2023-08-13 09:08:48 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-08-13 09:08:48 | INFO | train | epoch 030 | loss 1.891 | trans_loss 4.748 | nll_loss 1.942 | w2v_ctc_loss 0.61 | task_loss 1.406 | contrastive_loss 0.124 | total 4138.93 | n_correct 2876.36 | ppl 3.84 | accuracy 69.495 | wps 10704.7 | ups 1.29 | wpb 8277.9 | bsz 305.7 | num_updates 44201 | lr 6.72665e-05 | gnorm 0.529 | clip 0 | loss_scale 32 | train_wall 1013 | gb_free 16.9 | wall 36572
2023-08-13 09:08:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 09:08:48 | INFO | fairseq.trainer | begin training epoch 31
2023-08-13 09:08:48 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 09:10:04 | INFO | train_inner | epoch 031:     99 / 1474 loss=1.885, trans_loss=4.738, nll_loss=1.928, w2v_ctc_loss=0.612, task_loss=1.502, contrastive_loss=0.071, total=4054.44, n_correct=2827.19, ppl=3.81, accuracy=69.731, wps=6500.4, ups=0.8, wpb=8108.9, bsz=288.2, num_updates=44300, lr=6.71913e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=69, gb_free=16.2, wall=36648
2023-08-13 09:11:13 | INFO | train_inner | epoch 031:    199 / 1474 loss=1.885, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.607, task_loss=1.44, contrastive_loss=0.099, total=4147.4, n_correct=2891.63, ppl=3.81, accuracy=69.722, wps=12082.3, ups=1.46, wpb=8294.8, bsz=302.2, num_updates=44400, lr=6.71156e-05, gnorm=0.539, clip=0, loss_scale=32, train_wall=68, gb_free=16.5, wall=36717
2023-08-13 09:12:22 | INFO | train_inner | epoch 031:    299 / 1474 loss=1.885, trans_loss=4.732, nll_loss=1.922, w2v_ctc_loss=0.603, task_loss=1.436, contrastive_loss=0.136, total=4149.21, n_correct=2896.82, ppl=3.79, accuracy=69.816, wps=11935.2, ups=1.44, wpb=8298.4, bsz=301.6, num_updates=44500, lr=6.70402e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=15.8, wall=36786
2023-08-13 09:13:32 | INFO | train_inner | epoch 031:    399 / 1474 loss=1.887, trans_loss=4.745, nll_loss=1.938, w2v_ctc_loss=0.608, task_loss=1.536, contrastive_loss=0.075, total=4092.62, n_correct=2850.54, ppl=3.83, accuracy=69.651, wps=11785.4, ups=1.44, wpb=8185.2, bsz=285.6, num_updates=44600, lr=6.6965e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=16.9, wall=36856
2023-08-13 09:14:41 | INFO | train_inner | epoch 031:    499 / 1474 loss=1.888, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.618, task_loss=1.471, contrastive_loss=0.083, total=4111.85, n_correct=2863.17, ppl=3.81, accuracy=69.632, wps=11796.2, ups=1.43, wpb=8223.7, bsz=300.3, num_updates=44700, lr=6.689e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=10.6, wall=36925
2023-08-13 09:15:50 | INFO | train_inner | epoch 031:    599 / 1474 loss=1.878, trans_loss=4.734, nll_loss=1.925, w2v_ctc_loss=0.599, task_loss=1.467, contrastive_loss=0.073, total=4083.44, n_correct=2850.16, ppl=3.8, accuracy=69.798, wps=11834.6, ups=1.45, wpb=8166.9, bsz=294.5, num_updates=44800, lr=6.68153e-05, gnorm=0.526, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=36994
2023-08-13 09:16:59 | INFO | train_inner | epoch 031:    699 / 1474 loss=1.875, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.597, task_loss=1.335, contrastive_loss=0.075, total=4213.98, n_correct=2942.59, ppl=3.8, accuracy=69.829, wps=12227.9, ups=1.45, wpb=8428, bsz=315.7, num_updates=44900, lr=6.67409e-05, gnorm=0.525, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=37063
2023-08-13 09:18:09 | INFO | train_inner | epoch 031:    799 / 1474 loss=1.894, trans_loss=4.746, nll_loss=1.94, w2v_ctc_loss=0.609, task_loss=1.473, contrastive_loss=0.145, total=4097.37, n_correct=2844.57, ppl=3.84, accuracy=69.424, wps=11818.9, ups=1.44, wpb=8194.7, bsz=295.8, num_updates=45000, lr=6.66667e-05, gnorm=0.531, clip=0, loss_scale=32, train_wall=69, gb_free=12.6, wall=37133
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:0')
2023-08-13 09:19:18 | INFO | train_inner | epoch 031:    899 / 1474 loss=1.883, trans_loss=4.732, nll_loss=1.921, w2v_ctc_loss=0.608, task_loss=1.464, contrastive_loss=0.089, total=4096.72, n_correct=2856.79, ppl=3.79, accuracy=69.734, wps=11843, ups=1.45, wpb=8193.4, bsz=296.1, num_updates=45100, lr=6.65927e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=37202
2023-08-13 09:20:27 | INFO | train_inner | epoch 031:    999 / 1474 loss=1.892, trans_loss=4.749, nll_loss=1.944, w2v_ctc_loss=0.603, task_loss=1.327, contrastive_loss=0.171, total=4187.84, n_correct=2912.26, ppl=3.85, accuracy=69.541, wps=12120.9, ups=1.45, wpb=8375.7, bsz=319.5, num_updates=45200, lr=6.6519e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=37271
2023-08-13 09:21:36 | INFO | train_inner | epoch 031:   1099 / 1474 loss=1.885, trans_loss=4.742, nll_loss=1.935, w2v_ctc_loss=0.602, task_loss=1.374, contrastive_loss=0.119, total=4149.44, n_correct=2890.46, ppl=3.82, accuracy=69.659, wps=11955.8, ups=1.44, wpb=8298.9, bsz=315, num_updates=45300, lr=6.64455e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=17.3, wall=37340
2023-08-13 09:22:45 | INFO | train_inner | epoch 031:   1199 / 1474 loss=1.894, trans_loss=4.743, nll_loss=1.937, w2v_ctc_loss=0.601, task_loss=1.316, contrastive_loss=0.236, total=4189.76, n_correct=2917.38, ppl=3.83, accuracy=69.631, wps=12126, ups=1.45, wpb=8379.5, bsz=321.3, num_updates=45400, lr=6.63723e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=12.9, wall=37409
2023-08-13 09:23:55 | INFO | train_inner | epoch 031:   1299 / 1474 loss=1.881, trans_loss=4.746, nll_loss=1.941, w2v_ctc_loss=0.605, task_loss=1.262, contrastive_loss=0.079, total=4227.44, n_correct=2943.61, ppl=3.84, accuracy=69.631, wps=12230.8, ups=1.45, wpb=8454.9, bsz=326.3, num_updates=45500, lr=6.62994e-05, gnorm=0.523, clip=0, loss_scale=32, train_wall=69, gb_free=16.1, wall=37479
2023-08-13 09:25:04 | INFO | train_inner | epoch 031:   1399 / 1474 loss=1.903, trans_loss=4.745, nll_loss=1.94, w2v_ctc_loss=0.603, task_loss=1.289, contrastive_loss=0.284, total=4186.05, n_correct=2910.65, ppl=3.84, accuracy=69.532, wps=12057.3, ups=1.44, wpb=8372.1, bsz=326.6, num_updates=45600, lr=6.62266e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=17.2, wall=37548
2023-08-13 09:25:56 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:6')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:5')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:7')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:1')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:4')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:3')
mt_weight tensor(0.5000)
asr_weight tensor(0.2336, device='cuda:2')
2023-08-13 09:26:20 | INFO | dev_st | epoch 031 | valid on 'dev_st' subset | loss 3.946 | trans_loss 5.158 | nll_loss 2.413 | w2v_ctc_loss 1.301 | task_loss 4.666 | contrastive_loss 0.291 | total 4003.4 | n_correct 2680.2 | ppl 5.33 | accuracy 66.948 | uer 17.126 | wer 19.242 | raw_wer 19.242 | bleu 22.63 | wps 2113.8 | wpb 4003.4 | bsz 141.8 | num_updates 45675 | best_bleu 22.82
2023-08-13 09:26:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 45675 updates
2023-08-13 09:26:20 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6302.pt
2023-08-13 09:26:23 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6302.pt
2023-08-13 09:26:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint.best_bleu_22.6302.pt (epoch 31 @ 45675 updates, score 22.63) (writing took 21.32822433486581 seconds)
2023-08-13 09:26:42 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-08-13 09:26:42 | INFO | train | epoch 031 | loss 1.887 | trans_loss 4.74 | nll_loss 1.933 | w2v_ctc_loss 0.606 | task_loss 1.406 | contrastive_loss 0.123 | total 4138.65 | n_correct 2883.03 | ppl 3.82 | accuracy 69.661 | wps 11359.9 | ups 1.37 | wpb 8277.3 | bsz 305.7 | num_updates 45675 | lr 6.61722e-05 | gnorm 0.532 | clip 0 | loss_scale 32 | train_wall 1014 | gb_free 11.7 | wall 37646
2023-08-13 09:26:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 09:26:42 | INFO | fairseq.trainer | begin training epoch 32
2023-08-13 09:26:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 09:27:06 | INFO | train_inner | epoch 032:     25 / 1474 loss=1.881, trans_loss=4.737, nll_loss=1.929, w2v_ctc_loss=0.606, task_loss=1.482, contrastive_loss=0.069, total=4042.6, n_correct=2818.83, ppl=3.81, accuracy=69.728, wps=6619.2, ups=0.82, wpb=8085.2, bsz=288.7, num_updates=45700, lr=6.61541e-05, gnorm=0.54, clip=0, loss_scale=32, train_wall=68, gb_free=16, wall=37670
2023-08-13 09:28:16 | INFO | train_inner | epoch 032:    125 / 1474 loss=1.862, trans_loss=4.716, nll_loss=1.901, w2v_ctc_loss=0.582, task_loss=1.298, contrastive_loss=0.08, total=4227.68, n_correct=2967.91, ppl=3.73, accuracy=70.202, wps=12100.9, ups=1.43, wpb=8455.4, bsz=323.3, num_updates=45800, lr=6.60819e-05, gnorm=0.517, clip=0, loss_scale=32, train_wall=69, gb_free=15.9, wall=37740
2023-08-13 09:29:26 | INFO | train_inner | epoch 032:    225 / 1474 loss=1.873, trans_loss=4.732, nll_loss=1.923, w2v_ctc_loss=0.595, task_loss=1.334, contrastive_loss=0.088, total=4157.32, n_correct=2905.25, ppl=3.79, accuracy=69.883, wps=11954.6, ups=1.44, wpb=8314.6, bsz=320.6, num_updates=45900, lr=6.60098e-05, gnorm=0.524, clip=0, loss_scale=32, train_wall=69, gb_free=17, wall=37810
2023-08-13 09:30:34 | INFO | train_inner | epoch 032:    325 / 1474 loss=1.866, trans_loss=4.718, nll_loss=1.904, w2v_ctc_loss=0.587, task_loss=1.328, contrastive_loss=0.083, total=4183.45, n_correct=2934.38, ppl=3.74, accuracy=70.143, wps=12157, ups=1.45, wpb=8366.9, bsz=314.4, num_updates=46000, lr=6.5938e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=17.3, wall=37878
2023-08-13 09:30:34 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 09:30:58 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.952 | trans_loss 5.169 | nll_loss 2.424 | w2v_ctc_loss 1.294 | task_loss 4.633 | contrastive_loss 0.299 | total 4003.4 | n_correct 2683 | ppl 5.37 | accuracy 67.018 | uer 17.076 | wer 19.097 | raw_wer 19.097 | bleu 22.33 | wps 2191.5 | wpb 4003.4 | bsz 141.8 | num_updates 46000 | best_bleu 22.82
2023-08-13 09:30:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 46000 updates
2023-08-13 09:30:58 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-13 09:31:02 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_32_46000.pt
2023-08-13 09:31:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_32_46000.pt (epoch 32 @ 46000 updates, score 22.33) (writing took 20.497025437653065 seconds)
2023-08-13 09:32:28 | INFO | train_inner | epoch 032:    425 / 1474 loss=1.872, trans_loss=4.723, nll_loss=1.91, w2v_ctc_loss=0.597, task_loss=1.399, contrastive_loss=0.079, total=4157.28, n_correct=2913.18, ppl=3.76, accuracy=70.074, wps=7324.9, ups=0.88, wpb=8314.6, bsz=305.9, num_updates=46100, lr=6.58665e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=69, gb_free=14.6, wall=37992
2023-08-13 09:33:38 | INFO | train_inner | epoch 032:    525 / 1474 loss=1.889, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.605, task_loss=1.361, contrastive_loss=0.163, total=4198.93, n_correct=2927.78, ppl=3.8, accuracy=69.727, wps=12009.7, ups=1.43, wpb=8397.9, bsz=317.6, num_updates=46200, lr=6.57952e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=38062
2023-08-13 09:34:47 | INFO | train_inner | epoch 032:    625 / 1474 loss=1.879, trans_loss=4.734, nll_loss=1.925, w2v_ctc_loss=0.601, task_loss=1.45, contrastive_loss=0.087, total=4142.69, n_correct=2890.21, ppl=3.8, accuracy=69.767, wps=11943.3, ups=1.44, wpb=8285.4, bsz=301.6, num_updates=46300, lr=6.57241e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=69, gb_free=17.1, wall=38131
2023-08-13 09:35:57 | INFO | train_inner | epoch 032:    725 / 1474 loss=1.882, trans_loss=4.737, nll_loss=1.928, w2v_ctc_loss=0.611, task_loss=1.437, contrastive_loss=0.072, total=4154.59, n_correct=2902.11, ppl=3.81, accuracy=69.853, wps=11922.2, ups=1.43, wpb=8309.2, bsz=301.8, num_updates=46400, lr=6.56532e-05, gnorm=0.527, clip=0, loss_scale=64, train_wall=69, gb_free=15.6, wall=38201
2023-08-13 09:37:05 | INFO | train_inner | epoch 032:    825 / 1474 loss=1.874, trans_loss=4.73, nll_loss=1.918, w2v_ctc_loss=0.595, task_loss=1.449, contrastive_loss=0.07, total=4114.54, n_correct=2878.15, ppl=3.78, accuracy=69.951, wps=12008.6, ups=1.46, wpb=8229.1, bsz=294.9, num_updates=46500, lr=6.55826e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=16.8, wall=38269
2023-08-13 09:38:15 | INFO | train_inner | epoch 032:    925 / 1474 loss=1.874, trans_loss=4.732, nll_loss=1.923, w2v_ctc_loss=0.594, task_loss=1.454, contrastive_loss=0.067, total=4139.67, n_correct=2894.29, ppl=3.79, accuracy=69.916, wps=11885.5, ups=1.44, wpb=8279.3, bsz=298.3, num_updates=46600, lr=6.55122e-05, gnorm=0.53, clip=0, loss_scale=64, train_wall=69, gb_free=16.6, wall=38339
2023-08-13 09:39:24 | INFO | train_inner | epoch 032:   1025 / 1474 loss=1.888, trans_loss=4.739, nll_loss=1.931, w2v_ctc_loss=0.602, task_loss=1.395, contrastive_loss=0.163, total=4119.15, n_correct=2873.45, ppl=3.81, accuracy=69.758, wps=11946, ups=1.45, wpb=8238.3, bsz=304.5, num_updates=46700, lr=6.5442e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=69, gb_free=16.2, wall=38408
2023-08-13 09:40:33 | INFO | train_inner | epoch 032:   1125 / 1474 loss=1.889, trans_loss=4.737, nll_loss=1.927, w2v_ctc_loss=0.607, task_loss=1.656, contrastive_loss=0.103, total=4019.61, n_correct=2798.35, ppl=3.8, accuracy=69.617, wps=11591.6, ups=1.44, wpb=8039.2, bsz=271.4, num_updates=46800, lr=6.5372e-05, gnorm=0.534, clip=0, loss_scale=64, train_wall=69, gb_free=17.4, wall=38477
2023-08-13 09:41:42 | INFO | train_inner | epoch 032:   1225 / 1474 loss=1.896, trans_loss=4.744, nll_loss=1.938, w2v_ctc_loss=0.601, task_loss=1.39, contrastive_loss=0.207, total=4149.28, n_correct=2888.7, ppl=3.83, accuracy=69.619, wps=12033.3, ups=1.45, wpb=8298.6, bsz=310.3, num_updates=46900, lr=6.53023e-05, gnorm=0.533, clip=0, loss_scale=64, train_wall=69, gb_free=15.7, wall=38546
2023-08-13 09:42:51 | INFO | train_inner | epoch 032:   1325 / 1474 loss=1.88, trans_loss=4.736, nll_loss=1.927, w2v_ctc_loss=0.606, task_loss=1.445, contrastive_loss=0.068, total=4079.22, n_correct=2845.47, ppl=3.8, accuracy=69.755, wps=11873.1, ups=1.46, wpb=8158.4, bsz=296.2, num_updates=47000, lr=6.52328e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=68, gb_free=14.8, wall=38615
2023-08-13 09:44:00 | INFO | train_inner | epoch 032:   1425 / 1474 loss=1.903, trans_loss=4.737, nll_loss=1.929, w2v_ctc_loss=0.61, task_loss=1.414, contrastive_loss=0.305, total=4111.41, n_correct=2865.1, ppl=3.81, accuracy=69.687, wps=11926.2, ups=1.45, wpb=8222.8, bsz=306.1, num_updates=47100, lr=6.51635e-05, gnorm=0.535, clip=0, loss_scale=64, train_wall=68, gb_free=15.7, wall=38684
2023-08-13 09:44:33 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 09:44:57 | INFO | dev_st | epoch 032 | valid on 'dev_st' subset | loss 3.957 | trans_loss 5.158 | nll_loss 2.413 | w2v_ctc_loss 1.339 | task_loss 4.641 | contrastive_loss 0.297 | total 4003.4 | n_correct 2682.8 | ppl 5.33 | accuracy 67.013 | uer 17.23 | wer 19.239 | raw_wer 19.239 | bleu 22.39 | wps 2197.7 | wpb 4003.4 | bsz 141.8 | num_updates 47149 | best_bleu 22.82
2023-08-13 09:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 47149 updates
2023-08-13 09:44:57 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-13 09:45:12 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-13 09:45:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_last.pt (epoch 32 @ 47149 updates, score 22.39) (writing took 15.626428367570043 seconds)
2023-08-13 09:45:12 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-08-13 09:45:12 | INFO | train | epoch 032 | loss 1.881 | trans_loss 4.732 | nll_loss 1.922 | w2v_ctc_loss 0.599 | task_loss 1.406 | contrastive_loss 0.122 | total 4138.65 | n_correct 2891 | ppl 3.79 | accuracy 69.854 | wps 10983.3 | ups 1.33 | wpb 8277.3 | bsz 305.7 | num_updates 47149 | lr 6.51297e-05 | gnorm 0.53 | clip 0 | loss_scale 64 | train_wall 1013 | gb_free 16.2 | wall 38756
2023-08-13 09:45:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 09:45:13 | INFO | fairseq.trainer | begin training epoch 33
2023-08-13 09:45:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 09:45:55 | INFO | train_inner | epoch 033:     51 / 1474 loss=1.883, trans_loss=4.735, nll_loss=1.926, w2v_ctc_loss=0.592, task_loss=1.314, contrastive_loss=0.171, total=4156.71, n_correct=2902.57, ppl=3.8, accuracy=69.829, wps=7225.2, ups=0.87, wpb=8313.4, bsz=322.5, num_updates=47200, lr=6.50945e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=68, gb_free=16.2, wall=38799
2023-08-13 09:47:04 | INFO | train_inner | epoch 033:    151 / 1474 loss=1.865, trans_loss=4.715, nll_loss=1.899, w2v_ctc_loss=0.584, task_loss=1.518, contrastive_loss=0.061, total=4071.44, n_correct=2856.9, ppl=3.73, accuracy=70.169, wps=11827.8, ups=1.45, wpb=8142.9, bsz=284.1, num_updates=47300, lr=6.50256e-05, gnorm=0.528, clip=0, loss_scale=64, train_wall=68, gb_free=15.9, wall=38868
2023-08-13 09:48:14 | INFO | train_inner | epoch 033:    251 / 1474 loss=1.884, trans_loss=4.718, nll_loss=1.905, w2v_ctc_loss=0.589, task_loss=1.199, contrastive_loss=0.233, total=4281.28, n_correct=3002.23, ppl=3.75, accuracy=70.125, wps=12278.8, ups=1.43, wpb=8562.6, bsz=346.3, num_updates=47400, lr=6.4957e-05, gnorm=0.526, clip=0, loss_scale=64, train_wall=69, gb_free=16.2, wall=38938
2023-08-13 09:49:23 | INFO | train_inner | epoch 033:    351 / 1474 loss=1.874, trans_loss=4.724, nll_loss=1.912, w2v_ctc_loss=0.596, task_loss=1.444, contrastive_loss=0.086, total=4111.69, n_correct=2879.28, ppl=3.76, accuracy=70.027, wps=11922.6, ups=1.45, wpb=8223.4, bsz=298.4, num_updates=47500, lr=6.48886e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=69, gb_free=16.6, wall=39007
2023-08-13 09:50:31 | INFO | train_inner | epoch 033:    451 / 1474 loss=1.86, trans_loss=4.714, nll_loss=1.898, w2v_ctc_loss=0.585, task_loss=1.322, contrastive_loss=0.068, total=4147.28, n_correct=2914.49, ppl=3.73, accuracy=70.275, wps=12118.4, ups=1.46, wpb=8294.6, bsz=313.5, num_updates=47600, lr=6.48204e-05, gnorm=0.521, clip=0, loss_scale=64, train_wall=68, gb_free=16.4, wall=39075
2023-08-13 09:51:40 | INFO | train_inner | epoch 033:    551 / 1474 loss=1.879, trans_loss=4.727, nll_loss=1.915, w2v_ctc_loss=0.601, task_loss=1.473, contrastive_loss=0.09, total=4127.68, n_correct=2885.36, ppl=3.77, accuracy=69.903, wps=11950.9, ups=1.45, wpb=8255.4, bsz=292.6, num_updates=47700, lr=6.47524e-05, gnorm=0.536, clip=0, loss_scale=64, train_wall=69, gb_free=15.4, wall=39144
2023-08-13 09:52:50 | INFO | train_inner | epoch 033:    651 / 1474 loss=1.882, trans_loss=4.737, nll_loss=1.927, w2v_ctc_loss=0.596, task_loss=1.438, contrastive_loss=0.123, total=4164.1, n_correct=2904.16, ppl=3.8, accuracy=69.743, wps=11997.1, ups=1.44, wpb=8328.2, bsz=302.4, num_updates=47800, lr=6.46846e-05, gnorm=0.532, clip=0, loss_scale=64, train_wall=69, gb_free=15.1, wall=39214
2023-08-13 09:53:59 | INFO | train_inner | epoch 033:    751 / 1474 loss=1.884, trans_loss=4.733, nll_loss=1.923, w2v_ctc_loss=0.613, task_loss=1.539, contrastive_loss=0.069, total=4064.29, n_correct=2834.69, ppl=3.79, accuracy=69.746, wps=11776.8, ups=1.45, wpb=8128.6, bsz=285.8, num_updates=47900, lr=6.46171e-05, gnorm=0.541, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=39283
2023-08-13 09:55:08 | INFO | train_inner | epoch 033:    851 / 1474 loss=1.866, trans_loss=4.719, nll_loss=1.906, w2v_ctc_loss=0.58, task_loss=1.326, contrastive_loss=0.139, total=4141.12, n_correct=2906.72, ppl=3.75, accuracy=70.192, wps=11977.5, ups=1.45, wpb=8282.2, bsz=318.5, num_updates=48000, lr=6.45497e-05, gnorm=0.524, clip=0, loss_scale=64, train_wall=69, gb_free=16.4, wall=39352
2023-08-13 09:55:08 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 09:55:32 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.971 | trans_loss 5.164 | nll_loss 2.42 | w2v_ctc_loss 1.367 | task_loss 4.676 | contrastive_loss 0.296 | total 4003.4 | n_correct 2680.2 | ppl 5.35 | accuracy 66.948 | uer 17.243 | wer 19.19 | raw_wer 19.19 | bleu 22.34 | wps 2180.4 | wpb 4003.4 | bsz 141.8 | num_updates 48000 | best_bleu 22.82
2023-08-13 09:55:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48000 updates
2023-08-13 09:55:32 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-13 09:55:35 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_33_48000.pt
2023-08-13 09:55:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_33_48000.pt (epoch 33 @ 48000 updates, score 22.34) (writing took 20.00533047877252 seconds)
2023-08-13 09:56:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-08-13 09:57:02 | INFO | train_inner | epoch 033:    952 / 1474 loss=1.876, trans_loss=4.728, nll_loss=1.917, w2v_ctc_loss=0.604, task_loss=1.426, contrastive_loss=0.073, total=4135.14, n_correct=2890.12, ppl=3.78, accuracy=69.892, wps=7260.9, ups=0.88, wpb=8270.3, bsz=304, num_updates=48100, lr=6.44826e-05, gnorm=0.529, clip=0, loss_scale=64, train_wall=69, gb_free=10.9, wall=39466
2023-08-13 09:57:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-08-13 09:58:12 | INFO | train_inner | epoch 033:   1053 / 1474 loss=1.871, trans_loss=4.722, nll_loss=1.909, w2v_ctc_loss=0.597, task_loss=1.444, contrastive_loss=0.071, total=4120.84, n_correct=2885.02, ppl=3.75, accuracy=70.01, wps=11715.3, ups=1.42, wpb=8241.7, bsz=300, num_updates=48200, lr=6.44157e-05, gnorm=0.532, clip=0, loss_scale=32, train_wall=70, gb_free=15.4, wall=39536
2023-08-13 09:59:22 | INFO | train_inner | epoch 033:   1153 / 1474 loss=1.883, trans_loss=4.735, nll_loss=1.925, w2v_ctc_loss=0.59, task_loss=1.408, contrastive_loss=0.17, total=4181.58, n_correct=2916.93, ppl=3.8, accuracy=69.757, wps=12040.4, ups=1.44, wpb=8363.2, bsz=310, num_updates=48300, lr=6.43489e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=14.8, wall=39606
2023-08-13 10:00:31 | INFO | train_inner | epoch 033:   1253 / 1474 loss=1.876, trans_loss=4.726, nll_loss=1.914, w2v_ctc_loss=0.603, task_loss=1.477, contrastive_loss=0.072, total=4115.76, n_correct=2880.15, ppl=3.77, accuracy=69.979, wps=11796.9, ups=1.43, wpb=8231.5, bsz=294.7, num_updates=48400, lr=6.42824e-05, gnorm=0.534, clip=0, loss_scale=32, train_wall=69, gb_free=16.5, wall=39675
2023-08-13 10:01:41 | INFO | train_inner | epoch 033:   1353 / 1474 loss=1.873, trans_loss=4.727, nll_loss=1.916, w2v_ctc_loss=0.598, task_loss=1.38, contrastive_loss=0.09, total=4120.69, n_correct=2884.14, ppl=3.77, accuracy=69.992, wps=11828.1, ups=1.44, wpb=8241.4, bsz=311.9, num_updates=48500, lr=6.42161e-05, gnorm=0.543, clip=0, loss_scale=32, train_wall=69, gb_free=16.6, wall=39745
2023-08-13 10:02:50 | INFO | train_inner | epoch 033:   1453 / 1474 loss=1.888, trans_loss=4.73, nll_loss=1.92, w2v_ctc_loss=0.597, task_loss=1.401, contrastive_loss=0.238, total=4125.28, n_correct=2881.1, ppl=3.79, accuracy=69.84, wps=11900.3, ups=1.44, wpb=8250.6, bsz=308.7, num_updates=48600, lr=6.415e-05, gnorm=0.538, clip=0, loss_scale=32, train_wall=69, gb_free=16.7, wall=39814
2023-08-13 10:03:05 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 10:03:28 | INFO | dev_st | epoch 033 | valid on 'dev_st' subset | loss 3.969 | trans_loss 5.164 | nll_loss 2.419 | w2v_ctc_loss 1.364 | task_loss 4.659 | contrastive_loss 0.288 | total 4003.4 | n_correct 2685.3 | ppl 5.35 | accuracy 67.075 | uer 17.416 | wer 19.574 | raw_wer 19.574 | bleu 22.4 | wps 2198.2 | wpb 4003.4 | bsz 141.8 | num_updates 48621 | best_bleu 22.82
2023-08-13 10:03:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 48621 updates
2023-08-13 10:03:28 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-13 10:03:43 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_last.pt
2023-08-13 10:03:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_last.pt (epoch 33 @ 48621 updates, score 22.4) (writing took 15.618056897073984 seconds)
2023-08-13 10:03:44 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-08-13 10:03:44 | INFO | train | epoch 033 | loss 1.876 | trans_loss 4.725 | nll_loss 1.913 | w2v_ctc_loss 0.595 | task_loss 1.409 | contrastive_loss 0.113 | total 4136.64 | n_correct 2894.76 | ppl 3.77 | accuracy 69.978 | wps 10960.4 | ups 1.32 | wpb 8273.3 | bsz 304.9 | num_updates 48621 | lr 6.41362e-05 | gnorm 0.532 | clip 0 | loss_scale 32 | train_wall 1014 | gb_free 17.6 | wall 39868
2023-08-13 10:03:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 1474
2023-08-13 10:03:44 | INFO | fairseq.trainer | begin training epoch 34
2023-08-13 10:03:44 | INFO | fairseq_cli.train | Start iterating over samples
2023-08-13 10:04:46 | INFO | train_inner | epoch 034:     79 / 1474 loss=1.866, trans_loss=4.713, nll_loss=1.898, w2v_ctc_loss=0.592, task_loss=1.393, contrastive_loss=0.074, total=4131.47, n_correct=2901.34, ppl=3.73, accuracy=70.225, wps=7176.9, ups=0.87, wpb=8262.9, bsz=301.7, num_updates=48700, lr=6.40841e-05, gnorm=0.535, clip=0, loss_scale=32, train_wall=68, gb_free=16.4, wall=39930
2023-08-13 10:05:55 | INFO | train_inner | epoch 034:    179 / 1474 loss=1.862, trans_loss=4.705, nll_loss=1.886, w2v_ctc_loss=0.588, task_loss=1.47, contrastive_loss=0.075, total=4065.88, n_correct=2862.63, ppl=3.7, accuracy=70.406, wps=11665.9, ups=1.43, wpb=8131.8, bsz=295.1, num_updates=48800, lr=6.40184e-05, gnorm=0.533, clip=0, loss_scale=32, train_wall=69, gb_free=15.7, wall=39999
2023-08-13 10:07:05 | INFO | train_inner | epoch 034:    279 / 1474 loss=1.89, trans_loss=4.725, nll_loss=1.913, w2v_ctc_loss=0.587, task_loss=1.315, contrastive_loss=0.28, total=4246.3, n_correct=2970.93, ppl=3.76, accuracy=69.965, wps=12171.4, ups=1.43, wpb=8492.6, bsz=328.7, num_updates=48900, lr=6.39529e-05, gnorm=0.53, clip=0, loss_scale=32, train_wall=69, gb_free=17.5, wall=40069
2023-08-13 10:08:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-08-13 10:08:15 | INFO | train_inner | epoch 034:    380 / 1474 loss=1.869, trans_loss=4.707, nll_loss=1.89, w2v_ctc_loss=0.583, task_loss=1.353, contrastive_loss=0.175, total=4143.18, n_correct=2912.18, ppl=3.71, accuracy=70.289, wps=11840.2, ups=1.43, wpb=8286.4, bsz=314, num_updates=49000, lr=6.38877e-05, gnorm=0.527, clip=0, loss_scale=16, train_wall=70, gb_free=15.6, wall=40139
2023-08-13 10:09:24 | INFO | train_inner | epoch 034:    480 / 1474 loss=1.874, trans_loss=4.719, nll_loss=1.904, w2v_ctc_loss=0.602, task_loss=1.528, contrastive_loss=0.069, total=4080.7, n_correct=2858.56, ppl=3.74, accuracy=70.051, wps=11781.5, ups=1.44, wpb=8161.4, bsz=286.7, num_updates=49100, lr=6.38226e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=15.4, wall=40208
2023-08-13 10:10:33 | INFO | train_inner | epoch 034:    580 / 1474 loss=1.864, trans_loss=4.709, nll_loss=1.893, w2v_ctc_loss=0.588, task_loss=1.423, contrastive_loss=0.071, total=4126.98, n_correct=2904.37, ppl=3.71, accuracy=70.375, wps=11964.3, ups=1.45, wpb=8254, bsz=300.1, num_updates=49200, lr=6.37577e-05, gnorm=0.53, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=40277
2023-08-13 10:11:42 | INFO | train_inner | epoch 034:    680 / 1474 loss=1.866, trans_loss=4.717, nll_loss=1.902, w2v_ctc_loss=0.591, task_loss=1.444, contrastive_loss=0.066, total=4110.23, n_correct=2884.51, ppl=3.74, accuracy=70.179, wps=11940.1, ups=1.45, wpb=8220.5, bsz=297.1, num_updates=49300, lr=6.3693e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=16, wall=40346
2023-08-13 10:12:51 | INFO | train_inner | epoch 034:    780 / 1474 loss=1.877, trans_loss=4.734, nll_loss=1.925, w2v_ctc_loss=0.584, task_loss=1.457, contrastive_loss=0.136, total=4087.05, n_correct=2858.51, ppl=3.8, accuracy=69.941, wps=11800, ups=1.44, wpb=8174.1, bsz=297.4, num_updates=49400, lr=6.36285e-05, gnorm=0.536, clip=0, loss_scale=16, train_wall=69, gb_free=15.8, wall=40415
2023-08-13 10:14:01 | INFO | train_inner | epoch 034:    880 / 1474 loss=1.877, trans_loss=4.725, nll_loss=1.913, w2v_ctc_loss=0.597, task_loss=1.498, contrastive_loss=0.094, total=4088.94, n_correct=2860.08, ppl=3.77, accuracy=69.947, wps=11778.6, ups=1.44, wpb=8177.9, bsz=294.2, num_updates=49500, lr=6.35642e-05, gnorm=0.54, clip=0, loss_scale=16, train_wall=69, gb_free=14.5, wall=40485
2023-08-13 10:15:10 | INFO | train_inner | epoch 034:    980 / 1474 loss=1.874, trans_loss=4.723, nll_loss=1.911, w2v_ctc_loss=0.601, task_loss=1.377, contrastive_loss=0.088, total=4175.9, n_correct=2922.92, ppl=3.76, accuracy=69.995, wps=12006.6, ups=1.44, wpb=8351.8, bsz=312.7, num_updates=49600, lr=6.35001e-05, gnorm=0.532, clip=0, loss_scale=16, train_wall=69, gb_free=13.4, wall=40554
2023-08-13 10:16:19 | INFO | train_inner | epoch 034:   1080 / 1474 loss=1.869, trans_loss=4.72, nll_loss=1.906, w2v_ctc_loss=0.599, task_loss=1.355, contrastive_loss=0.071, total=4152.17, n_correct=2912.62, ppl=3.75, accuracy=70.147, wps=12103.8, ups=1.46, wpb=8304.3, bsz=309, num_updates=49700, lr=6.34361e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=14.1, wall=40623
2023-08-13 10:17:28 | INFO | train_inner | epoch 034:   1180 / 1474 loss=1.871, trans_loss=4.721, nll_loss=1.907, w2v_ctc_loss=0.593, task_loss=1.448, contrastive_loss=0.084, total=4101.68, n_correct=2875.91, ppl=3.75, accuracy=70.115, wps=11899.6, ups=1.45, wpb=8203.4, bsz=298, num_updates=49800, lr=6.33724e-05, gnorm=0.535, clip=0, loss_scale=16, train_wall=69, gb_free=15.9, wall=40692
2023-08-13 10:18:37 | INFO | train_inner | epoch 034:   1280 / 1474 loss=1.866, trans_loss=4.716, nll_loss=1.901, w2v_ctc_loss=0.591, task_loss=1.416, contrastive_loss=0.068, total=4146.01, n_correct=2907.91, ppl=3.73, accuracy=70.138, wps=12066.8, ups=1.46, wpb=8292, bsz=300.6, num_updates=49900, lr=6.33089e-05, gnorm=0.528, clip=0, loss_scale=16, train_wall=68, gb_free=17, wall=40761
2023-08-13 10:19:47 | INFO | train_inner | epoch 034:   1380 / 1474 loss=1.882, trans_loss=4.727, nll_loss=1.915, w2v_ctc_loss=0.604, task_loss=1.343, contrastive_loss=0.132, total=4197.99, n_correct=2935.35, ppl=3.77, accuracy=69.923, wps=12020.2, ups=1.43, wpb=8396, bsz=321.1, num_updates=50000, lr=6.32456e-05, gnorm=0.531, clip=0, loss_scale=16, train_wall=69, gb_free=17, wall=40831
2023-08-13 10:19:47 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2023-08-13 10:19:47 | INFO | fairseq_cli.train | begin validation on "dev_st" subset
2023-08-13 10:20:10 | INFO | dev_st | epoch 034 | valid on 'dev_st' subset | loss 3.953 | trans_loss 5.161 | nll_loss 2.413 | w2v_ctc_loss 1.315 | task_loss 4.655 | contrastive_loss 0.293 | total 4003.4 | n_correct 2687.2 | ppl 5.33 | accuracy 67.123 | uer 17.134 | wer 19.201 | raw_wer 19.201 | bleu 22.29 | wps 2104.6 | wpb 4003.4 | bsz 141.8 | num_updates 50000 | best_bleu 22.82
2023-08-13 10:20:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 50000 updates
2023-08-13 10:20:10 | INFO | fairseq.trainer | Saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-13 10:20:14 | INFO | fairseq.trainer | Finished saving checkpoint to /mnt/zhangyh/fairseq-AT/egs/pretrain-all/checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_34_50000.pt
2023-08-13 10:20:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint ./checkpoints/mustc/st/ende_shrink_v1_merge_large_0812_AT_sentence_alpha1.5_mt0.5/checkpoint_34_50000.pt (epoch 34 @ 50000 updates, score 22.29) (writing took 22.836799835786223 seconds)
2023-08-13 10:20:34 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-08-13 10:20:34 | INFO | train | epoch 034 | loss 1.872 | trans_loss 4.719 | nll_loss 1.905 | w2v_ctc_loss 0.593 | task_loss 1.415 | contrastive_loss 0.108 | total 4132.44 | n_correct 2897.7 | ppl 3.74 | accuracy 70.121 | wps 11284.6 | ups 1.37 | wpb 8264.9 | bsz 304.1 | num_updates 50000 | lr 6.32456e-05 | gnorm 0.532 | clip 0 | loss_scale 16 | train_wall 949 | gb_free 17 | wall 40878
2023-08-13 10:20:34 | INFO | fairseq_cli.train | done training in 40826.8 seconds
Exception in thread Thread-7:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-6:
Traceback (most recent call last):
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    self.run()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/site-packages/tensorboardX/event_file_writer.py", line 202, in run
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    data = self._queue.get(True, queue_wait_duration)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/queues.py", line 111, in get
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    res = self._recv_bytes()
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    raise EOFError
EOFError
    raise EOFError
EOFError
    buf = self._recv_bytes(maxlength)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
/home/zhangyh/miniconda3/envs/st-at/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1472 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
